<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Untitled</title>
</head>
<body><div class="page"><p/>
<p>Introduction to 
Logic Circuits
&amp; Logic Design
with VHDL
</p>
<p>Brock J. LaMeres</p>
<p/>
</div>
<div class="page"><p/>
<p>INTRODUCTION TO LOGIC CIRCUITS &amp;
</p>
<p>LOGIC DESIGN WITH VHDL</p>
<p/>
</div>
<div class="page"><p/>
</div>
<div class="page"><p/>
<p>INTRODUCTION TO LOGIC CIRCUITS &amp;
</p>
<p>LOGIC DESIGN WITH VHDL
1ST EDITION
</p>
<p>Brock J. LaMeres</p>
<p/>
</div>
<div class="page"><p/>
<p>Editor
Brock J. LaMeres
Department of Electrical &amp; Computer Engineering
Montana State University
Bozeman, MT, USA
</p>
<p>ISBN 978-3-319-34194-1 ISBN 978-3-319-34195-8 (eBook)
DOI 10.1007/978-3-319-34195-8
</p>
<p>Library of Congress Control Number: 2016940960
</p>
<p># Springer International Publishing Switzerland 2017
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the material is
concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting, reproduction
on microfilms or in any other physical way, and transmission or information storage and retrieval, electronic
adaptation, computer software, or by similar or dissimilar methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication does not
imply, even in the absence of a specific statement, that such names are exempt from the relevant protective laws and
regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this book are believed
to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors give a warranty,
express or implied, with respect to the material contained herein or for any errors or omissions that may have been
made.
</p>
<p>Printed on acid-free paper
</p>
<p>This Springer imprint is published by Springer Nature
The registered company is Springer International Publishing AG Switzerland</p>
<p/>
</div>
<div class="page"><p/>
<p>Preface
The purpose of this new book is to fill a void that has appeared in the instruction of digital circuits
</p>
<p>over the past decade due to the rapid abstraction of system design. Up until the mid-1980s, digital
</p>
<p>circuits were designed using classical techniques. Classical techniques relied heavily on manual design
</p>
<p>practices for the synthesis, minimization, and interfacing of digital systems. Corresponding to this design
</p>
<p>style, academic textbooks were developed that taught classical digital design techniques. Around 1990,
</p>
<p>large-scale digital systems began being designed using hardware description languages (HDL) and
</p>
<p>automated synthesis tools. Broad-scale adoption of this modern design approach spread through the
</p>
<p>industry during this decade. Around 2000, hardware description languages and the modern digital
</p>
<p>design approach began to be taught in universities, mainly at the senior and graduate level. There
</p>
<p>were a variety of reasons that the modern digital design approach did not penetrate the lower levels of
</p>
<p>academia during this time. First, the design and simulation tools were difficult to use and overwhelmed
</p>
<p>freshman and sophomore students. Second, the ability to implement the designs in a laboratory setting
</p>
<p>was infeasible. The modern design tools at the time were targeted at custom integrated circuits, which
</p>
<p>are cost and time prohibitive to implement in a university setting. Between 2000 and 2005, rapid
</p>
<p>advances in programmable logic and design tools allowed the modern digital design approach to be
</p>
<p>implemented in a university setting, even in lower level courses. This allowed students to learn the
</p>
<p>modern design approach based on HDLs and prototype their designs in real hardware, mainly Field
</p>
<p>Programmable Gate Arrays (FPGAs). This spurred an abundance of textbooks to be authored teaching
</p>
<p>hardware description languages and higher levels of design abstraction. This trend has continued until
</p>
<p>today. While abstraction is a critical tool for engineering design, the rapid movement toward teaching only
</p>
<p>the modern digital design techniques has left a void for freshman and sophomore level courses in digital
</p>
<p>circuitry. Legacy textbooks that teach the classical design approach are outdated and do not contain
</p>
<p>sufficient coverage of HDLs to prepare the students for follow-on classes. Newer textbooks that teach
</p>
<p>the modern digital design approach move immediately into high-level behavioral modeling with minimal
</p>
<p>or no coverage of the underlying hardware used to implement the systems. As a result, students are not
</p>
<p>being provided the resources to understand the fundamental hardware theory that lies beneath the
</p>
<p>modern abstraction such as interfacing, gate-level implementation, and technology optimization.
</p>
<p>Students moving too rapidly into high levels of abstraction have little understanding of what is going
</p>
<p>on when they click the &ldquo;compile &amp; synthesize&rdquo; button of their design tool. This leads to graduates who can
</p>
<p>model a breadth of different systems in an HDL, but have no depth into how the system is implemented in
</p>
<p>hardware. This becomes problematic when an issue arises in a real design and there is no foundational
</p>
<p>knowledge for the students to fall back on in order to debug the problem.
</p>
<p>This new book addresses the lower level foundational void by providing a comprehensive, bottoms-
</p>
<p>up, coverage of digital systems. The book begins with a description of lower level hardware including
</p>
<p>binary representations, gate-level implementation, interfacing, and simple combinational logic design.
</p>
<p>Only after a foundation has been laid in the underlying hardware theory is the VHDL language
</p>
<p>introduced. The VHDL introduction gives only the basic concepts of the language in order to model,
</p>
<p>simulate, and synthesize combinational logic. This allows the students to gain familiarity with the
</p>
<p>language and the modern design approach without getting overwhelmed by the full capability of the
</p>
<p>language. The book then covers sequential logic and finite state machines at the component level. Once
</p>
<p>this secondary foundation has been laid, the remaining capabilities of VHDL are presented that allow
</p>
<p>sophisticated, synchronous systems to be modeled. An entire chapter is then dedicated to examples of
</p>
<p>sequential system modeling, which allows the students to learn by example. The second part of the
</p>
<p>textbook introduces the details of programmable logic, semiconductor memory, and arithmetic circuits.
</p>
<p>The book culminates with a discussion of computer system design, which incorporates all of the
</p>
<p>v</p>
<p/>
</div>
<div class="page"><p/>
<p>knowledge gained in the previous chapters. Each component of a computer system is described with an
</p>
<p>accompanying VHDL implementation, all while continually reinforcing the underlying hardware beneath
</p>
<p>the HDL abstraction.
</p>
<p>Written the Way It Is Taught
</p>
<p>The organization of this book is designed to follow the way in which the material is actually learned.
</p>
<p>Topics are presented only once sufficient background has been provided by earlier chapters to fully
</p>
<p>understand the material. An example of this learning-oriented organization is how the VHDL language is
</p>
<p>broken into two chapters. Chapter 5 presents an introduction to VHDL and the basic constructs to model
</p>
<p>combinational logic. This is an ideal location to introduce the language because the reader has just
</p>
<p>learned about combinational logic theory in Chap. 4. This allows the student to begin gaining experience
</p>
<p>using the VHDL simulation tools on basic combinational logic circuits. The more advanced constructs of
</p>
<p>VHDL such as sequential modeling and test benches are presented in Chap. 8 only after a thorough
</p>
<p>background in sequential logic is presented in Chap. 7. Another example of this learning-oriented
</p>
<p>approach is how arithmetic circuits are not introduced until Chap. 12. While technically the arithmetic
</p>
<p>circuits in Chap. 12 are combinational logic circuits and could be presented in Chap. 4, the student does
</p>
<p>not have the necessary background in Chap. 4 to fully understand the operation of the arithmetic circuitry
</p>
<p>so its introduction is postponed.
</p>
<p>This incremental, just-in-time presentation of material allows the book to follow the way the material
</p>
<p>is actually taught in the classroom. This design also avoids the need for the instructor to assign sections
</p>
<p>that move back-and-forth through the text. This not only reduces course design effort for the instructor
</p>
<p>but also allows the student to know where they are in the sequence of learning. At any point, the student
</p>
<p>should know the material in prior chapters and be moving toward understanding the material in
</p>
<p>subsequent ones.
</p>
<p>An additional advantage of this book&rsquo;s organization is that it supports giving the student hands-on
</p>
<p>experience with digital circuitry for courses with an accompanying laboratory component. The flow is
</p>
<p>designed to support lab exercises that begin using discrete logic gates on a breadboard and then move
</p>
<p>into HDL-based designs implemented on off-the-shelf FPGA boards. Using this approach to a laboratory
</p>
<p>experience gives the student experience with the basic electrical operation of digital circuits, interfacing,
</p>
<p>and HDL-based designs.
</p>
<p>Learning Outcomes
</p>
<p>Each chapter begins with an explanation of its learning objective followed by a brief preview of the
</p>
<p>chapter topics. The specific learning outcomes are then presented for the chapter in the form of concise
</p>
<p>statements about the measurable knowledge and/or skills the student will possess by the end of the
</p>
<p>chapter. Each section addresses a single, specific learning outcome. This eases the process of
</p>
<p>assessment and gives specific details on student performance. There are 600+ exercise problems
</p>
<p>and concept check questions for each section tied directly to specific learning outcomes for both
</p>
<p>formative and summative assessment.
</p>
<p>Teaching by Example
</p>
<p>With over 200 worked examples, concept checks for each section, 200+ supporting figures, and 600
</p>
<p>+ exercise problems, students are provided with multiple ways to learn. Each topic is described in a clear,
</p>
<p>concise written form with accompanying figures as necessary. This is then followed by annotated worked
</p>
<p>examples that match the form of the exercise problems at the end of each chapter. Additionally, concept
</p>
<p>check questions are placed at the end of each section in the book to measure the student&rsquo;s general
</p>
<p>vi &bull; Preface</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_5">http://dx.doi.org/10.1007/978-3-319-34195-8_5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_4">http://dx.doi.org/10.1007/978-3-319-34195-8_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_8">http://dx.doi.org/10.1007/978-3-319-34195-8_8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_7">http://dx.doi.org/10.1007/978-3-319-34195-8_7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_12">http://dx.doi.org/10.1007/978-3-319-34195-8_12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_12">http://dx.doi.org/10.1007/978-3-319-34195-8_12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_4">http://dx.doi.org/10.1007/978-3-319-34195-8_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_4">http://dx.doi.org/10.1007/978-3-319-34195-8_4</a></div>
</div>
<div class="page"><p/>
<p>understanding of the material using a concept inventory assessment style. These features provide the
</p>
<p>student multiple ways to learn the material and build an understanding of digital circuitry.
</p>
<p>Course Design
</p>
<p>The book can be used in multiple ways. The first is to use the book to cover two, semester-based
</p>
<p>college courses in digital logic. The first course in this sequence is an introduction to logic circuits and
</p>
<p>covers Chaps. 1&ndash;7. This introductory course, which is found in nearly all accredited electrical and
</p>
<p>computer engineering programs, gives students a basic foundation in digital hardware and interfacing.
</p>
<p>Chapters 1&ndash;7 only cover relevant topics in digital circuits to make room for a thorough introduction to
</p>
<p>VHDL. At the end of this course students have a solid foundation in digital circuits and are able to design
</p>
<p>and simulate VHDL models of concurrent and hierarchical systems. The second course in this sequence
</p>
<p>covers logic design using chapters 8&ndash;13. In this second course, students learn the advanced features of
</p>
<p>VHDL such as packages, sequential behavioral modeling, and test benches. This provides the basis for
</p>
<p>building larger digital systems such as registers, finite state machines, and arithmetic circuits. Chapter 13
</p>
<p>brings all of the concepts together through the design of a simple 8-bit computer system that can be
</p>
<p>simulated and implemented using many off-the-shelf FPGA boards.
</p>
<p>This book can also be used in a more accelerated digital logic course that reaches a higher level of
</p>
<p>abstraction in a single semester. This is accomplished by skipping some chapters and moving quickly
</p>
<p>through others. In this use model, it is likely that Chap. 2 on numbers systems and Chap. 3 on digital
</p>
<p>circuits would be quickly referenced but not covered in detail. Chapters 4 and 7 could also be covered
</p>
<p>quickly in order to move rapidly into VHDL modeling without spending significant time looking at the
</p>
<p>underlying hardware implementation. This approach allows a higher level of abstraction to be taught but
</p>
<p>provides the student with the reference material so that they can delve in the details of the hardware
</p>
<p>implementation if interested.
</p>
<p>All exercise and concept problems that do not involve a VHDL model are designed so that they can
</p>
<p>be implemented as a multiple choice or numeric entry question in a standard course management
</p>
<p>system. This allows the questions to be automatically graded. For the VHDL design questions, it is
</p>
<p>expected that the students will upload their VHDL source files and screenshots of their simulation
</p>
<p>waveforms to the course management system for manual grading by the instructor or teaching assistant.
</p>
<p>Instructor Resources
</p>
<p>Instructors adopting this book can request a solution manual that contains a graphic-rich description
</p>
<p>of the solutions for each of the 600+ exercise problems. Instructors can also receive the VHDL solutions
</p>
<p>and test benches for each VHDL design exercise. A complementary lab manual has also been
</p>
<p>developed to provide additional learning activities based on both the 74HC discrete logic family and
</p>
<p>an off-the-shelf FPGA board. This manual is provided separately from the book in order to support the
</p>
<p>ever-changing technology options available for laboratory exercises.
</p>
<p>Bozeman, MT, USA Brock J. LaMeres
</p>
<p>Preface &bull; vii</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_1">http://dx.doi.org/10.1007/978-3-319-34195-8_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_7">http://dx.doi.org/10.1007/978-3-319-34195-8_7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_1">http://dx.doi.org/10.1007/978-3-319-34195-8_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_7">http://dx.doi.org/10.1007/978-3-319-34195-8_7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_8">http://dx.doi.org/10.1007/978-3-319-34195-8_8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_13">http://dx.doi.org/10.1007/978-3-319-34195-8_13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_13">http://dx.doi.org/10.1007/978-3-319-34195-8_13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_2">http://dx.doi.org/10.1007/978-3-319-34195-8_2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_3">http://dx.doi.org/10.1007/978-3-319-34195-8_3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_4">http://dx.doi.org/10.1007/978-3-319-34195-8_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_7">http://dx.doi.org/10.1007/978-3-319-34195-8_7</a></div>
</div>
<div class="page"><p/>
</div>
<div class="page"><p/>
<p>Acknowledgements
</p>
<p>Dr. LaMeres would like to thank his family for their endless support of this endeavor. To JoAnn, my
</p>
<p>beautiful wife and soul mate, nothing that I do is possible without you by my side. To Alexis and
</p>
<p>Kylie, my two wonderful daughters, you are my inspiration and the reason I have hope.
</p>
<p>Dr. LaMeres would also like to thank the 400+ engineering students at Montana State University
</p>
<p>that helped proofread this book in preparation for the first edition.
</p>
<p>ix</p>
<p/>
</div>
<div class="page"><p/>
</div>
<div class="page"><p/>
<p>Contents
1: INTRODUCTION: ANALOG VS. DIGITAL ............................................................... 1
</p>
<p>1.1 DIFFERENCES BETWEEN ANALOG AND DIGITAL SYSTEMS .................................................. 1
</p>
<p>1.2 ADVANTAGES OF DIGITAL SYSTEMS OVER ANALOG SYSTEMS ............................................ 2
</p>
<p>2: NUMBER SYSTEMS ................................................................................................. 7
</p>
<p>2.1 POSITIONAL NUMBER SYSTEMS ..................................................................................... 7
</p>
<p>2.1.1 Generic Structure ............................................................................................. 8
</p>
<p>2.1.2 Decimal Number System (Base 10) ................................................................ 9
</p>
<p>2.1.3 Binary Number System (Base 2) ..................................................................... 9
</p>
<p>2.1.4 Octal Number System (Base 8) ...................................................................... 10
</p>
<p>2.1.5 Hexadecimal Number System (Base 16) ........................................................ 10
</p>
<p>2.2 BASE CONVERSION ..................................................................................................... 11
</p>
<p>2.2.1 Converting to Decimal ..................................................................................... 11
</p>
<p>2.2.2 Converting from Decimal ................................................................................. 14
</p>
<p>2.2.3 Converting Between 2n Bases ........................................................................ 17
</p>
<p>2.3 BINARY ARITHMETIC .................................................................................................... 21
</p>
<p>2.3.1 Addition (Carries) ............................................................................................. 21
</p>
<p>2.3.2 Subtraction (Borrows) ...................................................................................... 22
</p>
<p>2.4 UNSIGNED AND SIGNED NUMBERS ................................................................................. 23
</p>
<p>2.4.1 Unsigned Numbers .......................................................................................... 23
</p>
<p>2.4.2 Signed Numbers .............................................................................................. 24
</p>
<p>3: DIGITAL CIRCUITRY AND INTERFACING .............................................................. 37
</p>
<p>3.1 BASIC GATES ............................................................................................................. 37
</p>
<p>3.1.1 Describing the Operation of a Logic Circuit .................................................... 37
</p>
<p>3.1.2 The Buffer ........................................................................................................ 39
</p>
<p>3.1.3 The Inverter ...................................................................................................... 40
</p>
<p>3.1.4 The AND Gate ................................................................................................. 40
</p>
<p>3.1.5 The NAND Gate .............................................................................................. 41
</p>
<p>3.1.6 The OR Gate ................................................................................................... 41
</p>
<p>3.1.7 The NOR Gate ................................................................................................. 41
</p>
<p>3.1.8 The XOR Gate ................................................................................................. 42
</p>
<p>3.1.9 The XNOR Gate .............................................................................................. 43
</p>
<p>3.2 DIGITAL CIRCUIT OPERATION ........................................................................................ 44
</p>
<p>3.2.1 Logic Levels ..................................................................................................... 44
</p>
<p>3.2.2 Output DC Specifications ................................................................................ 45
</p>
<p>3.2.3 Input DC Specifications ................................................................................... 46
</p>
<p>3.2.4 Noise Margins .................................................................................................. 47
</p>
<p>3.2.5 Power Supplies ................................................................................................ 48
</p>
<p>3.2.6 Switching Characteristics ................................................................................ 51
</p>
<p>3.2.7 Data Sheets ..................................................................................................... 51
</p>
<p>xi</p>
<p/>
</div>
<div class="page"><p/>
<p>3.3 LOGIC FAMILIES .......................................................................................................... 56
</p>
<p>3.3.1 Complementary Metal Oxide Semiconductors ................................................ 56
</p>
<p>3.3.2 Transistor-Transistor Logic .............................................................................. 65
</p>
<p>3.3.3 The 7400 Series Logic Families ...................................................................... 67
</p>
<p>3.4 DRIVING LOADS .......................................................................................................... 71
</p>
<p>3.4.1 Driving Other Gates ......................................................................................... 71
</p>
<p>3.4.2 Driving Resistive Loads ................................................................................... 73
</p>
<p>3.4.3 Driving LEDs .................................................................................................... 75
</p>
<p>4: COMBINATIONAL LOGIC DESIGN ......................................................................... 81
</p>
<p>4.1 BOOLEAN ALGEBRA ..................................................................................................... 81
</p>
<p>4.1.1 Operations ....................................................................................................... 82
</p>
<p>4.1.2 Axioms ............................................................................................................. 82
</p>
<p>4.1.3 Theorems ......................................................................................................... 83
</p>
<p>4.1.4 Functionally Complete Operation Sets ............................................................ 98
</p>
<p>4.2 COMBINATIONAL LOGIC ANALYSIS .................................................................................. 99
</p>
<p>4.2.1 Finding the Logic Expression from a Logic Diagram ...................................... 99
</p>
<p>4.2.2 Finding the Truth Table from a Logic Diagram ................................................ 100
</p>
<p>4.2.3 Timing Analysis of a Combinational Logic Circuit ........................................... 101
</p>
<p>4.3 COMBINATIONAL LOGIC SYNTHESIS ................................................................................ 103
</p>
<p>4.3.1 Canonical Sum of Products ............................................................................. 103
</p>
<p>4.3.2 The Minterm List (Σ) ........................................................................................ 104
</p>
<p>4.3.3 Canonical Product of Sums (POS) .................................................................. 106
</p>
<p>4.3.4 The Maxterm List (Π) ....................................................................................... 108
</p>
<p>4.3.5 Minterm and Maxterm List Equivalence .......................................................... 110
</p>
<p>4.4 LOGIC MINIMIZATION .................................................................................................... 112
</p>
<p>4.4.1 Algebraic Minimization ..................................................................................... 112
</p>
<p>4.4.2 Minimization Using Karnaugh Maps ................................................................ 113
</p>
<p>4.4.3 Don&rsquo;t Cares ...................................................................................................... 125
</p>
<p>4.4.4 Using XOR Gates ............................................................................................ 126
</p>
<p>4.5 TIMING HAZARDS AND GLITCHES ................................................................................... 129
</p>
<p>5: VHDL (PART 1) ......................................................................................................... 139
</p>
<p>5.1 HISTORY OF HARDWARE DESCRIPTION LANGUAGES ......................................................... 139
</p>
<p>5.2 HDL ABSTRACTION ..................................................................................................... 143
</p>
<p>5.3 THE MODERN DIGITAL DESIGN FLOW ............................................................................ 146
</p>
<p>5.4 VHDL CONSTRUCTS .................................................................................................. 149
</p>
<p>5.4.1 Data Types ....................................................................................................... 150
</p>
<p>5.4.2 Libraries and Packages ................................................................................... 152
</p>
<p>5.4.3 The Entity ......................................................................................................... 152
</p>
<p>5.4.4 The Architecture .............................................................................................. 153
</p>
<p>5.5 MODELING CONCURRENT FUNCTIONALITY IN VHDL ......................................................... 155
</p>
<p>5.5.1 VHDL Operators .............................................................................................. 155
</p>
<p>5.5.2 Concurrent Signal Assignments ...................................................................... 158
</p>
<p>5.5.3 Concurrent Signal Assignments with Logical Operators ................................ 159
</p>
<p>xii &bull; Contents</p>
<p/>
</div>
<div class="page"><p/>
<p>5.5.4 Conditional Signal Assignments ...................................................................... 160
</p>
<p>5.5.5 Selected Signal Assignments .......................................................................... 161
</p>
<p>5.5.6 Delayed Signal Assignments .......................................................................... 164
</p>
<p>5.6 STRUCTURAL DESIGN USING COMPONENTS .................................................................... 165
</p>
<p>5.6.1 Component Instantiation .................................................................................. 166
</p>
<p>5.7 OVERVIEW OF SIMULATION TEST BENCHES ..................................................................... 168
</p>
<p>6: MSI LOGIC ................................................................................................................ 175
</p>
<p>6.1 DECODERS ................................................................................................................. 175
</p>
<p>6.1.1 Example: One-Hot Decoder ............................................................................ 175
</p>
<p>6.1.2 Example: Seven-Segment Display Decoder ................................................... 179
</p>
<p>6.2 ENCODERS ................................................................................................................. 183
</p>
<p>6.2.1 Example: One-Hot Binary Encoder ................................................................. 183
</p>
<p>6.3 MULTIPLEXERS ............................................................................................................ 185
</p>
<p>6.4 DEMULTIPLEXERS ........................................................................................................ 187
</p>
<p>7: SEQUENTIAL LOGIC DESIGN ................................................................................ 195
</p>
<p>7.1 SEQUENTIAL LOGIC STORAGE DEVICES .......................................................................... 195
</p>
<p>7.1.1 The Cross-Coupled Inverter Pair ..................................................................... 195
</p>
<p>7.1.2 Metastability ..................................................................................................... 196
</p>
<p>7.1.3 The SR Latch ................................................................................................... 198
</p>
<p>7.1.4 The S0R0 Latch ................................................................................................. 201
</p>
<p>7.1.5 SR Latch with Enable ...................................................................................... 204
</p>
<p>7.1.6 The D-Latch ..................................................................................................... 205
</p>
<p>7.1.7 The D-Flip-Flop ................................................................................................ 207
</p>
<p>7.2 SEQUENTIAL LOGIC TIMING CONSIDERATIONS .................................................................. 210
</p>
<p>7.3 COMMON CIRCUITS BASED ON SEQUENTIAL STORAGE DEVICES ........................................ 212
</p>
<p>7.3.1 Toggle Flop Clock Divider ................................................................................ 212
</p>
<p>7.3.2 Ripple Counter ................................................................................................. 213
</p>
<p>7.3.3 Switch Debouncing .......................................................................................... 213
</p>
<p>7.3.4 Shift Registers ................................................................................................. 217
</p>
<p>7.4 FINITE-STATE MACHINES .............................................................................................. 219
</p>
<p>7.4.1 Describing the Functionality of an FSM .......................................................... 219
</p>
<p>7.4.2 Logic Synthesis for an FSM ............................................................................ 221
</p>
<p>7.4.3 FSM Design Process Overview ...................................................................... 228
</p>
<p>7.4.4 FSM Design Examples .................................................................................... 229
</p>
<p>7.5 COUNTERS ................................................................................................................. 236
</p>
<p>7.5.1 2-Bit Binary Up Counter ................................................................................... 236
</p>
<p>7.5.2 2-Bit Binary Up/Down Counter ........................................................................ 237
</p>
<p>7.5.3 2-Bit Gray Code Up Counter ........................................................................... 240
</p>
<p>7.5.4 2-Bit Gray Code Up/Down Counter ................................................................. 242
</p>
<p>7.5.5 3-Bit One-Hot Up Counter ............................................................................... 244
</p>
<p>7.5.6 3-Bit One-Hot Up/Down Counter ..................................................................... 245
</p>
<p>7.6 FINITE-STATE MACHINE&rsquo;S RESET CONDITION .................................................................. 249
</p>
<p>Contents &bull; xiii</p>
<p/>
</div>
<div class="page"><p/>
<p>7.7 SEQUENTIAL LOGIC ANALYSIS ....................................................................................... 250
</p>
<p>7.7.1 Finding the State Equations and Output Logic Expressions of an FSM ........ 250
</p>
<p>7.7.2 Finding the State Transition Table of an FSM ................................................. 251
</p>
<p>7.7.3 Finding the State Diagram of an FSM ............................................................. 252
</p>
<p>7.7.4 Determining the Maximum Clock Frequency of an FSM ................................ 253
</p>
<p>8: VHDL (PART 2) ......................................................................................................... 265
</p>
<p>8.1 THE PROCESS ............................................................................................................ 265
</p>
<p>8.1.1 Sensitivity List .................................................................................................. 265
</p>
<p>8.1.2 The Wait Statement ......................................................................................... 266
</p>
<p>8.1.3 Sequential Signal Assignments ....................................................................... 267
</p>
<p>8.1.4 Variables .......................................................................................................... 269
</p>
<p>8.2 CONDITIONAL PROGRAMMING CONSTRUCTS .................................................................... 270
</p>
<p>8.2.1 If/Then Statements .......................................................................................... 270
</p>
<p>8.2.2 Case Statements ............................................................................................. 272
</p>
<p>8.2.3 Infinite Loops ................................................................................................... 273
</p>
<p>8.2.4 While Loops ..................................................................................................... 275
</p>
<p>8.2.5 For Loops ......................................................................................................... 275
</p>
<p>8.3 SIGNAL ATTRIBUTES .................................................................................................... 276
</p>
<p>8.4 TEST BENCHES .......................................................................................................... 278
</p>
<p>8.4.1 Report Statement ............................................................................................. 279
</p>
<p>8.4.2 Assert Statement ............................................................................................. 280
</p>
<p>8.5 PACKAGES ................................................................................................................. 281
</p>
<p>8.5.1 STD_LOGIC_1164 .......................................................................................... 282
</p>
<p>8.5.2 NUMERIC_STD ............................................................................................... 286
</p>
<p>8.5.3 NUMERIC_STD_UNSIGNED ......................................................................... 288
</p>
<p>8.5.4 NUMERIC_BIT ................................................................................................ 288
</p>
<p>8.5.5 NUMERIC_BIT_UNSIGNED ........................................................................... 289
</p>
<p>8.5.6 MATH_REAL ................................................................................................... 289
</p>
<p>8.5.7 MATH_COMPLEX ........................................................................................... 291
</p>
<p>8.5.8 TEXTIO and STD_LOGIC_TEXTIO ................................................................ 291
</p>
<p>8.5.9 Legacy Packages (STD_LOGIC_ARITH/UNSIGNED/SIGNED) ................... 302
</p>
<p>9: BEHAVIORAL MODELING OF SEQUENTIAL LOGIC ............................................ 309
</p>
<p>9.1 MODELING SEQUENTIAL STORAGE DEVICES IN VHDL ..................................................... 309
</p>
<p>9.1.1 D-Latch ............................................................................................................ 309
</p>
<p>9.1.2 D-Flip-Flop ....................................................................................................... 310
</p>
<p>9.1.3 D-Flip-Flop with Asynchronous Reset ............................................................. 310
</p>
<p>9.1.4 D-Flip-Flop with Asynchronous Reset and Preset .......................................... 311
</p>
<p>9.1.5 D-Flip-Flop with Synchronous Enable ............................................................. 312
</p>
<p>9.2 MODELING FINITE-STATE MACHINES IN VHDL ................................................................ 313
</p>
<p>9.2.1 Modeling the States with User-Defined, Enumerated Data Types ................. 315
</p>
<p>9.2.2 The State Memory Process ............................................................................. 315
</p>
<p>9.2.3 The Next State Logic Process ......................................................................... 315
</p>
<p>9.2.4 The Output Logic Process ............................................................................... 316
</p>
<p>9.2.5 Explicitly Defining State Codes with Subtypes ............................................... 318
</p>
<p>xiv &bull; Contents</p>
<p/>
</div>
<div class="page"><p/>
<p>9.3 FSM DESIGN EXAMPLES IN VHDL .............................................................................. 319
</p>
<p>9.3.1 Serial Bit Sequence Detector in VHDL ........................................................... 319
</p>
<p>9.3.2 Vending Machine Controller in VHDL ............................................................. 321
</p>
<p>9.3.3 2-Bit, Binary Up/Down Counter in VHDL ........................................................ 323
</p>
<p>9.4 MODELING COUNTERS IN VHDL ................................................................................... 325
</p>
<p>9.4.1 Counters in VHDL Using the Type UNSIGNED .............................................. 325
</p>
<p>9.4.2 Counters in VHDL Using the Type INTEGER ................................................. 326
</p>
<p>9.4.3 Counters in VHDL Using the Type STD_LOGIC_VECTOR ........................... 327
</p>
<p>9.4.4 Counters with Enables in VHDL ...................................................................... 329
</p>
<p>9.4.5 Counters with Loads ........................................................................................ 330
</p>
<p>9.5 RTL MODELING ......................................................................................................... 332
</p>
<p>9.5.1 Modeling Registers in VHDL ........................................................................... 332
</p>
<p>9.5.2 Shift Registers in VHDL ................................................................................... 333
</p>
<p>9.5.3 Registers as Agents on a Data Bus ................................................................ 334
</p>
<p>10: MEMORY ................................................................................................................ 341
</p>
<p>10.1 MEMORY ARCHITECTURE AND TERMINOLOGY ................................................................... 341
</p>
<p>10.1.1 Memory Map Model ......................................................................................... 341
</p>
<p>10.1.2 Volatile vs. Nonvolatile Memory ...................................................................... 342
</p>
<p>10.1.3 Read-Only vs. Read/Write Memory ................................................................ 342
</p>
<p>10.1.4 Random Access vs. Sequential Access ......................................................... 342
</p>
<p>10.2 NONVOLATILE MEMORY TECHNOLOGY ............................................................................ 343
</p>
<p>10.2.1 ROM Architecture ............................................................................................ 343
</p>
<p>10.2.2 Mask Read-Only Memory ............................................................................... 346
</p>
<p>10.2.3 Programmable Read-Only Memory ................................................................ 347
</p>
<p>10.2.4 Erasable Programmable Read-Only Memory ................................................. 348
</p>
<p>10.2.5 Electrically Erasable Programmable Read-Only Memory .............................. 350
</p>
<p>10.2.6 FLASH Memory ............................................................................................... 351
</p>
<p>10.3 VOLATILE MEMORY TECHNOLOGY .................................................................................. 352
</p>
<p>10.3.1 Static Random Access Memory ...................................................................... 352
</p>
<p>10.3.2 Dynamic Random Access Memory ................................................................. 355
</p>
<p>10.4 MODELING MEMORY WITH VHDL ................................................................................. 362
</p>
<p>10.4.1 Read-Only Memory in VHDL ........................................................................... 362
</p>
<p>10.4.2 Read/Write Memory in VHDL .......................................................................... 364
</p>
<p>11: PROGRAMMABLE LOGIC ..................................................................................... 371
</p>
<p>11.1 PROGRAMMABLE ARRAYS ............................................................................................. 371
</p>
<p>11.1.1 Programmable Logic Array .............................................................................. 371
</p>
<p>11.1.2 Programmable Array Logic .............................................................................. 372
</p>
<p>11.1.3 Generic Array Logic ......................................................................................... 373
</p>
<p>11.1.4 Hard Array Logic .............................................................................................. 374
</p>
<p>11.1.5 Complex Programmable Logic Devices .......................................................... 374
</p>
<p>11.2 FIELD PROGRAMMABLE GATE ARRAYS ........................................................................... 375
</p>
<p>11.2.1 Configurable Logic Block (or Logic Element) .................................................. 376
</p>
<p>11.2.2 Look-Up Tables ................................................................................................ 377
</p>
<p>11.2.3 Programmable Interconnect Points (PIPs) ...................................................... 380
</p>
<p>Contents &bull; xv</p>
<p/>
</div>
<div class="page"><p/>
<p>11.2.4 Input/Output Block ........................................................................................... 381
</p>
<p>11.2.5 Configuration Memory ..................................................................................... 382
</p>
<p>12: ARITHMETIC CIRCUITS ........................................................................................ 385
</p>
<p>12.1 ADDITION ................................................................................................................... 385
</p>
<p>12.1.1 Half Adders ...................................................................................................... 385
</p>
<p>12.1.2 Full Adders ...................................................................................................... 386
</p>
<p>12.1.3 Ripple Carry Adder (RCA) ............................................................................... 388
</p>
<p>12.1.4 Carry Look Ahead Adder (CLA) ...................................................................... 390
</p>
<p>12.1.5 Adders in VHDL ............................................................................................... 393
</p>
<p>12.2 SUBTRACTION ............................................................................................................. 399
</p>
<p>12.3 MULTIPLICATION .......................................................................................................... 402
</p>
<p>12.3.1 Unsigned Multiplication ................................................................................... 402
</p>
<p>12.3.2 A Simple Circuit to Multiply by Powers of Two ................................................ 405
</p>
<p>12.3.3 Signed Multiplication ....................................................................................... 405
</p>
<p>12.4 DIVISION .................................................................................................................... 408
</p>
<p>12.4.1 Unsigned Division ............................................................................................ 408
</p>
<p>12.4.2 A Simple Circuit to Divide by Powers of Two .................................................. 411
</p>
<p>12.4.3 Signed Division ................................................................................................ 412
</p>
<p>13: COMPUTER SYSTEM DESIGN ............................................................................. 417
</p>
<p>13.1 COMPUTER HARDWARE ............................................................................................... 417
</p>
<p>13.1.1 Program Memory ............................................................................................. 418
</p>
<p>13.1.2 Data Memory ................................................................................................... 418
</p>
<p>13.1.3 Input/Output Ports ........................................................................................... 418
</p>
<p>13.1.4 Central Processing Unit ................................................................................... 419
</p>
<p>13.1.5 A Memory Mapped System ............................................................................. 420
</p>
<p>13.2 COMPUTER SOFTWARE ................................................................................................ 422
</p>
<p>13.2.1 Opcodes and Operands .................................................................................. 422
</p>
<p>13.2.2 Addressing Modes ........................................................................................... 423
</p>
<p>13.2.3 Classes of Instructions .................................................................................... 424
</p>
<p>13.3 COMPUTER IMPLEMENTATION: AN 8-BIT COMPUTER EXAMPLE ........................................... 431
</p>
<p>13.3.1 Top-Level Block Diagram ................................................................................ 431
</p>
<p>13.3.2 Instruction Set Design ..................................................................................... 432
</p>
<p>13.3.3 Memory System Implementation ..................................................................... 433
</p>
<p>13.3.4 CPU Implementation ....................................................................................... 438
</p>
<p>13.4 ARCHITECTURE CONSIDERATIONS .................................................................................. 457
</p>
<p>13.4.1 Von Neumann Architecture ............................................................................. 457
</p>
<p>13.4.2 Harvard Architecture ....................................................................................... 457
</p>
<p>APPENDIX A: LIST OF WORKED EXAMPLES ........................................................... 463
</p>
<p>SUGGESTED READINGS ............................................................................................ 469
</p>
<p>INDEX ............................................................................................................................ 471
</p>
<p>xvi &bull; Contents</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 1: Introduction: Analog
</p>
<p>vs. Digital
We often hear that we live in a digital age. This refers to the massive adoption of computer systems
</p>
<p>within every aspect of our lives from smart phones to automobiles to household appliances. This
</p>
<p>statement also refers to the transformation that has occurred to our telecommunications infrastructure
</p>
<p>that now transmits voice, video, and data using 1&rsquo;s and 0&rsquo;s. There are a variety of reasons that digital
</p>
<p>systems have become so prevalent in our lives. In order to understand these reasons, it is good to start
</p>
<p>with an understanding of what a digital system is and how it compares to its counterpart, the analog
</p>
<p>system. The goal of this chapter is to provide an understanding of the basic principles of analog and
</p>
<p>digital systems.
</p>
<p>Learning Outcomes&mdash;After completing this chapter, you will be able to:
</p>
<p>1.1 Describe the fundamental differences between analog and digital systems.
1.2 Describe the advantages of digital systems compared to analog systems.
</p>
<p>1.1 Differences Between Analog and Digital Systems
</p>
<p>Let&rsquo;s begin by looking at signaling. In electrical systems, signals represent information that is
</p>
<p>transmitted between devices using an electrical quantity (voltage or current). An analog signal is defined
</p>
<p>as a continuous, time-varying quantity that corresponds directly to the information it represents. An
</p>
<p>example of this would be a barometric pressure sensor that outputs an electrical voltage corresponding
</p>
<p>to the pressure being measured. As the pressure goes up, so does the voltage. While the range of the
</p>
<p>input (pressure) and output (voltage) will have different spans, there is a direct mapping between the
</p>
<p>pressure and voltage. Another example would be sound striking a traditional analog microphone. Sound
</p>
<p>is a pressure wave that travels through a medium such as air. As the pressure wave strikes the
</p>
<p>diaphragm in the microphone, the diaphragm moves back and forth. Through the process of inductive
</p>
<p>coupling, this movement is converted to an electric current. The characteristics of the current signal
</p>
<p>produced (e.g., frequency and magnitude) correspond directly to the characteristics of the incoming
</p>
<p>sound wave. The current can travel down a wire and go through another system that works in the
</p>
<p>opposite manner by inductively coupling the current onto another diaphragm, which in turn moves back
</p>
<p>and forth forming a pressure wave and thus sound (i.e., a speaker). In both of these examples, the
</p>
<p>electrical signal represents the actual information that is being transmitted and is considered analog.
</p>
<p>Analog signals can be represented mathematically as a function with respect to time.
</p>
<p>In digital signaling the electrical signal itself is not directly the information it represents; instead, the
</p>
<p>information is encoded. The most common type of encoding is binary (1&rsquo;s and 0&rsquo;s). The 1&rsquo;s and 0&rsquo;s are
</p>
<p>represented by the electrical signal. The simplest form of digital signaling is to define a threshold voltage
</p>
<p>directly in the middle of the range of the electrical signal. If the signal is above this threshold, the signal is
</p>
<p>representing a 1. If the signal is below this threshold, the signal is representing a 0. This type of signaling
</p>
<p>is not considered continuous as in analog signaling; instead, it is considered to be discrete because the
</p>
<p>information is transmitted as a series of distinct values. The signal transitions between a 1 to 0 or 0 to
</p>
<p>1 are assumed to occur instantaneously. While this is obviously impossible, for the purposes of
</p>
<p>information transmission, the values can be interpreted as a series of discrete values. This is a digital
</p>
<p>signal and is not the actual information, but rather the binary encoded representation of the original
</p>
<p>information. Digital signals are not represented using traditional mathematical functions; instead, the
</p>
<p>digital values are typically held in tables of 1&rsquo;s and 0&rsquo;s.
</p>
<p># Springer International Publishing Switzerland 2017
</p>
<p>B.J. LaMeres, Introduction to Logic Circuits &amp; Logic Design with VHDL,
</p>
<p>DOI 10.1007/978-3-319-34195-8_1
</p>
<p>1</p>
<p/>
</div>
<div class="page"><p/>
<p>Figure 1.1 shows an example analog signal (left) and an example digital signal (right). While the
</p>
<p>digital signal is in reality continuous, it represents a series of discrete 1 and 0 values.
</p>
<p>CC1.1 If a digital signal is only a discrete representation ofreal information, how is it possible to  
</p>
<p>produce high quality music without hearing &ldquo;gaps&rdquo; in the output due to the digitization 
process?
</p>
<p>A) The gaps are present but they occur so quickly that the human ear can&rsquo;t detect 
them.
</p>
<p>B) When the digital music is converted back to analog sound the gaps are smoothed 
out since an analog signal is by definition continuous.
</p>
<p>C) Digital information is a continuous, time-varying signal so there aren&rsquo;t gaps.
</p>
<p>D) The gaps can be heard if the music is played slowly, but at normal speed, they 
can&rsquo;t be.
</p>
<p>CONCEPT CHECK
</p>
<p>1.2 Advantages of Digital Systems Over Analog Systems
</p>
<p>There are a variety of reasons that digital systems are preferred over analog systems. First is their
</p>
<p>ability to operate within the presence of noise. Since an analog signal is a direct representation of the
</p>
<p>physical quantity it is transmitting, any noise that is coupled onto the electrical signal is interpreted as
</p>
<p>noise on the original physical quantity. An example of this is when you are listening to an AM/FM radio
</p>
<p>and you hear distortion of the sound coming out of the speaker. The distortion you hear is not due to
</p>
<p>actual distortion of the music as it was played at the radio station, but rather electrical noise that was
</p>
<p>coupled onto the analog signal transmitted to your radio prior to being converted back into sound by
</p>
<p>the speakers. Since the signal in this case is analog, the speaker simply converts it in its entirety
</p>
<p>(noise + music) into sound. In the case of digital signaling, a significant amount of noise can be added
</p>
<p>Fig. 1.1
Analog (left) vs. digital (right) signals
</p>
<p>2 &bull; Chapter 1: Introduction: Analog vs. Digital</p>
<p/>
</div>
<div class="page"><p/>
<p>to the signal while still preserving the original 1&rsquo;s and 0&rsquo;s that are being transmitted. For example, if the
</p>
<p>signal is representing a 0, the receiver will still interpret the signal as a 0 as long as the noise doesn&rsquo;t
</p>
<p>cause the level to exceed the threshold. Once the receiver interprets the signal as a 0, it stores the
</p>
<p>encoded value as a 0, thus ignoring any noise present during the original transmission. Figure 1.2 shows
</p>
<p>the exact same noise added to the analog and digital signals from Fig. 1.1. The analog signal is distorted;
</p>
<p>however, the digital signal is still able to transmit the 0&rsquo;s and 1&rsquo;s that represent the information.
</p>
<p>Another reason that digital systems are preferred over analog ones is the simplicity of the circuitry. In
</p>
<p>order to produce a 1 and 0, you simply need an electrical switch. If the switch connects the output to a
</p>
<p>voltage below the threshold, then it produces a 0. If the switch connects the output to a voltage above the
</p>
<p>threshold, then it produces a 1. It is relatively simple to create such a switching circuit using modern
</p>
<p>transistors. Analog circuitry, however, needs to perform the conversion of the physical quantity it is
</p>
<p>representing (e.g., pressure, sound) into an electrical signal all the while maintaining a direct correspon-
</p>
<p>dence between the input and output. Since analog circuits produce a direct, continuous representation of
</p>
<p>information, they require more complicated designs to achieve linearity in the presence of environmental
</p>
<p>variations (e.g., power supply, temperature, fabrication differences). Since digital circuits only produce a
</p>
<p>discrete representation of the information, they can be implemented with simple switches that are only
</p>
<p>altered when information is produced or retrieved. Figure 1.3 shows an example comparison between an
</p>
<p>analog inverting amplifier and a digital inverter. The analog amplifier uses dozens of transistors (inside
</p>
<p>the triangle) and two resistors to perform the inversion of the input. The digital inverter uses two
</p>
<p>transistors that act as switches to perform the inversion.
</p>
<p>Fig. 1.2
Noise on analog (left) and digital (right) signals
</p>
<p>1.2 Advantages of Digital Systems Over Analog Systems &bull; 3</p>
<p/>
</div>
<div class="page"><p/>
<p>A final reason that digital systems are being widely adopted is their reduced power consumption.
</p>
<p>With the advent of complementary metal oxide transistors (CMOS), electrical switches can be created
</p>
<p>that consume very little power to turn on or off and consume relatively negligible amounts of power to
</p>
<p>keep on or off. This has allowed large-scale digital systems to be fabricated without excessive levels of
</p>
<p>power consumption. For stationary digital systems such as servers and workstations, extremely large
</p>
<p>and complicated systems can be constructed that consume reasonable amounts of power. For portable
</p>
<p>digital systems such as smart phones and tablets, this means useful tools can be designed that are able
</p>
<p>to run on portable power sources. Analog circuits, on the other hand, require continuous power to
</p>
<p>accurately convert and transmit the electrical signal representing the physical quantity. Also, the circuit
</p>
<p>techniques that are required to compensate for variances in power supply and fabrication processes in
</p>
<p>analog systems require additional power consumption. For these reasons, analog systems are being
</p>
<p>replaced with digital systems wherever possible to exploit their noise immunity, simplicity, and low power
</p>
<p>consumption. While analog systems will always be needed at the transition between the physical (e.g.,
</p>
<p>microphones, camera lenses, sensors, video displays) and the electrical world, it is anticipated that the
</p>
<p>push toward digitization of everything in between (e.g., processing, transmission, storage) will continue.
</p>
<p>CC1.2 When does the magnitude of electrical noise on a digital signal prevent the original 
information from being determined?
</p>
<p>A) When it causes the system to draw too much power.
</p>
<p>B) When the shape of the noise makes the digital signal look smooth and 
continuous like a sine wave.
</p>
<p>C) When the magnitude of the noise is large enough that it causes the signal to 
inadvertently cross the threshold voltage.
</p>
<p>D) It doesn&rsquo;t.  A digital signal can withstand any magnitude of noise.
</p>
<p>CONCEPT CHECK
</p>
<p>Fig. 1.3
Analog (left) vs. digital (right) circuits
</p>
<p>4 &bull; Chapter 1: Introduction: Analog vs. Digital</p>
<p/>
</div>
<div class="page"><p/>
<p>Summary
</p>
<p>v An analog system uses a direct mapping
between an electrical quantity and the infor-
mation being processed. A digital system, on
the other hand, uses a discrete representa-
tion of the information.
</p>
<p>v Using a discrete representation allows the
digital signals to be more immune to noise
in addition to requiring simple circuits that
require less power to perform the
computations.
</p>
<p>Exercise Problems
</p>
<p>Section 1.1: Differences Between Analog
</p>
<p>and Digital Systems
</p>
<p>1.1.1 If an electrical signal is a direct function of a
physical quantity, is it considered analog or
digital?
</p>
<p>1.1.2 If an electrical signal is a discrete representa-
tion of information, is it considered analog or
digital?
</p>
<p>1.1.3 What part of any system will always require an
analog component?
</p>
<p>1.1.4 Is the sound coming out of earbuds analog or
digital?
</p>
<p>1.1.5 Is the MP3 file stored on an iPod analog or
digital?
</p>
<p>1.1.6 Is the circuitry that reads the MP3 file from
memory in an iPod analog or digital?
</p>
<p>1.1.7 Is the electrical signal that travels down ear-
phone wires analog or digital?
</p>
<p>1.1.8 Is the voltage coming out of the battery in an
iPod analog or digital?
</p>
<p>1.1.9 Is the physical interface on the touch display of
an iPod analog or digital?
</p>
<p>1.1.10 Take a look around right now and identify two
digital technologies in use.
</p>
<p>1.1.11 Take a look around right now and identify two
analog technologies in use.
</p>
<p>Section 1.2: Advantages of Digital
</p>
<p>Systems Over Analog Systems
</p>
<p>1.2.1 Give three advantages of using digital systems
over analog.
</p>
<p>1.2.2 Name a technology or device that has evolved
from analog to digital in your lifetime.
</p>
<p>1.2.3 Name an analog technology or device that has
become obsolete in your lifetime.
</p>
<p>1.2.4 Name an analog technology or device that has
been replaced by digital technology but is still
in use due to nostalgia.
</p>
<p>1.2.5 Name a technology or device invented in your
lifetime that could not have been possible with-
out digital technology.
</p>
<p>Exercise Problems &bull; 5</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 2: Number Systems
Logic circuits are used to generate and transmit 1s and 0s to compute and convey information. This
</p>
<p>two-valued number system is called binary. As presented earlier, there are many advantages of using a
</p>
<p>binary system; however, the human brain has been taught to count, label, and measure using the
</p>
<p>decimal number system. The decimal number system contains 10 unique symbols (0 ! 9) commonly
</p>
<p>referred to as the Arabic numerals. Each of these symbols is assigned a relative magnitude to the other
</p>
<p>symbols. For example, 0 is less than 1, 1 is less than 2, etc. It is often conjectured that the 10-symbol
</p>
<p>number system that we humans use is due to the availability of our ten fingers (or digits) to visualize
</p>
<p>counting up to 10. Regardless, our brains are trained to think of the real world in terms of a decimal
</p>
<p>system. In order to bridge the gap between the way our brains think (decimal) and how we build our
</p>
<p>computers (binary), we need to understand the basics of number systems. This includes the formal
</p>
<p>definition of a positional number system and how it can be extended to accommodate any arbitrarily large
</p>
<p>(or small) value. This also includes how to convert between different number systems that contain
</p>
<p>different numbers of symbols. In this chapter, we cover four different number systems: decimal
</p>
<p>(10 symbols), binary (2 symbols), octal (8 symbols), and hexadecimal (16 symbols). The study of
</p>
<p>decimal and binary is obvious as they represent how our brains interpret the physical world (decimal)
</p>
<p>and how our computers work (binary). Hexadecimal is studied because it is a useful means to represent
</p>
<p>large sets of binary values using a manageable number of symbols. Octal is rarely used but is studied as
</p>
<p>an example of how the formalization of the number systems can be applied to all systems regardless of
</p>
<p>the number of symbols they contain. This chapter also discusses how to perform basic arithmetic in the
</p>
<p>binary number system and represent negative numbers. The goal of this chapter is to provide an
</p>
<p>understanding of the basic principles of binary number systems.
</p>
<p>Learning Outcomes&mdash;After completing this chapter, you will be able to:
</p>
<p>2.1 Describe the formation and use of positional number systems.
2.2 Convert numbers between different bases.
2.3 Perform binary addition and subtraction by hand.
2.4 Use two&rsquo;s complement numbers to represent negative numbers.
</p>
<p>2.1 Positional Number Systems
</p>
<p>A positional number system allows the expansion of the original set of symbols so that they can be
</p>
<p>used to represent any arbitrarily large (or small) value. For example, if we use the 10 symbols in our
</p>
<p>decimal system, we can count from 0 to 9. Using just the individual symbols we do not have enough
</p>
<p>symbols to count beyond 9. To overcome this, we use the same set of symbols but assign a different
</p>
<p>value to the symbol based on its position within the number. The position of the symbol with respect to
</p>
<p>other symbols in the number allows an individual symbol to represent greater (or lesser) values. We can
</p>
<p>use this approach to represent numbers larger than the original set of symbols. For example, let&rsquo;s say we
</p>
<p>want to count from 0 upward by 1. We begin counting 0, 1, 2, 3, 4, 5, 6, 7, 8 to 9. When we are out of
</p>
<p>symbols and wish to go higher, we bring on a symbol in a different position with that position being valued
</p>
<p>higher and then start counting over with our original symbols (e.g., . . ., 9, 10, 11,. . . 19, 20, 21, . . .). This is
</p>
<p>repeated each time a position runs out of symbols (e.g., . . ., 99, 100, 101, . . . 999, 1000, 1001, . . .).
</p>
<p>First, let&rsquo;s look at the formation of a number system. The first thing that is needed is a set of symbols.
</p>
<p>The formal term for one of the symbols in a number system is a numeral. One or more numerals are used
</p>
<p>to form a number. We define the number of numerals in the system using the terms radix or base.
</p>
<p># Springer International Publishing Switzerland 2017
</p>
<p>B.J. LaMeres, Introduction to Logic Circuits &amp; Logic Design with VHDL,
</p>
<p>DOI 10.1007/978-3-319-34195-8_2
</p>
<p>7</p>
<p/>
</div>
<div class="page"><p/>
<p>For example, our decimal number system is said to be base 10, or have a radix of 10 because it consists
</p>
<p>of 10 unique numerals or symbols:
</p>
<p>Radix &frac14; Base � the number of numerals in the number system
</p>
<p>The next thing that is needed is the relative value of each numeral with respect to the other numerals
</p>
<p>in the set. We can say 0 &lt; 1 &lt; 2 &lt; 3, etc. to define the relative magnitudes of the numerals in this set.
</p>
<p>The numerals are defined to be greater or less than their neighbors by a magnitude of 1. For example, in
</p>
<p>the decimal number system each of the subsequent numerals is greater than its predecessor by exactly
</p>
<p>1. When we define this relative magnitude we are defining that the numeral 1 is greater than the numeral
</p>
<p>0 by a magnitude of 1; the numeral 2 is greater than the numeral 1 by a magnitude of 1, etc. At this point
</p>
<p>we have the ability to count from 0 to 9 by 1&rsquo;s. We also have the basic structure for mathematical
</p>
<p>operations that have results that fall within the numeral set from 0 to 9 (e.g., 1 + 2 &frac14; 3). In order to
</p>
<p>expand the values that these numerals can represent, we need to define the rules of a positional number
</p>
<p>system.
</p>
<p>2.1.1 Generic Structure
</p>
<p>In order to represent larger or smaller numbers than the lone numerals in a number system can
</p>
<p>represent, we adopt a positional system. In a positional number system, the relative position of the
</p>
<p>numeral within the overall number dictates its value. When we begin talking about the position of a
</p>
<p>numeral, we need to define a location to which all of the numerals are positioned with respect to. We
</p>
<p>define the radix point as the point within a number to which numerals to the left represent whole numbers
</p>
<p>and numerals to the right represent fractional numbers. The radix point is denoted with a period (i.e., &ldquo;.&rdquo;).
</p>
<p>A particular number system often renames this radix point to reflect its base. For example, in the base
</p>
<p>10-number system (i.e., decimal), the radix point is commonly called the decimal point; however, the term
</p>
<p>radix point can be used across all number systems as a generic term. If the radix point is not present in a
</p>
<p>number, it is assumed to be to the right of number. Figure 2.1 shows an example number highlighting the
</p>
<p>radix point and the relative positions of the whole and fractional numerals.
</p>
<p>Next, we need to define the position of each numeral with respect to the radix point. The position of
</p>
<p>the numeral is assigned a whole number with the number to the left of the radix point having a position
</p>
<p>value of 0. The position number increases by 1 as numerals are added to the left (2, 3, 4 . . .) and
</p>
<p>decreased by 1 as numerals are added to the right (�1, �2, �3). We will use the variable p to represent
</p>
<p>position. The position number will be used to calculate the value of each numeral in the number based on
</p>
<p>its relative position to the radix point. Figure 2.2 shows the example number with the position value of
</p>
<p>each numeral highlighted.
</p>
<p>Fig. 2.1
Definition of radix point
</p>
<p>Fig. 2.2
Definition of position number (p) within the number
</p>
<p>8 &bull; Chapter 2: Number Systems</p>
<p/>
</div>
<div class="page"><p/>
<p>In order to create a generalized format of a number, we assign the term digit (d) to each of the
</p>
<p>numerals in the number. The term digit signifies that the numeral has a position. The position of the digit
</p>
<p>within the number is denoted as a subscript. The term digit can be used as a generic term to describe a
</p>
<p>numeral across all systems, although some number systems will use a unique term instead of digit which
</p>
<p>indicates its base. For example, the binary system uses the term bit instead of digit; however, using the
</p>
<p>term digit to describe a generic numeral in any system is still acceptable. Figure 2.3 shows the generic
</p>
<p>subscript notation used to describe the position of each digit in the number.
</p>
<p>We write a number from left to right starting with the highest position digit that is greater than 0 and
</p>
<p>end with the lowest position digit that is greater than 0. This reduces the amount of numerals that are
</p>
<p>written; however, a number can be represented with an arbitrary number of 0s to the left of the highest
</p>
<p>position digit greater than 0 and an arbitrary number of 0s to the right of the lowest position digit greater
</p>
<p>than 0 without affecting the value of the number. For example, the number 132.654 could be written as
</p>
<p>0132.6540 without affecting the value of the number. The 0s to the left of the number are called leading
</p>
<p>0s and the 0s to the right of the number are called trailing 0s. The reason this is being stated is because
</p>
<p>when a number is implemented in circuitry, the number of numerals is fixed and each numeral must have
</p>
<p>a value. The variable n is used to represent the number of numerals in a number. If a number is defined
</p>
<p>with n &frac14; 4, that means 4 numerals are always used. The number 0 would be represented as 0000 with
</p>
<p>both representations having an equal value.
</p>
<p>2.1.2 Decimal Number System (Base 10)
</p>
<p>As mentioned earlier, the decimal number system contains 10 unique numerals (0, 1, 2, 3, 4, 5, 6, 7,
</p>
<p>8, and 9). This system is thus a base 10 or a radix 10 system. The relative magnitudes of the symbols are
</p>
<p>0 &lt; 1 &lt; 2 &lt; 3 &lt; 4 &lt; 5 &lt; 6 &lt; 7 &lt; 8 &lt; 9.
</p>
<p>2.1.3 Binary Number System (Base 2)
</p>
<p>The binary number system contains two unique numerals (0 and 1). This system is thus a base 2 or
</p>
<p>a radix 2 system. The relative magnitudes of the symbols are 0 &lt; 1. At first glance, this system looks
</p>
<p>very limited in its ability to represent large numbers due to the small number of numerals. When counting
</p>
<p>up, as soon as you count from 0 to 1, you are out of symbols and must increment the p + 1 position in
</p>
<p>order to represent the next number (e.g., 0, 1, 10, 11, 100, 101, . . .); however, magnitudes of each
</p>
<p>position scale quickly so that circuits with a reasonable amount of digits can represent very large
</p>
<p>numbers. The term bit is used instead of digit in this system to describe the individual numerals and at
</p>
<p>the same time indicate the base of the number.
</p>
<p>Due to the need for multiple bits to represent meaningful information, there are terms dedicated to
</p>
<p>describe the number of bits in a group. When 4 bits are grouped together, they are called a nibble. When
</p>
<p>8 bits are grouped together, they are called a byte. Larger groupings of bits are calledwords. The size of
</p>
<p>the word can be stated as either an n-bit word or omitted if the size of the word is inherently implied. For
</p>
<p>example, if you were using a 32-bit microprocessor, using the term word would be interpreted as a 32-bit
</p>
<p>word. For example, if there was a 32-bit grouping, it would be referred to as a 32-bit word. The leftmost bit
</p>
<p>Fig. 2.3
Digit notation
</p>
<p>2.1 Positional Number Systems &bull; 9</p>
<p/>
</div>
<div class="page"><p/>
<p>in a binary number is called the most significant bit (MSB). The rightmost bit in a binary number is
</p>
<p>called the least significant bit (LSB).
</p>
<p>2.1.4 Octal Number System (Base 8)
</p>
<p>The octal number system contains 8 unique numerals (0, 1, 2, 3, 4, 5, 6, 7). This system is thus a
</p>
<p>base 8 or a radix 8 system. The relative magnitudes of the symbols are 0 &lt; 1 &lt; 2 &lt; 3 &lt; 4 &lt; 5 &lt; 6
</p>
<p>&lt; 7. We use the generic term digit to describe the numerals within an octal number.
</p>
<p>2.1.5 Hexadecimal Number System (Base 16)
</p>
<p>The hexadecimal number system contains 16 unique numerals. This system is most often referred
</p>
<p>to in spoken word as &ldquo;hex&rdquo; for short. Since we only have 10 Arabic numerals in our familiar decimal
</p>
<p>system, we need to use other symbols to represent the remaining 6 numerals. We use the alphabetic
</p>
<p>characters A&ndash;F in order to expand the system to 16 numerals. The 16 numerals in the hexadecimal
</p>
<p>system are 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, and F. The relative magnitudes of the symbols are
</p>
<p>0 &lt; 1 &lt; 2 &lt; 3 &lt; 4 &lt; 5 &lt; 6 &lt; 7 &lt; 8 &lt; 9 &lt; A &lt; B &lt; C &lt; D &lt; E &lt; F. We use the generic term digit
</p>
<p>to describe the numerals within a hexadecimal number.
</p>
<p>At this point, it becomes necessary to indicate the base of a written number. The number 10 has an
</p>
<p>entirely different value if it is a decimal number or binary number. In order to handle this, a subscript is
</p>
<p>typically included at the end of the number to denote its base. For example, 1010 indicates that this
</p>
<p>number is decimal &ldquo;ten.&rdquo; If the number was written as 102, this number would represent binary &ldquo;one zero.&rdquo;
</p>
<p>Table 2.1 lists the equivalent values in each of the 4 number systems just described for counts from 010 to
</p>
<p>1510. The left side of the table does not include leading 0s. The right side of the table contains the same
</p>
<p>information but includes the leading zeros. The equivalencies of decimal, binary, and hexadecimal in this
</p>
<p>table are typically committed to memory.
</p>
<p>Table 2.1
Number system equivalency
</p>
<p>10 &bull; Chapter 2: Number Systems</p>
<p/>
</div>
<div class="page"><p/>
<p>CC2.1 The base of a number system is arbitrary and is commonly selected to match a particular 
</p>
<p>aspect of the physical system in which it is used (e.g., base 10 corresponds to our 10 
fingers, base 2 corresponds to the 2 states of a switch).  If a physical system contained 3 
unique modes and a base of 3 was chosen for the number system, what is the base 3 
equivalent of the decimal number 3?
</p>
<p>A) 310 = 113 B) 310 = 33 C) 310 = 103 D) 310 = 213
</p>
<p>CONCEPT CHECK
</p>
<p>2.2 Base Conversion
</p>
<p>Now we look at converting between bases. There are distinct techniques for converting to and from
</p>
<p>decimal. There are also techniques for converting between bases that are powers of 2 (e.g., base 2, 4,
</p>
<p>8, 16).
</p>
<p>2.2.1 Converting to Decimal
</p>
<p>The value of each digit within a number is based on the individual digit value and the digit&rsquo;s position.
</p>
<p>Each position in the number contains a different weight based on its relative location to the radix point.
</p>
<p>The weight of each position is based on the radix of the number system that is being used. The weight of
</p>
<p>each position in decimal is defined as
</p>
<p>Weight &frac14; Radix&eth; &THORN;p
</p>
<p>This expression gives the number system the ability to represent fractional numbers since an
</p>
<p>expression with a negative exponent (e.g., x�y) is evaluated as one over the expression with the
</p>
<p>exponent change to positive (e.g., 1/xy). Figure 2.4 shows the generic structure of a number with its
</p>
<p>positional weight highlighted.
</p>
<p>In order to find the decimal value of each of the numerals in the number, its individual numeral value
</p>
<p>is multiplied by its positional weight. In order to find the value of the entire number, each value of the
</p>
<p>individual numeral-weight products is summed. The generalized format of this conversion is written as
</p>
<p>Total Decimal Value &frac14;
X
</p>
<p>pmax
</p>
<p>i&frac14;pmin
</p>
<p>di � radix&eth; &THORN;
i
</p>
<p>In this expression, pmax represents the highest position number that contains a numeral greater than
</p>
<p>0. The variable pmin represents the lowest position number that contains a numeral greater than 0. These
</p>
<p>limits are used to simplify the hand calculations; however, these terms theoretically could be +1 to �1
</p>
<p>Fig. 2.4
Weight definition
</p>
<p>2.2 Base Conversion &bull; 11</p>
<p/>
</div>
<div class="page"><p/>
<p>with no effect on the result since the summation of every leading 0 and every trailing 0 contributes
</p>
<p>nothing to the result.
</p>
<p>As an example, let&rsquo;s evaluate this expression for a decimal number. The result will yield the original
</p>
<p>number but will illustrate how positional weight is used. Let&rsquo;s take the number 132.65410. To find the
</p>
<p>decimal value of this number, each numeral is multiplied by its positional weight and then all of the
</p>
<p>products are summed. The positional weight for the digit 1 is (radix)p or (10)2. In decimal this is called the
</p>
<p>hundred&rsquo;s position. The positional weight for the digit 3 is (10)1, referred to as the ten&rsquo;s position. The
</p>
<p>positional weight for digit 2 is (10)0, referred to as the one&rsquo;s position. The positional weight for digit 6 is
</p>
<p>(10)�1, referred to as the tenth&rsquo;s position. The positional weight for digit 5 is (10)�2, referred to as the
</p>
<p>hundredth&rsquo;s position. The positional weight for digit 4 is (10)�3, referred to as the thousandth&rsquo;s position.
</p>
<p>When these weights are multiplied by their respective digits and summed, the result is the original
</p>
<p>decimal number 132.65410. Example 2.1 shows this process step by step.
</p>
<p>Example 2.1
Converting Decimal to Decimal
</p>
<p>This process is used to convert between any other base to decimal.
</p>
<p>2.2.1.1 Binary to Decimal
</p>
<p>Let&rsquo;s convert 101.112 to decimal. The same process is followed with the exception that the base in
</p>
<p>the summation is changed to 2. Converting from binary to decimal can be accomplished quickly in your
</p>
<p>head due to the fact that the bit values in the products are either 1 or 0. That means any bit that is a 0 has
</p>
<p>no impact on the outcome and any bit that is a 1 simply yields the weight of its position. Example 2.2
</p>
<p>shows the step-by-step process converting a binary number to decimal.
</p>
<p>12 &bull; Chapter 2: Number Systems</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 2.2
Converting Binary to Decimal
</p>
<p>2.2.1.2 Octal to Decimal
</p>
<p>When converting from octal to decimal, the same process is followed with the exception that the
</p>
<p>base in the weight is changed to 8. Example 2.3 shows an example of converting an octal number to
</p>
<p>decimal.
</p>
<p>Example 2.3
Converting Octal to Decimal
</p>
<p>2.2 Base Conversion &bull; 13</p>
<p/>
</div>
<div class="page"><p/>
<p>2.2.1.3 Hexadecimal to Decimal
</p>
<p>Let&rsquo;s convert 1AB.EF16 to decimal. The same process is followed with the exception that the base is
</p>
<p>changed to 16. When performing the conversion, the decimal equivalents of the numerals A&ndash;F need to
</p>
<p>be used. Example 2.4 shows the step-by-step process converting a hexadecimal number to decimal.
</p>
<p>Example 2.4
Converting Hexadecimal to Decimal
</p>
<p>2.2.2 Converting from Decimal
</p>
<p>The process of converting from decimal to another base consists of two separate algorithms. There
</p>
<p>is one algorithm for converting the whole number portion of the number and another algorithm for
</p>
<p>converting the fractional portion of the number. The process for converting the whole number portion
</p>
<p>is to divide the decimal number by the base of the system you wish to convert to. The division will result in
</p>
<p>a quotient and a whole number remainder. The remainder is recorded as the least significant numeral in
</p>
<p>the converted number. The resulting quotient is then divided again by the base, which results in a new
</p>
<p>quotient and new remainder. The remainder is recorded as the next higher order numeral in the new
</p>
<p>number. This process is repeated until a quotient of 0 is achieved. At that point the conversion is
</p>
<p>complete. The remainders will always be within the numeral set of the base being converted to.
</p>
<p>The process for converting the fractional portion is to multiply just the fractional component of the
</p>
<p>number by the base. This will result in a product that contains a whole number and a fraction. The whole
</p>
<p>number is recorded as themost significant digit of the new converted number. The new fractional portion
</p>
<p>is then multiplied again by the base with the whole number portion being recorded as the next lower order
</p>
<p>numeral. This process is repeated until the product yields a fractional component equal to zero or the
</p>
<p>desired level of accuracy has been achieved. The level of accuracy is specified by the number of
</p>
<p>numerals in the new converted number. For example, the conversion would be stated as &ldquo;convert this
</p>
<p>decimal number to binary with a fractional accuracy of 4 bits.&rdquo; This means the algorithm would stop once
</p>
<p>4-bits of fraction had been achieved in the conversion.
</p>
<p>14 &bull; Chapter 2: Number Systems</p>
<p/>
</div>
<div class="page"><p/>
<p>2.2.2.1 Decimal to Binary
</p>
<p>Let&rsquo;s convert 11.37510 to binary. Example 2.5 shows the step-by-step process converting a decimal
</p>
<p>number to binary.
</p>
<p>Example 2.5
Converting Decimal to Binary
</p>
<p>2.2.2.2 Decimal to Octal
</p>
<p>Let&rsquo;s convert 10.410 to octal with an accuracy of four fractional digits. When converting the fractional
</p>
<p>component of the number, the algorithm is continued until four digits worth of fractional numerals have
</p>
<p>been achieved. Once the accuracy has been achieved, the conversion is finished even though a product
</p>
<p>with a zero fractional value has not been obtained. Example 2.6 shows the step-by-step process
</p>
<p>converting a decimal number to octal with a fractional accuracy of four digits.
</p>
<p>2.2 Base Conversion &bull; 15</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 2.6
Converting Decimal to Octal
</p>
<p>2.2.2.3 Decimal to Hexadecimal
</p>
<p>Let&rsquo;s convert 254.65510 to hexadecimal with an accuracy of three fractional digits. When doing this
</p>
<p>conversion, all of the divisions and multiplications are done using decimal. If the results end up between
</p>
<p>1010 and 1510, then the decimal numbers are substituted with their hex symbol equivalent (i.e., A to F).
</p>
<p>Example 2.7 shows the step-by-step process of converting a decimal number to hex with a fractional
</p>
<p>accuracy of three digits.
</p>
<p>16 &bull; Chapter 2: Number Systems</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 2.7
Converting Decimal to Hexadecimal
</p>
<p>2.2.3 Converting Between 2n Bases
</p>
<p>Converting between 2n bases (e.g., 2, 4, 8, 16) takes advantage of the direct mapping that each of
</p>
<p>these bases has back to binary. Base 8 numbers take exactly 3 binary bits to represent all 8 symbols (i.e.,
</p>
<p>08 &frac14; 0002, 78 &frac14; 1112). Base 16 numbers take exactly 4 binary bits to represent all 16 symbols (i.e.,
</p>
<p>016 &frac14; 00002, F16 &frac14; 11112).
</p>
<p>When converting from binary to any other 2n base, the whole number bits are grouped into the
</p>
<p>appropriate-sized sets starting from the radix point and working left. If the final leftmost grouping does not
</p>
<p>have enough symbols, it is simply padded on left with leading 0s. Each of these groups is then directly
</p>
<p>substituted with their 2n base symbol. The fractional number bits are also grouped into the appropriate-
</p>
<p>sized sets starting from the radix point, but this time working right. Again, if the final rightmost grouping
</p>
<p>does not have enough symbols, it is simply padded on the right with trailing 0s. Each of these groups is
</p>
<p>then directly substituted with their 2n base symbol.
</p>
<p>2.2.3.1 Binary to Octal
</p>
<p>Example 2.8 shows the step-by-step process of converting a binary number to octal.
</p>
<p>2.2 Base Conversion &bull; 17</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 2.8
Converting Binary to Octal
</p>
<p>2.2.3.2 Binary to Hexadecimal
</p>
<p>Example 2.9 shows the step-by-step process of converting a binary number to hexadecimal.
</p>
<p>Example 2.9
Converting Binary to Hexadecimal
</p>
<p>2.2.3.3 Octal to Binary
</p>
<p>When converting to binary from any 2n base, each of the symbols in the originating number are
</p>
<p>replaced with the appropriate-sized number of bits. An octal symbol will be replaced with 3 binary bits
</p>
<p>while a hexadecimal symbol will be replaced with 4 binary bits. Any leading or trailing 0s can be removed
</p>
<p>from the converted number once complete. Example 2.10 shows the step-by-step process of converting
</p>
<p>an octal number to binary.
</p>
<p>18 &bull; Chapter 2: Number Systems</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 2.10
Converting Octal to Binary
</p>
<p>2.2.3.4 Hexadecimal to Binary
</p>
<p>Example 2.11 shows the step-by-step process of converting a hexadecimal number to binary.
</p>
<p>Example 2.11
Converting Hexadecimal to Binary
</p>
<p>2.2.3.5 Octal to Hexadecimal
</p>
<p>When converting between 2n bases (excluding binary) the number is first converted into binary and
</p>
<p>then converted from binary into the final 2n base using the algorithms described before. Example 2.12
</p>
<p>shows the step-by-step process of converting an octal number to hexadecimal.
</p>
<p>2.2 Base Conversion &bull; 19</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 2.12
Converting Octal to Hexadecimal
</p>
<p>2.2.3.6 Hexadecimal to Octal
</p>
<p>Example 2.13 shows the step-by-step process of converting a hexadecimal number to octal.
</p>
<p>Example 2.13
Converting Hexadecimal to Octal
</p>
<p>CC2.2 A &ldquo;googol&rdquo; is the term for the decimal number 1e100.  When written out manually this 
</p>
<p>number is a 1 with 100 zeros after it (e.g., 10,000,000,000,000,000,000,000,
000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,00
0,000,000,000,000,000).  This term is more commonly associated with the search engine 
company Google, which uses a different spelling but is pronounced the same.  How many 
bits does it take to represent a googol in binary?
</p>
<p>A) 100 bits B) 256 bits C) 332 bits D) 333 bits
</p>
<p>CONCEPT CHECK
</p>
<p>20 &bull; Chapter 2: Number Systems</p>
<p/>
</div>
<div class="page"><p/>
<p>2.3 Binary Arithmetic
</p>
<p>2.3.1 Addition (Carries)
</p>
<p>Binary addition is a straightforward process that mirrors the approach we have learned for longhand
</p>
<p>decimal addition. The two numbers (or terms) to be added are aligned at the radix point and addition
</p>
<p>begins at the least significant bit. If the sum of the least significant position yields a value with two bits
</p>
<p>(e.g., 102), then the least significant bit is recorded and the most significant bit is carried to the next higher
</p>
<p>position. The sum of the next higher position is then performed including the potential carry bit from the
</p>
<p>prior addition. This process continues from the least significant position to the most significant position.
</p>
<p>Example 2.14 shows how addition is performed on two individual bits.
</p>
<p>Example 2.14
Single-Bit Binary Addition
</p>
<p>When performing binary addition, the width of the inputs and output is fixed (i.e., n-bits). Carries that
</p>
<p>exist within the n-bits are treated in the normal fashion of including them in the next higher position sum;
</p>
<p>however, if the highest position summation produces a carry, this is a uniquely named event. This event
</p>
<p>is called a carry out or the sum is said to generate a carry. The reason this type of event is given special
</p>
<p>terminology is because in real circuitry, the number of bits of the inputs and output is fixed in hardware
</p>
<p>and the carry out is typically handled by a separate circuit. Example 2.15 shows this process when
</p>
<p>adding two 4-bit numbers.
</p>
<p>Example 2.15
Multiple-Bit Binary Addition
</p>
<p>The largest decimal sum that can result from the addition of two binary numbers is given by
</p>
<p>2�(2n � 1). For example, two 8-bit numbers to be added could both represent their highest
</p>
<p>decimal value of (2n � 1) or 25510 (i.e., 1111 11112). The sum of this number would result in
</p>
<p>51010 or (1 1111 11102). Notice that the largest sum achievable would only require one additional
</p>
<p>bit. This means that a single carry bit is sufficient to handle all possible magnitudes for binary
</p>
<p>addition.
</p>
<p>2.3 Binary Arithmetic &bull; 21</p>
<p/>
</div>
<div class="page"><p/>
<p>2.3.2 Subtraction (Borrows)
</p>
<p>Binary subtraction also mirrors longhand decimal subtraction. In subtraction, the formal terms for the
</p>
<p>two numbers being operated on are minuend and subtrahend. The subtrahend is subtracted from the
</p>
<p>minuend to find the difference. In longhand subtraction, the minuend is the top number and the
</p>
<p>subtrahend is the bottom number. For a given position if the minuend is less than the subtrahend, it
</p>
<p>needs to borrow from the next higher order position to produce a difference that is positive. If the next
</p>
<p>higher position does not have a value that can be borrowed from (i.e., 0), then it in turn needs to borrow
</p>
<p>from the next higher position, and so forth. Example 2.16 shows how subtraction is performed on two
</p>
<p>individual bits.
</p>
<p>Example 2.16
Single-Bit Binary Subtraction
</p>
<p>As with binary addition, binary subtraction is accomplished on fixed widths of inputs and output (i.e.,
</p>
<p>n-bits). The minuend and subtrahend are aligned at the radix point and subtraction begins at the least
</p>
<p>significant bit position. Borrows are used as necessary as the subtractions move from the least signifi-
</p>
<p>cant position to the most significant position. If the most significant position requires a borrow, this is a
</p>
<p>uniquely named event. This event is called a borrow in or the subtraction is said to require a borrow.
</p>
<p>Again, the reason this event is uniquely named is because in real circuitry, the number of bits of the input
</p>
<p>and output is fixed in hardware and the borrow in is typically handled by a separate circuit. Example 2.17
</p>
<p>shows this process when subtracting two 4-bit numbers.
</p>
<p>Example 2.17
Multiple-Bit Binary Subtraction
</p>
<p>22 &bull; Chapter 2: Number Systems</p>
<p/>
</div>
<div class="page"><p/>
<p>Notice that if the minuend is less than the subtrahend, then the difference will be negative. At this
</p>
<p>point, we need a way to handle negative numbers.
</p>
<p>CC2.3 If an 8-bit computer system can only perform unsigned addition on 8-bit inputs and produce 
</p>
<p>an 8-bit sum, how is it possible for this computer to perform addition on numbers that are 
larger than what can be represented with 8-bits (e.g., 1,00010 + 1,00010 = 2,00010)?
</p>
<p>A) There are multiple 8-bit adders in a computer to handle large numbers.
</p>
<p>B) The result is simply rounded to the nearest 8-bit number.
</p>
<p>C) The computer returns an error and requires smaller numbers to be entered.
</p>
<p>D) The computer keeps track of the carry out and uses it in a subsequent 8-bit addition, 
which enables larger numbers to be handled. 
</p>
<p>CONCEPT CHECK
</p>
<p>2.4 Unsigned and Signed Numbers
</p>
<p>All of the number systems presented in the prior sections were positive. We need to also have a
</p>
<p>mechanism to indicate negative numbers. When looking at negative numbers, we only focus on the
</p>
<p>mapping between decimal and binary since octal and hexadecimal are used as just another representa-
</p>
<p>tion of a binary number. In decimal, we are able to use the negative sign in front of a number to indicate
</p>
<p>that it is negative (e.g., �3410). In binary, this notation works fine for writing numbers on paper (e.g.,
</p>
<p>�10102), but we need a mechanism that can be implemented using real circuitry. In a real digital circuit,
</p>
<p>the circuits can only deal with 0s and 1s. There is no &ldquo;�&rdquo; in a digital circuit. Since we only have 0s and 1s
</p>
<p>in the hardware, we use a bit to represent whether a number is positive or negative. This is referred to as
</p>
<p>the sign bit. If a binary number is not going to have any negative values, then it is called an unsigned
</p>
<p>number and it can only represent positive numbers. If a binary number is going to allow negative
</p>
<p>numbers, it is called a signed number. It is important to always keep track of the type of number we
</p>
<p>are using as the same bit values can represent very different numbers depending on the coding
</p>
<p>mechanism that is being used.
</p>
<p>2.4.1 Unsigned Numbers
</p>
<p>An unsigned number is one that does not allow negative numbers. When talking about this type of
</p>
<p>code, the number of bits is fixed and stated up front. We use the variable n to represent the number of bits
</p>
<p>in the number. For example, if we had an 8-bit number, we would say, &ldquo;This is an 8-bit, unsigned number.&rdquo;
</p>
<p>The number of unique codes in an unsigned number is given by 2n. For example, if we had an 8-bit
</p>
<p>number, we would have 28 or 256 unique codes (e.g., 0000 00002 to 1111 11112).
</p>
<p>The range of an unsigned number refers to the decimal values that the binary code can represent. If
</p>
<p>we use the notationNunsigned to represent any possible value that an n-bit, unsigned number can take on,
</p>
<p>the range would be defined as 0 &lt; Nunsigned &lt; (2
n � 1):
</p>
<p>Range of an UNSIGNED number ) 0 � Nunsigned � 2
n � 1&eth; &THORN;
</p>
<p>For example, if we had an unsigned number with n &frac14; 4, it could take on a range of values from +010
(00002) to +1510 (11112). Notice that while this number has 16 unique possible codes, the highest
</p>
<p>decimal value it can represent is 1510. This is because one of the unique codes represents 010. This is
</p>
<p>2.4 Unsigned and Signed Numbers &bull; 23</p>
<p/>
</div>
<div class="page"><p/>
<p>the reason that the highest decimal value that can be represented is given by (2n � 1). Example 2.18
</p>
<p>shows this process for a 16-bit number.
</p>
<p>Example 2.18
Finding the Range of an Unsigned Number
</p>
<p>2.4.2 Signed Numbers
</p>
<p>Signed numbers are able to represent both positive and negative numbers. The most significant bit
</p>
<p>of these numbers is always the sign bit, which represents whether the number is positive or negative.
</p>
<p>The sign bit is defined to be a 0 if the number is positive and 1 if the number is negative. When using
</p>
<p>signed numbers, the number of bits is fixed so that the sign bit is always in the same position. There are a
</p>
<p>variety of ways to encode negative numbers using a sign bit. The encoding method used exclusively in
</p>
<p>modern computers is called two&rsquo;s complement. There are two other encoding techniques called signed
</p>
<p>magnitude and one&rsquo;s complement that are rarely used but are studied to motivate the power of two&rsquo;s
</p>
<p>complement. When talking about a signed number, the number of bits and the type of encoding are
</p>
<p>always stated. For example, we would say, &ldquo;This is an 8-bit, two&rsquo;s complement number.&rdquo;
</p>
<p>2.4.2.1 Signed Magnitude
</p>
<p>Signed magnitude is the simplest way to encode a negative number. In this approach, the most
</p>
<p>significant bit (i.e., leftmost bit) of the binary number is considered the sign bit (0 &frac14; positive, 1 &frac14; nega-
</p>
<p>tive). The rest of the bits to the right of the sign bit represent the magnitude or absolute value of the
</p>
<p>number. As an example of this approach, let&rsquo;s look at the decimal values that a 4-bit, signed magnitude
</p>
<p>number can take on. These are shown in Example 2.19.
</p>
<p>24 &bull; Chapter 2: Number Systems</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 2.19
Decimal Values That a 4-bit, Signed Magnitude Code Can Represent
</p>
<p>There are drawbacks of signed magnitude encoding that are apparent from this example. First, the
</p>
<p>value of 010 has two signed magnitude codes (00002 and 10002). This is an inefficient use of the
</p>
<p>available codes and leads to complexity when building arithmetic circuitry since it must account for
</p>
<p>two codes representing the same number.
</p>
<p>The second drawback is that addition using the negative numbers does not directly map to how
</p>
<p>decimal addition works. For example, in decimal if we added (�5) + (1), the result would be�4. In signed
</p>
<p>magnitude, adding these numbers using a traditional adder would produce (�5) + (1) &frac14; (�6). This is
</p>
<p>because the traditional addition would take place on the magnitude portion of the number. A 510 is
</p>
<p>represented with 1012. Adding 1 to this number would result in the next higher binary code 1102 or 610.
</p>
<p>Since the sign portion is separate, the addition is performed on |5|, thus yielding 6. Once the sign bit is
</p>
<p>included, the resulting number is �6. It is certainly possible to build an addition circuit that works on
</p>
<p>signed magnitude numbers, but it is more complex than a traditional adder because it must perform a
</p>
<p>different addition operation for the negative numbers versus the positive numbers. It is advantageous to
</p>
<p>have a single adder that works across the entire set of numbers.
</p>
<p>Due to the duplicate codes for 0, the range of decimal numbers that signedmagnitude can represent
</p>
<p>is reduced by 1 compared to unsigned encoding. For an n-bit number, there are 2n unique binary codes
</p>
<p>available but only 2n � 1 can be used to represent unique decimal numbers. If we use the notation NSM
to represent any possible value that an n-bit, signed magnitude number can take on, the range would be
</p>
<p>defined as
</p>
<p>Range of a SIGNED MAGNITUDE number ) � 2n�1 � 1
� �
</p>
<p>� NSM � &thorn; 2
n�1 � 1
</p>
<p>� �
</p>
<p>Example 2.20 shows how to use this expression to find the range of decimal values that an 8-bit,
</p>
<p>signed magnitude code can represent.
</p>
<p>2.4 Unsigned and Signed Numbers &bull; 25</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 2.20
Finding the Range of a Signed Magnitude Number
</p>
<p>The process to determine the decimal value from a signed magnitude binary code involves treating
</p>
<p>the sign bit separately from the rest of the code. The sign bit provides the polarity of the decimal number
</p>
<p>(0 &frac14; positive, 1 &frac14; negative). The remaining bits in the code are treated as unsigned numbers and
</p>
<p>converted to decimal using the standard conversion procedure described in the prior sections. This
</p>
<p>conversion yields the magnitude of the decimal number. The final decimal value is found by applying the
</p>
<p>sign. Example 2.21 shows an example of this process.
</p>
<p>Example 2.21
Finding the Decimal Value of a Signed Magnitude Number
</p>
<p>2.4.2.2 One&rsquo;s Complement
</p>
<p>One&rsquo;s complement is another simple way to encode negative numbers. In this approach, the
</p>
<p>negative number is obtained by taking its positive equivalent and flipping all of the 1s to 0s and 0s to
</p>
<p>1s. This procedure of flipping the bits is called a complement (notice the two es). In this way, the most
</p>
<p>significant bit of the number is still the sign bit (0 &frac14; positive, 1 &frac14; negative). The rest of the bits represent
</p>
<p>the value of the number, but in this encoding scheme the negative number values are less intuitive. As an
</p>
<p>example of this approach, let&rsquo;s look at the decimal values that a 4-bit, one&rsquo;s complement number can
</p>
<p>take on. These are shown in Example 2.22.
</p>
<p>26 &bull; Chapter 2: Number Systems</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 2.22
Decimal Values that a 4-bit, One's Complement Code Can Represent
</p>
<p>Again, we notice that there are two different codes for 010 (00002 and 11112). This is a drawback of
</p>
<p>one&rsquo;s complement because it reduces the possible range of numbers that can be represented from 2n to
</p>
<p>(2n � 1) and requires arithmetic operations that take into account the gap in the number system. There
</p>
<p>are advantages of one&rsquo;s complement, however. First, the numbers are ordered such that traditional
</p>
<p>addition works on both positive and negative numbers (excluding the double 0 gap). Taking the example
</p>
<p>of (�5) + (1) again, in one&rsquo;s complement the result yields �4, just as in a traditional decimal system.
</p>
<p>Notice that in one&rsquo;s complement, �510 is represented with 10102. Adding 1 to this entire binary code
</p>
<p>would result in the next higher binary code 10112 or �410 from the above table. This makes addition
</p>
<p>circuitry less complicated, but still not as simple as if the double 0 gap was eliminated. Another
</p>
<p>advantage of one&rsquo;s complement is that as the numbers are incremented beyond the largest value in
</p>
<p>the set, they roll over and start counting at the lowest number. For example, if you increment the number
</p>
<p>01112 (710), it goes to the next higher binary code 10002, which is �710. The ability to have the numbers
</p>
<p>roll over is a useful feature for computer systems.
</p>
<p>If we use the notation N1comp to represent any possible value that an n-bit, one&rsquo;s complement
</p>
<p>number can take on, the range is defined as
</p>
<p>Range of a ONE&rsquo;S COMPLEMENT number ) � 2n�1 � 1
� �
</p>
<p>� N1&rsquo;s comp � &thorn; 2
n�1 � 1
</p>
<p>� �
</p>
<p>Example 2.23 shows how to use this expression to find the range of decimal values that a 24-bit,
</p>
<p>one&rsquo;s complement code can represent.
</p>
<p>2.4 Unsigned and Signed Numbers &bull; 27</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 2.23
Finding the Range of a 1&rsquo;s Complement Number
</p>
<p>The process of finding the decimal value of a one&rsquo;s complement number involves first identifying
</p>
<p>whether the number is positive or negative by looking at the sign bit. If the number is positive (i.e., the
</p>
<p>sign bit is 0), then the number is treated as an unsigned code and is converted to decimal using the
</p>
<p>standard conversion procedure described in prior sections. If the number is negative (i.e., the sign bit is
</p>
<p>1), then the number sign is recorded separately and the code is complemented in order to convert it to its
</p>
<p>positive magnitude equivalent. This new positive number is then converted to decimal using the standard
</p>
<p>conversion procedure. As the final step, the sign is applied. Example 2.24 shows an example of this
</p>
<p>process.
</p>
<p>Example 2.24
Finding the Decimal Value of a 1&rsquo;s Complement Number
</p>
<p>2.4.2.3 Two&rsquo;s Complement
</p>
<p>Two&rsquo;s complement is an encoding scheme that addresses the double 0 issue in signed magnitude
</p>
<p>and 1&rsquo;s complement representations. In this approach, the negative number is obtained by subtracting its
</p>
<p>positive equivalent from 2n. This is identical to performing a complement on the positive equivalent and
</p>
<p>then adding one. If a carry is generated, it is discarded. This procedure is called &ldquo;taking the two&rsquo;s
</p>
<p>complement of a number.&rdquo; The procedure of complementing each bit and adding one is the most
</p>
<p>28 &bull; Chapter 2: Number Systems</p>
<p/>
</div>
<div class="page"><p/>
<p>common technique to perform a two&rsquo;s complement. In this way, the most significant bit of the number is
</p>
<p>still the sign bit (0 &frac14; positive, 1 &frac14; negative) but all of the negative numbers are in essence shifted up so
</p>
<p>that the double 0 gap is eliminated. Taking the two&rsquo;s complement of a positive number will give its
</p>
<p>negative counterpart and vice versa. Let&rsquo;s look at the decimal values that a 4-bit, two&rsquo;s complement
</p>
<p>number can take on. These are shown in Example 2.25.
</p>
<p>Example 2.25
Decimal Values That a 4-bit, Two&rsquo;s Complement Code Can Represent
</p>
<p>There are many advantages of two&rsquo;s complement encoding. First, there is no double 0 gap, which
</p>
<p>means that all possible 2n unique codes that can exist in an n-bit number are used. This gives the largest
</p>
<p>possible range of numbers that can be represented. Another advantage of two&rsquo;s complement is that
</p>
<p>addition with negative numbers works exactly the same as decimal. In our example of (�5) + (1), the
</p>
<p>result is (�4). Arithmetic circuitry can be built to mimic the way our decimal arithmetic works without the
</p>
<p>need to consider the double 0 gap. Finally, the rollover characteristic is preserved from one&rsquo;s comple-
</p>
<p>ment. Incrementing +7 by +1 will result in �8.
</p>
<p>If we use the notation N2comp to represent any possible value that an n-bit, two&rsquo;s complement
</p>
<p>number can take on, the range is defined as
</p>
<p>Range of a TWO&rsquo;S COMPLEMENT number ) � 2n�1
� �
</p>
<p>� N2&rsquo;s comp � &thorn; 2
n�1 � 1
</p>
<p>� �
</p>
<p>Example 2.26 shows how to use this expression to find the range of decimal values that a 32-bit,
</p>
<p>two&rsquo;s complement code can represent.
</p>
<p>2.4 Unsigned and Signed Numbers &bull; 29</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 2.26
Finding the Range of a Two&rsquo;s Complement Number
</p>
<p>The process of finding the decimal value of a two&rsquo;s complement number involves first identifying
</p>
<p>whether the number is positive or negative by looking at the sign bit. If the number is positive (i.e., the
</p>
<p>sign bit is 0), then the number is treated as an unsigned code and is converted to decimal using the
</p>
<p>standard conversion procedure described in prior sections. If the number is negative (i.e., the sign bit is
</p>
<p>1), then the number sign is recorded separately and a two&rsquo;s complement is performed on the code in
</p>
<p>order to convert it to its positive magnitude equivalent. This new positive number is then converted to
</p>
<p>decimal using the standard conversion procedure. The final step is to apply the sign. Example 2.27
</p>
<p>shows an example of this process.
</p>
<p>Example 2.27
Finding the Decimal Value of a Two&rsquo;s Complement Number
</p>
<p>To convert a decimal number into its two&rsquo;s complement code, the range is first checked to determine
</p>
<p>whether the number can be represented with the allocated number of bits. The next step is to convert the
</p>
<p>decimal number into unsigned binary. The final step is to apply the sign bit. If the original decimal number
</p>
<p>was positive, then the conversion is complete. If the original decimal number was negative, then the
</p>
<p>two&rsquo;s complement is taken on the unsigned binary code to find its negative equivalent. Example 2.28
</p>
<p>shows this procedure when converting �9910 to its 8-bit, two&rsquo;s complement code.
</p>
<p>30 &bull; Chapter 2: Number Systems</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 2.28
Finding the Two&rsquo;s Complement Code of a Decimal Number
</p>
<p>2.4.2.4 Arithmetic with Two&rsquo;s Complement
</p>
<p>Two&rsquo;s complement has a variety of arithmetic advantages. First, the operations of addition, subtrac-
</p>
<p>tion, and multiplication are handled exactly the same as when using unsigned numbers. This means that
</p>
<p>duplicate circuitry is not needed in a system that uses both number types. Second, the ability to convert a
</p>
<p>number from positive to its negative representation by performing a two&rsquo;s complement means that an
</p>
<p>adder circuit can be used for subtraction. For example, if we wanted to perform the subtraction
</p>
<p>1310 � 410 &frac14; 910, this is the same as performing 1310 + (�410) &frac14; 910. This allows us to use a single
</p>
<p>adder circuit to perform both addition and subtraction as long as we have the ability to take the two&rsquo;s
</p>
<p>complement of a number. Creating a circuit to perform two&rsquo;s complement can be simpler and faster than
</p>
<p>building a separate subtraction circuit, so this approach can sometimes be advantageous.
</p>
<p>There are specific rules for performing two&rsquo;s complement arithmetic that must be followed to ensure
</p>
<p>proper results. First, any carry or borrow that is generated is ignored. The second rule that must be
</p>
<p>followed is to always check if two&rsquo;s complement overflow occurred. Two&rsquo;s complement overflow refers
</p>
<p>to when the result of the operation falls outside of the range of values that can be represented by the
</p>
<p>number of bits being used. For example, if you are performing 8-bit, two&rsquo;s complement addition,
</p>
<p>the range of decimal values that can be represented is �12810 to +12710. Having two input terms of
</p>
<p>2.4 Unsigned and Signed Numbers &bull; 31</p>
<p/>
</div>
<div class="page"><p/>
<p>12710 (0111 11112) is perfectly legal because they can be represented by the 8 bits of the two&rsquo;s
</p>
<p>complement number; however, the summation of 12710 + 12710 &frac14; 25410 (1111 11102). This number
</p>
<p>does not fit within the range of values that can be represented and is actually the two&rsquo;s complement code
</p>
<p>for �210, which is obviously incorrect. Two&rsquo;s complement overflow occurs if any of the following occurs:
</p>
<p>&bull; The sum of like signs results in an answer with opposite sign (i.e., positive + positive &frac14; neg-
ative or negative + negative &frac14; positive)
</p>
<p>&bull; The subtraction of a positive number from a negative number results in a positive number (i.e.,
negative � positive &frac14; positive)
</p>
<p>&bull; The subtraction of a negative number from a positive number results in a negative number (i.e.,
positive � negative &frac14; negative)
</p>
<p>Computer systems that use two&rsquo;s complement have a dedicated logic circuit that monitors for any of
</p>
<p>these situations and lets the operator know that overflow has occurred. These circuits are straightforward
</p>
<p>since they simply monitor the sign bits of the input and output codes. Example 2.29 shows how to use
</p>
<p>two&rsquo;s complement in order to perform subtraction using an addition operation.
</p>
<p>Example 2.29
Two&rsquo;s Complement Addition
</p>
<p>32 &bull; Chapter 2: Number Systems</p>
<p/>
</div>
<div class="page"><p/>
<p>CC2.4 A 4-bit, two&rsquo;s complement number has 16 unique codes and can represent decimal 
</p>
<p>numbers between -810 to +710.  If the number of unique codes is even, why is it that the  
range of integers it can represent is not symmetrical about zero? 
</p>
<p>A) One of the positive codes is used to represent zero.  This prevents the highest 
positive number from reaching +810 and being symmetrical.
</p>
<p>B) It is asymmetrical because the system allows the numbers to roll over.
</p>
<p>C) It isn&rsquo;t asymmetrical if zero is considered a positive integer.  That way there are 
eight positive numbers and eight negatives numbers.
</p>
<p>D) It is asymmetrical because there are duplicate codes for 0.
</p>
<p>CONCEPT CHECK
</p>
<p>Summary
</p>
<p>v The base, or radix, of a number system refers
to the number of unique symbols within its
set. The definition of a number system
includes both the symbols used and the rela-
tive values of each symbol within the set.
</p>
<p>v Themost common number systems are base
10 (decimal), base 2 (binary), and base
16 (hexadecimal). Base 10 is used because
it is how the human brain has been trained to
treat numbers. Base 2 is used because the
two values are easily represented using elec-
trical switches. Base 16 is a convenient way
to describe large groups of bits.
</p>
<p>v A positional number system allows larger
(or smaller) numbers to be represented
beyond the values within the original symbol
set. This is accomplished by having each
position within a number have a different
weight.
</p>
<p>v There are specific algorithms that are used to
convert any base to or from decimal. There
are also algorithms to convert between num-
ber systems that contain a power-of-two
symbols (e.g., binary to hexadecimal and
hexadecimal to binary).
</p>
<p>v Binary arithmetic is performed on a fixed
width of bits (n). When an n-bit addition
results in a sum that cannot fit within n-bits,
it generates a carry out bit. In an n-bit sub-
traction, if the minuend is smaller than the
</p>
<p>subtrahend, a borrow in can be used to com-
plete the operation.
</p>
<p>v Binary codes can represent both unsigned
and signed numbers. For an arbitrary n-bit
binary code, it is important to know the
encoding technique and the range of values
that can be represented.
</p>
<p>v Signed numbers use the most significant
position to represent whether the number is
negative (0 &frac14; positive, 1 &frac14; negative). The
width of a signed number is always fixed.
</p>
<p>v Two&rsquo;s complement is the most common
encoding technique for signed numbers. It
has an advantage that there are no duplicate
codes for zero and that the encoding
approach provides a monotonic progression
of codes from the most negative number that
can be represented to the most positive. This
allows addition and subtraction to work the
same on two&rsquo;s complement numbers as it
does on unsigned numbers.
</p>
<p>v When performing arithmetic using two&rsquo;s com-
plement codes, the carry bit is ignored.
</p>
<p>v When performing arithmetic using two&rsquo;s com-
plement codes, if the result lies outside of the
range that can be represented it is called
two&rsquo;s complement overflow. Two&rsquo;s comple-
ment overflow can be determined by looking
at the sign bits of the input arguments and the
sign bit of the result.
</p>
<p>2.4 Unsigned and Signed Numbers &bull; 33</p>
<p/>
</div>
<div class="page"><p/>
<p>Exercise Problems
</p>
<p>Section 2.1: Positional Number Systems
</p>
<p>2.1.1 What is the radix of the binary number system?
</p>
<p>2.1.2 What is the radix of the decimal number
system?
</p>
<p>2.1.3 What is the radix of the hexadecimal number
system?
</p>
<p>2.1.4 What is the radix of the octal number system?
</p>
<p>2.1.5 For the number 261.367, what position (p) is
the number 2 in?
</p>
<p>2.1.6 For the number 261.367, what position (p) is
the number 1 in?
</p>
<p>2.1.7 For the number 261.367, what position (p) is
the number 3 in?
</p>
<p>2.1.8 For the number 261.367, what position (p) is
the number 7 in?
</p>
<p>2.1.9 What is the name of the number system
containing 102?
</p>
<p>2.1.10 What is the name of the number system
containing 1010?
</p>
<p>2.1.11 What is the name of the number system
containing 1016?
</p>
<p>2.1.12 What is the name of the number system
containing 108?
</p>
<p>2.1.13 Which of the four number systems covered in
this chapter (i.e., binary, decimal, hexadecimal,
and octal) could the number 22 be part of?
Give all that are possible.
</p>
<p>2.1.14 Which of the four number systems covered in
this chapter (i.e., binary, decimal, hexadecimal,
and octal) could the number 99 be part of?
Give all that are possible.
</p>
<p>2.1.15 Which of the four number systems covered in
this chapter (i.e., binary, decimal, hexadecimal,
and octal) could the number 1F be part of?
Give all that are possible.
</p>
<p>2.1.16 Which of the four number systems covered in
this chapter (i.e., binary, decimal, hexadecimal,
and octal) could the number 88 be part of?
Give all that are possible.
</p>
<p>Section 2.2: Base Conversions
</p>
<p>2.2.1 If the number 101.111 has a radix of 2, what is
the weight of the position containing the bit 0?
</p>
<p>2.2.2 If the number 261.367 has a radix of 10, what is
the weight of the position containing the
numeral 2?
</p>
<p>2.2.3 If the number 261.367 has a radix of 16, what is
the weight of the position containing the
numeral 1?
</p>
<p>2.2.4 If the number 261.367 has a radix of 8, what is
the weight of the position containing the
numeral 3?
</p>
<p>2.2.5 Convert 1100 11002 to decimal. Treat all num-
bers as unsigned.
</p>
<p>2.2.6 Convert 1001.10012 to decimal. Treat all num-
bers as unsigned.
</p>
<p>2.2.7 Convert 728 to decimal. Treat all numbers as
unsigned.
</p>
<p>2.2.8 Convert 12.578 to decimal. Treat all numbers
as unsigned.
</p>
<p>2.2.9 Convert F316 to decimal. Treat all numbers as
unsigned.
</p>
<p>2.2.10 Convert 15B.CEF16 to decimal. Treat all num-
bers as unsigned. Use an accuracy of seven
fractional digits.
</p>
<p>2.2.11 Convert 6710 to binary. Treat all numbers as
unsigned.
</p>
<p>2.2.12 Convert 252.98710 to binary. Treat all numbers
as unsigned. Use an accuracy of 4 fractional
bits and don&rsquo;t round up.
</p>
<p>2.2.13 Convert 6710 to octal. Treat all numbers as
unsigned.
</p>
<p>2.2.14 Convert 252.98710 to octal. Treat all numbers
as unsigned. Use an accuracy of four fractional
digits and don&rsquo;t round up.
</p>
<p>2.2.15 Convert 6710 to hexadecimal. Treat all num-
bers as unsigned.
</p>
<p>2.2.16 Convert 252.98710 to hexadecimal. Treat all
numbers as unsigned. Use an accuracy of
four fractional digits and don&rsquo;t round up.
</p>
<p>2.2.17 Convert 1 0000 11112 to octal. Treat all num-
bers as unsigned.
</p>
<p>2.2.18 Convert 1 0000 1111.0112 to hexadecimal.
Treat all numbers as unsigned.
</p>
<p>2.2.19 Convert 778 to binary. Treat all numbers as
unsigned.
</p>
<p>2.2.20 Convert F.A16 to binary. Treat all numbers as
unsigned.
</p>
<p>2.2.21 Convert 668 to hexadecimal. Treat all numbers
as unsigned.
</p>
<p>2.2.22 Convert AB.D16 to octal. Treat all numbers as
unsigned.
</p>
<p>Section 2.3: Binary Arithmetic
</p>
<p>2.3.1 Compute 10102 + 10112 by hand. Treat all
numbers as unsigned. Provide the 4-bit sum
and indicate whether a carry out occurred.
</p>
<p>2.3.2 Compute 1111 11112 + 0000 00012 by hand.
Treat all numbers as unsigned. Provide the
8-bit sum and indicate whether a carry out
occurred.
</p>
<p>2.3.3 Compute 1010.10102 + 1011.10112 by hand.
Treat all numbers as unsigned. Provide the
8-bit sum and indicate whether a carry out
occurred.
</p>
<p>2.3.4 Compute 1111 1111.10112 + 0000 0001.11002
by hand. Treat all numbers as unsigned. Pro-
vide the 12-bit sum and indicate whether a
carry out occurred.
</p>
<p>34 &bull; Chapter 2: Number Systems</p>
<p/>
</div>
<div class="page"><p/>
<p>2.3.5 Compute 10102 � 10112 by hand. Treat all
numbers as unsigned. Provide the 4-bit differ-
ence and indicate whether a borrow in occurred.
</p>
<p>2.3.6 Compute 1111 11112 � 0000 00012 by hand.
Treat all numbers as unsigned. Provide the
8-bit difference and indicate whether a borrow
in occurred.
</p>
<p>2.3.7 Compute 1010.10102 � 1011.10112 by hand.
Treat all numbers as unsigned. Provide the
8-bit difference and indicate whether a borrow
in occurred.
</p>
<p>2.3.8 Compute 1111 1111.10112 � 0000 0001.11002
by hand. Treat all numbers as unsigned. Pro-
vide the 12-bit difference and indicate whether
a borrow in occurred.
</p>
<p>Section 2.4: Unsigned and Signed
</p>
<p>Numbers
</p>
<p>2.4.1 What range of decimal numbers can be
represented by 8-bit, two&rsquo;s complement
numbers?
</p>
<p>2.4.2 What range of decimal numbers can be
represented by 16-bit, two&rsquo;s complement
numbers?
</p>
<p>2.4.3 What range of decimal numbers can be
represented by 32-bit, two&rsquo;s complement
numbers?
</p>
<p>2.4.4 What range of decimal numbers can be
represented by 64-bit, two&rsquo;s complement
numbers?
</p>
<p>2.4.5 What is the 8-bit, two&rsquo;s complement code for
+8810?
</p>
<p>2.4.6 What is the 8-bit, two&rsquo;s complement code for
�8810?
</p>
<p>2.4.7 What is the 8-bit, two&rsquo;s complement code for
�12810?
</p>
<p>2.4.8 What is the 8-bit, two&rsquo;s complement code for
�110?
</p>
<p>2.4.9 What is the decimal value of the 4-bit, two&rsquo;s
complement code 00102?
</p>
<p>2.4.10 What is the decimal value of the 4-bit, two&rsquo;s
complement code 10102?
</p>
<p>2.4.11 What is the decimal value of the 8-bit, two&rsquo;s
complement code 0111 11102?
</p>
<p>2.4.12 What is the decimal value of the 8-bit, two&rsquo;s
complement code 1111 11102?
</p>
<p>2.4.13 Compute 11102 + 10112 by hand. Treat all
numbers as 4-bit, two&rsquo;s complement codes.
Provide the 4-bit sum and indicate whether
two&rsquo;s complement overflow occurred.
</p>
<p>2.4.14 Compute 1101 11112 + 0000 00012 by hand.
Treat all numbers as 8-bit, two&rsquo;s complement
codes. Provide the 8-bit sum and indicate
whether two&rsquo;s complement overflow occurred.
</p>
<p>2.4.15 Compute 1010.10102 + 1000.10112 by hand.
Treat all numbers as 8-bit, two&rsquo;s complement
codes. Provide the 8-bit sum and indicate
whether two&rsquo;s complement overflow occurred.
</p>
<p>2.4.16 Compute 1110 1011.10012 + 0010 0001.11012
by hand. Treat all numbers as 12-bit, two&rsquo;s
complement codes. Provide the 12-bit sum
and indicate whether two&rsquo;s complement over-
flow occurred.
</p>
<p>2.4.17 Compute 410 � 510 using 4-bit two&rsquo;s comple-
ment addition. You will need to first convert
each number into its 4-bit two&rsquo;s complement
code and then perform binary addition (i.e.,
410 + (�510)). Provide the 4-bit result and indi-
cate whether two&rsquo;s complement overflow
occurred. Check your work by converting the
4-bit result back to decimal.
</p>
<p>2.4.18 Compute 710 � 710 using 4-bit two&rsquo;s comple-
ment addition. You will need to first convert
each decimal number into its 4-bit two&rsquo;s com-
plement code and then perform binary addition
(i.e., 710 + (�710)). Provide the 4-bit result and
indicate whether two&rsquo;s complement overflow
occurred. Check your work by converting the
4-bit result back to decimal.
</p>
<p>2.4.19 Compute 710 + 110 using 4-bit two&rsquo;s comple-
ment addition. You will need to first convert
each decimal number into its 4-bit two&rsquo;s com-
plement code and then perform binary addi-
tion. Provide the 4-bit result and indicate
whether two&rsquo;s complement overflow occurred.
Check your work by converting the 4-bit result
back to decimal.
</p>
<p>2.4.20 Compute 6410 � 10010 using 8-bit two&rsquo;s com-
plement addition. You will need to first convert
each number into its 8-bit two&rsquo;s complement
code and then perform binary addition (i.e.,
6410 + (�10010)). Provide the 8-bit result and
indicate whether two&rsquo;s complement overflow
occurred. Check your work by converting the
8-bit result back to decimal.
</p>
<p>2.4.21 Compute (�99)10 � 1110 using 8-bit two&rsquo;s
complement addition. You will need to first con-
vert each decimal number into its 8-bit two&rsquo;s
complement code and then perform binary
addition (i.e., (�9910) + (�1110)). Provide the
8-bit result and indicate whether two&rsquo;s comple-
ment overflow occurred. Check your work by
converting the 8-bit result back to decimal.
</p>
<p>2.4.22 Compute 5010 + 10010 using 8-bit two&rsquo;s com-
plement addition. You will need to first convert
each decimal number into its 8-bit two&rsquo;s com-
plement code and then perform binary addi-
tion. Provide the 8-bit result and indicate
whether two&rsquo;s complement overflow occurred.
Check your work by converting the 8-bit result
back to decimal.
</p>
<p>Exercise Problems &bull; 35</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 3: Digital Circuitry
</p>
<p>and Interfacing
Now we turn our attention to the physical circuitry and electrical quantities that are used to represent
</p>
<p>and operate on the binary codes 1 and 0. In this chapter we begin by looking at how logic circuits are
</p>
<p>described and introduce the basic set of gates used for all digital logic operations. We then look at the
</p>
<p>underlying circuitry that implements the basic gates including digital signaling and how voltages are used
</p>
<p>to represent 1s and 0s. We then look at interfacing between two digital circuits and how to ensure that
</p>
<p>when one circuit sends a binary code, the receiving circuit is able to determine which code was sent.
</p>
<p>Logic families are then introduced and the details of how basic gates are implemented at the switch level
</p>
<p>are presented. Finally, interfacing considerations are covered for the most common types of digital loads
</p>
<p>(i.e., other gates, resistors, and LEDs). The goal of this chapter is to provide an understanding of the
</p>
<p>basic electrical operation of digital circuits.
</p>
<p>Learning Outcomes&mdash;After completing this chapter, you will be able to:
</p>
<p>3.1 Describe the functional operation of a basic logic gate using truth tables, logic expressions,
and logic waveforms.
</p>
<p>3.2 Analyze the DC and AC behavior of a digital circuit to verify that it is operating within
specification.
</p>
<p>3.3 Describe the meaning of a logic family and the operation of the most common technologies
used today.
</p>
<p>3.4 Determine the operating conditions of a logic circuit when driving various types of loads.
</p>
<p>3.1 Basic Gates
</p>
<p>The term gate is used to describe a digital circuit that implements the most basic functions possible
</p>
<p>within the binary system. When discussing the operation of a logic gate, we ignore the details of how the
</p>
<p>1s and 0s are represented with voltages and manipulated using transistors. We instead treat the inputs
</p>
<p>and output as simply ideal 1s and 0s. This allows us to design more complex logic circuits without going
</p>
<p>into the details of the underlying physical hardware.
</p>
<p>3.1.1 Describing the Operation of a Logic Circuit
</p>
<p>3.1.1.1 The Logic Symbol
</p>
<p>A logic symbol is a graphical representation of the circuit that can be used in a schematic to show
</p>
<p>how circuits in a system interface to one another. For the set of basic logic gates, there are uniquely
</p>
<p>shaped symbols that graphically indicate their functionality. For more complex logic circuits that are
</p>
<p>implemented with multiple basic gates, a simple rectangular symbol is used. Inputs of the logic circuit are
</p>
<p>typically shown on the left of the symbol and outputs are on the right. Figure 3.1 shows two example logic
</p>
<p>symbols.
</p>
<p># Springer International Publishing Switzerland 2017
</p>
<p>B.J. LaMeres, Introduction to Logic Circuits &amp; Logic Design with VHDL,
</p>
<p>DOI 10.1007/978-3-319-34195-8_3
</p>
<p>37</p>
<p/>
</div>
<div class="page"><p/>
<p>3.1.1.2 The Truth Table
</p>
<p>We formally define the functionality of a logic circuit using a truth table. In a truth table, each and
</p>
<p>every possible input combination is listed and the corresponding output of the logic circuit is given. If a
</p>
<p>logic circuit has n inputs, then it will have 2n possible input codes. The binary codes are listed in
</p>
<p>ascending order within the truth table mimicking a binary count starting at 0. By always listing the input
</p>
<p>codes in this way, we can assign a row number to each input that is the decimal equivalent of the binary
</p>
<p>input code. Row numbers can be used to simplify the notation for describing the functionality of larger
</p>
<p>circuits. Figure 3.2 shows the formation of an example 3-input truth table.
</p>
<p>3.1.1.3 The Logic Function
</p>
<p>A logic expression (also called a logic function) is an equation that provides the functionality of each
</p>
<p>output in the circuit as a function of the inputs. The logic operations for the basic gates are given a
</p>
<p>symbolic set of operators (e.g., +,.,
L
</p>
<p>), the details of which will be given in the next sections. The logic
</p>
<p>function describes the operations that are necessary to produce the outputs listed in the truth table. A
</p>
<p>logic function is used to describe a single output that can take on only the values 1 and 0. If a circuit
</p>
<p>contains multiple outputs, then a logic function is needed for each output. The input variables can be
</p>
<p>included in the expression description just as in an analog function. For example, &ldquo;F(A,B,C) &frac14; . . .&rdquo; would
</p>
<p>state that &ldquo;F is a function of the inputs A, B, and C.&rdquo; This can also be written as &ldquo;FA,B,C &frac14; . . ..&rdquo; The input
</p>
<p>variables can also be excluded for brevity as in &ldquo;F &frac14; . . . .&rdquo; Figure 3.3 shows the formation of an example
</p>
<p>3-input logic expression.
</p>
<p>Fig. 3.1
Example logic symbols
</p>
<p>Fig. 3.2
Truth table formation
</p>
<p>38 &bull; Chapter 3: Digital Circuitry and Interfacing</p>
<p/>
</div>
<div class="page"><p/>
<p>3.1.1.4 The Logic Waveform
</p>
<p>A logicwaveform is a graphical depiction of the relationship of the output to the inputs with respect to
</p>
<p>time. This is often a useful description of behavior since it mimics the format that is typically observed
</p>
<p>when measuring a real digital circuit using test equipment such as an oscilloscope. In the waveform,
</p>
<p>each signal can only take on a value of 1 or 0. It is useful to write the logic values of the signal at each
</p>
<p>transition in the waveform for readability. Figure 3.4 shows an example logic waveform.
</p>
<p>3.1.2 The Buffer
</p>
<p>The first basic gate is the buffer. The output of a buffer is simply the input. The logic symbol, truth
</p>
<p>table, logic function and logic waveform for the buffer are given in Fig. 3.5.
</p>
<p>Fig. 3.3
Logic function formation
</p>
<p>Fig. 3.4
Example logic waveform
</p>
<p>Fig. 3.5
Buffer symbol, truth table, logic function, and logic waveform
</p>
<p>3.1 Basic Gates &bull; 39</p>
<p/>
</div>
<div class="page"><p/>
<p>3.1.3 The Inverter
</p>
<p>The next basic gate is the inverter. The output of an inverter is the complement of the input. Inversion
</p>
<p>is also often called the not operation. In spoken word, we might say &ldquo;A is equal to not B&rdquo;; thus this gate is
</p>
<p>also often called a not gate. The symbol for the inverter is the same as the buffer with the exception that
</p>
<p>an inversion bubble (i.e., a circle) is placed on the output. The inversion bubble is a common way to show
</p>
<p>inversions in schematics and will be used by many of the basic gates. In the logic function, there are two
</p>
<p>common ways to show this operation. The first way is by placing a prime (0) after the input variable (e.g.,
</p>
<p>Out &frac14; In0). This notation has the advantage that it is supported in all text editors but has the drawback
</p>
<p>that it can sometimes be difficult to see. The second way to indicate inversion in a logic function is by
</p>
<p>placing an inversion bar over the input variable (e.g., Out &frac14; In). The advantage of this notation is that it is
</p>
<p>easy to see but has the drawback that it is not supported by many text editors. In this text, both
</p>
<p>conventions will be used to provide exposure to each. The logic symbol, truth table, logic function, and
</p>
<p>logic waveform for the inverter are given in Fig. 3.6.
</p>
<p>3.1.4 The AND Gate
</p>
<p>The next basic gate is the AND gate. The output of an AND gate will only be true (i.e., a logic 1) if all
</p>
<p>of the inputs are true. This operation is also called a logical product because if the inputs were
</p>
<p>multiplied together, the only time the output would be a 1 is if each and every input was a 1. As a result,
</p>
<p>the logic operator is the dot (�). Another notation that is often seen is the ampersand (&amp;). The logic
</p>
<p>symbol, truth table, logic function, and logic waveform for a 2-input AND gate are given in Fig. 3.7.
</p>
<p>Ideal AND gates can have any number of inputs. The operation of an n-bit, AND gates still follows
</p>
<p>the rule that the output will only be true when all of the inputs are true. Later sections will discuss the
</p>
<p>limitations on expanding the number of inputs of these basic gates indefinitely.
</p>
<p>Fig. 3.6
Inverter symbol, truth table, logic function, and logic waveform
</p>
<p>Fig. 3.7
2-Input AND gate symbol, truth table, logic function, and logic waveform
</p>
<p>40 &bull; Chapter 3: Digital Circuitry and Interfacing</p>
<p/>
</div>
<div class="page"><p/>
<p>3.1.5 The NAND Gate
</p>
<p>The NAND gate is identical to the AND gate with the exception that the output is inverted. The &ldquo;N&rdquo; in
</p>
<p>NAND stands for &ldquo;NOT,&rdquo; which represents the inversion. The symbol for a NAND gate is an AND gate
</p>
<p>with an inversion bubble on the output. The logic expression for a NAND gate is the same as an AND
</p>
<p>gate but with an inversion bar over the entire operation. The logic symbol, truth table, logic function, and
</p>
<p>logic waveform for a 2-input NAND gate are given in Fig. 3.8. Ideal NAND gates can have any number of
</p>
<p>inputs with the operation of an n-bit, NAND gate following the rule that the output is always the inversion
</p>
<p>of an n-bit, AND operation.
</p>
<p>3.1.6 The OR Gate
</p>
<p>The next basic gate is the OR gate. The output of an OR gate will be true when any of the inputs
</p>
<p>are true. This operation is also called a logical sum because of its similarity to logical disjunction in which
</p>
<p>the output is true if at least one of the inputs is true. As a result, the logic operator is the plus sign (+). The
</p>
<p>logic symbol, truth table, logic function, and logic waveform for a 2-input OR gate are given in Fig. 3.9.
</p>
<p>Ideal OR gates can have any number of inputs. The operation of an n-bit, OR gates still follows the rule
</p>
<p>that the output will be true if any of the inputs are true.
</p>
<p>3.1.7 The NOR Gate
</p>
<p>The NOR gate is identical to the OR gate with the exception that the output is inverted. The symbol
</p>
<p>for a NOR gate is an OR gate with an inversion bubble on the output. The logic expression for a NOR
</p>
<p>gate is the same as an OR gate but with an inversion bar over the entire operation. The logic symbol,
</p>
<p>truth table, logic function, and logic waveform for a 2-input NOR gate are given in Fig. 3.10. Ideal NOR
</p>
<p>gates can have any number of inputs with the operation of an n-bit, NOR gate following the rule that the
</p>
<p>output is always the inversion of an n-bit, OR operation.
</p>
<p>Fig. 3.8
2-Input NAND gate symbol, truth table, logic function, and logic waveform
</p>
<p>Fig. 3.9
2-Input OR gate symbol, truth table, logic function, and logic waveform
</p>
<p>3.1 Basic Gates &bull; 41</p>
<p/>
</div>
<div class="page"><p/>
<p>3.1.8 The XOR Gate
</p>
<p>The next basic gate is the exclusive-OR gate, or XOR gate for short. This gate is also called a
</p>
<p>difference gate because for the 2-input configuration, its output will be true when the input codes are
</p>
<p>different from one another. The logic operator is a circle around a plus sign (
L
</p>
<p>). The logic symbol, truth
</p>
<p>table, logic function, and logic waveform for a 2-input XOR gate are given in Fig. 3.11.
</p>
<p>Using the formal definition of an XOR gate (i.e., the output is true if any of the input codes are
</p>
<p>different from one another), an XOR gate with more than two inputs can be built. The truth table for a
</p>
<p>3-bit, XOR gate using this definition is shown in Fig. 3.12. In modern electronics, this type of gate has
</p>
<p>found little use since it is much simpler to build this functionality using a combination of AND and OR
</p>
<p>gates. As such, XOR gates with greater than two inputs do not implement the difference function.
</p>
<p>Instead, a more useful functionality has been adopted in which the output of the n-bit, XOR gate is the
</p>
<p>result of a cascade of 2-input XOR gates. This results in an ultimate output that is true when there is an
</p>
<p>ODD number of 1s on the inputs. This functionality is much more useful in modern electronics for error
</p>
<p>correction codes and arithmetic. As such, this is the functionality that is seen in modern n-bit, XOR gates.
</p>
<p>This functionality is also shown in Fig. 3.12.
</p>
<p>Fig. 3.10
2-Input NOR gate symbol, truth table, logic function, and logic waveform
</p>
<p>Fig. 3.11
2-Input XOR gate symbol, truth table, logic function, and logic waveform
</p>
<p>42 &bull; Chapter 3: Digital Circuitry and Interfacing</p>
<p/>
</div>
<div class="page"><p/>
<p>3.1.9 The XNOR Gate
</p>
<p>The exclusive-NOR gate is identical to the XOR gate with the exception that the output is inverted.
</p>
<p>This gate is also called an equivalence gate because for the 2-input configuration, its output will be true
</p>
<p>when the input codes are equivalent to one another. The symbol for an XNOR gate is an XOR gate
</p>
<p>with an inversion bubble on the output. The logic expression for an XNOR gate is the same as an XOR
</p>
<p>gate but with an inversion bar over the entire operation. The logic symbol, truth table, logic function, and
</p>
<p>logic waveform for a 2-input XNOR gate are given in Fig. 3.13. XNOR gates can have any number of
</p>
<p>inputs with the operation of an n-bit, XNOR gate following the rule that the output is always the inversion
</p>
<p>of an n-bit, XOR operation (i.e., the output is true if there is an ODD number of 1s on the inputs).
</p>
<p>Fig. 3.12
3-Input XOR gate implementation
</p>
<p>Fig. 3.13
2-Input XNOR gate symbol, truth table, logic function, and logic waveform
</p>
<p>3.1 Basic Gates &bull; 43</p>
<p/>
</div>
<div class="page"><p/>
<p>CC3.1 Given the following logic diagram, which is the correct logic expression for F?
</p>
<p>A)   F = (A&middot;B)&rsquo; &oplus; C
</p>
<p>B)   F = (A&rsquo;&middot;B&rsquo;) &oplus; C 
</p>
<p>C)   F = (A&rsquo;&middot;B&rsquo; &oplus; C)
</p>
<p>D)   F = A&middot;B&rsquo; &oplus; C 
</p>
<p>CONCEPT CHECK
</p>
<p>3.2 Digital Circuit Operation
</p>
<p>Now we turn our attention to the physical hardware that is used to build the basic gates just
</p>
<p>described and how electrical quantities are used to represent and communicate the binary values
</p>
<p>1 and 0. We begin by looking at digital signaling. Digital signaling refers to how binary codes are
</p>
<p>generated and transmitted successfully between two digital circuits using electrical quantities (e.g.,
</p>
<p>voltage and current). Consider the digital system shown in Fig. 3.14. In this system, the sending circuit
</p>
<p>generates a binary code. The sending circuit is called either the transmitter (Tx) or driver. The transmitter
</p>
<p>represents the binary code using an electrical quantity such as voltage. The receiving circuit
</p>
<p>(Rx) observes this voltage and is able to determine the value of the binary code. In this way, 1s and 0s
</p>
<p>can be communicated between the two digital circuits. The transmitter and receiver are both designed to
</p>
<p>use the same digital signaling scheme so that they are able to communicate with each other. It should be
</p>
<p>noted that all digital circuits contain both inputs (Rx) and outputs (Tx) but are not shown in this figure for
</p>
<p>simplicity.
</p>
<p>3.2.1 Logic Levels
</p>
<p>A logic level is the term to describe all possible states that a signal can have. We will focus explicitly
</p>
<p>on circuits that represent binary values, so these will only have two finite states (1 and 0). To begin, we
</p>
<p>define a simplistic model of how to represent the binary codes using an electrical quantity. This model
</p>
<p>uses a voltage threshold (Vth) to represent the switching point between the binary codes. If the voltage of
</p>
<p>the signal (Vsig) is above this threshold, it is considered a logic HIGH. If the voltage is below this
</p>
<p>threshold, it is considered a logic LOW. A graphical depiction of this is shown in Fig. 3.15. The terms
</p>
<p>HIGH and LOW are used to describe which logic level corresponds to the higher or lower voltage.
</p>
<p>Fig. 3.14
Generic digital transmitter/receiver circuit
</p>
<p>44 &bull; Chapter 3: Digital Circuitry and Interfacing</p>
<p/>
</div>
<div class="page"><p/>
<p>It is straightforward to have the HIGH level correspond to the binary code 1 and the LOW level
</p>
<p>correspond to the binary code 0; however, it is equally valid to have the HIGH level correspond to the
</p>
<p>binary code 0 and the LOW level correspond to the binary code 1. As such, we need to define how the
</p>
<p>logic levels HIGH and LOWmap to the binary codes 1 and 0. We define two types of digital assignments:
</p>
<p>positive logic and negative logic. In positive logic, the logic HIGH level represents a binary 1 and the
</p>
<p>logic LOW level represents a binary 0. In negative logic, the logic HIGH level represents a binary 0 and
</p>
<p>the logic LOW level represents a binary 1. Table 3.1 shows the definition of positive and negative logic.
</p>
<p>There are certain types of digital circuits that benefit from using negative logic; however, we will focus
</p>
<p>specifically on systems that use positive logic since it is more intuitive when learning digital design for the
</p>
<p>first time. The transformation between positive and negative logic is straightforward and will be covered
</p>
<p>in Chap. 4.
</p>
<p>3.2.2 Output DC Specifications
</p>
<p>Transmitting circuits provide specifications on the range of output voltages (VO) that they are
</p>
<p>guaranteed to provide when outputting a logic 1 or 0. These are called the DC output specifications.
</p>
<p>There are four DC voltage specifications that specify this range: VOH-max, VOH-min, VOL-max, and VOL-min.
</p>
<p>The VOH-max and VOH-min specifications provide the range of voltages the transmitter is guaranteed to
</p>
<p>provide when outputting a logic HIGH (or logic 1 when using positive logic). The VOL-max and VOL-min
specifications provide the range of voltages the transmitter is guaranteed to provide when outputting a
</p>
<p>logic LOW (or logic 0 when using positive logic). In the subscripts for these specifications, the &ldquo;O&rdquo;
</p>
<p>signifies &ldquo;output&rdquo; and the &ldquo;L&rdquo; or &ldquo;H&rdquo; signifies &ldquo;LOW&rdquo; or &ldquo;HIGH,&rdquo; respectively.
</p>
<p>Fig. 3.15
Definition of logic HIGH and LOW
</p>
<p>Table 3.1
Definition of positive and negative logic
</p>
<p>3.2 Digital Circuit Operation &bull; 45</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_4">http://dx.doi.org/10.1007/978-3-319-34195-8_4</a></div>
</div>
<div class="page"><p/>
<p>The maximum amount of current that can flow through the transmitter&rsquo;s output (IO) is also specified.
</p>
<p>The specification IOH-max is the maximum amount of current that can flow through the transmitter&rsquo;s output
</p>
<p>when sending a logic HIGH. The specification IOL-max is the maximum amount of current that can flow
</p>
<p>through the transmitter&rsquo;s output when sending a logic LOW. When the maximum output currents are
</p>
<p>violated, it usually damages the part. Manufacturers will also provide a recommended amount of current
</p>
<p>for IO that will guarantee the specified operating parameters throughout the life of the part. Figure 3.16
</p>
<p>shows a graphical depiction of these DC specifications. When the transmitter output is providing current
</p>
<p>to the receiving circuit (a.k.a., the load), it is said to be sourcing current. When the transmitter output is
</p>
<p>drawing current from the receiving circuit, it is said to be sinking current. In most cases, the transmitter
</p>
<p>sources current when driving a logic HIGH and sinks current when driving a logic LOW. Figure 3.16
</p>
<p>shows a graphical depiction of these specifications.
</p>
<p>3.2.3 Input DC Specifications
</p>
<p>Receiving circuits provide specifications on the range of input voltages (VI) that they will interpret as
</p>
<p>either a logic HIGH or LOW. These are called the DC input specifications. There are four DC voltage
</p>
<p>specifications that specify this range: VIH-max, VIH-min, VIL-max, and VIL-min. The VIH-max and VIH-min
specifications provide the range of voltages that the receiver will interpret as a logic HIGH (or logic
</p>
<p>1 when using positive logic). The VIL-max and VIL-min specifications provide the range of voltages that the
</p>
<p>Fig. 3.16
DC specifications of a digital circuit
</p>
<p>46 &bull; Chapter 3: Digital Circuitry and Interfacing</p>
<p/>
</div>
<div class="page"><p/>
<p>receiver will interpret as a logic LOW (or logic 0 when using positive logic). In the subscripts for these
</p>
<p>specifications, the &ldquo;I&rdquo; signifies &ldquo;input.&rdquo;
</p>
<p>The maximum amount of current that the receiver will draw, or take in, when connected is also
</p>
<p>specified II). The specification IIH-max is the maximum amount of current that the receiver will draw when it
</p>
<p>is being driven with a logic HIGH. The specification IIL-max is the maximum amount of current that the
</p>
<p>receiver will draw when it is being driven with a logic LOW. Again, Fig. 3.16 shows a graphical depiction
</p>
<p>of these DC specifications.
</p>
<p>3.2.4 Noise Margins
</p>
<p>For digital circuits that are designed to operate with each other, the VOH-max and VIH-max
specifications have equal voltages. Similarly, the VOL-min and VIL-min specifications have equal voltages.
</p>
<p>The VOH-max and VOL-min output specifications represent the best-case scenario for digital signaling as
</p>
<p>the transmitter is sending the largest (or smallest) signal possible. If there is no loss in the interconnect
</p>
<p>between the transmitter and receiver, the full voltage levels will arrive at the receiver and be interpreted
</p>
<p>as the correct logic states (HIGH or LOW).
</p>
<p>The worst-case scenario for digital signaling is when the transmitter outputs its levels at VOH-min and
</p>
<p>VOL-max. These levels represent the furthest away from an ideal voltage level that the transmitter can
</p>
<p>send to the receiver and are susceptible to loss and noise that may occur in the interconnect system. In
</p>
<p>order to compensate for potential loss or noise, digital circuits have a predefined amount of margin built
</p>
<p>into their worst-case specifications. Let&rsquo;s take the worst-case example of a transmitter sending a logic
</p>
<p>HIGH at the level VOH-min. If the receiver was designed to have VIH-min (i.e., the lowest voltage that would
</p>
<p>still be interpreted as a logic 1) equal to VOH-min, then if even the smallest amount of the output signal was
</p>
<p>attenuated as it traveled through the interconnect, it would arrive at the receiver below VIH-min and would
</p>
<p>not be interpreted as a logic 1. Since there will always be some amount of loss in any interconnect
</p>
<p>system, the specifications for VIH-min are always less than VOH-min. The difference between these two
</p>
<p>quantities is called the noise margin. More specifically, it is called the noise margin HIGH (or NMH) to
</p>
<p>signify howmuchmargin is built into the Tx/Rx circuit when communicating a logic 1. Similarly, the VIL-max
specification is always higher than the VOL-max specification to account for any voltage added to the
</p>
<p>signal in the interconnect. The difference between these two quantities is called the noise margin LOW
</p>
<p>(or NML) to signify how much margin is built into the Tx/Rx circuit when communicating a logic 0. Noise
</p>
<p>margins are always specified as positive quantities, and thus the order of the subtrahend and minuend in
</p>
<p>these differences:
</p>
<p>NMH &frac14; VOH‐min � VIH‐min
</p>
<p>NML &frac14; VIL‐max � VOL‐max
</p>
<p>Figure 3.16 includes the graphical depiction of the noise margins. Notice in this figure that there is a
</p>
<p>region of voltages that the receiver will not interpret as either a HIGH or a LOW. This region lies between
</p>
<p>the VIH-min and VIL-max specifications. This is the uncertainty region and should be avoided. Signals in
</p>
<p>this region will cause the receiver&rsquo;s output to go to an unknown voltage. Digital transmitters are designed
</p>
<p>to transition between the LOWand HIGH states quickly enough so that the receiver does not have time to
</p>
<p>react to the input being in the uncertainty region.
</p>
<p>3.2 Digital Circuit Operation &bull; 47</p>
<p/>
</div>
<div class="page"><p/>
<p>3.2.5 Power Supplies
</p>
<p>All digital circuits require a power supply voltage and a ground. There are some types of digital
</p>
<p>circuits that may require multiple power supplies. For simplicity, we will focus on digital circuits that only
</p>
<p>require a single power supply voltage and ground. The power supply voltage is commonly given the
</p>
<p>abbreviations of either VCC or VDD. The &ldquo;CC&rdquo; or &ldquo;DD&rdquo; have to do with how the terminals of the transistors
</p>
<p>inside of the digital circuit are connected (i.e., &ldquo;collector to collector&rdquo; or &ldquo;drain to drain&rdquo;). Digital circuits will
</p>
<p>specify the required power supply voltage. Ground is considered an ideal 0v. Digital circuits will also
</p>
<p>specify the maximum amount of DC current that can flow through the VCC (ICC) and GND (IGND) pins
</p>
<p>before damaging the part.
</p>
<p>There are two components of power supply current. The first is the current that is required for the
</p>
<p>functional operation of the device. This is called the quiescent current (Iq). The second component of the
</p>
<p>power supply current is the output currents (IO). Any current that flows out of a digital circuit must also
</p>
<p>flow into it. When a transmitting circuit sources current to a load on its output pin, it must bring in that
</p>
<p>same amount of current on another pin. This is accomplished using the power supply pin (VCC).
</p>
<p>Conversely, when a transmitting circuit sinks current from a load on its output pin, an equal amount of
</p>
<p>current must exit the circuit on a different pin. This is accomplished using the GND pin. This means that
</p>
<p>the amount of current flowing through the VCC and GND pins will vary depending on the logic states that
</p>
<p>are being driven on the outputs. Since a digital circuit may contain numerous output pins, the maximum
</p>
<p>amount of current flowing through the VCC and GND pins can scale quickly and care must be taken not to
</p>
<p>damage the device.
</p>
<p>The quiescent current is often specified using the term ICC. This should not be confused with the
</p>
<p>specification for the maximum amount of current that can flow through the VCC pin, which is often called
</p>
<p>ICC-max. It is easy to tell the difference because ICC (or Iq) is much smaller than ICC-max for CMOS parts.
</p>
<p>ICC (or Iq) is specified in the μA to nA range while the maximum current that can flow through the VCC pin
</p>
<p>is specified in the mA range. Example 3.1 shows the process of calculating the ICC and IGND currents
</p>
<p>when sourcing multiple loads.
</p>
<p>48 &bull; Chapter 3: Digital Circuitry and Interfacing</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 3.1
Calculating ICC and IGND When Sourcing Multiple Loads
</p>
<p>3.2 Digital Circuit Operation &bull; 49</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 3.2 shows the process of calculating the ICC and IGND currents when both sourcing and
</p>
<p>sinking loads.
</p>
<p>Example 3.2
Calculating ICC and IGND When Both Sourcing and Sinking Loads
</p>
<p>50 &bull; Chapter 3: Digital Circuitry and Interfacing</p>
<p/>
</div>
<div class="page"><p/>
<p>3.2.6 Switching Characteristics
</p>
<p>Switching characteristics refer to the transient behavior of the logic circuits. The first group of
</p>
<p>switching specifications characterize the propagation delay of the gate. The propagation delay is the
</p>
<p>time it takes for the output to respond to a change on the input. The propagation delay is formally defined
</p>
<p>as the time it takes from the point at which the input has transitioned to 50 % of its final value to the point
</p>
<p>at which the output has transitioned to 50 % of its final value. The initial and final voltages for the input are
</p>
<p>defined to be GND and VCC, while the output initial and final voltages are defined to be VOL and VOH.
</p>
<p>Specifications are given for the propagation delay when transitioning from a LOW to HIGH (tPLH) and
</p>
<p>from a HIGH to LOW (tPHL). When these specifications are equal, the values are often given as a single
</p>
<p>specification of tpd. These specifications are shown graphically in Fig. 3.17.
</p>
<p>The second group of switching specifications characterize how quickly the output switches between
</p>
<p>states. The transition time is defined as the time it takes for the output to transition from 10 to 90 % of the
</p>
<p>output voltage range. The rise time (tr) is the time it takes for this transition when going from a LOW to
</p>
<p>HIGH, and the fall time (tf) is the time it takes for this transition when going from a HIGH to LOW. When
</p>
<p>these specifications are equal, the values are often given as a single specification of tt. These
</p>
<p>specifications are shown graphically in Fig. 3.17.
</p>
<p>3.2.7 Data Sheets
</p>
<p>The specifications for a particular part are given in its data sheet. The data sheet contains all of the
</p>
<p>operating characteristics for a part, in addition to functional information such as package geometries and
</p>
<p>pin assignments. The data sheet is usually the first place a designer will look when selecting a part.
</p>
<p>Figures 3.18, 3.19, and 3.20 show excerpts from an example data sheet highlighting some of the
</p>
<p>specifications just covered.
</p>
<p>Fig. 3.17
Switching characteristics of a digital circuit
</p>
<p>3.2 Digital Circuit Operation &bull; 51</p>
<p/>
</div>
<div class="page"><p/>
<p>Fig. 3.18
Example data sheet excerpt (1)
</p>
<p>52 &bull; Chapter 3: Digital Circuitry and Interfacing</p>
<p/>
</div>
<div class="page"><p/>
<p>Fig. 3.19
Example data sheet excerpt (2)
</p>
<p>3.2 Digital Circuit Operation &bull; 53</p>
<p/>
</div>
<div class="page"><p/>
<p>Fig. 3.20
Example data sheet excerpt (3)
</p>
<p>54 &bull; Chapter 3: Digital Circuitry and Interfacing</p>
<p/>
</div>
<div class="page"><p/>
<p>CC3.2(a) Given the following DC specifications for a driver/receiver pair, in what situation may a 
logic signal transmitted not be successfully received?
</p>
<p>VOH-max = +3.4v VIH-max = +3.4v
</p>
<p>VOH-min = +2.5v VIH-min = +2.5v
</p>
<p>VOL-max = +1.5v VIL-max = +2.0v
</p>
<p>VOL-min = 0v VIL-min = 0v
</p>
<p>A) Driving a HIGH with Vo=+3.4v
</p>
<p>B) Driving a HIGH with Vo=+2.5v
</p>
<p>C) Driving a LOW with Vo=+1.5v
</p>
<p>D) Driving a LOW with Vo=0v
</p>
<p>CC3.2(b) For the following driver configuration, which of the following is a valid constraint that 
could be put in place to prevent a violation of the maximum power supply currents 
(ICC-max and IGND-max)?
</p>
<p>A) Modify the driver transistors so that they can&rsquo;t provide more than 5mA on any 
output.
</p>
<p>B) Apply a cooling system (e.g., a heat sink or fan) to the driver chip.
</p>
<p>C) Design the logic so that no more than half of the outputs are HIGH at any given 
time.
</p>
<p>D) Drive multiple receivers with the same output pin.
</p>
<p>CC3.2(c) Why is it desirable to have the output of a digital circuit transition quickly between the
</p>
<p>logic LOW and logic HIGH levels? 
</p>
<p>A) So that the outputs are not able to respond as the input transitions through the
uncertainty region.  This avoids unwanted transitions.
</p>
<p>B) So that all signals look like square waves.
</p>
<p>C) To reduce power by minimizing the time spent switching.
</p>
<p>D) Because the system can only have two states, a LOW and a HIGH.
</p>
<p>CONCEPT CHECK
</p>
<p>3.2 Digital Circuit Operation &bull; 55</p>
<p/>
</div>
<div class="page"><p/>
<p>3.3 Logic Families
</p>
<p>It is apparent from the prior discussion of operating conditions that digital circuits need to have
</p>
<p>comparable input and output specifications in order to successfully communicate with each other. If a
</p>
<p>transmitter outputs a logic HIGH as +3.4v and the receiver needs a logic HIGH to be above +4v to be
</p>
<p>successfully interpreted as a logic HIGH, then these two circuits will not be able to communicate. In order
</p>
<p>to address this interoperability issue, digital circuits are grouped into logic families. A logic family is a
</p>
<p>group of parts that all adhere to a common set of specifications so that they work together. The logic
</p>
<p>family is given a specific name and once the specifications are agreed upon, different manufacturers
</p>
<p>produce parts that work within the particular family. Within a logic family, parts will all have the same
</p>
<p>power supply requirements and DC input/output specifications such that if connected directly, they will be
</p>
<p>able to successfully communicate with each other. The phrase &ldquo;connected directly&rdquo; is emphasized
</p>
<p>because it is very possible to insert an interconnect circuit between two circuits within the same logic
</p>
<p>family and alter the output voltage enough so that the receiver will not be able to interpret the correct logic
</p>
<p>level. Analyzing the effect of the interconnect circuit is part of the digital design process. There are many
</p>
<p>logic families that exist (up to 100 different types!) and more emerge each year as improvements are
</p>
<p>made to circuit fabrication processes that create smaller, faster, and lower power circuits.
</p>
<p>3.3.1 Complementary Metal Oxide Semiconductors
</p>
<p>The first group of logic families we will discuss is called complementary metal oxide
</p>
<p>semiconductors, or CMOS. This is currently the most popular group of logic families for digital circuits
</p>
<p>implemented on the same integrated circuit (IC). An integrated circuit is where the entire circuit is
</p>
<p>implemented on a single piece of semiconductor material (or chip). The IC can contain transistors,
</p>
<p>resistors, capacitors, inductors, wires, and insulators. Modern integrated circuits can contain billions of
</p>
<p>devices and meters of interconnect. The opposite of implementing the circuit on an integrated circuit is to
</p>
<p>use discrete components. Using discrete components refers to where every device (transistor, resistor,
</p>
<p>etc.) is its own part and is wired together externally using either a printed circuit board (PCB) or jumper
</p>
<p>wires as on a breadboard. The line between ICs and discrete parts has blurred in the past decades
</p>
<p>because modern discrete parts are actually fabricated as an IC and regularly contain multiple devices
</p>
<p>(e.g., four logic gates per chip). Regardless, the term discrete is still used to describe components that
</p>
<p>only contain a few components where the term IC typically refers to a much larger system that is custom
</p>
<p>designed.
</p>
<p>The term CMOS comes from the use of particular types of transistors to implement the digital
</p>
<p>circuits. The transistors are created using a metal oxide semiconductor (MOS) structure. These
</p>
<p>transistors are turned on or off based on an electric field, so they are given the name metal oxide
</p>
<p>semiconductor field effect transistors, or MOSFETs. There are two transistors that can be built using this
</p>
<p>approach that operate complementary to each other, thus the term complementary metal oxide
</p>
<p>semiconductors. To understand the basic operation of CMOS logic, we begin by treating the MOSFETs
</p>
<p>as ideal switches. This allows us to understand the basic functionality without diving into the detailed
</p>
<p>electronic analysis of the transistors.
</p>
<p>3.3.1.1 CMOS Operation
</p>
<p>In CMOS, there is a single power supply (VCC or VDD) and a single ground (GND). The ground signal
</p>
<p>is sometimes called VSS. The maximum input and output DC specifications are equal to the power
</p>
<p>supply (VCC &frac14; VOH-max &frac14; VIH-max). The minimum input and output DC specification are equal to ground
</p>
<p>(GND &frac14; 0v &frac14; VOL-min &frac14; VIL-min). In this way, using CMOS simplifies many of the specifications.
</p>
<p>If you state that you are using &ldquo;CMOS with a +3.4v power supply,&rdquo; you are inherently stating that
</p>
<p>VCC &frac14; VOH-max &frac14; VIH-max &frac14; +3.4v and that VOL-min &frac14; VIL-min &frac14; 0v. Many times the name of the logic
</p>
<p>56 &bull; Chapter 3: Digital Circuitry and Interfacing</p>
<p/>
</div>
<div class="page"><p/>
<p>family will be associated with the power supply voltage. For example, a logic family may go by the
</p>
<p>name &ldquo;+3.3v CMOS&rdquo; or &ldquo;+2.5v CMOS.&rdquo; These names give a first-level description of the logic family
</p>
<p>operation, but more details about the operation must be looked up in the data sheet.
</p>
<p>There are two types of transistors used in CMOS. The transistors will be closed or open based on an
</p>
<p>input logic level. The first transistor is called an N-type MOSFET, or NMOS. This transistor will turn on, or
</p>
<p>close, when the voltage between the gate and source (VGS) is greater than its threshold voltage. The
</p>
<p>threshold voltage (VT) is the amount of voltage needed to create a conduction path between the drain
</p>
<p>and the source terminals. The threshold voltage of an NMOS transistor is typically between 0.2v and 1v
</p>
<p>and much less than the VCC voltage in the system. The second transistor is called a P-type MOSFET, or
</p>
<p>PMOS. This transistor turns on, or closes, when the voltage between the gate and the source (VGS) is
</p>
<p>less than VT, where the VT for a PMOS is a negative value. This means that to turn on a PMOS transistor,
</p>
<p>the gate terminal needs to be at a lower voltage than the source. The type of transistor (i.e., P-type or
</p>
<p>N-type) has to do with the type of semiconductor material used to conduct current through the transistor.
</p>
<p>An NMOS transistor uses negative charge to conduct current (i.e., Negative-Type) while a PMOS uses
</p>
<p>positive charge (i.e., Positive-Type). Figure 3.21 shows the symbols for the PMOS and NMOS, the
</p>
<p>fabrication cross sections, and their switch-level equivalents.
</p>
<p>Fig. 3.21
CMOS transistors
</p>
<p>3.3 Logic Families &bull; 57</p>
<p/>
</div>
<div class="page"><p/>
<p>The basic operation of CMOS is that when driving a logic HIGH the switches are used to connect the
</p>
<p>output to the power supply (VCC), and when driving a logic LOW the switches are used to connect the
</p>
<p>output to GND. In CMOS, VCC is considered an ideal logic HIGH and GND is considered an ideal logic
</p>
<p>LOW. VCC is typically much larger than VT, so using these levels can easily turn on and off the transistors.
</p>
<p>The design of the circuit must never connect the output to VCC and GND at the same time or else the
</p>
<p>device itself will be damaged due to the current flowing directly from VCC to GND through the transistors.
</p>
<p>Due to the device physics of the MOSFETS, PMOS transistors are used to form the network that will
</p>
<p>connect the output to VCC (a.k.a., the pull-up network), and NMOS transistors are used to form the
</p>
<p>network that will connect the output to GND (a.k.a., the pull-down network). Since PMOS transistors are
</p>
<p>closed when the input is a 0 (thus providing a logic HIGH on the output) and NMOS transistors are closed
</p>
<p>when the input is a 1 (thus providing a logic LOW on the output), CMOS implements negative logic gates.
</p>
<p>This means that CMOS can implement inverters, NAND, and NOR gates but not buffers, AND, and OR
</p>
<p>gates directly. In order to create a CMOS AND gate, the circuit would implement a NAND gate followed
</p>
<p>by an inverter and similarly for an OR gate and buffer.
</p>
<p>3.3.1.2 CMOS Inverter
</p>
<p>Let&rsquo;s now look at how we can use these transistors to create a CMOS inverter. Consider the
</p>
<p>transistor arrangement shown in Fig. 3.22.
</p>
<p>The inputs of both the PMOS and NMOS are connected together. The PMOS is used to connect the
</p>
<p>output to VCC and the NMOS is used to connect the output to GND. Since the inputs are connected
</p>
<p>together and the switches operate in a complementary manner, this circuit ensures that both transistors
</p>
<p>will never be on at the same time. When In &frac14; 0, the PMOS switch is closed and the NMOS switch is
</p>
<p>open. This connects the output directly to VCC, thus providing a logic HIGH on the output. When In &frac14; 1,
</p>
<p>the PMOS switch is open and the NMOS switch is closed. This connects the output directly to GND, thus
</p>
<p>providing a logic LOW. This configuration yields an inverter. This operation is shown graphically in
</p>
<p>Fig. 3.23.
</p>
<p>Fig. 3.22
CMOS inverter schematic
</p>
<p>58 &bull; Chapter 3: Digital Circuitry and Interfacing</p>
<p/>
</div>
<div class="page"><p/>
<p>3.3.1.3 CMOS NAND Gate
</p>
<p>Let&rsquo;s now look at how we use a similar arrangement of transistors to implement a 2-input NAND
</p>
<p>gate. Consider the transistor configuration shown in Fig. 3.24.
</p>
<p>Fig. 3.23
CMOS inverter operation
</p>
<p>Fig. 3.24
CMOS 2-input NAND gate schematic
</p>
<p>3.3 Logic Families &bull; 59</p>
<p/>
</div>
<div class="page"><p/>
<p>The pull-down network consists of two NMOS transistors in series (M1 and M2) and the pull-up
</p>
<p>network consists of two PMOS transistors in parallel (M3 and M4). Let&rsquo;s go through each of the input
</p>
<p>conditions and examine which transistors are on and which are off and how they impact the output. The
</p>
<p>first input condition is when A &frac14; 0 and B &frac14; 0. This condition turns on both M3 and M4 creating two
</p>
<p>parallel paths between the output and VCC. At the same time, it turns off both M1 and M2 preventing a
</p>
<p>path between the output and GND. This input condition results in an output that is connected to VCC
resulting in a logic HIGH. The second input condition is when A &frac14; 0 and B &frac14; 1. This condition turns on
</p>
<p>M3 in the pull-up network and M2 in the pull-down network. This condition also turns offM4 in the pull-up
</p>
<p>network and M1 in the pull-down network. Since the pull-up network is a parallel combination of PMOS
</p>
<p>transistors, there is still a path between the output and VCC through M3. Since the pull-down network is a
</p>
<p>series combination of NMOS transistors, both M1 and M2 must be on in order to connect the output to
</p>
<p>GND. This input condition results in an output that is connected to VCC resulting in a logic HIGH. The third
</p>
<p>input condition is when A &frac14; 1 and B &frac14; 0. This condition again provides a path between the output and
</p>
<p>VCC through M4 and prevents a path between the output and ground by having M2 open. This input
</p>
<p>condition results in an output that is connected to VCC resulting in a logic HIGH. The final input condition
</p>
<p>is when A &frac14; 1 and B &frac14; 1. In this input condition, both of the PMOS transistors in the pull-up network
</p>
<p>(M3 and M4) are off preventing the output from being connected to VCC. At the same time, this input turns
</p>
<p>on both M1 and M2 in the pull-down network connecting the output to GND. This input condition results in
</p>
<p>an output that is connected to GND resulting in a logic LOW. Based on the resulting output values
</p>
<p>corresponding to the four input codes, this circuit yields the logic operation of a 2-input NAND gate. This
</p>
<p>operation is shown graphically in Fig. 3.25.
</p>
<p>60 &bull; Chapter 3: Digital Circuitry and Interfacing</p>
<p/>
</div>
<div class="page"><p/>
<p>Creating a CMOS NAND gate with more than two inputs is accomplished by adding additional
</p>
<p>PMOS transistors to the pull-up network in parallel and additional NMOS transistors to the pull-down
</p>
<p>network in series. Figure 3.26 shows the schematic for a 3-input NAND gate. This procedure is followed
</p>
<p>for creating NAND gates with larger numbers of inputs.
</p>
<p>Fig. 3.25
CMOS 2-input NAND gate operation
</p>
<p>3.3 Logic Families &bull; 61</p>
<p/>
</div>
<div class="page"><p/>
<p>If the CMOS transistors were ideal switches, the approach of increasing the number of inputs could
</p>
<p>be continued indefinitely. In reality, the transistors are not ideal switches and there is a limit on how many
</p>
<p>transistors can be added in series and continue to operate. The limitation has to do with ensuring that
</p>
<p>each transistor has enough voltage to properly turn on or off. This is a factor in the series network
</p>
<p>because the drain terminals of the NMOS transistors are not all connected to GND. If a voltage develops
</p>
<p>across one of the lower transistors (e.g., M3), then it takes more voltage on the input to turn on the next
</p>
<p>transistor up (e.g., M2). If too many transistors are added in series, then the uppermost transistor in the
</p>
<p>series may not be able to be turned on or off by the input signals. The number of inputs that a logic gate
</p>
<p>can have within a particular logic family is called its fan-in specification. When a logic circuit requires a
</p>
<p>number of inputs that exceeds the fan-in specification for a particular logic family, then additional logic
</p>
<p>gates must be used. For example, if a circuit requires a 5-input NAND gate but the logic family has a
</p>
<p>fan-in specification of 4, this means that the largest NAND gate available only has 4-inputs. The 5-input
</p>
<p>NAND operation must be accomplished using additional circuit design techniques that use gates with
</p>
<p>4 or less inputs. These design techniques will be covered in Chap. 4.
</p>
<p>3.3.1.4 CMOS NOR Gate
</p>
<p>A CMOS NOR gate is created using a similar topology as a NAND gate with the exception that the
</p>
<p>pull-up network consists of PMOS transistors in series and the pull-down network that consists of NMOS
</p>
<p>transistors in parallel. Consider the transistor configuration shown in Fig. 3.27.
</p>
<p>Fig. 3.26
CMOS 3-input NAND gate schematic
</p>
<p>62 &bull; Chapter 3: Digital Circuitry and Interfacing</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_4">http://dx.doi.org/10.1007/978-3-319-34195-8_4</a></div>
</div>
<div class="page"><p/>
<p>The series configuration of the pull-up network will only connect the output to VCC when both inputs
</p>
<p>are 0. Conversely, the pull-down network prevents connecting the output to GND when both inputs are
</p>
<p>0. When either or both of the inputs are true, the pull-up network is off and the pull-down network is
</p>
<p>on. This yields the logic function for a NOR gate. This operation is shown graphically in Fig. 3.28. As with
</p>
<p>the NAND gate, the number of inputs can be increased by adding more PMOS transistors in series in the
</p>
<p>pull-up network and more NMOS transistors in parallel in the pull-down network.
</p>
<p>Fig. 3.27
CMOS 2-input NOR gate schematic
</p>
<p>3.3 Logic Families &bull; 63</p>
<p/>
</div>
<div class="page"><p/>
<p>The schematic for a 3-input NOR gate is given in Fig. 3.29. This approach can be used to increase
</p>
<p>the number of inputs up until the fan-in specification of the logic family is reached.
</p>
<p>Fig. 3.28
CMOS 2-input NOR gate operation
</p>
<p>64 &bull; Chapter 3: Digital Circuitry and Interfacing</p>
<p/>
</div>
<div class="page"><p/>
<p>3.3.2 Transistor-Transistor Logic
</p>
<p>One of the first logic families that emerged after the invention of the integrated circuit was transistor-
</p>
<p>transistor logic (TTL). This logic family uses bipolar junction transistor (BJT) as its fundamental switching
</p>
<p>item. This logic family defined a set of discrete parts that contained all of the basic gates in addition to
</p>
<p>more complex building blocks. TTL was used to build the first computer systems in the 1960s. TTL is not
</p>
<p>widely used today other than for specific applications because it consumes more power than CMOS and
</p>
<p>cannot achieve the density required for today&rsquo;s computer systems. TTL is discussed because it was the
</p>
<p>original logic family based on integrated circuits, so it provides a historical perspective of digital logic.
</p>
<p>Furthermore, the discrete logic pin-outs and part-numbering schemes are still used today for discrete
</p>
<p>CMOS parts.
</p>
<p>3.3.2.1 TTL Operation
</p>
<p>TTL logic uses BJT transistors and resistors to accomplish the logic operations. The operation of a
</p>
<p>BJT transistor is more complicated than an MOSFET; however, it performs essentially the same switch
</p>
<p>operation when used in a digital logic circuit. An input is used to turn the transistor on, which in turn allows
</p>
<p>current to flow between two other terminals. Figure 3.30 shows the symbol for the two types of BJT
</p>
<p>transistors. The PNP transistor is analogous to a PMOS and the NPN is analogous to an NMOS. Current
</p>
<p>will flow between the Emitter and Collector terminals when there is a sufficient voltage on the Base
</p>
<p>terminal. The amount of current that flows between the Emitter and Collector is related to the current
</p>
<p>flowing into the Base. The primary difference in operation between BJTs and MOSFETs is that BJTs
</p>
<p>require proper voltage biasing in order to turn on and also draws current through the BASE in order to
</p>
<p>stay on. The detailed operation of BJTs is beyond the scope of this text, so an overly simplified model of
</p>
<p>TTL logic gates is given.
</p>
<p>Fig. 3.29
CMOS 3-input NOR gate schematic
</p>
<p>3.3 Logic Families &bull; 65</p>
<p/>
</div>
<div class="page"><p/>
<p>Figure 3.31 shows a simplified model of how TTL logic operates using BJTs and resistors. This
</p>
<p>simplified model does not show all of the transistors that are used in modern TTL circuits but instead is
</p>
<p>intended to provide a high-level overview of the operation. This gate is an inverter that is created with an
</p>
<p>NPN transistor and a resistor. When the input is a logic HIGH, the NPN transistor turns on and conducts
</p>
<p>current between its collector and emitter terminals. This in effect closes the switch and connects the
</p>
<p>output to GND providing a logic LOW. During this state, current will also flow through the resistor to GND
</p>
<p>through Q1, thus consuming more power than the equivalent gate in CMOS. When the input is a logic
</p>
<p>LOW, the NPN transistor turns off and no current flows between its collector and emitter. This, in effect, is
</p>
<p>an open circuit leaving only the resistor connected to the output. The resistor pulls the output up to VCC
providing a logic HIGH on the output. One drawback of this state is that there will be a voltage drop
</p>
<p>across the resistor, so the output is not pulled fully to VCC.
</p>
<p>Fig. 3.30
PNP and NPN transistors
</p>
<p>66 &bull; Chapter 3: Digital Circuitry and Interfacing</p>
<p/>
</div>
<div class="page"><p/>
<p>3.3.3 The 7400 Series Logic Families
</p>
<p>The 7400 series of TTL circuits became popular in the 1960s and 1970s. This family was based on
</p>
<p>TTL and contained hundreds of different digital circuits. The original circuits came in either plastic or
</p>
<p>ceramic Dual-In-Line packages (DIP). The 7400 TTL logic family was powered off of a +5v supply. As
</p>
<p>mentioned before, this logic family set the pin-outs and part-numbering schemes for modern logic
</p>
<p>families. There were many derivatives of the original TTL logic family that made modifications to improve
</p>
<p>speed and reliability, decrease power, and reduce power supplies. Today&rsquo;s CMOS logic families within
</p>
<p>the 7400 series still use the same pin-outs and numbering schemes as the original TTL family. It is useful
</p>
<p>to understand the history of this series because these parts are often used in introductory laboratory
</p>
<p>exercises to learn how to interface digital logic circuits.
</p>
<p>Fig. 3.31
TTL inverter
</p>
<p>3.3 Logic Families &bull; 67</p>
<p/>
</div>
<div class="page"><p/>
<p>3.3.3.1 Part-Numbering Scheme
</p>
<p>The part numbering scheme for the 7400 series and its derivatives contains five different fields:
</p>
<p>(1) manufacturer, (2) temperature range, (3) logic family, (4) logic function, and (5) package type. The
</p>
<p>breakdown of these fields is shown in Fig. 3.32.
</p>
<p>Fig. 3.32
7400 series part-numbering scheme
</p>
<p>68 &bull; Chapter 3: Digital Circuitry and Interfacing</p>
<p/>
</div>
<div class="page"><p/>
<p>3.3.3.2 DC Operating Conditions
</p>
<p>Table 3.2 gives the DC operating conditions for a few of the logic families within the 7400 series.
</p>
<p>Notice that the CMOS families consume much less power than the TTL families. Also notice that the TTL
</p>
<p>output currents are asymmetrical. The differences between the IOH and IOL within the TTL families have
</p>
<p>to do with the nature of the bipolar transistors and the resistors used to create the pull-up networks within
</p>
<p>the devices. CMOS has symmetrical drive currents due to using complementary transistors for the pull-
</p>
<p>up (PMOS) and pull-down networks (NMOS).
</p>
<p>3.3.3.3 Pin-Out Information for the DIP Packages
</p>
<p>Figure 3.33 shows the pin-out assignments for a subset of the basic gates from the 74HC logic
</p>
<p>family in the Dual-In-Line package form factor. Most of the basic gates within the 7400 series follow these
</p>
<p>assignments. Notice that each of these basic gates comes in a 14-pin DIP package, each with a single
</p>
<p>VCC and single GND pin. It is up to the designer to ensure that the maximum current flowing through the
</p>
<p>VCC and GND pins does not exceed the maximum specification. This is particularly important for parts
</p>
<p>that contain numerous gates. For example, the 74HC00 part contains four, 2-input NAND gates. If each
</p>
<p>of the NAND gates was driving a logic HIGH at its maximum allowable output current (i.e., 25 mA from
</p>
<p>Fig. 3.19), then a total of 4∙25 mA + Iq &frac14; ~100 mA would be flowing through its VCC pin. Since the VCC
pin can only tolerate a maximum of 50 mA of current (from Fig. 3.19), the part would be damaged since
</p>
<p>the output current of ~100 mA would also flow through the VCC pin. The pin-outs in Fig. 3.33 are useful
</p>
<p>when first learning to design logic circuits because the DIP packages plug directly into a standard
</p>
<p>breadboard.
</p>
<p>Table 3.2
DC operating conditions for a sample of 7400 series logic families
</p>
<p>3.3 Logic Families &bull; 69</p>
<p/>
</div>
<div class="page"><p/>
<p>Fig. 3.33
Pin-outs for a subset of basic gates from the 74HC logic family in DIP packages
</p>
<p>70 &bull; Chapter 3: Digital Circuitry and Interfacing</p>
<p/>
</div>
<div class="page"><p/>
<p>CC3.3 Why doesn&rsquo;t the following CMOS transistor configuration yield a buffer?
</p>
<p>A) In order to turn on the NMOS transistor, VGS needs to be greater than zero.  In 
the given configuration, the gate terminal of the NMOS (G) needs to be driven 
above the source terminal (S).  If the source terminal was at +3.4v, then the input
(In) would never be able to provide a positive enough voltage to ensure the 
NMOS is on because &ldquo;In&rdquo; doesn&rsquo;t go above +3.4v.
</p>
<p>B) There is no way to turn on both transistors in this configuration.
</p>
<p>C) The power consumption will damage the device because both transistors will 
potentially be on.
</p>
<p>D) The sources of the two devices can&rsquo;t be connected together without causing a
short in the device.
</p>
<p>CONCEPT CHECK
</p>
<p>3.4 Driving Loads
</p>
<p>At this point we&rsquo;ve discussed in depth how proper care must be taken to ensure that not only do the
</p>
<p>output voltages of the driving gate meet the input specifications of the receiver in order to successfully
</p>
<p>transmit 1s and 0s, but that the output current of the driver does not exceed the maximum specifications
</p>
<p>so that the part is not damaged. The output voltage and current for a digital circuit depend greatly on the
</p>
<p>load that is being driven. The following sections discuss the impact of driving some of the most common
</p>
<p>digital loads.
</p>
<p>3.4.1 Driving Other Gates
</p>
<p>Within a logic family, all digital circuits are designed to operate with one another. If there is minimal
</p>
<p>loss or noise in the interconnect system, then 1s and 0s will be successfully transmitted and no current
</p>
<p>specifications will be exceeded. Consider the example in Example 3.3 for an inverter driving another
</p>
<p>inverter from the same logic family.
</p>
<p>3.4 Driving Loads &bull; 71</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 3.3
Determining if Specifications Are Violated When Driving Another Gate as a Load
</p>
<p>From this example, it is clear that there are no issues when a gate is driving another gate from
</p>
<p>the same family. This is as expected because that is the point of a logic family. In fact, gates are
</p>
<p>designed to drive multiple gates from within their own family. Based solely on the DC specifications for
</p>
<p>input and output current, it could be assumed that the number of other gates that can be driven is
</p>
<p>simply IO-max/II-max. For the example in Example 3.3, this would result in a 74HC gate being able to drive
</p>
<p>25,000 other gates (i.e., 25 mA/1 μA &frac14; 25,000). In reality, the maximum number of gates that can be
</p>
<p>driven is dictated by the switching characteristics. This limit is called the fan-out specification. The
</p>
<p>fan-out specification states the maximum number of other gates from within the same family that can be
</p>
<p>driven. As discussed earlier, the output signal needs to transition quickly through the uncertainty region
</p>
<p>so that the receiver does not have time to react and go to an unknown state. As more and more gates are
</p>
<p>driven, this transition time is slowed down. The fan-out specification provides a limit to the maximum
</p>
<p>number of gates from the same family that can be driven while still ensuring that the output signal
</p>
<p>transitions between states fast enough to avoid the receivers from going to an unknown state. Example
</p>
<p>3.4 shows the process of determining the maximum output current that a driver will need to provide when
</p>
<p>driving the maximum number of gates allowed by the fan-out specification.
</p>
<p>72 &bull; Chapter 3: Digital Circuitry and Interfacing</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 3.4
Determining the Output Current When Driving Multiple Gates as the Load
</p>
<p>3.4.2 Driving Resistive Loads
</p>
<p>There are many situations where a resistor is the load in a digital circuit. A resistive load can be an
</p>
<p>actual resistor that is present for some other purpose such as a pull-up, pull-down, or for impedance
</p>
<p>matching. More complex loads such as buzzers, relays, or other electronics can also be modeled as a
</p>
<p>resistor. When a resistor is the load in a digital circuit, care must be taken to avoid violating the output
</p>
<p>current specifications of the driver. The electrical circuit analysis technique that is used to evaluate how a
</p>
<p>resistive load impacts a digital circuit is Ohm&rsquo;s law. Ohm&rsquo;s law is a very simple relationship between the
</p>
<p>current and voltage in a resistor. Figure 3.34 gives a primer on Ohm&rsquo;s law. For use in digital circuits, there
</p>
<p>are only a select few cases that this technique will be applied to, so no prior experience with Ohm&rsquo;s law is
</p>
<p>required at this point.
</p>
<p>Fig. 3.34
A primer on Ohm&rsquo;s law
</p>
<p>3.4 Driving Loads &bull; 73</p>
<p/>
</div>
<div class="page"><p/>
<p>Let&rsquo;s see how we can use Ohm&rsquo;s law to analyze the impact of a resistive load in a digital circuit.
</p>
<p>Consider the circuit configuration in Example 3.5 and how we can use Ohm&rsquo;s law to determine the output
</p>
<p>current of the driver. The load in this case is a resistor connected between the output of the driver and the
</p>
<p>power supply (+5v). When driving a logic HIGH, the output level will be approximately equal to the power
</p>
<p>supply (i.e., +5v). Since in this situation both terminals of the resistor are at +5v, there is no voltage
</p>
<p>difference present. That means when plugging into Ohm&rsquo;s law, the voltage component is 0v, which gives
</p>
<p>0 amps of current. In the case where the driver is outputting a logic LOW, the output will be approximately
</p>
<p>GND. In this case, there is a voltage drop of +5v across the resistor (5v&ndash;0v). Plugging this into Ohm&rsquo;s law
</p>
<p>yields a current of 50 mA flowing through the resistor. This can become problematic because the current
</p>
<p>flows through the resistor and then into the output of the driver. For the 74HC logic family, this would
</p>
<p>exceed the IO max specification of 25 mA and damage the part. Additionally, as more current is drawn
</p>
<p>through the output, the output voltage becomes less and less ideal. In this example, the first order
</p>
<p>analysis uses VO &frac14; GND. In reality, as the output current increases, the output voltage will move further
</p>
<p>away from its ideal value and may eventually reach a value within the uncertainty region.
</p>
<p>Example 3.5
Determining the Output Current When Driving a Pull-Up Resistor as the Load
</p>
<p>74 &bull; Chapter 3: Digital Circuitry and Interfacing</p>
<p/>
</div>
<div class="page"><p/>
<p>A similar process can be used to determine the output current when driving a resistive load between
</p>
<p>the output and GND. This process is shown in Example 3.6.
</p>
<p>Example 3.6
Determining the Output Current When Driving a Pull-Down Resistor as the Load
</p>
<p>3.4.3 Driving LEDs
</p>
<p>A light-emitting diode (LED) is a very common type of load that is driven using a digital circuit. The
</p>
<p>behavior of diodes is typically covered in an analog electronics class. Since it is assumed that the reader
</p>
<p>has not been exposed to the operation of diodes, the behavior of the LED will be described using a highly
</p>
<p>simplified model. A diode has two terminals, the anode and cathode. Current that flows from the anode to
</p>
<p>the cathode is called the forward current. A voltage that is developed across a diode from its anode to
</p>
<p>cathode is called the forward voltage. A diode has a unique characteristic that when a forward voltage is
</p>
<p>supplied across its terminal, it will only increase up to a certain point. The amount is specified as the LED&rsquo;s
</p>
<p>forward voltage (vf) and is typically between 1.5v and 2v in modern LEDs. When a power supply circuit is
</p>
<p>connected to the LED, no current will flow until this forward voltage has been reached. Once it has been
</p>
<p>reached, current will begin to flow and the LED will prevent any further voltage from developing across
</p>
<p>it. Once current flows, the LED will begin emitting light. The more current that flows, the more light that will
</p>
<p>be emitted up until the point that the maximum allowable current through the LED is reached and then the
</p>
<p>device will be damaged. When using an LED, there are two specifications of interest: the forward voltage
</p>
<p>and the recommended forward current. The symbols for a diode and an LED are given in Fig. 3.35.
</p>
<p>3.4 Driving Loads &bull; 75</p>
<p/>
</div>
<div class="page"><p/>
<p>When designing an LED driver circuit, a voltage must be supplied in order to develop the forward
</p>
<p>voltage across the LED so that current will flow. A resistor is included in series with the LED for two
</p>
<p>reasons. The first reason is to provide a place for any additional voltage provided by the driver to develop
</p>
<p>in the situation that Vo &gt; Vf, which is most often the case. The second reason for the resistor is to set the
</p>
<p>output current. Since the voltage across the resistor will be a fixed amount (i.e., Vo � Vf), then the value
</p>
<p>of the resistor can be chosen to set the current. This current is typically set to an optimum value that turns
</p>
<p>on the LED to a desired luminosity while also ensuring that the maximum output current of the driver is
</p>
<p>not violated. Consider the LED driver configuration shown in Example 3.7 where the LED will be turned
</p>
<p>on when the driver outputs a HIGH.
</p>
<p>Example 3.7
Determining the Output Current When Driving an LED where HIGH &frac14; ON
</p>
<p>Fig. 3.35
Symbols for a diode and a light-emitting diode
</p>
<p>76 &bull; Chapter 3: Digital Circuitry and Interfacing</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 3.8 shows another example of driving an LED, but this time using a different configuration
</p>
<p>where the LED will be on when the driver outputs a logic LOW.
</p>
<p>Example 3.8
Determining the Output Current When Driving an LED where HIGH &frac14; OFF
</p>
<p>CC3.4 A fan-out specification is typically around 6-12.  If a logic family has a maximum output 
</p>
<p>current specification of IO-max=25mA and a maximum input current specification of only II-
max=1uA, a driver could conceivably source up to 25,000 gates (IO-max/II-max = 25mA/1uA = 
25,000) without violating its maximum output current specification.  Why isn&rsquo;t the fan-out 
specification then closer to 25,000?
</p>
<p>A) The fan-out specification has significant margin built into it in order to protect the 
driver.
</p>
<p>B) Connecting 25,000 loads to the driver would cause significant wiring congestion 
and would be impractical. 
</p>
<p>C) The fan-out specification is in place to reduce power, so keeping it small is 
desirable.
</p>
<p>D) The fan-out specification is in place for AC behavior.  It ensures that the AC 
loading on the driver doesn&rsquo;t slow down its output rise and fall times.  If too many 
loads are connected, the output transition will be too slow and it will reside in the 
uncertainty region for too long leading to unwanted switching on the receivers.
</p>
<p>CONCEPT CHECK
</p>
<p>CC3.4 A fan-out specification is typically around 6-12.  If a logic family has a maximum output 
</p>
<p>current specification of IO-max=25mA and a maximum input current specification of only II-
max=1uA, a driver could conceivably source up to 25,000 gates (IO-max/II-max = 25mA/1uA = 
25,000) without violating its maximum output current specification.  Why isn&rsquo;t the fan-out 
specification then closer to 25,000?
</p>
<p>A) The fan-out specification has significant margin built into it in order to protect the 
driver.
</p>
<p>B) Connecting 25,000 loads to the driver would cause significant wiring congestion 
and would be impractical. 
</p>
<p>C) The fan-out specification is in place to reduce power, so keeping it small is 
desirable.
</p>
<p>D) The fan-out specification is in place for AC behavior.  It ensures that the AC 
loading on the driver doesn&rsquo;t slow down its output rise and fall times.  If too many 
loads are connected, the output transition will be too slow and it will reside in the 
uncertainty region for too long leading to unwanted switching on the receivers.
</p>
<p>CONCEPT CHECK
</p>
<p>3.4 Driving Loads &bull; 77</p>
<p/>
</div>
<div class="page"><p/>
<p>Summary
</p>
<p>v The operation of a logic circuit can be
described using either a logic symbol, a
truth table, a logic expression, or a logic
waveform.
</p>
<p>v Logic gates represent the most basic
operations that can be performed on binary
numbers. They are BUF, INV, AND, NAND,
OR, NOR, XOR, and XNOR.
</p>
<p>v XOR gates that have a number of inputs
greater than two are created using a cascade
of 2-input XOR gates. This implementation
has more practical applications such as arith-
metic and error detection codes.
</p>
<p>v The logic level describes whether the electri-
cal signal representing one of the two states
is above or below a switching threshold
region. The two possible values that a logic
level can be are HIGH or LOW.
</p>
<p>v The logic value describes how the logic
levels are mapped into the two binary codes
0 and 1. In positive logic a HIGH &frac14; 1 and a
LOW &frac14; 0. In negative logic a HIGH &frac14; 0 and
a LOW &frac14; 1.
</p>
<p>v Logic circuits have DC specifications that
describe how input voltage levels
are interpreted as either HIGHs or LOWs
(VIH-max, VIH-min, VIL-max, and VIL-min).
Specifications are also given on what output
voltages will be produced when driving a
HIGH or LOW (VOH-max, VOH-min, VOL-max,
and VOL-min).
</p>
<p>v In order to successfully transmit digital infor-
mation, the output voltages of the driver that
represent a HIGH and LOW must arrive at
the receiver within the voltage ranges that
are interpreted as a HIGH and LOW. If the
voltage arrives at the receiver outside of
these specified input ranges, the receiver
will not know whether a HIGH or LOW is
being transmitted.
</p>
<p>v Logic circuits also specify maximum current
levels on the power supplies (IVCC, Ignd),
inputs (II-max), and outputs (IO-max) that may
</p>
<p>not be exceeded. If these levels are
exceeded, the circuit may not operate prop-
erly or be damaged.
</p>
<p>v The current exiting a logic circuit is equal to
the current entering.
</p>
<p>v When a logic circuit sources current to a load,
an equivalent current is drawn into the circuit
through its power supply pin.
</p>
<p>v When a logic circuit sinks current from a load,
an equivalent current flows out of the circuit
through its ground pin.
</p>
<p>v The type of load that is connected to the
output of a logic circuit dictates how much
current will be drawn from the driver.
</p>
<p>v The quiescent current (Iq or Icc) is the current
that the circuit always draws independent of
the input/output currents.
</p>
<p>v Logic circuits have AC specifications that
describe the delay from the input to the out-
put (tPLH, tPHL) and also how fast the outputs
transition between the HIGH and LOW levels
(tr, tf).
</p>
<p>v A logic family is a set of logic circuits that are
designed to operate with each other.
</p>
<p>v The fan-in of a logic family describes the
maximum number of inputs that a gate
may have.
</p>
<p>v The fan-out of a logic family describes the
maximum number of other gates from within
the same family that can be driven simulta-
neously by one gate.
</p>
<p>v CMOS logic is the most popular family series
in use today. CMOS logic uses two
transistors (NMOS and PMOS) that act as
complementary switches. CMOS transistors
draw very low quiescent current and can be
fabricated with extremely small feature sizes.
</p>
<p>v In CMOS, only inverters, NAND gates, and
NOR gates can be created directly. If it is
desired to create a buffer, AND gate, or OR
gate, an inverter is placed on the output of
the original inverter, NAND, or NOR gate.
</p>
<p>Exercise Problems
</p>
<p>Section 3.1: Basic Gates
</p>
<p>3.1.1 Give the truth table for a 3-input AND gate with
the input variables A, B, and C and output F.
</p>
<p>3.1.2 Give the truth table for a 3-input OR gate with
the input variables A, B, and C and output F.
</p>
<p>3.1.3 Give the truth table for a 3-input XNOR gate
with the input variables A, B, and C and
output F.
</p>
<p>3.1.4 Give the logic expression for a 3-input AND
gate with the input variables A, B, and C and
output F.
</p>
<p>78 &bull; Chapter 3: Digital Circuitry and Interfacing</p>
<p/>
</div>
<div class="page"><p/>
<p>3.1.5 Give the logic expression for a 3-input OR gate
with the input variables A, B, and C and
output F.
</p>
<p>3.1.6 Give the logic expression for a 3-input XNOR
gate with the input variables A, B, and C and
output F.
</p>
<p>3.1.7 Give the logic waveform for a 3-input AND gate
with the input variables A, B, and C and
output F.
</p>
<p>3.1.8 Give the logic waveform for a 3-input OR gate
with the input variables A, B, and C and
output F.
</p>
<p>3.1.9 Give the logic waveform for a 3-input XNOR
gate with the input variables A, B, and C and
output F.
</p>
<p>Section 3.2: Digital Circuit Operation
</p>
<p>3.2.1 Using the DC operating conditions from
Table 3.2, give the noise margin HIGH (NMH)
for the 74LS logic family.
</p>
<p>3.2.2 Using the DC operating conditions from
Table 3.2, give the noise margin LOW (NML)
for the 74LS logic family.
</p>
<p>3.2.3 Using the DC operating conditions from
Table 3.2, give the noise margin HIGH (NMH)
for the 74HC logic family with VCC &frac14; +5v.
</p>
<p>3.2.4 Using the DC operating conditions from
Table 3.2, give the noise margin LOW (NML)
for the 74HC logic family with VCC &frac14; +5v.
</p>
<p>3.2.5 Using the DC operating conditions from
Table 3.2, give the noise margin HIGH (NMH)
for the 74HC logic family with VCC &frac14; +3.4v.
</p>
<p>3.2.6 Using the DC operating conditions from
Table 3.2, give the noise margin LOW (NML)
for the 74HC logic family with VCC &frac14; +3.4v.
</p>
<p>3.2.7 For the driver configuration in Fig. 3.36, give
the current flowing through the VCC pin.
</p>
<p>3.2.8 For the driver configuration in Fig. 3.36, give
the current flowing through the GND pin.
</p>
<p>3.2.9 For the driver configuration in Fig. 3.37, give
the current flowing through the VCC pin.
</p>
<p>3.2.10 For the driver configuration in Fig. 3.37, give
the current flowing through the GND pin.
</p>
<p>3.2.11 Using the data sheet excerpt from Fig. 3.20,
give the maximum propagation delay (tpd) for
the 74HC04 inverter when powered with
VCC &frac14; +2v.
</p>
<p>3.2.12 Using the data sheet excerpt from Fig. 3.20,
give the maximum propagation delay from low
to high (tPLH) for the 74HC04 inverter when
powered with VCC &frac14; +2v.
</p>
<p>3.2.13 Using the data sheet excerpt from Fig. 3.20,
give the maximum propagation delay from high
to low (tPHL) for the 74HC04 inverter when
powered with VCC &frac14; +2v.
</p>
<p>3.2.14 Using the data sheet excerpt from Fig. 3.20,
give the maximum transition time (tt) for the
74HC04 inverter when powered with
VCC &frac14; +2v.
</p>
<p>3.2.15 Using the data sheet excerpt from Fig. 3.20,
give the maximum rise time (tr) for the 74HC04
inverter when powered with VCC &frac14; +2v.
</p>
<p>3.2.16 Using the data sheet excerpt from Fig. 3.20,
give the maximum fall time (tf) for the 74HC04
inverter when powered with VCC &frac14; +2v.
</p>
<p>Section 3.3: Logic Families
</p>
<p>3.3.1 Provide the transistor-level schematic for a
4-input NAND gate.
</p>
<p>3.3.2 Provide the transistor-level schematic for a
4-input NOR gate.
</p>
<p>3.3.3 Provide the transistor-level schematic for a
2-input AND gate.
</p>
<p>3.3.4 Provide the transistor-level schematic for a
2-input OR gate.
</p>
<p>3.3.5 Provide the transistor-level schematic for a
buffer.
</p>
<p>Fig. 3.37
Driver Configuration 2
</p>
<p>Fig. 3.36
Driver Configuration 1
</p>
<p>Exercise Problems &bull; 79</p>
<p/>
</div>
<div class="page"><p/>
<p>Section 3.4: Driving Loads
</p>
<p>3.4.1 In the driver configuration shown in Fig. 3.38,
the buffer is driving its maximum fan-out speci-
fication of 6. The maximum input current for
this logic family is II &frac14; 1 nA. What is the maxi-
mum output current (IO) that the driver will need
to source?
</p>
<p>3.4.2 For the pull-down driver configuration shown in
Fig. 3.39, calculate the value of the pull-down
resistor (R) in order to ensure that the output
current does not exceed 20 mA.
</p>
<p>3.4.3 For the pull-up driver configuration shown in
Fig. 3.40, calculate the value of the pull-up
resistor (R) in order to ensure that the output
current does not exceed 20 mA.
</p>
<p>3.4.4 For the LED driver configuration shown in
Fig. 3.41 where an output of HIGH on the driver
will turn on the LED, calculate the value of the
resistor (R) in order to set the LED forward
current to 5 mA. The LED has a forward volt-
age of 1.9v.
</p>
<p>3.4.5 For the LED driver configuration shown in
Fig. 3.42 where an output of LOW on the driver
will turn on the LED, calculate the value of the
resistor (R) in order to set the LED forward
current to 5 mA. The LED has a forward volt-
age of 1.9v.
</p>
<p>Fig. 3.38
Driver Configuration 3
</p>
<p>Fig. 3.39
Driver Configuration 4
</p>
<p>Fig. 3.40
Driver Configuration 5
</p>
<p>Fig. 3.42
Driver Configuration 7
</p>
<p>Fig. 3.41
Driver Configuration 6
</p>
<p>80 &bull; Chapter 3: Digital Circuitry and Interfacing</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 4: Combinational Logic
</p>
<p>Design
In this chapter we cover the techniques to synthesize, analyze, and manipulate logic functions. The
</p>
<p>purpose of these techniques is to ultimately create a logic circuit using the basic gates described in
</p>
<p>Chap. 3 from a truth table or word description. This process is called combinational logic design.
</p>
<p>Combinational logic refers to circuits where the output depends on the present value of the inputs.
</p>
<p>This simple definition implies that there is no storage capability in the circuitry and a change on the input
</p>
<p>immediately impacts the output. To begin, we first define the rules of Boolean algebra, which provide the
</p>
<p>framework for the legal operations and manipulations that can be taken on a two-valued number system
</p>
<p>(i.e., a binary system). We then explore a variety of logic design and manipulation techniques. These
</p>
<p>techniques allow us to directly create a logic circuit from a truth table and then to manipulate it to either
</p>
<p>reduce the number of gates necessary in the circuit or to convert the logic circuit into equivalent forms
</p>
<p>using alternate gates. The goal of this chapter is to provide an understanding of the basic principles of
</p>
<p>combinational logic design.
</p>
<p>Learning Outcomes&mdash;After completing this chapter, you will be able to:
</p>
<p>4.1 Describe the fundamental principles and theorems of Boolean algebra and how to use
them to manipulate logic expressions.
</p>
<p>4.2 Analyze a combinational logic circuit to determine its logic expression, truth table, and
timing information.
</p>
<p>4.3 Synthesize a logic circuit in canonical form (sum of products or product of sums) from a
functional description including a truth table, minterm list, or maxterm list.
</p>
<p>4.4 Synthesize a logic circuit in minimized form (sum of products or product of sums) through
algebraic manipulation or with a Karnaugh map.
</p>
<p>4.5 Describe the causes of timing hazards in digital logic circuits and the approaches to
mitigate them.
</p>
<p>4.1 Boolean Algebra
</p>
<p>The term algebra refers to the rules of a number system. In Chap. 2 we discussed the number of
</p>
<p>symbols and relative values of some of the common number systems. Algebra defines the operations
</p>
<p>that are legal to perform on that system. Once we have defined the rules for a system, we can then use
</p>
<p>the system for more powerful mathematics such as solving for unknowns and manipulating into equiva-
</p>
<p>lent forms. The ability to manipulate into equivalent forms allows us to minimize the number of logic
</p>
<p>operations necessary and also put into a form that can be directly synthesized using modern logic
</p>
<p>circuits.
</p>
<p>In 1854, English mathematician George Boole presented an abstract algebraic framework for a
</p>
<p>system that contained only two states, true and false. This framework essentially launched the field of
</p>
<p>computer science even before the existence of the modern integrated circuits that are used to implement
</p>
<p>digital logic today. In 1930, American mathematician Claude Shannon applied Boole&rsquo;s algebraic frame-
</p>
<p>work to his work on switching circuits at Bell Labs, thus launching the field of digital circuit design and
</p>
<p>information theory. Boole&rsquo;s original framework is still used extensively in modern digital circuit design and
</p>
<p>thus bears the name Boolean algebra. Today, the term Boolean algebra is often used to describe not only
</p>
<p>George Boole&rsquo;s original work, but all of those that contributed to the field after him.
</p>
<p># Springer International Publishing Switzerland 2017
</p>
<p>B.J. LaMeres, Introduction to Logic Circuits &amp; Logic Design with VHDL,
</p>
<p>DOI 10.1007/978-3-319-34195-8_4
</p>
<p>81</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_3">http://dx.doi.org/10.1007/978-3-319-34195-8_3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_2">http://dx.doi.org/10.1007/978-3-319-34195-8_2</a></div>
</div>
<div class="page"><p/>
<p>4.1.1 Operations
</p>
<p>In Boolean algebra there are two valid states (true and false) and three core operations. The
</p>
<p>operations are conjunction (^, equivalent to the AND operation), disjunction (_, equivalent to the OR
</p>
<p>operation), and negation (&Oslash;, equivalent to the NOT operation). From these three operations, more
</p>
<p>sophisticated operations can be created including other logic functions (i.e., BUF, NAND, NOR, XOR,
</p>
<p>XNOR) and arithmetic. Engineers primarily use the terms AND, OR, and NOT instead of conjunction,
</p>
<p>disjunction, and negation. Similarly, engineers primarily use the symbols for these operators described in
</p>
<p>Chap. 3 (e.g., �, +, and 0) instead of ^, _, and &Oslash;.
</p>
<p>4.1.2 Axioms
</p>
<p>An axiom is a statement of truth about a system that is accepted by the user. Axioms are very simple
</p>
<p>statements about a system, but need to be established before more complicated theorems can be
</p>
<p>proposed. Axioms are so basic that they do not need to be proved in order to be accepted. Axioms can
</p>
<p>be thought of as the basic laws of the algebraic framework. The terms axiom and postulate are
</p>
<p>synonymous and used interchangeably. In Boolean algebra there are five main axioms. These axioms
</p>
<p>will appear redundant with the description of basic gates from Chap. 3, but must be defined in this
</p>
<p>algebraic context so that more powerful theorems can be proposed.
</p>
<p>4.1.2.1 Axiom #1: Logical Values
</p>
<p>This axiom states that in Boolean algebra, a variable A can only take on one of the two values, 0 or
</p>
<p>1. If the variable A is not 0, then it must be a 1, and conversely, if it is not a 1, then it must be a 0.
</p>
<p>Axiom #1&mdash;Boolean Values: A &frac14; 0 if A 6&frac14; 1, conversely A &frac14; 1 if A 6&frac14; 0.
</p>
<p>4.1.2.2 Axiom #2: Definition of Logical Negation
</p>
<p>This axiom defines logical negation. Negation is also called the NOT operation or taking the
</p>
<p>complement. The negation operation is denoted using either a prime (0), an inversion bar, or the negation
</p>
<p>symbol (&Oslash;). If the complement is taken on a 0, it becomes a 1. If the complement is taken on a 1, it
</p>
<p>becomes a 0.
</p>
<p>Axiom #2&mdash;Definition of Logical Negation: if A &frac14; 0 then A0 &frac14; 1, conversely, if A &frac14; 1 then A0 &frac14; 0.
</p>
<p>4.1.2.3 Axiom #3: Definition of a Logical Product
</p>
<p>This axiom defines a logical product or multiplication. Logical multiplication is denoted using either a
</p>
<p>dot (�), an ampersand (&amp;), or the conjunction symbol (^). The result of logical multiplication is true when
</p>
<p>both inputs are true and false otherwise.
</p>
<p>Axiom #3&mdash;Definition of a Logical Product: A�B &frac14; 1 if A &frac14; B &frac14; 1 and A�B &frac14; 0 otherwise.
</p>
<p>82 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_3">http://dx.doi.org/10.1007/978-3-319-34195-8_3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_3">http://dx.doi.org/10.1007/978-3-319-34195-8_3</a></div>
</div>
<div class="page"><p/>
<p>4.1.2.4 Axiom #4: Definition of a Logical Sum
</p>
<p>This axiom defines a logical sum or addition. Logical addition is denoted using either a plus sign (+)
</p>
<p>or the disjunction symbol (_). The result of logical addition is true when any of the inputs are true and
</p>
<p>false otherwise.
</p>
<p>Axiom #4&mdash;Definition of a Logical Sum: A + B &frac14; 1 if A &frac14; 1 or B &frac14; 1 and A + B &frac14; 0 otherwise.
</p>
<p>4.1.2.5 Axiom #5: Logical Precedence
</p>
<p>This axiom defines the order of precedence for the three operators. Unless the precedence is
</p>
<p>explicitly stated using parentheses, negation takes precedence over a logical product and a logical
</p>
<p>product takes precedence over a logical sum.
</p>
<p>Axiom #5&mdash;Definition of Logical Precedence: NOT precedes AND, AND precedes OR.
</p>
<p>To illustrate Axiom #5, consider the logic function F &frac14; A0�B + C. In this function, the first operation
</p>
<p>that would take place is the NOToperation on A. This would be followed by the AND operation of A0 with
</p>
<p>B. Finally, the result would be OR&rsquo;d with C. The precedence of any function can also be explicitly stated
</p>
<p>using parentheses such as F &frac14; (((A0) � B) + C).
</p>
<p>4.1.3 Theorems
</p>
<p>A theorem is a more sophisticated truth about a system that is not intuitively obvious. Theorems are
</p>
<p>proposed and then must be proved. Once proved, they can be accepted as a truth about the system
</p>
<p>going forward. Proving a theorem in Boolean algebra is much simpler than in our traditional decimal
</p>
<p>system due to the fact that variables can only take on one of the two values, true or false. Since the
</p>
<p>number of input possibilities is bounded, Boolean algebra theorems can be proved by simply testing the
</p>
<p>theorem using every possible input code. This is called proof by exhaustion. The following theorems
</p>
<p>are used widely in the manipulation of logic expressions and reduction of terms within an expression.
</p>
<p>4.1.3.1 DeMorgan&rsquo;s Theorem of Duality
</p>
<p>Augustus DeMorgan was a British mathematician and logician who lived during the time of George
</p>
<p>Boole. DeMorgan is best known for his contribution to the field of logic through the creation of what have
</p>
<p>been later called the DeMorgan&rsquo;s Theorems (often called DeMorgan&rsquo;s laws). There are two major
</p>
<p>theorems that DeMorgan proposed that expanded Boolean algebra. The first theorem is named duality.
</p>
<p>Duality states that an algebraic equality will remain true if all 0s and 1s are interchanged and all AND and
</p>
<p>OR operations are interchanged. The new expression is called the dual of the original expression.
</p>
<p>Example 4.1 shows the process of proving duality using proof by exhaustion.
</p>
<p>4.1 Boolean Algebra &bull; 83</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 4.1
Proving DeMorgan&rsquo;s Theorem of Duality Using Proof by Exhaustion
</p>
<p>Duality is important for two reasons. First, it doubles the impact of a theorem. If a theorem is proved
</p>
<p>to be true, then the dual of that theorem is also proved to be true. This, in essence, gives twice the
</p>
<p>theorem with the same amount of proving. Boolean algebra theorems are almost always given in pairs,
</p>
<p>the original and the dual. That is why duality is covered as the first theorem.
</p>
<p>The second reason that duality is important is because it can be used to convert between positive
</p>
<p>and negative logic. Until now, we have used positive logic for all of our examples (i.e., a logic HIGH &frac14;
</p>
<p>true &frac14; 1 and a logic LOW &frac14; false &frac14; 0). As mentioned earlier, this convention is arbitrary and we could
</p>
<p>have easily chosen a HIGH to be false and a LOW to be true (i.e., negative logic). Duality allows us to
</p>
<p>take a logic expression that has been created using positive logic (F) and then convert it into an
</p>
<p>equivalent expression that is valid for negative logic (FD). Example 4.2 shows the process for how this
</p>
<p>works.
</p>
<p>84 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 4.2
Converting Between Positive and Negative Logic Using Duality
</p>
<p>One consideration when using duality is that the order of precedence follows the original function.
</p>
<p>This means that in the original function, the axiom for precedence states the order as NOT-AND-OR;
</p>
<p>however, this is not necessarily the correct precedence order in the dual. For example, if the original
</p>
<p>function was F &frac14; A � B + C, the AND operation of A and B would take place first, and then the result
</p>
<p>would be OR&rsquo;d with C. The dual of this expression is FD &frac14; A + B � C. If the expression for FD was
</p>
<p>evaluated using traditional Boolean precedence, it would show that FD does NOT give the correct result
</p>
<p>per the definition of a dual function (i.e., converting a function from positive to negative logic). The order
</p>
<p>of precedence for FD must correlate to the precedence in the original function. Since in the original
</p>
<p>function A and B were operated on first, they must also be operated on first in the dual. In order to easily
</p>
<p>manage this issue, parentheses can be used to track the order of operations from the original function to
</p>
<p>the dual. If we put parentheses in the original function to explicitly state the precedence of the operations,
</p>
<p>it would take the form F &frac14; (A � B) + C. These parentheses can be mapped directly to the dual yielding
</p>
<p>FD &frac14; (A + B) � C. This order of precedence in the dual is now correct.
</p>
<p>4.1 Boolean Algebra &bull; 85</p>
<p/>
</div>
<div class="page"><p/>
<p>Now that we have covered the duality operation, its usefulness, and its pitfalls, we can formally
</p>
<p>define this theorem as:
</p>
<p>DeMorgan&rsquo;s Duality: An algebraic equality will remain true if all 0s and 1s are interchanged and all AND
</p>
<p>and OR operations are interchanged. Furthermore, taking the dual of a positive logic function will
</p>
<p>produce the equivalent function using negative logic if the original order of precedence is maintained.
</p>
<p>4.1.3.2 Identity
</p>
<p>An identity operation is one that when performed on a variable will yield itself regardless of the
</p>
<p>variable&rsquo;s value. The following is the formal definition of identity theorem. Figure 4.1 shows the gate-level
</p>
<p>depiction of this theorem.
</p>
<p>Identity:OR&rsquo;ing any variable with a logic 0 will yield the original variable. The dual: AND&rsquo;ing any variable
</p>
<p>with a logic 1 will yield the original variable.
</p>
<p>Original Dual
</p>
<p>A+0 = A A&bull;1 = A
</p>
<p>The identity theorem is useful for reducing circuitry when it is discovered that a particular input will
</p>
<p>never change values. When this is the case, the static input variable can simply be removed from the
</p>
<p>logic expression making the entire circuit a simple wire from the remaining input variable to the output.
</p>
<p>4.1.3.3 Null Element
</p>
<p>A null element operation is one that, when performed on a constant value, will yield that same
</p>
<p>constant value regardless of the values of any variables within the same operation. The following is the
</p>
<p>formal definition of null element. Figure 4.2 shows the gate-level depiction of this theorem.
</p>
<p>Null Element: OR&rsquo;ing any variable with a logic 1 will yield a logic 1 regardless of the value of the input
</p>
<p>variable. The dual: AND&rsquo;ing any variable with a logic 0 will yield a logic 0 regardless of the value of the
</p>
<p>input variable.
</p>
<p>Original Dual
</p>
<p>A+1 = 1 A&bull;0 = 0
</p>
<p>Fig. 4.1
Gate-level depiction of the identity theorem
</p>
<p>Fig. 4.2
Gate-level depiction of the null element theorem
</p>
<p>86 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>The null element theorem is also useful for reducing circuitry when it is discovered that a particular
</p>
<p>input will never change values. It is also widely used in computer systems in order to set (i.e., force to a
</p>
<p>logic 1) or clear (i.e., force to a logic 0) the value of a storage element.
</p>
<p>4.1.3.4 Idempotent
</p>
<p>An idempotent operation is one that has no effect on the input, regardless of the number of times the
</p>
<p>operation is applied. The following is the formal definition of idempotence. Figure 4.3 shows the gate-
</p>
<p>level depiction of this theorem.
</p>
<p>Idempotent:OR&rsquo;ing a variable with itself results in itself. The dual: AND&rsquo;ing a variable with itself results in
</p>
<p>itself.
</p>
<p>Original Dual
</p>
<p>A+A = A A&bull;A = A
</p>
<p>This theorem also holds true for any number of operations such as A + A + A + . . . + A &frac14; A and
</p>
<p>A � A � A � . . . � A &frac14; A.
</p>
<p>4.1.3.5 Complements
</p>
<p>This theorem describes an operation of a variable with the variable&rsquo;s own complement. The
</p>
<p>following is the formal definition of complements. Figure 4.4 shows the gate-level depiction of this
</p>
<p>theorem.
</p>
<p>Complements: OR&rsquo;ing a variable with its complement will produce a logic 1. The dual: AND&rsquo;ing a
</p>
<p>variable with its complement will produce a logic 0.
</p>
<p>Original Dual
</p>
<p>A+A&rsquo; = 1 A&bull;A&rsquo; = 0
</p>
<p>The complement theorem is again useful for reducing circuitry when these types of logic
</p>
<p>expressions are discovered.
</p>
<p>Fig. 4.3
Gate-level depiction of the idempotent theorem
</p>
<p>Fig. 4.4
Gate-level depiction of the complements theorem
</p>
<p>4.1 Boolean Algebra &bull; 87</p>
<p/>
</div>
<div class="page"><p/>
<p>4.1.3.6 Involution
</p>
<p>An involution operation describes the result of double negation. The following is the formal definition
</p>
<p>of involution. Figure 4.5 shows the gate-level depiction of this theorem.
</p>
<p>Involution: Taking the double complement of a variable will result in the original variable.
</p>
<p>Original
</p>
<p>A&rsquo;&rsquo; = A
</p>
<p>This theorem is not only used to eliminate inverters but also provides us a powerful tool for inserting
</p>
<p>inverters in a circuit. We will see that this is used widely with the second of DeMorgan&rsquo;s laws that will be
</p>
<p>introduced at the end of this section.
</p>
<p>4.1.3.7 Commutative Property
</p>
<p>The term commutative is used to describe an operation in which the order of the quantities or
</p>
<p>variables in the operation has no impact on the result. The following is the formal definition of the
</p>
<p>commutative property. Figure 4.6 shows the gate-level depiction of this theorem.
</p>
<p>Commutative Property: Changing the order of variables in an OR operation does not change the end
</p>
<p>result. The dual: Changing the order of variables in an AND operation does not change the end result.
</p>
<p>Original Dual
</p>
<p>A+B = B+A A&bull;B = B&bull;A
</p>
<p>One practical use of the commutative property is when wiring or routing logic circuitry together.
</p>
<p>Example 4.3 shows how the commutative property can be used to untangle crossed wires when
</p>
<p>implementing a digital system.
</p>
<p>Fig. 4.5
Gate-level depiction of the involution theorem
</p>
<p>Fig. 4.6
Gate-level depiction of commutative property
</p>
<p>88 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 4.3
Using the Commutative Property to Untangle Crossed Wires
</p>
<p>4.1.3.8 Associative Property
</p>
<p>The term associative is used to describe an operation in which the grouping of the quantities or
</p>
<p>variables in the operation has no impact on the result. The following is the formal definition of the
</p>
<p>associative property. Figure 4.7 shows the gate-level depiction of this theorem.
</p>
<p>4.1 Boolean Algebra &bull; 89</p>
<p/>
</div>
<div class="page"><p/>
<p>Associative Property: The grouping of variables doesn&rsquo;t impact the result of an OR operation. The dual:
</p>
<p>The grouping of variables doesn&rsquo;t impact the result of an AND operation.
</p>
<p>Original Dual
</p>
<p>(A+B)+C = A+(B+C) (A∙B)∙C = A∙(B∙C)
</p>
<p>One practical use of the associative property is addressing fan-in limitations of a logic family. Since
</p>
<p>the grouping of the input variables does not impact the result, we can accomplish operations with large
</p>
<p>numbers of inputs using multiple gates with fewer inputs. Example 4.4 shows the process of using the
</p>
<p>associative property to address a fan-in limitation.
</p>
<p>Example 4.4
Using the Associative Property to Address Fan-In Limitations
</p>
<p>Fig. 4.7
Gate-level depiction of the associative property
</p>
<p>90 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>4.1.3.9 Distributive Property
</p>
<p>The term distributive describes how an operation on a parenthesized group of operations (or higher
</p>
<p>precedence operations) can be distributed through each term. The following is the formal definition of the
</p>
<p>distributive property. Figure 4.8 shows the gate-level depiction of this theorem.
</p>
<p>Distributive Property: An operation on a parenthesized operation(s), or higher precedence operator,
</p>
<p>will distribute through each term.
</p>
<p>Original Dual
</p>
<p>A∙(B+C) = A∙B + A∙C A+(B∙C) = (A+B)∙(A+C)
</p>
<p>The distributive property is used as a logic manipulation technique. It can be used to put a logic
</p>
<p>expression into a form more suitable for direct circuit synthesis, or to reduce the number of logic gates
</p>
<p>necessary. Example 4.5 shows how to use the distributive property to reduce the number of gates in a
</p>
<p>logic circuit.
</p>
<p>Example 4.5
Using the Distributive Property to Reduce the Number of Logic Gates in a Circuit
</p>
<p>Fig. 4.8
Gate-level depiction of the distributive property
</p>
<p>4.1 Boolean Algebra &bull; 91</p>
<p/>
</div>
<div class="page"><p/>
<p>4.1.3.10 Absorption
</p>
<p>The term absorption refers to when multiple logic terms within an expression produce the same
</p>
<p>results. This allows one of the terms to be eliminated from the expression, thus reducing the number of
</p>
<p>logic operations. The remaining terms essentially absorb the functionality of the eliminated term. This
</p>
<p>theorem is also called covering because the remaining term essentially covers the functionality of both
</p>
<p>itself and the eliminated term. The following is the formal definition of the absorption theorem. Figure 4.9
</p>
<p>shows the gate-level depiction of this theorem.
</p>
<p>Absorption: When a term within a logic expression produces the same output(s) as another term, the
</p>
<p>second term can be removed without affecting the result.
</p>
<p>Original Dual
</p>
<p>A+A∙B = A A∙(A+B) = A
</p>
<p>This theorem is better understood by looking at the evaluation of each term with respect to the
</p>
<p>original expression. Example 4.6 shows how the absorption theorem can be proven through proof by
</p>
<p>exhaustion by evaluating each term in a logic expression.
</p>
<p>Example 4.6
Proving the Absorption Theorem Using Proof by Exhaustion
</p>
<p>4.1.3.11 Uniting
</p>
<p>The uniting theorem, also called combining orminimization, provides a way to remove variables from
</p>
<p>an expression when they have no impact on the outcome. This theorem is one of the most widely used
</p>
<p>Fig. 4.9
Gate-level depiction of absorption
</p>
<p>92 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>techniques for the reduction of the number of gates needed in a combinational logic circuit. The following
</p>
<p>is the formal definition of the uniting theorem. Figure 4.10 shows the gate-level depiction of this theorem.
</p>
<p>Uniting: When a variable (B) and its complement (B0) appear in multiple product terms with a common
</p>
<p>variable (A) within a logical OR operation, the variable B does not have any effect on the result and can
</p>
<p>be removed.
</p>
<p>Original Dual
</p>
<p>A∙B +A∙B&rsquo; = A (A+B)∙(A+B&rsquo;) = A
</p>
<p>This theorem can be proved using prior theorems. Example 4.7 shows how the uniting theorem can
</p>
<p>be proved using a combination of the distributive property, the complements theorem, and the identity
</p>
<p>theorem.
</p>
<p>Example 4.7
Proving of the Uniting Theorem
</p>
<p>4.1.3.12 DeMorgan&rsquo;s Theorem
</p>
<p>Now we look at the second of DeMorgan&rsquo;s laws. This second theorem is simply known as
</p>
<p>DeMorgan&rsquo;s theorem. This theorem provides a technique to manipulate a logic expression that uses
</p>
<p>AND gates into one that uses OR gates and vice versa. It can also be used to manipulate traditional
</p>
<p>Boolean logic expressions that use AND-OR-NOT operators, into equivalent forms that use NAND and
</p>
<p>NOR gates. The following is the formal definition of DeMorgan&rsquo;s theorem. Figure 4.11 shows the gate-
</p>
<p>level depiction of this theorem.
</p>
<p>DeMorgan&rsquo;s Theorem: An OR operation with both inputs inverted is equivalent to an AND operation
</p>
<p>with the output inverted. The dual: An AND operation with both inputs inverted is equivalent to an OR
</p>
<p>operation with the output inverted.
</p>
<p>Fig. 4.10
Gate-level depiction of uniting
</p>
<p>4.1 Boolean Algebra &bull; 93</p>
<p/>
</div>
<div class="page"><p/>
<p>Original Dual
</p>
<p>A&rsquo; + B&rsquo; = (A∙B)&rsquo; A&rsquo; ∙ B&rsquo; = (A + B)&rsquo;
</p>
<p>This theorem is used widely in modern logic design because it bridges the gap between the design
</p>
<p>of logic circuitry using Boolean algebra and the physical implementation of the circuitry using CMOS.
</p>
<p>Recall that Boolean algebra is defined for only three operations, the AND, the OR, and inversion. CMOS,
</p>
<p>on the other hand, can only directly implement negative-type gates such as NAND, NOR, and NOT.
</p>
<p>DeMorgan&rsquo;s theorem allows us to design logic circuitry using Boolean algebra and synthesize logic
</p>
<p>diagrams with AND, OR, and NOT gates, and then directly convert the logic diagrams into an equivalent
</p>
<p>form using NAND, NOR, and NOT gates. As we&rsquo;ll see in the next section, Boolean algebra produces
</p>
<p>logic expressions in two common forms. These are the sum of products (SOP) and the product of
</p>
<p>sums (POS) forms. Using a combination of involution and DeMorgan&rsquo;s theorem, SOP and POS forms
</p>
<p>can be converted into equivalent logic circuits that use only NAND and NOR gates. Example 4.8 shows a
</p>
<p>process to convert a sum of products form into one that uses only NAND gates.
</p>
<p>Fig. 4.11
Gate-level depiction of DeMorgan&rsquo;s theorem
</p>
<p>94 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 4.8
Converting a Sum of Products Form into One That Uses Only NAND Gates
</p>
<p>4.1 Boolean Algebra &bull; 95</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 4.9 shows a process to convert a product of sums form into one that uses only NOR gates.
</p>
<p>Example 4.9
Converting a Product of Sums Form into One That Uses Only NOR Gates
</p>
<p>DeMorgan&rsquo;s theorem can also be accomplished algebraically using a process known as breaking
</p>
<p>the bar and flipping the operator. This process again takes advantage of the involution theorem, which
</p>
<p>allows double negation without impacting the result. When using this technique in algebraic form,
</p>
<p>involution takes the form of a double-inversion bar. If an inversion bar is broken, the expression will
</p>
<p>remain true as long as the operator directly below the break is flipped (AND to OR, OR to AND). Example
</p>
<p>4.10 shows how to use this technique when converting an OR gate with its inputs inverted into an AND
</p>
<p>gate with its output inverted.
</p>
<p>96 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 4.10
Using DeMorgan's Theorem in Algebraic Form (1)
</p>
<p>Example 4.11 shows how to use this technique when converting an AND gate with its inputs inverted
</p>
<p>into an OR gate with its output inverted.
</p>
<p>Example 4.11
Using DeMorgan's Theorem in Algebraic Form (2)
</p>
<p>Table 4.1 gives a summary of all the Boolean algebra theorems just covered. The theorems are
</p>
<p>grouped in this table with respect to the number of variables that they contain. This grouping is the most
</p>
<p>common way these theorems are presented.
</p>
<p>4.1 Boolean Algebra &bull; 97</p>
<p/>
</div>
<div class="page"><p/>
<p>4.1.4 Functionally Complete Operation Sets
</p>
<p>A set of Boolean operators is said to be functionally complete when the set can implement all
</p>
<p>possible logic functions. The set of operators {AND, OR, NOT} is functionally complete because every
</p>
<p>other operation can be implemented using these three operators (i.e., NAND, NOR, BUF, XOR, XNOR).
</p>
<p>The DeMorgan&rsquo;s theorem showed us that all AND and OR operations can be replaced with NAND and
</p>
<p>NOR operators. This means that NAND and NOR operations could be by themselves functionally
</p>
<p>complete if they could perform a NOToperation. Figure 4.12 shows how a NAND gate can be configured
</p>
<p>to perform a NOT operation. This configuration allows a NAND gate to be considered functionally
</p>
<p>complete because all other operations can be implemented.
</p>
<p>Table 4.1
Summary of Boolean algebra theorems
</p>
<p>Fig. 4.12
Configuration to use a NAND gate as an inverter
</p>
<p>98 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>This approach can also be used on a NOR gate to implement an inverter. Figure 4.13 shows how a
</p>
<p>NOR gate can be configured to perform a NOToperation, thus also making it functionally complete.
</p>
<p>CC4.1 If the logic expression F=A&middot;B&middot;C&middot;D&middot;E&middot;F&middot;G&middot;H is implemented with only 2-input AND gates, 
how many levels of logic will the final implementation have? Hint: Consider using the 
associative property to manipulate the logic expression to use only 2-input AND 
operations.  
</p>
<p>A) 2 B) 3 C) 4 D) 5
</p>
<p>CONCEPT CHECK
</p>
<p>4.2 Combinational Logic Analysis
</p>
<p>Combinational logic analysis refers to the act of deciphering the operation of a circuit from its final
</p>
<p>logic diagram. This is a useful skill that can aid designers when debugging their circuits. This can also be
</p>
<p>used to understand the timing performance of a circuit and to reverse-engineer an unknown design.
</p>
<p>4.2.1 Finding the Logic Expression from a Logic Diagram
</p>
<p>Combinational logic diagrams are typically written with their inputs on the left and their output on the
</p>
<p>right. As the inputs change, the intermediate nodes, or connections, within the diagram hold the interim
</p>
<p>computations that contribute to the ultimate circuit output. These computations propagate from left to
</p>
<p>right until ultimately the final output of the system reaches its final steady-state value. When analyzing
</p>
<p>the behavior of a combinational logic circuit a similar left-to-right approach is used. The first step is to
</p>
<p>label each intermediate node in the system. The second step is to write in the logic expression for each
</p>
<p>node based on the preceding logic operation(s). The logic expressions are written working left-to-right
</p>
<p>until the output of the system is reached and the final logic expression of the circuit has been found.
</p>
<p>Consider the example of this analysis in Example 4.12.
</p>
<p>Fig. 4.13
Configuration to use a NOR gate as an inverter
</p>
<p>4.2 Combinational Logic Analysis &bull; 99</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 4.12
Determining the Logic Expression from a Logic Diagram
</p>
<p>4.2.2 Finding the Truth Table from a Logic Diagram
</p>
<p>The final truth table of a circuit can also be found in a similar manner as the logic expression. Each
</p>
<p>internal node within the logic diagram can be evaluated working from the left to the right for each possible
</p>
<p>input code. Each subsequent node can then be evaluated using the values of the preceding nodes.
</p>
<p>Consider the example of this analysis in Example 4.13.
</p>
<p>100 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 4.13
Determining the Truth Table from a Logic Diagram
</p>
<p>4.2.3 Timing Analysis of a Combinational Logic Circuit
</p>
<p>Real logic gates have a propagation delay (tpd, tPHL, or tPLH) as presented in Chap. 3. Performing a
</p>
<p>timing analysis on a combinational logic circuit refers to observing how long it takes for a change in the
</p>
<p>inputs to propagate to the output. Different paths through the combinational logic circuit will take different
</p>
<p>times to compute since they may use gates with different delays. When determining the delay of the
</p>
<p>entire combinational logic circuit we always consider the longest delay path. This is because this delay
</p>
<p>represents the worst-case scenario. As long as we wait for the longest path to propagate through the
</p>
<p>circuit, then we are ensured that the output will always be valid after this time. To determine which signal
</p>
<p>path has the longest delay, we map out each and every path the inputs can take to the output of the
</p>
<p>circuit. We then sum up the gate delay along each path. The path with the longest delay dictates the
</p>
<p>delay of the entire combinational logic circuit. Consider this analysis shown in Example 4.14.
</p>
<p>4.2 Combinational Logic Analysis &bull; 101</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_3">http://dx.doi.org/10.1007/978-3-319-34195-8_3</a></div>
</div>
<div class="page"><p/>
<p>Example 4.14
Determining the Delay of a Combinational Logic Circuit
</p>
<p>CC4.2 Does the delay specification of a combinational logic circuit change based on the input 
values that the circuit is evaluating?
</p>
<p>A) Yes. There are times when the inputs switch between inputs codes that use 
paths through the circuit with different delays. 
</p>
<p>B) No. The delay is always specified as the longest delay path.
</p>
<p>C) Yes. The delay can vary between the longest delay path and zero.  A delay of 
zero occurs when the inputs switch between two inputs codes that produce the 
same output.
</p>
<p>D) No. The output is always produced at a time equal to the longest delay path.
</p>
<p>CONCEPT CHECK
</p>
<p>102 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>4.3 Combinational Logic Synthesis
</p>
<p>4.3.1 Canonical Sum of Products
</p>
<p>One technique to directly synthesize a logic circuit from a truth table is to use a canonical sum of
</p>
<p>products topology based on minterms. The term canonical refers to this topology yielding potentially
</p>
<p>unminimized logic. A minterm is a product term (i.e., an AND operation) that will be true for one and only
</p>
<p>one input code. The minterm must contain every input variable in its expression. Complements are
</p>
<p>applied to the input variables as necessary in order to produce a true output for the individual input code.
</p>
<p>We define the word literal to describe an input variable which may or may not be complemented. This is a
</p>
<p>more useful word because if we say that a minterm &ldquo;must include all variables,&rdquo; it implies that all variables
</p>
<p>are included in the term uncomplemented. A more useful statement is that a minterm &ldquo;must include all
</p>
<p>literals.&rdquo; This now implies that each variable must be included, but it can be in the form of itself or its
</p>
<p>complement (e.g., A or A0). Figure 4.14 shows the definition and gate-level depiction of a minterm
</p>
<p>expression. Each minterm can be denoted using the lower case &ldquo;m&rdquo; with the row number as a subscript.
</p>
<p>For an arbitrary truth table, a minterm can be used for each row corresponding to a true output. If
</p>
<p>each of these minterms&rsquo; outputs are fed into a single OR gate, then a sum of products logic circuit is
</p>
<p>formed that will produce the logic listed in the truth table. In this topology, any input code that corresponds
</p>
<p>to an output of 1 will cause its corresponding minterm to output a 1. Since a 1 on any input of an OR gate
</p>
<p>will cause the output to go to a 1, the output of the minterm is passed to the final result. Example 4.15
</p>
<p>shows this process. One important consideration of this approach is that no effort has been taken to
</p>
<p>minimize the logic expression. This unminimized logic expression is also called the canonical sum. The
</p>
<p>canonical sum is logically correct but uses the most amount of circuitry possible for a given truth table.
</p>
<p>This canonical sum can be the starting point for minimization using Boolean algebra.
</p>
<p>Fig. 4.14
Definition and gate-level depiction of a minterm
</p>
<p>4.3 Combinational Logic Synthesis &bull; 103</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 4.15
Creating a Canonical Sum of Products Logic Circuit Using Minterms
</p>
<p>4.3.2 The Minterm List (Σ)
</p>
<p>Aminterm list is a compact way to describe the functionality of a logic circuit by simply listing the row
</p>
<p>numbers that correspond to an output of 1 in the truth table. The &sum; symbol is used to denote a minterm
</p>
<p>list. All input variables must be listed in the order they appear in the truth table. This is necessary because
</p>
<p>since a minterm list uses only the row numbers to indicate which input codes result in an output of 1, the
</p>
<p>minterm list must indicate how many variables comprise the row number, which variable is in the most
</p>
<p>significant position, and which is in the least significant position. After the &sum; symbol, the row numbers
</p>
<p>corresponding to a true output are listed in a comma-delimited format within parentheses. Example 4.16
</p>
<p>shows the process for creating a minterm list from a truth table.
</p>
<p>104 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 4.16
Creating a Minterm List from a Truth Table
</p>
<p>A minterm list contains the same information as the truth table, the canonical sum, and the canonical
</p>
<p>sum of products logic diagram. Since the minterms themselves are formally defined for an input code, it
</p>
<p>is trivial to go back and forth between the minterm list and these other forms. Example 4.17 shows how a
</p>
<p>minterm list can be used to generate an equivalent truth table, canonical sum, and canonical sum of
</p>
<p>products logic diagram.
</p>
<p>4.3 Combinational Logic Synthesis &bull; 105</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 4.17
Creating Equivalent Functional Representations from a Minterm List
</p>
<p>4.3.3 Canonical Product of Sums (POS)
</p>
<p>Another technique to directly synthesize a logic circuit from a truth table is to use a canonical product
</p>
<p>of sums topology based onmaxterms. A maxterm is a sum term (i.e., an OR operation) that will be false
</p>
<p>for one and only one input code. The maxterm must contain every literal in its expression. Complements
</p>
<p>are applied to the input variables as necessary in order to produce a false output for the individual input
</p>
<p>code. Figure 4.15 shows the definition and gate-level depiction of a maxterm expression. Each maxterm
</p>
<p>can be denoted using the upper case &ldquo;M&rdquo; with the row number as a subscript.
</p>
<p>106 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>For an arbitrary truth table, a maxterm can be used for each row corresponding to a false output. If
</p>
<p>each of these maxterms outputs are fed into a single AND gate, then a product of sums logic circuit is
</p>
<p>formed that will produce the logic listed in the truth table. In this topology, any input code that corresponds
</p>
<p>to an output of 0 will cause its corresponding maxterm to output a 0. Since a 0 on any input of an AND
</p>
<p>gate will cause the output to go to a 0, the output of the maxterm is passed to the final result. Example
</p>
<p>4.18 shows this process. This approach is complementary to the sum of products approach. In the sum
</p>
<p>of products approach based on minterms, the circuit operates by producing 1s that are passed to the
</p>
<p>output for the rows that require a true output. For all other rows, the output is false. A product of sums
</p>
<p>approach based on maxterms operates by producing 0s that are passed to the output for the rows that
</p>
<p>require a false output. For all other rows, the output is true. These two approaches produce the
</p>
<p>equivalent logic functionality. Again, at this point no effort has been taken to minimize the logic expres-
</p>
<p>sion. This unminimized form is called a canonical product. The canonical product is logically correct,
</p>
<p>but uses the most amount of circuitry possible for a given truth table. This canonical product can be the
</p>
<p>starting point for minimization using the Boolean algebra theorems.
</p>
<p>Fig. 4.15
Definition and gate level depiction of a maxterm
</p>
<p>4.3 Combinational Logic Synthesis &bull; 107</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 4.18
Creating a Product of Sums Logic Circuit Using Maxterms
</p>
<p>4.3.4 The Maxterm List (Π)
</p>
<p>Amaxterm list is a compact way to describe the functionality of a logic circuit by simply listing the row
</p>
<p>numbers that correspond to an output of 0 in the truth table. The Π symbol is used to denote a maxterm
</p>
<p>list. All literals used in the logic expression must be listed in the order they appear in the truth table. After
</p>
<p>the Π symbol, the row numbers corresponding to a false output are listed in a comma-delimited format
</p>
<p>within parentheses. Example 4.19 shows the process for creating a maxterm list from a truth table.
</p>
<p>108 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 4.19
Creating a Maxterm List from a Truth Table
</p>
<p>A maxterm list contains the same information as the truth table, the canonical product, and the
</p>
<p>canonical product of sums logic diagram. Example 4.20 shows how a maxterm list can be used to
</p>
<p>generate these equivalent forms.
</p>
<p>4.3 Combinational Logic Synthesis &bull; 109</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 4.20
Creating Equivalent Functional Representations from a Maxterm List
</p>
<p>4.3.5 Minterm and Maxterm List Equivalence
</p>
<p>The examples in Examples 4.17 and 4.20 illustrate how minterm and maxterm lists produce
</p>
<p>the exact same logic functionality but in a complementary fashion. It is trivial to switch back and
</p>
<p>forth between minterm lists and maxterm lists. This is accomplished by simply changing the list type
</p>
<p>110 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>(i.e., min to max, max to min) and then switching the row numbers between those listed and those
</p>
<p>not listed. Example 4.21 shows multiple techniques for representing equivalent logic functionality as a
</p>
<p>truth table.
</p>
<p>Example 4.21
Creating Equivalent Forms to Represent Logic Functionality
</p>
<p>4.3 Combinational Logic Synthesis &bull; 111</p>
<p/>
</div>
<div class="page"><p/>
<p>CC4.3 All logic functions can be implemented equivalently using either a canonical sum of 
products (SOP) or canonical product of sums (POS) topology.  Which of these statements 
is true with respect to selecting a topology that requires the least amount of gates.
</p>
<p>A) Since a minterm list and a maxterm list can both be written to describe the same 
logic functionality, the number of gates in an SOP and POS will always be the 
same.
</p>
<p>B) If a minterm list has over half of its row numbers listed, an SOP topology will 
require fewer gates than a POS.
</p>
<p>C) A POS topology always requires more gates because it needs additional logic to 
convert the inputs from positive to negative logic.
</p>
<p>D) If a minterm list has over half of its row numbers listed, a POS topology will 
require fewer gates than SOP.
</p>
<p>CONCEPT CHECK
</p>
<p>4.4 Logic Minimization
</p>
<p>We now look at how to reduce the canonical expressions into equivalent forms that use less logic.
</p>
<p>This minimization is key to reducing the complexity of the logic prior to implementing in real circuitry. This
</p>
<p>reduces the amount of gates needed, placement area, wiring, and power consumption of the logic circuit.
</p>
<p>4.4.1 Algebraic Minimization
</p>
<p>Canonical expressions can be reduced algebraically by applying the theorems covered in prior
</p>
<p>sections. This process typically consists of a series of factoring based on the distributive property
</p>
<p>followed by replacing variables with constants (i.e., 0s and 1s) using the complements theorem. Finally,
</p>
<p>constants are removed using the identity theorem. Example 4.22 shows this process.
</p>
<p>112 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 4.22
Minimizing a Logic Expression Algebraically
</p>
<p>The primary drawback of this approach is that it requires recognition of where the theorems can be
</p>
<p>applied. This can often lead to missed minimizations. Computer automation is often the best mechanism
</p>
<p>to perform this minimization for large logic expressions.
</p>
<p>4.4.2 Minimization Using Karnaugh Maps
</p>
<p>A Karnaugh map is a graphical way to minimize logic expressions. This technique is named after
</p>
<p>Maurice Karnaugh, American physicist, who introduced themap in its latest form in 1953 while working at
</p>
<p>Bell Labs. The Karnaugh map (or K-map) is a way to put a truth table into a form that allows logic
</p>
<p>minimization through a graphical process. This technique provides a graphical process that
</p>
<p>accomplishes the same result as factoring variables via the distributive property and removing variables
</p>
<p>via the complements and identity theorems. K-maps present a truth table in a form that allows variables
</p>
<p>to be removed from the final logic expression in a graphical manner.
</p>
<p>4.4 Logic Minimization &bull; 113</p>
<p/>
</div>
<div class="page"><p/>
<p>4.4.2.1 Formation of a K-map
</p>
<p>A K-map is constructed as a two-dimensional grid. Each cell within the map corresponds to the
</p>
<p>output for a specific input code. The cells are positioned such that neighboring cells only differ by one bit
</p>
<p>in their input codes. Neighboring cells are defined as cells immediately adjacent horizontally and
</p>
<p>immediately adjacent vertically. Two cells positioned diagonally next to each other are not considered
</p>
<p>neighbors. The input codes for each variable are listed along the top and side of the K-map. Consider the
</p>
<p>construction of a 2-input K-map shown in Fig. 4.16.
</p>
<p>When constructing a 3-input K-map, it is important to remember that each input code can only differ
</p>
<p>from its neighbor by one bit. For example, the two codes 01 and 10 differ by two bits (i.e., the MSB is
</p>
<p>different and the LSB is different); thus they could not be neighbors; however, the codes 01-11 and 11-10
</p>
<p>can be neighbors. As such, the input codes along the top of the 3-input K-map must be ordered
</p>
<p>accordingly (i.e., 00-01-11-10). Consider the construction of a 3-input K-map shown in Fig. 4.17. The
</p>
<p>rows and columns that correspond to the input literals can now span multiple rows and columns. Notice
</p>
<p>how in this 3-input K-map, the literals A, A0, B, and B0 all correspond to two columns. Also, notice that B0
</p>
<p>spans two columns, but the columns are on different edges of the K-map. The side edges of the 3-input
</p>
<p>K-map are still considered neighbors because the input codes for these columns only differ by one bit.
</p>
<p>This is an important attribute once we get to the minimization of variables because it allows us to
</p>
<p>examine an input literal&rsquo;s impact not only within the obvious adjacent cells but also when the variables
</p>
<p>wrap around the edges of the K-map.
</p>
<p>Fig. 4.16
Formation of a 2-input K-map
</p>
<p>114 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>When constructing a 4-input K-map, the same rules apply that the input codes can only differ from
</p>
<p>their neighbors by one bit. Consider the construction of a 4-input K-map in Fig. 4.18. In a 4-input K-map,
</p>
<p>neighboring cells can wrap around both the top-to-bottom edges in addition to the side-to-side edges.
</p>
<p>Notice that all 16 cells are positioned within the map so that their neighbors on the top, bottom, and sides
</p>
<p>only differ by one bit in their input codes.
</p>
<p>Fig. 4.17
Formation of a 3-input K-map
</p>
<p>4.4 Logic Minimization &bull; 115</p>
<p/>
</div>
<div class="page"><p/>
<p>4.4.2.2 Logic Minimization Using K-maps (Sum of Products)
</p>
<p>Now we look at using a K-map to create a minimized logic expression in an SOP form. Remember
</p>
<p>that each cell with an output of 1 has a minterm associated with it, just as in the truth table. When two
</p>
<p>neighboring cells have outputs of 1, it graphically indicates that the two minterms can be reduced into a
</p>
<p>minimized product term that will cover both outputs. Consider the example given in Fig. 4.19.
</p>
<p>Fig. 4.18
Formation of a 4-input K-map
</p>
<p>116 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>These observations can be put into a formal process to produce a minimized SOP logic expression
</p>
<p>using a K-map. The steps are as follows:
</p>
<p>1. Circle groups of 1s in the K-map following the rules:
</p>
<p>&bull; Each circle should contain the largest number of 1s possible.
</p>
<p>&bull; The circles encompass only neighboring cells (i.e., side-to-side sides and/or top and
bottom).
</p>
<p>&bull; The circles must contain a number of 1s that is a power of 2 (i.e., 1, 2, 4, 8, or 16).
</p>
<p>&bull; Enter as many circles as possible without having any circles fully cover another circle.
</p>
<p>&bull; Each circle is called a Prime Implicant.
</p>
<p>2. Create a product term for each prime implicant following the rules:
</p>
<p>&bull; Each variable in the K-map is evaluated one by one.
</p>
<p>&bull; If the circle covers a region where the input variable is a 1, then include it in the product
term uncomplemented.
</p>
<p>&bull; If the circle covers a region where the input variable is a 0, then include it in the product
term complemented.
</p>
<p>Fig. 4.19
Observing how K-maps visually highlight logic minimizations
</p>
<p>4.4 Logic Minimization &bull; 117</p>
<p/>
</div>
<div class="page"><p/>
<p>&bull; If the circle covers a region where the input variable is both a 0 and 1, then the variable is
excluded from the product term.
</p>
<p>3. Sum all of the product terms for each prime implicant.
</p>
<p>Let&rsquo;s apply this approach to our 2-input K-map example. Example 4.23 shows the process of finding
</p>
<p>a minimized sum of products logic expression for a 2-input logic circuit using a K-map. This process
</p>
<p>yielded the same SOP expression as the algebraic minimization and observations shown in Fig. 4.19,
</p>
<p>but with a formalized process.
</p>
<p>Example 4.23
Using a K-map to Find a Minimized Sum of Products Expression (2-Input)
</p>
<p>Let&rsquo;s now apply this process to our 3-input K-map example. Example 4.24 shows the process of
</p>
<p>finding a minimized sum of products logic expression for a 3-input logic circuit using a K-map. This
</p>
<p>example shows circles that overlap. This is legal as long as one circle does not fully encompass another.
</p>
<p>Overlapping circles are common since the K-map process dictates that circles should be drawn that
</p>
<p>group the largest number of ones possible as long as they are in powers of 2. Forming groups of ones
</p>
<p>using ones that have already been circled is perfectly legal to accomplish larger groupings. The larger
</p>
<p>the grouping of ones, the more chance there is for a variable to be excluded from the product term. This
</p>
<p>results in better minimization of the logic.
</p>
<p>118 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 4.24
Using a K-map to Find a Minimized Sum of Products Expression (3-Input)
</p>
<p>Let&rsquo;s now apply this process to our 4-input K-map example. Example 4.25 shows the process of
</p>
<p>finding a minimized sum of products logic expression for a 4-input logic circuit using a K-map.
</p>
<p>4.4 Logic Minimization &bull; 119</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 4.25
Using a K-map to Find a Minimized Sum of Products Expression (4-Input)
</p>
<p>4.4.2.3 Logic Minimization Using K-maps (Product of Sums)
</p>
<p>K-maps can also be used to create minimized product of sums logic expressions. This is the same
</p>
<p>concept as how a minterm list and maxterm list each produces the same logic function, but in comple-
</p>
<p>mentary fashions. When creating a product of sums expression from a K-map, groups of 0s are circled.
</p>
<p>For each circle, a sum term is derived with a negation of variables similar to when forming a maxterm
</p>
<p>120 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>(i.e., in the input variable is a 0, then it is included uncomplemented in the sum term and vice versa). The
</p>
<p>final step in forming the minimized POS expression is to AND all of the sum terms together. The formal
</p>
<p>process is as follows:
</p>
<p>1. Circle groups of 0s in the K-map following the rules:
</p>
<p>&bull; Each circle should contain the largest number of 0s possible.
</p>
<p>&bull; The circles encompass only neighboring cells (i.e., side-to-side sides and/or top and
bottom).
</p>
<p>&bull; The circles must contain a number of 0s that is a power of 2 (i.e., 1, 2, 4, 8, or 16).
</p>
<p>&bull; Enter as many circles as possible without having any circles fully cover another circle.
</p>
<p>&bull; Each circle is called a prime implicant.
</p>
<p>2. Create a sum term for each prime implicant following the rules:
</p>
<p>&bull; Each variable in the K-map is evaluated one by one.
</p>
<p>&bull; If the circle covers a region where the input variable is a 1, then include it in the sum term
complemented.
</p>
<p>&bull; If the circle covers a region where the input variable is a 0, then include it in the sum term
uncomplemented.
</p>
<p>&bull; If the circles cover a region where the input variable is both a 0 and 1, then the variable is
excluded from the sum term.
</p>
<p>3. Multiply all of the sum terms for each prime implicant.
</p>
<p>Let&rsquo;s apply this approach to our 2-input K-map example. Example 4.26 shows the process of finding
</p>
<p>a minimized product of sums logic expression for a 2-input logic circuit using a K-map. Notice that this
</p>
<p>process yielded the same logic expression as the SOP approach shown in Example 4.23. This illustrates
</p>
<p>that both the POS and SOP expressions produce the correct logic for the circuit.
</p>
<p>Example 4.26
Using a K-map to Find a Minimized Product of Sums Expression (2-Input)
</p>
<p>4.4 Logic Minimization &bull; 121</p>
<p/>
</div>
<div class="page"><p/>
<p>Let&rsquo;s now apply this process to our 3-input K-map example. Example 4.27 shows the process of
</p>
<p>finding a minimized product of sums logic expression for a 3-input logic circuit using a K-map. Notice that
</p>
<p>the logic expression in POS form is not identical to the SOP expression found in Example 4.24; however,
</p>
<p>using a few steps of algebraic manipulation shows that the POS expression can be put into a form that is
</p>
<p>identical to the prior SOP expression. This illustrates that both the POS and SOP produce equivalent
</p>
<p>functionality for the circuit.
</p>
<p>Example 4.27
Using a K-map to Find a Minimized Product of Sums Expression (3-Input)
</p>
<p>Let&rsquo;s now apply this process to our 4-input K-map example. Example 4.28 shows the process of
</p>
<p>finding a minimized product of sums logic expression for a 4-input logic circuit using a K-map.
</p>
<p>122 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 4.28
Using a K-map to Find a Minimized Product of Sums Expression (4-Input)
</p>
<p>4.4.2.4 Minimal Sum
</p>
<p>One situation that arises when minimizing logic using a K-map is that some of the prime implicants
</p>
<p>may be redundant. Consider the example in Fig. 4.20.
</p>
<p>4.4 Logic Minimization &bull; 123</p>
<p/>
</div>
<div class="page"><p/>
<p>We need to define a formal process for identifying redundant prime implicants that can be removed
</p>
<p>without impacting the result of the logic expression. Let&rsquo;s start with examining the sum of products form.
</p>
<p>First, we define the term essential prime implicant as a prime implicant that cannot be removed from
</p>
<p>the logic expression without impacting its result. We then define the term minimal sum as a logic
</p>
<p>expression that represents the most minimal set of logic operations to accomplish a sum of products
</p>
<p>form. There may be multiple minimal sums for a given truth table, but each would have the same number
</p>
<p>of logic operations. In order to determine if a prime implicant is essential, we first put in each and every
</p>
<p>possible prime implicant into the K-map. This gives a logic expression known as the complete sum.
</p>
<p>From this point we identify any cells that have only one prime implicant covering them. These cells are
</p>
<p>Fig. 4.20
Observing redundant prime implicants in a K-map
</p>
<p>124 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>called distinguished one cells. Any prime implicant that covers a distinguished one cell is defined as an
</p>
<p>essential prime implicant. All prime implicants that are not essential are removed from the K-map. A
</p>
<p>minimal sum is then simply the sum of all remaining product terms associated with the essential prime
</p>
<p>implicants. Example 4.29 shows how to use this process.
</p>
<p>Example 4.29
Deriving the Minimal Sum from a K-map
</p>
<p>This process is identical for the product of sums form to produce the minimal product.
</p>
<p>4.4.3 Don&rsquo;t Cares
</p>
<p>There are often times when framing a design problem that there are specific input codes that require
</p>
<p>exact output values, but there are other codes where the output value doesn&rsquo;t matter. This can occur for a
</p>
<p>variety of reasons, such as knowing that certain input codes will never occur due to the nature of the
</p>
<p>problem or that the output of the circuit will only be used under certain input codes. We can take
</p>
<p>advantage of this situation to produce a more minimal logic circuit. We define an output as a don&rsquo;t
</p>
<p>care when it doesn&rsquo;t matter whether it is a 1 or 0 for the particular input code. The symbol for a don&rsquo;t care
</p>
<p>is &ldquo;X.&rdquo; We take advantage of don&rsquo;t cares when performing logic minimization by treating them as
</p>
<p>whatever output value will produce a minimal logic expression. Example 4.30 shows how to use this
</p>
<p>process.
</p>
<p>4.4 Logic Minimization &bull; 125</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 4.30
Using Don&rsquo;t Cares to Produce a Minimal SOP Logic Expression
</p>
<p>4.4.4 Using XOR Gates
</p>
<p>While Boolean algebra does not include the exclusive-OR and exclusive-NOR operations, XOR and
</p>
<p>XNOR gates do indeed exist in modern electronics. They can be a useful tool to provide logic circuitry
</p>
<p>with less operations, sometimes even compared to a minimal sum or product synthesized using the
</p>
<p>techniques just described. An XOR/XNOR operation can be identified by putting the values from a
</p>
<p>truth table into a K-map. The XOR/XNOR operations will result in a characteristic checkerboard pattern in
</p>
<p>the K-map. Consider the following patterns for XOR and XNOR gates in Figs. 4.21, 4.22, 4.23, and 4.24.
</p>
<p>126 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Fig. 4.21
XOR and XNOR checkerboard patterns observed in K-maps (2-input)
</p>
<p>Fig. 4.22
XOR and XNOR checkerboard patterns observed in K-maps (3-input)
</p>
<p>Fig. 4.23
XOR checkerboard pattern observed in K-maps (4-input)
</p>
<p>4.4 Logic Minimization &bull; 127</p>
<p/>
</div>
<div class="page"><p/>
<p>CC4.4(a) Logic minimization is accomplished by removing variables from the original canonical 
</p>
<p>logic expression that don&rsquo;t impact the result.  How does a Karnaugh map graphically 
show what variables can be removed?
</p>
<p>A) K-maps contain the same information as a truth table but the data is formatted as 
a grid.  This allows variables to be removed by inspection.
</p>
<p>B) K-maps rearrange a truth table so that adjacent cells have one and only one 
input variable changing at a time.  If adjacent cells have the same output value 
when an input variable is both a 0 and a 1, that variable has no impact on the 
interim result and can be eliminated.
</p>
<p>C) K-maps list both the rows with outputs of 1's and 0's simultaneously.  This allows 
minimization to occur for a SOP and POS topology that each have the same, but 
minimal, number of gates.
</p>
<p>D) K-maps display the truth table information in a grid format, which is a more 
compact way of presenting the behavior of a circuit.
</p>
<p>CC4.4(b) A &ldquo;Don&rsquo;t Care&rdquo; can be used to minimize a logic expression by assigning the output of a 
</p>
<p>row to either a 1 or a 0 in order to form larger groupings within a K-map.  How does the 
output of the circuit behave when it processes the input code for a row containing a 
don&rsquo;t care?
</p>
<p>A) The output will be whatever value was needed to form the largest grouping in the 
K-map.
</p>
<p>B) The output will go to either a 0 or a 1, but the final value is random.
</p>
<p>C) The output can toggle between a 0 and a 1 when this input code is present. 
</p>
<p>D) The output will be driven to exactly halfway between a 0 and a 1.
</p>
<p>CONCEPT CHECK
</p>
<p>Fig. 4.24
XNOR checkerboard pattern observed in K-maps (4-input)
</p>
<p>128 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>4.5 Timing Hazards and Glitches
</p>
<p>Timing hazards, or glitches, refer to unwanted transitions on the output of a combinational logic
</p>
<p>circuit. These are most commonly due to different delay paths through the gates in the circuit. In real
</p>
<p>circuitry there is always a finite propagation delay through each gate. Consider the circuit shown in
</p>
<p>Fig. 4.25 where gate delays are included and how they can produce unwanted transitions.
</p>
<p>These timing hazards are given unique names based on the type of transition that occurs. A static
</p>
<p>0 timing hazard is when the input switches between two input codes that both yield an output of 0 but the
</p>
<p>output momentarily switches to a 1. A static 1 timing hazard is when the input switches between two
</p>
<p>Fig. 4.25
Examining the source of a timing hazard (or glitch) in a combinational logic circuit
</p>
<p>4.5 Timing Hazards and Glitches &bull; 129</p>
<p/>
</div>
<div class="page"><p/>
<p>input codes that both yield an output of 1 but the output momentarily switches to a 0. A dynamic hazard
</p>
<p>is when the input switches between two input codes that result in a real transition on the output (i.e., 0 to
</p>
<p>1 or 1 to 0), but the output has a momentary glitch before reaching its final value. These definitions are
</p>
<p>shown in Fig. 4.26.
</p>
<p>Timing hazards can be addressed in a variety of ways. One way is to try to match the propagation
</p>
<p>delays through each path of the logic circuit. This can be difficult, particularly in modern logic families
</p>
<p>such as CMOS. In the example in Fig. 4.25, the root cause of the different propagation delays was due to
</p>
<p>an inverter on one of the variables. It seems obvious that this could be addressed by putting buffers on
</p>
<p>the other inputs with equal delays as the inverter. This would create a situation where all input codes
</p>
<p>would arrive at the first stage of AND gates at the same time regardless of whether they were inverted or
</p>
<p>not and eliminate the hazards; however, CMOS implements a buffer as two inverters in series, so it is
</p>
<p>difficult to insert a buffer in a circuit with an equal delay to an inverter. Addressing timing hazards in this
</p>
<p>way is possible, but it involves a time-consuming and tedious process of adjusting the transistors used to
</p>
<p>create the buffer and inverter to have equal delays.
</p>
<p>Another technique to address timing hazards is to place additional circuitry in the system that will
</p>
<p>ensure the correct output while the input codes switch. Consider how including a nonessential prime
</p>
<p>implicant can eliminate a timing hazard in Example 4.31. In this approach, the minimal sum from Fig. 4.25
</p>
<p>is instead replaced with the complete sum. The use of the complete sum instead of the minimal sum can
</p>
<p>be shown to eliminate both static and dynamic timing hazards. The drawback of this approach is the
</p>
<p>addition of extra circuitry in the combinational logic circuit (i.e., nonessential prime implicants).
</p>
<p>Fig. 4.26
Timing hazard definitions
</p>
<p>130 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 4.31
Eliminating a Timing Hazard by Including Nonessential Product Terms
</p>
<p>CC4.5 How long do you need to wait for all hazards to settle out?
</p>
<p>A) The time equal to the delay through the non-essential prime implicants.
</p>
<p>B) The time equal to the delay through the essential prime implicants.
</p>
<p>C) The time equal to the shortest delay path in the circuit.
</p>
<p>D) The time equal to the longest delay path in the circuit.
</p>
<p>CONCEPT CHECK
</p>
<p>4.5 Timing Hazards and Glitches &bull; 131</p>
<p/>
</div>
<div class="page"><p/>
<p>Summary
</p>
<p>v Boolean algebra defines the axioms and
theorems that guide the operations that can
be performed on a two-valued number
system.
</p>
<p>v Boolean algebra theorems allow logic
expressions to be manipulated to make cir-
cuit synthesis simpler. They also allow logic
expressions to be minimized.
</p>
<p>v The delay of a combinational logic circuit is
always dictated by the longest delay path
from the inputs to the output.
</p>
<p>v The canonical form of a logic expression is
one that has not been minimized.
</p>
<p>v A canonical sum of products form is a logic
synthesis technique based on minterms. A
minterm is a product term that will output a
one for only one unique input code. A
minterm is used for each row of a truth table
corresponding to an output of a one. Each of
the minterms is then summed together to
create the final system output.
</p>
<p>v A minterm list is a shorthand way of describ-
ing the information in a truth table. The sym-
bol &ldquo;Σ&rdquo; is used to denote a minterm list. Each
of the input variables is added to this symbol
as comma-delimited subscripts. The row
number is then listed for each row
corresponding to an output of a one.
</p>
<p>v A canonical product of sums form is a logic
synthesis technique based on maxterms. A
maxterm is a sum term that will output a zero
for only one unique input code. A maxterm is
used for each row of a truth table
corresponding to an output of a zero. Each
of the maxterms is then multiplied together to
create the final system output.
</p>
<p>v Amaxterm list is a shorthand way of describ-
ing the information in a truth table. The sym-
bol &ldquo;Π&rdquo; is used to denote a maxterm list. Each
of the input variables is added to this symbol
as comma-delimited subscripts. The row
number is then listed for each row
corresponding to an output of a zero.
</p>
<p>v Canonical logic expressions can be
minimized through a repetitive process of
factoring common variables using the distrib-
utive property and then eliminating remaining
variables using a combination of the
complements and identity theorems.
</p>
<p>v A Karnaugh map (K-map) is a graphical
approach to minimizing logic expressions. A
K-map arranges a truth table into a grid in
which the neighboring cells have input codes
that differ by only one bit. This allows the
impact of an input variable on a group of
outputs to be quickly identified.
</p>
<p>v Aminimized sum of products expression can
be found from a K-map by circling neighbor-
ing ones to form groups that can be produced
by a single product term. Each product term
(aka prime implicant) is then summed
together to form the circuit output.
</p>
<p>v Aminimized product of sums expression can
be found from a K-map by circling neighbor-
ing zeros to form groups that can be pro-
duced by a single sum term. Each sum term
(aka prime implicant) is then multiplied
together to form the circuit output.
</p>
<p>v A minimal sum or minimal product is a logic
expression that contains only essential prime
implicants and represents the smallest num-
ber of logic operations possible to produce
the desired output.
</p>
<p>v A don&rsquo;t care (X) can be used when the output
of a truth table row can be either a zero or a
one without affecting the system behavior.
This typically occurs when some of the input
codes of a truth table will never occur. The
value for the row of a truth table containing a
don&rsquo;t care output can be chosen to give the
most minimal logic expression. In a K-map,
don&rsquo;t cares can be included to form the larg-
est groupings in order to give the least
amount of logic.
</p>
<p>v While exclusive-OR gates are not used in
Boolean algebra, they can be visually
identified in K-maps by looking for checker-
board patterns.
</p>
<p>v Timing hazards are temporary glitches that
occur on the output of a combinational logic
circuit due to timing mismatches through dif-
ferent paths in the circuit. Hazards can be
minimized by including additional circuitry in
the system or by matching the delay of all
signal paths.
</p>
<p>132 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Exercise Problems
</p>
<p>Section 4.1: Boolean Algebra
</p>
<p>4.1.1 Which Boolean algebra theorem describes the
situation where any variable OR&rsquo;d with itself
will yield itself?
</p>
<p>4.1.2 Which Boolean algebra theorem describes the
situation where any variable that is double
complemented will yield itself?
</p>
<p>4.1.3 Which Boolean algebra theorem describes the
situation where any variable OR&rsquo;d with a 1 will
yield a 1?
</p>
<p>4.1.4 Which Boolean algebra theorem describes the
situation where a variable that exists in multiple
product terms can be factored out?
</p>
<p>4.1.5 Which Boolean algebra theorem describes the
situation where when output(s) corresponding
to a term within an expression are handled by
another term the original term can be
removed?
</p>
<p>4.1.6 Which Boolean algebra theorem describes the
situation where any variable AND&rsquo;d with its
complement will yield a 0?
</p>
<p>4.1.7 Which Boolean algebra theorem describes the
situation where any variable AND&rsquo;d with a 0 will
yield a 0?
</p>
<p>4.1.8 Which Boolean algebra theorem describes the
situation where an AND gate with its inputs
inverted is equivalent to an OR gate with its
outputs inverted?
</p>
<p>4.1.9 Which Boolean algebra theorem describes the
situation where a variable that exists in multiple
sum terms can be factored out?
</p>
<p>4.1.10 Which Boolean algebra theorem describes the
situation where an OR gate with its inputs
inverted is equivalent to an AND gate with its
outputs inverted?
</p>
<p>4.1.11 Which Boolean algebra theorem describes the
situation where the grouping of variables in an
OR operation does not affect the result?
</p>
<p>4.1.12 Which Boolean algebra theorem describes the
situation where any variable AND&rsquo;d with itself
will yield itself?
</p>
<p>4.1.13 Which Boolean algebra theorem describes the
situation where the order of variables in an OR
operation does not affect the result?
</p>
<p>4.1.14 Which Boolean algebra theorem describes the
situation where any variable AND&rsquo;d with a 1 will
yield itself?
</p>
<p>4.1.15 Which Boolean algebra theorem describes the
situation where the grouping of variables in an
AND operation does not affect the result?
</p>
<p>4.1.16 Which Boolean algebra theorem describes the
situation where any variable OR&rsquo;d with its com-
plement will yield a 1?
</p>
<p>4.1.17 Which Boolean algebra theorem describes the
situation where the order of variables in an
AND operation does not affect the result?
</p>
<p>4.1.18 Which Boolean algebra theorem describes the
situation where a variable OR&rsquo;d with a 0 will
yield itself?
</p>
<p>4.1.19 Use proof by exhaustion to prove that an OR
gate with its inputs inverted is equivalent to an
AND gate with its outputs inverted.
</p>
<p>4.1.20 Use proof by exhaustion to prove that an AND
gate with its inputs inverted is equivalent to an
OR gate with its outputs inverted.
</p>
<p>Section 4.2: Combinational LogicAnalysis
</p>
<p>4.2.1 For the logic diagram given in Fig. 4.27, give
the logic expression for the output F.
</p>
<p>4.2.2 For the logic diagram given in Fig. 4.27, give
the truth table for the output F.
</p>
<p>4.2.3 For the logic diagram given in Figure 4.27, give
the delay.
</p>
<p>4.2.4 For the logic diagram given in Fig. 4.28, give
the logic expression for the output F.
</p>
<p>4.2.5 For the logic diagram given in Fig. 4.28, give
the truth table for the output F.
</p>
<p>4.2.6 For the logic diagram given in Fig. 4.28, give
the delay.
</p>
<p>4.2.7 For the logic diagram given in Fig. 4.29, give
the logic expression for the output F.
</p>
<p>Fig. 4.27
</p>
<p>Combinational Logic Analysis 1
</p>
<p>Fig. 4.28
</p>
<p>Combinational Logic Analysis 2
</p>
<p>Fig. 4.29
</p>
<p>Combinational Logic Analysis 3
</p>
<p>Exercise Problems &bull; 133</p>
<p/>
</div>
<div class="page"><p/>
<p>4.2.8 For the logic diagram given in Fig. 4.29, give
the truth table for the output F.
</p>
<p>4.2.9 For the logic diagram given in Fig. 4.29, give
the delay.
</p>
<p>Section 4.3: Combinational Logic
</p>
<p>Synthesis
</p>
<p>4.3.1 For the 2-input truth table in Fig. 4.30, give the
canonical sum of products (SOP) logic expres-
sion.
</p>
<p>4.3.2 For the 2-input truth table in Fig. 4.30, give the
canonical sum of products (SOP) logic
diagram.
</p>
<p>4.3.3 For the 2-input truth table in Fig. 4.30, give the
minterm list.
</p>
<p>4.3.4 For the 2-input truth table in Fig. 4.30, give the
canonical product of sums (POS) logic
expression.
</p>
<p>4.3.5 For the 2-input truth table in Fig. 4.30, give the
canonical product of sums (POS) logic
diagram.
</p>
<p>4.3.6 For the 2-input truth table in Fig. 4.30, give the
maxterm list.
</p>
<p>4.3.7 For the 2-input minterm list in Fig. 4.31, give
the canonical sum of products (SOP) logic
expression.
</p>
<p>4.3.8 For the 2-input minterm list in Fig. 4.31, give
the canonical sum of products (SOP) logic
diagram.
</p>
<p>4.3.9 For the 2-input minterm list in Fig. 4.31, give
the truth table.
</p>
<p>4.3.10 For the 2-input minterm list in Fig. 4.31, give
the canonical product of sums (POS) logic
expression.
</p>
<p>4.3.11 For the 2-input minterm list in Fig. 4.31, give
the canonical product of sums (POS) logic
diagram.
</p>
<p>4.3.12 For the 2-input minterm list in Fig. 4.31, give
the maxterm list.
</p>
<p>4.3.13 For the 2-input maxterm list in Fig. 4.32, give
the canonical sum of products (SOP) logic
expression.
</p>
<p>4.3.14 For the 2-input maxterm list in Fig. 4.32, give
the canonical sum of products (SOP) logic
diagram.
</p>
<p>4.3.15 For the 2-input maxterm list in Fig. 4.32, give
the minterm list.
</p>
<p>4.3.16 For the 2-input maxterm list in Fig. 4.32, give
the canonical product of sums (POS) logic
expression.
</p>
<p>4.3.17 For the 2-input maxterm list in Fig. 4.32, give
the canonical product of sums (POS) logic
diagram.
</p>
<p>4.3.18 For the 2-input maxterm list in Fig. 4.32, give
the truth table.
</p>
<p>4.3.19 For the 3-input truth table in Fig. 4.33, give the
canonical sum of products (SOP) logic
expression.
</p>
<p>4.3.20 For the 3-input truth table in Fig. 4.33, give the
canonical sum of products (SOP) logic
diagram.
</p>
<p>4.3.21 For the 3-input truth table in Fig. 4.33, give the
minterm list.
</p>
<p>4.3.22 For the 3-input truth table in Fig. 4.33, give the
canonical product of sums (POS) logic
expression.
</p>
<p>4.3.23 For the 3-input truth table in Fig. 4.33, give the
canonical product of sums (POS) logic
diagram.
</p>
<p>4.3.24 For the 3-input truth table in Fig. 4.33, give the
maxterm list.
</p>
<p>4.3.25 For the 3-input minterm list in Fig. 4.34, give
the canonical sum of products (SOP) logic
expression.
</p>
<p>4.3.26 For the 3-input minterm list in Fig. 4.34, give
the canonical sum of products (SOP) logic
diagram.
</p>
<p>Fig. 4.32
</p>
<p>Combinational Logic Synthesis 3
</p>
<p>Fig. 4.33
</p>
<p>Combinational Logic Synthesis 4
</p>
<p>Fig. 4.34
</p>
<p>Combinational Logic Synthesis 5
</p>
<p>Fig. 4.31
</p>
<p>Combinational Logic Synthesis 2
</p>
<p>Fig. 4.30
</p>
<p>Combinational Logic Synthesis 1
</p>
<p>134 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>4.3.27 For the 3-input minterm list in Fig. 4.34, give
the truth table.
</p>
<p>4.3.28 For the 3-input minterm list in Fig. 4.34, give
the canonical product of sums (POS) logic
expression.
</p>
<p>4.3.29 For the 3-input minterm list in Fig. 4.34, give
the canonical product of sums (POS) logic
diagram.
</p>
<p>4.3.30 For the 3-input minterm list in Fig. 4.34, give
the maxterm list.
</p>
<p>4.3.31 For the 3-input maxterm list in Fig. 4.35, give
the canonical sum of products (SOP) logic
expression.
</p>
<p>4.3.32 For the 3-input maxterm list in Fig. 4.35, give
the canonical sum of products (SOP) logic
diagram.
</p>
<p>4.3.33 For the 3-input maxterm list in Fig. 4.35, give
the minterm list.
</p>
<p>4.3.34 For the 3-input maxterm list in Fig. 4.35, give
the canonical product of sums (POS) logic
expression.
</p>
<p>4.3.35 For the 3-input maxterm list in Fig. 4.35, give
the canonical product of sums (POS) logic
diagram.
</p>
<p>4.3.36 For the 3-input maxterm list in Fig. 4.35, give
the truth table.
</p>
<p>4.3.37 For the 4-input truth table in Fig. 4.36, give the
canonical sum of products (SOP) logic expres-
sion.
</p>
<p>4.3.38 For the 4-input truth table in Fig. 4.36, give the
canonical sum of products (SOP) logic
diagram.
</p>
<p>4.3.39 For the 4-input truth table in Fig. 4.36, give the
minterm list.
</p>
<p>4.3.40 For the 4-input truth table in Fig. 4.36, give the
canonical product of sums (POS) logic
expression.
</p>
<p>4.3.41 For the 4-input truth table in Fig. 4.36, give the
canonical product of sums (POS) logic
diagram.
</p>
<p>4.3.42 For the 4-input truth table in Fig. 4.36, give the
maxterm list.
</p>
<p>4.3.43 For the 4-input minterm list in Fig. 4.37, give
the canonical sum of products (SOP) logic
expression.
</p>
<p>4.3.44 For the 4-input minterm list in Fig. 4.37, give
the canonical sum of products (SOP) logic
diagram.
</p>
<p>4.3.45 For the 4-input minterm list in Fig. 4.37, give
the truth table.
</p>
<p>4.3.46 For the 4-input minterm list in Fig. 4.37, give
the canonical product of sums (POS) logic
expression.
</p>
<p>4.3.47 For the 4-input minterm list in Fig. 4.37, give
the canonical product of sums (POS) logic
diagram.
</p>
<p>4.3.48 For the 4-input minterm list in Fig. 4.37, give
the maxterm list.
</p>
<p>4.3.49 For the 4-input maxterm list in Fig. 4.38, give
the canonical sum of products (SOP) logic
expression.
</p>
<p>4.3.50 For the 4-input maxterm list in Fig. 4.38, give
the canonical sum of products (SOP) logic
diagram.
</p>
<p>4.3.51 For the 4-input maxterm list in Fig. 4.38, give
the minterm list.
</p>
<p>4.3.52 For the 4-input maxterm list in Fig. 4.38, give
the canonical product of sums (POS) logic
expression.
</p>
<p>4.3.53 For the 4-input maxterm list in Fig. 4.38, give
the canonical product of sums (POS) logic
diagram.
</p>
<p>4.3.54 For the 4-input maxterm list in Fig. 4.38, give
the truth table.
</p>
<p>Section 4.4: Logic Minimization
</p>
<p>4.4.1 For the 2-input truth table in Fig. 4.39, use a
K-map to derive a minimized sum of products
(SOP) logic expression.
</p>
<p>Fig. 4.35
</p>
<p>Combinational Logic Synthesis 6
</p>
<p>Fig. 4.36
</p>
<p>Combinational Logic Synthesis 7
</p>
<p>Fig. 4.37
</p>
<p>Combinational Logic Synthesis 8
</p>
<p>Fig. 4.38
</p>
<p>Combinational Logic Synthesis 9
</p>
<p>Exercise Problems &bull; 135</p>
<p/>
</div>
<div class="page"><p/>
<p>4.4.2 For the 2-input truth table in Fig. 4.39, use a
K-map to derive a minimized product of sums
(POS) logic expression.
</p>
<p>4.4.3 For the 2-input truth table in Fig. 4.40, use a
K-map to derive a minimized sum of products
(SOP) logic expression.
</p>
<p>4.4.4 For the 2-input truth table in Fig. 4.41, use a
K-map to derive a minimized product of sums
(POS) logic expression.
</p>
<p>4.4.5 For the 2-input truth table in Fig. 4.42, use a
K-map to derive a minimized sum of products
(SOP) logic expression.
</p>
<p>4.4.6 For the 2-input truth table in Fig. 4.42, use a
K-map to derive a minimized product of sums
(POS) logic expression.
</p>
<p>4.4.7 For the 3-input truth table in Fig. 4.43, use a
K-map to derive a minimized sum of products
(SOP) logic expression.
</p>
<p>4.4.8 For the 3-input truth table in Fig. 4.43, use a
K-map to derive a minimized product of sums
(POS) logic expression.
</p>
<p>4.4.9 For the 3-input truth table in Fig. 4.44, use a
K-map to derive a minimized sum of products
(SOP) logic expression.
</p>
<p>4.4.10 For the 3-input truth table in Fig. 4.44, use a
K-map to derive a minimized product of sums
(POS) logic expression.
</p>
<p>4.4.11 For the 3-input truth table in Fig. 4.45, use a
K-map to derive a minimized sum of products
(SOP) logic expression.
</p>
<p>4.4.12 For the 3-input truth table in Fig. 4.45, use a
K-map to derive a minimized product of sums
(POS) logic expression.
</p>
<p>4.4.13 For the 3-input truth table in Fig. 4.46, use a
K-map to derive a minimized sum of products
(SOP) logic expression.
</p>
<p>Fig. 4.39
</p>
<p>Logic Minimization 1
</p>
<p>Fig. 4.40
</p>
<p>Logic Minimization 2
</p>
<p>Fig. 4.41
</p>
<p>Logic Minimization 3
</p>
<p>Fig. 4.42
</p>
<p>Logic Minimization 4
</p>
<p>Fig. 4.43
</p>
<p>Logic Minimization 5
</p>
<p>Fig. 4.44
</p>
<p>Logic Minimization 6
</p>
<p>Fig. 4.45
</p>
<p>Logic Minimization 7
</p>
<p>Fig. 4.46
</p>
<p>Logic Minimization 8
</p>
<p>136 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>4.4.14 For the 3-input truth table in Fig. 4.46, use a
K-map to derive a minimized product of sums
(POS) logic expression.
</p>
<p>4.4.15 For the 4-input truth table in Fig. 4.47, use a
K-map to derive a minimized sum of products
(SOP) logic expression.
</p>
<p>4.4.16 For the 4-input truth table in Fig. 4.47, use a
K-map to derive a minimized product of sums
(POS) logic expression.
</p>
<p>4.4.17 For the 4-input truth table in Fig. 4.48, use a
K-map to derive a minimized sum of products
(SOP) logic expression.
</p>
<p>4.4.18 For the 4-input truth table in Fig. 4.48, use a
K-map to derive a minimized product of sums
(POS) logic expression.
</p>
<p>4.4.19 For the 4-input truth table in Fig. 4.49, use a
K-map to derive a minimized sum of products
(SOP) logic expression.
</p>
<p>4.4.20 For the 4-input truth table in Fig. 4.49, use a
K-map to derive a minimized product of sums
(POS) logic expression.
</p>
<p>4.4.21 For the 4-input truth table in Fig. 4.50, use a
K-map to derive a minimized sum of products
(SOP) logic expression.
</p>
<p>4.4.22 For the 4-input truth table in Fig. 4.50, use a
K-map to derive a minimized product of sums
(POS) logic expression.
</p>
<p>4.4.23 For the 3-input truth table and K-map in
Fig. 4.51, provide the row number(s) of any
distinguished one-cells.
</p>
<p>Fig. 4.47
</p>
<p>Logic Minimization 9
</p>
<p>Fig. 4.48
</p>
<p>Logic Minimization 10
</p>
<p>Fig. 4.49
</p>
<p>Logic Minimization 11
</p>
<p>Fig. 4.50
</p>
<p>Logic Minimization 12
</p>
<p>Fig. 4.51
</p>
<p>Logic Minimization 13
</p>
<p>Exercise Problems &bull; 137</p>
<p/>
</div>
<div class="page"><p/>
<p>4.4.24 For the 3-input truth table and K-map in
Fig. 4.51, give the product terms for the essen-
tial prime implicants.
</p>
<p>4.4.25 For the 3-input truth table and K-map in
Fig. 4.51, give the minimal sum of products
logic expression.
</p>
<p>4.4.26 For the 3-input truth table and K-map in
Fig. 4.51, give the complete sum of products
logic expression.
</p>
<p>4.4.27 For the 4-input truth table and K-map in
Fig. 4.52, provide the row number(s) of any
distinguished one-cells.
</p>
<p>4.4.28 For the 4-input truth table and K-map in
Fig. 4.52, give the product terms for the essen-
tial prime implicants.
</p>
<p>4.4.29 For the 4-input truth table and K-map in
Fig. 4.52, give the minimal sum of products
(SOP) logic expression.
</p>
<p>4.4.30 For the 4-input truth table and K-map in
Fig. 4.52, give the complete sum of products
(SOP) logic expression.
</p>
<p>4.4.31 For the 4-input truth table and K-map in
Fig. 4.53, give the minimal sum of products
(SOP) logic expression by exploiting &ldquo;don&rsquo;t
cares.&rdquo;
</p>
<p>4.4.32 For the 4-input truth table and K-map in
Fig. 4.53, give the minimal product of sums
(POS) logic expression by exploiting &ldquo;don&rsquo;t
cares.&rdquo;
</p>
<p>4.4.33 For the 4-input truth table and K-map in
Fig. 4.54, give the minimal product of sums
(POS) logic expression by exploiting &ldquo;don&rsquo;t
cares.&rdquo;
</p>
<p>4.4.34 For the 4-input truth table and K-map in
Fig. 4.54, give the minimal product of sums
(POS) logic expression by exploiting &ldquo;don&rsquo;t
cares&rdquo;.
</p>
<p>Section 4.5: Timing Hazards and Glitches
</p>
<p>4.5.1 Describe the situation in which a static-1 timing
hazard may occur.
</p>
<p>4.5.2 Describe the situation in which a static-0 timing
hazard may occur.
</p>
<p>4.5.3 In which topology will a static-1 timing hazard
occur (SOP, POS, or both)?
</p>
<p>4.5.4 In which topology will a static-0 timing hazard
occur (SOP, POS, or both)?
</p>
<p>4.5.5 For the 3-input truth table and K-map in
Fig. 4.51, give the product term that helps
eliminate static-1 timing hazards in this circuit.
</p>
<p>4.5.6 For the 3-input truth table and K-map in
Fig. 4.51, give the sum term that helps elimi-
nate static-0 timing hazards in this circuit.
</p>
<p>4.5.7 For the 4-input truth table and K-map in
Fig. 4.52, give the product term that helps
eliminate static-1 timing hazards in this circuit.
</p>
<p>4.5.8 For the 4-input truth table and K-map in
Fig. 4.52, give the sum term that helps elimi-
nate static-0 timing hazards in this circuit.
</p>
<p>Fig. 4.52
</p>
<p>Logic Minimization 14
</p>
<p>Fig. 4.53
</p>
<p>Logic Minimization 15
</p>
<p>Fig. 4.54
</p>
<p>Logic Minimization 16
</p>
<p>138 &bull; Chapter 4: Combinational Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 5: VHDL (Part 1)
Based on the material presented in Chap. 4, there are a few observations about logic design that are
</p>
<p>apparent. First, the size of logic circuitry can scale quickly to the point where it is difficult to design by
</p>
<p>hand. Second, the process of moving from a high-level description of how a circuit works (e.g., a truth
</p>
<p>table) to a form that is ready to be implemented with real circuitry (e.g., a minimized logic diagram) is
</p>
<p>straightforward and well defined. Both of these observations motivate the use of computer-aided design
</p>
<p>(CAD) tools to accomplish logic design. This chapter introduces hardware description languages (HDLs)
</p>
<p>as a means to describe digital circuitry using a text-based language. HDLs provide a means to describe
</p>
<p>large digital systems without the need for schematics, which can become impractical in very large
</p>
<p>designs. HDLs have evolved to support logic simulation at different levels of abstraction. This provides
</p>
<p>designers the ability to begin designing and verifying functionality of large systems at a high level of
</p>
<p>abstraction and postpone the details of the circuit implementation until later in the design cycle. This
</p>
<p>enables a top-down design approach that is scalable across different logic families. HDLs have also
</p>
<p>evolved to support automated synthesis, which allows the CAD tools to take a functional description of a
</p>
<p>system (e.g., a truth table) and automatically create the gate-level circuitry to be implemented in real
</p>
<p>hardware. This allows designers to focus their attention on designing the behavior of a system and not
</p>
<p>spend as much time performing the formal logic synthesis steps that were presented in Chap. 4. The
</p>
<p>intent of this chapter is to introduce HDLs and their use in the modern digital design flow. This chapter
</p>
<p>covers the basics of designing combinational logic in an HDL and also hierarchical design. The more
</p>
<p>advanced concepts of HDLs such as sequential logic design, high-level abstraction, and adding func-
</p>
<p>tionality to an HDL through additional libraries and packages are covered later so that the reader can get
</p>
<p>started quickly using HDLs to gain experience with the languages and design flow.
</p>
<p>There are two dominant hardware description languages in use today. They are VHDL and Verilog.
</p>
<p>VHDL stands for very high speed integrated circuit hardware description language. Verilog is not an
</p>
<p>acronym but rather a trade name. The use of these two HDLs is split nearly equally within the digital
</p>
<p>design industry. Once one language is learned it is simple to learn the other language, so the choice of
</p>
<p>the HDL to learn first is somewhat arbitrary. In this text we use VHDL to learn the concepts of an HDL.
</p>
<p>VHDL is stricter in its syntax and typecasting than Verilog, so it is a good platform for beginners as it
</p>
<p>provides more of a scaffold for the description of circuits. This helps avoid some of the common pitfalls
</p>
<p>that beginners typically encounter. The goal of this chapter is to provide an understanding of the basic
</p>
<p>principles of hardware description languages.
</p>
<p>Learning Outcomes&mdash;After completing this chapter, you will be able to:
</p>
<p>5.1 Describe the role of hardware description languages in modern digital design.
5.2 Describe the fundamentals of design abstraction in modern digital design.
5.3 Describe the modern digital design flow based on hardware description languages.
5.4 Describe the fundamental constructs of VHDL.
5.5 Design a VHDL model for a combinational logic circuit using concurrent modeling
</p>
<p>techniques (signal assignments and logical operators, conditional signal assignments,
and selected signal assignments).
</p>
<p>5.6 Design a VHDL model for a combinational logic circuit using a structural design approach.
5.7 Describe the role of a VHDL test bench.
</p>
<p>5.1 History of Hardware Description Languages
</p>
<p>The invention of the integrated circuit is most commonly credited to two individuals who filed patents
</p>
<p>on different variations of the same basic concept within 6 months of each other in 1959. Jack Kilby filed
</p>
<p># Springer International Publishing Switzerland 2017
</p>
<p>B.J. LaMeres, Introduction to Logic Circuits &amp; Logic Design with VHDL,
</p>
<p>DOI 10.1007/978-3-319-34195-8_5
</p>
<p>139</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_4">http://dx.doi.org/10.1007/978-3-319-34195-8_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_4">http://dx.doi.org/10.1007/978-3-319-34195-8_4</a></div>
</div>
<div class="page"><p/>
<p>the first patent on the integrated circuit in February of 1959 titled &ldquo;Miniaturized Electronic Circuits&rdquo; while
</p>
<p>working for Texas Instruments. Robert Noyce was the second to file a patent on the integrated circuit in
</p>
<p>July of 1959 titled &ldquo;Semiconductor Device and Lead Structure&rdquo; while at a company he cofounded called
</p>
<p>Fairchild Semiconductor. Kilby went on to win the Nobel Prize in Physics in 2000 for his invention, while
</p>
<p>Noyce went on to cofound Intel Corporation in 1968 with Gordon Moore. In 1971, Intel introduced the first
</p>
<p>single-chip microprocessor using integrated circuit technology, the Intel 4004. This microprocessor IC
</p>
<p>contained 2300 transistors. This series of inventions launched the semiconductor industry, which was
</p>
<p>the driving force behind the growth of Silicon Valley, and led to 40 years of unprecedented advancement
</p>
<p>in technology that has impacted every aspect of the modern world.
</p>
<p>Gordon Moore, cofounder of Intel, predicted in 1965 that the number of transistors on an integrated
</p>
<p>circuit would double every 2 years. This prediction, now known as Moore&rsquo;s law, has held true since the
</p>
<p>invention of the integrated circuit. As the number of transistors on an integrated circuit grew, so did the
</p>
<p>size of the design and the functionality that could be implemented. Once the first microprocessor was
</p>
<p>invented in 1971, the capability of CAD tools increased rapidly enabling larger designs to be accom-
</p>
<p>plished. These larger designs, including newer microprocessors, enabled the CAD tools to become even
</p>
<p>more sophisticated and, in turn, yield even larger designs. The rapid expansion of electronic systems
</p>
<p>based on digital integrated circuits required that different manufacturers needed to produce designs that
</p>
<p>were compatible with each other. The adoption of logic family standards helped manufacturers ensure
</p>
<p>that their parts would be compatible with other manufacturers at the physical layer (e.g., voltage and
</p>
<p>current); however, one challenge that was encountered by the industry was a way to document the
</p>
<p>complex behavior of larger systems. The use of schematics to document large digital designs became
</p>
<p>too cumbersome and difficult to understand by anyone besides the designer. Word descriptions of the
</p>
<p>behavior were easier to understand, but even this form of documentation became too voluminous to be
</p>
<p>effective for the size of designs that were emerging.
</p>
<p>In 1983, the US Department of Defense (DoD) sponsored a program to create a means to document
</p>
<p>the behavior of digital systems that could be used across all of its suppliers. This program was motivated
</p>
<p>by a lack of adequate documentation for the functionality of application-specific integrated circuits
</p>
<p>(ASICs) that were being supplied to the DoD. This lack of documentation was becoming a critical
</p>
<p>issue as ASICs would come to the end of their life cycle and need to be replaced. With the lack of a
</p>
<p>standardized documentation approach, suppliers had difficulty reproducing equivalent parts to those that
</p>
<p>had become obsolete. The DoD contracted three companies (Texas Instruments, IBM, and Intermetrics)
</p>
<p>to develop a standardized documentation tool that provided detailed information about both the interface
</p>
<p>(i.e., inputs and outputs) and the behavior of digital systems. The new tool was to be implemented in a
</p>
<p>format similar to a programming language. Due to the nature of this type of language-based tool, it was a
</p>
<p>natural extension of the original project scope to include the ability to simulate the behavior of a digital
</p>
<p>system. The simulation capability was desired to span multiple levels of abstraction to provide maximum
</p>
<p>flexibility. In 1985, the first version of this tool, called VHDL, was released. In order to gain widespread
</p>
<p>adoption and ensure consistency of use across the industry, VHDL was turned over to the Institute of
</p>
<p>Electrical and Electronic Engineers (IEEE) for standardization. IEEE is a professional association that
</p>
<p>defines a broad range of open technology standards. In 1987, IEEE released the first industry standard
</p>
<p>version of VHDL. The release was titled IEEE 1076-1987. Feedback from the initial version resulted in a
</p>
<p>major revision of the standard in 1993 titled IEEE 1076-1993. While many minor revisions have been
</p>
<p>made to the 1993 release, the 1076-1993 standard contains the vast majority of VHDL functionality in
</p>
<p>use today. The most recent VHDL standard is IEEE 1076-2008.
</p>
<p>Also in 1983, the Verilog HDL was developed by Automated Integrated Design Systems as a logic
</p>
<p>simulation language. The development of Verilog took place completely independent from the VHDL
</p>
<p>project. Automated Integrated Design Systems (renamed Gateway Design Automation in 1985) was
</p>
<p>acquired by CAD tool vendor Cadence Design Systems in 1990. In response to the rapid adoption of the
</p>
<p>140 &bull; Chapter 5: VHDL (Part 1)</p>
<p/>
</div>
<div class="page"><p/>
<p>open VHDL standard, Cadence made the Verilog HDL open to the public in order to stay competitive.
</p>
<p>IEEE once again developed the open standard for this HDL, and in 1995 released the Verilog standard
</p>
<p>titled IEEE 1364.
</p>
<p>The development of CAD tools to accomplish automated logic synthesis can be dated back to the
</p>
<p>1970s when IBM began developing a series of practical synthesis engines that were used in the design
</p>
<p>of their mainframe computers; however, the main advancement in logic synthesis came with the founding
</p>
<p>of a company called Synopsis in 1986. Synopsis was the first company to focus on logic synthesis
</p>
<p>directly from HDLs. This was a major contribution because designers were already using HDLs to
</p>
<p>describe and simulate their digital systems, and now logic synthesis became integrated in the same
</p>
<p>design flow. Due to the complexity of synthesizing highly abstract functional descriptions, only lower
</p>
<p>levels of abstraction that were thoroughly elaborated were initially able to be synthesized. As CAD tool
</p>
<p>capability evolved, synthesis of higher levels of abstraction became possible, but even today not all
</p>
<p>functionality that can be described in an HDL can be synthesized.
</p>
<p>The history of HDLs, their standardization, and the creation of the associated logic synthesis tools
</p>
<p>are key to understanding the use and limitations of HDLs. HDLs were originally designed for documen-
</p>
<p>tation and behavioral simulation. Logic synthesis tools were developed independently and modified later
</p>
<p>to work with HDLs. This history provides some background into the most common pitfalls that beginning
</p>
<p>digital designers encounter, that being that most any type of behavior can be described and simulated in
</p>
<p>an HDL, but only a subset of well-described functionality can be synthesized. Beginning digital designers
</p>
<p>are often plagued by issues related to designs that simulate perfectly but that will not synthesize
</p>
<p>correctly. In this book, an effort is made to introduce VHDL at a level that provides a reasonable amount
</p>
<p>of abstraction while preserving the ability to be synthesized. Figure 5.1 shows a timeline of some of the
</p>
<p>major technology milestones that have occurred in the past 150 years in the field of digital logic and
</p>
<p>HDLs.
</p>
<p>5.1 History of Hardware Description Languages &bull; 141</p>
<p/>
</div>
<div class="page"><p/>
<p>CC5.1 Why does VHDL support modeling techniques that aren&rsquo;t synthesizable? 
</p>
<p>A) Since synthesis wasn&rsquo;t within the original scope of the VHDL project, there wasn&rsquo;t 
sufficient time to make everything synthesizable.
</p>
<p>B) At the time VHDL was created, synthesis was deemed too difficult to implement.
</p>
<p>C) To allow VHDL to be used as a generic programming language.
</p>
<p>D) VHDL needs to support all steps in the modern digital design flow, some of which 
are unsynthesizable such as test pattern generation and timing verification.
</p>
<p>CONCEPT CHECK
</p>
<p>Fig. 5.1
Major milestones in the advancement of digital logic and HDLs
</p>
<p>142 &bull; Chapter 5: VHDL (Part 1)</p>
<p/>
</div>
<div class="page"><p/>
<p>5.2 HDL Abstraction
</p>
<p>HDLs were originally defined to be able to model behavior at multiple levels of abstraction.
</p>
<p>Abstraction is an important concept in engineering design because it allows us to specify how systems
</p>
<p>will operate without getting consumed prematurely with implementation details. Also, by removing the
</p>
<p>details of the lower level implementation, simulations can be conducted in reasonable amounts of time to
</p>
<p>model the higher level functionality. If a full computer system was simulated using detailed models for
</p>
<p>every MOSFET, it would take an impracticable amount of time to complete. Figure 5.2 shows a graphical
</p>
<p>depiction of the different layers of abstraction in digital system design.
</p>
<p>The highest level of abstraction is the system level. At this level, behavior of a system is described
</p>
<p>by stating a set of broad specifications. An example of a design at this level is a specification such as &ldquo;the
</p>
<p>computer system will perform 10 Tera Floating Point Operations per Second (10 TFLOPS) on double
</p>
<p>precision data and consume no more than 100 Watts of power.&rdquo; Notice that these specifications do not
</p>
<p>dictate the lower level details such as the type of logic family or the type of computer architecture to use.
</p>
<p>One level down from the system level is the algorithmic level. At this level, the specifications begin to be
</p>
<p>broken down into subsystems, each with an associated behavior that will accomplish a part of the
</p>
<p>Fig. 5.2
Levels of design abstraction
</p>
<p>5.2 HDL Abstraction &bull; 143</p>
<p/>
</div>
<div class="page"><p/>
<p>primary task. At this level, the example computer specifications might be broken down into subsystems
</p>
<p>such as a central processing unit (CPU) to perform the computation and random access memory (RAM)
</p>
<p>to hold the inputs and outputs of the computation. One level down from the algorithmic level is the
</p>
<p>register transfer level (RTL). At this level, the details of how data is moved between and within
</p>
<p>subsystems are described in addition to how the data is manipulated based on system inputs. One
</p>
<p>level down from the RTL level is the gate level. At this level, the design is described using basic gates and
</p>
<p>registers (or storage elements). The gate level is essentially a schematic (either graphically or text
</p>
<p>based) that contains the components and connections that will implement the functionality from the
</p>
<p>above levels of abstraction. One level down from the gate level is the circuit level. The circuit level
</p>
<p>describes the operation of the basic gates and registers using transistors, wires, and other electrical
</p>
<p>components such as resistors and capacitors. Finally, the lowest level of design abstraction is the
</p>
<p>material level. This level describes how different materials are combined and shaped in order to
</p>
<p>implement the transistors, devices, and wires from the circuit level.
</p>
<p>HDLs are designed to model behavior at all of these levels with the exception of the material level.
</p>
<p>While there is some capability to model circuit-level behavior such as MOSFETs as ideal switches and
</p>
<p>pull-up/pull-down resistors, HDLs are not typically used at the circuit level. Another graphical depiction of
</p>
<p>design abstraction is known as the Gajski and Kuhn&rsquo;s Y-chart. A Y-chart depicts abstraction across
</p>
<p>three different design domains: behavioral, structural, and physical. Each of these design domains
</p>
<p>contains levels of abstraction (i.e., system, algorithm, RTL, gate, and circuit). An example Y-chart is
</p>
<p>shown in Fig. 5.3.
</p>
<p>Fig. 5.3
Y-Chart of design abstraction
</p>
<p>144 &bull; Chapter 5: VHDL (Part 1)</p>
<p/>
</div>
<div class="page"><p/>
<p>A Y-chart also depicts how the abstraction levels of different design domains are related to each
</p>
<p>other. A top-down design flow can be visualized in a Y-chart by spiraling inward in a clockwise direction.
</p>
<p>Moving from the behavioral domain to the structural domain is the process of synthesis. Whenever
</p>
<p>synthesis is performed, the resulting system should be compared with the prior behavioral description.
</p>
<p>This checking is called verification. The process of creating the physical circuitry corresponding to the
</p>
<p>structural description is called implementation. The spiral continues down through the levels of abstrac-
</p>
<p>tion until the design is implemented at a level that the geometries representing circuit elements
</p>
<p>(transistors, wires, etc.) are ready to be fabricated in silicon. Figure 5.4 shows the top-down design
</p>
<p>process depicted as an inward spiral on the Y-chart.
</p>
<p>The Y-chart represents a formal approach for large digital systems. For large systems that are
</p>
<p>designed by teams of engineers, it is critical that a formal, top-down design process is followed to
</p>
<p>eliminate potentially costly design errors as the implementation is carried out at lower levels of
</p>
<p>abstraction.
</p>
<p>Fig. 5.4
Y-Chart illustrating top-down design approach
</p>
<p>5.2 HDL Abstraction &bull; 145</p>
<p/>
</div>
<div class="page"><p/>
<p>CC5.2 Why is abstraction an essential part of engineering design?
</p>
<p>A) Without abstraction all schematics would be drawn at the transistor-level.
</p>
<p>B) Abstraction allows computer programs to aid in the design process.
</p>
<p>C) Abstraction allows the details of the implementation to be hidden while the 
higher-level systems are designed.  Without abstraction, the details of the 
implementation would overwhelm the designer.
</p>
<p>D) Abstraction allows analog circuit designers to include digital blocks in their 
systems.
</p>
<p>CONCEPT CHECK
</p>
<p>5.3 The Modern Digital Design Flow
</p>
<p>When performing a smaller design or the design of fully contained subsystems, the process can be
</p>
<p>broken down into individual steps. These steps are shown in Fig. 5.5. This process is given generically
</p>
<p>and applies to both classical andmodern digital design. The distinction between classical and modern is
</p>
<p>that modern digital design uses HDLs and automated CAD tools for simulation, synthesis, place and
</p>
<p>route, and verification.
</p>
<p>Fig. 5.5
Generic digital design flow
</p>
<p>146 &bull; Chapter 5: VHDL (Part 1)</p>
<p/>
</div>
<div class="page"><p/>
<p>This generic design process flow can be used across classical and modern digital design, although
</p>
<p>modern digital design allows additional verification at each step using automated CAD tools. Figure 5.6
</p>
<p>shows how this flow is used in the classical design approach of a combinational logic circuit.
</p>
<p>Fig. 5.6
Classical digital design flow
</p>
<p>5.3 The Modern Digital Design Flow &bull; 147</p>
<p/>
</div>
<div class="page"><p/>
<p>The modern design flow based on HDLs includes the ability to simulate functionality at each step of
</p>
<p>the process. Functional simulations can be performed on the initial behavioral description of the system.
</p>
<p>At each step of the design process the functionality is described in more detail, ultimately moving toward
</p>
<p>the fabrication step. At each level, the detailed information can be included in the simulation to verify that
</p>
<p>the functionality is still correct and that the design is still meeting the original specifications. Figure 5.7
</p>
<p>shows the modern digital design flow with the inclusion of simulation capability at each step.
</p>
<p>Fig. 5.7
Modern digital design flow
</p>
<p>148 &bull; Chapter 5: VHDL (Part 1)</p>
<p/>
</div>
<div class="page"><p/>
<p>CC5.3 Why did digital designs move from schematic-entry to text-based HDLs?
</p>
<p>A) HDL models could be much larger by describing functionality in text similar to 
traditional programming language.
</p>
<p>B) Schematics required sophisticated graphics hardware to display correctly. 
</p>
<p>C) Schematics symbols became too small as designs became larger.
</p>
<p>D) Text was easier to understand by a broader range of engineers.
</p>
<p>CONCEPT CHECK
</p>
<p>5.4 VHDL Constructs
</p>
<p>Now we begin looking at the details of VHDL. AVHDL design describes a single system in a single
</p>
<p>file. The file has the suffix *.vhd. Within the file, there are two parts that describe the system: the entity
</p>
<p>and the architecture. The entity describes the interface to the system (i.e., the inputs and outputs) and
</p>
<p>the architecture describes the behavior. The functionality of VHDL (e.g., operators, signal types,
</p>
<p>functions) is defined in the package. Packages are grouped within a library. IEEE defines the base
</p>
<p>set of functionality for VHDL in the standard package. This package is contained within a library called
</p>
<p>IEEE. The library and package inclusion is stated at the beginning of a VHDL file before the entity and
</p>
<p>architecture. Additional functionality can be added to VHDL by including other packages, but all
</p>
<p>packages are based on the core functionality defined in the standard package. As a result, it is not
</p>
<p>necessary to explicitly state that a design is using the IEEE standard package because it is inherent in
</p>
<p>the use of VHDL. All functionality described in this chapter is for the IEEE standard package while other
</p>
<p>common packages are covered in Chap. 8. Figure 5.8 shows a graphical depiction of a VHDL file.
</p>
<p>VHDL is not case sensitive. Also, each VHDL assignment, definition, or declaration is terminated
</p>
<p>with a semicolon (;). As such, line wraps are allowed and do not signify the end of an assignment,
</p>
<p>definition, or declaration. Line wraps can be used to make the VHDL more readable. Comments in VHDL
</p>
<p>are preceded with two dashes (i.e., --) and continue until the end of the line. All user-defined names in
</p>
<p>VHDL must start with an alphabetic letter, not a number. User-defined names are not allowed to be the
</p>
<p>Fig. 5.8
The anatomy of a VHDL file
</p>
<p>5.4 VHDL Constructs &bull; 149</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_8">http://dx.doi.org/10.1007/978-3-319-34195-8_8</a></div>
</div>
<div class="page"><p/>
<p>same as any VHDL keyword. This chapter contains many definitions of syntax in VHDL. The following
</p>
<p>notations will be used throughout the chapter when introducing new constructs:
</p>
<p>bold &frac14; VHDL keyword, use as is
</p>
<p>italics &frac14; User-defined name
</p>
<p>&lt;&gt; &frac14; A required characteristic such as a data type and input/output
</p>
<p>5.4.1 Data Types
</p>
<p>In VHDL, every signal, constant, variable, and function must be assigned a data type. The IEEE
</p>
<p>standard package provides a variety of predefined data types. Some data types are synthesizable, while
</p>
<p>others are only for modeling abstract behavior. The following are the most commonly used data types in
</p>
<p>the VHDL standard package.
</p>
<p>5.4.1.1 Enumerated Types
</p>
<p>An enumerated type is one in which the exact values that the type can take on are defined.
</p>
<p>Type Values that the type can take on
</p>
<p>bit {0, 1}
</p>
<p>boolean {false, true}
</p>
<p>character {&ldquo;any of the 256 ASCII characters defined in ISO 8859-1&rdquo;}
</p>
<p>The type bit is synthesizable while Boolean and character are not. The individual scalar values are
</p>
<p>indicated by putting them inside single quotes (e.g., &lsquo;0,&rsquo; &lsquo;a,&rsquo; &lsquo;true&rsquo;).
</p>
<p>5.4.1.2 Range Types
</p>
<p>A range type is one that can take on any value within a range.
</p>
<p>Type Values that the type can take on
</p>
<p>integer Whole numbers between �2,147,483,648 to +2,147,483,647
</p>
<p>real Fractional numbers between �1.7e38 to +1.7e38
</p>
<p>The integer type is a 32-bit, signed, two&rsquo;s complement number and is synthesizable. If the full range
</p>
<p>of integer values is not desired, this type can be bounded by including range&lt;min&gt; to&lt;max&gt;. The real
</p>
<p>type is a 32-bit, floating point value and is not directly synthesizable unless an additional package is
</p>
<p>included that defines the floating point format. The values of these types are indicated by simply using
</p>
<p>the number without quotes (e.g., 33, 3.14).
</p>
<p>5.4.1.3 Physical Types
</p>
<p>A physical type is one that contains both a value and units. In VHDL, time is the primary supported
</p>
<p>physical type.
</p>
<p>150 &bull; Chapter 5: VHDL (Part 1)</p>
<p/>
</div>
<div class="page"><p/>
<p>Type Values that the type can take on
</p>
<p>time Whole numbers between �2,147,483,648 to +2,147,483,647
</p>
<p>(unit relationships) fs (femtosecond, 10�15), base unit
</p>
<p>ps &frac14; 1000 fs (picosecond, 10�12)
</p>
<p>ns &frac14; 1000 ps (nanosecond, 10�9)
</p>
<p>μs &frac14; 1000 ns (microsecond, 10�6)
</p>
<p>ms &frac14; 1000 μs (millisecond, 10�3)
</p>
<p>s &frac14; 1000 ms (second)
</p>
<p>min &frac14; 60 s (minute)
</p>
<p>h &frac14; 60 min (hour)
</p>
<p>The base unit for time is fs, meaning that if no units are provided, the value is assumed to be in
</p>
<p>femtoseconds. The value of time is held as a 32-bit, signed number and is not synthesizable.
</p>
<p>5.4.1.4 Vector Types
</p>
<p>A vector type is one that consists of a linear array of scalar types.
</p>
<p>Type Construction
</p>
<p>bit_vector A linear array of type bit
</p>
<p>string A linear array of type character
</p>
<p>The size of a vector type is defined by including the maximum index, the keyword downto, and the
</p>
<p>minimum index. For example, if a signal called BUS_A was given the type bit_vector(7 downto 0), it
</p>
<p>would create a vector of 8 scalars, each of type bit. The leftmost scalar would have an index of 7 and the
</p>
<p>rightmost scalar would have an index of 0. Each of the individual scalars within the vector can be
</p>
<p>accessed by providing the index number in parentheses. For example, BUS_A(0) would access the
</p>
<p>scalar in the rightmost position. The indices do not always need to have a minimum value of 0, but this is
</p>
<p>the most common indexing approach in logic design. The type bit_vector is synthesizable while string is
</p>
<p>not. The values of these types are indicated by enclosing them inside double quotes (e.g., &ldquo;0011,&rdquo;
</p>
<p>&ldquo;abcd&rdquo;).
</p>
<p>5.4.1.5 User-Defined Enumerated Types
</p>
<p>A user-defined enumerated type is one in which the name of the type is specified by the user in
</p>
<p>addition to all of the possible values that the type can assume. The creation of a user-defined
</p>
<p>enumerated type is shown below:
</p>
<p>type name is (value1, value2, . . .);
</p>
<p>Example:
</p>
<p>type traffic_light is (red, yellow, green);
</p>
<p>In this example, a new type is created called traffic_light. If we declared a new signal called Sig1 and
</p>
<p>assigned it the type traffic_light, the signal could only take on values of red, yellow, and green. User-
</p>
<p>defined enumerated types are synthesizable in specific applications.
</p>
<p>5.4 VHDL Constructs &bull; 151</p>
<p/>
</div>
<div class="page"><p/>
<p>5.4.1.6 Array Type
</p>
<p>An array contains multiple elements of the same type. Elements within an array can be scalar or
</p>
<p>vectors. In order to use an array, a new type must be declared that defines the configuration of the array.
</p>
<p>Once the new type is created, signals may be declared of that type. The range of the array must be
</p>
<p>defined in the array type declaration. The range is specified with integers (min and max) and either the
</p>
<p>keywords downto or to. The creation of an array type is shown below:
</p>
<p>type name is array (&lt;range&gt;) of &lt;element_type&gt;;
</p>
<p>Example:
</p>
<p>type block_8x16 is array (0 to 7) bit_vector(15 downto 0);
signal my_array : block_8x16;
</p>
<p>In this example, the new array type is declared with eight elements. The beginning index of the array
</p>
<p>is 0 and the ending index is 7. Each element in the array is a 16-bit vector of type bit_vector.
</p>
<p>5.4.1.7 Subtypes
</p>
<p>A subtype is a constrained version, or subset of another type. Subtypes are user defined, although a
</p>
<p>few commonly used subtypes are predefined in the standard package. The following is the syntax for
</p>
<p>declaring a subtype and two examples of commonly used subtypes (NATURAL and POSTIVE) that are
</p>
<p>defined in the standard package:
</p>
<p>subtype name is &lt;type&gt; range &lt;min&gt; to &lt;max&gt;;
</p>
<p>Example:
</p>
<p>subtype NATURAL is integer range 0 to 255;
subtype POSTIVE is integer range 1 to 256;
</p>
<p>5.4.2 Libraries and Packages
</p>
<p>As mentioned earlier, the IEEE standard package is implied when using VHDL; however, we can
</p>
<p>use it as an example of how to include packages in VHDL. The keyword library is used to signify that
</p>
<p>packages are going to be added to the VHDL design from the specified library. The name of the library
</p>
<p>follows this keyword. To include a specific package from the library, a new line is used with the keyword
</p>
<p>use followed by the package details. The package syntax has three fields separated with a period. The
</p>
<p>first field is the library name. The second field is the package name. The third field is the specific
</p>
<p>functionality of the package to be included. If all functionality of a package is to be used, then the
</p>
<p>keyword all is used in the third field. Examples of how to include some of the commonly used packages
</p>
<p>from the IEEE library are shown below:
</p>
<p>library IEEE;
</p>
<p>use IEEE.std_logic_1164.all;
use IEEE.numeric_std.all;
use IEEE.std_logic_textio.all;
</p>
<p>5.4.3 The Entity
</p>
<p>The entity in VHDL describes the inputs and outputs of the system. These are called ports. Each
</p>
<p>port needs to have its name, mode, and type specified. The name is user defined. The mode describes
</p>
<p>the direction data is transferred through the port and can take on values of in, out, inout, and buffer.
</p>
<p>152 &bull; Chapter 5: VHDL (Part 1)</p>
<p/>
</div>
<div class="page"><p/>
<p>The type is one of the legal data types described above. Port names with the same mode and type can
</p>
<p>be listed on the same line separated by commas. The definition of an entity is given below:
</p>
<p>entity entity_name is
port (port_name : &lt;mode&gt; &lt;type&gt;;
</p>
<p>port_name : &lt;mode&gt; &lt;type&gt;);
end entity;
</p>
<p>Example 5.1 shows multiple approaches for defining an entity.
</p>
<p>Example 5.1
Defining VHDL Entities
</p>
<p>5.4.4 The Architecture
</p>
<p>The architecture in VHDL describes the behavior of a system. There are numerous techniques to
</p>
<p>describe behavior in VHDL that span multiple levels of abstraction. The architecture is where the majority
</p>
<p>of the design work is conducted. The form of a generic architecture is given below:
</p>
<p>architecture architecture_name of &lt;entity associated with&gt; is
</p>
<p>-- user-defined enumerated type declarations (optional)
-- signal declarations (optional)
-- constant declarations (optional)
-- component declarations (optional)
</p>
<p>begin
</p>
<p>-- behavioral description of the system goes here
</p>
<p>end architecture;
</p>
<p>5.4.4.1 Signal Declarations
</p>
<p>A signal that is used for internal connections within a system is declared in the architecture. Each
</p>
<p>signal must be declared with a type. The signal can only be used to make connections of like types.
</p>
<p>A signal is declared with the keyword signal followed by a user-defined name, colon, and the type.
</p>
<p>5.4 VHDL Constructs &bull; 153</p>
<p/>
</div>
<div class="page"><p/>
<p>Signals of like type can be declared on the same line separated with a comma. All of the legal data types
</p>
<p>described above can be used for signals. Signals represent wires within the system, so they do not have
</p>
<p>a direction or mode. Signals cannot have the same name as a port in the system in which they reside.
</p>
<p>The syntax for a signal declaration is as follows:
</p>
<p>signal name : &lt;type&gt;;
</p>
<p>Example:
</p>
<p>signal node1 : bit;
signal a1, b1 : integer;
signal Bus3 : bit_vector (15 downto 0);
signal C_int : integer range 0 to 255;
</p>
<p>VHDL supports a hierarchical design approach. Signal names can be the same within a subsystem
</p>
<p>as those at a higher level without conflict. Figure 5.9 shows an example of legal signal naming in a
</p>
<p>hierarchical design.
</p>
<p>5.4.4.2 Constant Declarations
</p>
<p>A constant is useful for representing a quantity that will be used multiple times in the architecture.
</p>
<p>The syntax for declaring a constant is as follows:
</p>
<p>constant constant_name : &lt;type&gt; :&frac14; &lt;value&gt;;
</p>
<p>Example:
</p>
<p>constant BUS_WIDTH : integer :&frac14; 32;
</p>
<p>Once declared, the constant name can now be used throughout the architecture. The following
</p>
<p>example illustrates how we can use a constant to define the size of a vector. Notice that since we defined
</p>
<p>the constant to be the actual width of the vector (i.e., 32 bits), we need to subtract one from its value when
</p>
<p>defining the indices (i.e., 31 downto 0).
</p>
<p>Example:
</p>
<p>signal BUS_A : bit_vector (BUS_WIDTH-1 downto 0);
</p>
<p>Fig. 5.9
VHDL signals and systems
</p>
<p>154 &bull; Chapter 5: VHDL (Part 1)</p>
<p/>
</div>
<div class="page"><p/>
<p>5.4.4.3 Component Declarations
</p>
<p>A component is the term used for a VHDL subsystem that is instantiated within a higher level
</p>
<p>system. If a component is going to be used within a system, it must be declared in the architecture before
</p>
<p>the begin statement. The syntax for a component declaration is as follows:
</p>
<p>component component_name
port (port_name : &lt;mode&gt; &lt;type&gt;;
</p>
<p>port_name : &lt;mode&gt; &lt;type&gt;);
end component;
</p>
<p>The port definitions of the component must match the port definitions of the subsystem&rsquo;s entity
</p>
<p>exactly. As such, these lines are typically copied directly from the lower level systems VHDL entity
</p>
<p>description. Once declared, a component can be instantiated after the begin statement in the architec-
</p>
<p>ture as many times as needed.
</p>
<p>CC5.4(a) Why don&rsquo;t we need to explicitly include the STANDARD package when creating a VHDL 
design?
</p>
<p>A) It defines the base functionality of VHDL so its use is implied.
</p>
<p>B) The simulator will automatically add it to the .vhd file upon compile.
</p>
<p>C) It isn&rsquo;t recognized by synthesizers so it shouldn&rsquo;t be included.
</p>
<p>D) It is a historical artifact that that isn&rsquo;t used anymore.
</p>
<p>CC5.4(b) What is the difference between types Boolean {TRUE, FALSE} and bit {0, 1}?
</p>
<p>A) They are the same.
</p>
<p>B) Boolean is used for decision making constructs (when, else) while bit is used to 
model real digital signals.
</p>
<p>C) Logical operators work with type Boolean but not for type bit.
</p>
<p>D) Only type bit is synthesizable. 
</p>
<p>CONCEPT CHECK
</p>
<p>5.5 Modeling Concurrent Functionality in VHDL
</p>
<p>It is important to remember that VHDL is a hardware description language, not a programming
</p>
<p>language. In a programming language, the lines of code are executed sequentially as they appear in the
</p>
<p>source file. In VHDL, the lines of code represent the behavior of real hardware. As a result, all signal
</p>
<p>assignments are by default executed concurrently unless specifically noted otherwise. All operations in
</p>
<p>VHDL must be on like types and the result must be assigned to the same type as the operation inputs.
</p>
<p>5.5.1 VHDL Operators
</p>
<p>There are a variety of predefined operators in the IEEE standard package. It is important to note that
</p>
<p>operators are defined to work on specific data types and that not all operators are synthesizable.
</p>
<p>5.5 Modeling Concurrent Functionality in VHDL &bull; 155</p>
<p/>
</div>
<div class="page"><p/>
<p>5.5.1.1 Assignment Operator
</p>
<p>VHDL uses &lt;&frac14; for all signal assignments and :&frac14; for all variable and initialization assignments.
</p>
<p>These assignment operators work on all data types. The target of the assignment goes on the left of
</p>
<p>these operators and the input arguments go on the right.
</p>
<p>Example:
</p>
<p>F1 &lt;&frac14; A; -- F1 and A must be the same size and type
F2 &lt;&frac14; &lsquo;0&rsquo;; -- F2 is type bit in this example
F3 &lt;&frac14; &ldquo;0000&rdquo;; -- F3 is type bit_vector(3 downto 0) in this example
F4 &lt;&frac14; &ldquo;hello&rdquo;; -- F4 is type string in this example
F5 &lt;&frac14; 3.14; -- F5 is type real in this example
F6 &lt;&frac14; x&rdquo;1A&rdquo;; -- F6 is type bit_vector(7 downto 0), x&rdquo;1A&rdquo; is in HEX
</p>
<p>5.5.1.2 Logical Operators
</p>
<p>VHDL contains the following logical operators:
</p>
<p>Operator Operation
</p>
<p>not Logical negation
</p>
<p>and Logical AND
</p>
<p>nand Logical NAND
</p>
<p>or Logical OR
</p>
<p>nor Logical NOR
</p>
<p>xor Logical exclusive-OR
</p>
<p>xnor Logical exclusive-NOR
</p>
<p>These operators work on types bit, bit_vector, and boolean. For operations on the type bit_vector,
</p>
<p>the input vectors must be the same size and will take place in a bit-wise fashion. For example, if two 8-bit
</p>
<p>buses called BusA and BusB were AND&rsquo;d together, BusA(0) would be individually AND&rsquo;d with BusB(0),
</p>
<p>BusA(1) would be individually AND&rsquo;d with BusB(1), etc. The not operator is a unary operation (i.e., it
</p>
<p>operates on a single input), and the keyword is put before the signal being operated on. All other
</p>
<p>operators have two or more inputs and are placed in between the input names.
</p>
<p>Example:
</p>
<p>F1 &lt;&frac14; not A;
F2 &lt;&frac14; B and C;
</p>
<p>The order of precedence in VHDL is different from that in Boolean algebra. The NOT operator is a
</p>
<p>higher priority than all other operators. All other logical operators have the same priority and have no
</p>
<p>inherent precedence. This means that in VHDL, the AND operator will not precede the OR operation as it
</p>
<p>does in Boolean algebra. Parentheses are used to explicitly describe precedence. If operators are used
</p>
<p>that have the same priority and parentheses are not provided, then the operations will take place on the
</p>
<p>signals listed first moving left to right in the signal assignment. The following are examples on how to use
</p>
<p>these operators.
</p>
<p>156 &bull; Chapter 5: VHDL (Part 1)</p>
<p/>
</div>
<div class="page"><p/>
<p>Example:
</p>
<p>F3 &lt;&frac14; not D nand E; -- D will be complemented first, the result
-- will then be NAND&rsquo;d with E, then the
-- result will be assigned to F3
</p>
<p>F4 &lt;&frac14; not (F or G); -- the parentheses take precedence so
-- F will be OR&rsquo;d with G first, then
</p>
<p>-- complemented, and then assigned to F4.
</p>
<p>F5 &lt;&frac14; H nor I nor J; -- logic operations can have any number of
-- inputs.
</p>
<p>F6 &lt;&frac14; K xor L xnor M; -- XOR and XNOR have the same priority so with
-- no parentheses given, the logic operations
-- will take place on the signals from
-- left to right. K will be XOR&rsquo;d with L first,
-- then the result will be XNOR&rsquo;d with M.
</p>
<p>5.5.1.3 Numerical Operators
</p>
<p>VHDL contains the following numerical operators:
</p>
<p>Operator Operation
</p>
<p>+ Addition
</p>
<p>- Subtraction
</p>
<p>* Multiplication
</p>
<p>/ Division
</p>
<p>mod Modulus
</p>
<p>rem Remainder
</p>
<p>abs Absolute value
</p>
<p>** Exponential
</p>
<p>These operators work on types integer and real. Note that the default VHDL standard does not
</p>
<p>support numerical operators on types bit and bit_vector.
</p>
<p>5.5.1.4 Relational Operators
</p>
<p>VHDL contains the following relational operators. These operators compare two inputs of the same
</p>
<p>type and returns the type Boolean (i.e., true or false).
</p>
<p>Operator Returns true if the comparison is:
</p>
<p>&frac14; Equal
</p>
<p>/&frac14; Not equal
</p>
<p>&lt; Less than
</p>
<p>&lt;&frac14; Less than or equal
</p>
<p>&gt; Greater than
</p>
<p>&gt;&frac14; Greater than or equal
</p>
<p>5.5.1.5 Shift Operators
</p>
<p>VHDL contains the following shift operators. These operators work on vector types bit_vector and
</p>
<p>string.
</p>
<p>5.5 Modeling Concurrent Functionality in VHDL &bull; 157</p>
<p/>
</div>
<div class="page"><p/>
<p>Operator Operation
</p>
<p>sll Shift left logical
</p>
<p>srl Shift right logical
</p>
<p>sla Shift left arithmetic
</p>
<p>sra Shift right arithmetic
</p>
<p>rol Rotate left
</p>
<p>ror Rotate right
</p>
<p>The syntax for using a shift operation is to provide the name of the vector followed by the desired
</p>
<p>shift operator, followed by an integer indicating how many shift operations to perform. The target of the
</p>
<p>assignment must be of the same type and size as the input.
</p>
<p>Example:
</p>
<p>A &lt;&frac14; B srl 3; -- A is assigned the result of a logical shift
-- right 3 times on B.
</p>
<p>5.5.1.6 Concatenation Operator
</p>
<p>In VHDL the &amp; is used to concatenate multiple signals. The target of this operation must be the same
</p>
<p>size of the sum of the sizes of the input arguments.
</p>
<p>Example:
</p>
<p>Bus1 &lt;&frac14; &ldquo;11&rdquo; &amp; &ldquo;00&rdquo;; -- Bus1 must be 4-bits and will be assigned
-- the value &ldquo;1100&rdquo;
</p>
<p>Bus2 &lt;&frac14; BusA &amp; BusB; -- If BusA and BusB are 4-bits, then Bus2
-- must be 8-bits.
</p>
<p>Bus3 &lt;&frac14; &lsquo;0&rsquo; &amp; BusA; -- This attaches a leading &lsquo;0&rsquo; to BusA. Bus3
-- must be 5-bits
</p>
<p>5.5.2 Concurrent Signal Assignments
</p>
<p>Concurrent signal assignments are accomplished by simply using the &lt;&frac14; operator after the begin
</p>
<p>statement in the architecture. Each individual assignment will be executed concurrently and synthesized
</p>
<p>as separate logic circuits. Consider the following example.
</p>
<p>Example:
</p>
<p>X &lt;&frac14; A;
Y &lt;&frac14; B;
Z &lt;&frac14; C;
</p>
<p>When simulated, these three lines of VHDL will make three separate signal assignments at the
</p>
<p>exact same time. This is different from a programming language that will first assign A to X, then B to Y,
</p>
<p>and finally C to Z. In VHDL this functionality is identical to three separate wires. This description will be
</p>
<p>directly synthesized into three separate wires.
</p>
<p>Below is another example of how concurrent signal assignments in VHDL differ from a sequentially
</p>
<p>executed programming language.
</p>
<p>Example:
</p>
<p>A &lt;&frac14; B;
B &lt;&frac14; C;
</p>
<p>158 &bull; Chapter 5: VHDL (Part 1)</p>
<p/>
</div>
<div class="page"><p/>
<p>In a VHDL simulation, the signal assignments of C to B and B to A will take place at the same time;
</p>
<p>however, during synthesis, the signal B will be eliminated from the design since this functionality
</p>
<p>describes two wires in series. Automated synthesis tools will eliminate this unnecessary signal name.
</p>
<p>This is not the same functionality that would result if this example was implemented as a sequentially
</p>
<p>executed computer program. A computer program would execute the assignment of B to A first, and then
</p>
<p>assign the value of C to B second. In this way, B represents a storage element that is passed to A before
</p>
<p>it is updated with C.
</p>
<p>5.5.3 Concurrent Signal Assignments with Logical Operators
</p>
<p>Each of the logical operators described in Sect. 5.5.1.2 can be used in conjunction with concurrent
</p>
<p>signal assignments to create individual combinational logic circuits. Example 5.2 shows how to design a
</p>
<p>VHDL model of a combinational logic circuit using this approach.
</p>
<p>Example 5.2
Modeling Logic Using Concurrent Signal Assignments and Logical Operators
</p>
<p>5.5 Modeling Concurrent Functionality in VHDL &bull; 159</p>
<p/>
</div>
<div class="page"><p/>
<p>5.5.4 Conditional Signal Assignments
</p>
<p>Logical operators are good for describing the behavior of small circuits; however, in the prior
</p>
<p>example we still needed to create the canonical sum of products logic expression by hand before
</p>
<p>describing the functionality in VHDL. The true power of an HDL is when the behavior of the system
</p>
<p>can be described fully without requiring any hand design. A conditional signal assignment allows us to
</p>
<p>describe a concurrent signal assignment using Boolean conditions that effect the values of the result. In a
</p>
<p>conditional signal assignment, the keyword when is used to describe the signal assignment for a
</p>
<p>particular Boolean condition. The keyword else is used to describe the signal assignments for any
</p>
<p>other conditions. Multiple Boolean conditions can be used to fully describe the output of the circuit under
</p>
<p>all input conditions. Logical operators can also be used in the Boolean conditions to create more
</p>
<p>sophisticated conditions. The Boolean conditions can be encompassed within parentheses for readabil-
</p>
<p>ity. The syntax for a conditional signal assignment is shown below:
</p>
<p>signal_name &lt;&frac14; expression_1 when condition_1 else
expression_2 when condition_2 else
</p>
<p>:
expression_n;
</p>
<p>Example:
</p>
<p>F1 &lt;&frac14; &lsquo;0&rsquo; when A&frac14;&lsquo;0&rsquo; else &lsquo;1&rsquo;;
F2 &lt;&frac14; &lsquo;1&rsquo; when (A&frac14;&rsquo;0&rsquo; and B&frac14;&rsquo;1&rsquo;) else &lsquo;0&rsquo;;
F3 &lt;&frac14; A when (C &frac14; D) else B;
</p>
<p>An important consideration of conditional signal assignments is that they are still executed concur-
</p>
<p>rently. Each assignment represents a separate, combinational logic circuit. In the above example, F1,
</p>
<p>F2, and F3 will be implemented as three separate circuits. Example 5.3 shows how to design a VHDL
</p>
<p>model of a combinational logic circuit using conditional signal assignments. Note that this example uses
</p>
<p>the same truth table as in Example 5.2 to illustrate a comparison between approaches.
</p>
<p>160 &bull; Chapter 5: VHDL (Part 1)</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 5.3
Modeling Logic Using Conditional Signal Assignments
</p>
<p>5.5.5 Selected Signal Assignments
</p>
<p>A selected signal assignment provides another technique to implement concurrent signal
</p>
<p>assignments. In this approach, the signal assignment is based on a specific value on the input signal.
</p>
<p>The keyword with is used to begin the selected signal assignment. It is then followed by the name of the
</p>
<p>input that will be used to dictate the value of the output. Only a single variable name can be listed as the
</p>
<p>input. This means that if the assignment is going to be based on multiple variables, they must first be
</p>
<p>concatenated into a single vector name before starting the selected signal assignment. After the input is
</p>
<p>listed, the keyword select signifies the beginning of the signal assignments. An assignment is made to a
</p>
<p>signal based on a list of possible input values that follow the keyword when. Multiple values of the input
</p>
<p>codes can be used and are separated by commas. The keyword others is used to cover any input values
</p>
<p>that are not explicitly stated. The syntax for a selected signal assignment is as follows:
</p>
<p>5.5 Modeling Concurrent Functionality in VHDL &bull; 161</p>
<p/>
</div>
<div class="page"><p/>
<p>with input_name select
signal_name &lt;&frac14; expression_1 when condition_1,
</p>
<p>expression_2 when condition_2,
:
</p>
<p>expression_n when others;
</p>
<p>Example:
</p>
<p>with A select
F1 &lt;&frac14; &lsquo;1&rsquo; when &lsquo;0&rsquo;, -- F1 will be assigned &lsquo;1&rsquo; when A&frac14;&rsquo;0&rsquo;
</p>
<p>&lsquo;0&rsquo; when &lsquo;1&rsquo;; -- F1 will be assigned &lsquo;0&rsquo; when A&frac14;&rsquo;1&rsquo;
</p>
<p>AB &lt;&frac14; A&amp;B; -- concatenate A and B so that they can be used as a vector
with AB select
F2 &lt;&frac14; &lsquo;0&rsquo; when &ldquo;00&rdquo;, -- F2 will be assigned &lsquo;0&rsquo; when AB&frac14;&rdquo;00&rdquo;
</p>
<p>&lsquo;1&rsquo; when &ldquo;01&rdquo;,
&lsquo;1&rsquo; when &ldquo;10&rdquo;,
&lsquo;0&rsquo; when &ldquo;11&rdquo;;
</p>
<p>with AB select
F3 &lt;&frac14; &lsquo;1&rsquo; when &ldquo;01&rdquo;,
</p>
<p>&lsquo;1&rsquo; when &ldquo;10&rdquo;,
&lsquo;0&rsquo; when others;
</p>
<p>One feature of selected signal assignments that makes its form even more compact is that multiple
</p>
<p>input codes that correspond to the same output assignment can be listed on the same line pipe (|)-
</p>
<p>delimited. The example for F3 can be equivalently described as:
</p>
<p>with AB select
F3 &lt;&frac14; &lsquo;1&rsquo; when &ldquo;01&rdquo; | &ldquo;10&rdquo;,
</p>
<p>&lsquo;0&rsquo; when others;
</p>
<p>Example 5.4 shows how to design a VHDL model of a combinational logic circuit using selected
</p>
<p>signal assignments. Note that this example again uses the same truth table as in Examples 5.2 and 5.3
</p>
<p>to illustrate a comparison between approaches.
</p>
<p>162 &bull; Chapter 5: VHDL (Part 1)</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 5.4
Modeling Logic Using Selected Signal Assignments
</p>
<p>5.5 Modeling Concurrent Functionality in VHDL &bull; 163</p>
<p/>
</div>
<div class="page"><p/>
<p>5.5.6 Delayed Signal Assignments
</p>
<p>VHDL provides the ability to delay a concurrent signal assignment in order to more accurately model
</p>
<p>the behavior of real gates. The keyword after is used to delay an assignment by a certain amount of time.
</p>
<p>The magnitude of the delay is provided as type time. The syntax for delaying an assignment is as follows:
</p>
<p>signal_name &lt;&frac14; &lt;expression&gt; after &lt;time&gt;;
</p>
<p>Example:
</p>
<p>A &lt;&frac14; B after 3us;
C &lt;&frac14; D and E after 10ns;
</p>
<p>If an input pulse is shorter in duration than the amount of the delay, the input pulse is ignored. This is
</p>
<p>called the inertial delay model. Example 5.5 shows how to design a VHDL model with a delayed signal
</p>
<p>assignment using the inertial delay model.
</p>
<p>Example 5.5
Modeling Logic Using Delayed Signal Assignments (Inertial Delay Model)
</p>
<p>Ignoring brief input pulses on the input accurately models the behavior of on-chip gates. When the
</p>
<p>input pulse is faster than the delay of the gate, the output of the gate does not have time to respond. As a
</p>
<p>result, there will not be a logic change on the output. If it is desired to have all pulses on the inputs show
</p>
<p>up on the outputs when modeling the behavior of other types of digital logic, the keyword transport is
</p>
<p>used in conjunction with the after statement. This is called the transport delay model:
</p>
<p>signal_name &lt;&frac14; transport &lt;expression&gt; after &lt;time&gt;;
</p>
<p>Example 5.6 shows how to perform a delayed signal assignment using the transport delay model.
</p>
<p>164 &bull; Chapter 5: VHDL (Part 1)</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 5.6
Modeling Logic Using Delayed Signal Assignments (Transport Delay Model)
</p>
<p>CC5.5(a) Why is concurrency such an important concept in HDLs?
</p>
<p>A) Concurrency is a feature of HDLs that can&rsquo;t be modeled using schematics.
</p>
<p>B) Concurrency allows automated synthesis to be performed. 
</p>
<p>C) Concurrency allows logic simulators to display useful system information.
</p>
<p>D) Concurrency is necessary to model real systems that operate in parallel.
</p>
<p>CC5.5(b) Why does modeling combinational logic in its canonical form with concurrent signal 
assignments with logical operators defeat the purpose of the modern digital design flow?
</p>
<p>A) It requires the designer to first create the circuit using the classical digital design 
approach and then enter it into the HDL in a form that is essentially a text-based 
netlist.  This doesn&rsquo;t take advantage of the abstraction capabilities and 
automated synthesis in the modern flow.
</p>
<p>B) It cannot be synthesized because the order of precedence of the logical 
operators in VHDL doesn&rsquo;t match the precedence defined in Boolean algebra.
</p>
<p>C) The circuit is in its simplest form so there is no work for the synthesizer to do.
</p>
<p>D) It doesn&rsquo;t allow an else clause to cover the outputs for any remaining input codes 
not explicitly listed.
</p>
<p>CONCEPT CHECK
</p>
<p>5.6 Structural Design Using Components
</p>
<p>Structural design in VHDL refers to including lower level subsystems within a higher level system in
</p>
<p>order to produce the desired functionality. A purely structural VHDL design would not contain any
</p>
<p>behavioral modeling in the architecture such as signal assignments, but instead just contain the
</p>
<p>instantiation and interconnections of other subsystems. A subsystem is called a component in VHDL.
</p>
<p>For any component that is going to be used in an architecture, it must be declared before the begin
</p>
<p>5.6 Structural Design Using Components &bull; 165</p>
<p/>
</div>
<div class="page"><p/>
<p>statement. Refer to Sect. 5.4.4.3 for the syntax of declaring a component. A specific component only
</p>
<p>needs to be declared once. After the begin statement it can be used as many times as necessary. Each
</p>
<p>component is executed concurrently.
</p>
<p>5.6.1 Component Instantiation
</p>
<p>The term instantiation refers to the use or inclusion of the component in the VHDL system. When a
</p>
<p>component is instantiated, it needs to be given a unique identifying name. This is called the instance
</p>
<p>name. To instantiate a component, the instance name is given first, followed by a colon and then the
</p>
<p>component name. The last part of instantiating a component is connecting signals to its ports. The way in
</p>
<p>which signals are connected to the ports of the component is called the port map. The syntax for
</p>
<p>instantiating a component is as follows:
</p>
<p>instance_name : &lt;component name&gt;
port map (&lt;port connections&gt;);
</p>
<p>There are two techniques to connect signals to the ports of the component, explicit port mapping
</p>
<p>and positional port mapping.
</p>
<p>5.6.1.1 Explicit Port Mapping
</p>
<p>In explicit port mapping the name of each port of the component is given, followed by the connection
</p>
<p>indicator &frac14;&gt;, followed by the signal it is connected to. The port connections can be listed in any order
</p>
<p>since the details of the connection (i.e., port name to signal name) are explicit. Each connection name is
</p>
<p>separated by a comma. The syntax for explicit port mapping is as follows:
</p>
<p>instance_name : &lt;component name&gt;
port map (port1 &frac14;&gt; signal1, port2 &frac14;&gt; signal2, . . .);
</p>
<p>Example 5.7 shows how to design a VHDL model of a combinational logic circuit using structural
</p>
<p>VHDL and explicit port mapping. Note that this example again uses the same truth table as in Examples
</p>
<p>5.2, 5.3, and 5.4 to illustrate a comparison between approaches.
</p>
<p>166 &bull; Chapter 5: VHDL (Part 1)</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 5.7
Modeling Logic Using Structural VHDL (Explicit Port Mapping)
</p>
<p>5.6.1.2 Positional Port Mapping
</p>
<p>In positional port mapping the names of the ports of the component are not explicitly listed. Instead,
</p>
<p>the signals are listed in the same order that the ports of the component were defined. Each signal name
</p>
<p>5.6 Structural Design Using Components &bull; 167</p>
<p/>
</div>
<div class="page"><p/>
<p>is separated by a comma. This approach requires less text to describe but can also lead to
</p>
<p>misconnections due to mismatches in the order of the signals being connected. The syntax for positional
</p>
<p>port mapping is as follows:
</p>
<p>instance_name : &lt;component name&gt;
port map (signal1, signal2, . . .);
</p>
<p>Example 5.8 shows how to create the same structural VHDL model as in Example 5.7, but using
</p>
<p>positional port mapping instead.
</p>
<p>Example 5.8
Modeling Logic Using Structural VHDL (Positional Port Mapping)
</p>
<p>CC5.6 Does the use of components model concurrent functionality? Why?
</p>
<p>A) No.  Since the lower level behavior of the component being instantiated may 
contain non-concurrent behavior, it is not known what functionality will be 
modeled.
</p>
<p>B) Yes.  The components are treated like independent sub-systems whose behavior 
runs in parallel just as if separate parts were placed in a design.
</p>
<p>CONCEPT CHECK
</p>
<p>5.7 Overview of Simulation Test Benches
</p>
<p>One of the essential components of the modern digital design flow is verifying functionality through
</p>
<p>simulation. This simulation takes place at many levels of abstraction. For a system to be tested, there
</p>
<p>needs to be a mechanism to generate input patterns to drive the system and then observe the outputs to
</p>
<p>verify correct operation. The mechanism to do this in VHDL is called a test bench. A test bench is a file in
</p>
<p>168 &bull; Chapter 5: VHDL (Part 1)</p>
<p/>
</div>
<div class="page"><p/>
<p>VHDL that has no inputs or outputs. The test bench declares the system to be tested as a component
</p>
<p>and then instantiates it. The test bench generates the input conditions and drives them into the input
</p>
<p>ports of the system being tested. VHDL contains numerous methods to generate stimulus patterns.
</p>
<p>Since a test bench will not be synthesized, very abstract behavioral modeling can be used to generate
</p>
<p>the inputs. The output of the system can be viewed as a waveform in a simulation tool. VHDL also has the
</p>
<p>ability to check the outputs against the expected results and notify the user if differences occur.
</p>
<p>Figure 5.10 gives an overview of how test benches are used in VHDL. The techniques to generate the
</p>
<p>stimulus patterns are covered in Chap. 8.
</p>
<p>Fig. 5.10
Overview of VHDL test benches
</p>
<p>5.7 Overview of Simulation Test Benches &bull; 169</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_8">http://dx.doi.org/10.1007/978-3-319-34195-8_8</a></div>
</div>
<div class="page"><p/>
<p>CC5.7 How can the output of a DUT be verified when it is connected to a signal that does not go 
anywhere?
</p>
<p>A) It can&rsquo;t.  The output must be routed to an output port on the test bench.
</p>
<p>B) The values of any dangling signal are automatically written to a text file.
</p>
<p>C) It is viewed in the logic simulator as either a waveform or text listing.
</p>
<p>D) It can&rsquo;t.  A signal that does not go anywhere will cause an error when the VHDL 
file is compiled.
</p>
<p>CONCEPT CHECK
</p>
<p>Summary
</p>
<p>v The modern digital design flow relies on
computer-aided engineering (CAE) and
computer-aided design (CAD) tools to man-
age the size and complexity of today&rsquo;s digital
designs.
</p>
<p>v Hardware description languages (HDLs)
allow the functionality of digital systems to
be entered using text. VHDL and Verilog are
the two most common HDLs in use today.
</p>
<p>v VHDL was originally created to document the
behavior of large digital systems and support
functional simulations.
</p>
<p>v The ability to automatically synthesize a logic
circuit from a VHDL behavioral description
became possible approximately 10 years
after the original definition of VHDL. As
such, only a subset of the behavioral
modeling techniques in VHDL can be auto-
matically synthesized.
</p>
<p>v HDLs can model digital systems at different
levels of design abstraction. These include
the system, algorithmic, RTL, gate, and cir-
cuit levels. Designing at a higher level of
abstraction allows more complex systems to
be modeled without worrying about the
details of the implementation.
</p>
<p>v In a VHDL source file there are three main
sections. These are the package, the entity,
and the architecture. Including a package
allows additional functionality to be included
in VHDL. The entity is where the inputs and
outputs of the system are declared. The
architecture is where the behavior of the sys-
tem is described.
</p>
<p>v A port is an input or output to a system that is
declared in the entity. A signal is an internal
connection within the system that is declared
in the architecture. A signal is not visible
outside of the system.
</p>
<p>v A component is how a VHDL system uses
another subsystem. A component is first
declared, which defines the name and entity
of the subsystem to be used. The component
can then be instantiated one or more times.
The ports of the component can be
connected using either explicit or positional
port mapping.
</p>
<p>v Concurrency is the term that describes
operations being performed in parallel. This
allows real-world system behavior to be
modeled.
</p>
<p>v VHDL contains three direct techniques to
model concurrent logic behavior. These are
concurrent signal assignments with logical
operators, conditional signal assignments,
and selected signal assignments.
</p>
<p>v VHDL components are also treated as con-
current subsystems.
</p>
<p>v Delay can be modeled in VHDL using either
the initial or transport model.
</p>
<p>v A simulation test bench is a VHDL file that
drives stimulus into a device under test
(DUT). Test benches do not have inputs or
outputs and are not synthesizable.
</p>
<p>170 &bull; Chapter 5: VHDL (Part 1)</p>
<p/>
</div>
<div class="page"><p/>
<p>Exercise Problems
</p>
<p>Section 5.1: History of HDLs
</p>
<p>5.1.1 What was the original purpose of VHDL?
</p>
<p>5.1.2 Can all of the functionality that can be
described in VHDL be simulated?
</p>
<p>5.1.3 Can all of the functionality that can be
described in VHDL be synthesized?
</p>
<p>Section 5.2: HDL Abstraction
</p>
<p>5.2.1 Give the level of design abstraction that the
following statement relates to: if there is ever
an error in the system, it should return to the
reset state.
</p>
<p>5.2.2 Give the level of design abstraction that the
following statement relates to: once the design
is implemented in a sum of products form,
DeMorgan&rsquo;s theorem will be used to convert it
to a NAND-gate-only implementation.
</p>
<p>5.2.3 Give the level of design abstraction that the
following statement relates to: the design will
be broken down into two subsystems: one that
will handle data collection and the other that
will control data flow.
</p>
<p>5.2.4 Give the level of design abstraction that the
following statement relates to: the interconnect
on the IC should be changed from aluminum to
copper to achieve the performance needed in
this design.
</p>
<p>5.2.5 Give the level of design abstraction that the
following statement relates to: the MOSFETs
need to be able to drive at least eight other
loads in this design.
</p>
<p>5.2.6 Give the level of design abstraction that the
following statement relates to: this system will
contain 1 host computer and support up to
1000 client computers.
</p>
<p>5.2.7 Give the design domain that the following activ-
ity relates to: drawing the physical layout of the
CPU will require 6 months of engineering time.
</p>
<p>5.2.8 Give the design domain that the following activ-
ity relates to: the CPU will be connected to four
banks of memory.
</p>
<p>5.2.9 Give the design domain that the following activ-
ity relates to: the fan-in specifications for this
logic family require excessive logic circuitry to
be used.
</p>
<p>5.2.10 Give the design domain that the following activ-
ity relates to: the performance specifications
for this system require one TFLOP at &lt;5 W.
</p>
<p>Section 5.3: The Modern Digital Design
</p>
<p>Flow
</p>
<p>5.3.1 Which step in the modern digital design flow
does the following statement relate to: a CAD
tool will convert the behavioral model into a
gate-level description of functionality.
</p>
<p>5.3.2 Which step in the modern digital design flow
does the following statement relate to: after
realistic gate and wiring delays are determined,
one last simulation should be performed to
make sure that the design meets the original
timing requirements.
</p>
<p>5.3.3 Which step in the modern digital design flow
does the following statement relate to: if the
memory is distributed around the perimeter of
the CPU, the wiring density will be minimized.
</p>
<p>5.3.4 Which step in the modern digital design flow
does the following statement relate to: the
design meets all requirements so now I&rsquo;m
building the hardware that will be shipped.
</p>
<p>5.3.5 Which step in the modern digital design flow
does the following statement relate to: the sys-
tem will be broken down into three subsystems
with the following behaviors.
</p>
<p>5.3.6 Which step in the modern digital design flow
does the following statement relate to: this sys-
tem needs to have 10 Gbytes of memory.
</p>
<p>5.3.7 Which step in the modern digital design flow
does the following statement relate to: to meet
the power requirements, the gates will be
implemented in the 74HC logic family.
</p>
<p>Section 5.4: VHDL Constructs
</p>
<p>5.4.1 In which construct of VHDL are the inputs and
outputs of the system defined?
</p>
<p>5.4.2 In which construct of VHDL is the behavior of
the system described?
</p>
<p>5.4.3 Which construct is used to add additional func-
tionality such as data types to VHDL?
</p>
<p>5.4.4 What are all the possible values that the type
bit can take on in VHDL?
</p>
<p>5.4.5 What are all the possible values that the type
Boolean can take on in VHDL?
</p>
<p>5.4.6 What is the range of decimal numbers that can
be represented using the type integer in
VHDL?
</p>
<p>5.4.7 What is the width of the vector defined using
the type bit_vector(63 downto 0)?
</p>
<p>5.4.8 What is the syntax for indexing the most signif-
icant bit in the type bit_vector(31 downto 0)?
Assume the vector is named example.
</p>
<p>5.4.9 What is the syntax for indexing the least signif-
icant bit in the type bit_vector(31 downto 0)?
Assume the vector is named example.
</p>
<p>5.4.10 What is the difference between an enumerated
type and a range type?
</p>
<p>5.4.11 What scalar type does a bit_vector consist of?
</p>
<p>5.4.12 What scalar type does a string consist of?
</p>
<p>Exercise Problems &bull; 171</p>
<p/>
</div>
<div class="page"><p/>
<p>Section 5.5: Modeling Concurrent Func-
</p>
<p>tionality in VHDL
</p>
<p>5.5.1 Design a VHDLmodel to implement the behav-
ior described by the 3-input minterm list shown
in Fig. 5.11. Use concurrent signal
assignments and logical operators. Declare
your entity to match the block diagram
provided. Use the type bit for your ports.
</p>
<p>5.5.2 Design a VHDLmodel to implement the behav-
ior described by the 3-input minterm list shown
in Fig. 5.11. Use conditional signal
assignments. Declare your entity to match the
block diagram provided. Use the type bit for
your ports.
</p>
<p>5.5.3 Design a VHDLmodel to implement the behav-
ior described by the 3-input minterm list shown
in Fig. 5.11. Use selected signal assignments.
Declare your entity to match the block diagram
provided. Use the type bit for your ports.
</p>
<p>5.5.4 Design a VHDLmodel to implement the behav-
ior described by the 3-input maxterm list shown
in Fig. 5.12. Use concurrent signal
assignments and logical operators. Declare
your entity to match the block diagram
provided. Use the type bit for your ports.
</p>
<p>5.5.5 Design a VHDLmodel to implement the behav-
ior described by the 3-input maxterm list shown
in Fig. 5.12. Use conditional signal
assignments. Declare your entity to match the
block diagram provided. Use the type bit for
your ports.
</p>
<p>5.5.6 Design a VHDLmodel to implement the behav-
ior described by the 3-input maxterm list shown
in Fig. 5.12. Use selected signal assignments.
Declare your entity to match the block diagram
provided. Use the type bit for your ports.
</p>
<p>5.5.7 Design a VHDLmodel to implement the behav-
ior described by the 3-input truth table shown in
Fig. 5.13. Use concurrent signal assignments
and logical operators. Declare your entity to
</p>
<p>match the block diagram provided. Use the
type bit for your ports.
</p>
<p>5.5.8 Design a VHDLmodel to implement the behav-
ior described by the 3-input truth table shown in
Fig. 5.13. Use conditional signal assignments.
Declare your entity to match the block diagram
provided. Use the type bit for your ports.
</p>
<p>5.5.9 Design a VHDLmodel to implement the behav-
ior described by the 3-input truth table shown in
Fig. 5.13. Use selected signal assignments.
Declare your entity to match the block diagram
provided. Use the type bit for your ports.
</p>
<p>5.5.10 Design a VHDLmodel to implement the behav-
ior described by the 4-input minterm list shown
in Fig. 5.14. Use concurrent signal
assignments and logical operators. Declare
your entity to match the block diagram
provided. Use the type bit for your ports.
</p>
<p>5.5.11 Design a VHDLmodel to implement the behav-
ior described by the 4-input minterm list shown
in Fig. 5.14. Use conditional signal
assignments. Declare your entity to match the
block diagram provided. Use the type bit for
your ports.
</p>
<p>5.5.12 Design a VHDLmodel to implement the behav-
ior described by the 4-input minterm list shown
in Fig. 5.14. Use selected signal assignments.
Declare your entity to match the block diagram
provided. Use the type bit for your ports.
</p>
<p>5.5.13 Design a VHDLmodel to implement the behav-
ior described by the 4-input maxterm list shown
in Fig. 5.15. Use concurrent signal
assignments and logical operators. Declare
your entity to match the block diagram
provided. Use the type bit for your ports.
</p>
<p>Fig. 5.13
System G Functionality
</p>
<p>Fig. 5.11
System E Functionality
</p>
<p>Fig. 5.14
System I Functionality
</p>
<p>Fig. 5.12
System F Functionality
</p>
<p>172 &bull; Chapter 5: VHDL (Part 1)</p>
<p/>
</div>
<div class="page"><p/>
<p>5.5.14 Design a VHDLmodel to implement the behav-
ior described by the 4-input maxterm list
shown in Fig. 5.15. Use conditional signal
assignments. Declare your entity to match the
block diagram provided. Use the type bit for
your ports.
</p>
<p>5.5.15 Design a VHDLmodel to implement the behav-
ior described by the 4-input maxterm list shown
in Fig. 5.15. Use selected signal assignments.
Declare your entity to match the block diagram
provided. Use the type bit for your ports.
</p>
<p>5.5.16 Design a VHDLmodel to implement the behav-
ior described by the 4-input truth table shown in
Fig. 5.16. Use concurrent signal assignments
and logical operators. Declare your entity to
match the block diagram provided. Use the
type bit for your ports.
</p>
<p>5.5.17 Design a VHDLmodel to implement the behav-
ior described by the 4-input truth table shown in
Fig. 5.16. Use conditional signal assignments.
Declare your entity to match the block diagram
provided. Use the type bit for your ports.
</p>
<p>5.5.18 Design a VHDLmodel to implement the behav-
ior described by the 4-input truth table shown in
Fig. 5.16. Use selected signal assignments.
Declare your entity to match the block diagram
provided. Use the type bit for your ports.
</p>
<p>Section 5.6: Structural Design in VHDL
</p>
<p>5.6.1 Design a VHDLmodel to implement the behav-
ior described by the 3-input minterm list shown
in Fig. 5.11. Use a structural design approach
and basic gates. You will need to create what-
ever basic gates are needed for your design
(e.g., INV1, AND2, OR4) and then instantiate
them in your upper level architecture to create
the desired functionality. The lower level gates
can be implemented with concurrent signal
assignments and logical operators (e.g., F &lt;&frac14;
not A). Declare your entity to match the block
diagram provided. Use the type bit for your
ports.
</p>
<p>5.6.2 Design a VHDLmodel to implement the behav-
ior described by the 3-input maxterm list shown
in Fig. 5.12. Use a structural design approach
and basic gates. You will need to create what-
ever basic gates are needed for your design
(e.g., INV1, AND2, OR4) and then instantiate
them in your upper level architecture to create
the desired functionality. The lower level gates
can be implemented with concurrent signal
assignments and logical operators (e.g., F &lt;&frac14;
not A). Declare your entity to match the block
diagram provided. Use the type bit for your
ports.
</p>
<p>5.6.3 Design a VHDLmodel to implement the behav-
ior described by the 3-input truth table shown in
Fig. 5.13. Use a structural design approach
and basic gates. You will need to create what-
ever basic gates are needed for your design
(e.g., INV1, AND2, OR4) and then instantiate
them in your upper level architecture to create
the desired functionality. The lower level gates
can be implemented with concurrent signal
assignments and logical operators (e.g., F &lt;&frac14;
not A). Declare your entity to match the block
diagram provided. Use the type bit for your
ports.
</p>
<p>5.6.4 Design a VHDLmodel to implement the behav-
ior described by the 4-input minterm list shown
in Fig. 5.14. Use a structural design approach
and basic gates. You will need to create what-
ever basic gates are needed for your design
(e.g., INV1, AND2, OR4) and then instantiate
them in your upper level architecture to create
the desired functionality. The lower level gates
can be implemented with concurrent signal
assignments and logical operators (e.g., F &lt;&frac14;
not A). Declare your entity to match the block
diagram provided. Use the type bit for your
ports.
</p>
<p>5.6.5 Design a VHDLmodel to implement the behav-
ior described by the 4-input maxterm list shown
in Fig. 5.15. Use a structural design approach
and basic gates. You will need to create what-
ever basic gates are needed for your design
(e.g., INV1, AND2, OR4) and then instantiate
them in your upper level architecture to create
</p>
<p>Fig. 5.16
System K Functionality
</p>
<p>Fig. 5.15
System J Functionality
</p>
<p>Exercise Problems &bull; 173</p>
<p/>
</div>
<div class="page"><p/>
<p>the desired functionality. The lower level gates
can be implemented with concurrent signal
assignments and logical operators (e.g., F &lt;&frac14;
not A). Declare your entity to match the block
diagram provided. Use the type bit for your
ports.
</p>
<p>5.6.6 Design a VHDLmodel to implement the behav-
ior described by the 4-input truth table shown in
Fig. 5.16. Use a structural design approach
and basic gates. You will need to create what-
ever basic gates are needed for your design
(e.g., INV1, AND2, OR4) and then instantiate
them in your upper level architecture to create
the desired functionality. The lower level gates
</p>
<p>can be implemented with concurrent signal
assignments and logical operators (e.g., F &lt;&frac14;
not A). Declare your entity to match the block
diagram provided. Use the type bit for your
ports.
</p>
<p>Section 5.7: Overview of Simulation Test
</p>
<p>Benches
</p>
<p>5.7.1 What is the purpose of a test bench?
</p>
<p>5.7.2 Does a test bench have input and output ports?
</p>
<p>5.7.3 Can a test bench be simulated?
</p>
<p>5.7.4 Can a test bench be synthesized?
</p>
<p>174 &bull; Chapter 5: VHDL (Part 1)</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 6: MSI Logic
This chapter introduces a group of combinational logic building blocks that are commonly used in
</p>
<p>digital design. As we move into systems that are larger than individual gates, there are naming
</p>
<p>conventions that are used to describe the size of the logic. Table 6.1 gives these naming conventions.
</p>
<p>In this chapter we look at medium-scale integrated circuit (MSI) logic. Each of these building blocks can
</p>
<p>be implemented using the combinational logic design steps covered in Chaps. 4 and 5. The goal of this
</p>
<p>chapter is to provide an understanding of the basic principles of MSI logic.
</p>
<p>Learning Outcomes&mdash;After completing this chapter, you will be able to:
</p>
<p>6.1 Design a decoder circuit using both the classical digital design approach and the modern
HDL-based approach.
</p>
<p>6.2 Design an encoder circuit using both the classical digital design approach and the modern
HDL-based approach.
</p>
<p>6.3 Design a multiplexer circuit using both the classical digital design approach and the
modern HDL-based approach.
</p>
<p>6.4 Design a demultiplexer circuit using both the classical digital design approach and the
modern HDL-based approach.
</p>
<p>6.1 Decoders
</p>
<p>A decoder is a circuit that takes in a binary code and has outputs that are asserted for specific values
</p>
<p>of that code. The code can be of any type or size (e.g., unsigned, two&rsquo;s complement). Each output will
</p>
<p>assert for only specific input codes. Since combinational logic circuits only produce a single output, this
</p>
<p>means that within a decoder, there will be a separate combinational logic circuit for each output.
</p>
<p>6.1.1 Example: One-Hot Decoder
</p>
<p>A one-hot decoder is a circuit that has n inputs and 2n outputs. Each output will assert for one and
</p>
<p>only one input code. Since there are 2n outputs, there will always be one and only one output asserted at
</p>
<p>Table 6.1
Naming convention for the size of digital systems
</p>
<p># Springer International Publishing Switzerland 2017
</p>
<p>B.J. LaMeres, Introduction to Logic Circuits &amp; Logic Design with VHDL,
</p>
<p>DOI 10.1007/978-3-319-34195-8_6
</p>
<p>175</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_4">http://dx.doi.org/10.1007/978-3-319-34195-8_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_5">http://dx.doi.org/10.1007/978-3-319-34195-8_5</a></div>
</div>
<div class="page"><p/>
<p>any given time. Example 6.1 shows the process of designing a 2-to-4 one-hot decoder by hand (i.e.,
</p>
<p>using the classical digital design approach).
</p>
<p>Example 6.1
2-to-4 One-Hot Decoder&mdash;Logic Synthesis by Hand
</p>
<p>As decoders get larger, it is necessary to use hardware description languages to model their
</p>
<p>behavior. Example 6.2 shows how to model a 3-to-8 one-hot decoder in VHDL with concurrent signal
</p>
<p>assignments and logic operators.
</p>
<p>176 &bull; Chapter 6: MSI Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 6.2
3-to-8 One-Hot Decoder&mdash;VHDL Modeling Using Logical Operators
</p>
<p>This description can be further simplified by using vector notation for the ports and describing the
</p>
<p>functionality using either conditional or select signal assignment. Example 6.3 shows how to model the
</p>
<p>3-to-8 one-hot decoder in VHDL with conditional and select signal assignments.
</p>
<p>6.1 Decoders &bull; 177</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 6.3
3-to-8 One-Hot Decoder&mdash;VHDL Modeling Using Conditional and Select Signal Assignments
</p>
<p>178 &bull; Chapter 6: MSI Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>6.1.2 Example: Seven-Segment Display Decoder
</p>
<p>A seven-segment display decoder is a circuit used to drive character displays that are commonly
</p>
<p>found in applications such as digital clocks and household appliances. A character display is made up of
</p>
<p>seven individual LEDs, typically labeled a&ndash;g. The input to the decoder is the binary equivalent of the
</p>
<p>decimal or Hex character that is to be displayed. The output of the decoder is the arrangement of LEDs
</p>
<p>that will form the character. Decoders with 2-inputs can drive characters &ldquo;0&rdquo; to &ldquo;3.&rdquo;Decoders with 3-inputs
</p>
<p>can drive characters &ldquo;0&rdquo; to &ldquo;7.&rdquo; Decoders with 4-inputs can drive characters &ldquo;0&rdquo; to &ldquo;F&rdquo; with the case of the
</p>
<p>Hex characters being &ldquo;A, b, c or C, d, E, and F.&rdquo;
</p>
<p>Let&rsquo;s look at an example of how to design a 3-input, seven-segment decoder by hand. The first step
</p>
<p>in the process is to create the truth table for the outputs that will drive the LEDs in the display. We&rsquo;ll call
</p>
<p>these outputs Fa, Fb, . . ., Fg. Example 6.4 shows how to construct the truth table for the seven-segment
</p>
<p>display decoder. In this table, a logic 1 corresponds to the LED being ON.
</p>
<p>Example 6.4
Seven-Segment Display Decoder&mdash;Truth Table
</p>
<p>If we wish to design this decoder by hand we need to create seven separate combinational logic
</p>
<p>circuits. Each of the outputs (Fa&ndash;Fg) can be put into a 3-input K-map to find the minimized logic
</p>
<p>expression. Example 6.5 shows the design of the decoder from the truth table in Example 6.4 by hand.
</p>
<p>6.1 Decoders &bull; 179</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 6.5
Seven-Segment Display Decoder&mdash;Logic Synthesis by Hand
</p>
<p>This same functionality can be modeled in VHDL using concurrent signal assignments with logical
</p>
<p>operators. Example 6.6 shows how to model the seven-segment decoder in VHDL using concurrent
</p>
<p>signal assignments with logic operators.
</p>
<p>180 &bull; Chapter 6: MSI Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 6.6
Seven-Segment Display Decoder&mdash;Modeling Using Logical Operators
</p>
<p>Again, a more compact description of the decoder can be accomplished if the ports are described as
</p>
<p>vectors and a conditional or select signal assignment is used. Example 6.7 shows how to model the
</p>
<p>seven-segment decoder in VHDL using conditional and selected signal assignments.
</p>
<p>6.1 Decoders &bull; 181</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 6.7
Seven-Segment Display Decoder&mdash;Modeling Using Conditional and Selected Signal Assignments
</p>
<p>CC6.1 In a decoder, a logic expression is created for each output.  Once all of the output logic 
expressions are found, how can the decoder logic be further minimized?
</p>
<p>A) By using K-maps to find the output logic expressions.
</p>
<p>B) By buffering the inputs so that they can drive a large number of other gates.
</p>
<p>C) By identifying any logic terms that are used in multiple locations (inversions, 
product terms, and sum terms) and sharing the interim results among multiple 
circuits in the decoder.
</p>
<p>D) By ignoring fan-out.
</p>
<p>CONCEPT CHECK
</p>
<p>182 &bull; Chapter 6: MSI Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>6.2 Encoders
</p>
<p>An encoder works in the opposite manner as a decoder. An assertion on a specific input port
</p>
<p>corresponds to a unique code on the output port.
</p>
<p>6.2.1 Example: One-Hot Binary Encoder
</p>
<p>A one-hot binary encoder has n outputs and 2n inputs. The output will be an n-bit, binary code which
</p>
<p>corresponds to an assertion on one and only one of the inputs. Example 6.8 shows the process of
</p>
<p>designing a 4-to-2 binary encoder by hand (i.e., using the classical digital design approach).
</p>
<p>Example 6.8
4-to-2 Binary Encoder&mdash;Logic Synthesis by Hand
</p>
<p>In VHDL this can be implemented using logical operators, conditional signal assignments, or
</p>
<p>selected signal assignments. In the conditional and selected signal assignments, if an output is not
</p>
<p>listed for each and every input possibility, then an output must be specified to cover any remaining input
</p>
<p>conditions. In the conditional signal assignment, the covering value is specified after the final else
</p>
<p>statement. In the selected signal assignment, the covering value is specified using the when others
</p>
<p>clause. Example 6.9 shows how to model the encoder in VHDL using each of the abovementioned
</p>
<p>modeling techniques.
</p>
<p>6.2 Encoders &bull; 183</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 6.9
4-to-2 Binary Encoder&mdash;VHDL Modeling
</p>
<p>184 &bull; Chapter 6: MSI Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>CC6.2 If it is desired to have the outputs of an encoder produce 0&rsquo;s for all input codes not defined 
</p>
<p>in the truth table, can &ldquo;don&rsquo;t cares&rdquo; be used when deriving the minimized logic 
expressions? Why?
</p>
<p>A) No. Don&rsquo;t cares aren&rsquo;t used in encoders.
</p>
<p>B) Yes. Don&rsquo;t cares can always be used in K-maps.
</p>
<p>C) Yes. All that needs to be done is to treat each X as a 0 when forming the most 
minimal prime implicant.
</p>
<p>D) No. Each cell in the K-map corresponding to an undefined input code needs to 
contain a 0 so don&rsquo;t cares are not applicable.
</p>
<p>CONCEPT CHECK
</p>
<p>6.3 Multiplexers
</p>
<p>A multiplexer is a circuit that passes one of its multiple inputs to a single output based on a select
</p>
<p>input. This can be thought of as a digital switch. The multiplexer has n select lines, 2n inputs, and one
</p>
<p>output. Example 6.10 shows the process of designing a 2-to-1 multiplexer by hand (i.e., using the
</p>
<p>classical digital design approach).
</p>
<p>Example 6.10
2-to-1 Multiplexer&mdash;Logic Synthesis by Hand
</p>
<p>6.3 Multiplexers &bull; 185</p>
<p/>
</div>
<div class="page"><p/>
<p>Again, in VHDL a multiplexer can be implemented using different behavioral models. Let&rsquo;s look at
</p>
<p>the modeling of a 4-to-1 multiplexer in VHDL using logical operators, conditional signal assignments, and
</p>
<p>selected signal assignments. This multiplexer requires two select lines to address each of the four input
</p>
<p>lines. Each of the product terms in the multiplexer logic expression must include both select lines. The
</p>
<p>polarity of the select lines is chosen so that when an input is selected, its product term will allow the input
</p>
<p>to pass to the OR gate. In the VHDL implementation of the multiplexer using conditional and selected
</p>
<p>signal assignments, since every possible value of Sel is listed, it is not necessary to use a final else or
</p>
<p>when others clause. Example 6.11 shows the VHDL modeling of a 4-to-1 multiplexer.
</p>
<p>Example 6.11
4-to-1 Multiplexer&mdash;VHDL Modeling
</p>
<p>186 &bull; Chapter 6: MSI Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>CC6.3 How are the product terms in a multiplexer based on the identity theorem?
</p>
<p>A) Only the select product term will pass its input to the final sum term.  Since all of 
the unselected product terms output 0, the input will be passed through the sum 
term because anything OR&rsquo;d with a 0 is itself.
</p>
<p>B) The select lines are complemented such that they activate only one OR gate.
</p>
<p>C) The select line inputs will produce 1&rsquo;s on the inputs of the selected product term.  
This allows the input signal to pass through the selected AND gate because 
anything AND&rsquo;d with a 1 is itself.
</p>
<p>D) The select line inputs will produce 0&rsquo;s on the inputs of the selected sum term.  This 
allows the input signal to pass through the selected OR gate because anything 
OR&rsquo;d with a 0 is itself.
</p>
<p>CONCEPT CHECK
</p>
<p>6.4 Demultiplexers
</p>
<p>A demultiplexer works in a complementary fashion to a multiplexer. A demultiplexer has one input
</p>
<p>that is routed to one of its multiple outputs. The output that is active is dictated by a select input. A demux
</p>
<p>has n select lines that chooses to route the input to one of its 2n outputs. When an output is not selected,
</p>
<p>it outputs a logic 0. Example 6.12 shows the process of designing a 1-to-2 demultiplexer by hand (i.e.,
</p>
<p>using the classical digital design approach).
</p>
<p>Example 6.12
1-to-2 Demultiplexer&mdash;Logic Synthesis by Hand
</p>
<p>6.4 Demultiplexers &bull; 187</p>
<p/>
</div>
<div class="page"><p/>
<p>Again, in VHDL a demultiplexer can be implemented using different behavioral models. Example
</p>
<p>6.13 shows the modeling of a 1-to-4 demultiplexer in VHDL using logical operators, conditional signal
</p>
<p>assignments, and selected signal assignments. This demultiplexer requires two select lines in order to
</p>
<p>choose between the four outputs.
</p>
<p>Example 6.13
1-to-4 Demultiplexer&mdash;VHDL Modeling
</p>
<p>188 &bull; Chapter 6: MSI Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>CC6.4 How many select lines are needed in a 1-to-64 demultiplexer?
</p>
<p>A) 1 B) 4 C) 6         D) 64
</p>
<p>CONCEPT CHECK
</p>
<p>Summary
</p>
<p>v The term medium-scale integrated circuit
(MSI) logic refers to a set of basic combina-
tional logic circuits that implement simple,
commonly used functions such as decoders,
encoders, multiplexers, and demultiplexers.
MSI logic can also include operations such
as comparators and simple arithmetic
circuits.
</p>
<p>v While an MSI logic circuit may have multiple
outputs, each output requires its own unique
logic expression that is based on the system
inputs.
</p>
<p>v A decoder is a system that has a greater
number of outputs than inputs. The behavior
of each output is based on each unique
input code.
</p>
<p>v An encoder a system that has a greater num-
ber of inputs than outputs. A compressed
output code is produced based on which
input(s) lines are asserted.
</p>
<p>v A multiplexer is a system that has one output
and multiple inputs. At any given time, one
and only one input is routed to the output
based on the value on a set of select
lines. For n select lines, a multiplexer can
support 2n inputs.
</p>
<p>v A demultiplexer is a system that has one
input and multiple outputs. The input is
routed to one of the outputs depending on
the value on a set of select lines. For n select
lines, a demultiplexer can support 2n outputs.
</p>
<p>v HDLs are particularly useful for describing
MSI logic due to their abstract modeling
capability. Through the use of Boolean
conditions and vector assignments, the
behavior of MSI logic can be modeled in a
compact and intuitive manner.
</p>
<p>6.4 Demultiplexers &bull; 189</p>
<p/>
</div>
<div class="page"><p/>
<p>Exercise Problems
</p>
<p>Section 6.1&mdash;Decoders
</p>
<p>6.1.1 Design a 4-to-16 one-hot decoder by hand.
The block diagram and truth table for the
decoder are given in Fig. 6.1. Give the
minimized logic expressions for each output
(i.e., F0, F1, . . ., F15) and the full logic diagram
for the system.
</p>
<p>6.1.2 Design a VHDL model for a 4-to-16 one-hot
decoder using concurrent signal assignments
and logical operators. Use the entity definition
given in Fig. 6.2.
</p>
<p>6.1.3 Design a VHDL model for a 4-to-16 one-hot
decoder using conditional signal assignments.
Use the entity definition given in Fig. 6.2.
</p>
<p>6.1.4 Design a VHDL model for a 4-to-16 one-hot
decoder using selected signal assignments.
Use the entity definition given in Fig. 6.2.
</p>
<p>6.1.5 Design a 4-input, seven-segment HEX charac-
ter decoder by hand. The system has four
inputs called A, B, C, and D. The system has
seven outputs called Fa, Fb, Fc, Fd, Fe, Ff, and
Fg. These outputs drive the individual LEDs
within the display. A logic 1 on an output
corresponds to the LED being ON. The display
will show the HEX characters 0&ndash;9, A, b, c, d, E,
and F corresponding to the 4-bit input code on
A. A template for creating the truth tables for
this system is provided in Fig. 6.3. Provide the
minimized logic expressions for each of the
seven outputs and the overall logic diagram
for the decoder.
</p>
<p>Fig. 6.1
4-to-16 One-Hot Decoder Functionality
</p>
<p>Fig. 6.2
4-to-16 One-Hot Decoder Entity
</p>
<p>190 &bull; Chapter 6: MSI Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>6.1.6 Design a VHDL model for a 4-input, seven-
segment HEX character decoder using condi-
tional signal assignments. Use the entity defi-
nition given in Fig. 6.4 for your design. The
system has a 4-bit input vector called A and a
7-bit output vector called F. The individual
scalars within the output vector (i.e., F
(6 downto 0)) correspond to the character dis-
play segments a, b, c, d, e, f, and g, respec-
tively. A logic 1 on an output corresponds to the
LED being ON. The display will show the HEX
characters 0&ndash;9, A, b, c, d, E, and F
corresponding to the 4-bit input code on A. A
</p>
<p>template for creating the truth table is provided
in Fig. 6.3. The signals in this table correspond
to the entity in this problem as follows: A &frac14; A
(3), B &frac14; A(2), C &frac14; A(1), D &frac14; A(0), Fa &frac14; F(6),
Fb &frac14; F(5), Fc &frac14; F(4), Fd &frac14; F(3), Fe &frac14; F(2), Ff
&frac14; F(1), and Fg &frac14; F(0).
</p>
<p>Fig. 6.3
7-Segment Display Decoder Truth Table
</p>
<p>Fig. 6.4
7-Segment Display Decoder Entity
</p>
<p>Exercise Problems &bull; 191</p>
<p/>
</div>
<div class="page"><p/>
<p>6.1.7 Design a VHDL model for a 4-input, seven-
segment HEX character decoder using
selected signal assignments. Use the entity
definition given in Fig. 6.4 for your design.
The system has a 4-bit input vector called A
and a 7-bit output vector called F. The individ-
ual scalars within the output vector (i.e., F
(6 downto 0)) correspond to the character dis-
play segments a, b, c, d, e, f, and g, respec-
tively. A logic 1 on an output corresponds to the
LED being ON. The display will show the HEX
characters 0&ndash;9, A, b, c, d, E, and F
corresponding to the 4-bit input code on A. A
template for creating the truth table for this
system is provided in Fig. 6.3. The signals in
this table correspond to the entity in this prob-
lem as follows: A &frac14; A(3), B &frac14; A(2), C &frac14; A(1),
D &frac14; A(0), Fa &frac14; F(6), Fb &frac14; F(5), Fc &frac14; F(4), Fd
&frac14; F(3), Fe &frac14; F(2), Ff &frac14; F(1), and Fg &frac14; F(0).
</p>
<p>Section 6.2&mdash;Encoders
</p>
<p>6.2.1 Design an 8-to-3 binary encoder by hand. The
block diagram and truth table for the encoder
are given in Fig. 6.5. Give the logic expressions
for each output and the full logic diagram for
the system.
</p>
<p>6.2.2 Design a VHDL model for an 8-to-3 binary
encoder using concurrent signal assignments
and logical operators. Use the entity definition
given in Fig. 6.6 for your design.
</p>
<p>6.2.3 Design a VHDL model for an 8-to-3 binary
encoder using conditional signal assignments.
Use the entity definition given in Fig. 6.6 for
your design.
</p>
<p>6.2.4 Design a VHDL model for an 8-to-3 binary
encoder using selected signal assignments.
Use the entity definition given in Fig. 6.6 for
your design.
</p>
<p>Section 6.3&mdash;Multiplexers
</p>
<p>6.3.1 Design an 8-to-1 multiplexer by hand. The
block diagram and truth table for the multi-
plexer are given in Fig. 6.7. Give the minimized
logic expressions for the output and the full
logic diagram for the system.
</p>
<p>6.3.2 Design a VHDL model for an 8-to-1 multiplexer
using concurrent signal assignments and logi-
cal operators. Use the entity definition given in
Fig. 6.8 for your design.
</p>
<p>6.3.3 Design a VHDL model for an 8-to-1 multiplexer
using conditional signal assignments. Use the
entity definition given in Fig. 6.8 for your
design.
</p>
<p>6.3.4 Design a VHDL model for an 8-to-1 multiplexer
using selected signal assignments. Use the
entity definition given in Fig. 6.8 for your
design.
</p>
<p>Section 6.4&mdash;Demultiplexers
</p>
<p>6.4.1 Design a 1-to-8 demultiplexer by hand. The
block diagram and truth table for the demulti-
plexer are given in Fig. 6.9. Give the minimized
logic expressions for each output and the full
logic diagram for the system.
</p>
<p>Fig. 6.5
8-to-3 One-Hot Encoder Functionality
</p>
<p>Fig. 6.6
8-to-3 One-Hot Encoder Entity
</p>
<p>Fig. 6.7
8-to-1 Multiplexer Functionality
</p>
<p>Fig. 6.8
8-to-1 Multiplexer Entity
</p>
<p>192 &bull; Chapter 6: MSI Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>6.4.2 Design a VHDL model for a 1-to-8 demulti-
plexer using concurrent signal assignments
and logical operators. Use the entity definition
given in Fig. 6.10 for your design.
</p>
<p>6.4.3 Design a VHDL model for a 1-to-8 demulti-
plexer using conditional signal assignments.
Use the entity definition given in Fig. 6.10 for
your design.
</p>
<p>6.4.4 Design a VHDL model for a 1-to-8 demulti-
plexer using selected signal assignments.
Use the entity definition given in Fig. 6.10 for
your design.
</p>
<p>Fig. 6.9
1-to-8 Demultiplexer Functionality
</p>
<p>Fig. 6.10
1-to-8 Demultiplexer Entity
</p>
<p>Exercise Problems &bull; 193</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 7: Sequential Logic Design
In this chapter we begin looking at sequential logic design. Sequential logic design differs from
</p>
<p>combinational logic design in that the outputs of the circuit depend not only on the current values of the
</p>
<p>inputs but also on the past values of the inputs. This is different from the combinational logic design
</p>
<p>where the output of the circuitry depends only on the current values of the inputs. The ability of a
</p>
<p>sequential logic circuit to base its outputs on both the current and past inputs allows more sophisticated
</p>
<p>and intelligent systems to be created. We begin by looking at sequential logic storage devices, which are
</p>
<p>used to hold the past values of a system. This is followed by an investigation of timing considerations of
</p>
<p>sequential logic circuits. We then look at some useful circuits that can be created using only sequential
</p>
<p>logic storage devices. Finally, we look at one of the most important logic circuits in digital systems, the
</p>
<p>finite-state machine (FSM). The goal of this chapter is to provide an understanding of the basic operation
</p>
<p>of sequential logic circuits.
</p>
<p>Learning Outcomes&mdash;After completing this chapter, you will be able to:
</p>
<p>7.1 Describe the operation of a sequential logic storage device.
7.2 Describe sequential logic timing considerations.
7.3 Design a variety of common circuits based on sequential storage devices (toggle flops,
</p>
<p>ripple counters, switch debouncers, and shift registers).
7.4 Design an FSM using the classical digital design approach.
7.5 Design a counter using the classical digital design approach and using an HDL-based,
</p>
<p>structural approach.
7.6 Describe the FSM reset condition.
7.7 Analyze an FSM to determine its functional operation and maximum clock frequency.
</p>
<p>7.1 Sequential Logic Storage Devices
</p>
<p>7.1.1 The Cross-Coupled Inverter Pair
</p>
<p>The first thing that is needed in sequential logic is a storage device. The fundamental storage device
</p>
<p>in sequential logic is based on a positive feedback configuration. Consider the circuit in Fig. 7.1. This
</p>
<p>circuit configuration is called the cross-coupled inverter pair. In this circuit if the input of U1 starts with a
</p>
<p>value of 1, it will produce an output of Q &frac14; 0. This output is fed back to the input of U2, thus producing an
</p>
<p>output of Qn &frac14; 1. Qn is fed back to the original input of U1, thus reinforcing the initial condition. This
</p>
<p>circuit will hold, or store, a logic 0 without being driven by any other inputs. This circuit operates in a
</p>
<p>complementary manner when the initial value of U1 is a 0. With this input condition, the circuit will store a
</p>
<p>logic 1 without being driven by any other inputs.
</p>
<p># Springer International Publishing Switzerland 2017
</p>
<p>B.J. LaMeres, Introduction to Logic Circuits &amp; Logic Design with VHDL,
</p>
<p>DOI 10.1007/978-3-319-34195-8_7
</p>
<p>195</p>
<p/>
</div>
<div class="page"><p/>
<p>7.1.2 Metastability
</p>
<p>The cross-coupled inverter pair in Fig. 7.1 exhibits what is called metastable behavior due to its
</p>
<p>positive-feedback configuration. Metastability refers to when a system can exist in a state of equilibrium
</p>
<p>when undisturbed but can be moved to a different, more stable state of equilibrium when sufficiently
</p>
<p>disturbed. Systems that exhibit high levels of metastability have an equilibrium state that is highly
</p>
<p>unstable, meaning that if disturbed even slightly the system will move rapidly to a more stable point of
</p>
<p>equilibrium. The cross-coupled inverter pair is a highly metastable system. This system actually contains
</p>
<p>three equilibrium states. The first is when the input of U1 is exactly between a logic 0 and logic 1 (i.e.,
</p>
<p>VCC/2). In this state, the output of U1 is also exactly VCC/2. This voltage is fed back to the input of U2, thus
</p>
<p>producing an output of exactly VCC/2 on U2. This in turn is fed back to the original input on U1 reinforcing
</p>
<p>the initial state. Despite this system being at equilibrium in this condition, this state is highly unstable.
</p>
<p>With minimal disturbance to any of the nodes within the system, it will move rapidly to one of the twomore
</p>
<p>stable states. The two stable states for this system are when Q &frac14; 0 or when Q &frac14; 1 (see Fig. 7.1). Once
</p>
<p>the transition begins between the unstable equilibrium state toward one of the twomore stable states, the
</p>
<p>positive feedback in the system continually reinforces the transition until the system reaches its final
</p>
<p>state. In electrical systems, this initial disturbance is caused by the presence of noise, or unwanted
</p>
<p>voltage in the system. Noise can come from many sources including random thermal motion of charge
</p>
<p>carriers in the semiconductor materials, electromagnetic energy, or naturally occurring ionizing particles.
</p>
<p>Noise is present in every electrical system so the cross-coupled inverter pair will never be able to stay in
</p>
<p>the unstable equilibrium state where all nodes are at VCC/2.
</p>
<p>The cross-coupled inverter pair has two stable states; thus it is called a bistable element. In order to
</p>
<p>understand the bistable behavior of this circuit, let&rsquo;s look at its behavior when the initial input value on U1
</p>
<p>is set directly between a logic 0 and logic 1 (i.e., VCC/2) and how a small amount of noise will cause the
</p>
<p>system to move toward a stable state. Recall that an inverter is designed to have an output that quickly
</p>
<p>transitions between a logic LOW and HIGH in order to minimize the time spent in the uncertainty region.
</p>
<p>This is accomplished by designing the inverter to have what is called gain. Gain can be thought of as a
</p>
<p>multiplying factor that is applied to the input of the circuit when producing the output (i.e., Vout &frac14; gain∙Vin).
</p>
<p>The gain for an inverter will be negative since the output moves in the opposite direction of the input. The
</p>
<p>inverter is designed to have a very high gain such that even the smallest change on the input when in the
</p>
<p>transition region will result in a large change on the output. Consider the behavior of this circuit shown in
</p>
<p>Fig. 7.2. In this example, let&rsquo;s represent the gain of the inverter as �g and see how the system responds
</p>
<p>when a small positive voltage noise (Vn) is added to the VCC/2 input on U1.
</p>
<p>Fig. 7.1
Storage using a cross-coupled inverter pair
</p>
<p>196 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Figure 7.3 shows how the system responds when a small negative voltage noise (�Vn) is added to
</p>
<p>the VCC/2 input on U1.
</p>
<p>Fig. 7.2
Examining metastability moving toward the state Q &frac14; 0
</p>
<p>7.1 Sequential Logic Storage Devices &bull; 197</p>
<p/>
</div>
<div class="page"><p/>
<p>7.1.3 The SR Latch
</p>
<p>While the cross-coupled inverter pair is the fundamental storage concept for sequential logic, there
</p>
<p>is no mechanism to set the initial value of Q. All that is guaranteed is that the circuit will store a value in
</p>
<p>one of the two stable states (Q &frac14; 0 or Q &frac14; 1). The SR Latch provides ameans to control the initial values
</p>
<p>in this positive-feedback configuration by replacing the inverters with NOR gates. In this circuit, S stands
</p>
<p>for set and indicates when the output is forced to a logic 1 (Q &frac14; 1), and R stands for reset and indicates
</p>
<p>when the output is forced to a logic 0 (Q &frac14; 0). When both S &frac14; 0 and R &frac14; 0, the SR Latch is put into a
</p>
<p>store mode and it will hold the last value of Q. In all of these input conditions, Qn is the complement of
</p>
<p>Q. Consider the behavior of the SR Latch during its store state shown in Fig. 7.4.
</p>
<p>Fig. 7.3
Examining metastability moving toward the state Q &frac14; 1
</p>
<p>198 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>The SR Latch has two input conditions that will force the outputs to known values. The first condition
</p>
<p>is called the set state. In this state, the inputs are configured as S &frac14; 1 and R &frac14; 0. This input condition will
</p>
<p>force the outputs to Q &frac14; 1 (e.g., setting Q) and Qn &frac14; 0. The second input condition is called the reset
</p>
<p>state. In this state the inputs are configured as S &frac14; 0 and R &frac14; 1. This input condition will force the
</p>
<p>outputs to Q &frac14; 0 (i.e., resetting Q) and Qn &frac14; 1. Consider the behavior of the SR Latch during its set and
</p>
<p>reset states shown in Fig. 7.5.
</p>
<p>Fig. 7.4
SR Latch behavior&mdash;store state (S &frac14; 0, R &frac14; 0)
</p>
<p>7.1 Sequential Logic Storage Devices &bull; 199</p>
<p/>
</div>
<div class="page"><p/>
<p>The final input condition for the SR Latch leads to potential metastability and should be avoided.
</p>
<p>When S &frac14; 1 and R &frac14; 1, the outputs of the SR Latch will both go to logic 0&rsquo;s. The problem with this state
</p>
<p>is that if the inputs subsequently change to the store state (S &frac14; 0, R &frac14; 0), the outputs will go metastable
</p>
<p>and then settle in one of the two stable states (Q &frac14; 0 or Q &frac14; 1). The reason this state is avoided is
</p>
<p>because the final resting state of the SR Latch is random and unknown. Consider this operation shown in
</p>
<p>Fig. 7.6.
</p>
<p>Fig. 7.5
SR Latch behavior&mdash;set (S &frac14; 1, R &frac14; 0) and reset (S &frac14; 0, R &frac14; 1) states
</p>
<p>Fig. 7.6
SR Latch behavior&mdash;don&rsquo;t use state (S &frac14; 1 and R &frac14; 1)
</p>
<p>200 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Figure 7.7 shows the final truth table for the SR Latch.
</p>
<p>The SR Latch has some drawbacks when it comes to implementation with real circuitry. First, it takes
</p>
<p>two independent inputs to control the outputs. Second, the state where S &frac14; 1 and R &frac14; 1 causes
</p>
<p>problems when real propagation delays are considered through the gates. Since it is impossible to
</p>
<p>match the delays exactly between U1 and U2, the SR Latch may occasionally enter this state and
</p>
<p>experience momentary metastable behavior. In order to address these issues, a number of
</p>
<p>improvements can be made to this circuit to create two of the most commonly used storage devices in
</p>
<p>sequential logic, the D-Latch and the D-flip-flop. In order to understand the operation of these storage
</p>
<p>devices, two incremental modifications are made to the SR Latch. The first is called the S0R0 Latch and
</p>
<p>the second is the SR Latch with enable. These two circuits are rarely implemented and are only
</p>
<p>explained to understand how the SR Latch is modified to create a D-Latch and ultimately a D-flip-flop.
</p>
<p>7.1.4 The S0R0 Latch
</p>
<p>The S0R0 Latch operates in a similar manner as the SR Latch with the exception that the input codes
</p>
<p>corresponding to the store, set, and reset states are complemented. To accomplish this complementary
</p>
<p>behavior, the S0R0 Latch is implemented with NAND gates configured in a positive-feedback configura-
</p>
<p>tion. In this configuration, the S0R0 Latch will store the last output when S0 &frac14; 1 and R0 &frac14; 1. It will set the
</p>
<p>output (Q &frac14; 1) when S0 &frac14; 0 and R0 &frac14; 1. Finally, it will reset the output (Q &frac14; 0) when S0 &frac14; 1 and R0 &frac14; 0.
</p>
<p>Consider the behavior of the S0R0 Latch during its store state shown in Fig. 7.8.
</p>
<p>Fig. 7.7
SR Latch truth table
</p>
<p>7.1 Sequential Logic Storage Devices &bull; 201</p>
<p/>
</div>
<div class="page"><p/>
<p>Just as with the SR Latch, the S0R0 Latch has two input configurations to control the values of the
</p>
<p>outputs. Consider the behavior of the S0R0 Latch during its set and reset states shown in Fig. 7.9.
</p>
<p>Fig. 7.8
S0R0 Latch behavior&mdash;store state (S0 &frac14; 1, R0 &frac14; 1)
</p>
<p>202 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>And finally, just as with the SR Latch, the S0R0 Latch has a state that leads to potential metastability
</p>
<p>and should be avoided. Consider the operation of the S0R0 Latch when the inputs are configured as
</p>
<p>S0 &frac14; 0 and R0 &frac14; 0 shown in Fig. 7.10.
</p>
<p>The final truth table for the S0R0 Latch is given in Fig. 7.11.
</p>
<p>Fig. 7.10
S0R0 Latch behavior&mdash;don&rsquo;t use state (S0 &frac14; 0 and R0 &frac14; 0)
</p>
<p>Fig. 7.9
S0R0 Latch behavior&mdash;set (S0 &frac14; 0, R0 &frac14; 1) and reset (S0 &frac14; 1, R0 &frac14; 0) states
</p>
<p>7.1 Sequential Logic Storage Devices &bull; 203</p>
<p/>
</div>
<div class="page"><p/>
<p>7.1.5 SR Latch with Enable
</p>
<p>The next modification that is made in order to move toward a D-Latch and ultimately a D-flip-flop is to
</p>
<p>add an enable line to the S0R0 Latch. The enable is implemented by adding two NAND gates on the input
</p>
<p>stage of the S0R0 Latch. The SR Latch with enable is shown in Fig. 7.12. In this topology, the use of NAND
</p>
<p>gates changes the polarity of the inputs, so this circuit once again has a set state where S &frac14; 1, R &frac14; 0
</p>
<p>and a reset state of S &frac14; 0 and R &frac14; 1. The enable line is labeled C, which stands for clock. The rationale
</p>
<p>for this will be demonstrated upon moving through the explanation of the D-Latch.
</p>
<p>Recall that any time a 0 is present on one of the inputs to a NAND gate, the output will always be a
</p>
<p>1 regardless of the value of the other inputs. In the SR Latch with enable configuration, any time C &frac14; 0,
</p>
<p>the outputs of U3 and U4 will be 1&rsquo;s and will be fed into the inputs of the cross-coupled NAND gate
</p>
<p>configuration (U1 and U2). Recall that the cross-coupled configuration of U1 and U2 is an S0R0 Latch and
</p>
<p>will be put into a store state when S0 &frac14; 1 and R0 &frac14; 1. This is the store state (C &frac14; 0). When C &frac14; 1, it has
</p>
<p>the effect of inverting the values of the S and R inputs before they reach U1 and U2. This condition allows
</p>
<p>the set state to be entered when S &frac14; 1, R &frac14; 0, and C &frac14; 1 and the reset state to be entered when S &frac14; 0,
</p>
<p>R &frac14; 1, and C &frac14; 1. Consider this operation in Fig. 7.13.
</p>
<p>Fig. 7.11
S0R0 Latch truth table
</p>
<p>Fig. 7.12
SR Latch with enable schematic
</p>
<p>204 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Again, there is a potential metastable state when S &frac14; 1, R &frac14; 1, and C &frac14; 1 that should be avoided.
</p>
<p>There is also a second store state when S &frac14; 0, R &frac14; 0, and C &frac14; 1 that is not used because storage is to
</p>
<p>be dictated by the C input.
</p>
<p>7.1.6 The D-Latch
</p>
<p>The SR Latch with enable can be modified to create a new storage device called a D-Latch. Instead
</p>
<p>of having two separate input lines to control the outputs of the latch, the R input of the latch is instead
</p>
<p>Fig. 7.13
SR Latch with enable behavior&mdash;store, set, and reset
</p>
<p>7.1 Sequential Logic Storage Devices &bull; 205</p>
<p/>
</div>
<div class="page"><p/>
<p>driven with an inverted version of the S input. This prevents the S and R inputs from ever being the same
</p>
<p>value and removes the two &ldquo;Don&rsquo;t Use&rdquo; states in the truth table shown in Fig. 7.12. The new, single input
</p>
<p>is renamed D to stand for data. This new circuit still has the behavior that it will store the last value of Q
</p>
<p>and Qn when C &frac14; 0. When C &frac14; 1, the output will be Q &frac14; 1 when D &frac14; 1 and will be Q &frac14; 0 when D &frac14; 0.
</p>
<p>The behavior of the output when C &frac14; 1 is called tracking the input. The D-Latch schematic, symbol, and
</p>
<p>truth table are given in Fig. 7.14.
</p>
<p>The timing diagram for the D-Latch is shown in Fig. 7.15.
</p>
<p>Fig. 7.14
D-Latch schematic, symbol, and truth table
</p>
<p>Fig. 7.15
D-Latch timing diagram
</p>
<p>206 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>7.1.7 The D-Flip-Flop
</p>
<p>The final and most widely used storage device in sequential logic is the D-flip-flop. The D-flip-flop is
</p>
<p>similar in behavior to the D-Latch with the exception that the store mode is triggered by a transition, or
</p>
<p>edge on the clock signal instead of a level. This allows the D-flip-flop to implement higher frequency
</p>
<p>systems since the outputs are updated in a shorter amount of time. The schematic, symbol, and truth
</p>
<p>table are given in Fig. 7.16 for a rising edge triggered D-flip-flop. To indicate that the device is edge
</p>
<p>sensitive, the input for the clock is designated with a &ldquo;&gt;.&rdquo; The U3 inverter in this schematic creates the
</p>
<p>rising edge behavior. If U3 is omitted, this circuit would be a negative edge triggered D-flip-flop.
</p>
<p>The D-flip-flop schematic shown above is called a master/slave configuration because of how the
</p>
<p>data is passed through the two D-Latches (U1 and U2). Due to the U4 inverter, the two D-Latches will
</p>
<p>always be in complementary modes. When U1 is in hold mode, U2 will be in track mode and vice versa.
</p>
<p>When the clock signal transitions HIGH, U1 will store the last value of data. During the time when the
</p>
<p>clock is HIGH, U2 will enter track mode and pass this value to Q. In this way, the data is latched into the
</p>
<p>storage device on the rising edge of the clock and is present on Q. This is the master operation of the
</p>
<p>device because U1, or the first D-Latch, is holding the value, and the second D-Latch (the slave) is simply
</p>
<p>passing this value to the output Q. When the clock transitions LOW, U2 will store the output of U1. Since
</p>
<p>there is a finite delay through U1, the U2 D-Latch is able to store the value before U1 fully enters track
</p>
<p>mode. U2 will drive Q for the duration of the time that the clock is LOW. This is the slave operation of the
</p>
<p>device because U2, or the second D-Latch, is holding the value. During the time the clock is LOW, U1 is
</p>
<p>in track mode, which passes the input data to the middle of the D-flip-flop preparing for the next rising
</p>
<p>edge of the clock. The master/slave configuration creates a behavior where the Q output of the D-flip-flop
</p>
<p>is only updated with the value of D on a rising edge of the clock. At all other times, Q holds the last value
</p>
<p>of D. An example timing diagram for the operation of a rising edge D-flip-flop is given in Fig. 7.17.
</p>
<p>Fig. 7.16
D-flip-flop (rising edge triggered) schematic, symbol, and truth table
</p>
<p>7.1 Sequential Logic Storage Devices &bull; 207</p>
<p/>
</div>
<div class="page"><p/>
<p>D-flip-flops often have additional signals that will set the initial conditions of the outputs that are
</p>
<p>separate from the clock. A reset input is used to force the outputs to Q &frac14; 0 and Qn &frac14; 1. A preset input is
</p>
<p>used to force the outputs to Q &frac14; 1 and Qn &frac14; 0. In most modern D-flip-flops, these inputs are active
</p>
<p>LOW, meaning that the line is asserted when the input is a 0. Active LOW inputs are indicated by placing
</p>
<p>an inversion bubble on the input pin of the symbol. These lines are typically asynchronous, meaning that
</p>
<p>when they are asserted, action is immediately taken to alter the outputs. This is different from a
</p>
<p>synchronous input in which action is only taken on the edge of the clock. Figure 7.18 shows the symbols
</p>
<p>and truth tables for two D-flip-flop variants, one with an active LOW reset and another with both an active
</p>
<p>LOW reset and active LOW preset.
</p>
<p>Fig. 7.17
D-flip-flop (rising edge triggered) timing diagram
</p>
<p>208 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>D-flip-flops can also be created with an enable line. An enable line controls whether or not the output
</p>
<p>is updated. Enable lines are synchronous, meaning that when they are asserted, the outputs will be
</p>
<p>updated on the rising edge of the clock. When de-asserted, the outputs are not updated. This behavior in
</p>
<p>effect ignores the clock input when de-asserted. Figure 7.19 shows the symbol and truth table for a D-flip-
</p>
<p>flop with a synchronous enable.
</p>
<p>The behavior of the D-flip-flop allows us to design systems that are synchronous to a clock signal. A
</p>
<p>clock signal is a periodic square wave that dictates when events occur in a digital system. A synchronous
</p>
<p>system based on D-flip-flops will allow the outputs of its storage devices to be updated upon a rising edge
</p>
<p>of the clock. This is advantageous because when the Q outputs are storing values they can be used as
</p>
<p>inputs for combinational logic circuits. Since combinational logic circuits contain a certain amount of
</p>
<p>propagation delay before the final output is calculated, the D-flip-flop can hold the inputs at a steady
</p>
<p>value while the output is generated. Since the input on a D-flip-flop is ignored during all other times, the
</p>
<p>output of a combinational logic circuit can be fed back as an input to a D-flip-flop. This gives a system the
</p>
<p>Fig. 7.18
D-flip-flop with asynchronous reset and preset
</p>
<p>Fig. 7.19
D-flip-flop with synchronous enable
</p>
<p>7.1 Sequential Logic Storage Devices &bull; 209</p>
<p/>
</div>
<div class="page"><p/>
<p>ability to generate outputs based on the current values of inputs in addition to past values of the inputs
</p>
<p>that are being held on the outputs of D-flip-flops. This is the definition of sequential logic. An example
</p>
<p>synchronous, sequential system is shown in Fig. 7.20.
</p>
<p>CC7.1(a) What will always cause a digital storage device to come out of metastability and settle in 
one of its two stable states? Why?
</p>
<p>A) The power supply.  The power supply provides the necessary current for the 
device to overcome metastability.
</p>
<p>B) Electrical noise.  Noise will always push the storage device toward one state or 
another.  Once the storage device starts moving toward one of its stable 
states, the positive feedback of the storage device will reinforce the transition 
until the output eventually comes to rest in a stable state.
</p>
<p>C) A reset.  A reset will put the device into a known stable state.  
</p>
<p>D) A rising edge of clock.  The clock also puts the device into a known stable 
state.
</p>
<p>CC7.1(b) What was the purpose of replacing the inverters in the cross-coupled inverter pair with 
NOR gates to form the SR Latch?
</p>
<p>A) NOR gates are easier to implement in CMOS.
</p>
<p>B) To provide the additional output Qn.
</p>
<p>C) To provide more drive strength for storing.
</p>
<p>D) To provide inputs to explicitly set the value being stored.
</p>
<p>CONCEPT CHECK
</p>
<p>7.2 Sequential Logic Timing Considerations
</p>
<p>There are a variety of timing specifications that need to be met in order to successfully design
</p>
<p>circuits using sequential storage devices. The first specification is called the setup time (tsetup or ts). The
</p>
<p>setup time specifies how long the data input needs to be at a steady state before the clock event. The
</p>
<p>second specification is called the hold time (thold or th). The hold time specifies how long the data input
</p>
<p>needs to be at a steady state after the clock event. If these specifications are violated (i.e., the input
</p>
<p>Fig. 7.20
An example synchronous system based on a D-flip-flop
</p>
<p>210 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>transitions too close to the clock transition), the storage device will not be able to determine whether the
</p>
<p>input was a 1 or 0 and will go metastable. The time a storage device will remain metastable is a
</p>
<p>deterministic value and is specified by the part manufacturer (tmeta). In general, metastability should be
</p>
<p>avoided; however, knowing the maximum duration of metastability for a storage device allows us to
</p>
<p>design circuits to overcome potential metastable conditions. During the time the device is metastable,
</p>
<p>the output will have random behavior. It may go to a steady state 1, or a steady state 0, or toggle between
</p>
<p>a 0 and 1 uncontrollably. Once the device comes out of metastability, it will come to rest in one of its two
</p>
<p>stable states (Q &frac14; 0 or Q &frac14; 1). The final resting state is random and unknown. Another specification for
</p>
<p>sequential storage devices is the delay from the time a clock transition occurs to the point that the data is
</p>
<p>present on the Q output. This specification is called the Clock-to-Q delay and is given the notation tCQ.
</p>
<p>These specifications are shown in Fig. 7.21.
</p>
<p>CC7.2 Which D-flop-flop timing specification requires all of combinational logic circuits in the 
system to settle on their final output before a triggering clock edge can occur?
</p>
<p>A) tsetup B) thold C) tCQ D) tmeta
</p>
<p>CONCEPT CHECK
</p>
<p>Fig. 7.21
Sequential storage device timing specifications
</p>
<p>7.2 Sequential Logic Timing Considerations &bull; 211</p>
<p/>
</div>
<div class="page"><p/>
<p>7.3 Common Circuits Based on Sequential Storage Devices
</p>
<p>Sequential logic storage devices give us the ability to create sophisticated circuits that can make
</p>
<p>decisions based on the current and past values of the inputs; however, there are a variety of simple, yet
</p>
<p>useful, circuits that can be created with only these storage devices. This section introduces a few of
</p>
<p>these circuits.
</p>
<p>7.3.1 Toggle Flop Clock Divider
</p>
<p>A toggle flop is a circuit that contains a D-flip-flop configured with its Qn output wired back to its D
</p>
<p>input. This configuration is also commonly referred to as a T-Flip-Flop or T-Flop. In this circuit, the only
</p>
<p>input is the clock signal. Let&rsquo;s examine the behavior of this circuit when its outputs are initialized to Q &frac14; 0
</p>
<p>and Qn &frac14; 1. Since Qn is wired to the D input, a logic 1 is present on the input before the first clock edge.
</p>
<p>Upon a rising edge of the clock, Q is updated with the value of D. This puts the outputs at Q &frac14; 1 and
</p>
<p>Qn &frac14; 0. With these outputs, now a logic 0 is present on the input before the next clock edge. Upon the
</p>
<p>next rising edge of the clock, Q is updated with the value of D. This time the outputs go to Q &frac14; 0 and
</p>
<p>Qn &frac14; 1. This behavior continues indefinitely. The circuit is called a toggle flop because the outputs
</p>
<p>simply toggle between a 0 and 1 every time there is a rising edge of the clock. This configuration
</p>
<p>produces outputs that are square waves with exactly half the frequency of the incoming clock. As a
</p>
<p>result, this circuit is also called a clock divider. This circuit can be given its own symbol with a label of &ldquo;T&rdquo;
</p>
<p>indicating that it is a toggle flop. The configuration of a toggle flop (T-Flop) and timing diagram are shown
</p>
<p>in Fig. 7.22.
</p>
<p>Fig. 7.22
Toggle flop clock frequency divider
</p>
<p>212 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>7.3.2 Ripple Counter
</p>
<p>The toggle flop configuration can be used to create a simple binary counter called a ripple counter. In
</p>
<p>this configuration, the Qn output of a toggle flop is used as the clock for a subsequent toggle flop. Since
</p>
<p>the output of the first toggle flop is a square wave that is &frac12; the frequency of the incoming clock, this
</p>
<p>configuration will produce an output on the second toggle flop that is &frac14; the frequency of the incoming
</p>
<p>clock. This is by nature the behavior of a binary counter. The output of this counter is present on the Q
</p>
<p>pins of each toggle flop. Toggle flops are added until the desired width of the counter is achieved with
</p>
<p>each toggle flop representing one bit of the counter. Since each toggle flop produces the clock for the
</p>
<p>subsequent latch, the clock is said to ripple through the circuit, hence the name ripple counter. A 3-bit
</p>
<p>ripple counter is shown in Fig. 7.23.
</p>
<p>7.3.3 Switch Debouncing
</p>
<p>Another useful circuit based on sequential storage devices is a switch debouncer. Mechanical
</p>
<p>switches have a well-known issue of not producing clean logic transitions on their outputs when pressed.
</p>
<p>This becomes problematic when using a switch to create an input for a digital device because it will
</p>
<p>cause unwanted logic-level transitions on the output of the gate. In the case of a clock input, this
</p>
<p>unwanted transition can cause a storage device to unintentionally latch incorrect data.
</p>
<p>Fig. 7.23
3-Bit ripple counter
</p>
<p>7.3 Common Circuits Based on Sequential Storage Devices &bull; 213</p>
<p/>
</div>
<div class="page"><p/>
<p>The primary cause of these unclean logic transitions is due to the physical vibrations of the metal
</p>
<p>contacts when they collide with each other during a button press or switch actuation. Within a mechanical
</p>
<p>switch, there is typically one contact that is fixed and another that is designed to move when the button is
</p>
<p>pressed. The contact that is designed to move can be thought of as a beam that is fixed on one side and
</p>
<p>free on the other. As the free side of the beammoves toward the fixed contact in order to close the circuit,
</p>
<p>it will collide and then vibrate just as a tuning fork does when struck. The vibration will eventually diminish
</p>
<p>and the contact will come to rest, thus making a clean electrical connection; however, during the vibration
</p>
<p>period the moving contact will bounce up and down on the destination contact. This bouncing causes the
</p>
<p>switch to open and close multiple times before coming to rest in the closed position. This phenomenon is
</p>
<p>accurately referred to as switch bounce. Switch bounce is present in all mechanical switches and gets
</p>
<p>progressively worse as the switches are used more and more.
</p>
<p>Figure 7.24 shows some of the common types of switches found in digital systems. The term pole is
</p>
<p>used to describe the number of separate circuits controlled by the switch. The term throw is used to
</p>
<p>describe the number of separate closed positions the switch can be in.
</p>
<p>Let&rsquo;s look at switch bounce when using a SPSTswitch to provide an input to a logic gate. An SPST
</p>
<p>requires a resistor and can be configured to provide either a logic HIGH or LOW when in the open
</p>
<p>position and the opposite logic level when in the closed position. The example configuration in Fig. 7.25
</p>
<p>provides a logic LOW when in the open position and a logic HIGH when in the closed position. In the
</p>
<p>open position, the input to the gate (SW) is pulled to GND to create a logic LOW. In the closed position,
</p>
<p>the input to the gate is pulled to VCC to create a logic HIGH. A resistor is necessary to prevent a short
</p>
<p>circuit between VCC and GND when the switch is closed. Since the input current specification for a logic
</p>
<p>gate is very small, the voltage developed across the resistor due to the gate input current is negligible.
</p>
<p>This means that the resistor can be inserted in the pull-down network without developing a noticeable
</p>
<p>voltage. When the switch closes, the free-moving contact will bounce off of the destination contact
</p>
<p>numerous times before settling in the closed position. During the time while the switch is bouncing, the
</p>
<p>switch will repeatedly toggle between the open (HIGH) and closed (LOW) positions.
</p>
<p>Fig. 7.24
Common types of mechanical switches
</p>
<p>214 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>A possible solution to eliminate this switch bounce is to instead use an SPDTswitch in conjunction
</p>
<p>with a sequential storage device. Before looking at this solution, we need to examine an additional
</p>
<p>condition introduced by the SPDT switch. The SPDT switch has what is known as break-before-make
</p>
<p>behavior. The term break is used to describe when a switch is open while the term make is used to
</p>
<p>describe when the switch is closed. When an SPDTswitch is pressed, the input will be floating during the
</p>
<p>time when the free-moving contact is transitioning toward the destination contact. During this time, the
</p>
<p>output of the switch is unknown and can cause unwanted logic transitions if it is being used to drive the
</p>
<p>input of a logic gate.
</p>
<p>Let&rsquo;s look at switch bounce when using an SPDT switch without additional circuitry to handle
</p>
<p>bouncing. An SPDT has two positions that the free-moving contact can make a connection to (i.e.,
</p>
<p>double throw). When using this switch to drive a logic level into a gate, one position is configured as a
</p>
<p>logic HIGH and the other a logic LOW. Consider the SPDTswitch configuration in Fig. 7.26. Position 1 of
</p>
<p>the SPDTswitch is connected to GND, while position 2 is connected to VCC. When unpressed the switch
</p>
<p>is in position 1. When pressed, the free-moving contact will transition from position 1 to 2. During the
</p>
<p>transition the free-moving contact is floating. This creates a condition where the input to the gate (SW) is
</p>
<p>unknown. This floating input will cause unpredictable behavior on the output of the gate. Upon reaching
</p>
<p>position 2, the free-moving contact will bounce off of the destination contact. This will cause the input of
</p>
<p>the logic gate to toggle between a logic HIGH and floating repeatedly until the free-moving contact comes
</p>
<p>to rest in position 2.
</p>
<p>Fig. 7.25
Switch bouncing in a single-pole, single-throw switch
</p>
<p>7.3 Common Circuits Based on Sequential Storage Devices &bull; 215</p>
<p/>
</div>
<div class="page"><p/>
<p>The SPDTswitch is ideal for use with an S0R0 Latch in order to produce a clean logic transition. This
</p>
<p>is because during the break portion of the transition, an S0R0 Latch can be used to hold the last value of
</p>
<p>the switch. This is unique to the SPDTconfiguration. The SPSTswitch in comparison does not have the
</p>
<p>break characteristic; rather it always drives a logic level in both of its possible positions. Consider the
</p>
<p>debounce circuit for an SPDTswitch in Fig. 7.27. This circuit is based on an S0R0 Latch with two pull-up
</p>
<p>resistors. Since the S0R0 Latch is created using NAND gates, this circuit is commonly called a NAND-
</p>
<p>Debounce circuit. In the unpressed configuration, the switch drives S0 &frac14; 0 and the R2 pull-up resistor
</p>
<p>drives R0 &frac14; 1. This creates a logic 0 on the output of the circuit (Qn &frac14; 0). During a switch press, the free-
</p>
<p>moving contact is floating; thus it is not driving in a logic level into the S0R0 Latch. Instead, both pull-up
</p>
<p>resistors pull S0 and R0 to 1&rsquo;s. This puts the latch into its hold mode and the output will remain at a logic
</p>
<p>0 (Qn &frac14; 0). Once the free-moving contact reaches the destination contact, the switch will drive R0 &frac14; 0.
</p>
<p>Since at this point the R1 pull-up is driving S0 &frac14; 1, the latch outputs a logic 1 (Qn &frac14; 1). When the free-
</p>
<p>moving contact bounces off of the destination contact, it will put the latch back into the hold mode;
</p>
<p>however, this time the last value that will be held is Qn &frac14; 1. As the switch continues to bounce, the latch
</p>
<p>will move between the Qn &frac14; 1 and Qn&frac14;&ldquo;Last Qn&rdquo; states, both of which produce an output of 1. In this
</p>
<p>way, the SPDTswitch in conjunction with the S0R0 Latch produces a clean 0 to 1 logic transition despite
</p>
<p>the break-before-make behavior of the switch and the contact bounce.
</p>
<p>Fig. 7.26
Switch bouncing in a single-pole, double-throw switch
</p>
<p>216 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>7.3.4 Shift Registers
</p>
<p>A shift register is a chain of D-flip-flops where each is connected to a common clock. The output of
</p>
<p>the first D-flip-flop is connected to the input of the second D-flip-flop. The output of the second D-flip-flop
</p>
<p>is connected to the input of the third D-flip-flop, and so on. When data is present on the input to the first
</p>
<p>D-flip-flop, it will be latched upon the first rising edge of the clock. On the second rising edge of the clock,
</p>
<p>the same data will be latched into the second D-flip-flop. This continues on each rising edge of the clock
</p>
<p>Fig. 7.27
NAND debounce circuit for an SPDT switch
</p>
<p>7.3 Common Circuits Based on Sequential Storage Devices &bull; 217</p>
<p/>
</div>
<div class="page"><p/>
<p>until the data has been shifted entirely through the chain of D-flip-flops. Shift registers are commonly
</p>
<p>used to convert a serial string of data into a parallel format. If an n-bit, serial sequence of information is
</p>
<p>clocked into the shift register, after n clocks the data will be held on each of the D-flip-flop outputs. At this
</p>
<p>moment, the n-bits can be read as a parallel value. Consider the shift register configuration shown in
</p>
<p>Fig. 7.28.
</p>
<p>CC7.3 Which D-flip-flop timing specification is most responsible for the ripple delay in a ripple 
counter?
</p>
<p>A) tsetup B) thold C) tCQ D) tmeta
</p>
<p>CONCEPT CHECK
</p>
<p>Fig. 7.28
4-Bit shift register
</p>
<p>218 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>7.4 Finite-State Machines
</p>
<p>Now we turn our attention to one of the most powerful sequential logic circuits, the FSM. An FSM, or
</p>
<p>state machine, is a circuit that contains a predefined number of states (i.e., a finite number of states). The
</p>
<p>machine can exist in one and only one state at a time. The circuit transitions between states based on a
</p>
<p>triggering event, most commonly the edge of a clock, in addition to the values of any inputs of the
</p>
<p>machine. The number of states and all possible transitions are predefined. Through the use of states and
</p>
<p>a predefined sequence of transitions, the circuit is able to make decisions on the next state to transition to
</p>
<p>based on a history of past states. This allows the circuit to create outputs that are more intelligent
</p>
<p>compared to a simple combinational logic circuit that has outputs based only on the current values of the
</p>
<p>inputs.
</p>
<p>7.4.1 Describing the Functionality of an FSM
</p>
<p>The design of a state machine begins with an abstract word description of the desired circuit
</p>
<p>behavior. We will use a design example of a push-button motor controller to describe all of the steps
</p>
<p>involved in creating an FSM. Example 7.1 starts the FSM design process by stating the word description
</p>
<p>of the system.
</p>
<p>Example 7.1
Push-Button Window Controller&mdash;Word Description
</p>
<p>7.4.1.1 State Diagrams
</p>
<p>A state diagram is a graphical way to describe the functionality of an FSM. A state diagram is a form
</p>
<p>of a directed graph, in which each state (or vertex) within the system is denoted as a circle and given a
</p>
<p>descriptive name. The names are written inside of the circles. The transitions between states are
</p>
<p>denoted using arrows with the input conditions causing the transitions written next to them. Transitions
</p>
<p>(or edges) can move to different states upon particular input conditions or remain in the same state. For a
</p>
<p>state machine implemented using sequential logic storage, an evaluation of when to transition states is
</p>
<p>triggered every time the storage devices update their outputs. For example, if the system was
</p>
<p>implemented using rising edge triggered D-flip-flops, then an evaluation would occur on every rising
</p>
<p>edge of the clock.
</p>
<p>7.4 Finite-State Machines &bull; 219</p>
<p/>
</div>
<div class="page"><p/>
<p>There are two different types of output conditions for a state machine. The first is when the output
</p>
<p>only depends on the current state of the machine. This type of system is called aMoore machine. In this
</p>
<p>case, the outputs of the system are written inside of the state circles. This indicates the output value that
</p>
<p>will be generated for each specific state. The second output condition is when the outputs depend on
</p>
<p>both the current state and the system inputs. This type of system is called aMealy machine. In this case,
</p>
<p>the outputs of the system are written next to the state transitions corresponding to the appropriate input
</p>
<p>values. Outputs in a state diagram are typically written inside of parentheses. Example 7.2 shows the
</p>
<p>construction of the state diagram for our push-button window controller design.
</p>
<p>Example 7.2
Push-Button Window Controller&mdash;State Diagram
</p>
<p>220 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>7.4.1.2 State Transition Tables
</p>
<p>The state diagram can now be described in a table format that is similar to a truth table. This puts the
</p>
<p>state machine behavior in a form that makes logic synthesis straightforward. The table contains the
</p>
<p>same information as in the state diagram. The state that the machine exists in is called the current state.
</p>
<p>For each current state that the machine can reside in, every possible input condition is listed along with
</p>
<p>the destination state of each transition. The destination state for a transition is called the next state. Also
</p>
<p>listed in the table are the outputs corresponding to each current state and, in the case of a Mealy
</p>
<p>machine, the output corresponding to each input condition. Example 7.3 shows the construction of the
</p>
<p>state transition table for the push-button window controller design. This information is identical to the
</p>
<p>state diagram given in Example 7.2.
</p>
<p>Example 7.3
Push-Button Window Controller&mdash;State Transition Table
</p>
<p>7.4.2 Logic Synthesis for an FSM
</p>
<p>Once the behavior of the state machine has been described, it can be directly synthesized. There
</p>
<p>are three main components of a state machine: the state memory, the next state logic, and the output
</p>
<p>logic. Figure 7.29 shows a block diagram of a state machine highlighting these three components. The
</p>
<p>next state logic block is a group of combinational logic that produces the next state signals based on the
</p>
<p>current state and any system inputs. The state memory holds the current state of the system. The current
</p>
<p>state is updated with next state on every rising edge of the clock, which is indicated with the &ldquo;&gt;&rdquo; symbol
</p>
<p>within the block. This behavior is created using D-flip-flops where the current state is held on the Q
</p>
<p>outputs of the D-flip-flops, while the next state is present on the D inputs of the D-flip-flops. In this way,
</p>
<p>every rising edge of the clock will trigger an evaluation of which state to move to next. This decision is
</p>
<p>based on the current state and the current inputs. The output logic block is a group of combinational logic
</p>
<p>that creates the outputs of the system. This block always uses the current state as an input and,
</p>
<p>depending on the type of machine (Mealy vs. Moore), uses the system inputs. It is useful to keep this
</p>
<p>block diagram in mind when synthesizing FSM as it will aid in keeping the individual design steps
</p>
<p>separate and clear.
</p>
<p>7.4 Finite-State Machines &bull; 221</p>
<p/>
</div>
<div class="page"><p/>
<p>7.4.2.1 State Memory
</p>
<p>The state memory is the circuitry that will hold the current state of the machine. Upon a rising edge of
</p>
<p>a clock it will update the current state with the next state. At all other times, the next state input is ignored.
</p>
<p>This gives time for the next state logic circuitry to compute the results for the next state. This behavior is
</p>
<p>identical to that of a D-flip-flop; thus the state memory is simply one or more D-flip-flops. The number of
</p>
<p>D-flip-flops required depends on how the states are encoded. State encoding is the process of assigning
</p>
<p>a binary value to the descriptive names of the states from the state diagram and state transition tables.
</p>
<p>Once the descriptive names have been converted into representative codes using 1&rsquo;s and 0&rsquo;s, the states
</p>
<p>can be implemented in real circuitry. The assignment of codes is arbitrary and can be selected in order to
</p>
<p>minimize the circuitry needed in the machine.
</p>
<p>There are three main styles of state encoding. The first is straight binary encoding. In this approach
</p>
<p>the state codes are simply a set of binary counts (i.e., 00, 01, 10, 11 . . .). The binary counts are assigned
</p>
<p>starting at the beginning of the state diagram and incrementally assigned toward the end. This type of
</p>
<p>encoding has the advantage that it is very efficient in minimizing the number of D-flip-flops needed for the
</p>
<p>state memory. With n D-flip-flops, 2n states can be encoded. When a large number of states is required,
</p>
<p>the number of D-flip-flops can be calculated using the rules of logarithmic math. Example 7.4 shows how
</p>
<p>to solve for the number of bits needed in the binary state code based on the number of states in the
</p>
<p>machine.
</p>
<p>Fig. 7.29
Main components of a finite-state machine
</p>
<p>222 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 7.4
Solving for the Number of Bits Needed for Binary State Encoding
</p>
<p>The second type of state encoding is called gray code encoding. A gray code is one in which the
</p>
<p>value of a code differs by only one bit from any of its neighbors (i.e., 00, 01, 11, 10 . . .). A gray code is
</p>
<p>useful for reducing the number of bit transitions on the state codes when the machine has a transition
</p>
<p>sequence that is linear. Reducing the number of bit transitions can reduce the amount of power
</p>
<p>consumption and noise generated by the circuit. When the state transitions of a machine are highly
</p>
<p>nonlinear, a gray code encoding approach does not provide any benefit. Gray code is also an efficient
</p>
<p>coding approach. With n D-flip-flops, 2n states can be encoded just as in binary encoding. Figure 7.30
</p>
<p>shows the process of creating n-bit, gray code patterns.
</p>
<p>7.4 Finite-State Machines &bull; 223</p>
<p/>
</div>
<div class="page"><p/>
<p>The third common technique to encode states is using one-hot encoding. In this approach, a
</p>
<p>separate D-flip-flop is asserted for each state in the machine. For an n-state machine, this encoding
</p>
<p>approach requires n D-flip-flops. For example, if a machine had three states, the one-hot state codes
</p>
<p>would be &ldquo;001,&rdquo; &ldquo;010,&rdquo; and &ldquo;100.&rdquo; This approach has the advantage that the next state logic circuitry is
</p>
<p>very simple; further, there is less chance that the different propagation delays through the next state logic
</p>
<p>will cause an inadvertent state to be entered. This approach is not as efficient as binary and gray code in
</p>
<p>terms of minimizing the number of D-flip-flops because it requires one D-flip-flop for each state; however,
</p>
<p>in modern digital integrated circuits that have abundant D-flip-flops, one-hot encoding is commonly used.
</p>
<p>Figure 7.31 shows the differences between these three state encoding approaches.
</p>
<p>Once the codes have been assigned to the state names, each of the bits within the code must be
</p>
<p>given a unique signal name. The signal names are necessary because the individual bits within the state
</p>
<p>code are going to be implemented with real circuitry so each signal name will correspond to an actual
</p>
<p>Fig. 7.30
Creating an n-bit gray code pattern
</p>
<p>Fig. 7.31
Comparison of different state encoding approaches
</p>
<p>224 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>node in the logic diagram. These individual signal names are called state variables. Unique variable
</p>
<p>names are needed for both the current state and next state signals. The current state variables are driven
</p>
<p>by the Q outputs of the D-flip-flops holding the state codes. The next state variables are driven by the
</p>
<p>next state logic circuitry and are connected to the D inputs of the D-flip-flops. State variable names are
</p>
<p>commonly chosen that are descriptive both in terms of their purpose and connection location. For
</p>
<p>example, current state variables are often given the names Q, Q_cur or Q_current to indicate that they
</p>
<p>come from the Q outputs of the D-flip-flops. Next state variables are given names such as Q*, Q_nxt or
</p>
<p>Q_next to indicate that they are the next value of Q and are connected to the D input of the D-flip-flops.
</p>
<p>Once state codes and state variable names are assigned, the state transition table is updated with the
</p>
<p>detailed information.
</p>
<p>Returning to our push-button window controller example, let&rsquo;s encode our states in straight binary
</p>
<p>and use the state variable names of Q_cur and Q_nxt. Example 7.5 shows the process of state encoding
</p>
<p>and the new state transition table.
</p>
<p>Example 7.5
Push-Button Window Controller&mdash;State Encoding
</p>
<p>7.4.2.2 Next State Logic
</p>
<p>The next step in the statemachine design is to synthesize the next state logic. The next state logic will
</p>
<p>compute the values of the next state variables based on the current state and the system inputs. Recall
</p>
<p>that a combinational logic function drives one and only one output bit. This means that every bit within the
</p>
<p>next state code needs to have a dedicated combinational logic circuit. The state transition table contains
</p>
<p>all of the necessary information to synthesize the next state logic including the exact output values of each
</p>
<p>next state variable for each and every input combination of state code and system input(s).
</p>
<p>7.4 Finite-State Machines &bull; 225</p>
<p/>
</div>
<div class="page"><p/>
<p>In our push-button window controller example, we only need to create one combinational logic
</p>
<p>circuit because there is only one next state variable (Q_nxt). The inputs to the combinational logic circuit
</p>
<p>are Q_cur and Press. Notice that the state transition table was created such that the order of the input
</p>
<p>values is listed in a binary count just as in a formal truth table formation. This makes synthesizing the
</p>
<p>combinational logic circuit straightforward. Example 7.6 shows the steps to synthesize the next state
</p>
<p>logic for this push-button window controller.
</p>
<p>Example 7.6
Push-Button Window Controller&mdash;Next State Logic
</p>
<p>7.4.2.3 Output Logic
</p>
<p>The next step in the state machine design is to synthesize the output logic. The output logic will
</p>
<p>compute the values of the system outputs based on the current state and, in the case of a Mealy
</p>
<p>machine, the system inputs. Each of the output signals will require a dedicated combinational logic
</p>
<p>circuit. Again, the state transition table contains all of the necessary information to synthesize the output
</p>
<p>logic.
</p>
<p>In our push-button window controller example, we need to create one circuit to compute the output
</p>
<p>&ldquo;Open_CW&rdquo; and one circuit to compute the output &ldquo;Close_CCW.&rdquo; In this example, the inputs to these
</p>
<p>circuits are the current state (Q_cur) and the system input (Press). Example 7.7 shows the steps to
</p>
<p>synthesize the output logic for the push-button window controller.
</p>
<p>226 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 7.7
Push-Button Window Controller&mdash;Output Logic
</p>
<p>7.4.2.4 The Final Logic Diagram
</p>
<p>The final step in the design of the state machine is to create the logic diagram. It is useful to recall the
</p>
<p>block diagram for a state machine from Fig. 7.29. A logic diagram begins by entering the state memory.
</p>
<p>Recall that the state memory consists of D-flip-flops that hold the current state code. One D-flip-flop is
</p>
<p>needed for every current state variable. When entering the D-flip-flops, it is useful to label them with the
</p>
<p>current state variable they will be holding. The next part of the logic diagram is the next state logic. Each
</p>
<p>of the combinational logic circuits that compute the next state variables should be drawn to the left of D-
</p>
<p>flip-flop holding the corresponding current state variable. The output of each next state logic circuit is
</p>
<p>connected to the D input of the corresponding D-flip-flop. Finally, the output logic is entered with the
</p>
<p>inputs to the logic coming from the current state and potentially from the system inputs.
</p>
<p>Example 7.8 shows the process for creating the final logic diagram for our push-button window
</p>
<p>controller. Notice that the state memory is implemented with one D-flip-flop since there is only 1-bit in the
</p>
<p>current state code (Q_cur). The next state logic is a combinational logic circuit that computes Q_nxt
</p>
<p>based on the values of Q_cur and Press. Finally, the output logic consists of two separate combinational
</p>
<p>logic circuits to compute the system outputs Open_CW and Close_CCW based on Q_cur and Press. In
</p>
<p>this diagram the Qn output of the D-flip-flop could have been used for the inverted versions of Q_cur;
</p>
<p>however, inversion bubbles were used instead in order to make the diagram more readable.
</p>
<p>7.4 Finite-State Machines &bull; 227</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 7.8
Push-Button Window Controller&mdash;Logic Diagram
</p>
<p>7.4.3 FSM Design Process Overview
</p>
<p>The entire FSM design process is given in Fig. 7.32.
</p>
<p>Fig. 7.32
Finite-state machine design flow
</p>
<p>228 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>7.4.4 FSM Design Examples
</p>
<p>7.4.4.1 Serial Bit Sequence Detector
</p>
<p>Let&rsquo;s consider the design of a 3-bit serial sequence detector. Example 7.9 provides the word
</p>
<p>description, state diagram, and state transition table for this FSM.
</p>
<p>Example 7.9
Serial Bit Sequence Detector (Part 1)
</p>
<p>Example 7.10 provides the state encoding and next state logic synthesis for the 3-bit serial bit
</p>
<p>sequence detector.
</p>
<p>7.4 Finite-State Machines &bull; 229</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 7.10
Serial Bit Sequence Detector (Part 2)
</p>
<p>Example 7.11 shows the output logic synthesis and final logic diagram for the 3-bit serial bit
</p>
<p>sequence detector.
</p>
<p>230 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 7.11
Serial Bit Sequence Detector (Part 3)
</p>
<p>7.4.4.2 Vending Machine Controller
</p>
<p>Let&rsquo;s now look at the design of a simple vending machine controller. Example 7.12 provides the word
</p>
<p>description, state diagram, and state transition table for this FSM.
</p>
<p>7.4 Finite-State Machines &bull; 231</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 7.12
Vending Machine Controller (Part 1)
</p>
<p>232 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 7.13 provides the state encoding and next state logic synthesis for the simple vending
</p>
<p>machine controller.
</p>
<p>Example 7.13
Vending Machine Controller (Part 2)
</p>
<p>7.4 Finite-State Machines &bull; 233</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 7.14 shows the output logic synthesis and final logic diagram for the vending machine
</p>
<p>controller.
</p>
<p>Example 7.14
Vending Machine Controller (Part 3)
</p>
<p>234 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>CC7.4(a) What allows a finite state machine to make more intelligent decisions about the system 
outputs compared to combinational logic alone?
</p>
<p>A) A finite state machine has knowledge about the past inputs.
</p>
<p>B) The D-flip-flops allow the outputs to be generated more rapidly.
</p>
<p>C) The next state and output logic allows the finite state machine to be more 
complex and implement larger truth tables.
</p>
<p>D) A synchronous system is always more intelligent.
</p>
<p>CC7.4(b) When designing a finite state machine, many of the details of the implementation can be 
abstracted.  At what design step do the details of the implementation start being 
considered?
</p>
<p>A) The state diagram step.
</p>
<p>B) The state transition table step.
</p>
<p>C) The state memory synthesis step.
</p>
<p>D) The word description.
</p>
<p>CC7.4(c) What impact does adding an additional state have on the implementation of the state 
memory logic in a finite state machine?
</p>
<p>A) It adds an additional D-flip-flop.
</p>
<p>B) It adds a new state code that must be supported.
</p>
<p>C) It adds more combinational logic to the logic diagram.
</p>
<p>D) It reduces the speed that the machine can run at.
</p>
<p>CC7.4(d) Which of the following statements about the next state logic is FALSE?
</p>
<p>A) It is always combinational logic.
</p>
<p>B) It always uses the current state as one of its inputs.
</p>
<p>C) Its outputs are connected to the D inputs of the D-flip-flops in the state 
memory.
</p>
<p>D) It uses the results of the output logic as part of its inputs. 
</p>
<p>CC7.4(e) Why does the output logic stage of a finite state machine always use the current state 
as one of its inputs?
</p>
<p>A) If it didn&rsquo;t, it would simply be a separate combinational logic circuit and not be 
part of the finite state machine.
</p>
<p>B) To make better decisions about what the system outputs should be.
</p>
<p>C) Because the next state logic is located too far away.
</p>
<p>D) Because the current state is produced on every triggering clock edge.
</p>
<p>CC7.4(f) What impact does asserting a reset have on a finite state machine?
</p>
<p>A) It will cause the output logic to produce all zeros.
</p>
<p>B) It will cause the next state logic to produce all zeros.
</p>
<p>C) It will set the current state code to all zeros.
</p>
<p>D) It will start the system clock.
</p>
<p>CONCEPT CHECK
</p>
<p>7.4 Finite-State Machines &bull; 235</p>
<p/>
</div>
<div class="page"><p/>
<p>7.5 Counters
</p>
<p>A counter is a special type of FSM. A counter will traverse the states within a state diagram in a linear
</p>
<p>fashion continually circling around all states. This behavior allows a special type of output topology called
</p>
<p>state-encoded outputs. Since each state in the counter represents a unique counter output, the states
</p>
<p>can be encoded with the associated counter output value. In this way, the current state code of the
</p>
<p>machine can be used as the output of the entire system.
</p>
<p>7.5.1 2-Bit Binary Up Counter
</p>
<p>Let&rsquo;s consider the design of a 2-bit binary up counter. Example 7.15 provides the word description,
</p>
<p>state diagram, state transition table, and state encoding for this counter.
</p>
<p>Example 7.15
2-bit Binary Up Counter (Part 1)
</p>
<p>Example 7.16 shows the next state and output logic synthesis, the final logic diagram, and resultant
</p>
<p>representative timing diagram for the 2-bit binary up counter.
</p>
<p>236 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 7.16
2-Bit Binary Up Counter (Part 2)
</p>
<p>7.5.2 2-Bit Binary Up/Down Counter
</p>
<p>Let&rsquo;s now consider a 2-bit binary up/down counter. In this type of counter, there is an input that
</p>
<p>dictates whether the counter increments or decrements. This counter can still be implemented as a
</p>
<p>Moore machine and use state-encoded outputs. Example 7.17 provides the word description, state
</p>
<p>diagram, state transition table, and state encoding for this counter.
</p>
<p>7.5 Counters &bull; 237</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 7.17
2-Bit Binary Up/Down Counter (Part 1)
</p>
<p>238 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 7.18 shows the next state and output logic synthesis, the final logic diagram, and resultant
</p>
<p>representative timing diagram for the 2-bit binary up/down counter.
</p>
<p>Example 7.18
2-Bit Binary Up/Down Counter (Part 2)
</p>
<p>7.5 Counters &bull; 239</p>
<p/>
</div>
<div class="page"><p/>
<p>7.5.3 2-Bit Gray Code Up Counter
</p>
<p>A gray code counter is one in which the output only differs by one bit from its prior value. This type of
</p>
<p>counter can be implemented using state-encoded outputs by simply encoding the states in gray code.
</p>
<p>Let&rsquo;s consider the design of a 2-bit gray code up counter. Example 7.19 provides the word description,
</p>
<p>state diagram, state transition table, and state encoding for this counter.
</p>
<p>Example 7.19
2-Bit Gray Code Up Counter (Part 1)
</p>
<p>240 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 7.20 shows the next state and output logic synthesis, the final logic diagram, and resultant
</p>
<p>representative timing diagram for the 2-bit gray code up counter.
</p>
<p>Example 7.20
2-Bit Gray Code Up Counter (Part 2)
</p>
<p>7.5 Counters &bull; 241</p>
<p/>
</div>
<div class="page"><p/>
<p>7.5.4 2-Bit Gray Code Up/Down Counter
</p>
<p>Let&rsquo;s now consider a 2-bit gray code up/down counter. In this type of counter, there is an input that
</p>
<p>dictates whether the counter increments or decrements. This counter can still be implemented as a
</p>
<p>Moore machine and use state-encoded outputs. Example 7.21 provides the word description, state
</p>
<p>diagram, state transition table, and state encoding for this counter.
</p>
<p>Example 7.21
2-Bit Gray Code Up/Down Counter (Part 1)
</p>
<p>242 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 7.22 shows the next state and output logic synthesis, the final logic diagram, and resultant
</p>
<p>representative timing diagram for the 2-bit gray code up/down counter.
</p>
<p>Example 7.22
2-Bit Gray Code Up/Down Counter (Part 2)
</p>
<p>7.5 Counters &bull; 243</p>
<p/>
</div>
<div class="page"><p/>
<p>7.5.5 3-Bit One-Hot Up Counter
</p>
<p>A one-hot counter creates an output in which one and only one bit is asserted at a time. In an up
</p>
<p>counter configuration, the assertion is made on the least significant bit first, followed by the next higher
</p>
<p>significant bit, and so on (i.e., 001, 010, 100, 001 . . .). A one-hot counter can be created using state-
</p>
<p>encoded outputs. For an n-bit counter, the machine will require n D-flip-flops. Let&rsquo;s consider a 3-bit
</p>
<p>one-hot up counter. Example 7.23 provides the word description, state diagram, state transition table,
</p>
<p>and state encoding for this counter.
</p>
<p>Example 7.23
3-Bit One-Hot Up Counter (Part 1)
</p>
<p>244 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 7.24 shows the next state and output logic synthesis, the final logic diagram, and resultant
</p>
<p>representative timing diagram for the 3-bit one-hot up counter.
</p>
<p>Example 7.24
3-Bit One-Hot Up Counter (Part 2)
</p>
<p>7.5.6 3-Bit One-Hot Up/Down Counter
</p>
<p>Let&rsquo;s now consider a 3-bit one-hot up/down counter. In this type of counter, there is an input that
</p>
<p>dictates whether the counter increments or decrements. This counter can still be implemented as a
</p>
<p>Moore machine and use state-encoded outputs. Example 7.25 provides the word description, state
</p>
<p>diagram, state transition table, and state encoding for this counter.
</p>
<p>7.5 Counters &bull; 245</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 7.25
3-Bit One-Hot Up/Down Counter (Part 1)
</p>
<p>246 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 7.26 shows the next state and output logic synthesis for the 3-bit one-hot up/down counter.
</p>
<p>Example 7.26
3-Bit One-Hot Up/Down Counter (Part 2)
</p>
<p>7.5 Counters &bull; 247</p>
<p/>
</div>
<div class="page"><p/>
<p>Finally, Example 7.27 shows the logic diagram and resultant representative timing diagram for the
</p>
<p>counter.
</p>
<p>Example 7.27
3-Bit One-Hot Up/Down Counter (Part 3)
</p>
<p>CC7.5 What characteristic of a counter makes it a special case of a finite state machine?
</p>
<p>A) The state transitions are mostly linear, which reduces the implementation 
complexity.
</p>
<p>B) The outputs are always a gray code.
</p>
<p>C) The next state logic circuitry is typically just sum terms. 
</p>
<p>D) There is never a situation where a counter could be a Mealy machine. 
</p>
<p>CONCEPT CHECK
</p>
<p>248 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>7.6 Finite-State Machine&rsquo;s Reset Condition
</p>
<p>The one-hot counter designs in Examples 7.23 and 7.25 were the first FSM examples that had an
</p>
<p>initial state that was not encoded with all 0&rsquo;s. Notice that all of the other FSM examples had initial states
</p>
<p>with state codes comprised of all 0&rsquo;s (e.g., w_closed &frac14; 0, S0 &frac14; &ldquo;00,&rdquo; C0 &frac14; &ldquo;00,&rdquo; GC_0 &frac14; &ldquo;00&rdquo;). When
</p>
<p>the initial state is encoded with all 0&rsquo;s, the FSM can be put into this state by asserting the reset line of all of
</p>
<p>the D-flip-flops in the state memory. By asserting the reset line, the Q outputs of all of the D-Flip-Flips are
</p>
<p>forced to 0&rsquo;s. This sets the initial current state value to whatever state is encoded with all 0&rsquo;s. The initial
</p>
<p>state of a machine is often referred to as the reset state. The circuitry to initialize state machines is often
</p>
<p>omitted from the logic diagram as it is assumed that the necessary circuitry will exist in order to put the
</p>
<p>state machine into the reset state. If the reset state is encoded with all 0&rsquo;s, then the reset line can be used
</p>
<p>alone; however, if the reset state code contains 1&rsquo;s, then both the reset and preset lines must be used to
</p>
<p>put the machine into the reset state upon start up. Let&rsquo;s look at the behavior of the one-hot up counter
</p>
<p>again. Figure 7.33 shows how using the reset lines of the D-flip-flops alone will cause the circuit to
</p>
<p>operate incorrectly. Instead, a combination of the reset and preset lines must be used to get the one-hot
</p>
<p>counter into its initial state of Hot_0 &frac14; &ldquo;001&rdquo;.
</p>
<p>Fig. 7.33
Finite-state machine reset state
</p>
<p>7.6 Finite-State Machine&rsquo;s Reset Condition &bull; 249</p>
<p/>
</div>
<div class="page"><p/>
<p>Resets are most often asynchronous so that they can immediately alter the state of the FSM. If a
</p>
<p>reset was implemented in a synchronous manner and there was a clock failure, the system could not be
</p>
<p>reset since there would be no more subsequent clock edges that would recognize that the reset line was
</p>
<p>asserted. An asynchronous reset allows the system to be fully restarted even in the event of a clock
</p>
<p>failure.
</p>
<p>CC7.6 What is the downside of using D-flip-flops that do not have preset capability in a finite state 
machine?
</p>
<p>A) The finite state machine will run slower.
</p>
<p>B) The next state logic will be more complex.
</p>
<p>C) The output logic will not be able to support both Mealy and Moore type machine 
architectures.
</p>
<p>D) The start-up state can never have a 1 in its state code.
</p>
<p>CONCEPT CHECK
</p>
<p>7.7 Sequential Logic Analysis
</p>
<p>Sequential logic analysis refers to the act of deciphering the operation of a circuit from its final logic
</p>
<p>diagram. This is similar to combinational logic analysis with the exception that the storage capability of
</p>
<p>the D-flip-flops must be considered. This analysis is also used to understand the timing of a sequential
</p>
<p>logic circuit and can be used to predict the maximum clock rate that can be used.
</p>
<p>7.7.1 Finding the State Equations and Output Logic Expressions of an FSM
</p>
<p>When given the logic diagram for an FSM and it is desired to reverse-engineer its behavior, the first
</p>
<p>step is to determine the next state logic and output logic expressions. This can be accomplished by first
</p>
<p>labeling the current and next state variables on the inputs and outputs of the D-flip-flops that are
</p>
<p>implementing the state memory of the FSM. The outputs of the D-flip-flops are labeled with arbitrary
</p>
<p>current state variable names (e.g., Q1_cur, Q0_cur) and the inputs are labeled with arbitrary next state
</p>
<p>variable names (e.g., Q1_nxt, Q0_nxt). The numbering of the state variables can be assigned to the D-
</p>
<p>flip-flops arbitrarily as long as the current and next state bit numbering is matched. For example, if a D-
</p>
<p>flip-flop is labeled to hold bit 0 of the state code, its output should be labeled Q0_cur and its input should
</p>
<p>be labeled Q0_nxt.
</p>
<p>Once the current state variable nets are labeled in the logic diagram, the expressions for the next
</p>
<p>state logic can be found by analyzing the combinational logic circuitry driving the next state variables
</p>
<p>(e.g., Q1_nxt, Q0_nxt). The next state logic expressions will be in terms of the current state variables
</p>
<p>(e.g., Q1_cur, Q0_cur) and any inputs to the FSM.
</p>
<p>The output logic expressions can also be found by analyzing the combinational logic driving the
</p>
<p>outputs of the FSM. Again, these will be in terms of the current state variables and potentially the inputs
</p>
<p>to the FSM. When analyzing the output logic, the type of machine can be determined. If the output logic
</p>
<p>only depends on combinational logic that is driven by the current state variables, the FSM is a Moore
</p>
<p>machine. If the output logic depends on both the current state variables and the FSM inputs, the FSM is a
</p>
<p>Mealy machine. An example of this analysis approach is given in Example 7.28.
</p>
<p>250 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 7.28
Determining the Next State Logic and Output Logic Expression of an FSM
</p>
<p>7.7.2 Finding the State Transition Table of an FSM
</p>
<p>Once the next state logic and output logic expressions are known, the state transition table can be
</p>
<p>created. It is useful to assign more descriptive names to all possible state codes in the FSM. The number
</p>
<p>of unique states possible depends on how many D-flip-flops are used in the state memory of the FSM.
</p>
<p>For example, if the FSM uses two D-flip-flops there are four unique state codes (i.e., 00, 01, 10, 11). We
</p>
<p>can assign descriptive names such as S0 &frac14; 00, S1 &frac14; 01, S2 &frac14; 10, and S3 &frac14; 11. When first creating
</p>
<p>the transition table, we assign labels and list each possible state code. If a particular code is not used, it
</p>
<p>can be removed from the transition table at the end of the analysis. The state code that the machine will
</p>
<p>start in can be found by analyzing its reset and preset connections. This code is typically listed first in the
</p>
<p>7.7 Sequential Logic Analysis &bull; 251</p>
<p/>
</div>
<div class="page"><p/>
<p>table. The transition table is then populated with all possible combinations of current states and inputs.
</p>
<p>The next state codes and output logic values can then be populated by evaluating the next state logic
</p>
<p>and output logic expressions found earlier. An example of this analysis is shown in Example 7.29.
</p>
<p>Example 7.29
Determining the State Transition Table of an FSM
</p>
<p>7.7.3 Finding the State Diagram of an FSM
</p>
<p>Once the state transition table is found, creating the state diagram becomes possible. We start the
</p>
<p>diagram with the state corresponding to the reset state. We then draw how the FSM transitions between
</p>
<p>each of its possible states based on the inputs to the machine and list the corresponding outputs. An
</p>
<p>example of this analysis is shown in Example 7.30.
</p>
<p>252 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 7.30
Determining the State Diagram of an FSM
</p>
<p>7.7.4 Determining the Maximum Clock Frequency of an FSM
</p>
<p>The maximum clock frequency is often one of the banner specifications for a digital system. The
</p>
<p>clock frequency of an FSM depends on a variety of timing specifications within the sequential circuit
</p>
<p>including the setup and hold time of the D-flip-flop, the clock-to-Q delay of the D-flip-flop, the combina-
</p>
<p>tional logic delay driving the input of the D-flip-flop, the delay of the interconnect that wires the circuit
</p>
<p>together, and the desired margin for the circuit. The basic concept of analyzing the timing of FSM is to
</p>
<p>determine how long we must wait after a rising (assuming a rising edge triggered D-flip-flop) clock edge
</p>
<p>7.7 Sequential Logic Analysis &bull; 253</p>
<p/>
</div>
<div class="page"><p/>
<p>occurs until the subsequent rising clock edge can occur. The amount of time that must be allowed
</p>
<p>between rising clock edges depends on howmuch delay exists in the system. A sufficient amount of time
</p>
<p>must exist between clock edges to allow the logic computations to settle so that on the next clock edge
</p>
<p>the D-flip-flops can latch in a new value on their inputs.
</p>
<p>Let&rsquo;s examine all of the sources of delay in an FSM. Let&rsquo;s begin by assuming that all logic values are
</p>
<p>at a stable value and we experience a rising clock edge. The value present on the D input of the D-flip-
</p>
<p>flop is latched into the storage device and will appear on the Q output after one clock-to-Q delay of the
</p>
<p>device (tCQ). Once the new value is produced on the output of the D-flip-flop, it is then used by a variety of
</p>
<p>combinational logic circuits to produce the next state codes and the outputs of the FSM. The next state
</p>
<p>code computation is typically longer than the output computation, so let&rsquo;s examine that path. The new
</p>
<p>value on Q propagates through the combinational logic circuitry and produces the next state code at the
</p>
<p>D input of the D-flip-flop. The delay to produce this next state code includes wiring delay in addition to
</p>
<p>gate delay. When analyzing the delay of the combinational logic circuitry (tcmb) and the delay of the
</p>
<p>interconnect (tint), the worst-case path is always considered. Once the new logic value is produced by the
</p>
<p>next state logic circuitry, it must remain stable for a certain amount of time in order to meet the D-flip-flop&rsquo;s
</p>
<p>setup specification (tsetup). Once this specification is met, the D-flip-flop could be clocked with the next
</p>
<p>clock edge; however, this represents a scenario without any margin in the timing. This means that if
</p>
<p>anything in the system caused the delay to increase even slightly, the D-flip-flop could go metastable. To
</p>
<p>avoid this situation, margin is included in the delay (tmargin). This provides some padding so that the
</p>
<p>system can reliably operate. A margin of 10 % is typical in digital systems. The time that must exist
</p>
<p>between rising clock edges is then simply the sum of all of these sources of delay (tCQ + tcmb + tint +
</p>
<p>tsetup + tmargin). Since the time between rising clock edges is defined as the period of the signal (T), this
</p>
<p>value is also the definition of the period of the fastest clock. Since the frequency of a signal is simply
</p>
<p>f &frac14; 1/T, the maximum clock frequency for the FSM is the reciprocal of the sum of the delay.
</p>
<p>One specification that is not discussed in the above description is the hold time of the D-flip-flop
</p>
<p>(thold). The hold specification is the amount of time that the input to the D-flip-flop must remain constant
</p>
<p>after the clock edge. In modern storage devices, this time is typically very small and considerably less
</p>
<p>than the tCQ specification. If the hold specification is less than tCQ it can be ignored because the output of
</p>
<p>the D-flip-flop will not change until after one tCQ anyway. This means that the hold requirements are
</p>
<p>inherently met. This is the situation with the majority of modern D-flip-flops. In the rare case that the hold
</p>
<p>time is greater than tCQ, then it is used in place of tCQ in the summation of delays. Figure 7.34 gives the
</p>
<p>summary of the maximum clock frequency calculation when analyzing an FSM.
</p>
<p>254 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Let&rsquo;s take a look at an example of how to use this analysis. Example 7.31 shows this analysis for the
</p>
<p>FSM analyzed in prior sections but this time considering the delay specifications of each device.
</p>
<p>Fig. 7.34
Timing analysis of a finite-state machine
</p>
<p>7.7 Sequential Logic Analysis &bull; 255</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 7.31
Determining the Maximum Clock Frequency of an FSM
</p>
<p>CC7.7 What is the risk of running the clock above its maximum allowable frequency in a finite 
state machine?
</p>
<p>A) The power consumption may drop below the recommended level.
</p>
<p>B) The setup and hold specifications of the D-flip-flops may be violated, which may 
put the machine into an unwanted state.
</p>
<p>C) The states may transition too quickly to be usable.
</p>
<p>D) The crystal generating the clock may become unstable.
</p>
<p>CONCEPT CHECK
</p>
<p>256 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Summary
</p>
<p>v Sequential logic refers to a circuit that bases
its outputs on both the present and past
values of the inputs. Past values are held in
sequential logic storage device.
</p>
<p>v All sequential logic storage devices are
based on a cross-coupled feedback loop.
The positive-feedback loop formed in this
configuration will hold either a 1 or a 0. This
is known as a bistable device.
</p>
<p>v If the inputs of the feedback loop in a sequen-
tial logic storage device are driven to exactly
between a 1 and a 0 (i.e., Vcc/2) and then
released, the device will go metastable.
Metastability refers to the behavior where
the device will ultimately be pushed toward
one of the two stable states in the system,
typically by electrical noise. Once the device
begins moving toward one of the stable
states, the positive feedback will reinforce
the transition until it reaches the stable
state. The stable state that the device will
move toward is random and unknown.
</p>
<p>v Cross-coupled inverters are the most basic
form of the positive-feedback loop configura-
tion. To give the ability to drive the outputs of
the storage device to known values, the
inverters are replaced with NOR gates to
form the SR Latch. A variety of other
modifications can be made to the loop con-
figuration to ultimately produce a D-latch and
D-flip-flop.
</p>
<p>v A D-flip-flop will update its Q output with the
value on its D input on every triggering edge
of a clock. The amount of time that it takes for
the Q output to update after a triggering clock
edge is called the &ldquo;t-clock-to-Q&rdquo; (tCQ)
specification.
</p>
<p>v The setup and hold times of a D-flip-flop
describe how long before (tsetup) and after
(thold) the triggering clock edge that the data
on the D input of the device must be stable. If
the D input transitions too close to the trigger-
ing clock edge (i.e., violating a setup or hold
specification) then the device will go meta-
stable and the ultimate value on Q is
unknown.
</p>
<p>v A synchronous system is one in which all
logic transitions occur based on a single
timing event. The timing event is typically
the triggering edge of a clock.
</p>
<p>v There are a variety of common circuits that
can be accomplished using just sequential
storage devices. Examples of these circuits
include switch debouncing, toggle-flops, rip-
ple counters, and shift registers.
</p>
<p>v An FSM is a system that produces outputs
based on the current value of the inputs and
a history of past inputs. The history of inputs
is recorded as states that the machine has
been in. As the machine responds to new
inputs, it transitions between states. This
allows an FSM to make more sophisticated
decisions about what outputs to produce by
knowing its history.
</p>
<p>v A state diagram is a graphical way to
describe the behavior of an FSM. States are
represented using circles and transitions are
represented using arrows. Outputs are listed
either inside of the state circle or next to the
transition arrow.
</p>
<p>v A state transition table contains the same
information as a state diagram, but in tabular
format. This allows the system to be more
easily synthesized because the information
is in a form similar to a truth table.
</p>
<p>v The first step in FSM synthesis is creating the
state memory. The state memory consists of
a set of D-flip-flops that hold the current state
of the FSM. Each state in the FSM must be
assigned a binary code. The type of
encoding is arbitrary; however, there are cer-
tain encoding types that are commonly used
such as binary, gray code, and one-hot.
Once the codes are assigned, state variables
need to be defined for each bit position for
both the current state and the next state
codes. The state variables for the current
state represent the Q outputs of the D-flip-
flops, which hold the current state code. The
state variables for the next state code repre-
sent the D inputs of the D-flip-flops. A D-flip-
flop is needed for each bit in the state code.
On the triggering edge of a clock, the current
state will be updated with the next state code.
</p>
<p>v The second step in FSM synthesis is creating
the next state logic. The next state logic is
combinational logic circuitry that produces
the next state codes based on the current
state variables and any system inputs. The
next state logic drives the D inputs of the D-
flip-flops in the state memory.
</p>
<p>v The third step in FSM synthesis is creating
the output logic. The output logic is combina-
tional logic circuitry that produces the system
outputs based on the current state, and
potentially the system inputs.
</p>
<p>v The output logic always depends on the cur-
rent state of an FSM. If the output logic also
depends on the system inputs, the machine
is a Mealy machine. If the output logic does
</p>
<p>7.7 Sequential Logic Analysis &bull; 257</p>
<p/>
</div>
<div class="page"><p/>
<p>not depend on the system inputs, the
machine is a Moore machine.
</p>
<p>v A counter is a special type of FSM in which
the states are traversed linearly. The linear
progression of states allows the next state
logic to be simplified. The complexity of the
output logic in a counter can also be reduced
by encoding the states with the desired
counter output for that state. This technique,
known as state-encoded outputs, allows the
system outputs to simply be the current state
of the FSM.
</p>
<p>v The reset state of an FSM is the state that the
machine will go to when it begins operation.
The state code for the reset state must be
configured using the reset and/or preset lines
of the D-flip-flops. If only reset lines are used
on the D-flip-flops, the reset state must be
encoded using only zeros.
</p>
<p>v Given the logic diagram for a state machine,
the logic expression for the next state mem-
ory and the output logic can be determined
by analyzing the combinational logic driving
the D inputs of the state memory (i.e., the
next state logic) and the combinational logic
driving the system outputs (i.e., the output
logic).
</p>
<p>v Given the logic diagram for a state diagram,
the state diagram can be determined by first
finding the logic expressions for the next
state and output logic. The number of D-flip-
flops in the logic diagram can then be used to
</p>
<p>calculate the possible number of state codes
that the machine has. The state codes are
then used to calculate the next state logic
and output values. From this information a
state transition table can be created and in
turn the state diagram.
</p>
<p>v The maximum frequency of an FSM is found
by summing all sources of time delay that
must be accounted for before the next trig-
gering edge of the clock can occur. These
sources include tCQ, the worst-case combi-
national logic path, the worst-case intercon-
nect delay path, the setup/hold time of the
D-flip-flops, and any margin that is to be
included. The sum of these timing delays
represents the smallest period (T) that the
clock can have. This is then converted to
frequency.
</p>
<p>v If the tCQ time is greater than or equal to the
hold time, the hold time can be ignored in the
maximum frequency calculation. This is
because the outputs of the D-flip-flops are
inherently held while the D-flip-flops are pro-
ducing the next output value. The time it
takes to change the outputs after a triggering
clock edge is defined as tCQ. This means as
long as tCQ � thold, the hold time specifica-
tion is inherently met since the logic driving
the next state codes uses the Q outputs of
the D-flip-flops.
</p>
<p>Exercise Problems
</p>
<p>For some of the following exercise problems
</p>
<p>you will be asked to design a VHDL model
</p>
<p>and perform a functional simulation. You will
</p>
<p>be provided with a test bench for each of
</p>
<p>these problems. The details of how to create
</p>
<p>your own VHDL test bench are provided later
</p>
<p>in Chap. 8. For some of the following exer-
</p>
<p>cise problems you will be asked to use D-flip-
</p>
<p>flops as part of a VHDL design. You will be
</p>
<p>provided with the model of the D-flip-flop and
</p>
<p>can declare it as a component in your
</p>
<p>design. The VHDL entity for a D-flip-flop is
</p>
<p>given in Fig. 7.35. Keep in mind that this D-
</p>
<p>flip-flop has an active LOW reset. This
</p>
<p>means that when the reset line is pulled to
</p>
<p>a 0, the outputs will go to Q &frac14; 0 and Qn &frac14; 1.
</p>
<p>When the reset line is LOW, the incoming
</p>
<p>clock is ignored. Once the reset line goes
</p>
<p>HIGH, the D-flip-flop resumes normal behav-
</p>
<p>ior. The details of how to create your own
</p>
<p>model of a D-flip-flop are provided later in
</p>
<p>Chap. 8.
</p>
<p>Fig. 7.35
D-Flip-Flop Entity
</p>
<p>258 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_8">http://dx.doi.org/10.1007/978-3-319-34195-8_8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_8">http://dx.doi.org/10.1007/978-3-319-34195-8_8</a></div>
</div>
<div class="page"><p/>
<p>Section 7.1&mdash;Sequential Logic Storage
</p>
<p>Devices
</p>
<p>7.1.1 What does the term metastability refer to in a
sequential storage device?
</p>
<p>7.1.2 What does the term bistable refer to in a
sequential storage device?
</p>
<p>7.1.3 You are given a cross-coupled inverter pair in
which all nodes are set to Vcc/2. Why will this
configuration always move to a more stable
state?
</p>
<p>7.1.4 An SR Latch essentially implements the same
cross-coupled feedback loop to store informa-
tion as in a cross-coupled inverter pair. What is
the purpose of using NOR gates instead of
inverters in the SR Latch configuration?
</p>
<p>7.1.5 Why isn&rsquo;t the input condition S &frac14; R &frac14; 1 used
in an SR Latch?
</p>
<p>7.1.6 How will the output Q behave in an SR Latch if
the inputs continuously switch between S &frac14; 0,
R &frac14; 1 and S &frac14; 1, R &frac14; 1 every 10 ns?
</p>
<p>7.1.7 How do D-flip-flops enable synchronous
systems?
</p>
<p>7.1.8 What signal in the D-flip-flop in Fig. 7.35 has
the highest priority?
</p>
<p>7.1.9 For the timing diagram shown in Fig. 7.36,
draw the outputs Q and Qn for a rising edge-
triggered D-flip-flop with active LOW.
</p>
<p>7.1.10 For the timing diagram shown in Fig. 7.37,
draw the outputs Q and Qn for a rising edge-
triggered D-flip-flop with active LOW.
</p>
<p>7.1.11 For the timing diagram shown in Fig. 7.38,
draw the outputs Q and Qn for a rising edge-
triggered D-flip-flop with active LOW.
</p>
<p>Section 7.2&mdash;Sequential Logic Timing
</p>
<p>Considerations
</p>
<p>7.2.1 What timing specification is violated in a D-flip-
flop when the data is not held long enough
before the triggering clock edge occurs?
</p>
<p>7.2.2 What timing specification is violated in a D-flip-
flop when the data is not held long enough after
the triggering clock edge occurs?
</p>
<p>7.2.3 What is the timing specification for a D-flip-flop
that describes how long after the triggering
clock edge occurs that the new data will be
present on the Q output?
</p>
<p>7.2.4 What is the timing specification for a D-flip-flop
that describes how long after the device goes
metastable that the outputs will settle to known
states.
</p>
<p>7.2.5 If the Q output of a D-flip-flop is driving the D
input of another D-flip-flop from the same logic
family, can the hold time be ignored if it is less
than the clock-to-Q delay? Provide an expla-
nation as to why or why not.
</p>
<p>Section 7.3&mdash;Common Circuits Based on
</p>
<p>Sequential Storage Devices
</p>
<p>7.3.1 In a toggle flop (T-flop) configuration, the Qn
output of the D-flip-flop is routed back to the D
input. This can lead to a hold time violation if
the output arrives on the input too quickly.
Under what condition(s) is a hold time violate
not an issue?
</p>
<p>7.3.2 In a toggle flop (T-flop) configuration, what
timing specifications dictate how quickly the
next edge of the incoming clock can occur?
</p>
<p>7.3.3 One drawback of a ripple counter is that the
delay through the cascade of D-flip-flops can
become considerable for large counters. At
what point does the delay of a ripple counter
prevent it from being useful?
</p>
<p>7.3.4 A common use of a ripple counter is in the
creation of a 2n programmable clock divider.
</p>
<p>Fig. 7.36
D-Flip-Flop Timing Diagram Exercise 1
</p>
<p>Fig. 7.37
`D-Flip-Flop Timing Diagram Exercise 2
</p>
<p>Fig. 7.38
D-Flip-Flop Timing Diagram Exercise 3
</p>
<p>Exercise Problems &bull; 259</p>
<p/>
</div>
<div class="page"><p/>
<p>In a ripple counter, bit(0) has a frequency that is
exactly 1/2 of the incoming clock, bit(1) has a
frequency that is exactly 1/4 of the incoming
clock, bit(2) has a frequency that is exactly 1/8
of the incoming clock, etc. This behavior can
be exploited to create a divided down output
clock that is divided by multiples of 2n by
selecting a particular bit of the counter. The
typical configuration of this programmable
clock divider is to route each bit of the counter
to an input of a multiplexer. The select lines
going to the multiplexer choose which bit of
the counter is used as the divided down clock
output. This architecture is shown in Fig. 7.39.
Design a VHDL model to implement the pro-
grammable clock divider shown in this figure.
Use the entity definition provided in this figure
for your design. Use a 4-bit ripple counter to
produce four divided versions of the clock (1/2,
1/4, 1/8, and 1/16). Your system will take in two
select lines that will choose which version of
the clock is to be routed to the output. Instanti-
ate the D-flip-flops model provided to imple-
ment the ripple counter. Implement the 4-to-1
multiplexer using conditional signal
assignments. The multiplexer does not need
to be its own component.
</p>
<p>7.3.5 What phenomenon causes switch bounce in
an SPST switch?
</p>
<p>7.3.6 What two phenomena causes switch bounce in
a SPDTswitch?
</p>
<p>Section 7.4&mdash;Finite-State Machines
</p>
<p>7.4.1 For the state diagram in Fig. 7.40, answer the
following questions regarding the number of D-
flip-flops needed to implement the state mem-
ory of the FSM.
</p>
<p>a) How many D-flip-flops will this
machine take if the states are
encoded in binary?
</p>
<p>b) How many D-flip-flops will this
machine take if the states are
encoded in gray code?
</p>
<p>c) How many D-flip-flops will this
machine take if the states are
encoded in one-hot?
</p>
<p>7.4.2 For the state diagram in Fig. 7.40, is this a
Mealy or Moore machine?
</p>
<p>7.4.3 Design the FSM circuitry by hand to implement
the behavior described by the state diagram in
Fig. 7.40. Name the current state variables
Q1_cur and Q0_cur and name the next state
variables Q1_nxt and Q0_nxt. Use the follow-
ing state codes:
</p>
<p>Start &frac14; &ldquo;00&rdquo;
Midway &frac14; &ldquo;01&rdquo;
Done &frac14; &ldquo;10&rdquo;
a) What is the next state logic expres-
</p>
<p>sion for Q1_nxt?
</p>
<p>b) What is the next state logic expres-
sion for Q0_nxt?
</p>
<p>c) What is the output logic expression
for Dout?
</p>
<p>d) Draw the final logic diagram for this machine.
</p>
<p>7.4.4 Design a VHDL model to implement the behav-
ior described by the state diagram in Fig. 7.40.
Use the entity definition provided in Fig. 7.41 for
your design. Name the current state variables
Q1_cur and Q0_cur and name the next state
variables Q1_nxt and Q0_nxt. Instantiate the D-
flip-flop model provided to implement your state
memory. Use concurrent signal assignments
</p>
<p>Fig. 7.40
FSM 1 State Diagram
</p>
<p>Fig. 7.39
Programmable Clock Entity
</p>
<p>260 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>with logical operators for the implementation of
your next state and output logic.
</p>
<p>7.4.5 Design a VHDLmodel to implement the behav-
ior described by the state diagram in Fig. 7.40.
Use the entity definition provided in Fig. 7.41
for your design. Name the current state
variables Q1_cur and Q0_cur and name the
next state variables Q1_nxt and Q0_nxt.
Instantiate the D-flip-flop model provided to
implement your state memory. Use conditional
signal assignments for the implementation of
your next state and output logic.
</p>
<p>7.4.6 Design a VHDLmodel to implement the behav-
ior described by the state diagram in Fig. 7.40.
Use the entity definition provided in Fig. 7.41
for your design. Name the current state
variables Q1_cur and Q0_cur and name the
next state variables Q1_nxt and Q0_nxt.
Instantiate the D-flip-flop model provided to
implement your state memory. Use selected
signal assignments for the implementation of
your next state and output logic.
</p>
<p>7.4.7 For the state diagram in Fig. 7.42, answer the
following questions regarding the number of D-
flip-flops needed to implement the state mem-
ory of the FSM.
</p>
<p>a) How many D-flip-flops will this machine
take if the states are encoded in binary?
</p>
<p>b) How many D-flip-flops will this machine
take if the states are encoded in gray
code?
</p>
<p>c) How many D-flip-flops will this machine
take if the states are encoded in one-hot?
</p>
<p>7.4.8 For the state diagram in Fig. 7.42, is this a
Mealy or Moore machine?
</p>
<p>7.4.9 Design the FSM circuitry by hand to implement
the behavior described by the state diagram in
Fig. 7.42. Name the current state variables
Q1_cur and Q0_cur and name the next state
variables Q1_nxt and Q0_nxt. Also, use the
following state codes:
</p>
<p>S0 &frac14; &ldquo;00&rdquo;
S1 &frac14; &ldquo;01&rdquo;
S2 &frac14; &ldquo;10&rdquo;
S3 &frac14; &ldquo;11&rdquo;
a) What is the next state logic expression
</p>
<p>for Q1_nxt?
</p>
<p>b) What is the next state logic expression
for Q0_nxt?
</p>
<p>c) What is the output logic expression for
Dout?
</p>
<p>d) Draw the final logic diagram for this
machine.
</p>
<p>7.4.10 Design a VHDLmodel to implement the behav-
ior described by the state diagram in Fig. 7.42.
Use the entity definition provided in Fig. 7.43
for your design. Name the current state
variables Q1_cur and Q0_cur and name the
next state variables Q1_nxt and Q0_nxt.
Instantiate the D-flip-flop model provided to
implement your state memory. Use concurrent
signal assignments with logical operators for
the implementation of your next state and out-
put logic.
</p>
<p>7.4.11 Design a VHDLmodel to implement the behav-
ior described by the state diagram in Fig. 7.42.
Use the entity definition provided in Fig. 7.43
for your design. Name the current state
variables Q1_cur and Q0_cur and name the
next state variables Q1_nxt and Q0_nxt.
Instantiate the D-flip-flop model provided to
implement your state memory. Use conditional
signal assignments for the implementation of
your next state and output logic.
</p>
<p>7.4.12 Design a VHDLmodel to implement the behav-
ior described by the state diagram in Fig. 7.42.
Use the entity definition provided in Fig. 7.43
for your design. Name the current state
variables Q1_cur and Q0_cur and name the
next state variables Q1_nxt and Q0_nxt.
Instantiate the D-flip-flop model provided to
implement your state memory. Use selected
signal assignments for the implementation of
your next state and output logic.Fig. 7.42
</p>
<p>FSM 2 State Diagram
</p>
<p>Fig. 7.43
FSM 2 Entity
</p>
<p>Fig. 7.41
FSM 1 Entity
</p>
<p>Exercise Problems &bull; 261</p>
<p/>
</div>
<div class="page"><p/>
<p>7.4.13 Design a 4-bit serial bit sequence detector by
hand similar to the one described in Example
7.9. The input to your state detector is called
DIN and the output is called FOUND. Your
detector will assert FOUND anytime there is a
4-bit sequence of &ldquo;0101.&rdquo; For all other input
sequences the output is not asserted.
</p>
<p>a) Provide the state diagram for this FSM.
</p>
<p>b) Encode your states using binary
encoding. How many D-flip-flops does it
take to implement the state memory for
this FSM?
</p>
<p>c) Provide the state transition table for
this FSM.
</p>
<p>d) Synthesize the combinational logic
expressions for the next state logic.
</p>
<p>e) Synthesize the combinational logic
expression for the output logic.
</p>
<p>f) Is this machine a Mealy or Moore
machine?
</p>
<p>g) Draw the logic diagram for this FSM.
</p>
<p>7.4.14 Design a 20 cent vending machine controller by
hand similar to the one described in Example
7.12. Your controller will take in nickels and
dimes and dispense a product anytime the cus-
tomer has entered 20 cents. Your FSM has two
inputs, Nin andDin. Nin is assertedwhenever the
customer enters a nickel while Din is asserted
anytime the customer enters a dime. Your FSM
has two outputs, Dispense and Change. Dis-
pense is asserted anytime the customer has
entered at least 20 cents andChange is asserted
anytime the customer has entered more than
20 cents and needs a nickel in change.
</p>
<p>a) Provide the state diagram for this FSM.
</p>
<p>b) Encode your states using binary
encoding. How many D-flip-flops does it
take to implement the state memory for
this FSM?
</p>
<p>c) Provide the state transition table for
this FSM.
</p>
<p>d) Synthesize the combinational logic
expressions for the next state logic.
</p>
<p>e) Synthesize the combinational logic
expressions for the output logic.
</p>
<p>f) Is this machine a Mealy or Moore
machine?
</p>
<p>g) Draw the logic diagram for this FSM.
</p>
<p>7.4.15 Design an FSM by hand that controls a traffic
light at the intersection of a busy highway and a
seldom used side road. You will be designing
the control signals for just the red, yellow, and
green lights facing the highway. Under normal
conditions, the highway has a green light. The
side road has a car detector that indicates
when a car pulls up by asserting a signal called
CAR. When CAR is asserted, you will change
the highway traffic light from green to yellow.
</p>
<p>Once yellow, you will always go to red. Once in
the red position, a built-in timer will begin a
countdown and provide your controller a signal
called TIMEOUTwhen 15 s has passed. Once
TIMEOUT is asserted, you will change the
highway traffic light back to green. Your system
will have three outputs GRN, YLW, and RED
that control when the highway facing traffic
lights are on (1 &frac14; ON, 0 &frac14; OFF).
</p>
<p>a) Provide the state diagram for this FSM.
</p>
<p>b) Encode your states using binary
encoding. How many D-flip-flops does it
take to implement the state memory for
this FSM?
</p>
<p>c) Provide the state transition table for
this FSM.
</p>
<p>d) Synthesize the combinational logic
expressions for the next state logic.
</p>
<p>e) Synthesize the combinational logic
expressions for the output logic.
</p>
<p>f) Is thismachineaMealyorMooremachine?
</p>
<p>g) Draw the logic diagram for this FSM.
</p>
<p>Section 7.5&mdash;Counters
</p>
<p>7.5.1 Design a 3-bit binary up counter by hand. This
state machine will need eight states and require
three bits for the state variable codes. Name the
current state variables Q2_cur, Q1_cur, and
Q0_cur and the next state variables Q2_nxt,
Q1_nxt, and Q0_nxt. The output of your counter
will be a 3-bit vector called Count.
</p>
<p>a) What is the next state logic expression
for Q2_nxt?
</p>
<p>b) What is the next state logic expression
for Q1_nxt?
</p>
<p>c) What is the next state logic expression
for Q0_nxt?
</p>
<p>d) What is the output logic expression for
Count(2)?
</p>
<p>e) What is the output logic expression for
Count(1)?
</p>
<p>f) What is the output logic expression for
Count(0)?
</p>
<p>g) Draw the logic diagram for this counter.
</p>
<p>7.5.2 Design a VHDL model for a 3-bit binary up
counter. Instantiate the D-flip-flop model
provided to implement your state memory.
Use whatever concurrent signal assignment
modeling approach you wish to model the
next state and output logic. Use the VHDL
entity provided in Fig. 7.44 for your design.
</p>
<p>Fig. 7.44
3-Bit Binary Up Counter Entity
</p>
<p>262 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>7.5.3 Design a 3-bit binary up/down counter by
hand. The counter will have an input called
&ldquo;Up&rdquo; that will dictate the direction of the
counter. When Up &frac14; 1, the counter should
increment and when Up &frac14; 0 it should decre-
ment. This state machine will need eight states
and require three bits for the state variable
codes. Name the current state variables
Q2_cur, Q1_cur, and Q0_cur and the next
state variables Q2_nxt, Q1_nxt, and Q0_nxt.
The output of your counter will be a 3-bit vector
called Count.
</p>
<p>a) What is the next state logic expression
for Q2_nxt?
</p>
<p>b) What is the next state logic expression
for Q1_nxt?
</p>
<p>c) What is the next state logic expression
for Q0_nxt?
</p>
<p>d) What is the output logic expression for
Count(2)?
</p>
<p>e) What is the output logic expression for
Count(1)?
</p>
<p>f) What is the output logic expression for
Count(0)?
</p>
<p>g) Draw the logic diagram for this counter.
</p>
<p>7.5.4 Design a VHDL model for a 3-bit binary
up/down counter. Instantiate the D-flip-flop
model provided to implement your state mem-
ory. Use whatever concurrent signal assign-
ment modeling approach you wish to model
the next state and output logic. Use the VHDL
entity provided in Fig. 7.45 for your design.
</p>
<p>7.5.5 Design a 3-bit gray code up counter by hand.
This state machine will need eight states and
require three bits for the state variable codes.
Name the current state variables Q2_cur,
Q1_cur, and Q0_cur and the next state
variables Q2_nxt, Q1_nxt, and Q0_nxt. The
output of your counter will be a 3-bit vector
called Count.
</p>
<p>a) What is the next state logic expression
for Q2_nxt?
</p>
<p>b) What is the next state logic expression
for Q1_nxt?
</p>
<p>c) What is the next state logic expression
for Q0_nxt?
</p>
<p>d) What is the output logic expression for
Count(2)?
</p>
<p>e) What is the output logic expression for
Count(1)?
</p>
<p>f) What is the output logic expression for
Count(0)?
</p>
<p>g) Draw the logic diagram for this counter.
</p>
<p>7.5.6 Design a VHDL model for a 3-bit gray code up
counter. Instantiate the D-flip-flop model
provided to implement your state memory.
Use whatever concurrent signal assignment
modeling approach you wish to model the
next state and output logic. Use the VHDL
entity provided in Fig. 7.46 for your design.
</p>
<p>7.5.7 Design a 3-bit gray code up/down counter by
hand. The counter will have an input called
&ldquo;Up&rdquo; that will dictate the direction of the
counter. When Up &frac14; 1, the counter should
increment and when Up &frac14; 0 it should decre-
ment. This state machine will need eight states
and require three bits for the state variable
codes. Name the current state variables
Q2_cur, Q1_cur, and Q0_cur and the next
state variables Q2_nxt, Q1_nxt, and Q0_nxt.
The output of your counter will be a 3-bit vector
called Count.
</p>
<p>a) What is the next state logic expression
for Q2_nxt?
</p>
<p>b) What is the next state logic expression
for Q1_nxt?
</p>
<p>c) What is the next state logic expression
for Q0_nxt?
</p>
<p>d) What is the output logic expression for
Count(2)?
</p>
<p>e) What is the output logic expression for
Count(1)?
</p>
<p>f) What is the output logic expression for
Count(0)?
</p>
<p>g) Draw the logic diagram for this counter.
</p>
<p>7.5.8 Design a VHDL model for a 3-bit gray code
up/down counter. Instantiate the D-flip-flop
model provided to implement your state mem-
ory. Use whatever concurrent signal assign-
ment modeling approach you wish to model
the next state and output logic. Use the VHDL
entity provided in Fig. 7.47 for your design.
</p>
<p>Fig. 7.47
3-Bit Gray Code Up/Down Counter Entity
</p>
<p>Fig. 7.45
3-Bit Binary Up/Down Counter Entity
</p>
<p>Fig. 7.46
3-Bit Gray Code Up Counter Entity
</p>
<p>Exercise Problems &bull; 263</p>
<p/>
</div>
<div class="page"><p/>
<p>Section 7.6&mdash;Finite-State Machine&rsquo;s
</p>
<p>Reset Condition
</p>
<p>7.6.1 Are resets typically synchronous or
asynchronous?
</p>
<p>7.6.2 Why is it necessary to have a reset/preset
condition in an FSM?
</p>
<p>7.6.3 How does the reset/preset condition corre-
spond to the behavior described in the state
diagram?
</p>
<p>7.6.4 When is it necessary to also use the preset line
(s) of a D-flip-flop instead of just the reset line
(s) when implementing the state memory of an
FSM?
</p>
<p>7.6.5 If an FSM has eight unique states that are
encoded in binary and all D-flip-flops used for
the state memory use their reset lines, what is
the state code that the machine will go to upon
reset?
</p>
<p>Section 7.7&mdash;Sequential Logic Analysis
</p>
<p>7.7.1 For the FSM logic diagram in Fig. 7.48, give the
next state logic expression for Q_nxt.
</p>
<p>7.7.2 For the FSM logic diagram in Fig. 7.48, give the
output logic expression for Tout.
</p>
<p>7.7.3 For the FSM logic diagram in Fig. 7.48, give the
state transition table.
</p>
<p>7.7.4 For the FSM logic diagram in Fig. 7.48, give the
state diagram.
</p>
<p>7.7.5 For the FSM logic diagram in Fig. 7.48, give the
maximum clock frequency.
</p>
<p>7.7.6 For the FSM logic diagram in Fig. 7.49, give the
next state logic expression for Q_nxt.
</p>
<p>7.7.7 For the FSM logic diagram in Fig. 7.49, give the
output logic expression for F.
</p>
<p>7.7.8 For the FSM logic diagram in Fig. 7.49, give the
state transition table.
</p>
<p>7.7.9 For the FSM logic diagram in Fig. 7.49, give the
state diagram.
</p>
<p>7.7.10 For the FSM logic diagram in Fig. 7.49, give the
maximum clock frequency.
</p>
<p>7.7.11 For the FSM logic diagram in Fig. 7.50, give the
next state logic expressions for Q1_nxt and
Q0_nxt.
</p>
<p>7.7.12 For the FSM logic diagram in Fig. 7.50, give the
output logic expression for Return.
</p>
<p>7.7.13 For the FSM logic diagram in Fig. 7.50, give the
state transition table.
</p>
<p>7.7.14 For the FSM logic diagram in Fig. 7.50, give the
state diagram.
</p>
<p>7.7.15 For the FSM logic diagram in Fig. 7.50, give the
maximum clock frequency.
</p>
<p>Fig. 7.48
Sequential Logic Analysis 1
</p>
<p>Fig. 7.49
Sequential Logic Analysis 2
</p>
<p>Fig. 7.50
Sequential Logic Analysis 3
</p>
<p>264 &bull; Chapter 7: Sequential Logic Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 8: VHDL (Part 2)
In Chap. 5 VHDL was presented as a way to describe the behavior of concurrent systems. The
</p>
<p>modeling techniques presented were appropriate for combinational logic because these types of circuits
</p>
<p>have outputs dependent only on the current values of their inputs. This means a model that continuously
</p>
<p>performs signal assignments provides an accurate model of this circuit behavior. In Chap. 7 sequential
</p>
<p>logic storage devices were presented that did not continuously update their outputs based on the
</p>
<p>instantaneous values of their inputs. Instead, sequential storage devices only update their outputs
</p>
<p>based upon an event, most often the edge of a clock signal. The modeling techniques presented in
</p>
<p>Chap. 5 are unable to accurately describe this type of behavior. In this chapter we describe the VHDL
</p>
<p>constructs to model signal assignments that are triggered by an event in order to accurately model
</p>
<p>sequential logic. We can then use these techniques to describe more complex sequential logic circuits
</p>
<p>such as finite-state machines and register transfer-level systems. This chapter also presents how to
</p>
<p>create test benches and looks at commonly used packages that increase the capability and accuracy
</p>
<p>with which VHDL can model modern systems. The goal of this chapter is to give an understanding of the
</p>
<p>full capability of hardware description languages.
</p>
<p>Learning Outcomes&mdash;After completing this chapter, you will be able to:
</p>
<p>8.1 Describe the behavior of a VHDL process and how it is used to model sequential logic
circuits.
</p>
<p>8.2 Model combinational logic circuits using a process and conditional programming
constructs.
</p>
<p>8.3 Describe how and why signal attributes are used in VHDL models.
8.4 Design a test bench to verify the functional operation of a system.
8.5 Describe the capabilities provided by the most common VHDL packages.
</p>
<p>8.1 The Process
</p>
<p>VHDL uses a process to model signal assignments that are based on an event. A process is a
</p>
<p>technique to model behavior of a system; thus a process is placed in the VHDL architecture after the
</p>
<p>begin statement. The signal assignments within a process have unique characteristics that allow them to
</p>
<p>accurately model sequential logic. First, the signal assignments do not take place until the process ends
</p>
<p>or is suspended. Second, the signal assignments will be made only once each time the process is
</p>
<p>triggered. Finally, the signal assignments will be executed in the order that they appear within the
</p>
<p>process. This assignment behavior is called a sequential signal assignment. Sequential signal
</p>
<p>assignments allow a process to model register transfer-level behavior where a signal can be used as
</p>
<p>both the operand of an assignment and the destination of a different assignment within the same
</p>
<p>process. VHDL provides two techniques to trigger a process, the sensitivity list and the wait statement.
</p>
<p>8.1.1 Sensitivity List
</p>
<p>A sensitivity list is a mechanism to control when a process is triggered (or started). A sensitivity list
</p>
<p>contains a list of signals that the process is sensitive to. If there is a transition on any of the signals in the
</p>
<p>list, the process will be triggered and the signal assignments in the process will be made. The following is
</p>
<p>the syntax for a process that uses a sensitivity list:
</p>
<p>process_name : process (&lt;signal_name1&gt;, &lt;signal_name2&gt;, . . .)
</p>
<p>-- variable declarations
</p>
<p># Springer International Publishing Switzerland 2017
</p>
<p>B.J. LaMeres, Introduction to Logic Circuits &amp; Logic Design with VHDL,
</p>
<p>DOI 10.1007/978-3-319-34195-8_8
</p>
<p>265</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_5">http://dx.doi.org/10.1007/978-3-319-34195-8_5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_7">http://dx.doi.org/10.1007/978-3-319-34195-8_7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_5">http://dx.doi.org/10.1007/978-3-319-34195-8_5</a></div>
</div>
<div class="page"><p/>
<p>begin
</p>
<p>sequential_signal_assignment_1
sequential_signal_assignment_2
</p>
<p>:
end process;
</p>
<p>Let&rsquo;s look at a simple model for a flip flop.
</p>
<p>Example:
</p>
<p>FlipFlop : process (Clock)
begin
</p>
<p>Q &lt;&frac14; D;
end process;
</p>
<p>In this example, a transition on the signal clock (LOW to HIGH or HIGH to LOW) will trigger the
</p>
<p>process. The signal assignment of D to Q will be executed once the process ends. When the signal clock
</p>
<p>is not transitioning, the process will not trigger and no assignments will be made to Q, thus modeling the
</p>
<p>behavior of Q holding its last value. This behavior is close to modeling the behavior of a real D-flip-flop,
</p>
<p>but more constructs are needed to model behavior that is sensitive to only a particular type of transition
</p>
<p>(i.e., rising or falling edge). These constructs will be covered later.
</p>
<p>8.1.2 The Wait Statement
</p>
<p>Await statement is a mechanism to suspend (or stop) a process and allow signal assignments to be
</p>
<p>executed without the need for the process to end. When using a wait statement, a sensitivity list is not
</p>
<p>used. Without a sensitivity list, the process will immediately trigger. Within the process, the wait
</p>
<p>statement is used to stop and start the process. There are three ways in which wait statements can be
</p>
<p>used. The first is an indefinite wait. In the following example, the process does not contain a sensitivity
</p>
<p>list, so it will trigger immediately. The keyword wait is used to suspend the process. Once this statement
</p>
<p>is reached, the signal assignments to Y1 and Y2 will be executed and the process will suspend
</p>
<p>indefinitely.
</p>
<p>Example:
</p>
<p>Proc_Ex1 : process
begin
</p>
<p>Y1 &lt;&frac14; &rsquo;0&rsquo;;
Y2 &lt;&frac14; &rsquo;1&rsquo;;
wait;
</p>
<p>end process;
</p>
<p>The second technique to use a wait statement to suspend a process is to use it in conjunction with
</p>
<p>the keyword for and a time expression. In the following example, the process will trigger immediately
</p>
<p>since it does not contain a sensitivity list. Once the process reaches the wait statement, it will suspend
</p>
<p>and execute the first signal assignment to CLK (CLK &lt;&frac14; &lsquo;0&rsquo;). After 5 ns, the process will start again.
</p>
<p>Once it reaches the second wait statement, it will suspend and execute the second signal assignment to
</p>
<p>CLK (CLK &lt;&frac14; &ldquo;1&rdquo;). After another 5 ns, the process will start again and immediately end due to the end
</p>
<p>process statement. After the process ends, it will immediately trigger again due to the lack of a sensitivity
</p>
<p>list and repeat the behavior just described. This behavior will continue indefinitely. This example creates
</p>
<p>a square wave called CLK with a period of 10 ns.
</p>
<p>Example:
</p>
<p>Proc_Ex2 : process
begin
</p>
<p>CLK &lt;&frac14; &rsquo;0&rsquo;; wait for 5 ns;
CLK &lt;&frac14; &rsquo;1&rsquo;; wait for 5 ns;
</p>
<p>end process;
</p>
<p>266 &bull; Chapter 8: VHDL (Part 2)</p>
<p/>
</div>
<div class="page"><p/>
<p>The third technique to use a wait statement to suspend a process is to use it in conjunction with the
</p>
<p>keyword until and a Boolean condition. In the following example, the process will again trigger immedi-
</p>
<p>ately because there is not a sensitivity list present. The process will then immediately suspend and only
</p>
<p>resume once a Boolean condition becomes true (i.e., Counter &gt; 15). Once this condition is true, the
</p>
<p>process will start again. Once it reaches the second wait statement, it will execute the first signal
</p>
<p>assignment to RollOver (RollOver &lt;&frac14; &ldquo;1&rdquo;). After 1 ns, the process will resume. Once the process
</p>
<p>ends, it will execute the second signal assignment to RollOver (RollOver &lt;&frac14; &ldquo;0&rdquo;).
</p>
<p>Example:
</p>
<p>Proc_Ex3 : process
begin
</p>
<p>wait until (Counter &gt; 15); -- first wait statement
RollOver &lt;&frac14; &rsquo;1&rsquo;; wait for 1 ns; -- second wait statement
RollOver &lt;&frac14; &rsquo;0&rsquo;;
</p>
<p>end process;
</p>
<p>Wait statements are typically not synthesizable and are most often used for creating stimulus
</p>
<p>patterns in test benches.
</p>
<p>8.1.3 Sequential Signal Assignments
</p>
<p>One of the more confusing concepts of a process is how sequential signal assignments behave. The
</p>
<p>rules of signal assignments within a process are as follows:
</p>
<p>&bull; Signals cannot be declared within a process.
</p>
<p>&bull; Signal assignments do not take place until the process ends or suspends.
</p>
<p>&bull; Signal assignments are executed in the sequence they appear in the process (once the
process ends or process suspends).
</p>
<p>Let&rsquo;s take a look at an example of how signals behave in a process. Example 8.1 shows the
</p>
<p>behavior of sequential signal assignments when executed within a process. Intuitively, we would assume
</p>
<p>that F will be the complement of A; however, due to the way that sequential signal assignments are
</p>
<p>performed within a process, this is not the case. In order to understand this behavior, let&rsquo;s look at the
</p>
<p>situation where A transitions from a 0 to a 1 with B &frac14; 0 and F &frac14; 0 initially. This transition triggers the
</p>
<p>process since A is listed in the sensitivity list. When the process triggers, A &frac14; 1 since this is where the
</p>
<p>input resides after the triggering transition. The first signal assignment (B &lt;&frac14; A) will cause B &frac14; 1, but
</p>
<p>this assignment occurs only after the process ends. This means that when the second signal assignment
</p>
<p>is evaluated (F &lt;&frac14; not B), it uses the initial value of B from when the process triggered (B &frac14; 0) since B is
</p>
<p>not updated to a 1 until the process ends. The second assignment yields F &frac14; 1. When the process ends,
</p>
<p>A &frac14; 1, B &frac14; 1, and F &frac14; 1. The behavior of this process will always result in A &frac14; B &frac14; F. This is counter-
</p>
<p>intuitive because the statement F &lt;&frac14; not B leads us to believe that F will always be the complement of A
</p>
<p>and B; however, this is not the case due to the way that signal assignments are only updated in a process
</p>
<p>upon suspension or when the process ends.
</p>
<p>8.1 The Process &bull; 267</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 8.1
Behavior of Sequential Signal Assignments Within a Process
</p>
<p>Now let&rsquo;s consider how these assignments behave when executed as concurrent signal
</p>
<p>assignments. Example 8.2 shows the behavior of the same signal assignments as in Example 8.1, but
</p>
<p>this time outside of a process. In this model, the statements are executed concurrently and produce the
</p>
<p>expected behavior of F being the complement of A.
</p>
<p>Example 8.2
Behavior of Concurrent Signal Assignments Outside a Process
</p>
<p>While the behavior of the sequential signal assignments initially seems counterintuitive, it is
</p>
<p>necessary in order to model the behavior of sequential storage devices and will become clear once
</p>
<p>more VHDL constructs have been introduced.
</p>
<p>268 &bull; Chapter 8: VHDL (Part 2)</p>
<p/>
</div>
<div class="page"><p/>
<p>8.1.4 Variables
</p>
<p>There are situations inside of processes in which it is desired for assignments to be made instanta-
</p>
<p>neously instead of when the process suspends. For these situations, VHDL provides the concept of a
</p>
<p>variable. A variable has the following characteristics:
</p>
<p>&bull; Variables only exist within a process.
</p>
<p>&bull; Variables are defined in a process before the begin statement.
</p>
<p>&bull; Once the process ends, variables are removed from the system. This means that assignments
to variables cannot be made by systems outside of the process.
</p>
<p>&bull; Assignments to variables are made using the &ldquo;:&frac14;&rdquo; operator.
</p>
<p>&bull; Assignments to variables are made instantaneously.
</p>
<p>A variable is declared before the begin statement in a process. The syntax for declaring a variable is
</p>
<p>as follows:
</p>
<p>variable variable_name : &lt;type&gt; :&frac14; &lt;initial_value&gt;;
</p>
<p>Let&rsquo;s reconsider the example in Example 8.1, but this time we&rsquo;ll use a variable in order to accomplish
</p>
<p>instantaneous signal assignments within the process. Example 8.3 shows this approach to model the
</p>
<p>behavior where F is the complement of A.
</p>
<p>Example 8.3
Variable Assignment Behavior
</p>
<p>8.1 The Process &bull; 269</p>
<p/>
</div>
<div class="page"><p/>
<p>CC8.1 If a model of a combinational logic circuit excludes one of its inputs from the sensitivity list, 
what is the implied behavior?
</p>
<p>A) A storage element because the output will be held at its last value when the 
unlisted input transitions.
</p>
<p>B) An infinite loop.
</p>
<p>C) A don&rsquo;t care will be used to form the minimal logic expression.
</p>
<p>D) Not applicable because this syntax will not compile.
</p>
<p>CONCEPT CHECK
</p>
<p>8.2 Conditional Programming Constructs
</p>
<p>One of the more powerful features that processes provide in VHDL is the ability to use conditional
</p>
<p>programming constructs such as if/then clauses, case statements, and loops. These constructs are only
</p>
<p>available within a process, but their use is not limited to modeling sequential logic. As we&rsquo;ll see, the
</p>
<p>characteristics of a process also support modeling of combinational logic circuits, so these conditional
</p>
<p>constructs are a very useful tool in VHDL. This provides the ability to model both combinational and
</p>
<p>sequential logic using the more familiar programming language constructs.
</p>
<p>8.2.1 If/Then Statements
</p>
<p>An if/then statement provides a way to make conditional signal assignments based on Boolean
</p>
<p>conditions. The if portion of statement is followed by a Boolean condition that if evaluated TRUE will
</p>
<p>cause the signal assignment after the then statement to be performed. If the Boolean condition is
</p>
<p>evaluated FALSE, no assignment is made. VHDL provides multiple variants of the if/then statement.
</p>
<p>An if/then/else statement provides a final signal assignment that will be made if the Boolean condition is
</p>
<p>evaluated false. An if/then/elsif statement allows multiple Boolean conditions to be used. The syntax for
</p>
<p>the various forms of the VHDL if/then statement is as follows:
</p>
<p>if boolean_condition then sequential_statement
end if;
</p>
<p>if boolean_condition then sequential_statement_1
else sequential_statement_2
end if;
</p>
<p>if boolean_condition_1 then sequential_statement_1
elsif boolean_condition_2 then sequential_statement_2
:
:
</p>
<p>elsif boolean_condition_n then sequential_statement_n
end if;
</p>
<p>if boolean_condition_1 then sequential_statement_1
elsif boolean_condition_2 then sequential_statement_2
:
:
</p>
<p>elsif boolean_condition_n then sequential_statement_n
else sequential_statement_n+1
end if;
</p>
<p>270 &bull; Chapter 8: VHDL (Part 2)</p>
<p/>
</div>
<div class="page"><p/>
<p>Let&rsquo;s take a look at using an if/then statement to describe the behavior of a combinational logic
</p>
<p>circuit. Recall that a combinational logic circuit is one in which the output depends on the instantaneous
</p>
<p>values of the inputs. This behavior can be modeled by placing all of the inputs to the circuit in the
</p>
<p>sensitivity list of a process. A change on any of the inputs in the sensitivity list will trigger the process and
</p>
<p>cause the output to be updated. Example 8.4 shows how to model a 3-input combinational logic circuit
</p>
<p>using if/then statements within a process.
</p>
<p>Example 8.4
Using If/Then Statements to Model Combinational Logic
</p>
<p>8.2 Conditional Programming Constructs &bull; 271</p>
<p/>
</div>
<div class="page"><p/>
<p>8.2.2 Case Statements
</p>
<p>A case statement is another technique to model signal assignments based on Boolean conditions.
</p>
<p>As with the if/then statement, a case statement can only be used inside of a process. The statement
</p>
<p>begins with the keyword case followed by the input signal name that assignments will be based off
</p>
<p>of. The input signal name can be optionally enclosed in parentheses for readability. The keywordwhen is
</p>
<p>used to specify a particular value (or choice) of the input signal that will result in associated sequential
</p>
<p>signal assignments. The assignments are listed after the &frac14;&gt; symbol. The following is the syntax for a
</p>
<p>case statement:
</p>
<p>case (input_name) is
when choice_1 &frac14;&gt; sequential_statement(s);
when choice_2 &frac14;&gt; sequential_statement(s);
</p>
<p>:
:
</p>
<p>when choice_n &frac14;&gt; sequential_statement(s);
end case;
</p>
<p>When not all of the possible input conditions (or choices) are specified, a when others clause is
</p>
<p>used to provide signal assignments for all other input conditions. The following is the syntax for a case
</p>
<p>statement that uses a when others clause:
</p>
<p>case (input_name) is
when choice_1 &frac14;&gt; sequential_statement(s);
when choice_2 &frac14;&gt; sequential_statement(s);
</p>
<p>:
:
</p>
<p>when others &frac14;&gt; sequential_statement(s);
end case;
</p>
<p>Multiple choices that correspond to the same signal assignments can be pipe delimited in the case
</p>
<p>statement. The following is the syntax for a case statement with pipe-delimited choices:
</p>
<p>case (input_name) is
when choice_1 | choice_2 &frac14;&gt; sequential_statement(s);
when others &frac14;&gt; sequential_statement(s);
</p>
<p>end case;
</p>
<p>The input signal for a case statement must be a single signal name. If multiple scalars are to be used
</p>
<p>as the input expression for a case statement, they should be concatenated either outside of the process
</p>
<p>resulting in a new signal vector or within the process resulting in a new variable vector. Example 8.5
</p>
<p>shows how to model a 3-input combinational logic circuit using case statements within a process.
</p>
<p>272 &bull; Chapter 8: VHDL (Part 2)</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 8.5
Using Case Statements to Model Combinational Logic
</p>
<p>If/then statements can be embedded within a case statement and, conversely, case statements can
</p>
<p>be embedded within an if/then statement.
</p>
<p>8.2.3 Infinite Loops
</p>
<p>A loopwithin VHDL provides a mechanism to perform repetitive assignments infinitely. This is useful
</p>
<p>in test benches for creating stimulus such as clocks or other periodic waveforms. A loop can only be used
</p>
<p>within a process. The keyword loop is used to signify the beginning of the loop. Sequential signal
</p>
<p>8.2 Conditional Programming Constructs &bull; 273</p>
<p/>
</div>
<div class="page"><p/>
<p>assignments are then inserted. The end of the loop is signified with the keywords end loop. Within the
</p>
<p>loop, the wait for, wait until, and after statements are all legal. Signal assignments within a loop will be
</p>
<p>executed repeatedly forever unless an exit or next statement is encountered. The exit clause provides a
</p>
<p>Boolean condition that will force the loop to end if the condition is evaluated true. When using the exit
</p>
<p>statement, an additional signal assignment is typically placed after the loop to provide the desired
</p>
<p>behavior when the loop is not active. Using flow control statements such as wait for and wait after
</p>
<p>provides a means to avoid having the loop immediately executed again after exiting. The next clause
</p>
<p>provides a way to skip the remaining signal assignments and begin the next iteration of the loop. The
</p>
<p>following is the syntax for an infinite loop in VHDL:
</p>
<p>loop
</p>
<p>exit when boolean_condition; -- optional exit statement
next when boolean_condition; -- optional next statement
sequential_statement(s);
</p>
<p>end loop;
</p>
<p>Consider the following example of an infinite loop that generates a clock signal (CLK) with a period
</p>
<p>of 100 ns. In this example, the process does not contain a sensitivity list, so a wait statement must be
</p>
<p>used to control the signal assignments. This process in this example will trigger immediately and then
</p>
<p>enter the infinite loop and never exit.
</p>
<p>Example:
</p>
<p>Clock_Proc1 : process
begin
loop
</p>
<p>CLK &lt;&frac14; not CLK;
wait for 50 ns;
</p>
<p>end loop;
end process;
</p>
<p>Now consider the following loop example that will generate a clock signal with a period of 100 ns with
</p>
<p>an enable (EN) line. This loop will produce a periodic clock signal as long as EN &frac14; 1. When EN &frac14; 0, the
</p>
<p>clock output will remain at CLK &frac14; 0. An exit condition is placed at the beginning of the loop to check if
</p>
<p>EN &frac14; 0. If this condition is true, the loop will exit and the clock signal will be assigned a 0. The process
</p>
<p>will then wait until EN &frac14; 1. Once EN &frac14; 1, the process will end and then immediately trigger again and
</p>
<p>reenter the loop. When EN &frac14; 1, the clock signal will be toggled (CLK &lt;&frac14; not CLK) and then wait for
</p>
<p>50 ns. This toggling behavior will repeat as long as EN &frac14; 1.
</p>
<p>Example:
</p>
<p>Clock_Proc2 : process
begin
loop
</p>
<p>exit when EN&frac14;&rsquo;0&rsquo;;
CLK &lt;&frac14; not CLK;
wait for 50 ns;
</p>
<p>end loop;
</p>
<p>CLK &lt;&frac14; &rsquo;0&rsquo;;
wait until EN&frac14;&rsquo;1&rsquo;;
</p>
<p>end process;
</p>
<p>It is important to keep in mind that infinite loops that continuously make signal assignments without
</p>
<p>the use of sensitivity lists or wait statements will cause logic simulators to hang.
</p>
<p>274 &bull; Chapter 8: VHDL (Part 2)</p>
<p/>
</div>
<div class="page"><p/>
<p>8.2.4 While Loops
</p>
<p>A while loop provides a looping structure with a Boolean condition that controls its execution. The
</p>
<p>loop will only execute as long as its condition is evaluated true. The following is the syntax for a VHDL
</p>
<p>while loop:
</p>
<p>while boolean_condition loop
sequential_statement(s);
</p>
<p>end loop;
</p>
<p>Let&rsquo;s implement the previous example of a loop that generates a clock signal (CLK) with a period of
</p>
<p>100 ns as long as EN &frac14; 1. The Boolean condition for the while loop is EN &frac14; 1. When EN &frac14; 1, the loop
</p>
<p>will be executed indefinitely. When EN &frac14; 0, the while loop will be skipped. In this case, an additional
</p>
<p>signal assignment is necessary to model the desired behavior when the loop is not used (i.e., CLK &frac14; 0).
</p>
<p>Example:
</p>
<p>Clock_Proc3 : process
begin
while (EN&frac14;&rsquo;1&rsquo;) loop
CLK &lt;&frac14; not CLK;
wait for 50 ns;
</p>
<p>end loop;
</p>
<p>CLK &lt;&frac14; &rsquo;0&rsquo;;
wait until EN&frac14;&rsquo;1&rsquo;;
</p>
<p>end process;
</p>
<p>8.2.5 For Loops
</p>
<p>A for loop provides the ability to create a loop that will execute a predefined number of times. The
</p>
<p>range of the loop is specified with integers (min, max) at the beginning of the for loop. A loop variable is
</p>
<p>implicitly declared in the loop that will increment (or decrement) from min to max of the range. The loop
</p>
<p>variable is of type integer. If it is desired to have the loop variable increment frommin to max, the keyword
</p>
<p>to is used when specifying the range of the loop. If it is desired to have the loop variable decrement max
</p>
<p>to min, the keyword downto is used when specifying the range of the loop. The loop variable can be
</p>
<p>used within the loop as an index for vectors; thus the for loop is useful for automatically accessing and
</p>
<p>assigning multiple signals within a single loop structure. The following is the syntax for a VHDL for loop in
</p>
<p>which the loop variable will increment from min to max of the range:
</p>
<p>for loop_variable in min to max loop
sequential_statement(s);
</p>
<p>end loop;
</p>
<p>The following is the syntax for a VHDL for loop in which the loop variable will decrement from max to
</p>
<p>min of the range:
</p>
<p>for loop_variable in max downto min loop
sequential_statement(s);
</p>
<p>end loop;
</p>
<p>For loops are useful for test benches in which a range of patterns are to be created. For loops are
</p>
<p>also synthesizable as long as the complete behavior of the desired system is described by the loop. The
</p>
<p>following is an example of creating a simple counter using the loop variable. The signal Count_Out in this
</p>
<p>example is of type integer. This allows the loop variable i to be assigned to Count_Out each time through
</p>
<p>the loop since the loop variable is also of type integer. This counter will count from 0 to 15 and then
</p>
<p>repeat. The count will increment every 50 ns.
</p>
<p>8.2 Conditional Programming Constructs &bull; 275</p>
<p/>
</div>
<div class="page"><p/>
<p>Example:
</p>
<p>Counter_Proc : process
begin
for i in 0 to 15 loop
Count_Out &lt;&frac14; i;
wait for 50 ns;
</p>
<p>end loop;
end process;
</p>
<p>CC8.2 When using an if/then statement to model a combinational logic circuit, is using the else
clause the same as using don&rsquo;t cares when minimizing a logic expression with a K-map?
</p>
<p>A) Yes.  The else clause allows the synthesizer to assign whatever output values 
are necessary in order to create the most minimal circuit.
</p>
<p>B) No.  The else clause explicitly states the output values for all input codes not 
listed in the if/elsif portion of the if/then construct.  This is the same as filling in 
the truth table with specific values for all input codes covered by the else clause 
and the synthesizer will create the logic expression accordingly. 
</p>
<p>CONCEPT CHECK
</p>
<p>8.3 Signal Attributes
</p>
<p>There are situations where we want to describe behavior that is based on more than just the current
</p>
<p>value of a signal. For example, a real D-flip-flop will only update its outputs on a particular type of
</p>
<p>transition (i.e., rising or falling). In order to model this behavior, we need to specify more information
</p>
<p>about the signal. This is accomplished by using attributes. Attributes provide additional information about
</p>
<p>a signal other than just its present value. An attribute can provide information such as past values,
</p>
<p>whether an assignment was made to a signal, or when the last time an assignment resulted in a value
</p>
<p>change. A signal attribute is implemented by placing an apostrophe (&rsquo;) after the signal name and then
</p>
<p>listing the VHDL attribute keyword. Different attributes will result in different output types. Attributes that
</p>
<p>yield Boolean output types can be used as inputs to Boolean decision conditions for other VHDL
</p>
<p>constructs. Other attributes can be used to define the range of new vectors by referencing the size of
</p>
<p>existing vectors or automatically defining the number of iterations in a loop. Finally, some attributes can
</p>
<p>be used to create self-checking test benches that monitor the impact of circuit delays on the functionality
</p>
<p>of a system. The following are a list of the commonly used, predefined VHDL signal attributes. The
</p>
<p>example signal name A is used to illustrate how scalar attributes operate. The example signal B is used
</p>
<p>to illustrate how vector attributes operate with type bit_vector (7 downto 0).
</p>
<p>Attribute Information returned Type returned
</p>
<p>A&rsquo;event True when signal A changes, false otherwise Boolean
</p>
<p>A&rsquo;active True when an assignment is made to A, false otherwise Boolean
</p>
<p>A&rsquo;last_event Time when signal A last changed Time
</p>
<p>A&rsquo;last_active Time when signal A was last assigned to Time
</p>
<p>A&rsquo;last_value The previous value of A Same type as A
</p>
<p>B&rsquo;length Size of the vector (e.g., 8) Integer
</p>
<p>B&rsquo;left Left bound of the vector (e.g., 7) Integer
</p>
<p>B&rsquo;right Right bound of the vector (e.g., 0) Integer
</p>
<p>B&rsquo;range Range of the vector &ldquo;(7 downto 0)&rdquo; String
</p>
<p>276 &bull; Chapter 8: VHDL (Part 2)</p>
<p/>
</div>
<div class="page"><p/>
<p>Signal attributes can be used to model edge-sensitive behavior. Let&rsquo;s look at the model for a simple
</p>
<p>D-flip-flop. A process is used to model the synchronous behavior of the D-flip-flop. The sensitivity list
</p>
<p>contains only the Clock input. The D input is not included in the sensitivity list because a change on D
</p>
<p>should not trigger the process. Attributes and logical operators are not allowed in the sensitivity list of a
</p>
<p>process. As a result, the process will trigger on every edge of the clock signal. Within the process, an
</p>
<p>if/then statement is used with the Boolean condition (Clock&rsquo;event and Clock&frac14;&lsquo;1&rsquo;) in order to make
</p>
<p>signal assignments only on a rising edge of the clock. The syntax for this Boolean condition is
</p>
<p>understood and is synthesizable by all CAD tools. An else clause is not included in the if/then statement.
</p>
<p>This implies that when there is not a rising edge, no assignments will be made to the outputs and they will
</p>
<p>simply hold their last value. Example 8.6 shows how to model a simple D-flip-flop using attributes. Note
</p>
<p>that this example does not model the reset behavior of a real D-flip-flop.
</p>
<p>Example 8.6
Behavioral Modeling of a Rising Edge-Triggered D-Flip-Flop Using Attributes
</p>
<p>CC8.3 If the D input to a D-flip-flop is tied to a 0, which of the following conditions will return true 
on every triggering edge of the clock?
</p>
<p>A) Q&rsquo;event and Q=&rsquo;0&rsquo;
</p>
<p>B) Q&rsquo;active and Q=&rsquo;0&rsquo;
</p>
<p>C) Q&rsquo;last_event=&lsquo;0&rsquo; and Q=&rsquo;0&rsquo;
</p>
<p>D) Q&rsquo;last_active=&rsquo;0&rsquo; and Q=&rsquo;0&rsquo;
</p>
<p>CONCEPT CHECK
</p>
<p>8.3 Signal Attributes &bull; 277</p>
<p/>
</div>
<div class="page"><p/>
<p>8.4 Test Benches
</p>
<p>The functional verification of VHDL designs is accomplished through simulation using a test bench.
</p>
<p>A test bench is a VHDL system that instantiates the system to be tested as a component and then
</p>
<p>generates the input patterns and observes the outputs. The system being tested is often called a device
</p>
<p>under test (DUT) or unit under test (UUT). Test benches are only used for simulation, so we can use
</p>
<p>abstract modeling techniques that are unsynthesizable to generate the stimulus patterns. VHDL also
</p>
<p>contains specific functionality to report on the status of a test and also automatically check that the
</p>
<p>outputs are correct. Example 8.7 shows how to create a simple test bench to verify the operation of
</p>
<p>SystemX. The test bench does not have any inputs or outputs; thus there are no ports declared in the
</p>
<p>entity. SystemX is declared as a component in the test bench and then instantiated (DUT1). Internal
</p>
<p>signals are declared to connect to the component under test (A_TB, B_TB, C_TB, F_TB). A process is
</p>
<p>then used to drive the inputs of SystemX. Within the process, wait statements are used to control the
</p>
<p>execution of the signal assignments; thus the process does not have a sensitivity list. Each possible input
</p>
<p>code is generated within the process. The output (F_TB) is observed using a simulation tool in either the
</p>
<p>form of a waveform or a table listing.
</p>
<p>278 &bull; Chapter 8: VHDL (Part 2)</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 8.7
Creating a VHDL Test Bench
</p>
<p>8.4.1 Report Statement
</p>
<p>The keyword report can be used within a test bench in order to provide the status of the current test.
</p>
<p>A report statement will print a string to the transcript window of the simulation tool. The report output also
</p>
<p>contains an optional severity level. There are four levels of severity (ERROR, WARNING, NOTE, and
</p>
<p>FAILURE). The severity level FAILURE will halt a simulation while the levels ERROR, WARNING, and
</p>
<p>NOTE will allow the simulation to continue. If the severity level is omitted, the report is assumed to be a
</p>
<p>severity level of NOTE. The syntax for using a report statement is as follows:
</p>
<p>report "string to be printed" severity &lt;level&gt;;
</p>
<p>8.4 Test Benches &bull; 279</p>
<p/>
</div>
<div class="page"><p/>
<p>Let&rsquo;s look at how we could use the report function within the example test bench to print the current
</p>
<p>value of the input pattern to the transcript window of the simulator. Example 8.8 shows the new process
</p>
<p>and resulting transcript output of the simulator when using report statements.
</p>
<p>Example 8.8
Using Report Statements in a VHDL Test Bench
</p>
<p>8.4.2 Assert Statement
</p>
<p>The assert statement provides a mechanism to check a Boolean condition before using the report
</p>
<p>statement. This allows report outputs to be selectively printed based on the values of signals in the
</p>
<p>system under test. This can be used to print either the successful operation or the failure of a system. If
</p>
<p>the Boolean condition associated with the assert statement is evaluated true, it will not execute the
</p>
<p>subsequent report statement. If the Boolean condition is evaluated false, it will execute the subsequent
</p>
<p>report statement. The assert statement is always used in conjunction with the report statement. The
</p>
<p>following is the syntax for the assert statement:
</p>
<p>assert boolean_condition report "string" severity &lt;level&gt;;
</p>
<p>280 &bull; Chapter 8: VHDL (Part 2)</p>
<p/>
</div>
<div class="page"><p/>
<p>Let&rsquo;s look at how we could use the assert function within the example test bench to check whether
</p>
<p>the output (F_TB) is correct. In the example in Example 8.9, the system passes the first pattern but fails
</p>
<p>the second.
</p>
<p>Example 8.9
Using Assert Statements in a VHDL Test Bench
</p>
<p>CC8.4 Could a test bench ever use sensitivity lists exclusively to create its stimulus?  Why or why 
not?
</p>
<p>A) Yes.  The signal assignments will simply be made when the process ends.
</p>
<p>B) No.  Since a sensitivity list triggers when there is a change on one or more of the 
signals listed, the processes in the test bench would never trigger because there 
is no method to make the initial signal transition.
</p>
<p>CONCEPT CHECK
</p>
<p>8.5 Packages
</p>
<p>One of the drawbacks of the VHDL standard package is that it provides limited functionality in its
</p>
<p>synthesizable data types. The bit and bit_vector, while synthesizable, lack the ability to accurately model
</p>
<p>many of the topologies implemented in modern digital systems. Of primary interest are topologies that
</p>
<p>involve multiple drivers connected to a single wire. The standard package will not permit this type of
</p>
<p>connection; however, this type of topology is a common way to interface multiple nodes on a shared
</p>
<p>interconnection. Furthermore, the standard package does not provide many useful features for these
</p>
<p>8.5 Packages &bull; 281</p>
<p/>
</div>
<div class="page"><p/>
<p>types, such as don&rsquo;t cares, arithmetic using the + and � operators, type conversion functions, or the
</p>
<p>ability to read/write external files. To increase the functionality of VHDL, packages are included in the
</p>
<p>design.
</p>
<p>8.5.1 STD_LOGIC_1164
</p>
<p>In the late 1980s, the IEEE 1164 standard was released that added functionality to VHDL to allow a
</p>
<p>multi-valued logic system (i.e., a signal can take on more values than just 0 and 1). This standard also
</p>
<p>provided a mechanism for multiple drivers to be connected to the same signal. An updated release in
</p>
<p>1993 called IEEE 1164-1993 was the most significant update to this standard and contains the majority
</p>
<p>of functionality used in VHDL today. Nearly all systems described in VHDL include the 1164 standard as
</p>
<p>a package. This package is included by adding the following syntax at the beginning of the VHDL file:
</p>
<p>library IEEE;
use IEEE.std_logic_1164.all;
</p>
<p>This package defines four new data types: std_ulogic, std_ulogic_vector, std_logic, and
</p>
<p>std_logic_vector. The std_ulogic and std_logic are enumerated, scalar types that can provide a
</p>
<p>multi-valued logic system. The types std_ulogic_vector and std_logic_vector are vector types containing
</p>
<p>a linear array of scalar types std_ulogic and std_logic, respectively. The scalar types can take on nine
</p>
<p>different values as described below:
</p>
<p>Value Description Notes
</p>
<p>U Uninitialized Default initial value
</p>
<p>X Forcing unknown
</p>
<p>0 Forcing 0
</p>
<p>1 Forcing 1
</p>
<p>Z High impedance
</p>
<p>W Weak unknown
</p>
<p>L Weak 0 Pull-down
</p>
<p>H Weak 1 Pull-up
</p>
<p>&ndash; Don&rsquo;t care Used for synthesis only
</p>
<p>These values can be assigned to signals by enclosing them in single quotes (scalars) or double
</p>
<p>quotes (vectors).
</p>
<p>Example:
</p>
<p>A &lt;&frac14; &rsquo;X&rsquo;; -- assignment to a scalar (std_ulogic or std_logic)
V &lt;&frac14; "01ZH"; -- assignment to a 4-bit vector (std_ulogic_vector or
</p>
<p>-- std_logic_vector)
</p>
<p>The type std_ulogic is unresolved (note: the &ldquo;u&rdquo; standard for &ldquo;unresolved&rdquo;). This means that if a
</p>
<p>signal is being driven by two circuits with type std_ulogic, the VHDL simulator will not be able to resolve
</p>
<p>the conflict and it will result in a compiler error. The std_logic type is resolved. This means that if a signal
</p>
<p>is being driven by two circuits with type std_logic, the VHDL simulator will be able to resolve the conflict
</p>
<p>and will allow the simulation to continue. Figure 8.1 shows an example of a shared signal topology and
</p>
<p>how conflicts are handled when using various data types.
</p>
<p>282 &bull; Chapter 8: VHDL (Part 2)</p>
<p/>
</div>
<div class="page"><p/>
<p>8.5.1.1 STD_LOGIC Resolution Function
</p>
<p>The std_logic_1164 will resolve signal conflict of type std_logic using a resolution function. The
</p>
<p>nine allowed values each has a relative drive strength that allows a resolution to be made in the event of
</p>
<p>conflict. Whenever there is a conflict, the simulator will consult the resolution function to determine the
</p>
<p>value of the signal. Figure 8.2 shows the relative drive strengths of the nine possible signal values
</p>
<p>provided by the std_logic_1164 package and the resolution function table.
</p>
<p>Fig. 8.1
STD_LOGIC_1164 unresolved vs. resolved conflict handling
</p>
<p>8.5 Packages &bull; 283</p>
<p/>
</div>
<div class="page"><p/>
<p>8.5.1.2 STD_LOGIC_1164 Logical Operators
</p>
<p>The std_logic_1164 also contains new definitions for all of the logical operators (and, nand, or, nor,
</p>
<p>xor, xnor, not) for types std_ulogic and std_logic. These are required since these data types can take on
</p>
<p>more logic values than just a 0 or 1; thus the logical operator definitions from the standard package are
</p>
<p>not sufficient.
</p>
<p>8.5.1.3 STD_LOGIC_1164 Edge Detection Functions
</p>
<p>The std_logic_1164 also provides functions for the detection of rising or falling transitions on a
</p>
<p>signal. The functions rising_edge() and falling_edge() provide a more readable form of this functionality
</p>
<p>compared to the (Clock&rsquo;event and Clock &frac14; &ldquo;1&rdquo;) approach. Example 8.10 shows the use of the
</p>
<p>rising_edge() function to model the behavior of a rising edge-triggered D-flip-flop.
</p>
<p>Fig. 8.2
STD_LOGIC_1164 resolution function
</p>
<p>284 &bull; Chapter 8: VHDL (Part 2)</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 8.10
Behavioral Modeling of a D-Flip-Flop Using the rising_edge() Function
</p>
<p>8.5.1.4 STD_LOGIC-Type Conversion Functions
</p>
<p>The std_logic_1164 package also provides functions to convert between data types. Functions exist
</p>
<p>to convert between bit, std_ulogic, and std_logic. Functions also exist to convert between these types&rsquo;
</p>
<p>vector forms (bit_vector, std_ulogic_vector, and std_logic_vector). The functions are listed below.
</p>
<p>Name Input type Return type
</p>
<p>To_bit() std_ulogic bit
</p>
<p>To_bitvector() std_ulogic_vector bit_vector
</p>
<p>To_bitvector() std_logic_vector bit_vector
</p>
<p>To_StdULogic() bit std_ulogic
</p>
<p>To_StdULogicVector() bit_vector std_ulogic_vector
</p>
<p>To_StdULogicVector() std_logic_vector std_ulogic_vector
</p>
<p>To_StdLogicVector() bit_vector std_logic_vector
</p>
<p>To_StdLogicVector() std_ulogic_vector std_logic_vector
</p>
<p>When using these functions, the function name and input signal are placed to the right of the
</p>
<p>assignment operator and the target signal is placed on the left.
</p>
<p>8.5 Packages &bull; 285</p>
<p/>
</div>
<div class="page"><p/>
<p>Example:
</p>
<p>A &lt;&frac14; To_bit(B); -- B is type std_ulogic, A is type bit
V &lt;&frac14; To_StdLogicVector(C); -- C is type bit_vector, V is std_logic_vector
</p>
<p>When identical function names exist that can have different input data types, the VHDL compiler will
</p>
<p>automatically decide which function to use based on the input argument type. For example, the function
</p>
<p>&ldquo;To_bitvector&rdquo; exists for an input of std_ulogic_vector and std_logic_vector. When using this function, the
</p>
<p>compiler will automatically detect which input type is being used and select the corresponding function
</p>
<p>variant. No additional syntax is required by the designer in this situation.
</p>
<p>8.5.2 NUMERIC_STD
</p>
<p>The numeric_std package provides numerical computation for types std_logic and std_logic_vector.
</p>
<p>When performing binary arithmetic, the results of arithmetic operations and comparisons vary greatly
</p>
<p>depending on whether the binary number is unsigned or signed. As a result, the numeric_std package
</p>
<p>defines two new data types, unsigned and signed. An unsigned type is defined to have its MSB in the
</p>
<p>leftmost position of the vector, and the LSB in the rightmost position of the vector. A signed number uses
</p>
<p>two&rsquo;s complement representation with the leftmost bit of the vector being the sign bit. When declaring a
</p>
<p>signal to be one of these types, it is implied that these represent the encoding of an underlying native type
</p>
<p>of std_logic/std_logic_vector. The use of unsigned/signed types provides the interpretation of how
</p>
<p>arithmetic, logical, and comparison operators will perform. This also implies that the numeric_std
</p>
<p>package requires the std_logic_1164 to always be included. While the numeric_std package includes
</p>
<p>an inclusion call of the std_logic_1164 package, it is common to explicitly include both the
</p>
<p>std_logic_1164 and the numeric_std packages in the main VHDL file. The VHDL compiler will ignore
</p>
<p>redundant package statements. The syntax for including these packages is as follows:
</p>
<p>library IEEE;
use IEEE.std_logic_1164.all; -- defines types std_ulogic and std_logic
use IEEE.numeric_std.all; -- defines types unsigned and signed
</p>
<p>8.5.2.1 NUMERIC_STD Arithmetic Functions
</p>
<p>The numeric_std package provides support for a variety of arithmetic functions for the types
</p>
<p>unsigned and signed. These include +,�, *, /,mod, rem, and abs functions. These arithmetic operations
</p>
<p>behave differently for the unsigned versus signed types, but the VHDL compiler will automatically use the
</p>
<p>correct operation based on the types of the input arguments.
</p>
<p>Most synthesis tools support the addition, subtraction, and multiplication operators in this package.
</p>
<p>This provides a higher level of abstraction when modeling arithmetic circuitry. Recall that the VHDL
</p>
<p>standard package does not support addition, subtraction, and multiplication of types bit/bit_vector using
</p>
<p>the +, �, and * operators. Using the numeric_std package gives the ability to model these arithmetic
</p>
<p>operations with a synthesizable data type using the more familiar mathematical operators. The division,
</p>
<p>modulo, remainder, and absolute value functions are not synthesizable directly from this package.
</p>
<p>Example:
</p>
<p>F &lt;&frac14; A + B; -- A, B, F are type unsigned(3 downto 0)
F &lt;&frac14; A - B;
</p>
<p>8.5.2.2 NUMERIC_STD Logical Functions
</p>
<p>The numeric_std package provides support for all of the logical operators (and, nand, or, nor, xor,
</p>
<p>xnor, not) for types unsigned and signed. It also provides two new shift functions shift_left() and
</p>
<p>286 &bull; Chapter 8: VHDL (Part 2)</p>
<p/>
</div>
<div class="page"><p/>
<p>shift_right(). These shift functions will fill the vacant position in the vector after the shift with a 0; thus
</p>
<p>these are logical shifts. This package also provides two new rotate functions rotate_left() and
</p>
<p>rotate_right().
</p>
<p>8.5.2.3 NUMERIC_STD Comparison Functions
</p>
<p>The numeric_std package provides support for all of the comparison functions for types unsigned
</p>
<p>and signed. These include &gt;, &lt;, &lt;&frac14;, &gt;&frac14;, &frac14;, and /&frac14;. These comparisons return type Boolean.
</p>
<p>Example: (A &frac14; &ldquo;0000&rdquo;, B &frac14; &ldquo;1111&rdquo;)
</p>
<p>if (A &lt; B) then -- This condition is TRUE if A and B are UNSIGNED
:
</p>
<p>if (A &lt; B) then -- This condition is FALSE if A and B are SIGNED
</p>
<p>8.5.2.4 NUMERIC_STD Edge Detection Functions
</p>
<p>The numeric_std also provides the functions rising_edge() and falling_edge() for the detection of
</p>
<p>rising or falling edge transition detection for types unsigned and signed.
</p>
<p>8.5.2.5 NUMERIC_STD Conversion Functions
</p>
<p>The numeric_std package contains a variety of useful conversion functions. Of particular usefulness
</p>
<p>are functions between the type integer and to/from unsigned/signed. This allows behavioral models for
</p>
<p>counters, adders, and subtractors to be implemented using the more readable type integer. After the
</p>
<p>functionally has been described, a conversion can be used to turn the result into types unsigned or
</p>
<p>signed to provide a synthesizable output. When converting an integer to a vector, a size argument is
</p>
<p>included. The size argument is of type integer and provides the number of bits in the vector that the
</p>
<p>integer will be converted to:
</p>
<p>Name Input type Return type
</p>
<p>To_integer() Unsigned Integer
</p>
<p>To_integer() Signed Integer
</p>
<p>To_unsigned() integer, &lt;size&gt; Unsigned (size-1 downto 0)
</p>
<p>To_signed() Integer, &lt;size&gt; Signed (size-1 downto 0)
</p>
<p>8.5.2.6 NUMERIC_STD Type Casting
</p>
<p>VHDL contains a set of built-in type casting operations that are commonly used with the numeric_std
</p>
<p>package to convert between std_logic_vector and unsigned/signed. Since the types unsigned/signed
</p>
<p>are based on the underlying type std_logic_vector, the conversion is simply known as casting. The
</p>
<p>following are the built-in type casting capabilities in VHDL.:
</p>
<p>Name Input type Return type
</p>
<p>std_logic_vector() Unsigned std_logic_vector
</p>
<p>std_logic_vector() Signed std_logic_vector
</p>
<p>unsigned() std_logic_vector Unsigned
</p>
<p>signed() std_logic_vector Signed
</p>
<p>When using these type casts, they are placed on the right-hand side of the assignment exactly as a
</p>
<p>conversion function.
</p>
<p>8.5 Packages &bull; 287</p>
<p/>
</div>
<div class="page"><p/>
<p>Example:
</p>
<p>A &lt;&frac14; std_logic_vector(B); -- B is unsigned, A is std_logic_vector
C &lt;&frac14; unsigned(D); -- D is std_logic_vector, C is unsigned
</p>
<p>Type casts and conversion functions can be compounded in order to perform multiple conversions
</p>
<p>in one assignment. This is useful when converting between types that do not have a direct cast or
</p>
<p>conversion function. Let&rsquo;s look at the example of converting an integer to an 8-bit std_logic_vector where
</p>
<p>the number being represented is unsigned. The first step is to convert the integer to an unsigned type.
</p>
<p>This can be accomplished with the to_unsigned function defined in the numeric_std package. This can
</p>
<p>be embedded in a second cast from unsigned to std_logic_vector. In the following example, E is the
</p>
<p>target of the operation and is of type std_logic vector. F is the argument of assignment and is of type
</p>
<p>integer. Recall that the to_unsigned conversions require both the input integer name and the size of the
</p>
<p>unsigned vector being converted to.
</p>
<p>Example:
</p>
<p>E &lt;&frac14; std_logic_vector(to_unsigned(F, 8));
</p>
<p>8.5.3 NUMERIC_STD_UNSIGNED
</p>
<p>When using the numeric_std package, the data types unsigned and signed must be used in order to
</p>
<p>get access to the numeric operators. While this provides ultimate control over the behavior of the signal
</p>
<p>operations and comparisons, many designs may only use unsigned types. In order to provide a
</p>
<p>mechanism to treat all vectors as unsigned while leaving their type as std_logic_vector, the numeric_st-
</p>
<p>d_unsigned package was created. When this package is used, it will treat all std_logic_vectors in the
</p>
<p>design as unsigned. This package requires the std_logic_1164 and numeric_std packages to be
</p>
<p>previously included. When used, all signals and ports can be declared as std_logic/std_logic_vector
</p>
<p>and they will be treated as unsigned when performing arithmetic operations and comparisons. The
</p>
<p>following is an example of how to include this package:
</p>
<p>library IEEE;
use IEEE.std_logic_1164.all;
use IEEE.numeric_std.all;
use IEEE.numeric_std_unsigned.all;
</p>
<p>8.5.3.1 NUMERIC_STD_UNSIGNED Conversion Functions
</p>
<p>The numeric_std_unsigned package contains a fewmore type conversions beyond the numeric_std
</p>
<p>package. These additional conversions are as follows:
</p>
<p>Name Input type Return type
</p>
<p>To_Integer std_logic_vector Integer
</p>
<p>To_StdLogicVector Unsigned std_logic_vector
</p>
<p>8.5.4 NUMERIC_BIT
</p>
<p>The numeric_bit package provides numerical computation for types bit and bit_vector. Since the
</p>
<p>vast majority of VHDL designs today use types std_logic/std_logic_vector instead of bit/bit_vector, this
</p>
<p>package is rarely used. This package is included by adding the following syntax at the beginning of the
</p>
<p>VHDL file in the design:
</p>
<p>288 &bull; Chapter 8: VHDL (Part 2)</p>
<p/>
</div>
<div class="page"><p/>
<p>library IEEE;
use IEEE.numeric_bit.all; -- defines types unsigned and signed
</p>
<p>The numeric_bit package is nearly identical to numeric_std. It defines data types unsigned and
</p>
<p>signed, which provide information on the encoding style of the underlying data types bit and bit_vector.
</p>
<p>All of the arithmetic, logical, and comparison functions defined in numeric_std are supported in
</p>
<p>numeric_bit (+, �, *, /, mod, rem, abs, and, nand, or, nor, xor, xnor, not, &gt;, &lt;, &lt;&frac14;, &gt;&frac14;, &frac14;, /&frac14;) for
</p>
<p>types unsigned and signed. This package also provides the same edge detection (rising_edge(),
</p>
<p>falling_edge()), shift (shift_left(), shift_right()), and rotate (rotate_left(), rotate_right()) functions for
</p>
<p>types unsigned and signed.
</p>
<p>The primary difference between numeric_bit and numeric_std is that numeric_bit also provides
</p>
<p>support for the shift/rotate operators from the standard package (sll, srl, rol, ror). Also, the conversion
</p>
<p>functions are defined only for conversions between integer, unsigned, and signed.
</p>
<p>Name Input type Return type
</p>
<p>To_integer Unsigned Integer
</p>
<p>To_integer Signed Integer
</p>
<p>To_unsigned Integer, &lt;size&gt; Unsigned (size-1 downto 0)
</p>
<p>To_signed Integer, &lt;size&gt; Signed (size-1 downto 0)
</p>
<p>8.5.5 NUMERIC_BIT_UNSIGNED
</p>
<p>The numeric_bit_unsigned package provides a way to treat all bit/bit_vectors in a design as
</p>
<p>unsigned numbers. The syntax for including the numeric_bit_unsigned package is shown below. In
</p>
<p>this example, all bit/bit_vectors will be treated as unsigned numbers for all arithmetic operations and
</p>
<p>comparisons:
</p>
<p>library IEEE;
use IEEE.numeric_bit.all;
use IEEE.numeric_bit_unsigned.all;
</p>
<p>8.5.5.1 NUMERIC_BIT_UNSIGNED Conversion Functions
</p>
<p>The numeric_bit_unsigned package contains a few more type conversions beyond the numeric_bit
</p>
<p>package. These additional conversions are as follows:
</p>
<p>Name Input type Return type
</p>
<p>To_integer std_logic_vector Integer
</p>
<p>To_BitVector Unsigned bit_vector
</p>
<p>8.5.6 MATH_REAL
</p>
<p>Themath_real package provides numerical computation for the type real. The type real is the VHDL
</p>
<p>type used to describe a 32-bit floating point number. None of the operators provided in the math_real
</p>
<p>package are synthesizable. This package is primarily used for test benches. This package is included by
</p>
<p>adding the following syntax at the beginning of the VHDL file in the design:
</p>
<p>library IEEE;
use IEEE.math_real.all;
</p>
<p>8.5 Packages &bull; 289</p>
<p/>
</div>
<div class="page"><p/>
<p>The math_real package defines a set of commonly used constants, which are shown below.
</p>
<p>Constant name Type Value Description
</p>
<p>MATH_E Real 2.718 Value of e
</p>
<p>MATH_1_E Real 0.367 Value of 1/e
</p>
<p>MATH_PI Real 3.141 Value of pi
</p>
<p>MATH_1_PI Real 0.318 Value of 1/pi
</p>
<p>MATH_LOG_OF_2 Real 0.693 Natural log of 2
</p>
<p>MATH_LOG_OF_10 Real 2.302 Natural log of10
</p>
<p>MATH_LOG2_OF_E Real 1.442 log base 2 of e
</p>
<p>MATH_LOG10_OF_E Real 0.434 log base 10 of e
</p>
<p>MATH_SQRT2 Real 1.414 sqrt of 2
</p>
<p>MATH_SQRT1_2 Real 0.707 sqrt of 1/2
</p>
<p>MATH_SQRT_PI Real 1.772 sqrt of pi
</p>
<p>MATH_DEG_TO_RAD Real 0.017 Conversion factor from degree to radian
</p>
<p>MATH_RAD_TO_DEG Real 57.295 Conversion factor from radian to degree
</p>
<p>Only three digits of accuracy are shown in this table; however, the constants defined in the
</p>
<p>math_real package have full 32-bit accuracy. The math_real package provides a set of commonly
</p>
<p>used floating point operators for the type real.
</p>
<p>Function name Return type Description
</p>
<p>SIGN Real Returns sign of input
</p>
<p>CEIL Real Returns smallest integer value
</p>
<p>FLOOR Real Returns largest integer value
</p>
<p>ROUND Real Rounds input up/down to whole number
</p>
<p>FMAX Real Returns largest of two inputs
</p>
<p>FMIN Real Returns smallest of two inputs
</p>
<p>SQRT Real Returns square root of input
</p>
<p>CBRT Real Returns cube root of input
</p>
<p>** Real Raise to power of (X**Y)
</p>
<p>EXP Real eX
</p>
<p>LOG Real log(X)
</p>
<p>SIN Real sin(X)
</p>
<p>COS Real cos(X)
</p>
<p>TAN Real tan(X)
</p>
<p>ASIN Real asin(X)
</p>
<p>ACOS Real acos(X)
</p>
<p>ATAN Real atan(X)
</p>
<p>ATAN2 Real atan(X/Y)
</p>
<p>SINH Real sinh(X)
</p>
<p>COSH Real cosh(X)
</p>
<p>TANH Real tanh(X)
</p>
<p>ASINH Real asinh(X)
</p>
<p>ACOSH Real acosh(X)
</p>
<p>ATANH Real atanh(X)
</p>
<p>290 &bull; Chapter 8: VHDL (Part 2)</p>
<p/>
</div>
<div class="page"><p/>
<p>8.5.7 MATH_COMPLEX
</p>
<p>The math_complex package provides numerical computation for complex numbers. Again, nothing
</p>
<p>in this package is synthesizable and is typically used only for test benches. This package is included by
</p>
<p>adding the following syntax at the beginning of the VHDL file in the design:
</p>
<p>library IEEE;
use IEEE.math_complex.all;
</p>
<p>This package defines three new data types, complex, complex_vector, and complex_polar. The
</p>
<p>type complex is defined with two fields, real and imaginary. The type complex_vector is a linear array of
</p>
<p>type complex. The type complex_polar is defined with two fields, magnitude and angle. This package
</p>
<p>provides a set of common operations for use with complex numbers. This package also supports the
</p>
<p>arithmetic operators +, �, *, and / for the type complex.
</p>
<p>Function name Return type Description
</p>
<p>CABS Real Absolute value of complex number
</p>
<p>CARG Real (radians) Returns angle of complex number
</p>
<p>CMPLX Complex Returns complex number form of input
</p>
<p>CONJ Complex or complex_polar Returns complex conjugate
</p>
<p>CSQRT Real Returns square root
</p>
<p>CEXP Real Returns eZ of complex input
</p>
<p>COMPLEX_TO_POLAR complex_polar Convert complex to complex_polar
</p>
<p>POLAR_TO_COMPLEX Complex Convert complex_polar to complex
</p>
<p>8.5.8 TEXTIO and STD_LOGIC_TEXTIO
</p>
<p>The textio package provides the ability to read and write to/from external input/output (I/O). External
</p>
<p>I/O refers to items such as files or the standard input/output of a computer. This package contains
</p>
<p>functions that allow the values of signals and variables to be read and written in addition to strings. This
</p>
<p>allowsmore sophisticated output messages to be created compared to the report statement alone, which
</p>
<p>can only output strings. The ability to read in values from a file allows sophisticated test patterns to be
</p>
<p>created outside of VHDL and then read in during simulation for testing a system. It is important to keep in
</p>
<p>mind that the term &ldquo;I/O&rdquo; refers to external files or the transcript window, not the inputs and outputs of a
</p>
<p>system model. The textio package is not synthesizable and is only used in test benches. The textio
</p>
<p>package is within the STD library and is included in a VHDL design using the following syntax:
</p>
<p>library STD;
use STD.textio.all;
</p>
<p>This package by itself only supports reading and writing types bit, bit_vector, integer, character, and
</p>
<p>string. Since the majority of synthesizable designs use types std_logic and std_logic_vector, an addi-
</p>
<p>tional package was created that added support for these types. The package is called std_logic_textio
</p>
<p>and is located within the IEEE library. The syntax for including this package is below:
</p>
<p>library IEEE;
use IEEE.std_logic_textio.all;
</p>
<p>The textio package defines two new types for interfacing with external I/O. These types are file and
</p>
<p>line. The type file is used to identify or create a file for reading/writing within the VHDL design. The syntax
</p>
<p>for declaring a file is as follows:
</p>
<p>file file_handle : &lt;file_type&gt; open &lt;file_mode&gt; is &lt;"filename"&gt;;
</p>
<p>8.5 Packages &bull; 291</p>
<p/>
</div>
<div class="page"><p/>
<p>Declaring a file will automatically open the file and keep it open until the end of the process that is
</p>
<p>using it. The file_handle is a unique identifier for the file that is used in subsequent procedures. The file
</p>
<p>handle name is user defined. A file handle eliminates the need to specify the entire file name each time a
</p>
<p>file access procedure is called. The file_type describes the information within the file. There are two
</p>
<p>supported file types, TEXT and INTF. A TEXT file is one that contains strings of characters. This is the
</p>
<p>most common type of file used as there are functions that can convert between types string, bit/bit_vector
</p>
<p>and std_logic/std_logic_vector. This allows all of the information in the file to be stored as characters,
</p>
<p>which makes the file readable by other programs. An INTF file type contains only integer values and the
</p>
<p>information is stored as a 32-bit, signed binary number. The file_mode describes whether the file will be
</p>
<p>read from or written to. There are two supported modes, WRITE_MODE and READ_MODE. The
</p>
<p>filename is given within double quotes and is user defined. It is common to enter an extension on the
</p>
<p>file so that it can be opened by other programs (e.g., output.txt). Declaring a file always takes place within
</p>
<p>a process before the process begins statement. The following are examples of how to declare files.:
</p>
<p>file Fout: TEXT open WRITE_MODE is "output_file.txt";
file Fin: TEXT open READ_MODE is "input_file.txt";
</p>
<p>The information within a file is accessed (either read or written) using the concept of a line. In the
</p>
<p>textio package, a file is interpreted as a sequence of lines, each containing either a string of characters or
</p>
<p>an integer value. The type line is used as a temporary buffer when accessing a line within the file. When
</p>
<p>accessing a file, a variable is created of type line. This variable is then used to either hold information that
</p>
<p>is read from a line in the file or to hold the information that is to be written to a line in the file. A variable is
</p>
<p>necessary for this behavior since assignments to/from the file must be made immediately. As such, a line
</p>
<p>variable is always declared within a process before the process begins statement. The syntax for
</p>
<p>declaring a variable of type line is as follows:
</p>
<p>variable &lt;line_variable_name&gt; : line;
</p>
<p>There are two procedures that allow information to be transferred between a line variable in VHDL
</p>
<p>and a line in a file. These procedures are readline() and writeline(). Their syntax is as follows:
</p>
<p>readline(&lt;file_handle&gt;, &lt;line_variable_name&gt;);
writeline(&lt;file_handle&gt;, &lt;line_variable_name&gt;);
</p>
<p>The transfer of information between a line variable and a line in a file using these procedures is
</p>
<p>accomplished on the entire line. There is no mechanism to read or write only a portion of the line in a file.
</p>
<p>Once a file is opened/created using a file declaration, the lines are accessed in the order they appear in
</p>
<p>the file. The first procedure called (either readline() or writeline()) will access the first line of the file. The
</p>
<p>next time a procedure is called, it will access the second line of the file. This will continue until all of the
</p>
<p>lines have been accessed. The textio package provides a function to indicate when the end of the file has
</p>
<p>been reached when performing a readline(). This function is called endfile() and returns type Boolean.
</p>
<p>This function will return true once the end of the file has been reached. Figure 8.3 shows a graphical
</p>
<p>representation of how the textio package handles external file access.
</p>
<p>292 &bull; Chapter 8: VHDL (Part 2)</p>
<p/>
</div>
<div class="page"><p/>
<p>Two additional procedures are provided to add or retrieve information to/from the line variable within
</p>
<p>the VHDL test bench. These procedures are read() and write(). The syntax for these procedures is as
</p>
<p>follows:
</p>
<p>read(&lt;line_variable_name&gt;, &lt;destination_variable&gt;);
write(&lt;line_variable_name&gt;, &lt;source_variable&gt;);
</p>
<p>When using the read() procedure, the information in the line variable is treated as space delimited.
</p>
<p>This means that each read() procedure will retrieve the information from the line variable until it reaches a
</p>
<p>white space. This allows multiple read() procedures to be used in order to parse the information into
</p>
<p>separate destination_variable names. The destination_variable must be of the appropriate type and size
</p>
<p>of the information being read from the file. For example, if the field in the line being read is a four-
</p>
<p>character string (&ldquo;wxyz&rdquo;), then a destination variable must be defined of type string(1 to 4). If the field
</p>
<p>being read is a 2-bit std_logic_vector, then a destination variable must be defined of type
</p>
<p>std_logic_vector(1 downto 0). The read() procedure will ignore the delimiting white space character.
</p>
<p>When using the write() procedure, the source_destination is assumed to be of type bit, bit_vector,
</p>
<p>integer, std_logic, or std_logic_vector. If it is desired to enter a text string directly, then the function string
</p>
<p>is used with the format string&rsquo;&lt;&ldquo;characters. . .&rdquo;&gt;. Multiple write() procedures can be used to insert
</p>
<p>information into the line variable. Each subsequent write procedure appends the information to the
</p>
<p>end of the string. This allows different types of information to be interleaved (e.g., text, signal value, text).
</p>
<p>Fig. 8.3
IEEE.textio package interpretation of files
</p>
<p>8.5 Packages &bull; 293</p>
<p/>
</div>
<div class="page"><p/>
<p>8.5.8.1 Example: Writing to an External File from a Test Bench
</p>
<p>Let&rsquo;s look at an example of a test bench that writes information about the tests being conducted to an
</p>
<p>external file. Example 8.11 shows the model for the system to be tested (SystemX) and an overview of
</p>
<p>the test bench approach (SystemX_TB).
</p>
<p>Example 8.11
Writing to an External File from a Test Bench (Part 1)
</p>
<p>Example 8.12 shows the details of the test bench model. In this test bench, a file is declared in order
</p>
<p>to create &ldquo;output_file.txt&rdquo;. This file is given the handle Fout. A line variable is also declared called
</p>
<p>current_line to act as a temporary buffer to hold information that will be written to the file. The procedure
</p>
<p>write() is used to add information to the line variable. The first write() procedure is used to create a text
</p>
<p>message (&ldquo;Beginning Test. . .&rdquo;). Notice that since the information to be written to the line variable is of type
</p>
<p>string, a conversion function must be used within the write() procedure (e.g.,. string&rsquo;(Beginning Test. . .&rdquo;).
</p>
<p>This message is written as the first line in the file using the writeline() procedure. After an input vector has
</p>
<p>been applied to the DUT, a new line is constructed containing descriptive text, the input vector value, and
</p>
<p>the output value from the DUT. This message is repeated for each input code in the test bench.
</p>
<p>294 &bull; Chapter 8: VHDL (Part 2)</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 8.12
Writing to an External File from a Test Bench (Part 2)
</p>
<p>8.5 Packages &bull; 295</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 8.13 shows the resulting file that is created from this test bench.
</p>
<p>Example 8.13
Writing to an External File from a Test Bench (Part 3)
</p>
<p>8.5.8.2 Example: Writing to STD_OUTPUT from a Test Bench
</p>
<p>The textio package also provides the ability to write to the standard output of the computer instead of
</p>
<p>to an external file. The standard output of the computer is typically routed to the transcript window of the
</p>
<p>simulator. This is accomplished by using a reserved file handle called OUTPUT. When using this file
</p>
<p>handle, a new file does not need to be declared in the test bench since it is already defined as part of the
</p>
<p>textio package. The reserved file handle name OUTPUTcan be used directly in the writeline() procedure.
</p>
<p>Let&rsquo;s look at an example of a test bench that outputs information about the test being conducted to
</p>
<p>STD_OUT. Example 8.14 shows this test bench approach. The test bench is identical as the one used in
</p>
<p>Example 8.12 with the exception that the writeline() procedure outputs are directed to the STD_OUTPUT
</p>
<p>of the computer using the reserved file handle name OUTPUT instead of to an external file.
</p>
<p>296 &bull; Chapter 8: VHDL (Part 2)</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 8.14
Writing to STD_OUT from a Test Bench (Part 1)
</p>
<p>Example 8.15 shows the output from the test bench. This output is displayed in the transcript
</p>
<p>window of the simulation tool.
</p>
<p>8.5 Packages &bull; 297</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 8.15
Writing to STD_OUT from a Test Bench (Part 2)
</p>
<p>8.5.8.3 Example: Reading from an External File in a Test Bench
</p>
<p>Let&rsquo;s now look at an example of reading test vectors from an external file. Example 8.16 shows the
</p>
<p>test bench setup. In this example, the SystemX design from the prior example will be tested using vectors
</p>
<p>provided by an external file (input_file.txt). The test bench will read in each line of the file individually and
</p>
<p>sequentially. After reading a line, the test bench will drive the DUTwith the input vector. In order to verify
</p>
<p>correct operation, the results will be written to the STD_OUTPUTof the computer.
</p>
<p>Example 8.16
Reading from an External File in a Test Bench (Part 1)
</p>
<p>298 &bull; Chapter 8: VHDL (Part 2)</p>
<p/>
</div>
<div class="page"><p/>
<p>In order to read the external vectors, a file is declared in READ_MODE. This opens the external file
</p>
<p>and allows the VHDL test bench to access its lines. A variable is declared to hold the line that is read
</p>
<p>using the readline() procedure. In this example, the line variable for reading is called &ldquo;current_read_line&rdquo;.
</p>
<p>A variable is also declared that will ultimately hold the vector that is extracted from current_read_line.
</p>
<p>This variable (called current_read_field) is declared to be of type std_logic_vector(2 downto 0) because
</p>
<p>the vectors in the file are 3-bit values. Once the line is read from the file using the readline() procedure,
</p>
<p>the vector can be read from the line variable using the read() procedure. Once the value resides in the
</p>
<p>current_read_field variable, it can be assigned to the DUT input signal vector ABC_TB. A set of
</p>
<p>messages are then written to the STD_OUTPUT of the computer using the reserved file handle
</p>
<p>OUTPUT. The messages contain descriptive text in addition to the values of the input vector and output
</p>
<p>value of the DUT. Example 8.17 shows the process to implement this behavior in the test bench.
</p>
<p>Example 8.17
Reading from an External File in a Test Bench (Part 2)
</p>
<p>Example 8.18 shows the results of this test bench, which are written to STD_OUTPUT.
</p>
<p>8.5 Packages &bull; 299</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 8.18
Reading from an External File in a Test Bench (Part 3)
</p>
<p>8.5.8.4 Example: Reading Space-Delimited Data from an External File in a Test Bench
</p>
<p>As mentioned earlier, information in a line variable is treated as white space delimited by the read()
</p>
<p>procedure. This allows more information than just a single vector to be read from a file. When a read()
</p>
<p>procedure is performed on a line variable, it will extract information until it reaches either a white space or
</p>
<p>the end-of-line character. If a white space is encountered, the read() procedure will end. Let&rsquo;s take a look
</p>
<p>at an example of how to read information from a file when it contains both strings and vectors. Example
</p>
<p>8.19 shows the test bench setup where an external file is to be read that contains both a text heading and
</p>
<p>test vector on each line. Since the header and the vector are separated with a white space character, two
</p>
<p>read() procedures need to be used to independently extract these distinct fields from the line variable.
</p>
<p>Example 8.19
Reading Space-Delimited Data from an External File in a Test Bench (Part 1)
</p>
<p>300 &bull; Chapter 8: VHDL (Part 2)</p>
<p/>
</div>
<div class="page"><p/>
<p>The test bench will transfer a line from the file into a line variable using the readline() procedure just
</p>
<p>as in the previous example; however, this time two different variables will need to be defined in order to
</p>
<p>read the two separate fields in the line. Each variable must be declared to be the proper type and size for
</p>
<p>the information in the field. For example, the first field in the file is a string of seven characters. As a result,
</p>
<p>the first variable declared (current_read_field1) will be of type string(1 to 7). Recall that strings are
</p>
<p>typically indexed incrementally from left to right starting with the index 1. The second field in the file is a
</p>
<p>3-bit vector, so the second variable declared (current_read_field2) will be of type std_logic_vector
</p>
<p>(2 downto 0). Each time a line is retrieved from the file using the readline() procedure, two subsequent
</p>
<p>read() procedures can be performed to extract the two fields from the line variable. The second field (i.e.,
</p>
<p>the vector) can be used to drive the input of the DUT. In this example, both fields are written to
</p>
<p>STD_OUTPUT in addition to the output of the DUT to verify proper functionality. Example 8.20 shows
</p>
<p>the test bench process which models this behavior.
</p>
<p>Example 8.20
Reading Space-Delimited Data from an External File in a Test Bench (Part 2)
</p>
<p>8.5 Packages &bull; 301</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 8.21 shows the results of this test bench, which are written to STD_OUTPUT.
</p>
<p>Example 8.21
Reading Space-Delimited Data from an External File in a Test Bench (Part 3)
</p>
<p>8.5.9 Legacy Packages (STD_LOGIC_ARITH/UNSIGNED/SIGNED)
</p>
<p>Prior to the release of the numeric_std package by IEEE, Synopsis, Inc. created a set of packages to
</p>
<p>provide computational operations for types std_logic and std_logic_vector. Since these arithmetic
</p>
<p>packages were defined very early in the life of VHDL, they were widely adopted. Unfortunately, due to
</p>
<p>these packages not being standardized through a governing body such as IEEE, vendors began
</p>
<p>modifying the packages to meet proprietary needs. This led to a variety of incompatibility issues that
</p>
<p>have plagued these packages. As a result, all new designs requiring computational operations should be
</p>
<p>based on the IEEE numeric_std package. While the IEEE standard is the recommended numerical
</p>
<p>package for VHDL, the original Synopsis packages are still commonly found in designs and in design
</p>
<p>examples, so providing an overview of their functionality is necessary.
</p>
<p>Synopsis, Inc. created the std_logic_arith package to provide computational operations for types
</p>
<p>std_logic and std_logic_vector. Just as with the numeric_std package, this package defines two new
</p>
<p>types, unsigned and signed. Arithmetic, comparison, and shift operators are provided for these types
</p>
<p>that include +, �, *, abs, &gt;, &lt;, &lt;&frac14;, &gt;&frac14;, &frac14;, /&frac14;, shl, and shr. This package also provides a set of
</p>
<p>conversion functions between types unsigned, signed, std_logic_vector, and integer. The syntax for
</p>
<p>these conversions is as follows:
</p>
<p>Name Input type Return type
</p>
<p>CONV_INTEGER Unsigned Integer
</p>
<p>CONV_INTEGER Signed Integer
</p>
<p>CONV_UNSIGNED Integer, &lt;size&gt; Unsigned
</p>
<p>CONV_UNSIGNED Signed Unsigned
</p>
<p>CONV_SIGNED Integer, &lt;size&gt; Signed
</p>
<p>CONV_SIGNED Unsigned Signed
</p>
<p>CONV_STD_LOGIC_VECTOR Integer, &lt;size&gt; std_logic_vector(size-1 downto 0)
</p>
<p>CONV_STD_LOGIC_VECTOR Unsigned, &lt;size&gt; std_logic_vector(size-1 downto 0)
</p>
<p>CONV_STD_LOGIC_VECTOR Signed, &lt;size&gt; std_logic_vector(size-1 downto 0)
</p>
<p>302 &bull; Chapter 8: VHDL (Part 2)</p>
<p/>
</div>
<div class="page"><p/>
<p>The Synopsis packages have the ability to treat all std_logic_vectors in a design as either unsigned
</p>
<p>or signed by including an additional package. The std_logic_unsigned package, when included in
</p>
<p>conjunction with the std_logic_arith package, will treat all std_logic_vectors in the design as unsigned
</p>
<p>numbers. The syntax for using the Synopsis arithmetic packages on unsigned numbers is as follows.
</p>
<p>The std_logic_1164 package is required to define types std_logic/std_logic_vector. The std_logic_arith
</p>
<p>package provides the computational operators for types std_logic/std_logic_vector. Finally, the
</p>
<p>std_logic_unsigned package treats all std_logic/std_logic_vector types as unsigned numbers when
</p>
<p>performing arithmetic operations:
</p>
<p>library IEEE;
use IEEE.std_logic_1164.all;
use IEEE.std_logic_arith.all;
use IEEE.std_logic_unsigned.all;
</p>
<p>The std_logic_signed package works in a similar manner with the exception that it treats all
</p>
<p>std_logic/std_logic_vector types as signed numbers when performing arithmetic operations. The
</p>
<p>std_logic_unsigned and std_logic_signed packages are never used together since they will conflict
</p>
<p>with each other.
</p>
<p>The syntax for using the std_logic_signed package is as follows:
</p>
<p>library IEEE;
use IEEE.std_logic_1164.all;
use IEEE.std_logic_arith.all;
use IEEE.std_logic_signed.all;
</p>
<p>One of the more confusing aspects of the Synopsis packages is that they are included in the IEEE
</p>
<p>library. This means that both the numeric_std package (IEEE standard) and the std_logic_arith package
</p>
<p>(Synopsis, non-standard) are part of the same library, but one is recommended while the other is not.
</p>
<p>This is due to the fact that the Synopsis packages were developed first, and putting them into the IEEE
</p>
<p>library was the most natural location since this library was provided as part of the VHDL standard. When
</p>
<p>the numeric_std package was standardized by IEEE, it also was naturally inserted into the IEEE library.
</p>
<p>As a result, today&rsquo;s IEEE library contains both styles of packages.
</p>
<p>CC8.5(a) Why is standardization important for VHDL packages?
</p>
<p>A) So that different CAD/CAE tools are interoperable.  
</p>
<p>B) To support IEEE.
</p>
<p>C) So that synthesis is possible.
</p>
<p>D) So that detailed manuals can be created.
</p>
<p>CC8.5(b) Why doesn&rsquo;t the VHDL standard package simply include all of the functionality that has 
been created in all of the packages that were developed later?
</p>
<p>A) There was not sufficient funding to keep the VHDL standard package updated.
</p>
<p>B) If every package was included, compilation would take an excessive amount of 
time.
</p>
<p>C) Explicitly defining packages helps remind the designer the proper way to 
create a VHDL model.
</p>
<p>D) Because not all designs require all of the functionality in every package.  Plus, 
some packages defined duplicate information.  For example, both the 
numeric_bit and numeric_std have data types called unsigned.
</p>
<p>CONCEPT CHECK
</p>
<p>8.5 Packages &bull; 303</p>
<p/>
</div>
<div class="page"><p/>
<p>Summary
</p>
<p>v To model sequential logic, an HDL needs to
be able to trigger signal assignments based
on a triggering event. This is accomplished in
VHDL using a process.
</p>
<p>v A sensitivity list is a way to control when a
VHDL process is triggered. A sensitivity list
contains a list of signals. If any of the signals
in the sensitivity list transition it will cause the
process to trigger. If a sensitivity list is omit-
ted, the process will trigger immediately.
</p>
<p>v Signal assignments are made when a pro-
cess suspends. There are two techniques to
suspend a process. The first is using the wait
statement. The second is simply ending the
process.
</p>
<p>v Sensitivity lists and wait statements are
never used at the same time. Sensitivity
lists are used to model synthesizable logic
while wait statements are used for test
benches.
</p>
<p>v When signal assignments are made in a pro-
cess, they are made in the order they are
listed in the process. If assignments are
made to the same signal within a process,
only the last assignment will take place when
the process suspends.
</p>
<p>v If assignments are needed to occur prior to
the process suspending, a variable is used.
In VHDL, variables only exist within a pro-
cess. Variables are defined when a process
triggers and deleted when the process ends.
</p>
<p>v Processes also allow more advanced
modeling constructs in VHDL. These include
if/then statements, case statements, infinite
loops, while loops, and for loops.
</p>
<p>v Signal attributes allow additional information
to be observed about a signal other than its
value.
</p>
<p>v A test bench is a way to simulate a device
under test (DUT) by instantiating it as a com-
ponent, driving in stimulus, and observing the
outputs. Test benches do not have inputs or
outputs and are unsynthesizable.
</p>
<p>v The report and assert statements provide a
way to perform automatic checking of the
outputs of a DUT within a test bench.
</p>
<p>v The IEEE STD_LOGIC_1164 package
provides more realistic data types for
modeling modern digital systems. This pack-
age provides the std_ulogic and std_logic
data types. These data types can take on
nine different values (U, X, 0, 1, Z, W, L, H,
and -). The std_logic data type provides a
resolution function that allows multiple
outputs to be connected to the same signal.
The resolution function will determine the
value of the signal based on a predefined
priority given in the function.
</p>
<p>v The IEEE STD_LOGIC_1164 package
provides logical operators and edge detec-
tion functions for the types std_ulogic and
std_logic. It also provides conversion
functions to and from the type bit.
</p>
<p>v The IEEE NUMERIC_STD package
provides the data types unsigned and
signed. These types use the underlying
data type std_logic. These types provide the
ability to treat vectors as either unsigned or
two&rsquo;s complement codes.
</p>
<p>v The IEEE NUMERIC_STD package
provides arithmetic operations for the types
unsigned and signed. This package also
provides conversion functions and type
casts to and from the types integer and
std_logic_vector.
</p>
<p>v The TEXTIO and STD_LOGIC_TEXTIO
packages provide the functionality to read
and write to files from within a test bench.
This allows more sophisticated vector
patterns to be driven into a DUT. This also
provides more sophisticated automatic
checking of a DUT.
</p>
<p>Exercise Problems
</p>
<p>Section 8.1&mdash;The Process
</p>
<p>8.1.1 When using a sensitivity list in a process, what
will cause the process to trigger?
</p>
<p>8.1.2 When using a sensitivity list in a process, what
will cause the process to suspend?
</p>
<p>8.1.3 When a sensitivity list is not used in a process,
when will the process trigger?
</p>
<p>8.1.4 Can a sensitivity list and a wait statement be
used in the same process at the same time?
</p>
<p>8.1.5 Does a wait statement trigger or suspend a
process?
</p>
<p>8.1.6 When are signal assignments officially made in
a process?
</p>
<p>8.1.7 Why are assignments in a process called
sequential signal assignments?
</p>
<p>304 &bull; Chapter 8: VHDL (Part 2)</p>
<p/>
</div>
<div class="page"><p/>
<p>8.1.8 Can signals be declared in a process?
</p>
<p>8.1.9 Are variables declared within a process visible
to the rest of the VHDL model (e.g., are they
visible outside of the process)?
</p>
<p>8.1.10 What happens to a variable when a process
ends?
</p>
<p>8.1.11 What is the assignment operator for variables?
</p>
<p>Section 8.2&mdash;Conditional Programming
</p>
<p>Constructs
</p>
<p>8.2.1 Design a VHDLmodel to implement the behav-
ior described by the 4-input truth table in
Fig. 8.4. Use a process and an if/then state-
ment. Use std_logic and std_logic_vector
types for your signals. Declare the entity to
match the block diagram provided. Hint: Notice
that there are far more input codes producing
F &frac14; 0 than producing F &frac14; 1. Can you use this
to your advantage to make your VHDL model
simpler?
</p>
<p>8.2.2 Design a VHDLmodel to implement the behav-
ior described by the 4-input truth table in
Fig. 8.4. Use a process and a case statement.
Use std_logic and std_logic_vector types for
your signals. Declare the entity to match the
block diagram provided.
</p>
<p>8.2.3 Design a VHDLmodel to implement the behav-
ior described by the 4-input minterm list in
Fig. 8.5. Use a process and an if/then state-
ment. Use std_logic and std_logic_vector
types for your signals. Declare the entity to
match the block diagram provided.
</p>
<p>8.2.4 Design a VHDLmodel to implement the behav-
ior described by the 4-input minterm list in
Fig. 8.5. Use a process and a case statement.
Use std_logic and std_logic_vector types for
your signals. Declare the entity to match the
block diagram provided.
</p>
<p>8.2.5 Design a VHDLmodel to implement the behav-
ior described by the 4-input maxterm list in
Fig. 8.6. Use a process and an if/then state-
ment. Use std_logic and std_logic_vector
types for your signals. Declare the entity to
match the block diagram provided.
</p>
<p>8.2.6 Design a VHDLmodel to implement the behav-
ior described by the 4-input maxterm list in
Fig. 8.6. Use a process and a case statement.
Use std_logic and std_logic_vector types for
your signals. Declare the entity to match the
block diagram provided.
</p>
<p>8.2.7 Design a VHDLmodel to implement the behav-
ior described by the 4-input truth table in
Fig. 8.7. Use a process and an if/then state-
ment. Use std_logic and std_logic_vector
types for your signals. Declare the entity to
match the block diagram provided. Hint: Notice
that there are far more input codes producing
F &frac14; 1 than producing F &frac14; 0. Can you use this
to your advantage to make your VHDL model
simpler?
</p>
<p>8.2.8 Design a VHDLmodel to implement the behav-
ior described by the 4-input truth table in
Fig. 8.7. Use a process and a case statement.
</p>
<p>Fig. 8.4
System I Functionality
</p>
<p>Fig. 8.5
System J Functionality
</p>
<p>Fig. 8.6
System K Functionality
</p>
<p>Fig. 8.7
System L Functionality
</p>
<p>Exercise Problems &bull; 305</p>
<p/>
</div>
<div class="page"><p/>
<p>Use std_logic and std_logic_vector types for
your signals. Declare the entity to match the
block diagram provided.
</p>
<p>8.2.9 Figure 8.8 shows the topology of a 4-bit shift
register when implemented structurally using
D-flip-flops. Design a VHDL model to describe
this functionality using a single process and
sequential signal assignments instead of
instantiating D-flip-flops. The figure also
provides the block diagram for the entity defini-
tion. Use std_logic and std_logic_vector types
for your signals.
</p>
<p>8.2.10 Design a VHDL model for a counter using a for
loop with an output type of integer. Figure 8.9
shows the block diagram for the entity defini-
tion. The counter should increment from 0 to
31 and then start over. Use wait statements
within your process to update the counter
value every 10 ns. Consider using the loop
variable of the for loop to generate your
counter value. NOTE: This design is not
synthesizable.
</p>
<p>8.2.11 Design a VHDL model for a counter using a for
loop with an output type of std_logic_vector
(4 downto 0). Figure 8.10 shows the block
diagram for the entity definition. The counter
should increment from 000002 to 111112 and
then start over. Use wait statements within your
process to update the counter value every
10 ns. Consider using the loop variable of the
for loop to generate an integer version of your
count value, and then use a type conversion
function to convert the integer to
std_logic_vector. NOTE: This design is not
synthesizable.
</p>
<p>Section 8.3&mdash;Signal Attributes
</p>
<p>8.3.1 What is the purpose of a signal attribute?
</p>
<p>8.3.2 What is the data type returned when using the
signal attribute &lsquo;event?
</p>
<p>8.3.3 What is the data type returned when using the
signal attribute &lsquo;last_event?
</p>
<p>8.3.4 What is the data type returned when using the
signal attribute &lsquo;length?
</p>
<p>Section 8.4&mdash;Test Benches
</p>
<p>8.4.1 Design a VHDL test bench to verify the func-
tional operation of the system in Fig. 8.4. Your
test bench should drive in each input code for
the vector ABCD in the order they appear in the
truth table (i.e., &ldquo;0000&rdquo;, &ldquo;0001&rdquo;, &ldquo;0010&rdquo;, . . .).
Have your test bench change the input pattern
every 10 ns using the wait for statement within
your stimulus process.
</p>
<p>8.4.2 Design a VHDL test bench to verify the func-
tional operation of the system in Fig. 8.4 using
report and assert statements. Your test bench
should drive in each input code for the vector
ABCD in the order they appear in the truth table
(i.e., &ldquo;0000&rdquo;, &ldquo;0001&rdquo;, &ldquo;0010&rdquo;, . . .). Have your
test bench change the input pattern every
10 ns using the wait for statement within your
stimulus process. Use the report and assert
statements to output a message on the status
of each test to the simulation transcript window.
For each input vector, create a message that
indicates the current input vector being tested,
the resulting output of your DUT, and whether
the DUToutput is correct.
</p>
<p>8.4.3 Design a VHDL test bench to verify the func-
tional operation of the system in Fig. 8.5. Your
test bench should drive in each input code for
the vector ABCD in the order they appear in the
truth table (i.e., &ldquo;0000&rdquo;, &ldquo;0001&rdquo;, &ldquo;0010&rdquo;, . . .).
Have your test bench change the input pattern
every 10 ns using the wait for statement within
your stimulus process.
</p>
<p>8.4.4 Design a VHDL test bench to verify the func-
tional operation of the system in Fig. 8.5 using
report and assert statements. Your test bench
should drive in each input code for the vector
ABCD in the order they appear in the truth table
(i.e., &ldquo;0000&rdquo;, &ldquo;0001&rdquo;, &ldquo;0010&rdquo;, . . .). Have your
test bench change the input pattern every
10 ns using the wait for statement within your
stimulus process. Use the report and assert
statements to output a message on the status
of each test to the simulation transcript window.
</p>
<p>Fig. 8.8
4-Bit Shift Register Functionality
</p>
<p>Fig. 8.9
Integer Counter Block Diagram
</p>
<p>Fig. 8.10
5-Bit Binary Counter Block Diagram
</p>
<p>306 &bull; Chapter 8: VHDL (Part 2)</p>
<p/>
</div>
<div class="page"><p/>
<p>For each input vector, create a message that
indicates the current input vector being tested,
the resulting output of your DUT, and whether
the DUToutput is correct.
</p>
<p>8.4.5 Design a VHDL test bench to verify the func-
tional operation of the system in Fig. 8.6. Your
test bench should drive in each input code for
the vector ABCD in the order they appear in the
truth table (i.e., &ldquo;0000&rdquo;, &ldquo;0001&rdquo;, &ldquo;0010&rdquo;, . . .).
Have your test bench change the input pattern
every 10 ns using the wait for statement within
your stimulus process.
</p>
<p>8.4.6 Design a VHDL test bench to verify the func-
tional operation of the system in Fig. 8.6 using
report and assert statements. Your test bench
should drive in each input code for the vector
ABCD in the order they appear in the truth table
(i.e., &ldquo;0000&rdquo;, &ldquo;0001&rdquo;, &ldquo;0010&rdquo;, . . .). Have your
test bench change the input pattern every
10 ns using the wait for statement within your
stimulus process. Use the report and assert
statements to output a message on the status
of each test to the simulation transcript window.
For each input vector create a message that
indicates the current input vector being tested,
the resulting output of your DUT, and whether
the DUToutput is correct.
</p>
<p>8.4.7 Design a VHDL test bench to verify the func-
tional operation of the system in Fig. 8.7. Your
test bench should drive in each input code for
the vector ABCD in the order they appear in the
truth table (i.e., &ldquo;0000&rdquo;, &ldquo;0001&rdquo;, &ldquo;0010&rdquo;, . . .).
Have your test bench change the input pattern
every 10 ns using the wait for statement within
your stimulus process.
</p>
<p>8.4.8 Design a VHDL test bench to verify the func-
tional operation of the system in Fig. 8.7 using
report and assert statements. Your test bench
should drive in each input code for the vector
ABCD in the order they appear in the truth table
(i.e., &ldquo;0000&rdquo;, &ldquo;0001&rdquo;, &ldquo;0010&rdquo;, . . .). Have your
test bench change the input pattern every
10 ns using the wait for statement within your
stimulus process. Use the report and assert
statements to output a message on the status
of each test to the simulation transcript window.
For each input vector, create a message that
indicates the current input vector being tested,
the resulting output of your DUT, and whether
the DUToutput is correct.
</p>
<p>Section 8.5&mdash;Packages
</p>
<p>8.5.1 What are all the possible values that a signal of
type std_logic can take on?
</p>
<p>8.5.2 What is the difference between the types
std_ulogic and std_logic?
</p>
<p>8.5.3 If a signal of type std_logic is assigned both a
0 and Z at the same time, what will the final
signal value be?
</p>
<p>8.5.4 If a signal of type std_logic is assigned both a
1 and X at the same time, what will the final
signal value be?
</p>
<p>8.5.5 If a signal of type std_logic is assigned both a
0 and L at the same time, what will the final
signal value be?
</p>
<p>8.5.6 Are any arithmetic operations provided for the
type std_logic_vector in the
STD_LOGIC_1164 package?
</p>
<p>8.5.7 If you declare a signal of type unsigned from
the NUMERIC_STD package, what are all the
possible values that the signal can take on?
</p>
<p>8.5.8 If you declare a signal of type signed from the
NUMERIC_STD package, what are all the pos-
sible values that the signal can take on?
</p>
<p>8.5.9 If two signals (A and B) are declared of type
signed from the NUMERIC_STD package and
hold the values A &lt;&frac14; &ldquo;1111&rdquo; and B &lt;&frac14; &ldquo;0000&rdquo;,
which signal has a greater value?
</p>
<p>8.5.10 If two signals (A and B) are declared of type
unsigned from the NUMERIC_STD package
and hold the values A &lt;&frac14; &ldquo;1111&rdquo; and
B &lt;&frac14; &ldquo;0000&rdquo;, which signal has a greater value?
</p>
<p>8.5.11 If you are using the NUMERIC_STD package,
what is the syntax to convert a signal of type
unsigned into std_logic_vector?
</p>
<p>8.5.12 If you are using the NUMERIC_STD package,
what is the syntax to convert a signal of type
integer into std_logic_vector?
</p>
<p>8.5.13 Design a self-checking VHDL test bench that
reads in test vectors from an external file to
verify the functional operation of the system in
Fig. 8.7. Create an input text file called
&ldquo;input_vectors.txt&rdquo; that contains each input
code for the vector ABCD in the order they
appear in the truth table (i.e., &ldquo;0000&rdquo;, &ldquo;0001&rdquo;,
&ldquo;0010&rdquo;, . . .) on a separate line. The test bench
should read in each line of the file individually
and use the corresponding input vector to drive
the DUT. Write the output results to an external
file called &ldquo;output_vectors.txt&rdquo;.
</p>
<p>8.5.14 Design a self-checking VHDL test bench that
reads in test vectors from an external file to
verify the functional operation of the system in
Fig. 8.7. Create an input text file called
&ldquo;input_vectors.txt&rdquo; that contains each input
code for the vector ABCD in the order they
appear in the truth table (i.e., &ldquo;0000&rdquo;, &ldquo;0001&rdquo;,
&ldquo;0010&rdquo;, . . .) on a separate line. The test bench
should read in each line of the file individually
and use the corresponding input vector to drive
the DUT. Write the output results to the
STD_OUTPUTof the simulator.
</p>
<p>Exercise Problems &bull; 307</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 9: Behavioral Modeling
</p>
<p>of Sequential Logic
In this chapter, we look at modeling sequential logic using the more sophisticated behavioral
</p>
<p>modeling techniques presented in Chap. 8. We begin by looking at modeling sequential storage devices.
</p>
<p>Next, we look at the behavioral modeling of finite-state machines. Finally, we look at register transfer
</p>
<p>level, or RTL modeling. The goal of this chapter is to provide an understanding of how hardware
</p>
<p>description languages can be used to create behavioral models of synchronous digital systems
</p>
<p>Learning Outcomes&mdash;After completing this chapter, you will be able to:
</p>
<p>9.1 Design a VHDL behavioral model for a sequential logic storage device.
9.2 Describe the process for creating a VHDL behavioral model for a finite-state machine.
9.3 Design a VHDL behavioral model for a finite-state machine.
9.4 Design a VHDL behavioral model for a counter.
9.5 Design a VHDL register transfer level (RTL) model of a synchronous digital system.
</p>
<p>9.1 Modeling Sequential Storage Devices in VHDL
</p>
<p>9.1.1 D-Latch
</p>
<p>Let&rsquo;s begin with the model of a simple D-Latch. Since the outputs of this sequential storage device
</p>
<p>are not updated continuously, its behavior is modeled using a process. Since we want to create a
</p>
<p>synthesizable model, we use a sensitivity list to trigger the process instead of wait statements. In the
</p>
<p>sensitivity list we need to include the C input since it controls when the D-Latch is in track or store mode.
</p>
<p>We also need to include the D input in the sensitivity list because during the track mode, the output Q will
</p>
<p>be continuously assigned the value of D, so any change on D needs to trigger the process. The use of an
</p>
<p>if/then statement is used to model the behavior during track mode (C &frac14; 1). Since the behavior is not
</p>
<p>explicitly stated for when C &frac14; 0, the outputs will hold their last value, which allows us to simply end the
</p>
<p>if/then statement to complete the model. Example 9.1 shows the behavioral model for a D-Latch.
</p>
<p>Example 9.1
Behavioral Model of a D-Latch in VHDL
</p>
<p># Springer International Publishing Switzerland 2017
</p>
<p>B.J. LaMeres, Introduction to Logic Circuits &amp; Logic Design with VHDL,
</p>
<p>DOI 10.1007/978-3-319-34195-8_9
</p>
<p>309</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_8">http://dx.doi.org/10.1007/978-3-319-34195-8_8</a></div>
</div>
<div class="page"><p/>
<p>9.1.2 D-Flip-Flop
</p>
<p>The rising edge behavior of a D-flip-flop is modeled using a (Clock&rsquo;event and Clock &frac14; &lsquo;1&rsquo;) Boolean
</p>
<p>condition within a process. The (rising_edge(Clock)) function can also be used for type std_logic.
</p>
<p>Example 9.2 shows the behavioral model for a rising edge-triggered D-flip-flop with both Q and Qn
</p>
<p>outputs.
</p>
<p>Example 9.2
Behavioral Model of a D-Flip-Flop in VHDL
</p>
<p>9.1.3 D-Flip-Flop with Asynchronous Reset
</p>
<p>D-flip-flops typically have a reset line in order to initialize their outputs to a known state (e.g., Q &frac14; 0,
</p>
<p>Qn &frac14; 1). Resets are asynchronous, meaning that whenever they are asserted, assignments to the
</p>
<p>outputs take place immediately. If a reset was synchronous, the output assignments would only take
</p>
<p>place on the next rising edge of the clock. This behavior is undesirable because if there is a system
</p>
<p>failure, there is no guarantee that a clock edge will ever occur. Thus the reset may never take place.
</p>
<p>Asynchronous resets are more desirable not only to put the D-flip-flops into a known state at startup, but
</p>
<p>also to recover from a system failure that may have impacted the clock signal. In order to model this
</p>
<p>asynchronous behavior, the reset signal is placed in the sensitivity list. This allows both the clock and the
</p>
<p>reset inputs to trigger the process. Within the process, an if/then/elsif statement is used to determine
</p>
<p>whether the reset has been asserted or a rising edge of the clock has occurred. The if/then/elsif
</p>
<p>statement first checks whether the reset input has been asserted. If it has, it makes the appropriate
</p>
<p>assignments to the outputs (Q &frac14; 0, Qn &frac14; 1). If the reset has not been asserted, the elsif clause checks
</p>
<p>whether a rising edge of the clock has occurred using the (Clock&rsquo;event and Clock &frac14; &lsquo;1&rsquo;) Boolean
</p>
<p>condition. If it has, the outputs are updated accordingly (Q &lt;&frac14; D, Qn &lt;&frac14; not D). A final else statement
</p>
<p>is not included so that assignments to the outputs are not made under any other condition. This models
</p>
<p>the store behavior of the D-flip-flop. Example 9.3 shows the behavioral model for a rising edge-triggered
</p>
<p>D-flip-flop with an asynchronous, active LOW reset.
</p>
<p>310 &bull; Chapter 9: Behavioral Modeling of Sequential Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 9.3
Behavioral Model of a D-Flip-Flop with Asynchronous Reset in VHDL
</p>
<p>9.1.4 D-Flip-Flop with Asynchronous Reset and Preset
</p>
<p>A D-flip-flop with both an asynchronous reset and asynchronous preset is handled in a similar
</p>
<p>manner as the D-flip-flop in the prior section. The preset input is included in the sensitivity list in order to
</p>
<p>trigger the process whenever a transition occurs on either the clock, reset, or preset inputs. An if/then/
</p>
<p>elsif statement is used to first check whether a reset has occurred; then whether a preset has occurred;
</p>
<p>and finally, whether a rising edge of the clock has occurred. Example 9.4 shows the model for a rising
</p>
<p>edge-triggered D-flip-flop with asynchronous, active LOW reset and preset.
</p>
<p>9.1 Modeling Sequential Storage Devices in VHDL &bull; 311</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 9.4
Behavioral Model of a D-Flip-Flop with Asynchronous Reset and Preset in VHDL
</p>
<p>9.1.5 D-Flip-Flop with Synchronous Enable
</p>
<p>An enable input is also a common feature of modern D-flip-flops. Enable inputs are synchronous,
</p>
<p>meaning that when they are asserted, action is only taken on the rising edge of the clock. This means
</p>
<p>that the enable input is not included in the sensitivity list of the process. Since action is only taken when
</p>
<p>there is a rising edge of the clock, a nested if/then statement is included beneath the elsif (Clock&rsquo;event
</p>
<p>and Clock &frac14; &lsquo;1&rsquo;) clause. Example 9.5 shows the model for a D-flip-flop with a synchronous enable
</p>
<p>(EN) input. When EN &frac14; 1, the D-flip-flop is enabled and assignments are made to the outputs only on the
</p>
<p>rising edge of the clock. When EN &frac14; 0, the D-flip-flop is disabled and assignments to the outputs are not
</p>
<p>made. When disabled, the D-flip-flop effectively ignores rising edges on the clock and the outputs remain
</p>
<p>at their last values.
</p>
<p>312 &bull; Chapter 9: Behavioral Modeling of Sequential Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 9.5
Behavioral Model of a D-Flip-Flop with Synchronous Enable in VHDL
</p>
<p>CC9.1 Why is the D input not listed in the sensitivity list of a D-flip-flop?
</p>
<p>A) To simplify the behavioral model.
</p>
<p>B) To avoid a setup time violation if D transitions too closely to the clock.
</p>
<p>C) Because a rising edge of clock is needed to make the assignment.
</p>
<p>D) Because the outputs of the D-flip-flop are not updated when D changes.
</p>
<p>CONCEPT CHECK
</p>
<p>9.2 Modeling Finite-State Machines in VHDL
</p>
<p>Finite-state machines can be easily modeled using the behavioral constructs from Chap. 8.
</p>
<p>The most common modeling practice for FSMs is to create a new user-defined type that can take on
</p>
<p>the descriptive state names from the state diagram. Two signals are then created of this type,
</p>
<p>current_state and next_state. Once these signals are created, all of the functional blocks in the state
</p>
<p>machine can use the descriptive state names in their conditional signal assignments. The synthesizer
</p>
<p>will automatically assign the state codes based on the most effective use of the target technology (e.g.,
</p>
<p>binary, gray code, one-hot). Within the VHDL state machine model, three processes are used to describe
</p>
<p>9.2 Modeling Finite-State Machines in VHDL &bull; 313</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_8">http://dx.doi.org/10.1007/978-3-319-34195-8_8</a></div>
</div>
<div class="page"><p/>
<p>each of the functional blocks, state memory, next state logic, and output logic. In order to examine how to
</p>
<p>model a finite-state machine using this approach, let&rsquo;s use the push-button window controller example
</p>
<p>from Chap. 7. Example 9.6 gives the overview of the design objectives for this example and the state
</p>
<p>diagram describing the behavior to be modeled in VHDL.
</p>
<p>Example 9.6
Push-Button Window Controller in VHDL&mdash;Design Description
</p>
<p>Let&rsquo;s begin by defining the entity. The system has an input called Press and two outputs called
</p>
<p>Open_CW and Close_CCW. The system also has clock and reset inputs. We will design the system to
</p>
<p>update on the rising edge of the clock and have an asynchronous, active LOW, reset. Example 9.7
</p>
<p>shows the VHDL entity definition for this example.
</p>
<p>Example 9.7
Push-Button Window Controller in VHDL&mdash;Entity Definition
</p>
<p>314 &bull; Chapter 9: Behavioral Modeling of Sequential Logic</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_7">http://dx.doi.org/10.1007/978-3-319-34195-8_7</a></div>
</div>
<div class="page"><p/>
<p>9.2.1 Modeling the States with User-Defined, Enumerated Data Types
</p>
<p>Now we begin designing the finite-state machine in VHDL using behavioral modeling constructs.
</p>
<p>The first step is to create a new user-defined, enumerated data type that can take on values that match
</p>
<p>the descriptive state names we&rsquo;ve chosen in the state diagram (i.e., w_closed and w_open). This is
</p>
<p>accomplished by declaring a new type before the begin statement in the architecture with the keyword
</p>
<p>type. For this example, we will create a new type called State_Type and explicitly enumerate the values
</p>
<p>that it can take on. This type can now be used in future signal declarations. We then create two new
</p>
<p>signals called current_state and next_state of type State_Type. These two signals will be used through-
</p>
<p>out the VHDL model in order to provide a high-level, readable description of the FSM behavior. The
</p>
<p>following syntax shows how to declare the new type and declare the current_state and next_state
</p>
<p>signals:
</p>
<p>type State_Type is (w_closed, w_open);
</p>
<p>signal current_state, next_state : State_Type;
</p>
<p>9.2.2 The State Memory Process
</p>
<p>Now we model the state memory of the FSM using a process. This process models the behavior of
</p>
<p>the D-flip-flops in the FSM that are holding the current state on their Q outputs. Each time there is a rising
</p>
<p>edge of the clock, the current state is updated with the next state value present on the D inputs of the
</p>
<p>D-flip-flops. This process must also model the reset condition. For this example we will have the state
</p>
<p>machine go to the w_closed state when Reset is asserted. At all other times, the process will simply
</p>
<p>update current_state with next_state on every rising edge of the clock. The process model is very similar
</p>
<p>to the model of a D-flip-flop. This is as expected since this process will synthesize into one or more D-flip-
</p>
<p>flops to hold the current state. The sensitivity list contains only Clock and Reset and assignments are
</p>
<p>only made to the signal current_state. The following syntax shows how to model the state memory of this
</p>
<p>FSM example:
</p>
<p>STATE_MEMORY : process (Clock, Reset)
</p>
<p>begin
</p>
<p>if (Reset &frac14; &rsquo;0&rsquo;) then
</p>
<p>current_state &lt;&frac14; w_closed;
</p>
<p>elsif (Clock&rsquo;event and Clock&frac14;&rsquo;1&rsquo;) then
</p>
<p>current_state &lt;&frac14; next_state;
</p>
<p>end if;
</p>
<p>end process;
</p>
<p>9.2.3 The Next State Logic Process
</p>
<p>Now we model the next state logic of the FSM using a second process. Recall that the next state
</p>
<p>logic is combinational logic; thus we need to include all of the input signals that the circuit considers in the
</p>
<p>next state calculation in the sensitivity list. The current_state signal will always be included in the
</p>
<p>sensitivity list of the next state logic process in addition to any inputs to the system. For this example
</p>
<p>the system has one other input called Press. This process makes assignments to the next_state signal. It
</p>
<p>is common to use a case statement to separate out the assignments that occur at each state. At each
</p>
<p>state within the case statement, an if/then statement is used to model the assignments for different input
</p>
<p>conditions on Press. The following syntax shows how to model the next state logic of this FSM example.
</p>
<p>Notice that we include awhen others clause to ensure that the state machine has a path back to the reset
</p>
<p>state in the case of an unexpected fault:
</p>
<p>9.2 Modeling Finite-State Machines in VHDL &bull; 315</p>
<p/>
</div>
<div class="page"><p/>
<p>NEXT_STATE_LOGIC : process (current_state, Press)
</p>
<p>begin
</p>
<p>case (current_state) is
</p>
<p>when w_closed &frac14;&gt; if (Press &frac14; &rsquo;1&rsquo;) then
</p>
<p>next_state &lt;&frac14; w_open;
</p>
<p>else
</p>
<p>next_state &lt;&frac14; w_closed;
</p>
<p>end if;
</p>
<p>when w_open &frac14;&gt; if (Press &frac14; &rsquo;1&rsquo;) then
</p>
<p>next_state &lt;&frac14; w_closed;
</p>
<p>else
</p>
<p>next_state &lt;&frac14; w_open;
</p>
<p>end if;
</p>
<p>when others &frac14;&gt; next_state &lt;&frac14; w_closed;
</p>
<p>end case;
</p>
<p>end process;
</p>
<p>9.2.4 The Output Logic Process
</p>
<p>Now we model the output logic of the FSM using a third process. Recall that output logic is
</p>
<p>combinational logic; thus we need to include all of the input signals that this circuit considers in the
</p>
<p>output assignments. The current_state will always be included in the sensitivity list. If the FSM is a Mealy
</p>
<p>machine, then the system inputs will also be included in the sensitivity list. If the machine is a Moore
</p>
<p>machine, then only the current_state will be present in the sensitivity list. For this example the FSM is a
</p>
<p>Mealy machine, so the input Press needs to be included in the sensitivity list. Note that this process only
</p>
<p>makes assignments to the outputs of the machine (Open_CW and Close_CCW). The following syntax
</p>
<p>shows how to model the output logic of this FSM example. Again, we include a when others clause to
</p>
<p>ensure that the state machine has explicit output behavior in the case of a fault:
</p>
<p>OUTPUT_LOGIC : process (current_state, Press)
</p>
<p>begin
</p>
<p>case (current_state) is
</p>
<p>when w_closed &frac14;&gt; if (Press &frac14; &rsquo;1&rsquo;) then
</p>
<p>Open_CW &lt;&frac14; &rsquo;1&rsquo;; Close_CCW &lt;&frac14; &rsquo;0&rsquo;;
</p>
<p>else
</p>
<p>Open_CW &lt;&frac14; &rsquo;0&rsquo;; Close_CCW &lt;&frac14; &rsquo;0&rsquo;;
</p>
<p>end if;
</p>
<p>when w_open &frac14;&gt; if (Press &frac14; &rsquo;1&rsquo;) then
</p>
<p>Open_CW &lt;&frac14; &rsquo;0&rsquo;; Close_CCW &lt;&frac14; &rsquo;1&rsquo;;
</p>
<p>else
</p>
<p>Open_CW &lt;&frac14; &rsquo;0&rsquo;; Close_CCW &lt;&frac14; &rsquo;0&rsquo;;
</p>
<p>end if;
</p>
<p>when others &frac14;&gt; Open_CW &lt;&frac14; &rsquo;0&rsquo;; Close_CCW &lt;&frac14; &rsquo;0&rsquo;;
</p>
<p>end case;
</p>
<p>end process;
</p>
<p>Putting this all together in the VHDL architecture yields a functional model for the FSM that can be
</p>
<p>simulated and synthesized. Once again, it is important to keep in mind that since we did not explicitly
</p>
<p>assign the state codes, the synthesizer will automatically assign the codes based on the most efficient
</p>
<p>use of the target technology. Example 9.8 shows the entire architecture for this example.
</p>
<p>316 &bull; Chapter 9: Behavioral Modeling of Sequential Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 9.8
Push-Button Window Controller in VHDL &ndash; Architecture
</p>
<p>Example 9.9 shows the simulation waveform for this state machine. This functional simulation was
</p>
<p>performed using ModelSim-Altera Starter Edition 10.1d.
</p>
<p>9.2 Modeling Finite-State Machines in VHDL &bull; 317</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 9.9
Push-Button Window Controller in VHDL&mdash;Simulation Waveform
</p>
<p>9.2.5 Explicitly Defining State Codes with Subtypes
</p>
<p>In the prior example, we did not have control over the state variable encoding. While the previous
</p>
<p>example is the most common way to model FSMs, there are situations where we would like to assign the
</p>
<p>state variable codes manually. This is accomplished using a subtype and constants. A subtype is simply
</p>
<p>a constrained type, meaning that it defines a subset of values that an existing type can take on. For
</p>
<p>example, we could create a subtype to constrain the std_logic data type to only allow values of 0 and
</p>
<p>1 and not the values of U, X, Z, W, L, H, and -. This would not be considered a new type since it is simply a
</p>
<p>constraint put upon the existing std_logic type. A subtype defines the constraint and has a unique name
</p>
<p>that can be used to declare other signals. To use this approach for manually encoding the states of an
</p>
<p>FSM, we first declare a new subtype called State_Type that is simply a version of the existing type
</p>
<p>std_logic. We then create constants to represent the descriptive state names in the state diagram. These
</p>
<p>constants are given the type State_Type and a specific value. The value given is the state code we wish
</p>
<p>to assign to the particular state name. Finally, the current_state and next_state signals are declared of
</p>
<p>type State_Type. In this way, we can use the same VHDL processes as in the previous example that use
</p>
<p>the descriptive state names from the state diagram. The following is the VHDL syntax for manually
</p>
<p>assigning the state codes using subtypes. This syntax would replace the State_Type declaration in the
</p>
<p>previous example. Example 9.10 shows the resulting simulation waveforms:
</p>
<p>subtype State_Type is std_logic;
</p>
<p>constant w_open : State_Type :&frac14; &lsquo;0&rsquo;;
</p>
<p>constant w_closed : State_Type :&frac14; &lsquo;1&rsquo;;
</p>
<p>signal current_state, next_state : State_Type;
</p>
<p>Example 9.10
Push-Button Window Controller in VHDL&mdash;Explicit State Codes
</p>
<p>318 &bull; Chapter 9: Behavioral Modeling of Sequential Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>CC9.2 Why is it always a good design approach to model a generic finite state machine using 
three processes?
</p>
<p>A) For readability.
</p>
<p>B) So that it is easy to identify whether the machine is a Mealy or Moore.
</p>
<p>C) So that the state memory process can be re-used in other FSMs.
</p>
<p>D) Because each of the three sub-systems of a FSM has unique inputs and outputs 
that should be handled using dedicated processes.
</p>
<p>CONCEPT CHECK
</p>
<p>9.3 FSM Design Examples in VHDL
</p>
<p>This section presents a set of example finite-state machine designs using the behavioral modeling
</p>
<p>constructs of VHDL. These examples are the same state machines that were presented in Chap. 7.
</p>
<p>9.3.1 Serial Bit Sequence Detector in VHDL
</p>
<p>Let&rsquo;s look at the design of the serial bit sequence detector finite-state machine from Chap. 7 using
</p>
<p>the behavioral modeling constructs of VHDL. Example 9.11 shows the design description and entity
</p>
<p>definition for this state machine.
</p>
<p>Example 9.11
Serial Bit Sequence Detector in VHDL&mdash;Design Description and Entity Definition
</p>
<p>Example 9.12 shows the architecture for the serial bit sequence detector. In this example, a
</p>
<p>user-defined type is created to model the descriptive state names in the state diagram.
</p>
<p>9.3 FSM Design Examples in VHDL &bull; 319</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_7">http://dx.doi.org/10.1007/978-3-319-34195-8_7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_7">http://dx.doi.org/10.1007/978-3-319-34195-8_7</a></div>
</div>
<div class="page"><p/>
<p>Example 9.12
Serial Bit Sequence Detector in VHDL &ndash; Architecture
</p>
<p>Example 9.13 shows the functional simulation waveform for this design.
</p>
<p>Example 9.13
Serial Bit Sequence Detector in VHDL&mdash;Simulation Waveform
</p>
<p>320 &bull; Chapter 9: Behavioral Modeling of Sequential Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>9.3.2 Vending Machine Controller in VHDL
</p>
<p>Let&rsquo;s now look at the design of the vending machine controller from Chap. 7 using the behavioral
</p>
<p>modeling constructs of VHDL. Example 9.14 shows the design description and entity definition.
</p>
<p>Example 9.14
Vending Machine Controller in VHDL&mdash;Design Description and Entity Definition
</p>
<p>Example 9.15 shows the VHDL architecture for the vending machine controller. In this model, the
</p>
<p>descriptive state names Wait, 25&cent;, and 50&cent; cannot be used directly. This is because Wait is a VHDL
</p>
<p>keyword and user-defined names cannot begin with a number. Instead, the letter &ldquo;s&rdquo; is placed in front of
</p>
<p>the state names in order to make them legal VHDL names (i.e., sWait, s25, s50).
</p>
<p>9.3 FSM Design Examples in VHDL &bull; 321</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_7">http://dx.doi.org/10.1007/978-3-319-34195-8_7</a></div>
</div>
<div class="page"><p/>
<p>Example 9.15
Vending Machine Controller in VHDL&mdash;Architecture
</p>
<p>Example 9.16 shows the resulting simulation waveform for this design.
</p>
<p>322 &bull; Chapter 9: Behavioral Modeling of Sequential Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 9.16
Vending Machine Controller in VHDL&mdash;Simulation Waveform
</p>
<p>9.3.3 2-Bit, Binary Up/Down Counter in VHDL
</p>
<p>Let&rsquo;s now look at how a simple counter can be implemented using the three-process behavioral
</p>
<p>modeling approach in VHDL. Example 9.17 shows the design description and entity definition for the
</p>
<p>2-bit, binary up/down counter FSM from Chap. 7.
</p>
<p>Example 9.17
2-Bit Binary Up/Down Counter in VHDL&mdash;Design Description and Entity Definition
</p>
<p>Example 9.18 shows the architecture for the 2-bit up/down counter using the three-process
</p>
<p>modeling approach. Since a counter&rsquo;s outputs only depend on the current state, counters are Moore
</p>
<p>machines. This simplifies the output logic process since it only needs to contain the current state in its
</p>
<p>sensitivity list.
</p>
<p>9.3 FSM Design Examples in VHDL &bull; 323</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_7">http://dx.doi.org/10.1007/978-3-319-34195-8_7</a></div>
</div>
<div class="page"><p/>
<p>Example 9.18
2-Bit Binary Up/Down Counter in VHDL&mdash;Architecture (Three-Process Model)
</p>
<p>Example 9.19 shows the resulting simulation waveform for this counter finite-state machine.
</p>
<p>324 &bull; Chapter 9: Behavioral Modeling of Sequential Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 9.19
2-Bit Binary Up/Down Counter in VHDL&mdash;Simulation Waveform
</p>
<p>CC9.3 The state memory process is nearly identical for all finite state machines with one 
exception.  What is it?
</p>
<p>A) The sensitivity list may need to include a preset signal.
</p>
<p>B) Sometimes it is modeled using an SR latch storage approach instead of with D-
flip-flop behavior.
</p>
<p>C) The name of the reset state will be different.
</p>
<p>D) The current_state and next_state signals are often swapped.
</p>
<p>CONCEPT CHECK
</p>
<p>9.4 Modeling Counters in VHDL
</p>
<p>Counters are a special case of finite-state machines because they move linearly through their
</p>
<p>discrete states (either forward or backwards) and typically are implemented with state-encoded outputs.
</p>
<p>Due to this simplified structure and widespread use in digital systems, VHDL allows counters to be
</p>
<p>modeled using a single process and with arithmetic operators (i.e., + and �). This enables a more
</p>
<p>compact model and allows much wider counters to be implemented.
</p>
<p>9.4.1 Counters in VHDL Using the Type UNSIGNED
</p>
<p>Let&rsquo;s look at how we canmodel a 4-bit, binary up counter with an output calledCNT. First, we want to
</p>
<p>model this counter using the &ldquo;+&rdquo; operator. Recall that the &ldquo;+&rdquo; operator is not defined in the std_logic_1164
</p>
<p>package. We need to include the numeric_std package in order to add this capability. Within the
</p>
<p>numeric_std package, the &ldquo;+&rdquo; operator is only defined for types signed and unsigned (and not for
</p>
<p>std_logic_vector), so the output CNT will be declared as type unsigned. Next, we want to implement
</p>
<p>the counter using a signal assignment in the form CNT &lt;&frac14; CNT + 1; however, since CNT is an output
</p>
<p>port, it cannot be used as an argument (right hand side) in an operation. We will need to create an internal
</p>
<p>signal to implement the counter functionality (i.e., CNT_tmp). Since a signal does not contain direction-
</p>
<p>ality, it can be used as both the target and an argument of an operation. Outside of the counter process, a
</p>
<p>concurrent signal assignment is used to continuously assign CNT_tmp to CNT in order to drive the output
</p>
<p>of the system. This means that we need to create the internal signal CNT_tmp of type unsigned also to
</p>
<p>support this assignment. Example 9.20 shows the VHDL model and simulation waveform for this
</p>
<p>counter. When the counter reaches its maximum value of &ldquo;1111,&rdquo; it rolls over to &ldquo;0000&rdquo; and continues
</p>
<p>counting because it is defined to only contain 4-bits.
</p>
<p>9.4 Modeling Counters in VHDL &bull; 325</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 9.20
4-Bit Binary Up Counter in VHDL Using the Type UNSIGNED
</p>
<p>9.4.2 Counters in VHDL Using the Type INTEGER
</p>
<p>Another common technique to model counters with a single process is to use the type integer. The
</p>
<p>numeric_std package supports the &ldquo;+&rdquo; operator for type integer. It also contains a conversion between
</p>
<p>the types integer and unsigned/signed. This means a process can be created to model the counter
</p>
<p>functionality with integers and then the result can be converted and assigned to the output of the system
</p>
<p>of type unsigned. One thing that must be considered when using integers is that they are defined as
</p>
<p>32-bit, two&rsquo;s complement numbers. This means that if a counter is defined to use integers and the
</p>
<p>maximum range of the counter is not explicitly controlled, the counter will increment through the entire
</p>
<p>range of 32-bit values it can take on. There are a variety of ways to explicitly bound the size of an integer
</p>
<p>counter. The first is to use an if/then clause within the process to check for the upper limit desired in the
</p>
<p>counter. For example, if we wish to create a 4-bit binary counter, we will check if the integer counter has
</p>
<p>reached 15 each time through the process. If it has, we will reset it to zero. Synthesizers will recognize
</p>
<p>that the integer counter is never allowed to exceed 15 (or &ldquo;1111&rdquo; for an unsigned counter) and remove the
</p>
<p>unused bits of the integer type during implementation (i.e., the remaining 28-bits). Example 9.21 shows
</p>
<p>the VHDL model and simulation waveform for this implementation of the 4-bit counter using integers.
</p>
<p>326 &bull; Chapter 9: Behavioral Modeling of Sequential Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 9.21
4-Bit Binary Up Counter in VHDL Using the Type INTEGER
</p>
<p>9.4.3 Counters in VHDL Using the Type STD_LOGIC_VECTOR
</p>
<p>It is often desired to have the ports of a system be defined of type std_logic/std_logic_vector for
</p>
<p>compatibility with other systems. One technique to accomplish this and also model the counter behavior
</p>
<p>internally using std_logic_vector is through inclusion of the numeric_std_unsigned package. This pack-
</p>
<p>age allows the use of std_logic_vector when declaring the ports and signals within the design and treats
</p>
<p>them as unsigned when performing arithmetic and comparison functions. Example 9.22 shows the
</p>
<p>VHDL model and simulation waveform for this alternative implementation of the 4-bit counter.
</p>
<p>9.4 Modeling Counters in VHDL &bull; 327</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 9.22
4-Bit Binary Up Counter in VHDL Using the Type STD_LOGIC_VECTOR (1)
</p>
<p>If it is designed to have an output type of std_logic_vector and use an integer in modeling the
</p>
<p>behavior of the counter, then a double conversion can be used. In the following example, the counter
</p>
<p>behavior is modeled using an integer type with range checking. A concurrent signal assignment is used
</p>
<p>at the end of the architecture in order to convert the integer to type std_logic_vector. This is accom-
</p>
<p>plished by first converting the type integer to unsigned and then converting the type unsigned to
</p>
<p>std_logic_vector. Example 9.23 shows the VHDL model and simulation waveform for this alternative
</p>
<p>implementation of the 4-bit counter.
</p>
<p>328 &bull; Chapter 9: Behavioral Modeling of Sequential Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 9.23
4-Bit Binary Up Counter in VHDL Using the Type STD_LOGIC_VECTOR (2)
</p>
<p>9.4.4 Counters with Enables in VHDL
</p>
<p>Including an enable in a counter is a common technique to prevent the counter from running
</p>
<p>continuously. When the enable is asserted, the counter will increment on the rising edge of the clock
</p>
<p>as usual. When the enable is de-asserted, the counter will simply hold its last value. Enable lines are
</p>
<p>synchronous, meaning that they are only evaluated on the rising edge of the clock. As such, they are
</p>
<p>modeled using a nested if/then statement within the if/then statement checking for a rising edge of the
</p>
<p>clock. Example 9.24 shows an example model for a 4-bit counter with enable.
</p>
<p>9.4 Modeling Counters in VHDL &bull; 329</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 9.24
4-Bit Binary Up Counter with Enable in VHDL
</p>
<p>9.4.5 Counters with Loads
</p>
<p>A counter with a load has the ability to set the counter to a specified value. The specified value is
</p>
<p>provided on an input port (i.e., CNT_in) with the same width as the counter output (CNT). A synchronous
</p>
<p>load input signal (i.e., Load) is used to indicate when the counter should set its value to the value present
</p>
<p>on CNT_in. Example 9.25 shows an example model for a 4-bit counter with load capability.
</p>
<p>330 &bull; Chapter 9: Behavioral Modeling of Sequential Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 9.25
4-Bit Binary Up Counter with Load in VHDL
</p>
<p>CC9.4 If a counter is modeled using only one process in VHDL, is it still a finite state machine?  
Why or why not?
</p>
<p>A) Yes.  It is just a special case of a FSM that can easily be modeled using one 
process.  Synthesizers will recognize the single process model as a FSM.
</p>
<p>B) No.  Using only one process will synthesize into combinational logic.  Without the 
ability to store a state, it is not a finite state machine.
</p>
<p>CONCEPT CHECK
</p>
<p>9.4 Modeling Counters in VHDL &bull; 331</p>
<p/>
</div>
<div class="page"><p/>
<p>9.5 RTL Modeling
</p>
<p>Register Transfer Level modeling refers to a level of design abstraction in which vector data is
</p>
<p>moved and operated on in a synchronous manner. This design methodology is widely used in data path
</p>
<p>modeling and computer system design.
</p>
<p>9.5.1 Modeling Registers in VHDL
</p>
<p>The term register describes a circuit that operates in a similar manner as a D-flip-flop with the
</p>
<p>exception that the input and output data are vectors. This circuit is implemented with a set of D-flip-flops
</p>
<p>all connected to the same clock, reset, and enable inputs. A register is a higher level of abstraction that
</p>
<p>allows vector data to be stored without getting into the details of the lower level implementation of the D-
</p>
<p>flip-flop components. Example 9.26 shows an RTL model of an 8-bit, synchronous register. This circuit
</p>
<p>has an active low, asynchronous reset that will cause the 8-bit output Reg_Out to go to 0 when it is
</p>
<p>asserted. When the reset is not asserted, the output will be updated with the 8-bit input Reg_In if the
</p>
<p>system is enabled (EN &frac14; 1) and there is a rising edge on the clock. If the register is disabled (EN &frac14; 0),
</p>
<p>the input clock is ignored. At all other times, the output holds its last value.
</p>
<p>Example 9.26
RTL Model of an 8-Bit Register in VHDL
</p>
<p>332 &bull; Chapter 9: Behavioral Modeling of Sequential Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>9.5.2 Shift Registers in VHDL
</p>
<p>A shift register is a circuit which consists of multiple registers connected in series. Data is shifted
</p>
<p>from one register to another on the rising edge of the clock. This type of circuit is often used in serial-to-
</p>
<p>parallel data converters. Example 9.27 shows an RTL model for a 4-stage, 8-bit shift register. In the
</p>
<p>simulation waveform, the data is shown in hexadecimal format.
</p>
<p>Example 9.27
RTL Model of a 4-Stage, 8-Bit Shift Register in VHDL
</p>
<p>9.5 RTL Modeling &bull; 333</p>
<p/>
</div>
<div class="page"><p/>
<p>9.5.3 Registers as Agents on a Data Bus
</p>
<p>One of the powerful topologies that registers can easily model is a multi-drop bus. In this topology,
</p>
<p>multiple registers are connected to a data bus as receivers or agents. Each agent has an enable line that
</p>
<p>controls when it latches information from the data bus into its storage elements. This topology is
</p>
<p>synchronous, meaning that each agent and the driver of the data bus ar connected to the same
</p>
<p>clock signal. Each agent has a dedicated, synchronous enable line that is provided by a system
</p>
<p>controller elsewhere in the design. Example 9.28 shows this multi-drop bus topology. In this example
</p>
<p>system, three registers (A, B, and C) are connected to a data bus as receivers. Each register is
</p>
<p>connected to the same clock and reset signals. Each register has its own dedicated enable line
</p>
<p>(A_EN, B_EN, and C_EN).
</p>
<p>Example 9.28
Registers as Agents on a Data Bus&mdash;System Topology
</p>
<p>This topology can be modeled using RTL abstraction by treating each register as a separate
</p>
<p>process. Example 9.29 shows how to describe this topology with an RTL model in VHDL. Notice that
</p>
<p>the three processes modeling the A, B, and C registers are nearly identical to each other with the
</p>
<p>exception of the signal names they use.
</p>
<p>334 &bull; Chapter 9: Behavioral Modeling of Sequential Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 9.29
Registers as Agents on a Data Bus&mdash;RTL Model in VHDL
</p>
<p>Example 9.30 shows the resulting simulation waveform for this system. Each register is updated
</p>
<p>with the value on the data bus whenever its dedicated enable line is asserted.
</p>
<p>9.5 RTL Modeling &bull; 335</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 9.30
Registers as Agents on a Data Bus&mdash;Simulation Waveform
</p>
<p>CC9.5 Does RTL modeling synthesize as combinational logic, sequential logic, or both?  Why?
</p>
<p>A) Combinational logic.  Since only one process is used for each register, it will be 
synthesized using basic gates.
</p>
<p>B) Sequential logic.  Since the sensitivity list contains clock and reset, it will 
synthesize into only D-flip-flops.
</p>
<p>C) Both.  The model has a sensitivity list containing clock and reset and uses an 
if/then statement indicative of a D-flip-flop.  This will synthesize a D-flip-flop to 
hold the value for each bit in the register.  In addition, the ability to manipulate the 
inputs into the register (using either logical operators, arithmetic operators, or 
choosing different signals to latch) will synthesize into combinational logic in front 
of the D input to each D-flip-flop.
</p>
<p>CONCEPT CHECK
</p>
<p>Summary
</p>
<p>v A synchronous system is modeled with a
process and a sensitivity list. The clock and
reset signals are always listed by themselves
in the sensitivity list. Within the process is an
if/then statement. The first clause of the
if/then statement handles the asynchronous
reset condition while the second elsif clause
handles the synchronous signal
assignments.
</p>
<p>v Edge sensitivity is modeled within a process
using either the (clock&rsquo;event and clock &frac14; &ldquo;1&rdquo;)
syntax or an edge detection function
provided by the STD_LOGIC_1164 package
(i.e., rising_edge()).
</p>
<p>v Most D-flip-flops and registers contain a syn-
chronous enable line. This is modeled using
a nested if/then statement within the main
process if/then statement. The nested if/then
goes beneath the clause for the synchronous
signal assignments.
</p>
<p>v Generic finite-state machines are modeled
using three separate processes that describe
the behavior of the next state logic, the state
memory, and the output logic. Separate pro-
cesses are used because each of the three
functions in an FSM are dependent on differ-
ent input signals.
</p>
<p>v In VHDL, descriptive state names can be
created for an FSM with a user-defined,
enumerated data type. The new type is first
declared and each of the descriptive state
names are provided that the new data type
can take on. Two signals are then created
called current_state and next_state using
the new data type. These two signals can
then be assigned the descriptive state
names of the FSM directly. This approach
allows the synthesizer to assign the state
codes arbitrarily. A subtype can be used if it
is desired to explicitly define the state codes.
</p>
<p>336 &bull; Chapter 9: Behavioral Modeling of Sequential Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>v Counters are a special type of finite-state
machine that can be modeled using a single
process. Only the clock and reset signals are
listed in the sensitivity list of the counter
process.
</p>
<p>v Registers are modeled in VHDL in a similar
manner to a D-flip-flop with a synchronous
enable. The only difference is that the inputs
and outputs are n-bit vectors.
</p>
<p>Exercise Problems
</p>
<p>Section 9.1&mdash;Modeling Sequential Stor-
</p>
<p>age Devices in VHDL
</p>
<p>9.1.1 How does a VHDL model for a D-flip-flop han-
dle treating reset as the highest priority input?
</p>
<p>9.1.2 For a VHDL model of a D-flip-flop with a syn-
chronous enable (EN), why isn&rsquo;t EN listed in
the sensitivity list?
</p>
<p>9.1.3 For a VHDL model of a D-flip-flop with a syn-
chronous enable (EN), what is the impact of
listing EN in the sensitivity list?
</p>
<p>9.1.4 For a VHDL model of a D-flip-flop with a syn-
chronous enable (EN), why is the behavior of
the enable modeled using a nested if/then
statement under the clock edge clause rather
than an additional elsif clause in the primary
if/then statement?
</p>
<p>Section 9.2&mdash;Modeling Finite-State
</p>
<p>Machines in VHDL
</p>
<p>9.2.1 What is the advantage of using user-defined,
enumerated data types for the states when
modeling a finite-state machine?
</p>
<p>9.2.2 What is the advantage of using subtypes for
the states when modeling a finite-state
machine?
</p>
<p>9.2.3 When using the three-process behavioral
modeling approach for finite-state machines,
does the next state logic process model com-
binational or sequential logic?
</p>
<p>9.2.4 When using the three-process behavioral
modeling approach for finite state machines,
does the state memory process model combi-
national or sequential logic?
</p>
<p>9.2.5 When using the three-process behavioral
modeling approach for finite state machines,
does the output logic process model combina-
tional or sequential logic?
</p>
<p>9.2.6 When using the three-process behavioral
modeling approach for finite state machines,
what inputs are listed in the sensitivity list of
the next state logic process?
</p>
<p>9.2.7 When using the three-process behavioral
modeling approach for finite state machines,
what inputs are listed in the sensitivity list of
the state memory process?
</p>
<p>9.2.8 When using the three-process behavioral
modeling approach for finite state machines,
what inputs are listed in the sensitivity list of
the output logic process?
</p>
<p>9.2.9 When using the three-process behavioral
modeling approach for finite state machines,
how can the signals listed in the sensitivity list
of the output logic process immediately tell
whether the FSM is a Mealy or a Moore
machine?
</p>
<p>9.2.10 Why is it not a good design approach to com-
bine the next state logic and output logic
behavior into a single process?
</p>
<p>Section 9.3&mdash;FSM Design Examples in
</p>
<p>VHDL
</p>
<p>9.3.1 Design a VHDL behavioral model to implement
the finite-state machine described by the state
diagram in Fig. 9.1. Use the entity definition
provided in this figure for your design. Use
the three-process approach to modeling
FSMs described in this chapter for your design.
Model the states in this machine with a user-
defined enumerated type.
</p>
<p>9.3.2 Design a VHDL behavioral model to implement
the finite-state machine described by the state
diagram in Fig. 9.1. Use the entity definition
provided in this figure for your design. Use
the three-process approach to modeling
FSMs described in this chapter for your design.
Explicitly assign binary state codes using
VHDL subtypes. Use the following state
codes: Start &frac14; &ldquo;00,&rdquo; Midway &frac14; &ldquo;01,&rdquo;
Done &frac14; &ldquo;10.&rdquo;
</p>
<p>9.3.3 Design a VHDL behavioral model to implement
the finite-state machine described by the state
</p>
<p>Fig. 9.1
FSM 1 State Diagram and Entity
</p>
<p>Exercise Problems &bull; 337</p>
<p/>
</div>
<div class="page"><p/>
<p>diagram in Fig. 9.2. Use the entity definition
provided in this figure for your design. Use
the three-process approach to modeling
FSMs described in this chapter for your design.
Model the states in this machine with a user-
defined enumerated type.
</p>
<p>9.3.4 Design a VHDL behavioral model to implement
the finite-state machine described by the state
diagram in Fig. 9.2. Use the entity definition
provided in this figure for your design. Use
the three-process approach to modeling
FSMs described in this chapter for your design.
Assign one-hot state codes using VHDL
subtypes. Use the following state codes:
S0 &frac14; &ldquo;0001,&rdquo; S1 &frac14; &ldquo;0010,&rdquo; S2 &frac14; &ldquo;0100,&rdquo;
S3 &frac14; &ldquo;1000.&rdquo;
</p>
<p>9.3.5 Design a VHDL behavioral model for a 4-bit
serial bit sequence detector similar to Example
9.11. Use the entity definition provided in
Fig. 9.3. Use the three-process approach to
modeling FSMs described in this chapter for
your design. The input to your sequence detec-
tor is called DIN and the output is called
FOUND. Your detector will assert FOUND any-
time there is a 4-bit sequence of &ldquo;0101.&rdquo; For all
other input sequences the output is not
asserted. Model the states in your machine
with a user-defined enumerated type.
</p>
<p>9.3.6 Design a VHDL behavioral model for a 20-cent
vending machine controller similar to Example
9.14. Use the entity definition provided in
Fig. 9.4. Use the three-process approach to
modeling FSMs described in this chapter for
</p>
<p>your design. Your controller will take in nickels
and dimes and dispense a product anytime the
customer has entered 20 cents. Your FSM has
two inputs, Nin and Din. Nin is asserted when-
ever the customer enters a nickel while Din is
asserted anytime the customer enters a dime.
Your FSM has two outputs, Dispense and
Change. Dispense is asserted anytime the
customer has entered at least 20 cents and
Change is asserted anytime the customer has
entered more than 20 cents and needs a nickel
in change. Model the states in this machine
with a user-defined enumerated type.
</p>
<p>9.3.7 Design a VHDL behavioral model for a finite-
state machine for a traffic light controller. Use
the entity definition provided in Fig. 9.5. This is
the same problem description as in exercise
7.4.15. This time, you will implement the func-
tionality using the behavioral modeling
techniques presented in this chapter. Your
FSMwill control a traffic light at the intersection
of a busy highway and a seldom used side
road. You will be designing the control signals
for just the red, yellow, and green lights facing
the highway. Under normal conditions, the
highway has a green light. The side road has
car detector that indicates when car pulls up by
asserting a signal called CAR. When CAR is
asserted, you will change the highway traffic
light from green to yellow, and then from yellow
to red. Once in the red position, a built-in timer
will begin a countdown and provide your con-
troller a signal called TIMEOUTwhen 15 s has
passed. Once TIMEOUT is asserted, you will
change the highway traffic light back to green.
Your system will have three outputs GRN,
YLW, and RED, which control when the high-
way facing traffic lights are on (1 &frac14; ON,
0 &frac14; OFF). Model the states in this machine
with a user-defined enumerated type.
</p>
<p>Section 9.4&mdash;Modeling Counters in VHDL
</p>
<p>9.4.1 Design a VHDL behavioral model for a 16-bit,
binary up counter using a single process. The
block diagram for the entity definition is shown
in Fig. 9.6. In your model, declare Count_Out
to be of type unsigned and implement the
</p>
<p>Fig. 9.3
Sequence Detector Entity
</p>
<p>Fig. 9.2
FSM 2 State Diagram and Entity
</p>
<p>Fig. 9.5
Traffic Light Controller Entity
</p>
<p>Fig. 9.4
Vending Machine Entity
</p>
<p>338 &bull; Chapter 9: Behavioral Modeling of Sequential Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>internal counter functionality with a signal of
type unsigned.
</p>
<p>9.4.2 Design a VHDL behavioral model for a 16-bit,
binary up counter using a single process. The
block diagram for the entity definition is shown
in Fig. 9.6. In your model, declare Count_Out
to be of type unsigned and implement the inter-
nal counter functionality with a signal of type
integer.
</p>
<p>9.4.3 Design a VHDL behavioral model for a 16-bit,
binary up counter using a single process. The
block diagram for the entity definition is shown
in Fig. 9.6. In your model, declare Count_Out
to be of type std_logic_vector and implement
the internal counter functionality with a signal
of type integer.
</p>
<p>9.4.4 Design a VHDL behavioral model for a 16-bit,
binary up counter with enable using a single
process. The block diagram for the entity defi-
nition is shown in Fig. 9.7. In your model,
declare Count_Out to be of type unsigned
and implement the internal counter functional-
ity with a signal of type unsigned.
</p>
<p>9.4.5 Design a VHDL behavioral model for a 16-bit,
binary up counter with enable using a single
process. The block diagram for the entity defi-
nition is shown in Fig. 9.7. In your model,
declare Count_Out to be of type unsigned
and implement the internal counter functional-
ity with a signal of type integer.
</p>
<p>9.4.6 Design a VHDL behavioral model for a 16-bit,
binary up counter with enable using a single
process. The block diagram for the entity defini-
tion is shown in Fig. 9.7. In your model, declare
Count_Out to be of type std_logic_vector and
implement the internal counter functionality with
a signal of type integer.
</p>
<p>9.4.7 Design a VHDL behavioral model for a 16-bit,
binary up counter with enable and load using a
single process. The block diagram for the entity
definition is shown in Fig. 9.8. In your model,
declare Count_Out to be of type unsigned and
implement the internal counter functionality
with a signal of type unsigned.
</p>
<p>9.4.8 Design a VHDL behavioral model for a 16-bit,
binary up counter with enable and load using a
single process. The block diagram for the entity
definition is shown in Fig. 9.8. In your model,
declare Count_Out to be of type unsigned and
implement the internal counter functionality
with a signal of type integer.
</p>
<p>9.4.9 Design a VHDL behavioral model for a 16-bit,
binary up counter with enable and load using a
single process. The block diagram for the entity
definition is shown in Fig. 9.8. In your model,
declare Count_Out to be of type
std_logic_vector and implement the internal
counter functionality with a signal of type
integer.
</p>
<p>9.4.10 Design a VHDL behavioral model for a 16-bit,
binary up/down counter using a single process.
The block diagram for the entity definition is
shown in Fig. 9.9. When Up &frac14; 1, the counter
will increment. When Up &frac14; 0, the counter will
decrement. In your model, declare Count_Out
to be of type unsigned and implement the inter-
nal counter functionality with a signal of type
unsigned.
</p>
<p>9.4.11 Design a VHDL behavioral model for a 16-bit,
binary up/down counter using a single process.
The block diagram for the entity definition is
shown in Fig. 9.9. When Up &frac14; 1, the counter
will increment. When Up &frac14; 0, the counter will
decrement. In your model, declare Count_Out
to be of type unsigned and implement the inter-
nal counter functionality with a signal of type
integer.
</p>
<p>9.4.12 Design a VHDL behavioral model for a 16-bit,
binary up/down counter using a single process.
The block diagram for the entity definition is
shown in Fig. 9.9. When Up &frac14; 1, the counter
will increment. When Up &frac14; 0, the counter will
decrement. In your model, declare Count_Out
to be of type std_logic_vector and implement
the internal counter functionality with a signal
of type integer.
</p>
<p>Fig. 9.9
16-Bit Binary Up/Down Counter Block
Diagram
</p>
<p>Fig. 9.7
16-Bit Binary Counter with Enable Block
Diagram
</p>
<p>Fig. 9.6
16-Bit Binary Up Counter Block Diagram
</p>
<p>Fig. 9.8
16-Bit Binary Counter with Load Block
Diagram
</p>
<p>Exercise Problems &bull; 339</p>
<p/>
</div>
<div class="page"><p/>
<p>Section 9.5&mdash;RTL Modeling
</p>
<p>9.5.1 In register transfer level modeling, how does
the width of the register relate to the number of
D-flip-flops that will be synthesized?
</p>
<p>9.5.2 In register transfer level modeling, how is the
synchronous data movement managed if all
registers are using the same clock?
</p>
<p>9.5.3 Design a VHDL RTL model of a 32-bit, syn-
chronous register. The block diagram for the
entity definition is shown in Fig. 9.10. The reg-
ister has a synchronous enable. The register
should be modeled using a single process.
</p>
<p>9.5.4 Design a VHDL RTL model of an 8-stage,
16-bit shift register. The block diagram for the
entity definition is shown in Fig. 9.11. Each
stage of the shift register will be provided as
an output of the system (A, B, C, D, E, F, G, and
H). Use std_logic or std_logic_vector for all
ports.
</p>
<p>9.5.5 Design a VHDL RTL model of the multi-drop
bus topology in Fig. 9.12. Each of the 16-bit
registers (RegA, RegB, RegC, and RegD) will
latch the contents of the 16-bit data bus if their
enable line is asserted. Each register should
be modeled using an individual process.
</p>
<p>Fig. 9.12
Agents on a Bus Block Diagram
</p>
<p>Fig. 9.10
32-Bit Register Block Diagram
</p>
<p>Fig. 9.11
16-Bit Shift Register Block Diagram
</p>
<p>340 &bull; Chapter 9: Behavioral Modeling of Sequential Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 10: Memory
This chapter introduces the basic concepts, terminology, and roles of memory in digital systems.
</p>
<p>The material presented here will not delve into the details of the device physics or low-level theory of
</p>
<p>operation. Instead, the intent of this chapter is to give a general overview of memory technology and its
</p>
<p>use in computer systems in addition to how to model memory in VHDL. The goal of this chapter is to give
</p>
<p>an understanding of the basic principles of semiconductor-based memory systems.
</p>
<p>Learning Outcomes&mdash;After completing this chapter, you will be able to:
</p>
<p>10.1 Describe the basic architecture and terminology for semiconductor-based memory
systems.
</p>
<p>10.2 Describe the basic architecture of nonvolatile memory systems.
10.3 Describe the basic architecture of volatile memory systems.
10.4 Design a VHDL behavioral model of a memory system.
</p>
<p>10.1 Memory Architecture and Terminology
</p>
<p>The termmemory is used to describe a system with the ability to store digital information. The term
</p>
<p>semiconductor memory refers to systems that are implemented using integrated circuit technology.
</p>
<p>These types of systems store the digital information using transistors, fuses, and/or capacitors on a
</p>
<p>single semiconductor substrate. Memory can also be implemented using technology other than
</p>
<p>semiconductors. Disk drives store information by altering the polarity of magnetic fields on a circular
</p>
<p>substrate. The two magnetic polarities (north and south) are used to represent different logic values (i.e.,
</p>
<p>0 or 1). Optical disks use lasers to burn pits into reflective substrates. The binary information is
</p>
<p>represented by light either being reflected (no pit) or not reflected (pit present). Semiconductor memory
</p>
<p>does not have any moving parts, so it is called solid-state memory and can hold more information per unit
</p>
<p>area than disk memory. Regardless of the technology used to store the binary data, all memory has
</p>
<p>common attributes and terminology that are discussed in this chapter.
</p>
<p>10.1.1 Memory Map Model
</p>
<p>The information stored in memory is called the data. When information is placed into memory, it is
</p>
<p>called a write. When information is retrieved from memory, it is called a read. In order to access data in
</p>
<p>memory, an address is used. While data can be accessed as individual bits, in order to reduce the
</p>
<p>number of address locations needed, data is typically grouped into N-bit words. If a memory system has
</p>
<p>N &frac14; 8, this means that 8 bits of data are stored at each address. The number of address locations is
</p>
<p>described using the variable M. The overall size of the memory is typically stated by saying "MxN." For
</p>
<p>example, if we had a 16 � 8 memory system, that means that there are 16 address locations, each
</p>
<p>capable of storing a byte of data. This memory would have a capacity of 16 � 8 &frac14; 128 bits. Since the
</p>
<p>address is implemented as a binary code, the number of lines in the address bus (n) will dictate the
</p>
<p>number of address locations that the memory system will have (M &frac14; 2n). Figure 10.1 shows a graphical
</p>
<p>depiction of how data resides in memory. This type of graphic is called a memory map model.
</p>
<p># Springer International Publishing Switzerland 2017
</p>
<p>B.J. LaMeres, Introduction to Logic Circuits &amp; Logic Design with VHDL,
</p>
<p>DOI 10.1007/978-3-319-34195-8_10
</p>
<p>341</p>
<p/>
</div>
<div class="page"><p/>
<p>10.1.2 Volatile vs. Nonvolatile Memory
</p>
<p>Memory is classified into two categories depending on whether it can store information when power
</p>
<p>is removed or not. The term nonvolatile is used to describe memory that holds information when the
</p>
<p>power is removed, while the term volatile is used to describe memory that loses its information when
</p>
<p>power is removed. Historically, volatile memory is able to run at faster speeds compared to nonvolatile
</p>
<p>memory, so it is used as the primary storage mechanism while a digital system is running. Nonvolatile
</p>
<p>memory is necessary in order to hold critical operation information for a digital system such as start-up
</p>
<p>instructions, operations systems, and applications.
</p>
<p>10.1.3 Read-Only vs. Read/Write Memory
</p>
<p>Memory can also be classified into two categories with respect to how data is accessed. Read-only
</p>
<p>memory (ROM) is a device that cannot be written to during normal operation. This type of memory is
</p>
<p>useful for holding critical system information or programs that should not be altered while the system is
</p>
<p>running. Read/write memory refers to memory that can be read and written to during normal operation
</p>
<p>and is used to hold temporary data and variables.
</p>
<p>10.1.4 Random Access vs. Sequential Access
</p>
<p>Random access memory (RAM) describes memory in which any location in the system can be
</p>
<p>accessed at any time. The opposite of this is sequential access memory, in which not all address
</p>
<p>locations are immediately available. An example of a sequential access memory system is a tape drive.
</p>
<p>In order to access the desired address in this system, the tape spool must be spun until the address is in
</p>
<p>a position that can be observed. Most semiconductor memory in modern systems is random access. The
</p>
<p>terms RAM and ROM have been adopted, somewhat inaccurately, to also describe groups of memory
</p>
<p>with particular behavior. While the term ROM technically describes a system that cannot be written to, it
</p>
<p>has taken on the additional association of being the term to describe nonvolatile memory. While the term
</p>
<p>RAM technically describes how data is accessed, it has taken on the additional association of being the
</p>
<p>term to describe volatile memory. When describing modern memory systems, the terms RAM and ROM
</p>
<p>are used most commonly to describe the characteristics of the memory being used; however, modern
</p>
<p>memory systems can be both read/write and nonvolatile, and the majority of memory is random access.
</p>
<p>CC10.1 An 8-bit wide memory has 8 address lines.  What is its capacity in bits?
</p>
<p>A) 64 B) 256 C) 1024 D) 2048
</p>
<p>CONCEPT CHECK
</p>
<p>Fig. 10.1
Memory map model
</p>
<p>342 &bull; Chapter 10: Memory</p>
<p/>
</div>
<div class="page"><p/>
<p>10.2 Nonvolatile Memory Technology
</p>
<p>10.2.1 ROM Architecture
</p>
<p>This section describes some of the most common nonvolatile memory technologies used to store
</p>
<p>digital information. An address decoder is used to access individual data words within the memory
</p>
<p>system. The address decoder asserts one and only one word line (WL) for each unique binary address
</p>
<p>that is present on its input. This operation is identical to a binary-to-one-hot decoder. For an n-bit
</p>
<p>address, the decoder can access 2n, or M words in memory. The word lines historically run horizontally
</p>
<p>across the memory array; thus they are often called row lines and the word line decoder is often called
</p>
<p>the row decoder. Bit lines (BL) run perpendicular to the word lines in order to provide individual bit storage
</p>
<p>access at the intersection of the bit and word lines. These lines typically run vertically through the
</p>
<p>memory array; thus they are often called column lines. The output of the memory system (i.e., Data_Out)
</p>
<p>is obtained by providing an address and then reading the word from buffered versions of the bit lines.
</p>
<p>When a system provides individual bit access to a row, or access to multiple data words sharing a row
</p>
<p>line, a column decoder is used to route the appropriate bit line(s) to the data out port.
</p>
<p>In a traditional ROM array, each bit line contains a pull-up network to VCC. This provides the ability to
</p>
<p>store a logic 1 at all locations within the array. If a logic 0 is desired at a particular location, an NMOS pull-
</p>
<p>down transistor is inserted. The gate of the NMOS is connected to the appropriate word line and the drain
</p>
<p>of the NMOS is connected to the bit line. When reading, the word line is asserted and turns on the NMOS
</p>
<p>transistor. This pulls the bit line to GND and produces a logic 0 on the output. When the NMOS transistor
</p>
<p>is excluded, the bit line remains at a logic 1 due to the pull-up network. Figure 10.2 shows the basic
</p>
<p>architecture of a ROM.
</p>
<p>10.2 Nonvolatile Memory Technology &bull; 343</p>
<p/>
</div>
<div class="page"><p/>
<p>Figure 10.3 shows the operation of a ROM when information is being read.
</p>
<p>Fig. 10.2
Basic architecture of read-only memory (ROM)
</p>
<p>344 &bull; Chapter 10: Memory</p>
<p/>
</div>
<div class="page"><p/>
<p>Memory can be designed to be either asynchronous or synchronous. Asynchronous memory
</p>
<p>updates its data outputs immediately upon receiving an address. Synchronous memory only updates
</p>
<p>its data outputs on the rising edge of a clock. The term latency is used to describe the delay between
</p>
<p>when a signal is sent to the memory (either the address in an asynchronous system or the clock in a
</p>
<p>synchronous system) and when the data is available. Figure 10.4 shows a comparison of the timing
</p>
<p>diagrams between asynchronous and synchronous ROM systems during a read cycle.
</p>
<p>Fig. 10.3
ROM operation during a read
</p>
<p>10.2 Nonvolatile Memory Technology &bull; 345</p>
<p/>
</div>
<div class="page"><p/>
<p>10.2.2 Mask Read-Only Memory
</p>
<p>A mask read-only memory (MROM) is a nonvolatile device that is programmed during fabrication.
</p>
<p>The termmask refers to a transparent plate that contains patterns to create the features of the devices on
</p>
<p>an integrated circuit using a process called photolithography. An MROM is fabricated with all of the
</p>
<p>features necessary for the memory device with the exception of the final connections between the NMOS
</p>
<p>transistors and the word and bit lines. This allows the majority of the device to be created prior to knowing
</p>
<p>what the final information to be stored is. Once the desired information to be stored is provided by the
</p>
<p>customer, the fabrication process is completed by adding connections between certain NMOS
</p>
<p>transistors and the word/bit lines in order to create logic 0s. Figure 10.5 shows an overview of the
</p>
<p>MROM programming process.
</p>
<p>Fig. 10.4
Asynchronous vs. synchronous ROM operation during a read cycle
</p>
<p>346 &bull; Chapter 10: Memory</p>
<p/>
</div>
<div class="page"><p/>
<p>10.2.3 Programmable Read-Only Memory
</p>
<p>A programmable read-only memory (PROM) is created in a similar manner as an MROM except that
</p>
<p>the programming is accomplished post-fabrication through the use of fuses or anti-fuses. A fuse is an
</p>
<p>electrical connection that is normally conductive. When a certain amount of current is passed through the
</p>
<p>fuse it will melt, or blow, and create an open circuit. The amount of current necessary to open the fuse is
</p>
<p>much larger than the current the fuse would conduct during normal operation. An anti-fuse operates in
</p>
<p>the opposite manner as a fuse. An anti-fuse is normally an open circuit. When a certain amount of current
</p>
<p>is forced into the anti-fuse, the insulating material breaks down and creates a conduction path. This turns
</p>
<p>the anti-fuse from an open circuit into a wire. Again, the amount of current necessary to close the anti-
</p>
<p>fuse is much larger than the current the anti-fuse would experience during normal operation. A PROM
</p>
<p>uses fuses or anti-fuses in order to connect/disconnect the NMOS transistors in the ROM array to the
</p>
<p>word/bit lines. A PROM programmer is used to burn the fuses or anti-fuses. A PROM can only be
</p>
<p>programmed once in this manner; thus it is a ROM and nonvolatile. A PROM has the advantage that
</p>
<p>programming can take place quickly as opposed to an MROM that must be programmed through device
</p>
<p>fabrication. Figure 10.6 shows an example PROM device based on fuses.
</p>
<p>Fig. 10.5
MROM overview
</p>
<p>10.2 Nonvolatile Memory Technology &bull; 347</p>
<p/>
</div>
<div class="page"><p/>
<p>10.2.4 Erasable Programmable Read-Only Memory
</p>
<p>As an improvement to the one-time programming characteristic of PROMs, an electrically program-
</p>
<p>mable ROM with the ability to be erased with ultraviolet (UV) light was created. The erasable program-
</p>
<p>mable read-only memory (EPROM) is based on a floating-gate transistor. In a floating-gate transistor,
</p>
<p>an additional metal oxide structure is added to the gate of an NMOS. This has the effect of increasing the
</p>
<p>threshold voltage. The geometry of the second metal oxide is designed such that the threshold voltage is
</p>
<p>high enough that normal CMOS logic levels are not able to turn the transistor on (i.e., VT1 &gt; VCC). This
</p>
<p>threshold can be changed by applying a large electric field across the two metal structures in the gate.
</p>
<p>This causes charge to tunnel into the secondary oxide, ultimately changing it into a conductor. This
</p>
<p>phenomenon is called Fowler&ndash;Nordheim tunneling. The new threshold voltage is low enough that normal
</p>
<p>CMOS logic levels are not able to turn the transistors off (i.e., VT2 &lt; GND). This process is how the
</p>
<p>device is programmed. This process is accomplished using a dedicated programmer; thus the EPROM
</p>
<p>must be removed from its system to program. Figure 10.7 shows an overview of a floating-gate transistor
</p>
<p>and how it is programmed.
</p>
<p>Fig. 10.6
PROM overview
</p>
<p>348 &bull; Chapter 10: Memory</p>
<p/>
</div>
<div class="page"><p/>
<p>In order to change the floating-gate transistor back into its normal state, the device is exposed to a
</p>
<p>strong ultraviolet light source. When the UV light strikes the trapped charge in the secondary oxide, it
</p>
<p>transfers enough energy to the charge particles that they can move back into the metal plates in the gate.
</p>
<p>This, in effect, erases the device and restores it back to a state with a high threshold voltage. EPROMs
</p>
<p>contain a transparent window on the top of their package that allows the UV light to strike the devices.
</p>
<p>The EPROMmust be removed from its system to perform the erase procedure. When the UV light erase
</p>
<p>procedure is performed, every device in the memory array is erased. EPROMs are a significant
</p>
<p>improvement over PROMs because they can be programmed multiple times; however, the programming
</p>
<p>and erase procedures are manually intensive and require an external programmer and external eraser.
</p>
<p>Figure 10.8 shows the erase procedure for a floating-gate transistor using UV light.
</p>
<p>Fig. 10.7
Floating-gate transistor&mdash;programming
</p>
<p>10.2 Nonvolatile Memory Technology &bull; 349</p>
<p/>
</div>
<div class="page"><p/>
<p>An EPROM array is created in the exact same manner as in a PROM array with the exception that
</p>
<p>additional programming circuitry is placed on the IC and a transparent window is included on the
</p>
<p>package to facilitate erasing. An EPROM is nonvolatile and read only since the programming procedure
</p>
<p>takes place outside of its destination system.
</p>
<p>10.2.5 Electrically Erasable Programmable Read-Only Memory
</p>
<p>In order to address the inconvenient programming and erasing procedures associated with
</p>
<p>EPROMs, the electrically erasable programmable ROM (EEPROM) was created. In this type of circuit,
</p>
<p>the floating-gate transistor is erased by applying a large electric field across the secondary oxide. This
</p>
<p>electric field provides the energy to move the trapped charge from the secondary oxide back into the
</p>
<p>metal plates of the gate. The advantage of this approach is that the circuitry to provide the large electric
</p>
<p>field can be generated using circuitry on the same substrate as the memory array, thus eliminating the
</p>
<p>need for an external UV light eraser. In addition, since the circuitry exists to generate large on-chip
</p>
<p>voltages, the device can also be programmed without the need for an external programmer. This allows
</p>
<p>an EEPROM to be programmed and erased while it resides in its target environment. Figure 10.9 shows
</p>
<p>the procedure for erasing a floating-gate transistor using an electric field.
</p>
<p>Fig. 10.8
Floating-gate transistor&mdash;erasing with UV light
</p>
<p>Fig. 10.9
Floating-gate transistor&mdash;erasing with electricity
</p>
<p>350 &bull; Chapter 10: Memory</p>
<p/>
</div>
<div class="page"><p/>
<p>Early EEPROMs were very slow and had a limited number of program/erase cycles; thus they were
</p>
<p>classified into the category of nonvolatile, ROM. Modern floating-gate transistors are now capable of
</p>
<p>access times on scale with other volatile memory systems; thus they have evolved into one of the few
</p>
<p>nonvolatile, read/write memory technologies used in computer systems today.
</p>
<p>10.2.6 FLASH Memory
</p>
<p>One of the early drawbacks of EEPROM was that the circuitry that provided the capability to
</p>
<p>program and erase individual bits also added to the size of each individual storage element. FLASH
</p>
<p>EEPROM was a technology that attempted to improve the density of floating-gate memory by program-
</p>
<p>ming and erasing in large groups of data, known as blocks. This allowed the individual storage cells to
</p>
<p>shrink and provided higher density memory parts. This new architecture was called NAND FLASH and
</p>
<p>provided faster write and erase times coupled with higher density storage elements. The limitation of
</p>
<p>NAND FLASH was that reading and writing could only be accomplished in a block-by-block basis. This
</p>
<p>characteristic precluded the use of NAND FLASH for run-time variables and data storage, but was well
</p>
<p>suited for streaming applications such as audio/video and program loading. As NAND FLASH technol-
</p>
<p>ogy advanced, the block size began to shrink and software adapted to accommodate the block-by-block
</p>
<p>data access. This expanded the applications that NAND FLASH could be deployed in. Today, NAND
</p>
<p>FLASH memory is used in nearly all portable devices (e.g., smart phones, tablets) and its use in solid-
</p>
<p>state hard drives is on pace to replace hard disk drives and optical disks as the primary nonvolatile
</p>
<p>storage medium in modern computers.
</p>
<p>In order to provide individual word access, NOR FLASH was introduced. In NOR FLASH, circuitry is
</p>
<p>added to provide individual access to data words. This architecture provided faster read times than
</p>
<p>NAND FLASH, but the additional circuitry causes the write and erase times to be slower and the
</p>
<p>individual storage cell size to be larger. Due to NAND FLASH having faster write times and higher
</p>
<p>density, it is seeing broader scale adoption compared to NOR FLASH despite only being able to access
</p>
<p>information in blocks. NOR FLASH is considered RAM while NAND FLASH is typically not; however, as
</p>
<p>the block size of NAND FLASH is continually reduced, its use for variable storage is becoming more
</p>
<p>attractive. All FLASH memory is nonvolatile and read/write.
</p>
<p>CC10.2 Which of the following is suitable for implementation in a read only memory?
</p>
<p>A) Variables that a computer program needs to continuously update.
</p>
<p>B) Information captured by a digital camera.
</p>
<p>C) A computer program on a spacecraft.
</p>
<p>D) Incoming digitized sound from a microphone.
</p>
<p>CONCEPT CHECK
</p>
<p>10.2 Nonvolatile Memory Technology &bull; 351</p>
<p/>
</div>
<div class="page"><p/>
<p>10.3 Volatile Memory Technology
</p>
<p>This section describes some common volatile memory technologies used to store digital
</p>
<p>information.
</p>
<p>10.3.1 Static Random Access Memory
</p>
<p>Static random access memory (SRAM) is a semiconductor technology that stores information using
</p>
<p>a cross-coupled inverter feedback loop. Figure 10.10 shows the schematic for the basic SRAM storage
</p>
<p>cell. In this configuration, two access transistors (M1 and M2) are used to read and write from the storage
</p>
<p>cell. The cell has two complementary ports called Bit Line (BL) and Bit Line&rsquo; (BLn). Due to the inverting
</p>
<p>functionality of the feedback loop, these two ports will always be the complement of each other. This
</p>
<p>behavior is advantageous because the two lines can be compared to each other to determine the data
</p>
<p>value. This allows the voltage levels used in the cell to be lowered while still being able to detect the
</p>
<p>stored data value. Word lines are used to control the access transistors. This storage element takes six
</p>
<p>CMOS transistors to implement and is often called a 6 Tconfiguration. The advantage of this memory cell
</p>
<p>is that it has very fast performance compared to other subsystems because of its underlying technology
</p>
<p>being simple CMOS transistors. SRAM cells are commonly implemented on the same IC substrate as
</p>
<p>the rest of the system, thus allowing a fully integrated system to be realized. SRAM cells are used for
</p>
<p>cache memory in computer systems.
</p>
<p>To build an SRAM memory system, cells are arranged in an array pattern. Figure 10.11 shows a
</p>
<p>4 � 4 SRAM array topology. In this configuration, word lines are shared horizontally across the array in
</p>
<p>order to provide addressing capability. An address decoder is used to convert the binary encoded
</p>
<p>address into the appropriate word line assertions. N storage cells are attached to the word line to provide
</p>
<p>the desired data word width. Bit lines are shared vertically across the array in order to provide data
</p>
<p>access (either read or write). A data line controller handles whether data is read from or written to the
</p>
<p>cells based on an external write enable (WE) signal. When WE is asserted (WE &frac14; 1), data will be written
</p>
<p>to the cells. When WE is de-asserted (WE &frac14; 0), data will be read from the cells. The data line controller
</p>
<p>also handles determining the correct logic value read from the cells by comparing BL to BLn. As more
</p>
<p>cells are added to the bit lines, the signal magnitude being driven by the storage cells diminishes due to
</p>
<p>Fig. 10.10
SRAM storage element (6 T)
</p>
<p>352 &bull; Chapter 10: Memory</p>
<p/>
</div>
<div class="page"><p/>
<p>the additional loading of the other cells. This is where having complementary data signals (BL and BLn)
</p>
<p>is advantageous because this effectively doubles the magnitude of the storage cell outputs. The
</p>
<p>comparison of BL to BLn is handled using a differential amplifier that produces a full logic-level output
</p>
<p>even when the incoming signals are very small.
</p>
<p>SRAM is volatile memory because when the power is removed, the cross-coupled inverters are not
</p>
<p>able to drive the feedback loop and the data is lost. SRAM is also read/write memory because the
</p>
<p>storage cells can be easily read from or written to during normal operation.
</p>
<p>Let&rsquo;s look at the operation of the SRAM array when writing the 4-bit word &ldquo;0111&rdquo; to address &ldquo;01.&rdquo;
</p>
<p>Figure 10.12 shows a graphical depiction of this operation. In this write cycle, the row address decoder
</p>
<p>observes the address input &ldquo;01&rdquo; and asserts WL1. Asserting this word line enables all of the access
</p>
<p>transistors (i.e., M1 and M2 in Fig. 10.10) of the storage cells in this row. The line drivers are designed to
</p>
<p>have a stronger drive strength than the inverters in the storage cells so that they can override their values
</p>
<p>during a write. The information &ldquo;0111&rdquo; is present on the Data_In bus and the write enable control line is
</p>
<p>Fig. 10.11
4 � 4 SRAM array topology
</p>
<p>10.3 Volatile Memory Technology &bull; 353</p>
<p/>
</div>
<div class="page"><p/>
<p>asserted (WE &frac14; 1) to indicate a write. The data line controller passes the information to be stored to the
</p>
<p>line drivers, which in turn converts each input into complementary signals and drives the bit lines. This
</p>
<p>overrides the information in each storage cell connected to WL1. The address decoder then de-asserts
</p>
<p>WL1 and the information is stored.
</p>
<p>Now let&rsquo;s look at the operation of the SRAM array when reading a 4-bit word from address &ldquo;10.&rdquo; Let&rsquo;s
</p>
<p>assume that this row was storing the value &ldquo;1010.&rdquo; Figure 10.13 shows a graphical depiction of this
</p>
<p>operation. In this read cycle, the row address decoder asserts WL2, which allows the SRAM cells to drive
</p>
<p>their respective bit lines. Note that each cell drives a complementary version of its stored value. The input
</p>
<p>control line is de-asserted (WE &frac14; 0), which indicates that the sense amps will read the BL and BLn lines
</p>
<p>in order to determine the full logic value stored in each cell. This logic value is then routed to the
</p>
<p>Data_Out port of the array. In an SRAM array, reading from the cell does not impact the contents of
</p>
<p>the cell. Once the read is complete, WL2 is de-asserted and the read cycle is complete.
</p>
<p>Fig. 10.12
SRAM operation during a write cycle&mdash;storing &ldquo;0111&rdquo; to address &ldquo;01&rdquo;
</p>
<p>354 &bull; Chapter 10: Memory</p>
<p/>
</div>
<div class="page"><p/>
<p>10.3.2 Dynamic Random Access Memory
</p>
<p>Dynamic random access memory (DRAM) is a semiconductor technology that stores information
</p>
<p>using a capacitor. A capacitor is a fundamental electrical device that stores charge. Figure 10.14 shows
</p>
<p>the schematic for the basic DRAM storage cell. The capacitor is accessed through a transistor (M1).
</p>
<p>Since this storage element takes one transistor and one capacitor, it is often referred to as a 1T1C
</p>
<p>configuration. Just as in SRAM memory, word lines are used to access the storage elements. The term
</p>
<p>digit line is used to describe the vertical connection to the storage cells. DRAM has an advantage over
</p>
<p>SRAM in that the storage element requires less area to implement. This allows DRAM memory to have
</p>
<p>much higher density compared to SRAM.
</p>
<p>Fig. 10.13
SRAM operation during a read cycle&mdash;reading &ldquo;0101&rdquo; from address &ldquo;10&rdquo;
</p>
<p>10.3 Volatile Memory Technology &bull; 355</p>
<p/>
</div>
<div class="page"><p/>
<p>There are a variety of considerations that must be accounted for when using DRAM. First, the
</p>
<p>charge in the capacitor will slowly dissipate over time due to the capacitors being non-ideal. If left
</p>
<p>unchecked, eventually the data held in the capacitor will be lost. In order to overcome this issue,
</p>
<p>DRAM has a dedicated circuit to refresh the contents of the storage cell. A refresh cycle involves
</p>
<p>periodically reading the value stored on the capacitor and then writing the same value back again at
</p>
<p>full signal strength. This behavior also means that DRAM is volatile because when the power is removed
</p>
<p>and the refresh cycle cannot be performed, the stored data is lost. DRAM is also considered read/write
</p>
<p>memory because the storage cells can be easily read from or written to during normal operation.
</p>
<p>Another consideration when using DRAM is that the voltage of the word line must be larger than VCC
in order to turn on the access transistor. In order to turn on an NMOS transistor, the gate terminal must be
</p>
<p>larger than the source terminal by at least a threshold voltage (VT). In traditional CMOS circuit design, the
</p>
<p>source terminal is typically connected to ground (0v). This means that the transistor can be easily turned
</p>
<p>on by driving the gate with a logic 1 (i.e., VCC) since this creates a VGS voltage much larger than VT. This
</p>
<p>is not always the case in DRAM. In DRAM, the source terminal is not connected to ground, but rather to
</p>
<p>the storage capacitor. In the worst-case situation, the capacitor could be storing a logic 1 (i.e., VCC). This
</p>
<p>means that in order for the word line to be able to turn on the access transistor, it must be equal to or
</p>
<p>larger than (VCC + VT). This is an issue because the highest voltage that the DRAM device has access to
</p>
<p>is VCC. In DRAM, a charge pump is used to create a voltage larger than VCC + VT that is driven on the
</p>
<p>word lines. Once this voltage is used, the charge is lost, so the line must be pumped up again before its
</p>
<p>next use. The process of &ldquo;pumping up&rdquo; takes time that must be considered when calculating the
</p>
<p>maximum speed of DRAM. Figure 10.15 shows a graphical depiction of this consideration.
</p>
<p>Another consideration when using DRAM is how the charge in the capacitor develops into an actual
</p>
<p>voltage on the digital line when the access transistor is closed. Consider the simple 4 � 4 array of DRAM
</p>
<p>cells shown in Fig. 10.16. In this topology, the DRAM cells are accessed using the same approach as in
</p>
<p>the SRAM array from Fig. 10.11.
</p>
<p>Fig. 10.14
DRAM storage element (1 T 1C)
</p>
<p>Fig. 10.15
DRAM charge pumping of word lines
</p>
<p>356 &bull; Chapter 10: Memory</p>
<p/>
</div>
<div class="page"><p/>
<p>One of the limitations of this simple configuration is that the charge stored in the capacitors cannot
</p>
<p>develop a full voltage level across the digit line when the access transistor is closed. This is because the
</p>
<p>digit line itself has capacitance that impacts how much voltage will be developed. In practice, the
</p>
<p>capacitance of the digit line (CDL) is much larger than the capacitance of the storage cell (CS) due to
</p>
<p>having significantly more area and being connected to numerous other storage cells. This becomes an
</p>
<p>issue because when the storage capacitor is connected to the digit line, the resulting voltage on the digit
</p>
<p>line (VDL) is much less than the original voltage on the storage cell (VS). This behavior is known as
</p>
<p>charge sharing because when the access transistor is closed, the charge on both capacitors is
</p>
<p>distributed across both devices and results in a final voltage that depends on the initial charge in the
</p>
<p>system and the values of the two capacitors. Example 10.1 shows an example of how to calculate the
</p>
<p>final digit line voltage when the storage cell is connected.
</p>
<p>Fig. 10.16
Simple 4 � 4 DRAM array topology
</p>
<p>10.3 Volatile Memory Technology &bull; 357</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 10.1
Calculating the final digit line voltage in a DRAM based on charge sharing
</p>
<p>The issue with the charge sharing behavior of a DRAM cell is that the final voltage on the word line is
</p>
<p>not large enough to be detected by a standard logic gate or latch. In order to overcome this issue, modern
</p>
<p>DRAM arrays use complementary storage cells and sense amplifiers. The complementary cells store the
</p>
<p>original data and its complement. Two digit lines (DL and DLn) are used to read the contents of the
</p>
<p>storage cells. DL and DLn are initially pre-charged to exactly VCC/2. When the access transistors are
</p>
<p>closed, the storage cells will share their charge with the digit lines andmove them slightly away from VCC/
</p>
<p>2 in different directions. This allows twice the voltage difference to be developed during a read. A sense
</p>
<p>358 &bull; Chapter 10: Memory</p>
<p/>
</div>
<div class="page"><p/>
<p>amplifier is then used to boost this small voltage difference into a full logic level that can be read by a
</p>
<p>standard logic gate or latch. Figure 10.17 shows the modern DRAM array topology based on comple-
</p>
<p>mentary storage cells.
</p>
<p>The sense amplifier is designed to boost small voltage deviations from VCC/2 on DL and DLn to full
</p>
<p>logic levels. The sense amplifier sits in between DL and DLn and has two complementary networks, the
</p>
<p>N-sense amplifier, and the P-sense amplifier. The N-sense amplifier is used to pull a signal that is below
</p>
<p>VCC/2 (either DL or DLn) down to GND. A control signal (N-Latch or NLATn) is used to turn on this
</p>
<p>network. The P-sense amplifier is used to pull a signal that is above VCC/2 (either DL or DLn) up to VCC. A
</p>
<p>control signal (active pull-up or ACT) is used to turn on this network. The two networks are activated in a
</p>
<p>sequence with the N-sense network activating first. Figure 10.18 shows an overview of the operation of a
</p>
<p>DRAM sense amplifier.
</p>
<p>Fig. 10.17
Modern DRAM array topology based on complementary storage cells
</p>
<p>10.3 Volatile Memory Technology &bull; 359</p>
<p/>
</div>
<div class="page"><p/>
<p>Let&rsquo;s now put everything together and look at the operation of a DRAM system during a read
</p>
<p>operation. Figure 10.19 shows a simplified timing diagram of a DRAM read cycle. This diagram shows
</p>
<p>the critical signals and their values when reading a logic 1. Notice that there is a sequence of steps that
</p>
<p>must be accomplished before the information in the storage cells can be retrieved.
</p>
<p>Fig. 10.18
DRAM sense amplifier
</p>
<p>360 &bull; Chapter 10: Memory</p>
<p/>
</div>
<div class="page"><p/>
<p>A DRAM write operation is accomplished by opening the access transistors to the complementary
</p>
<p>storage cells using WL, disabling the pre-charge drivers, and then writing full logic-level signals to the
</p>
<p>storage cells using the Data_In line driver.
</p>
<p>CC10.3 Which of the following is suitable for implementation in a read/write memory?
</p>
<p>A) A look up table containing the values of sine.
</p>
<p>B) Information captured by a digital camera.
</p>
<p>C) The boot up code for a computer.
</p>
<p>D) A computer program on a spacecraft.
</p>
<p>CONCEPT CHECK
</p>
<p>Fig. 10.19
DRAM operation during a read cycle&mdash;reading a 1 from a storage cell
</p>
<p>10.3 Volatile Memory Technology &bull; 361</p>
<p/>
</div>
<div class="page"><p/>
<p>10.4 Modeling Memory with VHDL
</p>
<p>10.4.1 Read-Only Memory in VHDL
</p>
<p>Modeling of memory in VHDL is accomplished using the array data type. Recall the syntax for
</p>
<p>declaring a new array type below:
</p>
<p>type name is array (&lt;range&gt;) of &lt;element_type&gt;;
</p>
<p>To create the ROM array, a new type is declared (e.g., ROM_type) that is an array. The range
</p>
<p>represents the addressing of the memory array and is provided as an integer. The element_type of the
</p>
<p>array specifies the data type to be stored at each address and represents the data in the memory array.
</p>
<p>The type of the element should be std_logic_vector with a width of N. To define a 4 � 4 array of memory,
</p>
<p>we would use the following syntax.
</p>
<p>Example:
</p>
<p>type ROM_type is array (0 to 3) of std_logic_vector(3 downto 0);
</p>
<p>Notice that the address is provided as an integer (0&ndash;3). This will require two address bits. Also notice
</p>
<p>that this defines 4-bit data words. Next, we define a new constant of type ROM_type. When defining a
</p>
<p>constant, we provide the contents at each address.
</p>
<p>Example:
</p>
<p>constant ROM : ROM_type :&frac14; (0 &frac14;&gt; &rdquo;1110&rdquo;,
</p>
<p>1 &frac14;&gt; &rdquo;0010&rdquo;,
</p>
<p>2 &frac14;&gt; &rdquo;1111&rdquo;,
</p>
<p>3 &frac14;&gt; &rdquo;0100&rdquo;);
</p>
<p>At this point, the ROM array is declared and initialized. In order to model the read behavior, a
</p>
<p>concurrent signal assignment is used. The assignment will be made to the output data_out based on the
</p>
<p>incoming address. The assignment to data_out will be the contents of the constant ROM at a particular
</p>
<p>address. Since the index of a VHDL array needs to be provided as an integer (e.g., 0,1,2,3) and the
</p>
<p>address of the memory system is provided as a std_logic_vector, a type conversion is required. Since
</p>
<p>there is not a direct conversion from type std_logic_vector to integer, two conversions are required. The
</p>
<p>first step is to convert the address from std_logic_vector to unsigned using the unsigned type conversion.
</p>
<p>This conversion exists within the numeric_std package. The second step is to convert the address from
</p>
<p>unsigned to integer using the to_integer conversion. The final assignment is as follows:
</p>
<p>Example:
</p>
<p>data_out &lt;&frac14; ROM(to_integer(unsigned(address)));
</p>
<p>Example 10.2 shows the entire VHDL model for this memory system and the simulation waveform.
</p>
<p>In the simulation, each possible address is provided (i.e., &ldquo;00,&rdquo; &ldquo;01,&rdquo; &ldquo;10,&rdquo; and &ldquo;11). For each address, the
</p>
<p>corresponding information appears on the data_out port. Since this is an asynchronous memory system,
</p>
<p>the data appears immediately upon receiving a new address.
</p>
<p>362 &bull; Chapter 10: Memory</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 10.2
Behavioral model of a 4 � 4 asynchronous read-only memory in VHDL
</p>
<p>Latency can be modeled in memory systems by using delayed signal assignments. In the above
</p>
<p>example, if the memory system had a latency of 5 ns, this could be modeled using the following
</p>
<p>approach:
</p>
<p>Example:
</p>
<p>data_out &lt;&frac14; ROM(to_integer(unsigned(address))) after 5 ns;
</p>
<p>A synchronous ROM can be created in a similar manner. In this approach, a clock edge is used to
</p>
<p>trigger when the data_out port is updated. A sensitivity list is used that contains only the signal clock to
</p>
<p>trigger the assignment. A rising edge condition is then used in an if/then statement to make the
</p>
<p>assignment only on a rising edge. Example 10.3 shows the VHDL model and simulation waveform for
</p>
<p>this system. Notice that prior to the first clock edge, the simulator does not know what to assign to
</p>
<p>data_out, so it lists the value as uninitialized.
</p>
<p>10.4 Modeling Memory with VHDL &bull; 363</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 10.3
Behavioral model of a 4 � 4 synchronous read-only memory in VHDL
</p>
<p>10.4.2 Read/Write Memory in VHDL
</p>
<p>In a read/write memory model, a new type is created using a VHDL array (e.g., RW_type) that
</p>
<p>defines the size of the storage system. To create the memory, a new signal is declared with the
</p>
<p>array type.
</p>
<p>Example:
</p>
<p>type RW_type is array (0 to 3) std_logic_vector(3 downto 0);
</p>
<p>signal RW : RW_type;
</p>
<p>Note that a signal is used in a read/write system as opposed to a constant as in the ROM system.
</p>
<p>This is because a read/write system is uninitialized until it is written to. A process is then used to model
</p>
<p>the behavior of the memory system. Since this is an asynchronous system, all inputs are listed in the
</p>
<p>sensitivity list (i.e., address, WE, and data_in). The process first checks whether the write enable line is
</p>
<p>364 &bull; Chapter 10: Memory</p>
<p/>
</div>
<div class="page"><p/>
<p>asserted (WE &frac14; 1), which indicates that a write cycle is being performed. If it is, then it makes an
</p>
<p>assignment to the RW signal at the location provided by the address input with the data provided by the
</p>
<p>data_in input. Since the RWarray is indexed using integers, type conversions are required to convert the
</p>
<p>address from std_logic_vector to integer. When WE is not asserted (WE &frac14; 0), a read cycle is being
</p>
<p>performed. In this case, the process makes an assignment to data_out with the contents stored at the
</p>
<p>provided address. This assignment also requires type conversions to change the address from
</p>
<p>std_logic_vector to integer. The following syntax implements this behavior.
</p>
<p>Example:
</p>
<p>MEMORY: process (address, WE, data_in)
</p>
<p>begin
</p>
<p>if (WE &frac14; &rsquo;1&rsquo;) then
</p>
<p>RW(to_integer(unsigned(address))) &lt;&frac14; data_in;
</p>
<p>else
</p>
<p>data_out &lt;&frac14; RW(to_integer(unsigned(address)));
</p>
<p>end if;
</p>
<p>end process;
</p>
<p>A read/write memory does not contain information until its storage locations are written to. As a
</p>
<p>result, if the memory is read from before it has been written to, the simulation will return uninitialized.
</p>
<p>Example 10.4 shows the entire VHDL model for an asynchronous read/write memory and the simulation
</p>
<p>waveform showing read/write cycles.
</p>
<p>10.4 Modeling Memory with VHDL &bull; 365</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 10.4
Behavioral model of a 4 � 4 asynchronous read/write memory in VHDL
</p>
<p>A synchronous read/write memory is made in a similar manner with the exception that a clock is
</p>
<p>used to trigger the signal assignments in the sensitivity list. The WE signal acts as a synchronous control
</p>
<p>signal indicating whether assignments are read from or written to the RWarray. Example 10.5 shows the
</p>
<p>entire VHDL model for a synchronous read/write memory and the simulation waveform showing both
</p>
<p>read and write cycles.
</p>
<p>366 &bull; Chapter 10: Memory</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 10.5
Behavioral model of a 4 � 4 synchronous read/write memory in VHDL
</p>
<p>CC10.4 Explain the advantage of modeling memory in VHDL without going into the details of the 
storage cell operation.
</p>
<p>A) It allows the details of the storage cell to be abstracted from the functional operation 
of the memory system.
</p>
<p>B) It is too difficult to model the analog behavior of the storage cell.
</p>
<p>C) There are too many cells to model so the simulation would take too long.
</p>
<p>D) It lets both ROM and R/W memory to be modeled in a similar manner.
</p>
<p>CONCEPT CHECK
</p>
<p>10.4 Modeling Memory with VHDL &bull; 367</p>
<p/>
</div>
<div class="page"><p/>
<p>Summary
</p>
<p>v The term memory refers to large arrays of
digital storage. The technology used in mem-
ory is typically optimized for storage density
at the expense of control capability. This is
different from a D-flip-flop, which is optimized
for complete control at the bit level.
</p>
<p>v A memory device always contains an
address bus input. The number of bits in the
address bus dictates how many storage
locations can be accessed. An n-bit address
bus can access 2n (or M) storage locations.
</p>
<p>v The width of each storage location (N) allows
the density of the memory array to be
increased by reading and writing vectors of
data instead of individual bits.
</p>
<p>v A memory map is a graphical depiction of a
memory array. A memory map is useful to
give an overview of the capacity of the array
and how different address ranges of the array
are used.
</p>
<p>v A read is an operation in which data is
retrieved from memory. A write is an opera-
tion in which data is stored to memory.
</p>
<p>v An asynchronous memory array responds
immediately to its control inputs. A synchro-
nous memory array only responds on the
triggering edge of clock.
</p>
<p>v Volatile memory will lose its data when the
power is removed. Nonvolatile memory will
retain its data when the power is removed.
</p>
<p>v ROM is a memory type that cannot be written
to during normal operation. Read/write (R/W)
memory is a memory type that can be written
to during normal operation. Both ROM and
R/Wmemory can be read from during normal
operation.
</p>
<p>v RAM is a memory type in which any location
in memory can be accessed at any time. In
sequential access memory the data can only
be retrieved in a linear sequence. This
means that in sequential memory the data
cannot be accessed arbitrarily.
</p>
<p>v The basic architecture of a ROM consists of
intersecting bit lines (vertical) and word lines
(horizontal) that contain storage cells at their
crossing points. The data is read out of the
ROM array using the bit lines. Each bit line
contains a pull-up resistor to initially store a
logic 1 at each location. If a logic 0 is desired
at a certain location, a pull-down transistor is
placed on a particular bit line with its gate
connected to the appropriate word line.
When the storage cell is addressed, the
word line will assert and turn on the pull-
down transistor producing a logic 0 on the
output.
</p>
<p>v There are a variety of technologies to imple-
ment the pull-down transistor in a ROM. Dif-
ferent ROM architectures include MROMs,
PROMs, EPROMs, and EEPROMs. These
memory types are nonvolatile.
</p>
<p>v A R/W memory requires a storage cell that
can be both read from and written to during
normal operation. A DRAM (dynamic RAM)
cell is a storage element that uses a capaci-
tor to hold charge corresponding to a logic
value. An SRAM (static RAM) cell is a stor-
age element that uses a cross-coupled
inverter pair to hold the value being stored
in the positive-feedback loop formed by the
inverters. Both DRAM and SRAM are volatile
and random access.
</p>
<p>v The floating-gate transistor enables memory
that is both nonvolatile and R/W. Modern
memory systems based on floating-gate
transistor technology allow writing to take
place using the existing system power supply
levels. This type of R/W memory is called
FLASH. In FLASH memory, the information
is read out in blocks; thus it is not technically
random access.
</p>
<p>v Memory can be modeled in VHDL using the
array data type.
</p>
<p>Exercise Problems
</p>
<p>Section 10.1: Memory Architecture and
</p>
<p>Terminology
</p>
<p>10.1.1 For a 512 k � 32 memory system, how many
unique address locations are there? Give the
exact number.
</p>
<p>10.1.2 For a 512 k � 32 memory system, what is the
data width at each address location?
</p>
<p>10.1.3 For a 512 k � 32 memory system, what is the
capacity in bits?
</p>
<p>10.1.4 For a 512 k � 32-bit memory system, what is
the capacity in bytes?
</p>
<p>10.1.5 For a 512 k � 32 memory system, how wide
does the incoming address bus need to be in
order to access every unique address
location?
</p>
<p>10.1.6 Name the type of memory with the following
characteristic: when power is removed, the
data is lost.
</p>
<p>368 &bull; Chapter 10: Memory</p>
<p/>
</div>
<div class="page"><p/>
<p>10.1.7 Name the type of memory with the following
characteristic: when power is removed, the
memory still holds its information.
</p>
<p>10.1.8 Name the type of memory with the following
characteristic: it can only be read from during
normal operation.
</p>
<p>10.1.9 Name the type of memory with the following
characteristic: during normal operation, it can
be read and written to.
</p>
<p>10.1.10 Name the type of memory with the following
characteristic: data can be accessed from any
address location at any time.
</p>
<p>10.1.11 10.1.11: Name the type of memory with the
following characteristic: data can only be
accessed in consecutive order; thus not every
location of memory is available
instantaneously.
</p>
<p>Section 10.2: Nonvolatile Memory
</p>
<p>Technology
</p>
<p>10.2.1 Name the type of memory with the following
characteristic: this memory is nonvolatile, read/
write, and only provides data access in blocks.
</p>
<p>10.2.2 Name the type of memory with the following
characteristic: this memory uses a floating-
gate transistor, can be erased with electricity,
and provides individual bit access.
</p>
<p>10.2.3 Name the type of memory with the following
characteristic: this memory is nonvolatile, read/
write, and provides word-level data access.
</p>
<p>10.2.4 Name the type of memory with the following
characteristic: this memory uses a floating-
gate transistor that is erased with UV light.
</p>
<p>10.2.5 Name the type of memory with the following
characteristic: this memory is programmed by
blowing fuses or anti-fuses.
</p>
<p>10.2.6 Name the type of memory with the following
characteristic: this memory is partially
fabricated prior to knowing the information to
be stored.
</p>
<p>Section 10.3: Volatile Memory
</p>
<p>Technology
</p>
<p>10.3.1 How many transistors does it take to imple-
ment an SRAM cell?
</p>
<p>10.3.2 Why doesn&rsquo;t an SRAM cell require a refresh
cycle?
</p>
<p>10.3.3 Design a VHDL model for the SRAM system
shown in Fig. 10.20. Your storage cell should
be designed such that its contents can be
overwritten by the line driver. Consider using
a resolved data type for this behavior that
models drive strength (e.g., in std_logic, a
1 has a higher drive strength than an H). You
will need to create a system for the differential
line driver with enable. This driver will need to
contain a high impedance state when disabled.
Both your line driver (Din) and receiver (Dout)
are differential. These systems can be
modeled using simple if/then statements. Cre-
ate a test bench for your system that will write a
</p>
<p>0 to the cell, then read it back to verify that the
0 was stored, and then repeat the write/read
cycles for a 1.
</p>
<p>10.3.4 Why is a DRAM cell referred to as a 1 T 1C
configuration?
</p>
<p>10.3.5 Why is a charge pump necessary on the word
lines of a DRAM array?
</p>
<p>10.3.6 Why does a DRAM cell require a refresh cycle?
</p>
<p>10.3.7 For the DRAM storage cell shown in Fig. 10.21,
solve for the final voltage on the digit line after
the access transistor (M1) closes if initially VS
&frac14; VCC (i.e., the cell is storing a 1). In this
system, CS &frac14; 5 pF, CDL &frac14; 10 pF, and VCC
&frac14; +3.4v. Prior to the access transistor closing,
the digit line is pre-charged to VCC/2.
</p>
<p>10.3.8 For the DRAM storage cell shown in Fig. 10.21,
solve for the final voltage on the digit line after
the access transistor (M1) closes if initially VS
&frac14; GND (i.e., the cell is storing a 0). In this
system, CS &frac14; 5 pF, CDL &frac14; 10 pF, and VCC
&frac14; +3.4v. Prior to the access transistor closing,
the digit line is pre-charged to VCC/2.
</p>
<p>Fig. 10.20
SRAM Cell Block Diagram
</p>
<p>Fig. 10.21
DRAM Charge Sharing Exercise
</p>
<p>Exercise Problems &bull; 369</p>
<p/>
</div>
<div class="page"><p/>
<p>Section 10.4: Modeling Memory with
</p>
<p>VHDL
</p>
<p>10.4.1 Design a VHDL model for the 16 � 8, asyn-
chronous, ROM system shown in Fig. 10.22.
The system should contain the information
provided in the memory map. Create a test
bench to simulate your model by reading from
each of the 16 unique addresses and observ-
ing Data_Out to verify that it contains the infor-
mation in the memory map.
</p>
<p>10.4.2 Design a VHDL model for the 16 � 8, synchro-
nous, ROM system shown in Fig. 10.23. The
system should contain the information
provided in the memory map. Create a test
bench to simulate your model by reading from
each of the 16 unique addresses and observ-
ing Data_Out to verify that it contains the infor-
mation in the memory map.
</p>
<p>10.4.3 Design a VHDL model for the 16 � 8, asyn-
chronous, read/write memory system shown in
Fig. 10.24. Create a test bench to simulate
your model. Your test bench should first read
from all of the address locations to verify that
they are uninitialized. Next, your test bench
should write unique information to each of the
address locations. Finally, your test bench
should read from each address location to ver-
ify that the information that was written was
stored and can be successfully retrieved.
</p>
<p>10.4.4 Design a VHDL model for the 16 � 8, synchro-
nous, read/write memory system shown in
Fig. 10.25. Create a test bench to simulate
your model. Your test bench should first read
from all of the address locations to verify that
they are uninitialized. Next, your test bench
should write unique information to each of the
address locations. Finally, your test bench
should read from each address location to ver-
ify that the information that was written was
stored and can be successfully retrieved.
</p>
<p>Fig. 10.22
16x8 Asynchronous ROM Block Diagram
</p>
<p>Fig. 10.23
16x8 Synchronous ROM Block Diagram
</p>
<p>Fig. 10.24
16x8 Asynchronous R/W Memory Block
Diagram
</p>
<p>Fig. 10.25
16x8 Synchronous R/W Memory Block
Diagram
</p>
<p>370 &bull; Chapter 10: Memory</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 11: Programmable Logic
This chapter provides an overview of programmable logic devices (PLDs). The term PLD is used as
</p>
<p>a generic description for any circuit that can be programmed to implement digital logic. The technology
</p>
<p>and architectures of PLDs have advanced over time. A historical perspective is given on how the first
</p>
<p>programmable devices evolved into the programmable technologies that are prevalent today. The goal of
</p>
<p>this chapter is to provide a basic understanding of the principles of programmable logic devices.
</p>
<p>Learning Outcomes&mdash;After completing this chapter, you will be able to:
</p>
<p>11.1 Describe the basic architecture and evolution of programmable logic devices.
11.2 Describe the basic architecture of Field Programmable Gate Arrays (FPGAs).
</p>
<p>11.1 Programmable Arrays
</p>
<p>11.1.1 Programmable Logic Array
</p>
<p>One of the first commercial PLDs developed using modern integrated circuit technology was the
</p>
<p>programmable logic array (PLA). In 1970, Texas Instrument introduced the PLA with an architecture
</p>
<p>that supported the implementation of arbitrary, sum of product logic expressions. The PLAwas fabricated
</p>
<p>with a dense array of AND gates, called an AND plane, and a dense array of OR gates, called an OR
</p>
<p>plane. Inputs to the PLA each had an inverter in order to provide the original variable and its complement.
</p>
<p>Arbitrary SOP logic expressions could be implemented by creating connections between the inputs, the
</p>
<p>AND plane, and the OR plane. The original PLAs were fabricated with all of the necessary features
</p>
<p>except the final connections to implement the SOP functions. When a customer provided the desired
</p>
<p>SOP expression, the connections were added as the final step of fabrication. This configuration
</p>
<p>technique was similar to an MROM approach. Figure 11.1 shows the basic architecture of a PLA.
</p>
<p>Fig. 11.1
Programmable logic array (PLA) architecture
</p>
<p># Springer International Publishing Switzerland 2017
</p>
<p>B.J. LaMeres, Introduction to Logic Circuits &amp; Logic Design with VHDL,
</p>
<p>DOI 10.1007/978-3-319-34195-8_11
</p>
<p>371</p>
<p/>
</div>
<div class="page"><p/>
<p>A more compact schematic for the PLA is drawn by representing all of the inputs into the AND and
</p>
<p>OR gates with a single wire. Connections are indicated by inserting Xs at the intersections of wires.
</p>
<p>Figure 11.2 shows this simplified PLA schematic implementing two different SOP logic expressions.
</p>
<p>11.1.2 Programmable Array Logic
</p>
<p>One of the drawbacks of the original PLA was that the programmability of the OR plane caused
</p>
<p>significant propagation delays through the combinational logic circuits. In order to improve on the
</p>
<p>performance of PLAs, the programmable array logic (PAL) was introduced in 1978 by the company
</p>
<p>Monolithic Memories, Inc. The PAL contained a programmable AND plane and a fixed-OR plane. The
</p>
<p>fixed-OR plane improved the performance of this programmable architecture. While not having a
</p>
<p>programmable OR plane reduced the flexibility of the device, most SOP expressions could be
</p>
<p>manipulated to work with a PAL. Another contribution of the PAL was that the AND plane could be
</p>
<p>programmed using fuses. Initially, all connections were present in the AND plane. An external program-
</p>
<p>mer was used to blow fuses in order to disconnect the inputs from the AND gates. While the fuse
</p>
<p>approach provided one-time-only programming, the ability to configure the logic post-fabrication was a
</p>
<p>significant advancement over the PLA, which had to be programmed at the manufacturer. Figure 11.3
</p>
<p>shows the architecture of a PAL.
</p>
<p>Fig. 11.2
Simplified PLA schematic
</p>
<p>372 &bull; Chapter 11: Programmable Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>11.1.3 Generic Array Logic
</p>
<p>As the popularity of the PAL grew, additional functionality was implemented to support more
</p>
<p>sophisticated designs. One of the most significant improvements was the addition of an output logic
</p>
<p>macrocell (OLMC). An OLMC provided a D-flip-flop and a selectable mux so that the output of the SOP
</p>
<p>circuit from the PAL could be used either as the system output or the input to a D-flip-flop. This enabled
</p>
<p>the implementation of sequential logic and finite-state machines. The OLMC could also be used to route
</p>
<p>the I/O pin back into the PAL to increase the number of inputs possible in the SOP expressions. Finally,
</p>
<p>the OLMC provided a multiplexer to allow feedback from either the PAL output or the output of the D-flip-
</p>
<p>flop. This architecture was named a generic array logic (GAL) to distinguish its features from a
</p>
<p>standard PAL. Figure 11.4 shows the architecture of a GAL consisting of a PAL and an OLMC.
</p>
<p>Fig. 11.3
Programmable array logic (PAL) architecture
</p>
<p>11.1 Programmable Arrays &bull; 373</p>
<p/>
</div>
<div class="page"><p/>
<p>11.1.4 Hard Array Logic
</p>
<p>For mature designs, PALs and GALs could be implemented as a hard array logic (HAL) device. A
</p>
<p>HAL was a version of a PAL or GAL that had the AND plane connections implemented during fabrication
</p>
<p>instead of through blowing fuses. This architecture was more efficient for high-volume applications as it
</p>
<p>eliminated the programming step post-fabrication and the device did not need to contain the additional
</p>
<p>programming circuitry.
</p>
<p>In 1983, Altera Inc. was founded as a programmable logic device company. In 1984, Altera released
</p>
<p>its first version of a PAL with a unique feature that it could be programmed and erased multiple times
</p>
<p>using a programmer and an UV light source similar to an EEPROM.
</p>
<p>11.1.5 Complex Programmable Logic Devices
</p>
<p>As the demand for larger programmable devices grew, the PAL&rsquo;s architecture was not able to scale
</p>
<p>efficiently due to a number of reasons: first, as the size of combinational logic circuits increased, the PAL
</p>
<p>encountered fan-in issues in its AND plane; secondly, for each input that was added to the PAL, the
</p>
<p>amount of circuitry needed on the chip grew geometrically due to requiring a connection to each AND
</p>
<p>gate in addition to the area associated with the additional OLMC. This led to a new PLD architecture in
</p>
<p>which the on-chip interconnect was partitioned across multiple PALs on a single chip. This partitioning
</p>
<p>meant that not all inputs to the device could be used by each PAL, so the design complexity increased;
</p>
<p>however, the additional programmable resources outweighed this drawback and this architecture was
</p>
<p>Fig. 11.4
Generic array logic (GAL) architecture
</p>
<p>374 &bull; Chapter 11: Programmable Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>broadly adopted. This new architecture was called a complex programmable logic device (CPLD).
</p>
<p>The term simple programmable logic device (SPLD) was created to describe all of the previous PLD
</p>
<p>architectures (i.e., PLA, PAL, GAL, and HAL). Figure 11.5 shows the architecture of the CPLD.
</p>
<p>CC11.1 What is the only source of delay mismatch from the inputs to the outputs in a 
programmable array?
</p>
<p>A) The AND gates will have different delays due to having different numbers of 
inputs.
</p>
<p>B) The OR gates will have different delays due to having different numbers of 
inputs.
</p>
<p>C) An input may or may not go through an inverter before reaching the A ND gates.
</p>
<p>D) None.  All paths through the programmable array have identical delay.
</p>
<p>CONCEPT CHECK
</p>
<p>11.2 Field Programmable Gate Arrays
</p>
<p>To address the need for even more programmable resources, a new architecture was developed by
</p>
<p>Xilinx Inc. in 1985. This new architecture was called a field programmable gate array (FPGA). An
</p>
<p>FPGA consists of an array of programmable logic blocks (or logic elements) and a network of program-
</p>
<p>mable interconnect that can be used to connect any logic element to any other logic element. Each logic
</p>
<p>block contained circuitry to implement arbitrary combinational logic circuits in addition to a D-flip-flop and
</p>
<p>a multiplexer for signal steering. This architecture effectively implemented an OLMC within each block,
</p>
<p>thus providing ultimate flexibility and providing significantly more resources for sequential logic. Today,
</p>
<p>FPGAs are the most commonly used programmable logic device, with Altera Inc. and Xilinx Inc. being
</p>
<p>the two largest manufacturers. Figure 11.6 shows the generic architecture of an FPGA.
</p>
<p>Fig. 11.5
Complex PLD (CPLD) architecture
</p>
<p>11.2 Field Programmable Gate Arrays &bull; 375</p>
<p/>
</div>
<div class="page"><p/>
<p>11.2.1 Configurable Logic Block (or Logic Element)
</p>
<p>The primary reconfigurable structure in the FPGA is the configurable logic block (CLB) or logic
</p>
<p>element (LE). Xilinx Inc. uses the term CLB while Altera uses LE. Combinational logic is implemented
</p>
<p>using a circuit called a Look-Up Table (LUT), which can implement any arbitrary truth table. The details
</p>
<p>of an LUT are given in the next section. The CLB/LE also contains a D-flip-flop for sequential logic. A
</p>
<p>signal steering multiplexer is used to select whether the output of the CLB/LE comes from the LUT or
</p>
<p>from the D-flip-flop. The LUTcan be used to drive a combinational logic expression into the D input of the
</p>
<p>D-flip-flop, thus creating a highly efficient topology for finite-state machines. A global routing network is
</p>
<p>used to provide common signals to the CLB/LE such as clock, reset, and enable. This global routing
</p>
<p>network can provide these common signals to the entire FPGA or local groups of CLB/LEs. Figure 11.7
</p>
<p>shows the topology of a simple CLB/LE.
</p>
<p>Fig. 11.6
Field programmable gate array (FPGA) architecture
</p>
<p>376 &bull; Chapter 11: Programmable Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>CLB/LEs have evolved to include numerous other features such as carry in/carry out signals so that
</p>
<p>arithmetic operations can be cascaded between multiple blocks in addition to signal feedback and D-flip-
</p>
<p>flop initialization.
</p>
<p>11.2.2 Look-Up Tables
</p>
<p>An LUT is the primary circuit used to implement combinational logic in FPGAs. This topology has
</p>
<p>also been adopted in modern CPLDs. In an LUT, the desired outputs of a truth table are loaded into a
</p>
<p>local configuration SRAM memory. The SRAM memory provides these values to the inputs of a
</p>
<p>multiplexer. The inputs to the combinational logic circuit are then used as the select lines to the
</p>
<p>multiplexer. For an arbitrary input to the combinational logic circuit, the multiplexer selects the appropri-
</p>
<p>ate value held in the SRAM and routes it to the output of the circuit. In this way, the multiplexer looks up
</p>
<p>the appropriate output value based on the input code. This architecture has the advantage that any logic
</p>
<p>function can be created without creating a custom logic circuit. Also, the delay through the LUT is
</p>
<p>identical regardless of what logic function is being implemented. Figure 11.8 shows a 2-input combina-
</p>
<p>tional logic circuit implemented with a 4-input multiplexer.
</p>
<p>Fig. 11.7
Simple FPGA configurable logic block (or logic element)
</p>
<p>11.2 Field Programmable Gate Arrays &bull; 377</p>
<p/>
</div>
<div class="page"><p/>
<p>Fan-in limitations can be encountered quickly in LUTs as the number of inputs of the combinational
</p>
<p>logic circuit being implemented grows. Recall that multiplexers are implemented with an SOP topology in
</p>
<p>which each product term in the first level of logic has a number of inputs equal to the number of select
</p>
<p>lines plus one. Also recall that the sum term in the second level of logic in the SOP topology has a
</p>
<p>number of inputs equal to the total number of inputs to the multiplexer. In the example circuit shown in
</p>
<p>Fig. 11.8, each product term in the multiplexer will have three inputs and the sum term will have four
</p>
<p>inputs. As an illustration of how quickly fan-in limitations are encountered, consider the implication of
</p>
<p>increasing the number of inputs in Fig. 11.8 from two to three. In this new configuration, the number of
</p>
<p>inputs in the product terms will increase from three to four and the number of inputs in the sum term will
</p>
<p>increase from four to eight. Eight inputs is often beyond the fan-in specifications of modern devices,
</p>
<p>meaning that even a 3-input combinational logic circuit will encounter fan-in issues when implemented
</p>
<p>using an LUT topology.
</p>
<p>To address this issue, multiplexer functionality in LUTs is typically implemented as a series of
</p>
<p>smaller, cascaded multiplexers. Each of the smaller multiplexers progressively chooses which row of
</p>
<p>the truth table to route to the output of the LUT. This eliminates fan-in issues at the expense of adding
</p>
<p>additional levels of logic to the circuit. While cascading multiplexers increase the overall circuit delay, this
</p>
<p>approach achieves a highly consistent delay because regardless of the truth table output value, the
</p>
<p>number of levels of logic through the multiplexers is always the same. Figure 11.9 shows how the 2-input
</p>
<p>truth table from Fig. 11.8 can be implemented using a 2-level cascade of 2-input multiplexers.
</p>
<p>Fig. 11.8
2-Input LUT implemented with a 4-input multiplexer
</p>
<p>378 &bull; Chapter 11: Programmable Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>If more inputs are needed in the LUT, additional MUX levels are added. Figure 11.10 shows the
</p>
<p>architecture for a 3-input LUT implemented with a 3-level cascade of 2-input multiplexers.
</p>
<p>Fig. 11.9
2-Input LUT implemented with a 2-level cascade of 2-input multiplexers
</p>
<p>11.2 Field Programmable Gate Arrays &bull; 379</p>
<p/>
</div>
<div class="page"><p/>
<p>Modern FPGAs can have LUTs with up to 6 inputs. If even more inputs are needed in a combina-
</p>
<p>tional logic expression, then multiple CLB/LEs are used that form even larger LUTs.
</p>
<p>11.2.3 Programmable Interconnect Points (PIPs)
</p>
<p>The configurable routing network on an FPGA is accomplished using programmable switches. A
</p>
<p>simple model for these switches is to use an NMOS transistor. A configuration SRAM bit stores whether
</p>
<p>the switch is opened or closed. On the FPGA, interconnect is routed vertically and horizontally between
</p>
<p>the CLB/LEs with switching points placed throughout the FPGA to facilitate any arbitrary routing
</p>
<p>configuration. Figure 11.11 shows how the routing can be configured into a full cross-point configuration
</p>
<p>using programmable switches.
</p>
<p>Fig. 11.10
3-Input LUT implemented with a 3-level cascade of 2-input multiplexers
</p>
<p>380 &bull; Chapter 11: Programmable Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>11.2.4 Input/Output Block
</p>
<p>FPGAs also contain input/output blocks (IOBs) that provide programmable functionality for
</p>
<p>interfacing to external circuitry. The IOBs contain both driver and receiver circuitry so that they can be
</p>
<p>programmed to be either inputs or outputs. D-flip-flops are included in both the input and output circuitry
</p>
<p>to support synchronous logic. Figure 11.12 shows the architecture of an FPGA IOB.
</p>
<p>Fig. 11.11
FPGA programmable interconnect
</p>
<p>11.2 Field Programmable Gate Arrays &bull; 381</p>
<p/>
</div>
<div class="page"><p/>
<p>11.2.5 Configuration Memory
</p>
<p>All of the programming information for an FPGA is contained within configuration SRAM that is
</p>
<p>distributed across the IC. Since this memory is volatile, the FPGA will lose its configuration when power
</p>
<p>is removed. Upon power-up, the FPGA must be programmed with its configuration data. This data is
</p>
<p>typically held in a nonvolatile memory such as FLASH. The &ldquo;FP&rdquo; in FPGA refers to the ability to program
</p>
<p>the device in the field, or post-fabrication. The &ldquo;GA&rdquo; in FPGA refers to the array topology of the
</p>
<p>programmable logic blocks or elements.
</p>
<p>CC11.2 What is the primary difference between an FPGA and a CPLD?
</p>
<p>A) The ability to create arbitrary SOP logic expressions.
</p>
<p>B) The abundance of configurable routing.
</p>
<p>C) The inclusion of D-flip-flops.
</p>
<p>D) The inclusion of programmable I/O pins.
</p>
<p>CONCEPT CHECK
</p>
<p>Fig. 11.12
FPGA input/output block (IOB)
</p>
<p>382 &bull; Chapter 11: Programmable Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>Summary
</p>
<p>v A programmable logic device (PLD) is a
generic term for a circuit that can be
configured to implement arbitrary logic
functions.
</p>
<p>v There are a variety of PLD architectures that
have been used to implement combinational
logic. These include the PLA and PAL. These
devices contain an AND plane and an OR
plane. The AND plane is configured to imple-
ment the product terms of an SOP expres-
sion. The OR plane is configured to
implement the sum term of an SOP
expression.
</p>
<p>v A GAL increases the complexity of logic
arrays by adding sequential logic storage
and programmable I/O capability.
</p>
<p>v A CPLD significantly increases the density of
PLDs by connecting an array of PALs
together and surrounding the logic with I/O
drivers.
</p>
<p>v FPGAs contain an array of programmable
logic elements that each consists of combi-
national logic capability and sequential logic
storage. FPGAs also contain a programma-
ble interconnect network that provides the
highest level of flexibility in programmable
logic.
</p>
<p>v An LUT is a simple method to create a pro-
grammable combinational logic circuit. An
LUT is simply a multiplexer with the inputs
to the circuit connected to the select lines of
the MUX. The desired outputs of the truth
table are connected to the MUX inputs. As
different input codes arrive on the select lines
of the MUX, they select the corresponding
logic value to be routed to the system output.
</p>
<p>Exercise Problems
</p>
<p>Section 11.1: Programmable Arrays
</p>
<p>11.1.1 Name the type of programmable logic
described by the characteristic: this device
adds an output logic macrocell to a traditional
PAL.
</p>
<p>11.1.2 Name the type of programmable logic
described by the characteristic: this device
combines multiple PALs on a single chip with
a partitioned interconnect system.
</p>
<p>11.1.3 Name the type of programmable logic
described by the characteristic: this device
has a programmable AND plane and program-
mable OR plane.
</p>
<p>11.1.4 Name the type of programmable logic
described by the characteristic: this device
has a programmable AND plane and fixed
OR plane.
</p>
<p>11.1.5 Name the type of programmable logic
described by the characteristic: this device is
a PAL or GAL that is programmed during
manufacturing.
</p>
<p>11.1.6 For the following unconfigured PAL schematic
in Fig. 11.13, draw in the connection points
(i.e., the Xs) to implement the two SOP logic
expressions shown on the outputs.
</p>
<p>Fig. 11.13
Blank PAL Schematic
</p>
<p>Exercise Problems &bull; 383</p>
<p/>
</div>
<div class="page"><p/>
<p>Section 11.2: Field Programmable Gate
</p>
<p>Arrays
</p>
<p>11.2.1 Give a general description of an FPGA that
differentiates it from other programmable logic
devices.
</p>
<p>11.2.2 Which part of an FPGA is described by the
following characteristic: this is used to interface
between the internal logic and external
circuitry.
</p>
<p>11.2.3 Which part of an FPGA is described by the
following characteristic: this is used to config-
ure the on-chip routing.
</p>
<p>11.2.4 Which part of an FPGA is described by the
following characteristic: this is the primary pro-
grammable element that makes up the array.
</p>
<p>11.2.5 Which part of an FPGA is described by the
following characteristic: this part is used to
implement the combinational logic within the
array.
</p>
<p>11.2.6 Draw the logic diagram of a 4-input LUT to
implement the truth table provided in
Fig. 11.14. Implement the LUT with only
2-input multiplexers. Be sure to label the
exact location of the inputs (A, B, C, and D),
the desired value for each row of the truth
table, and the output (F) in the diagram.
</p>
<p>Fig. 11.14
4-Input LUT Exercise
</p>
<p>384 &bull; Chapter 11: Programmable Logic</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 12: Arithmetic Circuits
This chapter presents the design and timing considerations of circuits to perform basic arithmetic
</p>
<p>operations including addition, subtraction, multiplication, and division. A discussion is also presented on
</p>
<p>how to model arithmetic circuits in VHDL. The goal of this chapter is to provide an understanding of the
</p>
<p>basic principles of binary arithmetic circuits.
</p>
<p>Learning Outcomes&mdash;After completing this chapter, you will be able to:
</p>
<p>12.1 Design a binary adder using both the classical digital design approach and the modern
HDL-based approach.
</p>
<p>12.2 Design a binary subtractor using both the classical digital design approach and the modern
HDL-based approach.
</p>
<p>12.3 Design a binary multiplier using both the classical digital design approach and the modern
HDL-based approach.
</p>
<p>12.4 Design a binary divider using both the classical digital design approach and the modern
HDL-based approach.
</p>
<p>12.1 Addition
</p>
<p>Binary addition is performed in a similar manner to performing decimal addition by hand. The
</p>
<p>addition begins in the least significant position of the number (p &frac14; 0). The addition produces the sum
</p>
<p>for this position. In the event that this positional sum cannot be represented by a single symbol, then the
</p>
<p>higher-order symbol is carried to the subsequent position ( p &frac14; 1). The addition in the next higher
</p>
<p>position must include the number that was carried in from the lower positional sum. This process
</p>
<p>continues until all of the symbols in the number have been operated on. The final positional sum can
</p>
<p>also produce a carry, which needs to be accounted for in a separate system.
</p>
<p>Designing a binary adder involves creating a combinational logic circuit to perform the positional
</p>
<p>additions. Since a combinational logic circuit can only produce a scalar output, circuitry is needed to
</p>
<p>produce the sum and the carry at each position. The binary adder size is predetermined and fixed prior to
</p>
<p>implementing the logic (i.e., an n-bit adder). Both inputs to the adder must adhere to the fixed size,
</p>
<p>regardless of their value. Smaller numbers simply contain leading zeros in their higher-order positions.
</p>
<p>For an n-bit adder, the largest sum that can be produced will require n + 1 bits. To illustrate this, consider
</p>
<p>a 4-bit adder. The largest numbers that the adder will operate on are 11112 + 11112. (or 1510 + 1510). The
</p>
<p>result of this addition is 111102 (or 3010). Notice that the largest sum produced fits within 5 bits, or n + 1.
</p>
<p>When constructing an adder circuit, the sum is always recorded using n-bits with a separate carry out bit.
</p>
<p>In our 4-bit example, the sum would be expressed as &ldquo;1110&rdquo; with a carry out. The carry out bit can be
</p>
<p>used in multiple word additions, used as part of the number when being decoded for a display, or simply
</p>
<p>discarded as in the case when using two&rsquo;s complement numbers.
</p>
<p>12.1.1 Half Adders
</p>
<p>When creating an adder, it is desirable to design incremental subsystems that can be reused. This
</p>
<p>reduces design effort and minimizes troubleshooting complexity. The most basic component in the adder
</p>
<p>is called a half adder. This circuit computes the sum and carry out on two input arguments. The reason it
</p>
<p>is called a half adder instead of a full adder is because it does not accommodate a carry in during the
</p>
<p>computation, thus it does not provide all of the necessary functionality required for the positional adder.
</p>
<p># Springer International Publishing Switzerland 2017
</p>
<p>B.J. LaMeres, Introduction to Logic Circuits &amp; Logic Design with VHDL,
</p>
<p>DOI 10.1007/978-3-319-34195-8_12
</p>
<p>385</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 12.1 shows the design of a half adder. Notice that two combinational logic circuits are required
</p>
<p>in order to produce the sum (the XOR gate) and the carry out (the AND gate). These two gates are in
</p>
<p>parallel to each other, thus the delay through the half adder is due to only one level of logic.
</p>
<p>Example 12.1
Design of a half adder
</p>
<p>12.1.2 Full Adders
</p>
<p>A full adder is a circuit that still produces a sum and carry out, but considers three inputs in the
</p>
<p>computations (A, B, and Cin). Example 12.2 shows the design of a full adder.
</p>
<p>Example 12.2
Design of a full adder
</p>
<p>386 &bull; Chapter 12: Arithmetic Circuits</p>
<p/>
</div>
<div class="page"><p/>
<p>As mentioned before, it is desirable to reuse design components as we construct more complex
</p>
<p>systems. One such design reuse approach is to create a full adder using two half adders. This is
</p>
<p>straightforward for the sum output since the logic is simply two cascaded XOR gates (Sum &frac14; A�B�Cin).
</p>
<p>The carry out is not as straightforward. Notice that the expression for Cout derived in Example 12.2
</p>
<p>contains the term (A + B). If this term could be manipulated to use an XOR gate instead, it would allow
</p>
<p>the full adder to take advantage of existing circuitry in the system. Figure 12.1 shows a derivation of an
</p>
<p>equivalency that allows (A + B) to be replaced with (A�B) in the Cout logic expression.
</p>
<p>The ability to implement the carry out logic using the expression Cout &frac14; A�B + (A�B)�Cin allows us
</p>
<p>to implement a full adder with two half adders and the addition of a single OR gate. Example 12.3 shows
</p>
<p>this approach. In this new configuration, the sum is produced in two levels of logic while the carry out is
</p>
<p>produced in three levels of logic.
</p>
<p>Fig. 12.1
A useful logic equivalency that can be exploited in arithmetic circuits
</p>
<p>12.1 Addition &bull; 387</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 12.3
Design of a full adder out of half adders
</p>
<p>12.1.3 Ripple Carry Adder (RCA)
</p>
<p>The full adder can now be used in the creation of multi-bit adders. The simplest architecture
</p>
<p>exploiting the full adder is called a ripple carry adder (RCA). In this approach, full adders are used to
</p>
<p>create the sum and carry out of each bit position. The carry out of each full adder is used as the carry in
</p>
<p>for the next higher position. Since each subsequent full adder needs to wait for the carry to be produced
</p>
<p>by the preceding stage, the carry is said to ripple through the circuit, thus giving this approach its name.
</p>
<p>Example 12.4 shows how to design a 4-bit ripple carry adder using a chain of full adders. Notice that the
</p>
<p>carry in for the full adder in position 0 is tied to a logic 0. The 0 input has no impact on the result of the sum
</p>
<p>but enables a full adder to be used in the 0th position.
</p>
<p>388 &bull; Chapter 12: Arithmetic Circuits</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 12.4
Design of a 4-Bit Ripple Carry Adder (RCA)
</p>
<p>While the ripple carry adder provides a simple architecture based on design reuse, its delay can
</p>
<p>become considerable when scaling to larger inputs sizes (e.g., n &frac14; 32 or n &frac14; 64). A simple analysis of
</p>
<p>the timing can be stated such that if the time for a full adder to complete its positional sum is tFA, then the
</p>
<p>time for an n-bit ripple carry adder to complete its computation is tRCA &frac14; n�tFA.
</p>
<p>If we examine the RCA in more detail, we can break down the delay in terms of the levels of logic
</p>
<p>necessary for the computation. Example 12.5 shows the timing analysis of the 4-bit RCA. This analysis
</p>
<p>determines the number of logic levels in the adder. The actual gate delays can then be plugged in to find
</p>
<p>the final delay. The inputs to the adder are A, B, and Cin and are always assumed to update at the same
</p>
<p>time. The first full adder requires two levels of logic to produce its sum and three levels to produce its
</p>
<p>carry out. Since the timing of a circuit is always stated as its worst case delay, we say that the first full
</p>
<p>adder takes three levels of logic. When the carry (C1) ripples to the next full adder (FA1), it must
</p>
<p>propagate through two additional levels of logic in order to produce C2. Notice that the first half adder
</p>
<p>in FA1 only depends on A1 and B1, thus it is able to perform this computation immediately. This half adder
</p>
<p>can be considered as first-level logic. More importantly, it means that when the carry in arrives (C1), only
</p>
<p>two additional levels of logic are needed, not three. The levels of logic for the RCA can be expressed as
</p>
<p>3 + 2�(n � 1). If each level of logic has a delay of tgate, then a more accurate expression for the RCA
</p>
<p>delay is tRCA &frac14; (3 + 2�(n � 1))�tgate.
</p>
<p>12.1 Addition &bull; 389</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 12.5
Timing analysis of a 4-bit ripple carry adder
</p>
<p>12.1.4 Carry Look Ahead Adder (CLA)
</p>
<p>In order to address the potentially significant delay of a ripple carry adder, a carry look ahead (CLA)
</p>
<p>adder was created. In this approach, additional circuitry is included that produces the intermediate carry
</p>
<p>in signals immediately instead of waiting for them to be created by the preceding full adder stage. This
</p>
<p>allows the adder to complete in a fixed amount of time instead of one that scales with the number of bits in
</p>
<p>the adder. Example 12.6 shows an overview of the design approach for a CLA.
</p>
<p>390 &bull; Chapter 12: Arithmetic Circuits</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 12.6
Design of a 4-Bit Carry Look Ahead Adder (CLA)&mdash;Overview
</p>
<p>For the CLA architecture to be effective, the look ahead circuitry needs to be dependent only on the
</p>
<p>system inputs A, B, and Cin (i.e., C0). A secondary characteristic of the CLA is that it should exploit as
</p>
<p>much design reuse as possible. In order to examine the design reuse aspects of a multi-bit adder, the
</p>
<p>concepts of carry generation (g) and propagation (p) are used. A full adder is said to generate a carry if
</p>
<p>its inputs A and B result in Cout &frac14; 1 when Cin &frac14; 0. A full adder is said to propagate a carry if its inputs A
</p>
<p>and B result in Cout &frac14; 1 when Cin &frac14; 1. These simple statements can be used to derive logic expressions
</p>
<p>for each stage of the adder that can take advantage of existing logic terms from prior stages. Example
</p>
<p>12.7 shows the derivation of these terms and how algebraic substitutions can be exploited to create look
</p>
<p>ahead circuitry for each full adder that is only dependent on the system inputs. In these derivations, the
</p>
<p>variable i is used to represent position since p is used to represent the propagate term.
</p>
<p>12.1 Addition &bull; 391</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 12.7
Design of a 4-Bit Carry Look Ahead Adder (CLA)&mdash;algebraic formation
</p>
<p>Example 12.8 shows a timing analysis of the 4-bit carry look ahead adder. Notice that the full adders
</p>
<p>are modified to add the logic for the generate and propagate bits in addition to removing the unnecessary
</p>
<p>gates associated with creating the carry out.
</p>
<p>392 &bull; Chapter 12: Arithmetic Circuits</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 12.8
Timing analysis of a 4-bit carry look ahead adder
</p>
<p>The 4-bit CLA can produce the sum in four levels of logic as long as fan-in specifications are met. As
</p>
<p>the CLA width increases, the look ahead circuitry will become fan-in limited and additional stages will be
</p>
<p>required to address the fan-in. Regardless, the CLA has considerably less delay than a RCA as the width
</p>
<p>of the adder is increased.
</p>
<p>12.1.5 Adders in VHDL
</p>
<p>12.1.5.1 Structural Model of a Ripple Carry Adder in VHDL
</p>
<p>A structural model of a ripple carry adder is useful to visualize the propagation delay of the circuit in
</p>
<p>addition to the impact of the carry rippling through the chain. Example 12.9 shows the structural model for
</p>
<p>a full adder in VHDL consisting of two half adders. The full adder is created by instantiating two versions
</p>
<p>of the half adder as components. In this example, all gates are modeled with a delay of 1ns.
</p>
<p>12.1 Addition &bull; 393</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 12.9
Structural model of a full adder in VHDL using two half adders
</p>
<p>Example 12.10 shows the structural model of a 4-bit ripple carry adder in VHDL. The RCA is created
</p>
<p>by instantiating four full adders. Notice that a logic 0 can be directly inserted into the port map of the first
</p>
<p>full adder to model the behavior of C0 &frac14; 0.
</p>
<p>394 &bull; Chapter 12: Arithmetic Circuits</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 12.10
Structural model of a 4-bit ripple carry adder in VHDL
</p>
<p>When creating arithmetic circuitry, testing under all input conditions is necessary to verify function-
</p>
<p>ality. Testing under each and every input condition can require a large number of input conditions. To test
</p>
<p>an n-bit adder under each and every numeric input condition will take (2n)2 test vectors. For our simple
</p>
<p>4-bit adder example, this equates to 256 input patterns. The large number of input patterns precludes the
</p>
<p>use of manual signal assignments in the test bench to stimulate the circuit. One approach to generating
</p>
<p>the input test patterns is to use nested for loops. Example 12.11 shows a test bench that uses two nested
</p>
<p>for loops to generate the 256 unique input conditions for the 4-bit ripple carry adder. Note that the loop
</p>
<p>variables i and j are automatically created when the loops are declared. Since the loop variables are
</p>
<p>defined as integers, type conversions are required prior to driving the values into the RCA. The
</p>
<p>simulation waveform illustrates how the ripple carry adder has a noticeable delay before the output
</p>
<p>sum is produced. During the time the carry is rippling through the adder chain, glitches can appear on
</p>
<p>each of the sum bits in addition to the carry out signal. The values in this waveform are displayed as
</p>
<p>unsigned decimal symbols to make the results easier to interpret.
</p>
<p>12.1 Addition &bull; 395</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 12.11
VHDL test bench for a 4-bit ripple carry adder using nested for loops
</p>
<p>12.1.5.2 Structural Model of a Carry Look Ahead Adder in VHDL
</p>
<p>A carry look ahead adder can also be modeled using a combination of concurrent signal
</p>
<p>assignments with logical operators and modified full adder components. Example 12.12 shows a
</p>
<p>structural model for a 4-bit CLA in VHDL. In this example, the gate delay is modeled using a constant
</p>
<p>(tgate) of 1ns. The delay due to multiple levels of logic is entered manually to simplify the model. The two
</p>
<p>cascaded XOR gates in the modified full adder are modeled using a single signal assignment with
</p>
<p>2*tgate of delay.
</p>
<p>396 &bull; Chapter 12: Arithmetic Circuits</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 12.12
Structural model of a 4-bit carry look ahead adder in VHDL
</p>
<p>Example 12.13 shows the simulation waveform for the 4-bit carry look ahead adder. The outputs still
</p>
<p>have intermediate transitions while the combinational logic is computing the results; however, the overall
</p>
<p>delay of the adder is bound to &lt; 4*tgate.
</p>
<p>12.1 Addition &bull; 397</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 12.13
4-Bit carry look ahead adder&mdash;simulation waveform
</p>
<p>12.1.5.3 Behavior Model of an Adder Using UNSIGNED Data Types
</p>
<p>VHDL also supports adder models at a higher level of abstraction using the &ldquo;+&rdquo; operator. While this
</p>
<p>operator is supported for the type integer in the std_logic_1164 package, modeling adders using integers
</p>
<p>can be onerous due to the multiple levels of casting, range checking, and manual handling of carry out. A
</p>
<p>simpler approach to modeling adder behavior is to use the types unsigned/signed and the &ldquo;+&rdquo; operator
</p>
<p>provided in the numeric_std package. Temporary signals or variables of these types are required to
</p>
<p>model the adder behavior with the &ldquo;+&rdquo; sign. Also, type casting is still required when assigning the values
</p>
<p>back to the output ports. One advantage of this approach is that range checking is eliminated because
</p>
<p>rollover is automatically handled with these types.
</p>
<p>Example 12.14 shows the behavioral model for a 4-bit adder in VHDL. In this model, a 5-bit unsigned
</p>
<p>vector is created (Sum_uns). The two inputs, A and B, are concatenated with a leading zero in order to
</p>
<p>facilitate assigning the sum to this 5-bit vector. The advantage of this approach is that the carry out of the
</p>
<p>adder is automatically included in the sum as the highest position bit. Since A and B are of type
</p>
<p>std_logic_vector, they must be converted to unsigned before the addition with the &ldquo;+&rdquo; operator can
</p>
<p>take place. The concatenation, type conversion, and addition can all take place in a single assignment.
</p>
<p>Example:
</p>
<p>Sum_uns &lt;&frac14; unsigned((&rsquo;0&rsquo; &amp; A)) + unsigned((&rsquo;0&rsquo; &amp; B));
</p>
<p>The 5-bit vector Sum_uns now contains the 4-bit sum and carry out. The final step is to assign the
</p>
<p>separate components of this vector to the output ports of the system. The 4-bit sum portion requires a
</p>
<p>type conversion back to std_logic_vector before it can be assigned to the output port Sum. Since the
</p>
<p>Cout port is a scalar, an unsigned signal can be assigned to it directly without the need for a conversion.
</p>
<p>Example:
</p>
<p>Sum &lt;&frac14; std_logic_vector(Sum_uns(3 downto 0));
</p>
<p>Cout &lt;&frac14; Sum_uns(4);
</p>
<p>398 &bull; Chapter 12: Arithmetic Circuits</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 12.14
Behavioral model of a 4-bit adder in VHDL
</p>
<p>CC12.1 Does a binary adder behave differently when it&rsquo;s operating on unsigned vs. two&rsquo;s 
complement numbers?  Why or why not?
</p>
<p>A) Yes.  The adder needs to keep track of the sign bit, thus extra circuitry is needed.
</p>
<p>B) No.  The binary addition is identical.  It is up to the designer to handle how the two&rsquo;s 
complement codes are interpreted and whether two&rsquo;s complement overflow occurred 
using a separate system.
</p>
<p>CONCEPT CHECK
</p>
<p>12.2 Subtraction
</p>
<p>Binary subtraction can be accomplished by building a dedicated circuit using a similar design
</p>
<p>approach as just described for adders. A more effective approach is to take advantage of two&rsquo;s
</p>
<p>complement representation in order to reuse existing adder circuitry. Recall that taking the two&rsquo;s
</p>
<p>complement of a number will produce an equivalent magnitude number, but with the opposite sign
</p>
<p>(i.e., positive to negative or negative to positive). This means that all that is required to create a subtractor
</p>
<p>from an adder is to first take the two&rsquo;s complement of the subtrahend input. Since the steps to take the
</p>
<p>two&rsquo;s complement of a number involve complementing each of the bits in the number and then adding
</p>
<p>12.2 Subtraction &bull; 399</p>
<p/>
</div>
<div class="page"><p/>
<p>1, the logic required is relatively simple. Example 12.15 shows a 4-bit subtractor using full adders. The
</p>
<p>subtrahend B is inverted prior to entering the full adders. Also, the carry in bit C0 is set to 1. This handles
</p>
<p>the &ldquo;adding 1&rdquo; step of the two&rsquo;s complement. All of the carries in the circuit are now treated as borrows
</p>
<p>and the sum is now treated as the difference.
</p>
<p>Example 12.15
Design of a 4-bit subtractor using full adders
</p>
<p>A programmable adder/subtractor can be created with the use of a programmable inverter and a
</p>
<p>control signal. The control signal will selectively invert B and also change the C0 bit between a 0 (for
</p>
<p>adding) and a 1 (for subtracting). Example 12.16 shows how an XOR gate can be used to create a
</p>
<p>programmable inverter for use in a programmable adder/subtractor circuit.
</p>
<p>Example 12.16
Creating a programmable inverter using an XOR Gate
</p>
<p>400 &bull; Chapter 12: Arithmetic Circuits</p>
<p/>
</div>
<div class="page"><p/>
<p>We can now define a control signal called (ADDn/SUB) that will control whether the circuit performs
</p>
<p>addition or subtraction. Example 12.17 shows the architecture of a 4-bit programmable adder/subtractor.
</p>
<p>It should be noted that this programmability adds another level of logic to the circuit, thus increasing its
</p>
<p>delay. The programmable architecture in Example 12.17 is shown for a ripple carry adder; however, this
</p>
<p>approach works equally well for a carry look ahead adder architecture.
</p>
<p>Example 12.17
Design of a 4-bit programmable adder/subtractor
</p>
<p>When using two&rsquo;s complement representation in arithmetic, care must be taken to monitor for two&rsquo;s
</p>
<p>complement overflow. Recall that when using two&rsquo;s complement representation, the number of bits of the
</p>
<p>numbers is fixed (e.g., 4-bits) and if a carry/borrow out is generated, it is ignored. This means that the
</p>
<p>Cout bit does not indicate whether two&rsquo;s complement overflow occurred. Instead, we must construct
</p>
<p>additional circuitry to monitor the arithmetic operations for overflow. Recall from Chap. 2 that two&rsquo;s
</p>
<p>complement overflow occurs in any of these situations:
</p>
<p>&bull; The sum of like signs results in an answer with opposite sign
</p>
<p>(i.e., Positive + Positive &frac14; Negative or Negative + Negative &frac14; Positive).
&bull; The subtraction of a positive number from a negative number results in a positive number
</p>
<p>(i.e., Negative &ndash; Positive &frac14; Positive).
&bull; The subtraction of a negative number from a positive number results in a negative number
</p>
<p>(i.e., Positive &ndash; Negative &frac14; Negative).
</p>
<p>The construction of circuitry for these conditions is straightforward since the sign bit of all numbers
</p>
<p>involved in the operation indicates whether the number is positive or negative. The sign bits of the input
</p>
<p>arguments and the output are fed into combinational logic circuitry that will assert for any of the above
</p>
<p>conditions. These signals are then logically combined to create two&rsquo;s complement overflow signal.
</p>
<p>12.2 Subtraction &bull; 401</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-34195-8_2">http://dx.doi.org/10.1007/978-3-319-34195-8_2</a></div>
</div>
<div class="page"><p/>
<p>CC12.2 What modifications can be made to the programmable adder/subtractor architecture so 
that it can be used to take the 2&rsquo;s complement of a number?
</p>
<p>A) Remove the input A.
</p>
<p>B) Add an additional control signal that will cause the circuit to ignore A and just 
perform a complement on B and then add 1.
</p>
<p>C) Add an additional 1 to the original number using an OR gate on Cin.
</p>
<p>D) Set A to 0, put the number to be manipulated on B, and put the system into 
subtraction mode.  The system will then complement the bits on B and then add 
1, thus performing two&rsquo;s complement negation.
</p>
<p>CONCEPT CHECK
</p>
<p>12.3 Multiplication
</p>
<p>12.3.1 Unsigned Multiplication
</p>
<p>Binary multiplication is performed in a similar manner to performing decimal multiplication by hand.
</p>
<p>Recall the process for long multiplication. First, the two numbers are placed vertically over one another
</p>
<p>with their least significant digits aligned. The upper number is called the multiplicand and the lower
</p>
<p>number is called the multiplier. Next, we multiply each individual digit within multiplier with the entire
</p>
<p>multiplicand, starting with the least position. The result of this interim multiplication is called the partial
</p>
<p>product. The partial product is recorded with its least significant digit aligned with the corresponding
</p>
<p>position of the multiplier digit. Finally, all partial products are summed to create the final product of the
</p>
<p>multiplication. This process is often called the shift and add approach. Example 12.18 shows the process
</p>
<p>for performing long multiplication on decimal numbers highlighting the individual steps.
</p>
<p>Binary multiplication follows this same process. Example 12.19 shows the process for performing
</p>
<p>long multiplication on binary numbers. Note that the inputs represent the largest unsigned numbers
</p>
<p>possible using 4-bits, thus producing the largest possible product. The largest product will require 8-bits
</p>
<p>to be represented. This means that for anymultiplication of n-bit inputs, the product will require 2�n bits for
</p>
<p>the result.
</p>
<p>Example 12.18
Performing long multiplication on decimal numbers
</p>
<p>402 &bull; Chapter 12: Arithmetic Circuits</p>
<p/>
</div>
<div class="page"><p/>
<p>The first step in designing a binary multiplier is to create circuitry that can compute the product on
</p>
<p>individual bits. Example 12.20 shows the design of a single-bit multiplier.
</p>
<p>We can create all of the partial products in one level of logic by placing an AND gate between each
</p>
<p>bit pairing in the two input numbers. This will require n2 AND gates. The next step involves creating
</p>
<p>adders that can perform the sum of the columns of bits within the partial products. This step is not as
</p>
<p>straightforward. Notice that in our 4-bit example in Example 12.19 that the number of input bits in the
</p>
<p>column addition can reach up to 6 (in position 3). It would be desirable to reuse the full adders previously
</p>
<p>created; however, the existing full adders could only accommodate 3 inputs (A, B, Cin). We can take
</p>
<p>advantage of the associative property of addition to form the final sum incrementally. Example 12.21
</p>
<p>shows the architecture of this multiplier. This approach implements a shift and add process to compute
</p>
<p>the product and is known as a combinational multiplier because it is implemented using only combina-
</p>
<p>tional logic. Note that this multiplier only handles unsigned numbers.
</p>
<p>Example 12.20
Design of a single-bit multiplier
</p>
<p>Example 12.19
Performing long multiplication on binary numbers
</p>
<p>12.3 Multiplication &bull; 403</p>
<p/>
</div>
<div class="page"><p/>
<p>Thismultiplier canhaveasignificant delay,which iscausedby thecascaded full adders.Example12.22
</p>
<p>shows the timing analysis of the combinationalmultiplier highlighting theworst case path through the circuit.
</p>
<p>Example 12.21
Design of a 4-bit unsigned multiplier
</p>
<p>Example 12.22
Timing analysis of a 4-bit unsigned multiplier
</p>
<p>404 &bull; Chapter 12: Arithmetic Circuits</p>
<p/>
</div>
<div class="page"><p/>
<p>12.3.2 A Simple Circuit to Multiply by Powers of Two
</p>
<p>In digital systems, a common operation is to multiply numbers by powers of two. For unsigned
</p>
<p>numbers, multiplying by two can be accomplished by performing a logical shift left. In this operation, all
</p>
<p>bits are moved to the next higher position (i.e., left) by one position and filling the 0th position with a zero.
</p>
<p>This has the effect of doubling the value of the number. This can be repeated to achieve higher powers of
</p>
<p>two. This process works as long as the resulting product fits within the number of bits available. Example
</p>
<p>12.23 shows this procedure.
</p>
<p>12.3.3 Signed Multiplication
</p>
<p>When performing multiplication on signed numbers, it is desirable to reuse the unsigned multiplier in
</p>
<p>Example 12.21. Let&rsquo;s examine if this is possible. Recall in decimal multiplication that the inputs are
</p>
<p>multiplied together independent of their sign. The sign of the product is handled separately following
</p>
<p>these rules:
</p>
<p>&bull; A positive number times a positive number produces a positive number.
</p>
<p>&bull; A negative number times a negative number produces a positive number.
</p>
<p>&bull; A positive number times a negative number produces a negative number.
</p>
<p>This process does not work properly in binary due to the way that negative numbers are represented
</p>
<p>with two&rsquo;s complement. Example 12.24 illustrates how an unsigned multiplier incorrectly handles signed
</p>
<p>numbers.
</p>
<p>Example 12.23
Multiplying an unsigned binary number by two using a logical shift left
</p>
<p>12.3 Multiplication &bull; 405</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 12.24
Illustrating how an unsigned multiplier incorrectly handles signed numbers
</p>
<p>Instead of building a dedicated multiplier for signed numbers, we can add functionality to the
</p>
<p>unsigned multiplier previously presented to handle negative numbers. The process involves first
</p>
<p>identifying any negative numbers. If a negative number is present, the two&rsquo;s complement is taken on it
</p>
<p>to produce its equivalent magnitude, positive representation. The multiplication is then performed on the
</p>
<p>positive values. The final step is to apply the correct sign to the product. If the product should be negative
</p>
<p>due to one of the inputs being negative, the sign is applied by taking the two&rsquo;s complement on the final
</p>
<p>result. This creates a number that is now in 2�n two&rsquo;s complement format. Example 12.25 shows an
</p>
<p>illustration of the process to correctly handle signed numbers using an unsigned multiplier.
</p>
<p>406 &bull; Chapter 12: Arithmetic Circuits</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 12.25
Process to correctly handle signed numbers using an unsigned multiplier
</p>
<p>CC12.3 Will the AND gates used to compute the partial products in a binary multiplier ever 
experience an issue with fan-in as the size of the multiplier increases?
</p>
<p>A) Yes.  When the number of bits of the multiplier arguments exceed the fan-in 
specification of the AND gates used for the partial products, a fan-in issue has 
occurred.
</p>
<p>B) No.  The number of inputs of the AND gates performing the partial products will 
always be two, regardless of the size of the input arguments to the multiplier.
</p>
<p>CONCEPT CHECK
</p>
<p>12.3 Multiplication &bull; 407</p>
<p/>
</div>
<div class="page"><p/>
<p>12.4 Division
</p>
<p>12.4.1 Unsigned Division
</p>
<p>There are a variety of methods to perform division, each with trade-offs between area, delay, and
</p>
<p>accuracy. To understand the general approach to building a divider circuit, let&rsquo;s focus on how a simple
</p>
<p>iterative divider can be built. Basic division yields a quotient and a remainder. The process begins by
</p>
<p>checking whether the divisor goes into the highest position digit in the dividend. The number of times this
</p>
<p>dividend digit can be divided is recorded as the highest position value of the quotient. Note that when
</p>
<p>performing division by hand, we typically skip over the condition when the result of these initial operations
</p>
<p>are zero, but when breaking down the process into steps that can be built with logic circuits, each step
</p>
<p>needs to be highlighted. The first quotient digit is then multiplied with the divisor and recorded below the
</p>
<p>original dividend. The next lower position digit of the dividend is brought down and joined with the product
</p>
<p>from the prior multiplication. This forms a new number to be divided by the divisor to create the next
</p>
<p>quotient value. This process is repeated until each of the quotient digits have been created. Any value
</p>
<p>that remains after the last subtraction is recorded as the remainder. Example 12.26 shows the long
</p>
<p>division process on decimal numbers highlight each incremental step.
</p>
<p>Example 12.26
Performing long division on decimal numbers
</p>
<p>408 &bull; Chapter 12: Arithmetic Circuits</p>
<p/>
</div>
<div class="page"><p/>
<p>Long division in binary follows this same process. Example 12.27 shows the long division process
</p>
<p>on two 4-bit, unsigned numbers. This division results in a 4-bit quotient and a 4-bit remainder.
</p>
<p>Example 12.27
Performing long multiplication on binary numbers
</p>
<p>When building a divider circuit using combinational logic, we can accomplish the computation using
</p>
<p>a series of iterative subtractors. Performing division is equivalent to subtracting the divisor from the
</p>
<p>interim dividend. If the subtraction is positive, then the divisor went into the dividend and the quotient is a
</p>
<p>1. If the subtraction yields a negative number, then the divisor did not go into the interim dividend and the
</p>
<p>quotient is 0. We can use the borrow out of a subtraction chain to provide the quotient. This has the
</p>
<p>advantage that the difference has already been calculated for the next subtraction. A multiplexer is used
</p>
<p>to select whether the difference is used in the next subtraction (Q &frac14; 0), or if the interim divisor is simply
</p>
<p>brought down (Q &frac14; 1). This inherently provides the functionality of the multiplication step in long division.
</p>
<p>Example 12.28 shows the architecture of a 4-bit, unsigned divider based on the iterative subtraction
</p>
<p>approach. Notice that when the borrow out of the 4-bit subtractor chain is a 0, it indicates that the
</p>
<p>subtraction yielded a positive number. This means that the divisor went into the interim dividend once. In
</p>
<p>this case, the quotient for this position is a 1. An inverter is required to produce the correct polarity of the
</p>
<p>quotient. The borrow out is also fed into the multiplexer stage as the select line to pass the difference to
</p>
<p>the next stage of subtractors. If the borrow out of the 4-bit subtractor chain is a 1, it indicates that the
</p>
<p>subtraction yielded a negative number. In this case, the quotient is a 0. This also means that the
</p>
<p>difference calculated is garbage and should not be used. The multiplexer stage instead selects the
</p>
<p>interim dividend as the input to the next stage of subtractors.
</p>
<p>12.4 Division &bull; 409</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 12.28
Design of a 4-bit unsigned divider using a series of iterative subtractors
</p>
<p>To illustrate how this architecture works, Example 12.29 walks through each step in the process
</p>
<p>where 11112 (1510) is divided by 01112 (710). In this example, the calculations propagate through the logic
</p>
<p>stages from top to bottom in the diagram.
</p>
<p>410 &bull; Chapter 12: Arithmetic Circuits</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 12.29
Dividing 11112 (1510) by 01112 (710) using the iterative subtraction architecture
</p>
<p>12.4.2 A Simple Circuit to Divide by Powers of Two
</p>
<p>For unsigned numbers, dividing by two can be accomplished by performing a logical shift right. In
</p>
<p>this operation, all bits are moved to the next lower position (i.e., right) by one position and then filling the
</p>
<p>highest position with a zero. This has the effect of halving the value of the number. This can be repeated
</p>
<p>to achieve higher powers of two. This process works until no more ones exist in the number and the result
</p>
<p>is simply all zeros. Example 12.30 shows this process.
</p>
<p>12.4 Division &bull; 411</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 12.30
Dividing an unsigned binary numbers by two using a logical shift right
</p>
<p>12.4.3 Signed Division
</p>
<p>When performing division on signed numbers, a similar strategy as in signed multiplication is used.
</p>
<p>The process involves first identifying any negative numbers. If a negative number is present, the two&rsquo;s
</p>
<p>complement is taken on it to produce its equivalent magnitude, positive representation. The division is
</p>
<p>then performed on the positive values. The final step is to apply the correct sign to the divisor and
</p>
<p>quotient. This is accomplished by taking the two&rsquo;s complement if a negative number is required. The
</p>
<p>rules governing the polarities of the quotient and remainders are:
</p>
<p>&bull; The quotient will be negative if the input signs are different (i.e., pos/neg or neg/pos).
</p>
<p>&bull; The remainder has the same sign as the dividend.
</p>
<p>CC12.4 Could a shift register help reduce the complexity of a combinational divider circuit?  How?
</p>
<p>A) Yes.  Instead of having redundant circuits holding the different shifted versions of 
the divisor, a shift register could be used to hold and shift the divisor after each 
subtraction. 
</p>
<p>B) No.  A state machine would then be needed to control the divisor shifting, which 
would make the system even more complex.
</p>
<p>CONCEPT CHECK
</p>
<p>Summary
</p>
<p>v Binary arithmetic is accomplished using
combinational logic circuitry. These circuits
tend to be the largest circuits in a system
and have the longest delay. Arithmetic
circuits are often broken up into interim
calculations in order to reduce the overall
delay of the computation.
</p>
<p>v A ripple carry adder performs addition by
reusing lower-level components that each
</p>
<p>performs a small part of the computation. A
full adder is made from two half adders and a
ripple carry adder is made from a chain of full
adders. This approach simplifies the design
of the adder but leads to long delay times
since the carry from each sum must ripple
to the next higher position&rsquo;s addition before it
can complete.
</p>
<p>412 &bull; Chapter 12: Arithmetic Circuits</p>
<p/>
</div>
<div class="page"><p/>
<p>v A carry look ahead adder attempts to
eliminate the linear dependence of delay on
the number of bits that exists in a ripple carry
adder. The carry look ahead adder contains
dedicated circuitry that calculates the carry
bits for each position of the addition. This
leads to a more constant delay as the width
of the adder increases.
</p>
<p>v A binary multiplier can be created in a similar
manner to the way multiplication is accom-
plished by hand using the shift and add
</p>
<p>approach. The partial products of the multi-
plication can be performed using 2-input
AND gates. The sum of the partial products
can have more inputs than the typical ripple
carry adder can accommodate. To handle
this, the additions are performed two bits at
a time using a series of adders.
</p>
<p>v Division can be accomplished using an itera-
tive subtractor architecture.
</p>
<p>Exercise Problems
</p>
<p>Section 12.1: Addition
</p>
<p>12.1.1 Give the total delay of the full adder shown in
Fig. 12.2 if all gates have a delay of 1 ns.
</p>
<p>12.1.2 Give the total delay of the full adder shown in
Fig. 12.2 if the XOR gates have delays of 5 ns
while the AND and OR gates have delays of
1 ns.
</p>
<p>12.1.3 Give the total delay of the 4-bit ripple carry
adder shown in Fig. 12.3 if all gates have a
delay of 2 ns.
</p>
<p>12.1.4 Give the total delay of the 4-bit ripple carry
adder shown in Fig. 12.3 if the XOR gates
have delays of 10 ns while the AND and OR
gates have delays of 2 ns.
</p>
<p>12.1.5 Design a VHDL model for an 8-bit Ripple Carry
Adder (RCA) using a structural design
approach. This involves creating a half adder
(half_adder.vhd), full adder (full_adder.vhd),
and then finally a top-level adder (rca.vhd) by
instantiating eight full adder components.
Model the ripple delay by inserting 1ns of
</p>
<p>gate delay for the XOR, AND, and OR
operators using a delayed signal assignment.
The general topology and entity definition for
the design are shown in Fig. 12.4. Create a test
bench to exhaustively verify this design under
all input conditions. The test bench should
drive in different values every 30 ns in order
to give sufficient time for the signals to ripple
through the adder.
</p>
<p>12.1.6 Give the total delay of the 4-bit carry look
ahead adder shown in Fig. 12.5 if all gates
have a delay of 2 ns.
</p>
<p>12.1.7 Give the total delay of the 4-bit carry look
ahead adder shown in Fig. 12.5 if the XOR
gates have delays of 10ns while the AND and
OR gates have delays of 2 ns.
</p>
<p>12.1.8 Design a VHDL model for an 8-bit Carry Look
Ahead Adder (cla.vhd). The model should
</p>
<p>Fig. 12.2
Full Adder Timing Exercise
</p>
<p>Fig. 12.3
4-Bit RCA Timing Exercise
</p>
<p>Fig. 12.5
4-Bit CLA Timing Exercise
</p>
<p>Fig. 12.4
4-Bit RCA Entity
</p>
<p>Exercise Problems &bull; 413</p>
<p/>
</div>
<div class="page"><p/>
<p>instantiate eight modified full adders
(mod_full_adder.vhd). The carry look ahead
logic should be implemented using concurrent
signal assignments with logical operators.
Model each level of gate delay as 1ns using
delayed signal assignments. The general
topology and entity definition for the design
are shown in Fig. 12.6. Create a test bench to
exhaustively verify this design under all input
conditions. The test bench should drive in dif-
ferent values every 30 ns in order to give suffi-
cient time for the signals to propagate through
the adder.
</p>
<p>Section 12.2: Subtraction
</p>
<p>12.2.1 How is the programmable adder/subtractor
architecture shown in Fig. 12.7 analogous to
2&rsquo;s complement arithmetic?
</p>
<p>12.2.2 Will the programmable adder/subtractor archi-
tecture shown in Fig. 12.7 work for negative
numbers encoded using signed magnitude or
1&rsquo;s complement?
</p>
<p>12.2.3 When calculating the delay of the programma-
ble adder/subtractor architecture shown in
Fig. 12.7 does the delay of the XOR gate that
acts as the programmable inverter need to be
considered?
</p>
<p>12.2.4 Design a VHDL model for an 8-bit, program-
mable adder/subtractor. The design will have
an input called &ldquo;ADDn_SUB&rdquo; that will control
whether the system behaves as an adder (0) or
as a subtractor (1). The design should operate
on two&rsquo;s complement signed numbers. The
result of the operation(s) will appear on the
port called &ldquo;Sum_Diff&rdquo;. The model should
assert the output &ldquo;Cout&rdquo; when an addition
</p>
<p>creates a carry or when a subtraction creates
a borrow. The circuit will also assert the output
Vout when either operation results in two&rsquo;s
complement overflow. The entity definition
and block diagram for the system is shown in
Fig. 12.8. Create a test bench to exhaustively
verify this design under all input conditions.
</p>
<p>Section 12.3: Multiplication
</p>
<p>12.3.1 Give the total delay of the 4-bit unsigned multi-
plier shown in Fig. 12.9 if all gates have a delay
of 1ns. The addition is performed using a ripple
carry adder.
</p>
<p>12.3.2 For the 4-bit unsigned multiplier shown in
Fig. 12.9, how many levels of logic does it
take to compute all of the partial products?
</p>
<p>12.3.3 For the 4-bit unsigned multiplier shown in
Fig. 12.9, how many AND gates are needed
to compute the partial products?
</p>
<p>12.3.4 For the 4-bit unsigned multiplier shown in
Fig. 12.9, how many total AND gates are
used if the additions are implemented using
full adders made of half adders?
</p>
<p>12.3.5 Based on the architecture of a unsigned multi-
plier in Fig. 12.9, how many AND gates are
needed to compute the partial products if the
inputs are increased to 8-bits?
</p>
<p>12.3.6 For an 8-bit multiplier, how many bits are
needed to represent the product?
</p>
<p>Fig. 12.7
Programmable Adder/Subtractor Block
Diagram
</p>
<p>Fig. 12.6
4-Bit CLA Entity
</p>
<p>Fig. 12.8
Programmable Adder/Subtractor Entity
</p>
<p>Fig. 12.9
4-Bit Unsigned Multiplier Block Diagram
</p>
<p>414 &bull; Chapter 12: Arithmetic Circuits</p>
<p/>
</div>
<div class="page"><p/>
<p>12.3.7 For an 8-bit unsigned multiplier, what is the
largest value that the product can ever take
on? Give your answer in decimal.
</p>
<p>12.3.8 For an 8-bit signed multiplier, what is the larg-
est value that the product can ever take on?
Give your answer in decimal.
</p>
<p>12.3.9 For an 8-bit signed multiplier, what is the
smallest value that the product can ever take
on? Give your answer in decimal.
</p>
<p>12.3.10 What is the maximum number of times that a
4-bit unsigned multiplicand can be multiplied
by two using the logical shift left approach
before the product is too large to be
represented by an 8-bit-product? Hint: The
maximum number of times this operation can
be performed corresponds to when the multi-
plicand starts at its lowest possible nonzero
value (i.e., 1).
</p>
<p>12.3.11 Design a VHDL model for an 8-bit unsigned
multiplier using whatever modeling approach
you wish. Create a test bench to exhaustively
verify this design under all input conditions.
The entity definition for this multiplier is given
in Fig. 12.10. Hint: Consider converting the
inputs into type integers and then performing
the multiplication using the &ldquo;*&rdquo; operation. The
result of this operation will need to be an inter-
nal signal also of type interger. The integer
product can then be converted back to a 16-
bit std_logic_vector. Make sure to apply a
range to your internal integers.
</p>
<p>12.3.12 Design a VHDL model for an 8-bit signed mul-
tiplier using whatever modeling approach you
wish. Create a test bench to exhaustively verify
this design under all input conditions. The
entity definition for this multiplier is given in
Fig. 12.11. Hint: Consider converting the inputs
into type integers and then performing the mul-
tiplication using the &ldquo;*&rdquo; operation. The result of
this operation will need to be an internal signal
also of type interger. The integer product can
then be converted back to a 16-bit
std_logic_vector. Make sure to apply a range
to your internal integers.
</p>
<p>Section 12.4: Division
</p>
<p>12.4.1 For a 4-bit divider, how many bits are needed
for the quotient?
</p>
<p>12.4.2 For a 4-bit divider, how many bits are needed
for the remainder?
</p>
<p>12.4.3 Explain the basic concept of the iterative-
subtractor approach to division.
</p>
<p>12.4.4 For the 4-bit divider shown in Example 12.28,
estimate the total delay assuming all gates
have a delay of 1 ns.
</p>
<p>Fig. 12.11
8-Bit Signed Multiplier Entity
</p>
<p>Fig. 12.10
8-Bit Unsigned Multiplier Entity
</p>
<p>Exercise Problems &bull; 415</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 13: Computer System Design
One of the most common digital systems in use today is the computer. A computer accomplishes
</p>
<p>tasks through an architecture that uses both hardware and software. The hardware in a computer
</p>
<p>consists of many of the elements that we have covered so far. These include registers, arithmetic and
</p>
<p>logic circuits, finite-state machines, and memory. What makes a computer so useful is that the hardware
</p>
<p>is designed to accomplish a predetermined set of instructions. These instructions are relatively simple,
</p>
<p>such as moving data between memory and a register or performing arithmetic on two numbers. The
</p>
<p>instructions are comprised of binary codes that are stored in a memory device and represent the
</p>
<p>sequence of operations that the hardware will perform to accomplish a task. This sequence of
</p>
<p>instructions is called a computer program. What makes this architecture so useful is that the preexisting
</p>
<p>hardware can be programmed to perform an almost unlimited number of tasks by simply defining the
</p>
<p>sequence of instructions to be executed. The process of designing the sequence of instructions, or
</p>
<p>program, is called software development or software engineering.
</p>
<p>The idea of a general-purpose computing machine dates back to the nineteenth century. The first
</p>
<p>computing machines were implemented with mechanical systems and were typically analog in nature.
</p>
<p>As technology advanced, computer hardware evolved from electromechanical switches to vacuum
</p>
<p>tubes and ultimately to integrated circuits. These newer technologies enabled switching circuits and
</p>
<p>provided the capability to build binary computers. Today&rsquo;s computers are built exclusively with semicon-
</p>
<p>ductor materials and integrated circuit technology. The term microcomputer is used to describe a
</p>
<p>computer that has its processing hardware implemented with integrated circuitry. Nearly all modern
</p>
<p>computers are binary. Binary computers are designed to operate on a fixed set of bits. For example, an
</p>
<p>8-bit computer would perform operations on 8 bits at a time. This means it moves data between registers
</p>
<p>and memory and performs arithmetic and logic operations in groups of 8 bits.
</p>
<p>This chapter covers the basics of a simple computer system and presents the design of an 8-bit
</p>
<p>system to illustrate the details of instruction execution. The goal of this chapter is to provide an
</p>
<p>understanding of the basic principles of computer systems.
</p>
<p>Learning Outcomes&mdash;After completing this chapter, you will be able to:
</p>
<p>13.1 Describe the basic components and operation of computer hardware.
13.2 Describe the basic components and operation of computer software.
13.3 Design a fully operational computer system using VHDL.
13.4 Describe the difference between the Von Neumann and Harvard computer architectures.
</p>
<p>13.1 Computer Hardware
</p>
<p>Computer hardware refers to all of the physical components within the system. This hardware
</p>
<p>includes all circuit components in a computer such as the memory devices, registers, and finite-state
</p>
<p>machines. Figure 13.1 shows a block diagram of the basic hardware components in a computer.
</p>
<p># Springer International Publishing Switzerland 2017
</p>
<p>B.J. LaMeres, Introduction to Logic Circuits &amp; Logic Design with VHDL,
</p>
<p>DOI 10.1007/978-3-319-34195-8_13
</p>
<p>417</p>
<p/>
</div>
<div class="page"><p/>
<p>13.1.1 Program Memory
</p>
<p>The instructions that are executed by a computer are held in program memory. Program memory is
</p>
<p>treated as read-only memory during execution in order to prevent the instructions from being overwritten
</p>
<p>by the computer. Some computer systems will implement the program memory on a true ROM device
</p>
<p>(MROM or PROM), while others will use an EEPROM that can be read from during normal operation but
</p>
<p>can only be written to using a dedicated write procedure. Programs are typically held in nonvolatile
</p>
<p>memory so that the computer system does not lose its program when power is removed. Modern
</p>
<p>computers will often copy a program from nonvolatile memory (e.g., a hard disk drive) to volatile memory
</p>
<p>after start-up in order to speed up instruction execution. In this case, care must be taken that the program
</p>
<p>does not overwrite itself.
</p>
<p>13.1.2 Data Memory
</p>
<p>Computers also require data memory, which can be written to and read from during normal
</p>
<p>operation. This memory is used to hold temporary variables that are created by the software program.
</p>
<p>This memory expands the capability of the computer system by allowing large amounts of information to
</p>
<p>be created and stored by the program. Additionally, computations can be performed that are larger than
</p>
<p>the width of the computer system by holding interim portions of the calculation (e.g., performing a 128-bit
</p>
<p>addition on a 32-bit computer). Data memory is implemented with R/W memory, most often SRAM or
</p>
<p>DRAM.
</p>
<p>13.1.3 Input/Output Ports
</p>
<p>The term port is used to describe the mechanism to get information from the output world into or out
</p>
<p>of the computer. Ports can be input, output, or bidirectional. I/O ports can be designed to pass information
</p>
<p>in a serial or parallel format.
</p>
<p>Fig. 13.1
Hardware components of a computer system
</p>
<p>418 &bull; Chapter 13: Computer System Design</p>
<p/>
</div>
<div class="page"><p/>
<p>13.1.4 Central Processing Unit
</p>
<p>The central processing unit (CPU) is considered the brains of the computer. The CPU handles
</p>
<p>reading instructions from memory, decoding them to understand which instruction is being performed,
</p>
<p>and executing the necessary steps to complete the instruction. The CPU also contains a set of registers
</p>
<p>that are used for general-purpose data storage, operational information, and system status. Finally, the
</p>
<p>CPU contains circuitry to perform arithmetic and logic operations on data.
</p>
<p>13.1.4.1 Control Unit
</p>
<p>The control unit is a finite-state machine that controls the operation of the computer. This FSM has
</p>
<p>states that perform fetching the instruction (i.e., reading it from program memory), decoding the instruc-
</p>
<p>tion, and executing the appropriate steps to accomplish the instruction. This process is known as fetch,
</p>
<p>decode, and execute and is repeated each time an instruction is performed by the CPU. As the control
</p>
<p>unit state machine traverses through its states, it asserts control signals that move and manipulate data
</p>
<p>in order to achieve the desired functionality of the instruction.
</p>
<p>13.1.4.2 Data Path: Registers
</p>
<p>The CPU groups its registers and ALU into a subsystem called the data path. The data path refers to
</p>
<p>the fast storage and data manipulations within the CPU. All of these operations are initiated and
</p>
<p>managed by the control unit state machine. The CPU contains a variety of registers that are necessary
</p>
<p>to execute instructions and hold status information about the system. Basic computers have the following
</p>
<p>registers in their CPU:
</p>
<p>&bull; Instruction Register (IR)&mdash;The instruction register holds the current binary code of the
instruction being executed. This code is read from program memory as the first part of
instruction execution. The IR is used by the control unit to decide which states in its FSM to
traverse in order to execute the instruction.
</p>
<p>&bull; Memory Address Register (MAR)&mdash;The MAR is used to hold the current address being used
to access memory. The MAR can be loaded with addresses in order to fetch instructions from
program memory or with addresses to access data memory and/or I/O ports.
</p>
<p>&bull; Program Counter (PC)&mdash;The program counter holds the address of the current instruction
being executed in program memory. The program counter will increment sequentially through
the program memory reading instructions until a dedicated instruction is used to set it to a new
location.
</p>
<p>&bull; General-Purpose Registers&mdash;These registers are available for temporary storage by the
program. Instructions exist to move information from memory into these registers and to move
information from these registers into memory. Instructions also exist to perform arithmetic and
logic operations on the information held in these registers.
</p>
<p>&bull; Condition Code Register (CCR)&mdash;The CCR holds status flags that provide information about
the arithmetic and logic operations performed in the CPU. Themost common flags are negative
(N), zero (Z), two&rsquo;s complement overflow (V), and carry (C). This register can also contain flags
that indicate the status of the computer, such as if an interrupt has occurred or if the computer
has been put into a low-power mode.
</p>
<p>13.1.4.3 Data Path: Arithmetic Logic Unit
</p>
<p>The arithmetic logic unit (ALU) is the system that performs all mathematical (i.e., addition, subtrac-
</p>
<p>tion, multiplication, and division) and logic operations (i.e., and, or, not, shifts). This system operates on
</p>
<p>data being held in CPU registers. The ALU has a unique symbol associated with it to distinguish it from
</p>
<p>other functional units in the CPU.
</p>
<p>13.1 Computer Hardware &bull; 419</p>
<p/>
</div>
<div class="page"><p/>
<p>Figure 13.2 shows the typical organization of a CPU. The registers and ALU are grouped into the
</p>
<p>data path. In this example, the computer system has two general-purpose registers called A and B. This
</p>
<p>CPU organization will be used throughout this chapter to illustrate the detailed execution of instructions.
</p>
<p>13.1.5 A Memory Mapped System
</p>
<p>A common way to simplify moving data in or out of the CPU is to assign a unique address to all
</p>
<p>hardware components in the memory system. Each input/output port and each location in both program
</p>
<p>and data memory are assigned a unique address. This allows the CPU to access everything in the
</p>
<p>memory system with a dedicated address. This reduces the number of lines that must pass into the CPU.
</p>
<p>A bus system facilitates transferring information within the computer system. An address bus is driven by
</p>
<p>the CPU to identify which location in the memory system is being accessed. A data bus is used to
</p>
<p>transfer information to/from the CPU and the memory system. Finally, a control bus is used to provide
</p>
<p>other required information about the transactions such as read or write lines. Figure 13.3 shows the
</p>
<p>computer hardware in a memory mapped architecture.
</p>
<p>Fig. 13.2
Typical CPU organization
</p>
<p>420 &bull; Chapter 13: Computer System Design</p>
<p/>
</div>
<div class="page"><p/>
<p>To help visualize how the memory addresses are assigned, a memory map is used. This is a
</p>
<p>graphical depiction of the memory system. In the memory map, the ranges of addresses are provided for
</p>
<p>each of the main subsections of memory. This gives the programmer a quick overview of the available
</p>
<p>resources in the computer system. Example 13.1 shows a representative memory map for a computer
</p>
<p>system with an address bus with a width of 8 bits. This address bus can provide 256 unique locations.
</p>
<p>For this example, the memory system is also 8 bits wide; thus the entire memory system is 256x8 in size.
</p>
<p>In this example 128 bytes are allocated for program memory; 96 bytes are allocated for data memory;
</p>
<p>16 bytes are allocated for output ports; and 16 bytes are allocated for input ports.
</p>
<p>CC13.1 Is the hardware of a computer programmed in a similar way to a programmable logic 
</p>
<p>device?
</p>
<p>A) Yes.  The control unit is reconfigured to produce the correct logic for each unique 
instruction just like a logic element in an FPGA is reconfigured to produce the  
desired logic expression.
</p>
<p>B) No.  The instruction code from program memory simply tells the state machine in 
the control unit which path to traverse in order to accomplish the desired task.
</p>
<p>CONCEPT CHECK
</p>
<p>Fig. 13.3
Computer hardware in a memory mapped configuration
</p>
<p>13.1 Computer Hardware &bull; 421</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 13.1
Memory map for a 256 � 8 memory system
</p>
<p>13.2 Computer Software
</p>
<p>Computer software refers to the instructions that the computer can execute and how they are
</p>
<p>designed to accomplish various tasks. The specific group of instructions that a computer can execute
</p>
<p>is known as its instruction set. The instruction set of a computer needs to be defined first before the
</p>
<p>computer hardware can be implemented. Some computer systems have a very small number of
</p>
<p>instructions in order to reduce the physical size of the circuitry needed in the CPU. This allows the
</p>
<p>CPU to execute the instructions very quickly, but requires a large number of operations to accomplish a
</p>
<p>given task. This architectural approach is called a reduced instruction set computer (RISC). The
</p>
<p>alternative to this approach is to make an instruction set with a large number of dedicated instructions
</p>
<p>that can accomplish a given task in fewer CPU operations. The drawback of this approach is that the
</p>
<p>physical size of the CPU must be larger in order to accommodate the various instructions. This
</p>
<p>architectural approach is called a complex instruction set computer (CISC).
</p>
<p>13.2.1 Opcodes and Operands
</p>
<p>A computer instruction consists of two fields, an opcode and an operand. The opcode is a unique
</p>
<p>binary code given to each instruction in the set. The CPU decodes the opcode in order to know which
</p>
<p>instruction is being executed and then takes the appropriate steps to complete the instruction. Each
</p>
<p>opcode is assigned a mnemonic, which is a descriptive name for the opcode that can be used when
</p>
<p>discussing the instruction functionally. An operand is additional information for the instruction that may be
</p>
<p>required. An instruction may have any number of operands including zero. Figure 13.4 shows an
</p>
<p>example of how the instruction opcodes and operands are placed into program memory.
</p>
<p>422 &bull; Chapter 13: Computer System Design</p>
<p/>
</div>
<div class="page"><p/>
<p>13.2.2 Addressing Modes
</p>
<p>An addressing mode describes the way in which the operand of an instruction is used. While modern
</p>
<p>computer systems may contain numerous addressing modes with varying complexities, we will focus on
</p>
<p>just a subset of basic addressing modes. These modes are immediate, direct, inherent, and indexed.
</p>
<p>13.2.2.1 Immediate Addressing (IMM)
</p>
<p>Immediate addressing is when the operand of an instruction is the information to be used by the
</p>
<p>instruction. For example, if an instruction existed to put a constant into a register within the CPU using
</p>
<p>immediate addressing, the operand would be the constant. When the CPU reads the operand, it simply
</p>
<p>inserts the contents into the CPU register and the instruction is complete.
</p>
<p>13.2.2.2 Direct Addressing (DIR)
</p>
<p>Direct addressing is when the operand of an instruction contains the address of where the informa-
</p>
<p>tion to be used is located. For example, if an instruction existed to put a constant into a register within the
</p>
<p>CPU using direct addressing, the operand would contain the address of where the constant was located
</p>
<p>in memory. When the CPU reads the operand, it puts this value out on the address bus and performs an
</p>
<p>additional read to retrieve the contents located at that address. The value read is then put into the CPU
</p>
<p>register and the instruction is complete.
</p>
<p>13.2.2.3 Inherent Addressing (INH)
</p>
<p>Inherent addressing refers to an instruction that does not require an operand because the opcode
</p>
<p>itself contains all of the necessary information for the instruction to complete. This type of addressing is
</p>
<p>used on instructions that performmanipulations on data held in CPU registers without the need to access
</p>
<p>Fig. 13.4
Anatomy of a computer instruction
</p>
<p>13.2 Computer Software &bull; 423</p>
<p/>
</div>
<div class="page"><p/>
<p>the memory system. For example, if an instruction existed to increment the contents of a register (A),
</p>
<p>then once the opcode is read by the CPU, it knows everything it needs to know in order to accomplish the
</p>
<p>task. The CPU simply asserts a series of control signals in order to increment the contents of A and then
</p>
<p>the instruction is complete. Notice that no operand is needed for this task. Instead, the location of the
</p>
<p>register to be manipulated (i.e., A) is inherent within the opcode.
</p>
<p>13.2.2.4 Indexed Addressing (IND)
</p>
<p>Indexed addressing refers to instructions that will access information at an address in memory to
</p>
<p>complete the instruction, but the address to be accessed is held in another CPU register. In this type of
</p>
<p>addressing, the operand of the instruction is used as an offset that can be applied to the address located
</p>
<p>in the CPU register. For example, let&rsquo;s say an instruction existed to put a constant into a register
</p>
<p>(A) within the CPU using indexed addressing. Let&rsquo;s also say that the instruction was designed to use
</p>
<p>the contents of another register (B) as part of the address of where the constant was located. When the
</p>
<p>CPU reads the opcode, it understands what the instruction is and that B holds part of the address to be
</p>
<p>accessed. It also knows that the operand is applied to B to form the actual address to be accessed.When
</p>
<p>the CPU reads the operand, it adds the value to the contents of B and then puts this new value out on the
</p>
<p>address bus and performs an additional read. The value read is then put into the CPU register A and the
</p>
<p>instruction is complete.
</p>
<p>13.2.3 Classes of Instructions
</p>
<p>There are three general classes of instructions: (1) loads and stores; (2) data manipulations; and
</p>
<p>(3) branches. To illustrate how these instructions are executed, examples will be given based on the
</p>
<p>computer architecture shown in Fig. 13.3.
</p>
<p>13.2.3.1 Loads and Stores
</p>
<p>This class of instructions accomplishes moving information between the CPU and memory. A load
</p>
<p>is an instruction that moves information from memory into a CPU register. When a load instruction uses
</p>
<p>immediate addressing, the operand of the instruction is the data to be loaded into the CPU register. As an
</p>
<p>example, let&rsquo;s look at an instruction to load the general-purpose register A using immediate addressing.
</p>
<p>Let&rsquo;s say that the opcode of the instruction is x&rdquo;86,&rdquo; has a mnemonic LDA_IMM, and is inserted into
</p>
<p>program memory starting at x&rdquo;00.&rdquo; Example 13.2 shows the steps involved in executing the LDA_IMM
</p>
<p>instruction.
</p>
<p>424 &bull; Chapter 13: Computer System Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 13.2
Execution of an instruction to &ldquo;Load Register A Using Immediate Addressing&rdquo;
</p>
<p>Now let&rsquo;s look at a load instruction using direct addressing. In direct addressing, the operand of the
</p>
<p>instruction is the address of where the data to be loaded resides. As an example, let&rsquo;s look at an
</p>
<p>instruction to load the general-purpose register A. Let&rsquo;s say that the opcode of the instruction is x&rdquo;87,&rdquo;
</p>
<p>has a mnemonic LDA_DIR, and is inserted into program memory starting at x&rdquo;08.&rdquo; The value to be
</p>
<p>loaded into A resides at address x&rdquo;80,&rdquo; which has already been initialized with x&rdquo;AA&rdquo; before this
</p>
<p>instruction. Example 13.3 shows the steps involved in executing the LDA_DIR instruction.
</p>
<p>13.2 Computer Software &bull; 425</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 13.3
Execution of an instruction to &ldquo;Load Register A Using Direct Addressing&rdquo;
</p>
<p>A store is an instruction that moves information from a CPU register intomemory. The operand of a
</p>
<p>store instruction indicates the address of where the contents of the CPU register will be written. As an
</p>
<p>example, let&rsquo;s look at an instruction to store the general-purpose register A into memory address x&rdquo;E0.&rdquo;
</p>
<p>Let&rsquo;s say that the opcode of the instruction is x&rdquo;96,&rdquo; has a mnemonic STA_DIR, and is inserted into
</p>
<p>program memory starting at x&rdquo;04.&rdquo; The initial value of A is x&rdquo;CC&rdquo; before the instruction is executed.
</p>
<p>Example 13.4 shows the steps involved in executing the STA_DIR instruction.
</p>
<p>426 &bull; Chapter 13: Computer System Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 13.4
Execution of an instruction to &ldquo;Store Register A Using Direct Addressing&rdquo;
</p>
<p>13.2.3.2 Data Manipulations
</p>
<p>This class of instructions refers to ALU operations. These operations take action on data that
</p>
<p>resides in the CPU registers. These instructions include arithmetic, logic operators, shifts and rotates,
</p>
<p>and tests and compares. Data manipulation instructions typically use inherent addressing because the
</p>
<p>operations are conducted on the contents of CPU registers and don&rsquo;t require additional memory access.
</p>
<p>As an example, let&rsquo;s look at an instruction to perform addition on registers A and B. The sum will be
</p>
<p>placed back in A. Let&rsquo;s say that the opcode of the instruction is x&rdquo;42,&rdquo; has a mnemonic ADD_AB, and is
</p>
<p>inserted into program memory starting at x&rdquo;04.&rdquo; Example 13.5 shows the steps involved in executing the
</p>
<p>ADD_AB instruction.
</p>
<p>13.2 Computer Software &bull; 427</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 13.5
Execution of an instruction to &ldquo;Add Registers A and B&rdquo;
</p>
<p>13.2.3.3 Branches
</p>
<p>In the previous examples the program counter was always incremented to point to the address of
</p>
<p>the next instruction in programmemory. This behavior only supports a linear execution of instructions. To
</p>
<p>provide the ability to specifically set the value of the program counter, instructions called branches are
</p>
<p>used. There are two types of branches: unconditional and conditional. In an unconditional branch, the
</p>
<p>program counter is always loaded with the value provided in the operand. As an example, let&rsquo;s look at an
</p>
<p>instruction to branch always to a specific address. This allows the program to perform loops. Let&rsquo;s say
</p>
<p>that the opcode of the instruction is x&rdquo;20,&rdquo; has a mnemonic BRA, and is inserted into program memory
</p>
<p>starting at x&rdquo;06.&rdquo; Example 13.6 shows the steps involved in executing the BRA instruction.
</p>
<p>428 &bull; Chapter 13: Computer System Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 13.6
Execution of an instruction to &ldquo;Branch Always&rdquo;
</p>
<p>In a conditional branch, the program counter is only updated if a particular condition is true. The
</p>
<p>conditions come from the status flags in the CCR (NZVC). This allows a program to selectively execute
</p>
<p>instructions based on the result of a prior operation. Let&rsquo;s look at an example instruction that will branch
</p>
<p>only if the Z flag is asserted. This instruction is called a branch if equal to zero. Let&rsquo;s say that the opcode
</p>
<p>of the instruction is x&rdquo;23,&rdquo; has a mnemonic BEQ, and is inserted into program memory starting at x&rdquo;05.&rdquo;
</p>
<p>Example 13.7 shows the steps involved in executing the BEQ instruction.
</p>
<p>13.2 Computer Software &bull; 429</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 13.7
Execution of an instruction to &ldquo;Branch if Equal to Zero&rdquo;
</p>
<p>Conditional branches allow computer programs to make decisions about which instructions to
</p>
<p>execute based on the results of previous instructions. This gives computers the ability to react to input
</p>
<p>signals or take action based on the results of arithmetic or logic operations. Computer instruction sets
</p>
<p>typically contain conditional branches based on the NZVC flags in the CCR. The following instructions
</p>
<p>are based on the values of the NZVC flags:
</p>
<p>&bull; BMI&mdash;Branch if minus (N &frac14; 1)
</p>
<p>&bull; BPL&mdash;Branch if plus (N &frac14; 0)
</p>
<p>&bull; BEQ&mdash;Branch if equal to zero (Z &frac14; 1)
</p>
<p>430 &bull; Chapter 13: Computer System Design</p>
<p/>
</div>
<div class="page"><p/>
<p>&bull; BNE&mdash;Branch if not equal to Zero (Z &frac14; 0)
</p>
<p>&bull; BVS&mdash;Branch if two&rsquo;s complement overflow occurred, or V is set (V &frac14; 1)
</p>
<p>&bull; BVC&mdash;Branch if two&rsquo;s complement overflow did not occur, or V is clear (V &frac14; 0)
</p>
<p>&bull; BCS&mdash;Branch if a carry occurred, or C is set (C &frac14; 1)
</p>
<p>&bull; BCC&mdash;Branch if a carry did not occur, or C is clear (C &frac14; 0)
</p>
<p>Combinations of these flags can be used to create more conditional branches.
</p>
<p>&bull; BHI&mdash;Branch if higher (C &frac14; 1 and Z &frac14; 0)
</p>
<p>&bull; BLS&mdash;Branch if lower or the same (C &frac14; 0 and Z &frac14; 1)
</p>
<p>&bull; BGE&mdash;Branch if greater than or equal ((N &frac14; 0 and V &frac14; 0) or (N &frac14; 1 and V &frac14; 1)), only valid for
signed numbers
</p>
<p>&bull; BLT&mdash;Branch if less than ((N &frac14; 1 and V &frac14; 0) or (N &frac14; 0 and V &frac14; 1)), only valid for signed
numbers
</p>
<p>&bull; BGT&mdash;Branch if greater than ((N &frac14; 0 and V &frac14; 0 and Z &frac14; 0) or (N &frac14; 1 and V &frac14; 1 and Z &frac14; 0)),
only valid for signed numbers
</p>
<p>&bull; BLE&mdash;Branch if less than or equal ((N &frac14; 1 and V &frac14; 0) or (N &frac14; 0 and V &frac14; 1) or (Z &frac14; 1)), only
valid for signed numbers
</p>
<p>CC13.2 Software development consists of choosing which instructions, and in what order, will be 
executed to accomplish a certain task.  The group of instructions is called the program
and is inserted into program memory.  Which of the following might a software developer 
care about?
</p>
<p>A) Minimizing the number of instructions that need to be executed to accomplish the 
task in order to increase the computation rate.
</p>
<p>B) Minimizing the number of registers used in the CPU to save power.
</p>
<p>C) Minimizing the overall size of the program to reduce the amount of program 
memory needed.
</p>
<p>D) Both A and C.
</p>
<p>CONCEPT CHECK
</p>
<p>13.3 Computer Implementation: An 8-Bit Computer Example
</p>
<p>13.3.1 Top-Level Block Diagram
</p>
<p>Let&rsquo;s now look at the detailed implementation and instruction execution of a computer system. In
</p>
<p>order to illustrate the detailed operation, we will use a simple 8-bit computer system design. Example
</p>
<p>13.8 shows the block diagram for the 8-bit computer system. This block diagram also contains the VHDL
</p>
<p>file and entity names, which will be used when the behavioral model is implemented.
</p>
<p>13.3 Computer Implementation: An 8-Bit Computer Example &bull; 431</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 13.8
Top-level block diagram for the 8-bit computer system
</p>
<p>We will use the memory map shown in Example 13.1 for our example computer system. This
</p>
<p>mapping provides 128 bytes of program memory, 96 bytes of data memory, 16� output ports, and 16�
</p>
<p>input ports. To simplify the operation of this example computer, the address bus is limited to 8 bits. This
</p>
<p>only provides 256 locations of memory access, but allows an entire address to be loaded into the CPU as
</p>
<p>a single operand of an instruction.
</p>
<p>13.3.2 Instruction Set Design
</p>
<p>Example 13.9 shows a basic instruction set for our example computer system. This set provides a
</p>
<p>variety of loads and stores, data manipulations, and branch instructions that will allow the computer to be
</p>
<p>programmed to perform more complex tasks through software development. These instructions are
</p>
<p>sufficient to provide a baseline of functionality in order to get the computer system operational. Additional
</p>
<p>instructions can be added as desired to increase the complexity of the system.
</p>
<p>432 &bull; Chapter 13: Computer System Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 13.9
Instruction set for the 8-bit computer system
</p>
<p>13.3.3 Memory System Implementation
</p>
<p>Let&rsquo;s now look at the memory system details. The memory system contains program memory, data
</p>
<p>memory, and input/output ports. Example 13.10 shows the block diagram of the memory system. The
</p>
<p>program and data memory will be implemented using lower level components (rom_128x8_sync.vhd
</p>
<p>and rw_96x8_sync.vhd), while the input and output ports can be modeled using a combination of RTL
</p>
<p>processes and combinational logic. The program and data memory components contain dedicated
</p>
<p>circuitry to handle their addressing ranges. Each output port also contains dedicated circuitry to handle
</p>
<p>its unique address. A multiplexer is used to handle the signal routing back to the CPU based on the
</p>
<p>address provided.
</p>
<p>13.3 Computer Implementation: An 8-Bit Computer Example &bull; 433</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 13.10
Memory system block diagram for the 8-bit computer system
</p>
<p>13.3.3.1 Program Memory Implementation in VHDL
</p>
<p>The program memory can be implemented in VHDL using the modeling techniques presented in
</p>
<p>Chap. 12. To make the VHDL more readable, the instruction mnemonics can be declared as constants.
</p>
<p>This allows the mnemonic to be used when populating the program memory array. The following VHDL
</p>
<p>shows how the mnemonics for our basic instruction set can be defined as constants:
</p>
<p>constant LDA_IMM : std_logic_vector (7 downto 0) :&frac14; x"86";
</p>
<p>constant LDA_DIR : std_logic_vector (7 downto 0) :&frac14; x"87";
</p>
<p>constant LDB_IMM : std_logic_vector (7 downto 0) :&frac14; x"88";
</p>
<p>constant LDB_DIR : std_logic_vector (7 downto 0) :&frac14; x"89";
</p>
<p>constant STA_DIR : std_logic_vector (7 downto 0) :&frac14; x"96";
</p>
<p>constant STB_DIR : std_logic_vector (7 downto 0) :&frac14; x"97";
</p>
<p>constant ADD_AB : std_logic_vector (7 downto 0) :&frac14; x"42";
</p>
<p>constant SUB_AB : std_logic_vector (7 downto 0) :&frac14; x"43";
</p>
<p>constant AND_AB : std_logic_vector (7 downto 0) :&frac14; x"44";
</p>
<p>constant OR_AB : std_logic_vector (7 downto 0) :&frac14; x"45";
</p>
<p>constant INCA : std_logic_vector (7 downto 0) :&frac14; x"46";
</p>
<p>constant INCB : std_logic_vector (7 downto 0) :&frac14; x"47";
</p>
<p>constant DECA : std_logic_vector (7 downto 0) :&frac14; x"48";
</p>
<p>constant DECB : std_logic_vector (7 downto 0) :&frac14; x"49";
</p>
<p>constant BRA : std_logic_vector (7 downto 0) :&frac14; x"20";
</p>
<p>constant BMI : std_logic_vector (7 downto 0) :&frac14; x"21";
</p>
<p>constant BPL : std_logic_vector (7 downto 0) :&frac14; x"22";
</p>
<p>constant BEQ : std_logic_vector (7 downto 0) :&frac14; x"23";
</p>
<p>constant BNE : std_logic_vector (7 downto 0) :&frac14; x"24";
</p>
<p>constant BVS : std_logic_vector (7 downto 0) :&frac14; x"25";
</p>
<p>434 &bull; Chapter 13: Computer System Design</p>
<p/>
</div>
<div class="page"><p/>
<p>constant BVC : std_logic_vector (7 downto 0) :&frac14; x"26";
</p>
<p>constant BCS : std_logic_vector (7 downto 0) :&frac14; x"27";
</p>
<p>constant BCC : std_logic_vector (7 downto 0) :&frac14; x"28";
</p>
<p>Now the program memory can be declared as an array type with initial values to define the program.
</p>
<p>The following VHDL shows how to declare the program memory and an example program to perform a
</p>
<p>load, store, and a branch always. This program will continually write x&rdquo;AA&rdquo; to port_out_00:
</p>
<p>type rom_type is array (0 to 127) of std_logic_vector(7 downto 0);
</p>
<p>constant ROM : rom_type :&frac14; (0 &frac14;&gt; LDA_IMM,
</p>
<p>1 &frac14;&gt; x"AA",
</p>
<p>2 &frac14;&gt; STA_DIR,
</p>
<p>3 &frac14;&gt; x"E0",
</p>
<p>4 &frac14;&gt; BRA,
</p>
<p>5 &frac14;&gt; x"00",
</p>
<p>others &frac14;&gt; x"00");
</p>
<p>The address mapping for the program memory is handled in two ways. First, notice that the array
</p>
<p>type defined above uses indices from 0 to 127. This provides the appropriate addresses for each location
</p>
<p>in the memory. The second step is to create an internal enable line that will only allow assignments from
</p>
<p>ROM to data_out when a valid address is entered. Consider the following VHDL to create an internal
</p>
<p>enable (EN) that will only be asserted when the address falls within the valid program memory range of
</p>
<p>0&ndash;127:
</p>
<p>enable : process (address)
</p>
<p>begin
</p>
<p>if ((to_integer(unsigned(address)) &gt;&frac14; 0) and
</p>
<p>(to_integer(unsigned(address)) &lt;&frac14; 127)) then
</p>
<p>EN &lt;&frac14; &rsquo;1&rsquo;;
</p>
<p>else
</p>
<p>EN &lt;&frac14; &rsquo;0&rsquo;;
</p>
<p>end if;
</p>
<p>end process;
</p>
<p>If this enable signal is not created, the simulation and synthesis will fail because data_out
</p>
<p>assignments will be attempted for addresses outside of the defined range of the ROM array. This enable
</p>
<p>line can now be used in the behavioral model for the ROM process as follows:
</p>
<p>memory : process (clock)
</p>
<p>begin
</p>
<p>if (clock&rsquo;event and clock&frac14;&rsquo;1&rsquo;) then
</p>
<p>if (EN&frac14;&rsquo;1&rsquo;) then
</p>
<p>data_out &lt;&frac14; ROM(to_integer(unsigned(address)));
</p>
<p>end if;
</p>
<p>end if;
</p>
<p>end process;
</p>
<p>13.3.3.2 Data Memory Implementation in VHDL
</p>
<p>The data memory is created using a similar strategy as the program memory. An array signal is
</p>
<p>declared with an address range corresponding to the memory map for the computer system (i.e.,
</p>
<p>128&ndash;223). An internal enable is again created that will prevent data_out assignments for addresses
</p>
<p>outside of this valid range. The following is the VHDL to declare the R/W memory array:
</p>
<p>type rw_type is array (128 to 223) of std_logic_vector(7 downto 0);
</p>
<p>signal RW : rw_type;
</p>
<p>13.3 Computer Implementation: An 8-Bit Computer Example &bull; 435</p>
<p/>
</div>
<div class="page"><p/>
<p>The following is the VHDL to model the local enable and signal assignments for the R/W memory:
</p>
<p>enable : process (address)
</p>
<p>begin
</p>
<p>if ( (to_integer(unsigned(address)) &gt;&frac14; 128) and
</p>
<p>(to_integer(unsigned(address)) &lt;&frac14; 223)) then
</p>
<p>EN &lt;&frac14; &rsquo;1&rsquo;;
</p>
<p>else
</p>
<p>EN &lt;&frac14; &rsquo;0&rsquo;;
</p>
<p>end if;
</p>
<p>end process;
</p>
<p>memory : process (clock)
</p>
<p>begin
</p>
<p>if (clock&rsquo;event and clock&frac14;&rsquo;1&rsquo;) then
</p>
<p>if (EN&frac14;&rsquo;1&rsquo; and write&frac14;&rsquo;1&rsquo;) then
</p>
<p>RW(to_integer(unsigned(address))) &lt;&frac14; data_in;
</p>
<p>elsif (EN&frac14;&rsquo;1&rsquo; and write&frac14;&rsquo;0&rsquo;) then
</p>
<p>data_out &lt;&frac14; RW(to_integer(unsigned(address)));
</p>
<p>end if;
</p>
<p>end if;
</p>
<p>end process;
</p>
<p>13.3.3.3 Implementation of Output Ports in VHDL
</p>
<p>Each output port in the computer system is assigned a unique address. Each output port also
</p>
<p>contains storage capability. This allows the CPU to update an output port by writing to its specific
</p>
<p>address. Once the CPU is done storing to the output port address and moves to the next instruction in
</p>
<p>the program, the output port holds its information until it is written to again. This behavior can be modeled
</p>
<p>using an RTL process that uses the address bus and the write signal to create a synchronous enable
</p>
<p>condition. Each port is modeled with its own process. The following VHDL shows how the output ports at
</p>
<p>x&rdquo;E0&rdquo; and x&rdquo;E1&rdquo; are modeled using address-specific processes:
</p>
<p>-- port_out_00 description : ADDRESS x"E0"
</p>
<p>U3 : process (clock, reset)
</p>
<p>begin
</p>
<p>if (reset &frac14; &rsquo;0&rsquo;) then
</p>
<p>port_out_00 &lt;&frac14; x"00";
</p>
<p>elsif (clock&rsquo;event and clock&frac14;&rsquo;1&rsquo;) then
</p>
<p>if (address &frac14; x"E0" and write &frac14; &rsquo;1&rsquo;) then
</p>
<p>port_out_00 &lt;&frac14; data_in;
</p>
<p>end if;
</p>
<p>end if;
</p>
<p>end process;
</p>
<p>-- port_out_01 description : ADDRESS x"E1"
</p>
<p>U4 : process (clock, reset)
</p>
<p>begin
</p>
<p>if (reset &frac14; &rsquo;0&rsquo;) then
</p>
<p>port_out_01 &lt;&frac14; x"00";
</p>
<p>elsif (clock&rsquo;event and clock&frac14;&rsquo;1&rsquo;) then
</p>
<p>if (address &frac14; x"E1" and write &frac14; &rsquo;1&rsquo;) then
</p>
<p>port_out_01 &lt;&frac14; data_in;
</p>
<p>end if;
</p>
<p>end if;
</p>
<p>end process;
</p>
<p>:
</p>
<p>&ldquo;the rest of the output port models go here. . .&rdquo;
</p>
<p>:
</p>
<p>436 &bull; Chapter 13: Computer System Design</p>
<p/>
</div>
<div class="page"><p/>
<p>13.3.3.4 Implementation of Input Ports in VHDL
</p>
<p>The input ports do not contain storage, but do require a mechanism to selectively route their
</p>
<p>information to the data_out port of the memory system. This is accomplished using the multiplexer
</p>
<p>shown in Example 13.10. The only functionality that is required for the input ports is connecting their
</p>
<p>ports to the multiplexer.
</p>
<p>13.3.3.5 Memory data_out Bus Implementation in VHDL
</p>
<p>Now that all of the memory functionality has been designed, the final step is to implement the
</p>
<p>multiplexer that handles routing the appropriate information to the CPU on the data_out bus based on the
</p>
<p>incoming address. The following VHDL provides a model for this behavior. Recall that a multiplexer is
</p>
<p>combinational logic, so if the behavior is to be modeled using a process, all inputs must be listed in the
</p>
<p>sensitivity list. These inputs include the outputs from the program and data memory in addition to all of
</p>
<p>the input ports. The sensitivity list must also include the address bus as it acts as the select input to the
</p>
<p>multiplexer. Within the process, an if/then statement is used to determine which subsystem drives
</p>
<p>data_out. Program memory will drive data_out when the incoming address is in the range of 0&ndash;127
</p>
<p>(x&rdquo;00&rdquo; to x&rdquo;7F&rdquo;). Data memory will drive data_out when the address is in the range of 128&ndash;223 (x&rdquo;80&rdquo; to
</p>
<p>x&rdquo;DF&rdquo;). An input port will drive data_out when the address is in the range of 240&ndash;255 (x&rdquo;F0&rdquo; to x&rdquo;FF&rdquo;).
</p>
<p>Each input port has a unique address, so the specific addresses are listed as elsif clauses:
</p>
<p>MUX1 : process (address, rom_data_out, rw_data_out,
</p>
<p>port_in_00, port_in_01, port_in_02, port_in_03,
</p>
<p>port_in_04, port_in_05, port_in_06, port_in_07,
</p>
<p>port_in_08, port_in_09, port_in_10, port_in_11,
</p>
<p>port_in_12, port_in_13, port_in_14, port_in_15)
</p>
<p>begin
</p>
<p>if ( (to_integer(unsigned(address)) &gt;&frac14; 0) and
</p>
<p>(to_integer(unsigned(address)) &lt;&frac14; 127)) then
</p>
<p>data_out &lt;&frac14; rom_data_out;
</p>
<p>elsif ( (to_integer(unsigned(address)) &gt;&frac14; 128) and
</p>
<p>(to_integer(unsigned(address)) &lt;&frac14; 223)) then
</p>
<p>data_out &lt;&frac14; rw_data_out;
</p>
<p>elsif (address &frac14; x"F0") then data_out &lt;&frac14; port_in_00;
</p>
<p>elsif (address &frac14; x"F1") then data_out &lt;&frac14; port_in_01;
</p>
<p>elsif (address &frac14; x"F2") then data_out &lt;&frac14; port_in_02;
</p>
<p>elsif (address &frac14; x"F3") then data_out &lt;&frac14; port_in_03;
</p>
<p>elsif (address &frac14; x"F4") then data_out &lt;&frac14; port_in_04;
</p>
<p>elsif (address &frac14; x"F5") then data_out &lt;&frac14; port_in_05;
</p>
<p>elsif (address &frac14; x"F6") then data_out &lt;&frac14; port_in_06;
</p>
<p>elsif (address &frac14; x"F7") then data_out &lt;&frac14; port_in_07;
</p>
<p>elsif (address &frac14; x"F8") then data_out &lt;&frac14; port_in_08;
</p>
<p>elsif (address &frac14; x"F9") then data_out &lt;&frac14; port_in_09;
</p>
<p>elsif (address &frac14; x"FA") then data_out &lt;&frac14; port_in_10;
</p>
<p>elsif (address &frac14; x"FB") then data_out &lt;&frac14; port_in_11;
</p>
<p>elsif (address &frac14; x"FC") then data_out &lt;&frac14; port_in_12;
</p>
<p>elsif (address &frac14; x"FD") then data_out &lt;&frac14; port_in_13;
</p>
<p>elsif (address &frac14; x"FE") then data_out &lt;&frac14; port_in_14;
</p>
<p>elsif (address &frac14; x"FF") then data_out &lt;&frac14; port_in_15;
</p>
<p>else data_out &lt;&frac14; x"00";
</p>
<p>end if;
</p>
<p>end process;
</p>
<p>13.3 Computer Implementation: An 8-Bit Computer Example &bull; 437</p>
<p/>
</div>
<div class="page"><p/>
<p>13.3.4 CPU Implementation
</p>
<p>Let&rsquo;s now look at the CPU details. The CPU contains two components, the control unit (control_unit.
</p>
<p>vhd) and the data path (data_path.vhd). The data path contains all of the registers and the ALU. The ALU
</p>
<p>is implemented as a sub-component within the data path (alu.vhd). The data path also contains a bus
</p>
<p>system in order to facilitate data movement between the registers and memory. The bus system is
</p>
<p>implemented with two multiplexers that are controlled by the control unit. The control unit contains the
</p>
<p>finite-state machine that generates all control signals for the data path as it performs the fetch-decode-
</p>
<p>execute steps of each instruction. Example 13.11 shows the block diagram of the CPU in our 8-bit
</p>
<p>microcomputer example.
</p>
<p>Example 13.11
CPU block diagram for the 8-bit computer system
</p>
<p>438 &bull; Chapter 13: Computer System Design</p>
<p/>
</div>
<div class="page"><p/>
<p>13.3.4.1 Data Path Implementation in VHDL
</p>
<p>Let&rsquo;s first look at the data path bus system that handles internal signal routing. The system consists
</p>
<p>of two 8-bit busses (Bus1 and Bus2) and two multiplexers. Bus1 is used as the destination of the PC, A,
</p>
<p>and B register outputs, while Bus2 is used as the input to the IR, MAR, PC, A, and B registers. Bus1 is
</p>
<p>connected directly to the to_memory port of the CPU to allow registers to write data to the memory
</p>
<p>system. Bus2 can be driven by the from_memory port of the CPU to allow the memory system to provide
</p>
<p>data for the CPU registers. The two multiplexers handle all signal routing and have their select lines
</p>
<p>(Bus1_Sel and Bus2_Sel) driven by the control unit. The following VHDL shows how the multiplexers are
</p>
<p>implemented. Again, a multiplexer is combinational logic, so all inputs must be listed in the sensitivity list
</p>
<p>of its process. Two concurrent signal assignments are also required to connect the MAR to the address
</p>
<p>port and to connect Bus1 to the to_memory port:
</p>
<p>MUX_BUS1 : process (Bus1_Sel, PC, A, B)
</p>
<p>begin
</p>
<p>case (Bus1_Sel) is
</p>
<p>when "00" &frac14;&gt; Bus1 &lt;&frac14; PC;
</p>
<p>when "01" &frac14;&gt; Bus1 &lt;&frac14; A;
</p>
<p>when "10" &frac14;&gt; Bus1 &lt;&frac14; B;
</p>
<p>when others &frac14;&gt; Bus1 &lt;&frac14; x"00";
</p>
<p>end case;
</p>
<p>end process;
</p>
<p>MUX_BUS2 : process (Bus2_Sel, ALU_Result, Bus1, from_memory)
</p>
<p>begin
</p>
<p>case (Bus2_Sel) is
</p>
<p>when "00" &frac14;&gt; Bus2 &lt;&frac14; ALU_Result;
</p>
<p>when "01" &frac14;&gt; Bus2 &lt;&frac14; Bus1;
</p>
<p>when "10" &frac14;&gt; Bus2 &lt;&frac14; from_memory;
</p>
<p>when others &frac14;&gt; Bus2 &lt;&frac14; x"00";
</p>
<p>end case;
</p>
<p>end process;
</p>
<p>address &lt;&frac14; MAR;
</p>
<p>to_memory &lt;&frac14; Bus1;
</p>
<p>Next, let&rsquo;s look at implementing the registers in the data path. Each register is implemented using a
</p>
<p>dedicated process that is sensitive to clock and reset. This models the behavior of synchronous latches,
</p>
<p>or registers. Each register has a synchronous enable line that dictates when the register is updated. The
</p>
<p>register output is only updated when the enable line is asserted and a rising edge of the clock is detected.
</p>
<p>The following VHDL shows how to model the instruction register (IR). Notice that the signal IR is only
</p>
<p>updated if IR_Load is asserted and there is a rising edge of the clock. In this case, IR is loaded with the
</p>
<p>value that resides on Bus2:
</p>
<p>INSTRUCTION_REGISTER : process (Clock, Reset)
</p>
<p>begin
</p>
<p>if (Reset &frac14; &rsquo;0&rsquo;) then
</p>
<p>IR &lt;&frac14; x"00";
</p>
<p>elsif (Clock&rsquo;event and Clock &frac14; &rsquo;1&rsquo;) then
</p>
<p>if (IR_Load &frac14; &rsquo;1&rsquo;) then
</p>
<p>IR &lt;&frac14; Bus2;
</p>
<p>end if;
</p>
<p>end if;
</p>
<p>end process;
</p>
<p>A nearly identical process is used to model the memory address register. A unique signal is declared
</p>
<p>called MAR in order to make the VHDL more readable. MAR is always assigned to address in this
</p>
<p>system:
</p>
<p>13.3 Computer Implementation: An 8-Bit Computer Example &bull; 439</p>
<p/>
</div>
<div class="page"><p/>
<p>MEMORY_ADDRESS_REGISTER : process (Clock, Reset)
</p>
<p>begin
</p>
<p>if (Reset &frac14; &rsquo;0&rsquo;) then
</p>
<p>MAR &lt;&frac14; x"00";
</p>
<p>elsif (Clock&rsquo;event and Clock &frac14; &rsquo;1&rsquo;) then
</p>
<p>if (MAR_Load &frac14; &rsquo;1&rsquo;) then
</p>
<p>MAR &lt;&frac14; Bus2;
</p>
<p>end if;
</p>
<p>end if;
</p>
<p>end process;
</p>
<p>Now let&rsquo;s look at the program counter process. This register contains additional functionality beyond
</p>
<p>simply latching in the value of Bus2. The program counter also has an increment feature. In order to use
</p>
<p>the &ldquo;+&rdquo; operator, we can declare a temporary unsigned vector called PC_uns. The PC process can model
</p>
<p>the appropriate behavior using PC_uns and then type cast it back to the original PC signal:
</p>
<p>PROGRAM_COUNTER : process (Clock, Reset)
</p>
<p>begin
</p>
<p>if (Reset &frac14; &rsquo;0&rsquo;) then
</p>
<p>PC_uns &lt;&frac14; x"00";
</p>
<p>elsif (Clock&rsquo;event and Clock &frac14; &rsquo;1&rsquo;) then
</p>
<p>if (PC_Load &frac14; &rsquo;1&rsquo;) then
</p>
<p>PC_uns &lt;&frac14; unsigned(Bus2);
</p>
<p>elsif (PC_Inc &frac14; &rsquo;1&rsquo;) then
</p>
<p>PC_uns &lt;&frac14; PC_uns + 1;
</p>
<p>end if;
</p>
<p>end if;
</p>
<p>end process;
</p>
<p>PC &lt;&frac14; std_logic_vector(PC_uns);
</p>
<p>The two general-purpose registers A and B are modeled using individual processes as follows:
</p>
<p>A_REGISTER : process (Clock, Reset)
</p>
<p>begin
</p>
<p>if (Reset &frac14; &rsquo;0&rsquo;) then
</p>
<p>A &lt;&frac14; x"00";
</p>
<p>elsif (Clock&rsquo;event and Clock &frac14; &rsquo;1&rsquo;) then
</p>
<p>if (A_Load &frac14; &rsquo;1&rsquo;) then
</p>
<p>A &lt;&frac14; Bus2;
</p>
<p>end if;
</p>
<p>end if;
</p>
<p>end process;
</p>
<p>B_REGISTER : process (Clock, Reset)
</p>
<p>begin
</p>
<p>if (Reset &frac14; &rsquo;0&rsquo;) then
</p>
<p>B &lt;&frac14; x"00";
</p>
<p>elsif (Clock&rsquo;event and Clock &frac14; &rsquo;1&rsquo;) then
</p>
<p>if (B_Load &frac14; &rsquo;1&rsquo;) then
</p>
<p>B &lt;&frac14; Bus2;
</p>
<p>end if;
</p>
<p>end if;
</p>
<p>end process;
</p>
<p>The condition code register latches in the status flags from the ALU (NZVC) when the CCR_Load
</p>
<p>line is asserted. This behavior is modeled using a similar approach as follows:
</p>
<p>CONDITION_CODE_REGISTER : process (Clock, Reset)
</p>
<p>begin
</p>
<p>if (Reset &frac14; &rsquo;0&rsquo;) then
</p>
<p>CCR_Result &lt;&frac14; x"0";
</p>
<p>elsif (Clock&rsquo;event and Clock &frac14; &rsquo;1&rsquo;) then
</p>
<p>440 &bull; Chapter 13: Computer System Design</p>
<p/>
</div>
<div class="page"><p/>
<p>if (CCR_Load &frac14; &rsquo;1&rsquo;) then
</p>
<p>CCR_Result &lt;&frac14; NZVC;
</p>
<p>end if;
</p>
<p>end if;
</p>
<p>end process;
</p>
<p>13.3.4.2 ALU Implementation in VHDL
</p>
<p>The ALU is a set of combinational logic circuitry that performs arithmetic and logic operations. The
</p>
<p>output of the ALU operation is called Result. The ALU also outputs four status flags as a 4-bit bus called
</p>
<p>NZVC. The ALU behavior can be modeled using if/then/elsif statements that decide which operation to
</p>
<p>perform based on the input control signal ALU_Sel. The following VHDL shows an example of how to
</p>
<p>implement the ALU addition functionality. In order to be able to use numerical operators (i.e., +, �), the
</p>
<p>numeric_std package is included. Variables can be used within the process to facilitate using the
</p>
<p>numerical operators. Recall that variables are updated instantaneously so an assignment can be
</p>
<p>made to the variable and its result is available immediately. Note that in the following VHDL, each
</p>
<p>operation also updates the NZVC flags. Each of these flags is updated individually. The N flag can be
</p>
<p>simply driven with position 7 of the ALU result since this bit is the sign bit for signed numbers. The Z flag
</p>
<p>can be driven using an if/then condition that checks whether the result was x&rdquo;00.&rdquo; The V flag is updated
</p>
<p>based on the type of the operation. For the addition operation, the V flag will be asserted if a POS
</p>
<p>+POS&frac14;NEG or a NEG+NEG&frac14;POS. These conditions can be checked by looking at the sign bits of the
</p>
<p>inputs and the sign bit of the result. Finally, the C flag can be directly driven with position 8 of the
</p>
<p>Sum_uns variable:
</p>
<p>ALU_PROCESS : process (A, B, ALU_Sel)
</p>
<p>variable Sum_uns : unsigned(8 downto 0);
</p>
<p>begin
</p>
<p>if (ALU_Sel &frac14; "000") then &ndash; ADDITION
</p>
<p>--- Sum Calculation ---------------------------------&ndash;
</p>
<p>Sum_uns :&frac14; unsigned(&rsquo;0&rsquo; &amp; A) + unsigned(&rsquo;0&rsquo; &amp; B);
</p>
<p>Result &lt;&frac14; std_logic_vector(Sum_uns(7 downto 0));
</p>
<p>--- Negative Flag (N) -------------------------------
</p>
<p>NZVC(3) &lt;&frac14; Sum_uns(7);
</p>
<p>--- Zero Flag (Z) ---------------------------------&ndash;
</p>
<p>if (Sum_uns(7 downto 0) &frac14; x"00") then
</p>
<p>NZVC(2) &lt;&frac14; &rsquo;1&rsquo;;
</p>
<p>else
</p>
<p>NZVC(2) &lt;&frac14; &rsquo;0&rsquo;;
</p>
<p>end if;
</p>
<p>--- Overflow Flag (V) -------------------------------
</p>
<p>if ((A(7)&frac14;&rsquo;0&rsquo; and B(7)&frac14;&rsquo;0&rsquo; and Sum_uns(7)&frac14;&rsquo;1&rsquo;) or
</p>
<p>(A(7)&frac14;&rsquo;1&rsquo; and B(7)&frac14;&rsquo;1&rsquo; and Sum_uns(7)&frac14;&rsquo;0&rsquo;)) then
</p>
<p>NZVC(1) &lt;&frac14; &rsquo;1&rsquo;;
</p>
<p>else
</p>
<p>NZVC(1) &lt;&frac14; &rsquo;0&rsquo;;
</p>
<p>end if;
</p>
<p>--- Carry Flag (C) ------------------------------------
</p>
<p>NZVC(0) &lt;&frac14; Sum_uns(8);
</p>
<p>elsif (ALU_Sel &frac14; . . .
</p>
<p>: &ldquo;other ALU functionality goes here&rdquo;
</p>
<p>end if;
</p>
<p>end process;
</p>
<p>13.3 Computer Implementation: An 8-Bit Computer Example &bull; 441</p>
<p/>
</div>
<div class="page"><p/>
<p>13.3.4.3 Control Unit Implementation in VHDL
</p>
<p>Let&rsquo;s now look at how to implement the control unit state machine. We&rsquo;ll first look at the formation of
</p>
<p>the VHDL to model the FSM and then turn to the detailed state transitions in order to accomplish a variety
</p>
<p>of the most common instructions. The control unit sends signals to the data path in order to move data in
</p>
<p>and out of registers and into the ALU to perform data manipulations. The finite-state machine is
</p>
<p>implemented with the behavioral modeling techniques presented in Chapter 9. The model contains
</p>
<p>three processes in order to implement the state memory, next state logic, and output logic of the FSM.
</p>
<p>User-defined types are created for each of the states defined in the state diagram of the FSM. The states
</p>
<p>associated with fetching (S_FETCH_0, S_FETCH_1, S_FETCH_2) and decoding the opcode
</p>
<p>(S_DECODE_3) are performed each time an instruction is executed. A unique path is then added
</p>
<p>after the decode state to perform the steps associated with executing each individual instruction. The
</p>
<p>FSM can be created one instruction at a time by adding additional state paths after the decode state. The
</p>
<p>following VHDL code shows how the user-defined state names are created for six basic instructions
</p>
<p>(LDA_IMM, LDA_DIR, STA_DIR, ADD_AB, BRA and BEQ):
</p>
<p>type state_type is
</p>
<p>(S_FETCH_0, S_FETCH_1, S_FETCH_2,
</p>
<p>S_DECODE_3,
</p>
<p>S_LDA_IMM_4, S_LDA_IMM_5, S_LDA_IMM_6,
</p>
<p>S_LDA_DIR_4, S_LDA_DIR_5, S_LDA_DIR_6, S_LDA_DIR_7,
</p>
<p>S_STA_DIR_4, S_STA_DIR_5, S_STA_DIR_6, S_STA_DIR_7, S_STA_DIR_8,
</p>
<p>S_ADD_AB_4,
</p>
<p>S_BRA_4, S_BRA_5, S_BRA_6,
</p>
<p>S_BEQ_4, S_BEQ_5, S_BEQ_6, S_BEQ_7);
</p>
<p>signal current_state, next_state : state_type;
</p>
<p>Within the architecture of the control unit model, the state memory is implemented as a separate
</p>
<p>process that will update the current state with the next state on each rising edge of the clock. The reset
</p>
<p>state will be the first fetch state in the FSM (i.e., S_FETCH_0). The following VHDL shows how the state
</p>
<p>memory in the control unit can be modeled:
</p>
<p>STATE_MEMORY : process (Clock, Reset)
</p>
<p>begin
</p>
<p>if (Reset &frac14; &rsquo;0&rsquo;) then
</p>
<p>current_state &lt;&frac14; S_FETCH_0;
</p>
<p>elsif (clock&rsquo;event and clock &frac14; &rsquo;1&rsquo;) then
</p>
<p>current_state &lt;&frac14; next_state;
</p>
<p>end if;
</p>
<p>end process;
</p>
<p>The next state logic is also implemented as a separate process. The next state logic depends on the
</p>
<p>current state, instruction register, and the CCR (CCR_Result). The following VHDL gives a portion of the
</p>
<p>next state logic process showing how the state transitions can be modeled:
</p>
<p>NEXT_STATE_LOGIC : process (current_state, IR, CCR_Result)
</p>
<p>begin
</p>
<p>if (current_state &frac14; S_FETCH_0) then
</p>
<p>next_state &lt;&frac14; S_FETCH_1;
</p>
<p>elsif (current_state &frac14; S_FETCH_1) then
</p>
<p>next_state &lt;&frac14; S_FETCH_2;
</p>
<p>elsif (current_state &frac14; S_FETCH_2) then
</p>
<p>next_state &lt;&frac14; S_DECODE_3;
</p>
<p>elsif (current_state &frac14; S_DECODE_3) then
</p>
<p>-- select execution path
</p>
<p>if (IR &frac14; LDA_IMM) then -- Load A Immediate
</p>
<p>next_state &lt;&frac14; S_LDA_IMM_4;
</p>
<p>elsif (IR &frac14; LDA_DIR) then -- Load A Direct
</p>
<p>next_state &lt;&frac14; S_LDA_DIR_4;
</p>
<p>elsif (IR &frac14; STA_DIR) then -- Store A Direct
</p>
<p>next_state &lt;&frac14; S_STA_DIR_4;
</p>
<p>elsif (IR &frac14; ADD_AB) then -- Add A and B
</p>
<p>442 &bull; Chapter 13: Computer System Design</p>
<p/>
</div>
<div class="page"><p/>
<p>next_state &lt;&frac14; S_ADD_AB_4;
</p>
<p>elsif (IR &frac14; BRA) then -- Branch Always
</p>
<p>next_state &lt;&frac14; S_BRA_4;
</p>
<p>elsif (IR&frac14;BEQ and CCR_Result(2)&frac14;&rsquo;1&rsquo;) then -- BEQ and Z&frac14;1
</p>
<p>next_state &lt;&frac14; S_BEQ_4;
</p>
<p>elsif (IR&frac14;BEQ and CCR_Result(2)&frac14;&rsquo;0&rsquo;) then -- BEQ and Z&frac14;0
</p>
<p>next_state &lt;&frac14; S_BEQ_7;
</p>
<p>else
</p>
<p>next_state &lt;&frac14; S_FETCH_0;
</p>
<p>end if;
</p>
<p>elsif. . .
</p>
<p>:
</p>
<p>&ldquo;paths for each instruction go here. . .&rdquo;
</p>
<p>:
</p>
<p>end if;
</p>
<p>end process;
</p>
<p>Finally, the output logic is modeled as a third, separate process. It is useful to explicitly state the
</p>
<p>outputs of the control unit for each state in the machine to allow easy debugging and avoid synthesizing
</p>
<p>latches. Our example computer system has Moore-type outputs, so the process only depends on the
</p>
<p>current state. The following VHDL shows a portion of the output logic process:
</p>
<p>OUTPUT_LOGIC : process (current_state)
</p>
<p>begin
</p>
<p>case(current_state) is
</p>
<p>when S_FETCH_0 &frac14;&gt; -- Put PC onto MAR to read Opcode
</p>
<p>IR_Load &lt;&frac14; &rsquo;0&rsquo;;
</p>
<p>MAR_Load &lt;&frac14; &rsquo;1&rsquo;;
</p>
<p>PC_Load &lt;&frac14; &rsquo;0&rsquo;;
</p>
<p>PC_Inc &lt;&frac14; &rsquo;0&rsquo;;
</p>
<p>A_Load &lt;&frac14; &rsquo;0&rsquo;;
</p>
<p>B_Load &lt;&frac14; &rsquo;0&rsquo;;
</p>
<p>ALU_Sel &lt;&frac14; "000";
</p>
<p>CCR_Load &lt;&frac14; &rsquo;0&rsquo;;
</p>
<p>Bus1_Sel &lt;&frac14; "00"; -- "00"&frac14;PC, "01"&frac14;A, "10"&frac14;B
</p>
<p>Bus2_Sel &lt;&frac14; "01"; -- "00"&frac14;ALU_Result, "01"&frac14;Bus1, "10"&frac14;from_memory
</p>
<p>write &lt;&frac14; &rsquo;0&rsquo;;
</p>
<p>when S_FETCH_1 &frac14;&gt; -- Increment PC
</p>
<p>IR_Load &lt;&frac14; &rsquo;0&rsquo;;
</p>
<p>MAR_Load &lt;&frac14; &rsquo;0&rsquo;;
</p>
<p>PC_Load &lt;&frac14; &rsquo;0&rsquo;;
</p>
<p>PC_Inc &lt;&frac14; &rsquo;1&rsquo;;
</p>
<p>A_Load &lt;&frac14; &rsquo;0&rsquo;;
</p>
<p>B_Load &lt;&frac14; &rsquo;0&rsquo;;
</p>
<p>ALU_Sel &lt;&frac14; "000";
</p>
<p>CCR_Load &lt;&frac14; &rsquo;0&rsquo;;
</p>
<p>Bus1_Sel &lt;&frac14; "00"; -- "00"&frac14;PC, "01"&frac14;A, "10"&frac14;B
</p>
<p>Bus2_Sel &lt;&frac14; "00"; -- "00"&frac14;ALU, "01"&frac14;Bus1, "10"&frac14;from_memory
</p>
<p>write &lt;&frac14; &rsquo;0&rsquo;;
</p>
<p>:
</p>
<p>&ldquo;output assignments for all other states go here. . .&rdquo; :
</p>
<p>end case;
</p>
<p>end process;
</p>
<p>13.3.4.3.1 Detailed Execution of LDA_IMM
</p>
<p>Now let&rsquo;s look at the details of the state transitions and output signals in the control unit FSM when
</p>
<p>executing a few of the most common instructions. Let&rsquo;s begin with the instruction to load register A using
</p>
<p>immediate addressing (LDA_IMM). Example 13.12 shows the state diagram for this instruction. The first
</p>
<p>three states (S_FETCH_0, S_FETCH_1, S_FETCH_2) handle fetching the opcode. The purpose of
</p>
<p>these states is to read the opcode from the address being held by the program counter and put it into the
</p>
<p>instruction register. Multiple states are needed to handle putting PC into MAR to provide the address of
</p>
<p>13.3 Computer Implementation: An 8-Bit Computer Example &bull; 443</p>
<p/>
</div>
<div class="page"><p/>
<p>the opcode, waiting for the memory system to provide the opcode, latching the opcode into IR, and
</p>
<p>incrementing PC to the next location in program memory. Another state is used to decode the opcode
</p>
<p>(S_DECODE_3) in order to decide which path to take in the state diagram based on the instruction being
</p>
<p>executed. After the decode state, a series of three more states are needed (S_LDA_IMM_4,
</p>
<p>S_LDA_IMM_5, S_LDA_IMM_6) to execute the instruction. The purpose of these states is to read the
</p>
<p>operand from the address being held by the program counter and put it into A. Multiple states are needed
</p>
<p>to handle putting PC into MAR to provide the address of the operand, waiting for the memory system to
</p>
<p>provide the operand, latching the operand into A, and incrementing PC to the next location in program
</p>
<p>memory. When the instruction completes, the value of the operand resides in A and PC is pointing to the
</p>
<p>next location in program memory, which is the opcode of the next instruction to be executed.
</p>
<p>Example 13.12
State diagram for LDA_IMM
</p>
<p>444 &bull; Chapter 13: Computer System Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 13.13 shows the simulation waveform for executing LDA_IMM. In this example, register A
</p>
<p>is loaded with the operand of the instruction, which holds the value x&rdquo;AA.&rdquo;
</p>
<p>Example 13.13
Simulation waveform for LDA_IMM
</p>
<p>13.3.4.3.2 Detailed Execution of LDA_DIR
</p>
<p>Now let&rsquo;s look at the details of the instruction to load register A using direct addressing (LDA_DIR).
</p>
<p>Example 13.14 shows the state diagram for this instruction. The first four states to fetch and decode the
</p>
<p>opcode are the same states as in the previous instruction and are performed each time a new instruction
</p>
<p>is executed. Once the opcode is decoded, the state machine traverses five new states to execute the
</p>
<p>instruction (S_LDA_DIR_4, S_LDA_DIR_5, S_LDA_DIR_6, S_LDA_DIR_7, S_LDA_DIR_8). The pur-
</p>
<p>pose of these states is to read the operand and then use it as the address of where to read the contents to
</p>
<p>put into A.
</p>
<p>13.3 Computer Implementation: An 8-Bit Computer Example &bull; 445</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 13.14
State diagram for LDA_DIR
</p>
<p>446 &bull; Chapter 13: Computer System Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 13.15 shows the simulation waveform for executing LDA_DIR. In this example, register A
</p>
<p>is loaded with the contents located at address x&rdquo;80,&rdquo; which has already been initialized to x&rdquo;AA.&rdquo;
</p>
<p>Example 13.15
Simulation waveform for LDA_DIR
</p>
<p>13.3.4.3.3 Detailed Execution of STA_DIR
</p>
<p>Now let&rsquo;s look at the details of the instruction to store register A to memory using direct addressing
</p>
<p>(STA_DIR). Example 13.16 shows the state diagram for this instruction. The first four states are again the
</p>
<p>same as prior instructions in order to fetch and decode the opcode. Once the opcode is decoded, the
</p>
<p>state machine traverses four new states to execute the instruction (S_STA_DIR_4, S_STA_DIR_5,
</p>
<p>S_STA_DIR_6, S_STA_DIR_7). The purpose of these states is to read the operand and then use it as
</p>
<p>the address of where to write the contents of A to.
</p>
<p>13.3 Computer Implementation: An 8-Bit Computer Example &bull; 447</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 13.16
State diagram for STA_DIR
</p>
<p>Example 13.17 shows the simulation waveform for executing STA_DIR. In this example, register A
</p>
<p>already contains the value x&rdquo;CC&rdquo; and will be stored to address x&rdquo;E0.&rdquo; The address x&rdquo;E0&rdquo; is an output port
</p>
<p>(port_out_00) in our example computer system.
</p>
<p>448 &bull; Chapter 13: Computer System Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 13.17
Simulation waveform for STA_DIR
</p>
<p>13.3.4.3.4 Detailed Execution of ADD_AB
</p>
<p>Now let&rsquo;s look at the details of the instruction to add A to B and store the sum back in A (ADD_AB).
</p>
<p>Example 13.18 shows the state diagram for this instruction. The first four states are again the same as
</p>
<p>prior instructions in order to fetch and decode the opcode. Once the opcode is decoded, the state
</p>
<p>machine only requires one more state to complete the operation (S_ADD_AB_4). The ALU is combina-
</p>
<p>tional logic, so it will begin to compute the sum immediately as soon as the inputs are updated. The inputs
</p>
<p>to the ALU are Bus1 and register B. Since B is directly connected to the ALU, all that is required to start
</p>
<p>the addition is to put A onto Bus1. The output of the ALU is put on Bus2 so that it can be latched into A on
</p>
<p>the next clock edge. The ALU also outputs the status flags NZVC, which are directly connected to the
</p>
<p>CCR. A_Load and CCR_Load are asserted in this state. A and CCR_Result will be updated in the next
</p>
<p>state (i.e., S_FETCH_0).
</p>
<p>13.3 Computer Implementation: An 8-Bit Computer Example &bull; 449</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 13.18
State diagram for ADD_AB
</p>
<p>Example 13.19 shows the simulation waveform for executing ADD_AB. In this example, two load
</p>
<p>immediate instructions were used to initialize the general-purpose registers to A&frac14;x&rdquo;FF&rdquo; and B&frac14;x&rdquo;01&rdquo;
</p>
<p>prior to the addition. The addition of these values will result in a sum of x&rdquo;00&rdquo; and assert the carry (C) and
</p>
<p>zero (Z) flags in the CCR.
</p>
<p>450 &bull; Chapter 13: Computer System Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 13.19
Simulation waveform for ADD_AB
</p>
<p>13.3.4.3.5 Detailed Execution of BRA
</p>
<p>Now let&rsquo;s look at the details of the instruction to branch always (BRA). Example 13.20 shows the
</p>
<p>state diagram for this instruction. The first four states are again the same as prior instructions in order to
</p>
<p>fetch and decode the opcode. Once the opcode is decoded, the state machine traverses four new states
</p>
<p>to execute the instruction (S_BRA_4, S_BRA_5, S_BRA_6). The purpose of these states is to read the
</p>
<p>operand and put its value into PC to set the new location in program memory to execute instructions.
</p>
<p>13.3 Computer Implementation: An 8-Bit Computer Example &bull; 451</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 13.20
State diagram for BRA
</p>
<p>452 &bull; Chapter 13: Computer System Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 13.21 shows the simulation waveform for executing BRA. In this example, PC is set back
</p>
<p>to address x&rdquo;00.&rdquo;
</p>
<p>Example 13.21
Simulation waveform for BRA
</p>
<p>13.3.4.3.6 Detailed Execution of BEQ
</p>
<p>Now let&rsquo;s look at the branch if equal to zero (BEQ) instruction. Example 13.22 shows the state
</p>
<p>diagram for this instruction. Notice that in this conditional branch, the path that is taken through the FSM
</p>
<p>depends on both IR and CCR. In the case that Z&frac14;1, the branch is taken, meaning that the operand is
</p>
<p>loaded into PC. In the case that Z &frac14; 0, the branch is not taken, meaning that PC is simply incremented to
</p>
<p>bypass the operand and point to the beginning of the next instruction in program memory.
</p>
<p>13.3 Computer Implementation: An 8-Bit Computer Example &bull; 453</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 13.22
State diagram for BEQ
</p>
<p>Example 13.23 shows the simulation waveform for executing BEQwhen the branch is taken. Prior to
</p>
<p>this instruction, an addition was performed on x&rdquo;FF&rdquo; and x&rdquo;01.&rdquo; This resulted in a sum of x&rdquo;00,&rdquo; which
</p>
<p>asserted the Z and C flags in the CCR. Since Z &frac14; 1 when BEQ is executed, the branch is taken.
</p>
<p>454 &bull; Chapter 13: Computer System Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 13.23
Simulation waveform for BEQ when taking the branch (Z &frac14; 1)
</p>
<p>Example 13.24 shows the simulation waveform for executing BEQ when the branch is not taken.
</p>
<p>Prior to this instruction, an addition was performed on x&rdquo;FE&rdquo; and x&rdquo;01.&rdquo; This resulted in a sum of x&rdquo;FF,&rdquo;
</p>
<p>which did not assert the Z flag. Since Z &frac14; 0 when BEQ is executed, the branch is not taken. When not
</p>
<p>taking the branch, PC must be incremented again in order to bypass the operand and point to the next
</p>
<p>location in program memory.
</p>
<p>13.3 Computer Implementation: An 8-Bit Computer Example &bull; 455</p>
<p/>
</div>
<div class="page"><p/>
<p>Example 13.24
Simulation waveform for BEQ when the branch is not taken (Z &frac14; 0)
</p>
<p>456 &bull; Chapter 13: Computer System Design</p>
<p/>
</div>
<div class="page"><p/>
<p>CC13.3 The 8-bit microcomputer example presented in this section is a very simple architecture 
</p>
<p>used to illustrate the basic concepts of a computer.  If we wanted to keep this computer 
an 8-bit system but increase the depth of the memory, it would require adding more 
address lines to the address bus.  What changes to the computer system would need to 
be made to accommodate the wider address bus?
</p>
<p>A) The width of the program counter would need to be increased to support the 
wider address bus.
</p>
<p>B) The size of the memory address register would need to be increased to support 
the wider address bus.
</p>
<p>C) Instructions that use direct addressing would need additional bytes of operand to 
pass the wider address into the CPU 8-bits at a time.
</p>
<p>D) All of the above.
</p>
<p>CONCEPT CHECK
</p>
<p>13.4 Architecture Considerations
</p>
<p>13.4.1 Von Neumann Architecture
</p>
<p>The computer system just presented represents a very simple architecture in which all memory
</p>
<p>devices (i.e., program, data, and I/O) are grouped into a single memory map. This approach is known as
</p>
<p>the Von Neumann architecture, named after the nineteenth-century mathematician that first described
</p>
<p>this structure in 1945. The advantage of this approach is in the simplicity of the CPU interface. The CPU
</p>
<p>can be constructed based on a single bus system that executes everything in a linear progression of
</p>
<p>states, regardless of whether memory is being accessed for an instruction or a variable. One of the
</p>
<p>drawbacks of this approach is that an instruction and variable data cannot be read at the same time. This
</p>
<p>creates a latency in data manipulation since the system needed to be constantly switching between
</p>
<p>reading instructions and accessing data. This latency became known as the Von Neumann bottleneck.
</p>
<p>13.4.2 Harvard Architecture
</p>
<p>As computer systems evolved and larger data sets in memory were being manipulated, it became
</p>
<p>apparent that it was advantageous to be able to access data in parallel with reading the next instruction.
</p>
<p>The Harvard architecture was proposed to address the Von Neumann bottleneck by separating the
</p>
<p>program and data memory and using two distinct bus systems for the CPU interface. This approach
</p>
<p>allows data and program information to be accessed in parallel and leads to performance improvement
</p>
<p>when large numbers of data manipulations in memory need to be performed. Figure 13.5 shows a
</p>
<p>comparison between the two architectures
</p>
<p>13.4 Architecture Considerations &bull; 457</p>
<p/>
</div>
<div class="page"><p/>
<p>CC13.4 Does a computer with a Harvard architecture require two control unit state machines?
</p>
<p>A) Yes.  It has two bus systems that need to be managed separately so two finite 
state machines are required.
</p>
<p>B) No.  A single state machine is still used to fetch, decode, and execute the 
instruction.  The only difference is that if data is required for the execute stage, it 
can be retrieved from data memory at the same time the state machine fetches 
the opcode of the next instruction from program memory.
</p>
<p>CONCEPT CHECK
</p>
<p>Fig. 13.5
Von Neumann vs. Harvard Architecture
</p>
<p>458 &bull; Chapter 13: Computer System Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Summary
</p>
<p>v A computer is a collection of hardware
components that are constructed to perform
a specific set of instructions to process and
store data. The main hardware components
of a computer are the CPU, program mem-
ory, data memory, and input/output ports.
</p>
<p>v The CPU consists of registers for fast stor-
age, an ALU for data manipulation, and a
control state machine that directs all activity
to execute an instruction.
</p>
<p>v A CPU is typically organized into a data path
and a control unit. The data path contains all
circuitry used to store and process informa-
tion. The data path includes the registers and
the ALU. The control unit is a large state
machine that sends control signals to the
data path in order to facilitate instruction
execution.
</p>
<p>v The control unit continuously performs a
fetch-decode-execute cycle in order to com-
plete instructions.
</p>
<p>v The instructions that a computer is designed
to execute are called its instruction set.
</p>
<p>v Instructions are inserted into program mem-
ory in a sequence that when executed will
accomplish a particular task. This sequence
of instructions is called a computer program.
</p>
<p>v An instruction consists of an opcode and a
potential operand. The opcode is the unique
binary code that tells the control state
machine which instruction is being executed.
An operand is additional information that may
be needed for the instruction.
</p>
<p>v An addressing mode refers to the way that
the operand is treated. In immediate
addressing the operand is the actual data to
be used. In direct addressing the operand is
the address of where the data is to be
retrieved or stored. In inherent addressing
all of the information needed to complete
the instruction is contained within the
opcode, so no operand is needed.
</p>
<p>v A computer also contains data memory to
hold temporary variables during run time.
</p>
<p>v A computer also contains input and output
ports to interface with the outside world.
</p>
<p>v A memory mapped system is one in which
the program memory, data memory, and I/O
ports are all assigned a unique address. This
allows the CPU to simply process information
as data and addresses and allows the pro-
gram to handle where the information is
being sent to. A memory map is a graphical
representation of what address ranges vari-
ous components are mapped to.
</p>
<p>v There are three primary classes of
instructions. These are loads and stores,
data manipulations, and branches.
</p>
<p>v Load instructions move information from
memory into a CPU register. A load instruc-
tion takes multiple read cycles. Store
instructions move information from a CPU
register into memory. A store instruction
takes multiple read cycles and at least one
write cycle.
</p>
<p>v Data manipulation instructions operate on
information being held in CPU registers.
Data manipulation instructions often use
inherent addressing.
</p>
<p>v Branch instructions alter the flow of instruc-
tion execution. Unconditional branches
always change the location in memory of
where the CPU is executing instructions.
Conditional branches only change the loca-
tion of instruction execution if a status flag is
asserted.
</p>
<p>v Status flags are held in the CCR and are
updated by certain instructions. The most
commonly used flags are the negative flag
(N), zero flag (Z), two&rsquo;s complement overflow
flag (V), and carry flag (C).
</p>
<p>Exercise Problems
</p>
<p>Section 13.1: Computer Hardware
</p>
<p>13.1.1 What computer hardware subsystem holds the
temporary variables used by the program?
</p>
<p>13.1.2 What computer hardware subsystem contains
fast storage for holding and/or manipulating
data and addresses?
</p>
<p>13.1.3 What computer hardware subsystem allows
the computer to interface to the outside world?
</p>
<p>13.1.4 What computer hardware subsystem contains
the state machine that orchestrates the fetch-
decode-execute process?
</p>
<p>13.1.5 What computer hardware subsystem contains
the circuitry that performs mathematical and
logic operations?
</p>
<p>13.1.6 What computer hardware subsystem holds the
instructions being executed?
</p>
<p>Section 13.2: Computer Software
</p>
<p>13.2.1 In computer software, what are the names of
the most basic operations that a computer can
perform?
</p>
<p>Exercise Problems &bull; 459</p>
<p/>
</div>
<div class="page"><p/>
<p>13.2.2 Which element of computer software is the
binary code that tells the CPUwhich instruction
is being executed?
</p>
<p>13.2.3 Which element of computer software is a col-
lection of instructions that perform a desired
task?
</p>
<p>13.2.4 Which element of computer software is the
supplementary information required by an
instruction such as constants or which
registers to use?
</p>
<p>13.2.5 Which class of instructions handles moving
information between memory and CPU
registers?
</p>
<p>13.2.6 Which class of instructions alters the flow of
program execution?
</p>
<p>13.2.7 Which class of instructions alters data using
either arithmetic or logical operations?
</p>
<p>Section 13.3: Computer Implementa-
</p>
<p>tion&mdash;An 8-Bit Computer Example
</p>
<p>13.3.1 Design the example 8-bit computer system
presented in this chapter in VHDL with the
ability to execute the three instructions
LDA_IMM, STA_DIR, and BRA. Simulate your
computer system using the following program
that will continually write the patterns x&rdquo;AA&rdquo;
and x&rdquo;BB&rdquo; to output ports port_out_00 and
port_out_01:
</p>
<p>constant ROM : rom_type :&frac14; (
</p>
<p>0 &frac14;&gt; LDA_IMM,
</p>
<p>1 &frac14;&gt; x"AA",
</p>
<p>2 &frac14;&gt; STA_DIR,
</p>
<p>3 &frac14;&gt; x"E0",
</p>
<p>4 &frac14;&gt; STA_DIR,
</p>
<p>5 &frac14;&gt; x"E1",
</p>
<p>6 &frac14;&gt; LDA_IMM,
</p>
<p>7 &frac14;&gt; x"BB",
</p>
<p>8 &frac14;&gt; STA_DIR,
</p>
<p>9 &frac14;&gt; x"E0",
</p>
<p>10 &frac14;&gt; STA_DIR,
</p>
<p>11 &frac14;&gt; x"E1",
</p>
<p>12 &frac14;&gt; BRA,
</p>
<p>13 &frac14;&gt; x"00",
</p>
<p>others &frac14;&gt; x"00");
</p>
<p>13.3.2 Add the functionality to the computer model
from 13.3.1 the ability to perform the LDA_DIR
instruction. Simulate your computer system
using the following program that will continually
read from port_in_00 and write its contents to
port_out_00:
</p>
<p>constant ROM : rom_type :&frac14; (
</p>
<p>0 &frac14;&gt; LDA_DIR,
</p>
<p>1 &frac14;&gt; x"F0",
</p>
<p>2 &frac14;&gt; STA_DIR,
</p>
<p>3 &frac14;&gt; x"E0",
</p>
<p>4 &frac14;&gt; BRA,
</p>
<p>5 &frac14;&gt; x"00",
</p>
<p>others &frac14;&gt; x"00");
</p>
<p>13.3.3 Add the functionality to the computer model
from 13.3.2 the ability to perform the
instructions LDB_IMM, LDB_DIR, and
STB_DIR. Modify the example programs
given in exercises 13.3.1 and 13.3.2 to use
register B in order to simulate your
implementation.
</p>
<p>13.3.4 Add the functionality to the computer model
from 13.3.3 the ability to perform the addition
instruction ADD_AB. Test your addition instruc-
tion by simulating the following program. The
first addition instruction will perform x&rdquo;FE&rdquo; +
x&rdquo;01&rdquo; &frac14; x&rdquo;FF&rdquo; and assert the negative
(N) flag. The second addition instruction will
perform x&rdquo;FF&rdquo; + x&rdquo;01&rdquo; &frac14; x&rdquo;00&rdquo; and assert the
carry (C) and zero (Z) flags. The third addition
instruction will perform x&rdquo;7F&rdquo; + x&rdquo;7F&rdquo; &frac14; x&rdquo;FE&rdquo;
and assert the two&rsquo;s complement overflow
(V) and negative (N) flags:
</p>
<p>constant ROM : rom_type :&frac14; (
</p>
<p>0 &frac14;&gt; LDA_IMM, -- A&frac14;x&rdquo;FE&rdquo;
</p>
<p>1 &frac14;&gt; x"FE",
</p>
<p>2 &frac14;&gt; LDB_IMM, -- B&frac14;x&rdquo;01&rdquo;
</p>
<p>3 &frac14;&gt; x"01",
</p>
<p>4 &frac14;&gt; ADD_AB, -- A&frac14;A+B
</p>
<p>5 &frac14;&gt; LDA_IMM, -- A&frac14;x&rdquo;FF&rdquo;
</p>
<p>6 &frac14;&gt; x"FF",
</p>
<p>7 &frac14;&gt; LDB_IMM, -- B&frac14;x&rdquo;01&rdquo;
</p>
<p>8 &frac14;&gt; x"01",
</p>
<p>9 &frac14;&gt; ADD_AB, -- A&frac14;A+B
</p>
<p>10 &frac14;&gt; LDA_IMM, -- A&frac14;x&rdquo;7F&rdquo;
</p>
<p>11 &frac14;&gt; x"7F",
</p>
<p>12 &frac14;&gt; LDB_IMM, -- B&frac14;x&rdquo;7F&rdquo;
</p>
<p>13 &frac14;&gt; x"7F",
</p>
<p>14 &frac14;&gt; ADD_AB, -- A&frac14;A+B
</p>
<p>15 &frac14;&gt; BRA,
</p>
<p>16 &frac14;&gt; x"00",
</p>
<p>others &frac14;&gt; x"00");
</p>
<p>13.3.5 Add the functionality to the computer model
from 13.3.4 the ability to perform the branch if
equal to zero instruction BEQ. Simulate your
implementation using the following program.
The first addition in this program will perform
x&rdquo;FE&rdquo; + x&rdquo;01&rdquo; &frac14; x&rdquo;FF&rdquo; (Z&frac14;0). The subsequent
BEQ instruction should NOT take the branch.
The second addition in this program will per-
form x&rdquo;FF&rdquo; + x&rdquo;01&rdquo;&frac14; x&rdquo;00&rdquo; (Z&frac14;1) and SHOULD
take the branch. The final instruction in this
program is a BRA that is inserted for safety. In
the event that the BEQ is not operating prop-
erly, the BRA will set the program counter back
to x&rdquo;00&rdquo; and prevent the program from running
away:
</p>
<p>constant ROM : rom_type :&frac14; (
</p>
<p>0 &frac14;&gt; LDA_IMM,
</p>
<p>1 &frac14;&gt; x"FE",
</p>
<p>2 &frac14;&gt; LDB_IMM,
</p>
<p>3 &frac14;&gt; x"01",
</p>
<p>4 &frac14;&gt; ADD_AB,
</p>
<p>5 &frac14;&gt; BEQ,
</p>
<p>460 &bull; Chapter 13: Computer System Design</p>
<p/>
</div>
<div class="page"><p/>
<p>6 &frac14;&gt; x&rdquo;00&rdquo;, -- should not
</p>
<p>-- branch
</p>
<p>7 &frac14;&gt; LDA_IMM,
</p>
<p>8 &frac14;&gt; x"FF",
</p>
<p>9 &frac14;&gt; LDB_IMM,
</p>
<p>10 &frac14;&gt; x"01",
</p>
<p>11 &frac14;&gt; ADD_AB,
</p>
<p>12 &frac14;&gt; BEQ,
</p>
<p>13 &frac14;&gt; x&rdquo;00&rdquo;, -- should
</p>
<p>-- branch
</p>
<p>14 &frac14;&gt; BRA,
</p>
<p>15 &frac14;&gt; x"00",
</p>
<p>others &frac14;&gt; x"00");
</p>
<p>13.3.6 Add the functionality to the computer model
from 13.3.4 all of the remaining instructions in
the set shown in Example 13.9. You will need
to create test programs to verify the execution
of each instruction.
</p>
<p>Section 13.4: Architectural
</p>
<p>Considerations
</p>
<p>13.4.1 Would the instruction set need to be different
between a Von Neumann versus a Harvard
architecture? Why or why not?
</p>
<p>13.4.2 Which of the three classes of computer
instructions (loads/stores, data manipulations,
and branches) are sped up by moving from the
Von Neumann architecture to the Harvard
architecture.
</p>
<p>13.4.3 In a memory mapped, Harvard architecture,
would the I/O system be placed in the program
memory or data memory block?
</p>
<p>13.4.4 A Harvard architecture requires two memory
address registers to handle two separate mem-
ory systems. Does it also require two instruc-
tion registers? Why or why not?
</p>
<p>13.4.5 A Harvard architecture requires two memory
address registers to handle two separate mem-
ory systems. Does it also require two program
counters? Why or why not?
</p>
<p>Exercise Problems &bull; 461</p>
<p/>
</div>
<div class="page"><p/>
<p>Appendix A: List of Worked Examples
</p>
<p>EXAMPLE 2.1. CONVERTING DECIMAL TO DECIMAL........................................................ ....................................................... 12
</p>
<p>EXAMPLE 2.2. CONVERTING BINARY TO DECIMAL ........................................................ ....................................................... 13
</p>
<p>EXAMPLE 2.3. CONVERTING OCTAL TO DECIMAL......................................................... ........................................................ 13
</p>
<p>EXAMPLE 2.4. CONVERTING HEXADECIMAL TO DECIMAL ................................................... ................................................... 14
</p>
<p>EXAMPLE 2.5. CONVERTING DECIMAL TO BINARY ....................................................... ........................................................ 15
</p>
<p>EXAMPLE 2.6. CONVERTING DECIMAL TO OCTAL......................................................... ........................................................ 16
</p>
<p>EXAMPLE 2.7. CONVERTING DECIMAL TO HEXADECIMAL ................................................... ................................................... 17
</p>
<p>EXAMPLE 2.8. CONVERTING BINARY TO OCTAL ......................................................... ......................................................... 18
</p>
<p>EXAMPLE 2.9. CONVERTING BINARY TO HEXADECIMAL .................................................... .................................................... 18
</p>
<p>EXAMPLE 2.10. CONVERTING OCTAL TO BINARY ........................................................ ........................................................ 19
</p>
<p>EXAMPLE 2.11. CONVERTING HEXADECIMAL TO BINARY.................................................... ................................................... 19
</p>
<p>EXAMPLE 2.12. CONVERTING OCTAL TO HEXADECIMAL .................................................... ................................................... 20
</p>
<p>EXAMPLE 2.13. CONVERTING HEXADECIMAL TO OCTAL .................................................... ................................................... 20
</p>
<p>EXAMPLE 2.14. SINGLE-BIT BINARY ADDITION .......................................................... ......................................................... 21
</p>
<p>EXAMPLE 2.15. MULTIPLE-BIT BINARY ADDITION ........................................................ ........................................................ 21
</p>
<p>EXAMPLE 2.16. SINGLE-BIT BINARY SUBTRACTION ....................................................... ...................................................... 22
</p>
<p>EXAMPLE 2.17. MULTIPLE-BIT BINARY SUBTRACTION..................................................... ..................................................... 22
</p>
<p>EXAMPLE 2.18. FINDING THE RANGE OF AN UNSIGNED NUMBER ............................................. ............................................. 24
</p>
<p>EXAMPLE 2.19. DECIMAL VALUES THAT A 4-BIT, SIGNED MAGNITUDE CODE CAN REPRESENT........................ ........................ 25
</p>
<p>EXAMPLE 2.20. FINDING THE RANGE OF A SIGNED MAGNITUDE NUMBER ....................................... ....................................... 26
</p>
<p>EXAMPLE 2.21. FINDING THE DECIMAL VALUE OF A SIGNED MAGNITUDE NUMBER................................. ................................. 26
</p>
<p>EXAMPLE 2.22. DECIMAL VALUES THAT A 4-BIT, ONE&rsquo;S COMPLEMENT CODE CAN REPRESENT........................ ....................... 27
</p>
<p>EXAMPLE 2.23. FINDING THE RANGE OF A 1&rsquo;S COMPLEMENT NUMBER ......................................... ........................................ 28
</p>
<p>EXAMPLE 2.24. FINDING THE DECIMAL VALUE OF A 1&rsquo;S COMPLEMENT NUMBER ................................... .................................. 28
</p>
<p>EXAMPLE 2.25. DECIMAL VALUES THAT A 4-BIT, TWO&rsquo;S COMPLEMENT CODE CAN REPRESENT........................ ....................... 29
</p>
<p>EXAMPLE 2.26. FINDING THE RANGE OF A TWO&rsquo;S COMPLEMENT NUMBER ....................................... ...................................... 30
</p>
<p>EXAMPLE 2.27. FINDING THE DECIMAL VALUE OF A TWO&rsquo;S COMPLEMENT NUMBER................................. ................................ 30
</p>
<p>EXAMPLE 2.28. FINDING THE TWO&rsquo;S COMPLEMENT CODE OF A DECIMAL NUMBER ................................. ................................ 31
</p>
<p>EXAMPLE 2.29. TWO&rsquo;S COMPLEMENT ADDITION......................................................... ......................................................... 32
</p>
<p>EXAMPLE 3.1. CALCULATING ICC AND IGND WHEN SOURCING MULTIPLE LOADS .................................. .................................. 49
</p>
<p>EXAMPLE 3.2. CALCULATING ICC AND IGND WHEN BOTH SOURCING AND SINKING LOADS ........................... ........................... 50
</p>
<p>EXAMPLE 3.3. DETERMINING IF SPECIFICATIONS ARE VIOLATED WHEN DRIVING ANOTHER GATE AS A LOAD............... .............. 72
</p>
<p>EXAMPLE 3.4. DETERMINING THE OUTPUT CURRENT WHEN DRIVING MULTIPLE GATES AS THE LOAD ................... ................... 73
</p>
<p>EXAMPLE 3.5. DETERMINING THE OUTPUT CURRENT WHEN DRIVING A PULL-UP RESISTOR AS THE LOAD ............... ................ 74
</p>
<p>EXAMPLE 3.6. DETERMINING THE OUTPUT CURRENT WHEN DRIVING A PULL-DOWN RESISTOR AS THE LOAD .............. ............. 75
</p>
<p>EXAMPLE 3.7. DETERMINING THE OUTPUT CURRENT WHEN DRIVING AN LED WHERE HIGH &frac14; ON ................... .................. 76
</p>
<p>EXAMPLE 3.8. DETERMINING THE OUTPUT CURRENT WHEN DRIVING AN LED WHERE HIGH &frac14; OFF ................. .................. 77
</p>
<p>EXAMPLE 4.1. PROVING DEMORGAN&rsquo;S THEOREM OF DUALITY USING PROOF BY EXHAUSTION......................... ........................ 84
</p>
<p>EXAMPLE 4.2. CONVERTING BETWEEN POSITIVE AND NEGATIVE LOGIC USING DUALITY ............................. ............................. 85
</p>
<p>EXAMPLE 4.3. USING THE COMMUTATIVE PROPERTY TO UNTANGLE CROSSED WIRES............................... .............................. 89
</p>
<p>EXAMPLE 4.4. USING THE ASSOCIATIVE PROPERTY TO ADDRESS FAN-IN LIMITATIONS............................... .............................. 90
</p>
<p>EXAMPLE 4.5. USING THE DISTRIBUTIVE PROPERTY TO REDUCE THE NUMBER OF LOGIC GATES IN A CIRCUIT ............. ............. 91
</p>
<p>EXAMPLE 4.6. PROVING THE ABSORPTION THEOREM USING PROOF BY EXHAUSTION............................... ............................... 92
</p>
<p>EXAMPLE 4.7. PROVING OF THE UNITING THEOREM ...................................................... ...................................................... 93
</p>
<p>EXAMPLE 4.8. CONVERTING A SUM OF PRODUCTS FORM INTO ONE THAT USES ONLY NAND GATES .................. .................. 95
</p>
<p>EXAMPLE 4.9. CONVERTING A PRODUCT OF SUMS FORM INTO ONE THAT USES ONLY NOR GATES ................... ................... 96
</p>
<p>EXAMPLE 4.10. USING DEMORGAN&rsquo;S THEOREM IN ALGEBRAIC FORM (1) ....................................... ...................................... 97
</p>
<p>EXAMPLE 4.11. USING DEMORGAN&rsquo;S THEOREM IN ALGEBRAIC FORM (2) ....................................... ...................................... 97
</p>
<p>EXAMPLE 4.12. DETERMINING THE LOGIC EXPRESSION FROM A LOGIC DIAGRAM................................. ................................. 100
</p>
<p>EXAMPLE 4.13. DETERMINING THE TRUTH TABLE FROM A LOGIC DIAGRAM..................................... ..................................... 101
</p>
<p>EXAMPLE 4.14. DETERMINING THE DELAY OF A COMBINATIONAL LOGIC CIRCUIT ................................. ................................. 102
</p>
<p># Springer International Publishing Switzerland 2017
</p>
<p>B.J. LaMeres, Introduction to Logic Circuits &amp; Logic Design with VHDL,
</p>
<p>DOI 10.1007/978-3-319-34195-8
</p>
<p>463</p>
<p/>
</div>
<div class="page"><p/>
<p>EXAMPLE 4.15. CREATING A CANONICAL SUM OF PRODUCTS LOGIC CIRCUIT USING MINTERMS...................... ...................... 104
</p>
<p>EXAMPLE 4.16. CREATING A MINTERM LIST FROM A TRUTH TABLE........................................... .......................................... 105
</p>
<p>EXAMPLE 4.17. CREATING EQUIVALENT FUNCTIONAL REPRESENTATIONS FROM A MINTERM LIST ...................... ...................... 106
</p>
<p>EXAMPLE 4.18. CREATING A PRODUCT OF SUMS LOGIC CIRCUIT USING MAXTERMS .............................. .............................. 108
</p>
<p>EXAMPLE 4.19. CREATING A MAXTERM LIST FROM A TRUTH TABLE.......................................... .......................................... 109
</p>
<p>EXAMPLE 4.20. CREATING EQUIVALENT FUNCTIONAL REPRESENTATIONS FROM A MAXTERM LIST ............................................ 110
</p>
<p>EXAMPLE 4.21. CREATING EQUIVALENT FORMS TO REPRESENT LOGIC FUNCTIONALITY .......................................................... 111
</p>
<p>EXAMPLE 4.22. MINIMIZING A LOGIC EXPRESSION ALGEBRAICALLY ...................................................................................... 113
</p>
<p>EXAMPLE 4.23. USING A K-MAP TO FIND A MINIMIZED SUM OF PRODUCTS EXPRESSION (2-INPUT) ........................................ 118
</p>
<p>EXAMPLE 4.24. USING A K-MAP TO FIND A MINIMIZED SUM OF PRODUCTS EXPRESSION (3-INPUT) ........................................ 119
</p>
<p>EXAMPLE 4.25. USING A K-MAP TO FIND A MINIMIZED SUM OF PRODUCTS EXPRESSION (4-INPUT) ................... .................... 120
</p>
<p>EXAMPLE 4.26. USING A K-MAP TO FIND A MINIMIZED PRODUCT OF SUMS EXPRESSION (2-INPUT).................... .................... 121
</p>
<p>EXAMPLE 4.27. USING A K-MAP TO FIND A MINIMIZED PRODUCT OF SUMS EXPRESSION (3-INPUT).................... .................... 122
</p>
<p>EXAMPLE 4.28. USING A K-MAP TO FIND A MINIMIZED PRODUCT OF SUMS EXPRESSION (4-INPUT).................... .................... 123
</p>
<p>EXAMPLE 4.29. DERIVING THE MINIMAL SUM FROM A K-MAP .............................................. .............................................. 125
</p>
<p>EXAMPLE 4.30. USING DON&rsquo;T CARES TO PRODUCE A MINIMAL SOP LOGIC EXPRESSION .......................... .......................... 126
</p>
<p>EXAMPLE 4.31. ELIMINATING A TIMING HAZARD BY INCLUDING NONESSENTIAL PRODUCT TERMS ...................... ...................... 131
</p>
<p>EXAMPLE 5.1. DEFINING VHDL ENTITIES ............................................................ ........................................................... 153
</p>
<p>EXAMPLE 5.2. MODELING LOGIC USING CONCURRENT SIGNAL ASSIGNMENTS AND LOGICAL OPERATORS ................ ................ 159
</p>
<p>EXAMPLE 5.3. MODELING LOGIC USING CONDITIONAL SIGNAL ASSIGNMENTS.................................... ................................... 161
</p>
<p>EXAMPLE 5.4. MODELING LOGIC USING SELECTED SIGNAL ASSIGNMENTS...................................... ..................................... 163
</p>
<p>EXAMPLE 5.5. MODELING LOGIC USING DELAYED SIGNAL ASSIGNMENTS (INERTIAL DELAY MODEL) .................... ................... 164
</p>
<p>EXAMPLE 5.6. MODELING LOGIC USING DELAYED SIGNAL ASSIGNMENTS (TRANSPORT DELAY MODEL).................. ................. 166
</p>
<p>EXAMPLE 5.7. MODELING LOGIC USING STRUCTURAL VHDL (EXPLICIT PORT MAPPING) ........................... .......................... 167
</p>
<p>EXAMPLE 5.8. MODELING LOGIC USING STRUCTURAL VHDL (POSITIONAL PORT MAPPING) ......................... ........................ 168
</p>
<p>EXAMPLE 6.1. 2-TO-4 ONE-HOT DECODER&mdash;LOGIC SYNTHESIS BY HAND ..................................... ..................................... 176
</p>
<p>EXAMPLE 6.2. 3-TO-8 ONE-HOT DECODER&mdash;VHDL MODELING USING LOGICAL OPERATORS ....................... ....................... 177
</p>
<p>EXAMPLE 6.3. 3-TO-8 ONE-HOT DECODER&mdash;VHDL MODELING USING CONDITIONAL AND SELECT SIGNAL ASSIGNMENTS .... ... 178
</p>
<p>EXAMPLE 6.4. 7-SEGMENT DISPLAY DECODER&mdash;TRUTH TABLE............................................. ............................................. 179
</p>
<p>EXAMPLE 6.5. 7-SEGMENT DISPLAY DECODER&mdash;LOGIC SYNTHESIS BY HAND................................... ................................... 180
</p>
<p>EXAMPLE 6.6. 7-SEGMENT DISPLAY DECODER&mdash;MODELING USING LOGICAL OPERATORS ........................... .......................... 181
</p>
<p>EXAMPLE 6.7. 7-SEGMENT DISPLAY DECODER&mdash;MODELING USING CONDITIONAL AND SELECTED SIGNAL ASSIGNMENTS ..... ..... 182
</p>
<p>EXAMPLE 6.8. 4-TO-2 BINARY ENCODER&mdash;LOGIC SYNTHESIS BY HAND....................................... ....................................... 183
</p>
<p>EXAMPLE 6.9. 4-TO-2 BINARY ENCODER&mdash;VHDL MODELING .............................................. ............................................. 184
</p>
<p>EXAMPLE 6.10. 2-TO-1 MULTIPLEXER&mdash;LOGIC SYNTHESIS BY HAND ......................................... ......................................... 185
</p>
<p>EXAMPLE 6.11. 4-TO-1 MULTIPLEXER&mdash;VHDL MODELING ................................................ ................................................ 186
</p>
<p>EXAMPLE 6.12. 1-TO-2 DEMULTIPLEXER&mdash;LOGIC SYNTHESIS BY HAND........................................ ....................................... 187
</p>
<p>EXAMPLE 6.13. 1-TO-4 DEMULTIPLEXER&mdash;VHDL MODELING .............................................. .............................................. 188
</p>
<p>EXAMPLE 7.1. PUSH-BUTTON WINDOW CONTROLLER&mdash;WORD DESCRIPTION .................................... ................................... 219
</p>
<p>EXAMPLE 7.2. PUSH-BUTTON WINDOW CONTROLLER&mdash;STATE DIAGRAM ....................................... ...................................... 220
</p>
<p>EXAMPLE 7.3. PUSH-BUTTON WINDOW CONTROLLER&mdash;STATE TRANSITION TABLE................................ ................................ 221
</p>
<p>EXAMPLE 7.4. SOLVING FOR THE NUMBER OF BITS NEEDED FOR BINARY STATE ENCODING ......................... ........................ 223
</p>
<p>EXAMPLE 7.5. PUSH-BUTTON WINDOW CONTROLLER&mdash;STATE ENCODING ...................................... ..................................... 225
</p>
<p>EXAMPLE 7.6. PUSH-BUTTON WINDOW CONTROLLER&mdash;NEXT STATE LOGIC .................................... .................................... 226
</p>
<p>EXAMPLE 7.7. PUSH-BUTTON WINDOW CONTROLLER&mdash;OUTPUT LOGIC ....................................... ....................................... 227
</p>
<p>EXAMPLE 7.8. PUSH-BUTTON WINDOW CONTROLLER&mdash;LOGIC DIAGRAM ....................................... ...................................... 228
</p>
<p>EXAMPLE 7.9. SERIAL BIT SEQUENCE DETECTOR (PART 1) ............................................... ............................................... 229
</p>
<p>EXAMPLE 7.10. SERIAL BIT SEQUENCE DETECTOR (PART 2) .............................................. .............................................. 230
</p>
<p>EXAMPLE 7.11. SERIAL BIT SEQUENCE DETECTOR (PART 3) .............................................. .............................................. 231
</p>
<p>EXAMPLE 7.12. VENDING MACHINE CONTROLLER (PART 1)................................................ ............................................... 232
</p>
<p>EXAMPLE 7.13. VENDING MACHINE CONTROLLER (PART 2)................................................ ............................................... 233
</p>
<p>EXAMPLE 7.14. VENDING MACHINE CONTROLLER (PART 3)................................................ ............................................... 234
</p>
<p>EXAMPLE 7.15. 2-BIT BINARY UP COUNTER (PART 1)................................................... .................................................. 236
</p>
<p>EXAMPLE 7.16. 2-BIT BINARY UP COUNTER (PART 2)................................................... .................................................. 237
</p>
<p>EXAMPLE 7.17. 2-BIT BINARY UP/DOWN COUNTER (PART 1).............................................. ............................................. 238
</p>
<p>EXAMPLE 7.18. 2-BIT BINARY UP/DOWN COUNTER (PART 2).............................................. ............................................. 239
</p>
<p>EXAMPLE 7.19. 2-BIT GRAY CODE UP COUNTER (PART 1)............................................... ............................................... 240
</p>
<p>464 &bull; Appendix A: List of Worked Examples</p>
<p/>
</div>
<div class="page"><p/>
<p>EXAMPLE 7.20. 2-BIT GRAY CODE UP COUNTER (PART 2)............................................... ............................................... 241
</p>
<p>EXAMPLE 7.21. 2-BIT GRAY CODE UP/DOWN COUNTER (PART 1).......................................... .......................................... 242
</p>
<p>EXAMPLE 7.22. 2-BIT GRAY CODE UP/DOWN COUNTER (PART 2).......................................... .......................................... 243
</p>
<p>EXAMPLE 7.23. 3-BIT ONE-HOT UP COUNTER (PART 1) ................................................. ................................................ 244
</p>
<p>EXAMPLE 7.24. 3-BIT ONE-HOT UP COUNTER (PART 2) ................................................. ................................................ 245
</p>
<p>EXAMPLE 7.25. 3-BIT ONE-HOT UP/DOWN COUNTER (PART 1) ............................................ ........................................... 246
</p>
<p>EXAMPLE 7.26. 3-BIT ONE-HOT UP/DOWN COUNTER (PART 2) ............................................ ........................................... 247
</p>
<p>EXAMPLE 7.27. 3-BIT ONE-HOT UP/DOWN COUNTER (PART 3) ............................................ ........................................... 248
</p>
<p>EXAMPLE 7.28. DETERMINING THE NEXT STATE LOGIC AND OUTPUT LOGIC EXPRESSION OF AN FSM.................. ................. 251
</p>
<p>EXAMPLE 7.29. DETERMINING THE STATE TRANSITION TABLE OF AN FSM..................................... ..................................... 252
</p>
<p>EXAMPLE 7.30. DETERMINING THE STATE DIAGRAM OF AN FSM ............................................ ........................................... 253
</p>
<p>EXAMPLE 7.31. DETERMINING THE MAXIMUM CLOCK FREQUENCY OF AN FSM.................................. .................................. 256
</p>
<p>EXAMPLE 8.1. BEHAVIOR OF SEQUENTIAL SIGNAL ASSIGNMENTS WITHIN A PROCESS .............................. .............................. 268
</p>
<p>EXAMPLE 8.2. BEHAVIOR OF CONCURRENT SIGNAL ASSIGNMENTS OUTSIDE A PROCESS............................ ............................ 268
</p>
<p>EXAMPLE 8.3. VARIABLE ASSIGNMENT BEHAVIOR....................................................... ....................................................... 269
</p>
<p>EXAMPLE 8.4. USING IF/THEN STATEMENTS TO MODEL COMBINATIONAL LOGIC.................................. .................................. 271
</p>
<p>EXAMPLE 8.5. USING CASE STATEMENTS TO MODEL COMBINATIONAL LOGIC .................................... ................................... 273
</p>
<p>EXAMPLE 8.6. BEHAVIORAL MODELING OF A RISING EDGE TRIGGERED D-FLIP-FLOP USING ATTRIBUTES ................ ............... 277
</p>
<p>EXAMPLE 8.7. CREATING A VHDL TEST BENCH ....................................................... ....................................................... 279
</p>
<p>EXAMPLE 8.8. USING REPORT STATEMENTS IN A VHDL TEST BENCH........................................ ........................................ 280
</p>
<p>EXAMPLE 8.9. USING ASSERT STATEMENTS IN A VHDL TEST BENCH ........................................ ........................................ 281
</p>
<p>EXAMPLE 8.10. BEHAVIORAL MODELING OF A D-FLIP-FLOP USING THE RISING_EDGE() FUNCTION ..................... .................... 285
</p>
<p>EXAMPLE 8.11. WRITING TO AN EXTERNAL FILE FROM A TEST BENCH (PART 1) ................................. ................................ 294
</p>
<p>EXAMPLE 8.12. WRITING TO AN EXTERNAL FILE FROM A TEST BENCH (PART 2) ................................. ................................ 295
</p>
<p>EXAMPLE 8.13. WRITING TO AN EXTERNAL FILE FROM A TEST BENCH (PART 3) ................................. ................................ 296
</p>
<p>EXAMPLE 8.14. WRITING TO STD_OUT FROM A TEST BENCH (PART 1) ..................................... ..................................... 297
</p>
<p>EXAMPLE 8.15. WRITING TO STD_OUT FROM A TEST BENCH (PART 2) ..................................... ..................................... 298
</p>
<p>EXAMPLE 8.16. READING FROM AN EXTERNAL FILE IN A TEST BENCH (PART 1) ................................. ................................ 298
</p>
<p>EXAMPLE 8.17. READING FROM AN EXTERNAL FILE IN A TEST BENCH (PART 2) ................................. ................................ 299
</p>
<p>EXAMPLE 8.18. READING FROM AN EXTERNAL FILE IN A TEST BENCH (PART 3) ................................. ................................ 300
</p>
<p>EXAMPLE 8.19. READING SPACE-DELIMITED DATA FROM AN EXTERNAL FILE IN A TEST BENCH (PART 1)................ ............... 300
</p>
<p>EXAMPLE 8.20. READING SPACE-DELIMITED DATA FROM AN EXTERNAL FILE IN A TEST BENCH (PART 2)................ ............... 301
</p>
<p>EXAMPLE 8.21. READING SPACE-DELIMITED DATA FROM AN EXTERNAL FILE IN A TEST BENCH (PART 3)................ ............... 302
</p>
<p>EXAMPLE 9.1. BEHAVIORAL MODEL OF A D-LATCH IN VHDL .............................................. .............................................. 309
</p>
<p>EXAMPLE 9.2. BEHAVIORAL MODEL OF A D-FLIP-FLOP IN VHDL ........................................... ........................................... 310
</p>
<p>EXAMPLE 9.3. BEHAVIORAL MODEL OF A D-FLIP-FLOP WITH ASYNCHRONOUS RESET IN VHDL............................................. 311
</p>
<p>EXAMPLE 9.4. BEHAVIORAL MODEL OF A D-FLIP-FLOP WITH ASYNCHRONOUS RESET AND PRESET IN VHDL ............. ............ 312
</p>
<p>EXAMPLE 9.5. BEHAVIORAL MODEL OF A D-FLIP-FLOP WITH SYNCHRONOUS ENABLE IN VHDL ...................... ...................... 313
</p>
<p>EXAMPLE 9.6. PUSH-BUTTON WINDOW CONTROLLER IN VHDL&mdash;DESIGN DESCRIPTION............................ ........................... 314
</p>
<p>EXAMPLE 9.7. PUSH-BUTTON WINDOW CONTROLLER IN VHDL&mdash;ENTITY DEFINITION ............................. ............................. 314
</p>
<p>EXAMPLE 9.8. PUSH-BUTTON WINDOW CONTROLLER IN VHDL&mdash;ARCHITECTURE ................................ ................................ 317
</p>
<p>EXAMPLE 9.9. PUSH-BUTTON WINDOW CONTROLLER IN VHDL&mdash;SIMULATION WAVEFORM ......................... .......................... 318
</p>
<p>EXAMPLE 9.10. PUSH-BUTTON WINDOW CONTROLLER IN VHDL&mdash;EXPLICIT STATE CODES......................... ......................... 318
</p>
<p>EXAMPLE 9.11. SERIAL BIT SEQUENCE DETECTOR IN VHDL&mdash;DESIGN DESCRIPTION AND ENTITY DEFINITION ........... ............ 319
</p>
<p>EXAMPLE 9.12. SERIAL BIT SEQUENCE DETECTOR IN VHDL&mdash;ARCHITECTURE .................................. ................................. 320
</p>
<p>EXAMPLE 9.13. SERIAL BIT SEQUENCE DETECTOR IN VHDL&mdash;SIMULATION WAVEFORM ........................... ........................... 320
</p>
<p>EXAMPLE 9.14. VENDING MACHINE CONTROLLER IN VHDL&mdash;DESIGN DESCRIPTION AND ENTITY DEFINITION............. ............. 321
</p>
<p>EXAMPLE 9.15. VENDING MACHINE CONTROLLER IN VHDL&mdash;ARCHITECTURE ................................... .................................. 322
</p>
<p>EXAMPLE 9.16. VENDING MACHINE CONTROLLER IN VHDL&mdash;SIMULATION WAVEFORM ............................. ............................ 323
</p>
<p>EXAMPLE 9.17. 2-BIT BINARY UP/DOWN COUNTER IN VHDL&mdash;DESIGN DESCRIPTION AND ENTITY DEFINITION ........... ........... 323
</p>
<p>EXAMPLE 9.18. 2-BIT BINARY UP/DOWN COUNTER IN VHDL&mdash;ARCHITECTURE (THREE PROCESS MODEL).............. ............. 324
</p>
<p>EXAMPLE 9.19. 2-BIT BINARY UP/DOWN COUNTER IN VHDL &ndash; SIMULATION WAVEFORM .......................... .......................... 325
</p>
<p>EXAMPLE 9.20. 4-BIT BINARY UP COUNTER IN VHDL USING THE TYPE UNSIGNED ........................... ........................... 326
</p>
<p>EXAMPLE 9.21. 4-BIT BINARY UP COUNTER IN VHDL USING THE TYPE INTEGER ............................ ............................. 327
</p>
<p>EXAMPLE 9.22. 4-BIT BINARY UP COUNTER IN VHDL USING THE TYPE STD_LOGIC_VECTOR (1) ............... ............... 328
</p>
<p>EXAMPLE 9.23. 4-BIT BINARY UP COUNTER IN VHDL USING THE TYPE STD_LOGIC_VECTOR (2) ............... ............... 329
</p>
<p>EXAMPLE 9.24. 4-BIT BINARY UP COUNTER WITH ENABLE IN VHDL ........................................ ........................................ 330
</p>
<p>Appendix A: List of Worked Examples &bull; 465</p>
<p/>
</div>
<div class="page"><p/>
<p>EXAMPLE 9.25. 4-BIT BINARY UP COUNTER WITH LOAD IN VHDL.......................................... .......................................... 331
</p>
<p>EXAMPLE 9.26. RTL MODEL OF AN 8-BIT REGISTER IN VHDL ............................................ ............................................ 332
</p>
<p>EXAMPLE 9.27. RTL MODEL OF A 4-STAGE, 8-BIT SHIFT REGISTER IN VHDL................................. ................................. 333
</p>
<p>EXAMPLE 9.28. REGISTERS AS AGENTS ON A DATA BUS&mdash;SYSTEM TOPOLOGY.................................. ................................. 334
</p>
<p>EXAMPLE 9.29. REGISTERS AS AGENTS ON A DATA BUS&mdash;RTL MODEL IN VHDL ............................... .............................. 335
</p>
<p>EXAMPLE 9.30. REGISTERS AS AGENTS ON A DATA BUS&mdash;SIMULATION WAVEFORM ............................... .............................. 336
</p>
<p>EXAMPLE 10.1. CALCULATING THE FINAL DIGIT LINE VOLTAGE IN A DRAM BASED ON CHARGE SHARING ............... .............. 338
</p>
<p>EXAMPLE 10.2. BEHAVIORAL MODEL OF A 4X4 ASYNCHRONOUS READ-ONLY MEMORY IN VHDL ..................... .................... 363
</p>
<p>EXAMPLE 10.3. BEHAVIORAL MODEL OF A 4X4 SYNCHRONOUS READ-ONLY MEMORY IN VHDL...................... ..................... 364
</p>
<p>EXAMPLE 10.4. BEHAVIORAL MODEL OF A 4X4 ASYNCHRONOUS READ/WRITE MEMORY IN VHDL.................... .................... 366
</p>
<p>EXAMPLE 10.5. BEHAVIORAL MODEL OF A 4X4 SYNCHRONOUS READ/WRITE MEMORY IN VHDL..................... ..................... 367
</p>
<p>EXAMPLE 12.1. DESIGN OF A HALF ADDER ........................................................... .......................................................... 386
</p>
<p>EXAMPLE 12.2. DESIGN OF A FULL ADDER .......................................................... ........................................................... 386
</p>
<p>EXAMPLE 12.3. DESIGN OF A FULL ADDER OUT OF HALF ADDERS .......................................... .......................................... 388
</p>
<p>EXAMPLE 12.4. DESIGN OF A 4-BIT RIPPLE CARRY ADDER (RCA) .......................................... ......................................... 389
</p>
<p>EXAMPLE 12.5. TIMING ANALYSIS OF A 4-BIT RIPPLE CARRY ADDER ......................................... ........................................ 390
</p>
<p>EXAMPLE 12.6. DESIGN OF A 4-BIT CARRY LOOK AHEAD ADDER (CLA)&mdash;OVERVIEW ............................ ............................ 391
</p>
<p>EXAMPLE 12.7. DESIGN OF A 4-BIT CARRY LOOK AHEAD ADDER (CLA)&mdash;ALGEBRAIC FORMATION ................... ................... 392
</p>
<p>EXAMPLE 12.8. TIMING ANALYSIS OF A 4-BIT CARRY LOOK AHEAD ADDER .................................... .................................... 393
</p>
<p>EXAMPLE 12.9. STRUCTURAL MODEL OF A FULL ADDER IN VHDL USING TWO HALF ADDERS....................... ...................... 394
</p>
<p>EXAMPLE 12.10. STRUCTURAL MODEL OF A 4-BIT RIPPLE CARRY ADDER IN VHDL.............................. ............................. 395
</p>
<p>EXAMPLE 12.11. VHDL TEST BENCH FOR A 4-BIT RIPPLE CARRY ADDER USING NESTED FOR LOOPS................ ................ 396
</p>
<p>EXAMPLE 12.12. STRUCTURAL MODEL OF A 4-BIT CARRY LOOK AHEAD ADDER IN VHDL......................... ......................... 397
</p>
<p>EXAMPLE 12.13. 4-BIT CARRY LOOK AHEAD ADDER&mdash;SIMULATION WAVEFORM ................................. ................................. 398
</p>
<p>EXAMPLE 12.14. BEHAVIORAL MODEL OF A 4-BIT ADDER IN VHDL ......................................... ......................................... 399
</p>
<p>EXAMPLE 12.15. DESIGN OF A 4-BIT SUBTRACTOR USING FULL ADDERS...................................... ..................................... 400
</p>
<p>EXAMPLE 12.16. CREATING A PROGRAMMABLE INVERTER USING AN XOR GATE ................................ ................................ 400
</p>
<p>EXAMPLE 12.17. DESIGN OF A 4-BIT PROGRAMMABLE ADDER/SUBTRACTOR .................................... ................................... 401
</p>
<p>EXAMPLE 12.18. PERFORMING LONG MULTIPLICATION ON DECIMAL NUMBERS ................................... .................................. 402
</p>
<p>EXAMPLE 12.19. PERFORMING LONG MULTIPLICATION ON BINARY NUMBERS .................................... ................................... 403
</p>
<p>EXAMPLE 12.20. DESIGN OF A SINGLE-BIT MULTIPLIER .................................................. .................................................. 403
</p>
<p>EXAMPLE 12.21. DESIGN OF A 4-BIT UNSIGNED MULTIPLIER............................................... .............................................. 404
</p>
<p>EXAMPLE 12.22. TIMING ANALYSIS OF A 4-BIT UNSIGNED MULTIPLIER ........................................ ....................................... 404
</p>
<p>EXAMPLE 12.23. MULTIPLYING AN UNSIGNED BINARY NUMBERS BY TWO USING A LOGICAL SHIFT LEFT ................ ................ 405
</p>
<p>EXAMPLE 12.24. ILLUSTRATING HOW AN UNSIGNED MULTIPLIER INCORRECTLY HANDLES SIGNED NUMBERS.............. .............. 406
</p>
<p>EXAMPLE 12.25. PROCESS TO CORRECTLY HANDLE SIGNED NUMBERS USING AN UNSIGNED MULTIPLIER ............... ............... 407
</p>
<p>EXAMPLE 12.26. PERFORMING LONG DIVISION ON DECIMAL NUMBERS ........................................ ....................................... 408
</p>
<p>EXAMPLE 12.27. PERFORMING LONG MULTIPLICATION ON BINARY NUMBERS .................................... ................................... 409
</p>
<p>EXAMPLE 12.28. DESIGN OF A 4-BIT UNSIGNED DIVIDER USING A SERIES OF ITERATIVE SUBTRACTORS ................ ................ 410
</p>
<p>EXAMPLE 12.29. DIVIDING 11112 (1510) BY 01112 (710) USING THE ITERATIVE SUBTRACTION ARCHITECTURE ....................... 411
</p>
<p>EXAMPLE 12.30. DIVIDING AN UNSIGNED BINARY NUMBERS BY TWO USING A LOGICAL SHIFT RIGHT.................. .................. 412
</p>
<p>EXAMPLE 13.1. MEMORY MAP FOR A 256X8 MEMORY SYSTEM............................................ ............................................ 422
</p>
<p>EXAMPLE 13.2. EXECUTION OF AN INSTRUCTION TO &ldquo;LOAD REGISTER A USING IMMEDIATE ADDRESSING&rdquo; ................ ............... 425
</p>
<p>EXAMPLE 13.3. EXECUTION OF AN INSTRUCTION TO &ldquo;LOAD REGISTER A USING DIRECT ADDRESSING&rdquo; .................. ................. 426
</p>
<p>EXAMPLE 13.4. EXECUTION OF AN INSTRUCTION TO &ldquo;STORE REGISTER A USING DIRECT ADDRESSING&rdquo; ................. ................ 427
</p>
<p>EXAMPLE 13.5. EXECUTION OF AN INSTRUCTION TO &ldquo;ADD REGISTERS A AND B&rdquo; ................................. ................................ 428
</p>
<p>EXAMPLE 13.6. EXECUTION OF AN INSTRUCTION TO &ldquo;BRANCH ALWAYS&rdquo; ....................................... ....................................... 429
</p>
<p>EXAMPLE 13.7. EXECUTION OF AN INSTRUCTION TO &ldquo;BRANCH IF EQUAL TO ZERO&rdquo;................................ ............................... 430
</p>
<p>EXAMPLE 13.8. TOP LEVEL BLOCK DIAGRAM FOR THE 8-BIT COMPUTER SYSTEM ................................ ............................... 432
</p>
<p>EXAMPLE 13.9. INSTRUCTION SET FOR THE 8-BIT COMPUTER SYSTEM........................................ ....................................... 433
</p>
<p>EXAMPLE 13.10. MEMORY SYSTEM BLOCK DIAGRAM FOR THE 8-BIT COMPUTER SYSTEM.......................... .......................... 434
</p>
<p>EXAMPLE 13.11. CPU BLOCK DIAGRAM FOR THE 8-BIT COMPUTER SYSTEM ................................... .................................. 438
</p>
<p>EXAMPLE 13.12. STATE DIAGRAM FOR LDA_IMM..................................................... ..................................................... 444
</p>
<p>EXAMPLE 13.13. SIMULATION WAVEFORM FOR LDA_IMM ................................................ ............................................... 445
</p>
<p>EXAMPLE 13.14. STATE DIAGRAM FOR LDA_DIR...................................................... ..................................................... 446
</p>
<p>EXAMPLE 13.15. SIMULATION WAVEFORM FOR LDA_DIR ................................................ ................................................ 447
</p>
<p>EXAMPLE 13.16. STATE DIAGRAM FOR STA_DIR ...................................................... ..................................................... 448
</p>
<p>466 &bull; Appendix A: List of Worked Examples</p>
<p/>
</div>
<div class="page"><p/>
<p>EXAMPLE 13.17. SIMULATION WAVEFORM FOR STA_DIR ................................................ ................................................ 449
</p>
<p>EXAMPLE 13.18. STATE DIAGRAM FOR ADD_AB...................................................... ...................................................... 450
</p>
<p>EXAMPLE 13.19. SIMULATION WAVEFORM FOR ADD_AB................................................. ................................................ 451
</p>
<p>EXAMPLE 13.20. STATE DIAGRAM FOR BRA.......................................................... ......................................................... 452
</p>
<p>EXAMPLE 13.21. SIMULATION WAVEFORM FOR BRA.................................................... .................................................... 453
</p>
<p>EXAMPLE 13.22. STATE DIAGRAM FOR BEQ.......................................................... ......................................................... 454
</p>
<p>EXAMPLE 13.23. SIMULATION WAVEFORM FOR BEQ WHEN TAKING THE BRANCH (Z &frac14; 1)......................... ......................... 455
</p>
<p>EXAMPLE 13.24. SIMULATION WAVEFORM FOR BEQ WHEN THE BRANCH IS NOT TAKEN (Z &frac14; 0) ................... .................... 456
</p>
<p>Appendix A: List of Worked Examples &bull; 467</p>
<p/>
</div>
<div class="page"><p/>
</div>
<div class="page"><p/>
<p>Suggested Readings
</p>
<p>1. Wakerly JF (2006) Digital design: principles and practice, 4th edn. Pearson Education, Upper Saddle River,
</p>
<p>NJ
</p>
<p>2. Kang S, Leblebici Y, Kim C (2015) &ldquo;Combinational MOS logic circuits&rdquo; in CMOS digital integrated circuits:
analysis and design, 4th edn. McGraw-Hill Education, New York, NY
</p>
<p>3. Cady FM (2007) Software and hardware engineering. Oxford University Press, Upper Saddle River, NJ
</p>
<p>4. Ciletti MD (2003) Modeling, synthesis, and rapid prototyping with Verilog HDL. Prentice Hall, Upper Saddle
</p>
<p>River, NJ
5. Mano MM, Ciletti MD (2012) Digital design &ndash; with an introduction to the Verilog HDL, 5th edn. Pearson,
</p>
<p>Upper Saddle River, NJ
</p>
<p>6. Yalamanchili S (1997) VHDL starter&rsquo;s guide. Prentice Hall, Upper Saddle River, NJ
7. IEEE Standard VHDL Language Reference Manual (2009) in IEEE Std 1076-2008 (Revision of IEEE Std
</p>
<p>1076-2002), Jan. 26 2009
</p>
<p># Springer International Publishing Switzerland 2017
</p>
<p>B.J. LaMeres, Introduction to Logic Circuits &amp; Logic Design with VHDL,
</p>
<p>DOI 10.1007/978-3-319-34195-8
</p>
<p>469</p>
<p/>
</div>
<div class="page"><p/>
<p>Index
</p>
<p>A
</p>
<p>Absorption, 92
</p>
<p>Abstraction, 143
</p>
<p>AC specifications. See Switching characteristics
</p>
<p>Adder/subtractor circuit, 400
</p>
<p>Adders
</p>
<p>in VHDL, 393
</p>
<p>Addition, 21, 385
</p>
<p>AND gate, 40
</p>
<p>Anti-fuse, 347
</p>
<p>Associative property, 89
</p>
<p>Asynchronous memory, 345
</p>
<p>Axioms, 82
</p>
<p>logical negation, 82
</p>
<p>logical precedence, 83
</p>
<p>logical product, 82
</p>
<p>logical sum, 83
</p>
<p>logical values, 82
</p>
<p>B
</p>
<p>Base, 7
</p>
<p>Base conversions, 11
</p>
<p>binary to decimal, 12
</p>
<p>binary to hexadecimal, 18
</p>
<p>binary to octal, 17
</p>
<p>decimal to binary, 15
</p>
<p>decimal to decimal, 11
</p>
<p>decimal to hexadecimal, 16
</p>
<p>decimal to octal, 15
</p>
<p>hexadecimal to binary, 19
</p>
<p>hexadecimal to decimal, 14
</p>
<p>hexadecimal to octal, 20
</p>
<p>octal to binary, 18
</p>
<p>octal to decimal, 13
</p>
<p>octal to hexadecimal, 19
</p>
<p>Binary addition. See Addition
</p>
<p>Binary number system, 9
</p>
<p>Binary subtraction. See Subtraction
</p>
<p>Bipolar junction transistor (BJT), 65
</p>
<p>Bistable, 196
</p>
<p>Boolean algebra, 81
</p>
<p>Boolean algebra theorems, 83
</p>
<p>Borrows, 22
</p>
<p>Break-before-make switch behavior, 215
</p>
<p>Buffer, 39
</p>
<p>Byte, 10
</p>
<p>C
</p>
<p>Canonical product of sums, 106
</p>
<p>Canonical sum of products, 103
</p>
<p>Capacity, 341
</p>
<p>Carry, 21
</p>
<p>Carry look ahead adders (CLA), 390
</p>
<p>Charge sharing, 357
</p>
<p>Classical digital design flow, 146
</p>
<p>CMOS. See Complementary metal oxide
</p>
<p>semiconductor (CMOS)
</p>
<p>CMOS gates
</p>
<p>inverter, 58
</p>
<p>NAND gate, 59
</p>
<p>NOR gate, 62
</p>
<p>Combinational logic analysis, 99
</p>
<p>Combining, 93
</p>
<p>Commutative property, 88
</p>
<p>Complementary metal oxide semiconductor
</p>
<p>(CMOS), 4, 56
</p>
<p>operation, 57
</p>
<p>Complements, 87
</p>
<p>Complete sum, 125
</p>
<p>Complex programmable logic device (CPLD), 375
</p>
<p>Computer system design, 417, 425, 427, 428, 432,
</p>
<p>433, 438, 439, 442, 444
</p>
<p>addressing modes, 423
</p>
<p>arithmetic logic unit (ALU), 419
</p>
<p>central processing unit, 419
</p>
<p>condition code register, 419
</p>
<p>control unit, 419
</p>
<p>data memory, 418
</p>
<p>data path, 419
</p>
<p>direct addressing, 423
</p>
<p>example 8-bit system, 432
</p>
<p>control unit, 442
</p>
<p>CPU, 438
</p>
<p>data path, 439
detailed instruction execution, 444
</p>
<p>instruction set, 432
</p>
<p>memory system, 433
</p>
<p>general purpose registers, 419
</p>
<p>hardware, 417
</p>
<p>immediate addressing, 423
</p>
<p>indexed addressing, 424
</p>
<p>inherent addressing, 424
</p>
<p>input output ports, 418
</p>
<p>instruction register, 419
</p>
<p>instructions, 417
</p>
<p>branches, 428
data manipulations, 427
</p>
<p>loads and stores, 425
</p>
<p>memory address register, 419
</p>
<p>memory map, 422
</p>
<p>memory mapped system, 420
</p>
<p>opcodes, 422
</p>
<p># Springer International Publishing Switzerland 2017
</p>
<p>B.J. LaMeres, Introduction to Logic Circuits &amp; Logic Design with VHDL,
</p>
<p>DOI 10.1007/978-3-319-34195-8
</p>
<p>471</p>
<p/>
</div>
<div class="page"><p/>
<p>Computer system design (cont.)
</p>
<p>operands, 422
</p>
<p>program, 417
</p>
<p>counter, 419
</p>
<p>memory, 418
</p>
<p>registers, 419
</p>
<p>software, 417, 422
</p>
<p>Configurable logic block (CLB), 376
</p>
<p>Conjunction (^), 82
</p>
<p>Converting between bases. See Base conversions
</p>
<p>Converting between positive and negative logic, 84
</p>
<p>Counters, 236, 325
</p>
<p>designing by hand, 236
</p>
<p>modeling in VHDL, 325
</p>
<p>Covering, 92
</p>
<p>Cross-coupled inverter pair, 195
</p>
<p>D
</p>
<p>Data sheet, 55
</p>
<p>7400 DC operating conditions, 69
</p>
<p>DC specifications, 45
</p>
<p>IIH-max, 47
</p>
<p>IIL-max, 47
</p>
<p>II-max, 47
</p>
<p>IOH-max, 46
</p>
<p>IOL-max, 46
</p>
<p>IO-max, 46
</p>
<p>Iq (quiescent current), 48
</p>
<p>NMH, 47
</p>
<p>NML, 47
</p>
<p>VIH-max, 47
</p>
<p>VIH-min, 47
</p>
<p>VIL-max, 47
</p>
<p>VIL-min, 47
</p>
<p>VOH-max, 45
</p>
<p>VOH-min, 45
</p>
<p>VOL-max, 45
</p>
<p>VOL-min, 45
</p>
<p>Decimal number system, 9
</p>
<p>Decoders, 175
</p>
<p>DeMorgan&rsquo;s Theorem, 93
</p>
<p>DeMorgan's Theorem of Duality, 83
</p>
<p>Demultiplexer design by hand, 187
</p>
<p>Demultiplexer modeling in VHDL, 188
</p>
<p>Demultiplexers, 187
</p>
<p>Design abstraction, 143
</p>
<p>Design domains, 144
</p>
<p>behavioral, 144
</p>
<p>physical, 144
</p>
<p>structural, 144
</p>
<p>Design levels, 144
</p>
<p>algorithmic, 144
</p>
<p>circuit, 144
</p>
<p>gate, 144
</p>
<p>register transfer, 144
</p>
<p>system, 144
</p>
<p>Design simplicity, 3
</p>
<p>D-flip-flop, 207
</p>
<p>Digit, 9
</p>
<p>Digit notation, 9
</p>
<p>Digital design flow, 146
</p>
<p>Diodes, 75
</p>
<p>7400 DIP pinout, 69
</p>
<p>Discrete components, 56
</p>
<p>Disjunction (_), 82
</p>
<p>Distinguished one cells, 125
</p>
<p>Distributive property, 91
</p>
<p>Division, 408
</p>
<p>by powers of 2, 412
</p>
<p>signed, 412
</p>
<p>unsigned, 408
</p>
<p>using iterative subtractions, 409
</p>
<p>D latch, 206
</p>
<p>Don&rsquo;t cares (X), 125
</p>
<p>Double pole, double throw (DPDT) switch, 214
</p>
<p>Double pole, single throw (DPST) switch, 214
</p>
<p>Driving loads, 71
</p>
<p>Driving resistive loads, 73
</p>
<p>Dual in-line package (DIP), 69
</p>
<p>Duality, 83
</p>
<p>Dynamic hazard, 130
</p>
<p>Dynamic random access memory (DRAM), 355
</p>
<p>E
</p>
<p>Electrical signaling, 1
</p>
<p>Electrically erasable programmable read only memory
</p>
<p>(EEPROM), 350
</p>
<p>Encoders, 183
</p>
<p>Erasable programmable read only memory
</p>
<p>(EPROM), 348
</p>
<p>Essential prime implicant, 125
</p>
<p>F
</p>
<p>Field programmable gate array (FPGA), 375
</p>
<p>Finite state machines (FSM), 219
</p>
<p>behavioral modeling in VHDL, 314
</p>
<p>binary state encoding, 222
</p>
<p>design examples by hand, 229
</p>
<p>design process, 228
</p>
<p>final logic diagram, 227
</p>
<p>gray code state encoding, 223
</p>
<p>introduction, 219
</p>
<p>next state logic, 225
</p>
<p>one-hot state encoding, 224
</p>
<p>output logic, 226
</p>
<p>reset condition, 249
</p>
<p>state diagram, 219
</p>
<p>state memory, 222
</p>
<p>state transition table, 221
</p>
<p>state variables, 225
</p>
<p>synthesis by hand, 221
</p>
<p>472 &bull; Index</p>
<p/>
</div>
<div class="page"><p/>
<p>FLASH memory, 351
</p>
<p>NAND-FLASH, 351
</p>
<p>NOR-FLASH, 351
</p>
<p>Floating-gate transistor, 348
</p>
<p>Forward current (IF), 75
</p>
<p>Forward voltage (VF), 75
</p>
<p>Full adders, 386
</p>
<p>Functionally complete sets, 98
</p>
<p>Fuse, 347
</p>
<p>G
</p>
<p>Gajski and Kuhn&rsquo;s Y-chart, 144
</p>
<p>Gates, 37
</p>
<p>Generic array logic (GAL), 373
</p>
<p>Glitches, 129
</p>
<p>H
</p>
<p>Half adders, 386
</p>
<p>Hard array logic (HAL), 374
</p>
<p>Hazards, 129
</p>
<p>Hexadecimal number system, 10
</p>
<p>History of HDLs, 140
</p>
<p>I
</p>
<p>Idempotent, 87
</p>
<p>Identity theorem, 86
</p>
<p>Input/output blocks (IOBs), 381
</p>
<p>Integrated circuit, 56
</p>
<p>Inverter, 40
</p>
<p>Involution, 88
</p>
<p>K
</p>
<p>Karnaugh map (K-map), 113
</p>
<p>L
</p>
<p>Large scale integrated circuit
</p>
<p>(LSI) logic, 175
</p>
<p>Leading zero, 9
</p>
<p>Least significant bit (LSB), 10
</p>
<p>Light emitting diodes (LEDs), 75
</p>
<p>Logic block (LE), 376
</p>
<p>Logic expression, 38
</p>
<p>Logic families, 56
</p>
<p>Logic function, 38
</p>
<p>Logic HIGH, 44
</p>
<p>Logic levels, 44
</p>
<p>Logic LOW, 44
</p>
<p>Logic minimization, 112
</p>
<p>Logic symbol, 37
</p>
<p>Logic synthesis, 103
</p>
<p>Logic value, 45
</p>
<p>Logic waveform, 39
</p>
<p>Look-up table (LUT), 377
</p>
<p>M
</p>
<p>Mask read-only memory (MROM), 346
</p>
<p>Maxterm list (Π), 108
</p>
<p>Maxterms, 106
</p>
<p>Mealy machine, 220
</p>
<p>Medium scale integrated circuit (MSI) logic, 175
</p>
<p>Memory map model, 341
</p>
<p>Metal oxide semiconductor field effect transistor
</p>
<p>(MOSFET), 56
</p>
<p>Metastability, 196
</p>
<p>Minimal sum, 123, 125
</p>
<p>Minimization, 112
</p>
<p>of logic algebraically, 112
</p>
<p>of logic using K-maps, 116
</p>
<p>Minterm list (&sum;), 104
</p>
<p>Minterms, 103
</p>
<p>Modern digital design flow, 146
</p>
<p>Moore machine, 220
</p>
<p>MOSFET. See Metal oxide semiconductor field effect
</p>
<p>transistor (MOSFET)
</p>
<p>Most significant bit (MSB), 10
</p>
<p>Multiplexer design by hand, 185
</p>
<p>Multiplexer modeling in VHDL, 186
</p>
<p>Multiplexers, 185
</p>
<p>Multiplication, 402
</p>
<p>by powers of 2, 405
</p>
<p>combinational multiplier, 403
</p>
<p>shift and add approach, 402
</p>
<p>signed, 405
</p>
<p>unsigned, 402
</p>
<p>N
</p>
<p>NAND-debounce circuit, 216
</p>
<p>NAND gate, 41
</p>
<p>Negation (&Oslash;), 82
</p>
<p>Negative logic, 45
</p>
<p>Nibble, 10
</p>
<p>NMOS, 57
</p>
<p>Noise, 2
</p>
<p>Noise margin HIGH (MNH), 47
</p>
<p>Noise margin LOW (MNL), 47
</p>
<p>Non-volatile memory, 342
</p>
<p>NOR gate, 41
</p>
<p>NPN, 65
</p>
<p>Null element, 86
</p>
<p>Numerals, 7
</p>
<p>O
</p>
<p>Octal number system, 10
</p>
<p>Ohm&rsquo;s law, 73
</p>
<p>One-hot binary encoder design by hand, 183
</p>
<p>One-hot binary encoder modeling in VHDL, 183
</p>
<p>One-hot decoder design by hand, 176
</p>
<p>Index &bull; 473</p>
<p/>
</div>
<div class="page"><p/>
<p>One-hot decoder modeling in VHDL, 176
</p>
<p>One&rsquo;s complement numbers, 26
</p>
<p>OR gate, 41
</p>
<p>Output DC specifications. See DC specifications
</p>
<p>Output logic macrocell (OLMC), 373
</p>
<p>P
</p>
<p>7400 Part numbering scheme, 68
</p>
<p>Place and route, 147
</p>
<p>PMOS, 57
</p>
<p>PNP, 65
</p>
<p>Positional number system, 7
</p>
<p>Positional weight, 11
</p>
<p>Positive logic, 45
</p>
<p>Postulates, 82
</p>
<p>Power consumption, 4
</p>
<p>Power supplies, 48
</p>
<p>ICC, 48
</p>
<p>IGND, 48
</p>
<p>VCC, 48
</p>
<p>Prime implicant, 117
</p>
<p>Product of sums (POS) form, 94
</p>
<p>Programmable array logic (PAL), 372
</p>
<p>Programmable interconnect points (PIPs), 380
</p>
<p>Programmable logic array (PLA), 371
</p>
<p>Programmable read only memory (PROM), 347
</p>
<p>Proof by exhaustion, 83
</p>
<p>Q
</p>
<p>Quiescent current (Iq), 48
</p>
<p>R
</p>
<p>Radix, 7
</p>
<p>Radix point, 8
</p>
<p>Random access memory (RAM), 342
</p>
<p>Range
</p>
<p>one&rsquo;s complement numbers, 27
</p>
<p>signed magnitude numbers, 25
</p>
<p>two&rsquo;s complement numbers, 29
</p>
<p>unsigned numbers, 23
</p>
<p>Read cycle, 341
</p>
<p>Read only memory (ROM), 342, 343
</p>
<p>Read/write (RW) memory, 342
</p>
<p>Ripple carry adders (RCA), 388
</p>
<p>Ripple counter, 213
</p>
<p>S
</p>
<p>7-Segment decoder design by hand, 179
</p>
<p>7-Segment decoder modeling in VHDL, 180
</p>
<p>Semiconductor memory, 341
</p>
<p>7400 Series logic families, 67
</p>
<p>Sequential access memory, 342
</p>
<p>Sequential logic analysis, 250
</p>
<p>Sequential logic timing, 211
</p>
<p>Shift register, 218
</p>
<p>Signaling, 1
</p>
<p>Signed magnitude numbers, 24
</p>
<p>Signed numbers, 24
</p>
<p>Simple programmable logic device (SPLD), 375
</p>
<p>Single pole, double throw (SPDT) switch, 214
</p>
<p>Single pole, single throw (SPST) switch, 214
</p>
<p>Sinking current, 46, 47
</p>
<p>Small scale integrated circuit (SSI) logic, 175
</p>
<p>Sourcing and sinking multiple loads, 50
</p>
<p>Sourcing current, 46
</p>
<p>Sourcing multiple loads, 50
</p>
<p>SR latch, 198, 201
</p>
<p>SR latch with enable, 204
</p>
<p>Static 0 hazard, 130
</p>
<p>Static 1 hazard, 130
</p>
<p>Static random access memory (SRAM), 352
</p>
<p>Subtraction, 22, 400
</p>
<p>Sum of products (SOP) form, 94
</p>
<p>Switch debouncing, 213
</p>
<p>Switching characteristics, 51
</p>
<p>tf (fall time), 51
</p>
<p>tPHL (propagation delay HIGH to LOW), 51
</p>
<p>tPLH (propagation delay LOW to HIGH), 51
</p>
<p>tr (rise time), 51
</p>
<p>tt (transition time), 51
</p>
<p>Synchronous memory, 345
</p>
<p>T
</p>
<p>Technology mapping, 147
</p>
<p>Timing hazards, 129
</p>
<p>Toggle flop (T-flop), 212
</p>
<p>Trailing zero, 9
</p>
<p>Transistor-transistor logic (TTL), 65
</p>
<p>Transmitter/receiver circuit, 44
</p>
<p>Truth table formation, 38
</p>
<p>TTL operation, 65
</p>
<p>Two&rsquo;s complement arithmetic, 31
</p>
<p>Two&rsquo;s complement numbers, 29
</p>
<p>U
</p>
<p>Uniting, 93
</p>
<p>Unsigned numbers, 23
</p>
<p>V
</p>
<p>Verification, 145
</p>
<p>Verilog HDL, 141
</p>
<p>Very large scale integrated circuit (VLSI) logic, 175
</p>
<p>VHDL, 139
</p>
<p>VHDL behavioral modeling techniques, 315, 318, 319,
</p>
<p>325&ndash;327, 329, 330
</p>
<p>adders, 393
</p>
<p>counters, 325
</p>
<p>using type INTEGER, 326
</p>
<p>using type STD_LOGIC_VECTOR, 327
</p>
<p>using type UNSIGNED, 325
</p>
<p>with enables, 329
with loads, 330
</p>
<p>D-flip-flops, 310
</p>
<p>474 &bull; Index</p>
<p/>
</div>
<div class="page"><p/>
<p>D-latches, 309
</p>
<p>finite state machines, 314
</p>
<p>design examples, 319
</p>
<p>explicit state encoding using subtypes, 318
</p>
<p>three process model, 315
user-enumerated state encoding, 315
</p>
<p>modeling agents on a bus, 334
</p>
<p>modeling memory, 362
</p>
<p>modeling registers, 332
</p>
<p>modeling shift registers, 333
</p>
<p>RTL modeling, 332
</p>
<p>VHDL constructs, 149, 155, 164, 166, 168, 265, 266,
</p>
<p>279, 280, 291
</p>
<p>architecture, 149, 153
</p>
<p>assignment operator (&lt;&frac14;), 156
</p>
<p>attributes, 276
</p>
<p>case statements, 272
</p>
<p>component declaration, 155
</p>
<p>concatenation operator, 158
</p>
<p>concurrent signal assignments, 158
</p>
<p>concurrent signal assignments with logical operators,
</p>
<p>159
</p>
<p>conditional signal assignments, 160
</p>
<p>constant declaration, 154
</p>
<p>data types, 150
</p>
<p>delayed signal assignments, 164
</p>
<p>inertial, 164
</p>
<p>transport, 164
</p>
<p>entity, 149
</p>
<p>entity definition, 153
</p>
<p>for loops, 275
</p>
<p>if/then statements, 270
</p>
<p>libraries and packages, 152
</p>
<p>logical operators, 156
</p>
<p>loop statements, 274
</p>
<p>numerical operators, 157
</p>
<p>operators, 155
</p>
<p>packages, 149
</p>
<p>process, 265
</p>
<p>sensitivity list, 265
wait statement, 266
</p>
<p>relational operators, 157
</p>
<p>selected signal assignments, 161
</p>
<p>sequential signal assignments, 267
</p>
<p>shift operators, 157
</p>
<p>signal declaration, 154
</p>
<p>structural design, 166
</p>
<p>component declaration, 155
</p>
<p>component instantiation, 166
</p>
<p>explicit port mapping, 166
port mapping, 166
</p>
<p>positional port mapping, 168
</p>
<p>test benches, 278
</p>
<p>assert statements, 280
</p>
<p>reading/writing external files, 291
</p>
<p>report statements, 279
</p>
<p>variables, 269
</p>
<p>while loops, 275
</p>
<p>VHDL data types
</p>
<p>array, 152
</p>
<p>bit, 150
</p>
<p>bit_vector, 151
</p>
<p>boolean, 150
</p>
<p>character, 150
</p>
<p>integer, 150
</p>
<p>natural, 152
</p>
<p>positive, 152
</p>
<p>real, 150
</p>
<p>std_logic, 282
</p>
<p>std_logic_vector, 282
</p>
<p>std_ulogic, 282
</p>
<p>std_ulogic_vector, 282
</p>
<p>string, 151
</p>
<p>time, 151
</p>
<p>user-defined enumerated, 151
</p>
<p>VHDL packages, 282, 283, 285, 287
</p>
<p>MATH_COMPLEX, 291
</p>
<p>MATH_REAL, 289
</p>
<p>NUMERIC_BIT, 288
</p>
<p>NUMERIC_BIT_UNSIGNED, 289
</p>
<p>NUMERIC_STD, 286
</p>
<p>conversion functions, 287
</p>
<p>type casting, 287
</p>
<p>NUMERIC_STD_UNSIGNED, 288
</p>
<p>standard, 149
</p>
<p>STD_LOGIC_1164, 282
</p>
<p>resolution function, 283
</p>
<p>type conversions, 285
</p>
<p>STD_LOGIC_ARITH, 302
</p>
<p>STD_LOGIC_SIGNED, 303
</p>
<p>STD_LOGIC_TEXTIO, 291
</p>
<p>STD_LOGIC_UNSIGNED, 303
</p>
<p>TEXTIO, 291
</p>
<p>Volatile memory, 342
</p>
<p>W
</p>
<p>Weight, 11
</p>
<p>Word, 10
</p>
<p>Write cycle, 341
</p>
<p>X
</p>
<p>X-don&rsquo;t cares, 125
</p>
<p>XNOR gate, 43
</p>
<p>XOR gate, 42
</p>
<p>XOR/XNOR gates in K-maps, 126
</p>
<p>Y
</p>
<p>Y-chart, 144
</p>
<p>Index &bull; 475</p>
<p/>
</div>
<ul>	<li>Preface</li>
<ul>	<li>Written the Way It Is Taught</li>
	<li>Learning Outcomes</li>
	<li>Teaching by Example</li>
	<li>Course Design</li>
	<li>Instructor Resources</li>
</ul>
	<li>Acknowledgements</li>
	<li>Contents</li>
	<li>1: Introduction: Analog vs. Digital</li>
<ul>	<li>1.1 Differences Between Analog and Digital Systems</li>
	<li>1.2 Advantages of Digital Systems Over Analog Systems</li>
</ul>
	<li>2: Number Systems</li>
<ul>	<li>2.1 Positional Number Systems</li>
<ul>	<li>2.1.1 Generic Structure</li>
	<li>2.1.2 Decimal Number System (Base 10)</li>
	<li>2.1.3 Binary Number System (Base 2)</li>
	<li>2.1.4 Octal Number System (Base 8)</li>
	<li>2.1.5 Hexadecimal Number System (Base 16)</li>
</ul>
	<li>2.2 Base Conversion</li>
<ul>	<li>2.2.1 Converting to Decimal</li>
<ul>	<li>2.2.1.1 Binary to Decimal</li>
	<li>2.2.1.2 Octal to Decimal</li>
	<li>2.2.1.3 Hexadecimal to Decimal</li>
</ul>
	<li>2.2.2 Converting from Decimal</li>
<ul>	<li>2.2.2.1 Decimal to Binary</li>
	<li>2.2.2.2 Decimal to Octal</li>
	<li>2.2.2.3 Decimal to Hexadecimal</li>
</ul>
	<li>2.2.3 Converting Between 2n Bases</li>
<ul>	<li>2.2.3.1 Binary to Octal</li>
	<li>2.2.3.2 Binary to Hexadecimal</li>
	<li>2.2.3.3 Octal to Binary</li>
	<li>2.2.3.4 Hexadecimal to Binary</li>
	<li>2.2.3.5 Octal to Hexadecimal</li>
	<li>2.2.3.6 Hexadecimal to Octal</li>
</ul>
</ul>
	<li>2.3 Binary Arithmetic</li>
<ul>	<li>2.3.1 Addition (Carries)</li>
	<li>2.3.2 Subtraction (Borrows)</li>
</ul>
	<li>2.4 Unsigned and Signed Numbers</li>
<ul>	<li>2.4.1 Unsigned Numbers</li>
	<li>2.4.2 Signed Numbers</li>
<ul>	<li>2.4.2.1 Signed Magnitude</li>
	<li>2.4.2.2 One&acute;s Complement</li>
	<li>2.4.2.3 Two&acute;s Complement</li>
	<li>2.4.2.4 Arithmetic with Two&acute;s Complement</li>
</ul>
</ul>
</ul>
	<li>3: Digital Circuitry and Interfacing</li>
<ul>	<li>3.1 Basic Gates</li>
<ul>	<li>3.1.1 Describing the Operation of a Logic Circuit</li>
<ul>	<li>3.1.1.1 The Logic Symbol</li>
	<li>3.1.1.2 The Truth Table</li>
	<li>3.1.1.3 The Logic Function</li>
	<li>3.1.1.4 The Logic Waveform</li>
</ul>
	<li>3.1.2 The Buffer</li>
	<li>3.1.3 The Inverter</li>
	<li>3.1.4 The AND Gate</li>
	<li>3.1.5 The NAND Gate</li>
	<li>3.1.6 The OR Gate</li>
	<li>3.1.7 The NOR Gate</li>
	<li>3.1.8 The XOR Gate</li>
	<li>3.1.9 The XNOR Gate</li>
</ul>
	<li>3.2 Digital Circuit Operation</li>
<ul>	<li>3.2.1 Logic Levels</li>
	<li>3.2.2 Output DC Specifications</li>
	<li>3.2.3 Input DC Specifications</li>
	<li>3.2.4 Noise Margins</li>
	<li>3.2.5 Power Supplies</li>
	<li>3.2.6 Switching Characteristics</li>
	<li>3.2.7 Data Sheets</li>
</ul>
	<li>3.3 Logic Families</li>
<ul>	<li>3.3.1 Complementary Metal Oxide Semiconductors</li>
<ul>	<li>3.3.1.1 CMOS Operation</li>
	<li>3.3.1.2 CMOS Inverter</li>
	<li>3.3.1.3 CMOS NAND Gate</li>
	<li>3.3.1.4 CMOS NOR Gate</li>
</ul>
	<li>3.3.2 Transistor-Transistor Logic</li>
<ul>	<li>3.3.2.1 TTL Operation</li>
</ul>
	<li>3.3.3 The 7400 Series Logic Families</li>
<ul>	<li>3.3.3.1 Part-Numbering Scheme</li>
	<li>3.3.3.2 DC Operating Conditions</li>
	<li>3.3.3.3 Pin-Out Information for the DIP Packages</li>
</ul>
</ul>
	<li>3.4 Driving Loads</li>
<ul>	<li>3.4.1 Driving Other Gates</li>
	<li>3.4.2 Driving Resistive Loads</li>
	<li>3.4.3 Driving LEDs</li>
</ul>
</ul>
	<li>4: Combinational Logic Design</li>
<ul>	<li>4.1 Boolean Algebra</li>
<ul>	<li>4.1.1 Operations</li>
	<li>4.1.2 Axioms</li>
<ul>	<li>4.1.2.1 Axiom #1: Logical Values</li>
	<li>4.1.2.2 Axiom #2: Definition of Logical Negation</li>
	<li>4.1.2.3 Axiom #3: Definition of a Logical Product</li>
	<li>4.1.2.4 Axiom #4: Definition of a Logical Sum</li>
	<li>4.1.2.5 Axiom #5: Logical Precedence</li>
</ul>
	<li>4.1.3 Theorems</li>
<ul>	<li>4.1.3.1 DeMorgan&acute;s Theorem of Duality</li>
	<li>4.1.3.2 Identity</li>
	<li>4.1.3.3 Null Element</li>
	<li>4.1.3.4 Idempotent</li>
	<li>4.1.3.5 Complements</li>
	<li>4.1.3.6 Involution</li>
	<li>4.1.3.7 Commutative Property</li>
	<li>4.1.3.8 Associative Property</li>
	<li>4.1.3.9 Distributive Property</li>
	<li>4.1.3.10 Absorption</li>
	<li>4.1.3.11 Uniting</li>
	<li>4.1.3.12 DeMorgan&acute;s Theorem</li>
</ul>
	<li>4.1.4 Functionally Complete Operation Sets</li>
</ul>
	<li>4.2 Combinational Logic Analysis</li>
<ul>	<li>4.2.1 Finding the Logic Expression from a Logic Diagram</li>
	<li>4.2.2 Finding the Truth Table from a Logic Diagram</li>
	<li>4.2.3 Timing Analysis of a Combinational Logic Circuit</li>
</ul>
	<li>4.3 Combinational Logic Synthesis</li>
<ul>	<li>4.3.1 Canonical Sum of Products</li>
	<li>4.3.2 The Minterm List (Sigma)</li>
	<li>4.3.3 Canonical Product of Sums (POS)</li>
	<li>4.3.4 The Maxterm List (Pi)</li>
	<li>4.3.5 Minterm and Maxterm List Equivalence</li>
</ul>
	<li>4.4 Logic Minimization</li>
<ul>	<li>4.4.1 Algebraic Minimization</li>
	<li>4.4.2 Minimization Using Karnaugh Maps</li>
<ul>	<li>4.4.2.1 Formation of a K-map</li>
	<li>4.4.2.2 Logic Minimization Using K-maps (Sum of Products)</li>
	<li>4.4.2.3 Logic Minimization Using K-maps (Product of Sums)</li>
	<li>4.4.2.4 Minimal Sum</li>
</ul>
	<li>4.4.3 Don&acute;t Cares</li>
	<li>4.4.4 Using XOR Gates</li>
</ul>
	<li>4.5 Timing Hazards and Glitches</li>
</ul>
	<li>5: VHDL (Part 1)</li>
<ul>	<li>5.1 History of Hardware Description Languages</li>
	<li>5.2 HDL Abstraction</li>
	<li>5.3 The Modern Digital Design Flow</li>
	<li>5.4 VHDL Constructs</li>
<ul>	<li>5.4.1 Data Types</li>
<ul>	<li>5.4.1.1 Enumerated Types</li>
	<li>5.4.1.2 Range Types</li>
	<li>5.4.1.3 Physical Types</li>
	<li>5.4.1.4 Vector Types</li>
	<li>5.4.1.5 User-Defined Enumerated Types</li>
	<li>5.4.1.6 Array Type</li>
	<li>5.4.1.7 Subtypes</li>
</ul>
	<li>5.4.2 Libraries and Packages</li>
	<li>5.4.3 The Entity</li>
	<li>5.4.4 The Architecture</li>
<ul>	<li>5.4.4.1 Signal Declarations</li>
	<li>5.4.4.2 Constant Declarations</li>
	<li>5.4.4.3 Component Declarations</li>
</ul>
</ul>
	<li>5.5 Modeling Concurrent Functionality in VHDL</li>
<ul>	<li>5.5.1 VHDL Operators</li>
<ul>	<li>5.5.1.1 Assignment Operator</li>
	<li>5.5.1.2 Logical Operators</li>
	<li>5.5.1.3 Numerical Operators</li>
	<li>5.5.1.4 Relational Operators</li>
	<li>5.5.1.5 Shift Operators</li>
	<li>5.5.1.6 Concatenation Operator</li>
</ul>
	<li>5.5.2 Concurrent Signal Assignments</li>
	<li>5.5.3 Concurrent Signal Assignments with Logical Operators</li>
	<li>5.5.4 Conditional Signal Assignments</li>
	<li>5.5.5 Selected Signal Assignments</li>
	<li>5.5.6 Delayed Signal Assignments</li>
</ul>
	<li>5.6 Structural Design Using Components</li>
<ul>	<li>5.6.1 Component Instantiation</li>
<ul>	<li>5.6.1.1 Explicit Port Mapping</li>
	<li>5.6.1.2 Positional Port Mapping</li>
</ul>
</ul>
	<li>5.7 Overview of Simulation Test Benches</li>
</ul>
	<li>6: MSI Logic</li>
<ul>	<li>6.1 Decoders</li>
<ul>	<li>6.1.1 Example: One-Hot Decoder</li>
	<li>6.1.2 Example: Seven-Segment Display Decoder</li>
</ul>
	<li>6.2 Encoders</li>
<ul>	<li>6.2.1 Example: One-Hot Binary Encoder</li>
</ul>
	<li>6.3 Multiplexers</li>
	<li>6.4 Demultiplexers</li>
</ul>
	<li>7: Sequential Logic Design</li>
<ul>	<li>7.1 Sequential Logic Storage Devices</li>
<ul>	<li>7.1.1 The Cross-Coupled Inverter Pair</li>
	<li>7.1.2 Metastability</li>
	<li>7.1.3 The SR Latch</li>
	<li>7.1.4 The SR Latch</li>
	<li>7.1.5 SR Latch with Enable</li>
	<li>7.1.6 The D-Latch</li>
	<li>7.1.7 The D-Flip-Flop</li>
</ul>
	<li>7.2 Sequential Logic Timing Considerations</li>
	<li>7.3 Common Circuits Based on Sequential Storage Devices</li>
<ul>	<li>7.3.1 Toggle Flop Clock Divider</li>
	<li>7.3.2 Ripple Counter</li>
	<li>7.3.3 Switch Debouncing</li>
	<li>7.3.4 Shift Registers</li>
</ul>
	<li>7.4 Finite-State Machines</li>
<ul>	<li>7.4.1 Describing the Functionality of an FSM</li>
<ul>	<li>7.4.1.1 State Diagrams</li>
	<li>7.4.1.2 State Transition Tables</li>
</ul>
	<li>7.4.2 Logic Synthesis for an FSM</li>
<ul>	<li>7.4.2.1 State Memory</li>
	<li>7.4.2.2 Next State Logic</li>
	<li>7.4.2.3 Output Logic</li>
	<li>7.4.2.4 The Final Logic Diagram</li>
</ul>
	<li>7.4.3 FSM Design Process Overview</li>
	<li>7.4.4 FSM Design Examples</li>
<ul>	<li>7.4.4.1 Serial Bit Sequence Detector</li>
	<li>7.4.4.2 Vending Machine Controller</li>
</ul>
</ul>
	<li>7.5 Counters</li>
<ul>	<li>7.5.1 2-Bit Binary Up Counter</li>
	<li>7.5.2 2-Bit Binary Up/Down Counter</li>
	<li>7.5.3 2-Bit Gray Code Up Counter</li>
	<li>7.5.4 2-Bit Gray Code Up/Down Counter</li>
	<li>7.5.5 3-Bit One-Hot Up Counter</li>
	<li>7.5.6 3-Bit One-Hot Up/Down Counter</li>
</ul>
	<li>7.6 Finite-State Machine&acute;s Reset Condition</li>
	<li>7.7 Sequential Logic Analysis</li>
<ul>	<li>7.7.1 Finding the State Equations and Output Logic Expressions of an FSM</li>
	<li>7.7.2 Finding the State Transition Table of an FSM</li>
	<li>7.7.3 Finding the State Diagram of an FSM</li>
	<li>7.7.4 Determining the Maximum Clock Frequency of an FSM</li>
</ul>
</ul>
	<li>8: VHDL (Part 2)</li>
<ul>	<li>8.1 The Process</li>
<ul>	<li>8.1.1 Sensitivity List</li>
	<li>8.1.2 The Wait Statement</li>
	<li>8.1.3 Sequential Signal Assignments</li>
	<li>8.1.4 Variables</li>
</ul>
	<li>8.2 Conditional Programming Constructs</li>
<ul>	<li>8.2.1 If/Then Statements</li>
	<li>8.2.2 Case Statements</li>
	<li>8.2.3 Infinite Loops</li>
	<li>8.2.4 While Loops</li>
	<li>8.2.5 For Loops</li>
</ul>
	<li>8.3 Signal Attributes</li>
	<li>8.4 Test Benches</li>
<ul>	<li>8.4.1 Report Statement</li>
	<li>8.4.2 Assert Statement</li>
</ul>
	<li>8.5 Packages</li>
<ul>	<li>8.5.1 STD_LOGIC_1164</li>
<ul>	<li>8.5.1.1 STD_LOGIC Resolution Function</li>
	<li>8.5.1.2 STD_LOGIC_1164 Logical Operators</li>
	<li>8.5.1.3 STD_LOGIC_1164 Edge Detection Functions</li>
	<li>8.5.1.4 STD_LOGIC-Type Conversion Functions</li>
</ul>
	<li>8.5.2 NUMERIC_STD</li>
<ul>	<li>8.5.2.1 NUMERIC_STD Arithmetic Functions</li>
	<li>8.5.2.2 NUMERIC_STD Logical Functions</li>
	<li>8.5.2.3 NUMERIC_STD Comparison Functions</li>
	<li>8.5.2.4 NUMERIC_STD Edge Detection Functions</li>
	<li>8.5.2.5 NUMERIC_STD Conversion Functions</li>
	<li>8.5.2.6 NUMERIC_STD Type Casting</li>
</ul>
	<li>8.5.3 NUMERIC_STD_UNSIGNED</li>
<ul>	<li>8.5.3.1 NUMERIC_STD_UNSIGNED Conversion Functions</li>
</ul>
	<li>8.5.4 NUMERIC_BIT</li>
	<li>8.5.5 NUMERIC_BIT_UNSIGNED</li>
<ul>	<li>8.5.5.1 NUMERIC_BIT_UNSIGNED Conversion Functions</li>
</ul>
	<li>8.5.6 MATH_REAL</li>
	<li>8.5.7 MATH_COMPLEX</li>
	<li>8.5.8 TEXTIO and STD_LOGIC_TEXTIO</li>
<ul>	<li>8.5.8.1 Example: Writing to an External File from a Test Bench</li>
	<li>8.5.8.2 Example: Writing to STD_OUTPUT from a Test Bench</li>
	<li>8.5.8.3 Example: Reading from an External File in a Test Bench</li>
	<li>8.5.8.4 Example: Reading Space-Delimited Data from an External File in a Test Bench</li>
</ul>
	<li>8.5.9 Legacy Packages (STD_LOGIC_ARITH/UNSIGNED/SIGNED)</li>
</ul>
</ul>
	<li>9: Behavioral Modeling of Sequential Logic</li>
<ul>	<li>9.1 Modeling Sequential Storage Devices in VHDL</li>
<ul>	<li>9.1.1 D-Latch</li>
	<li>9.1.2 D-Flip-Flop</li>
	<li>9.1.3 D-Flip-Flop with Asynchronous Reset</li>
	<li>9.1.4 D-Flip-Flop with Asynchronous Reset and Preset</li>
	<li>9.1.5 D-Flip-Flop with Synchronous Enable</li>
</ul>
	<li>9.2 Modeling Finite-State Machines in VHDL</li>
<ul>	<li>9.2.1 Modeling the States with User-Defined, Enumerated Data Types</li>
	<li>9.2.2 The State Memory Process</li>
	<li>9.2.3 The Next State Logic Process</li>
	<li>9.2.4 The Output Logic Process</li>
	<li>9.2.5 Explicitly Defining State Codes with Subtypes</li>
</ul>
	<li>9.3 FSM Design Examples in VHDL</li>
<ul>	<li>9.3.1 Serial Bit Sequence Detector in VHDL</li>
	<li>9.3.2 Vending Machine Controller in VHDL</li>
	<li>9.3.3 2-Bit, Binary Up/Down Counter in VHDL</li>
</ul>
	<li>9.4 Modeling Counters in VHDL</li>
<ul>	<li>9.4.1 Counters in VHDL Using the Type UNSIGNED</li>
	<li>9.4.2 Counters in VHDL Using the Type INTEGER</li>
	<li>9.4.3 Counters in VHDL Using the Type STD_LOGIC_VECTOR</li>
	<li>9.4.4 Counters with Enables in VHDL</li>
	<li>9.4.5 Counters with Loads</li>
</ul>
	<li>9.5 RTL Modeling</li>
<ul>	<li>9.5.1 Modeling Registers in VHDL</li>
	<li>9.5.2 Shift Registers in VHDL</li>
	<li>9.5.3 Registers as Agents on a Data Bus</li>
</ul>
</ul>
	<li>10: Memory</li>
<ul>	<li>10.1 Memory Architecture and Terminology</li>
<ul>	<li>10.1.1 Memory Map Model</li>
	<li>10.1.2 Volatile vs. Nonvolatile Memory</li>
	<li>10.1.3 Read-Only vs. Read/Write Memory</li>
	<li>10.1.4 Random Access vs. Sequential Access</li>
</ul>
	<li>10.2 Nonvolatile Memory Technology</li>
<ul>	<li>10.2.1 ROM Architecture</li>
	<li>10.2.2 Mask Read-Only Memory</li>
	<li>10.2.3 Programmable Read-Only Memory</li>
	<li>10.2.4 Erasable Programmable Read-Only Memory</li>
	<li>10.2.5 Electrically Erasable Programmable Read-Only Memory</li>
	<li>10.2.6 FLASH Memory</li>
</ul>
	<li>10.3 Volatile Memory Technology</li>
<ul>	<li>10.3.1 Static Random Access Memory</li>
	<li>10.3.2 Dynamic Random Access Memory</li>
</ul>
	<li>10.4 Modeling Memory with VHDL</li>
<ul>	<li>10.4.1 Read-Only Memory in VHDL</li>
	<li>10.4.2 Read/Write Memory in VHDL</li>
</ul>
</ul>
	<li>11: Programmable Logic</li>
<ul>	<li>11.1 Programmable Arrays</li>
<ul>	<li>11.1.1 Programmable Logic Array</li>
	<li>11.1.2 Programmable Array Logic</li>
	<li>11.1.3 Generic Array Logic</li>
	<li>11.1.4 Hard Array Logic</li>
	<li>11.1.5 Complex Programmable Logic Devices</li>
</ul>
	<li>11.2 Field Programmable Gate Arrays</li>
<ul>	<li>11.2.1 Configurable Logic Block (or Logic Element)</li>
	<li>11.2.2 Look-Up Tables</li>
	<li>11.2.3 Programmable Interconnect Points (PIPs)</li>
	<li>11.2.4 Input/Output Block</li>
	<li>11.2.5 Configuration Memory</li>
</ul>
</ul>
	<li>12: Arithmetic Circuits</li>
<ul>	<li>12.1 Addition</li>
<ul>	<li>12.1.1 Half Adders</li>
	<li>12.1.2 Full Adders</li>
	<li>12.1.3 Ripple Carry Adder (RCA)</li>
	<li>12.1.4 Carry Look Ahead Adder (CLA)</li>
	<li>12.1.5 Adders in VHDL</li>
<ul>	<li>12.1.5.1 Structural Model of a Ripple Carry Adder in VHDL</li>
	<li>12.1.5.2 Structural Model of a Carry Look Ahead Adder in VHDL</li>
	<li>12.1.5.3 Behavior Model of an Adder Using UNSIGNED Data Types</li>
</ul>
</ul>
	<li>12.2 Subtraction</li>
	<li>12.3 Multiplication</li>
<ul>	<li>12.3.1 Unsigned Multiplication</li>
	<li>12.3.2 A Simple Circuit to Multiply by Powers of Two</li>
	<li>12.3.3 Signed Multiplication</li>
</ul>
	<li>12.4 Division</li>
<ul>	<li>12.4.1 Unsigned Division</li>
	<li>12.4.2 A Simple Circuit to Divide by Powers of Two</li>
	<li>12.4.3 Signed Division</li>
</ul>
</ul>
	<li>13: Computer System Design</li>
<ul>	<li>13.1 Computer Hardware</li>
<ul>	<li>13.1.1 Program Memory</li>
	<li>13.1.2 Data Memory</li>
	<li>13.1.3 Input/Output Ports</li>
	<li>13.1.4 Central Processing Unit</li>
<ul>	<li>13.1.4.1 Control Unit</li>
	<li>13.1.4.2 Data Path: Registers</li>
	<li>13.1.4.3 Data Path: Arithmetic Logic Unit</li>
</ul>
	<li>13.1.5 A Memory Mapped System</li>
</ul>
	<li>13.2 Computer Software</li>
<ul>	<li>13.2.1 Opcodes and Operands</li>
	<li>13.2.2 Addressing Modes</li>
<ul>	<li>13.2.2.1 Immediate Addressing (IMM)</li>
	<li>13.2.2.2 Direct Addressing (DIR)</li>
	<li>13.2.2.3 Inherent Addressing (INH)</li>
	<li>13.2.2.4 Indexed Addressing (IND)</li>
</ul>
	<li>13.2.3 Classes of Instructions</li>
<ul>	<li>13.2.3.1 Loads and Stores</li>
	<li>13.2.3.2 Data Manipulations</li>
	<li>13.2.3.3 Branches</li>
</ul>
</ul>
	<li>13.3 Computer Implementation: An 8-Bit Computer Example</li>
<ul>	<li>13.3.1 Top-Level Block Diagram</li>
	<li>13.3.2 Instruction Set Design</li>
	<li>13.3.3 Memory System Implementation</li>
<ul>	<li>13.3.3.1 Program Memory Implementation in VHDL</li>
	<li>13.3.3.2 Data Memory Implementation in VHDL</li>
	<li>13.3.3.3 Implementation of Output Ports in VHDL</li>
	<li>13.3.3.4 Implementation of Input Ports in VHDL</li>
	<li>13.3.3.5 Memory data_out Bus Implementation in VHDL</li>
</ul>
	<li>13.3.4 CPU Implementation</li>
<ul>	<li>13.3.4.1 Data Path Implementation in VHDL</li>
	<li>13.3.4.2 ALU Implementation in VHDL</li>
	<li>13.3.4.3 Control Unit Implementation in VHDL</li>
<ul>	<li>Detailed Execution of LDA_IMM</li>
	<li>Detailed Execution of LDA_DIR</li>
	<li>Detailed Execution of STA_DIR</li>
	<li>Detailed Execution of ADD_AB</li>
	<li>Detailed Execution of BRA</li>
	<li>Detailed Execution of BEQ</li>
</ul>
</ul>
</ul>
	<li>13.4 Architecture Considerations</li>
<ul>	<li>13.4.1 Von Neumann Architecture</li>
	<li>13.4.2 Harvard Architecture</li>
</ul>
</ul>
	<li>Appendix A: List of Worked Examples</li>
	<li>Suggested Readings</li>
	<li>Index</li>
</ul>
</body></html>