<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Untitled</title>
</head>
<body><div class="page"><p/>
<p>Simon&nbsp;Grondin
</p>
<p>Psychology 
of 
Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>  Psychology of Perception </p>
<p/>
</div>
<div class="page"><p/>
<p>     </p>
<p/>
</div>
<div class="page"><p/>
<p>       Simon     Grondin     
</p>
<p> Psychology of Perception                       </p>
<p/>
</div>
<div class="page"><p/>
<p>     ISBN 978-3-319-31789-2      ISBN 978-3-319-31791-5 (eBook) 
 DOI 10.1007/978-3-319-31791-5 
</p>
<p> Library of Congress Control Number: 2016938797 
</p>
<p> &copy; Springer International Publishing Switzerland   2016 
 This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of 
the material is concerned, specifi cally the rights of translation, reprinting, reuse of illustrations, recitation, 
broadcasting, reproduction on microfi lms or in any other physical way, and transmission or information 
storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology 
now known or hereafter developed. 
 The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication 
does not imply, even in the absence of a specifi c statement, that such names are exempt from the relevant 
protective laws and regulations and therefore free for general use. 
 The publisher, the authors and the editors are safe to assume that the advice and information in this book 
are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the 
editors give a warranty, express or implied, with respect to the material contained herein or for any errors 
or omissions that may have been made. 
</p>
<p> Printed on acid-free paper 
</p>
<p>   This Springer imprint is published by Springer Nature  
 The registered company is Springer International Publishing AG Switzerland 
</p>
<p>   Simon     Grondin    
 Universit&eacute; Laval 
  &Eacute;cole de Psychologie 
  Qu&eacute;bec ,    Canada     </p>
<p/>
</div>
<div class="page"><p/>
<p>v
</p>
<p>  Pref ace   
</p>
<p> This book is a translation of &ldquo;Psychologie de la perception&rdquo; published by the  Presses 
de l&rsquo;Universit&eacute; Laval  and has the same name as a course offered at the School of 
Psychology of Laval University, Qu&eacute;bec. It is not a coincidence; the book was writ-
ten for students of this course. Over the years, whether at Laurentian University a 
few decades ago or at Laval University since 1996, I learned a lot from the questions 
and needs for clarifi cation voiced by the students. The book is partly a response to 
the requested explanations regarding some of the main phenomena, techniques, and 
principles encountered in the fi eld of perception. 
</p>
<p> I would like to thank Anne-Marie Grondin who produced numerous illustrations 
contained in this book; Tsuyoshi Kuroda, expert in psychoacoustics, who provided 
many tips and some fi gures in the preparation of Chaps. 2 and 3; and Daniel Voyer 
of the University of New Brunswick for his fi ne revision of the content.  
</p>
<p>  Qu&eacute;bec, QC, Canada     Simon     Grondin     </p>
<p/>
</div>
<div class="page"><p/>
<p>     </p>
<p/>
</div>
<div class="page"><p/>
<p>vii
</p>
<p>  Contents 
</p>
<p>    1     Psychophysics ............................................................................................  1   
    1.1  Detection ............................................................................................  1   
</p>
<p>    1.1.1  Absolute Threshold and Method of Constant Stimuli ...........  2   
    1.1.2  Signal Detection Theory ........................................................  3   
</p>
<p>    1.2  Discrimination ....................................................................................  6   
    1.2.1  Difference Threshold and Method of Constant Stimuli .........  6   
    1.2.2  Weber&rsquo;s Law of Discrimination and Its Generalized 
</p>
<p>Form .......................................................................................  8   
    1.3  Other Methods for Estimating Thresholds .........................................  9   
</p>
<p>    1.3.1  The Method of Adjustment ....................................................  9   
    1.3.2  The Method of Limits ............................................................  10   
    1.3.3  Adaptive Methods ..................................................................  12   
</p>
<p>    1.4  Scaling ................................................................................................  13   
    1.4.1  Methods ..................................................................................  14   
    1.4.2  Stevens&rsquo;s Law .........................................................................  14   
    1.4.3  Other Contributions from Stevens .........................................  15   
</p>
<p>     2     Physical and Biological Bases of Hearing ...............................................  17   
    2.1  Physical Characteristics of a Simple Sound Wave .............................  17   
</p>
<p>    2.1.1  Frequency and Phase ..............................................................  17   
    2.1.2  Amplitude ..............................................................................  19   
</p>
<p>    2.2  Physical Characteristics of a Complex Sound Wave .........................  20   
    2.3  Subjective Characteristics of Sounds .................................................  22   
</p>
<p>    2.3.1  Pitch, Loudness, and Timbre ..................................................  23   
    2.3.2  Other Subjective Characteristics ............................................  24   
</p>
<p>    2.4  Biological Bases .................................................................................  24   
    2.4.1  Outer, Middle, and Inner Ear .................................................  25   
    2.4.2  The Cochlea ...........................................................................  27   
    2.4.3  Central Mechanisms ...............................................................  28   </p>
<p/>
</div>
<div class="page"><p/>
<p>viii
</p>
<p>    2.5  Theories of Hearing ...........................................................................  28   
    2.5.1  Frequency Theory ..................................................................  29   
    2.5.2  Theories Based on Location ...................................................  30   
</p>
<p>    2.6  Clinical Aspects .................................................................................  32   
</p>
<p>     3     Hearing .......................................................................................................  35   
    3.1  Perceptual Organization .....................................................................  35   
</p>
<p>    3.1.1  Streaming ...............................................................................  36   
    3.1.2  Illusion of Continuity and Gap Transfer ................................  36   
</p>
<p>    3.2  Sound Location ..................................................................................  39   
    3.2.1  Location of Direction .............................................................  40   
    3.2.2  Location of Distance ..............................................................  41   
</p>
<p>    3.3  Hearing Music ....................................................................................  43   
    3.3.1  Technical Description ............................................................  43   
    3.3.2  Subjective Experience ............................................................  45   
</p>
<p>    3.4  Hearing Speech ..................................................................................  46   
    3.4.1  Linguistic Description ............................................................  46   
    3.4.2  Technical Analysis .................................................................  48   
    3.4.3  Theoretical Perspectives ........................................................  49   
    3.4.4  Intermodality ..........................................................................  51   
</p>
<p>     4     Biological Bases of Visual Perception ......................................................  53   
    4.1  The Eye ..............................................................................................  53   
</p>
<p>    4.1.1  The Eyeball ............................................................................  53   
    4.1.2  The Retina ..............................................................................  55   
</p>
<p>    4.2  Receptive Fields .................................................................................  57   
    4.3  Central Mechanisms ...........................................................................  59   
</p>
<p>    4.3.1  The Visual Cortex ..................................................................  60   
    4.3.2  Visual Pathways .....................................................................  61   
</p>
<p>    4.4  Clinical Aspects .................................................................................  63   
</p>
<p>     5     Color Perception .......................................................................................  67   
    5.1  Description of Light ...........................................................................  67   
</p>
<p>    5.1.1  Intensity ..................................................................................  68   
    5.1.2  Wavelength and Spectral Composition ..................................  68   
</p>
<p>    5.2  Perceptual Dimensions of Color ........................................................  70   
    5.3  Color Mixtures ...................................................................................  70   
</p>
<p>    5.3.1  Primary Colors .......................................................................  71   
    5.3.2  Addition and Subtraction .......................................................  72   
</p>
<p>    5.4  Theories of Color Vision ....................................................................  74   
    5.5  Chromatic Effects ..............................................................................  76   
    5.6  Clinical Aspects .................................................................................  80   
</p>
<p>     6     Form Perception ........................................................................................  83   
    6.1  Perception of Contours ......................................................................  83   
</p>
<p>    6.1.1  Edges and Subjective Contours ..............................................  84   
    6.1.2  Lateral Inhibition ...................................................................  85   
</p>
<p>Contents</p>
<p/>
</div>
<div class="page"><p/>
<p>ix
</p>
<p>    6.1.3  Mach Bands ...........................................................................  86   
    6.1.4  Factors Infl uencing the Perception of Contours .....................  87   
</p>
<p>    6.2  Gestalt: Perceptual Organization .......................................................  89   
    6.2.1  Figure/Ground Distinction .....................................................  90   
    6.2.2  Perceptual Grouping ..............................................................  92   
</p>
<p>    6.3  Theory of Multiple Spatial Channels .................................................  93   
    6.3.1  Basic Concepts .......................................................................  93   
    6.3.2  Contrast Sensitivity Function .................................................  97   
</p>
<p>    6.4  Form Recognition ..............................................................................  98   
    6.4.1  Templates or Characteristics? ................................................  98   
    6.4.2  A Computational Approach ...................................................  99   
    6.4.3  A Structural Model ................................................................  100   
    6.4.4  Agnosia ..................................................................................  101   
</p>
<p>     7     Depth Perception .......................................................................................  103   
    7.1  Cues for Perceiving a Third Dimension .............................................  103   
</p>
<p>    7.1.1  Binocular Cues .......................................................................  104   
    7.1.2  Monocular Cues .....................................................................  106   
</p>
<p>    7.2  Perceptual Constancy .........................................................................  111   
    7.2.1  Types of Constancy ................................................................  111   
    7.2.2  Interpretations and Investigations ..........................................  112   
    7.2.3  Gibson&rsquo;s Perspective ..............................................................  114   
</p>
<p>    7.3  Illusions ..............................................................................................  115   
    7.3.1  Variety of Illusions .................................................................  115   
    7.3.2  The Moon Illusion ..................................................................  118   
</p>
<p>     8     Perception and Attention ..........................................................................  123   
    8.1  What Is Attention? .............................................................................  124   
</p>
<p>    8.1.1  Blindnesses ............................................................................  124   
    8.2  Preparation and Orientation ...............................................................  125   
</p>
<p>    8.2.1  Spatial Preparation .................................................................  125   
    8.2.2  Temporal Preparation .............................................................  127   
</p>
<p>    8.3  Selectivity...........................................................................................  128   
    8.3.1  Visual Selectivity ...................................................................  128   
    8.3.2  Auditory Selectivity ...............................................................  130   
</p>
<p>    8.4  Visual Search .....................................................................................  133   
    8.5  Clinical Aspects .................................................................................  135   
</p>
<p>    Appendix A: ROC Curves ..............................................................................  137   
</p>
<p>  Appendix B: Fechner&rsquo;s Law ...........................................................................  139   
</p>
<p>  Appendix C: The Nervous System .................................................................  141   
</p>
<p>  References ........................................................................................................  147    
</p>
<p>   Index .................................................................................................................  153    
</p>
<p>Contents</p>
<p/>
</div>
<div class="page"><p/>
<p>     </p>
<p/>
</div>
<div class="page"><p/>
<p>xi
</p>
<p>  About the Author 
</p>
<p>     Simon     Grondin       is a Professor at the School of Psychology of Laval University, 
Qu&eacute;bec. His research interests are mainly on timing and time perception, rhythm, 
psychological time, psychophysics, cognitive neurosciences, and the relative age 
effect in sports. He is a former editor of the  Canadian Journal of Experimental 
Psychology  (2006&ndash;2009) and a former associate editor of  Attention, Perception and 
Psychophysics  (2006&ndash;2015).     </p>
<p/>
</div>
<div class="page"><p/>
<p>1&copy; Springer International Publishing Switzerland 2016 
</p>
<p>S. Grondin, Psychology of Perception, DOI 10.1007/978-3-319-31791-5_1
</p>
<p>Chapter 1
</p>
<p>Psychophysics
</p>
<p>A field of psychology, psychophysics has as main concern the understanding of the 
</p>
<p>passage of a physical event into a psychological reality. Researchers in psychophys-
</p>
<p>ics examine the link between the physical measurement of a stimulation and the 
</p>
<p>psychological measurement of this stimulation. Psychophysicists are primarily 
</p>
<p>interested in three types of capabilities: detecting stimuli, discriminating them, and 
</p>
<p>estimating their value (scaling). The first two types are associated with the funda-
</p>
<p>mental concepts of absolute threshold and differential threshold, respectively.
</p>
<p>1.1  Detection
</p>
<p>The different sensory systems provide information on the physical and chemical 
</p>
<p>changes that may occur in the environment. A fundamental objective of psycho-
</p>
<p>physics is to assess the minimum amplitude that these changes must have  so that an 
</p>
<p>individual can be notified. This minimum amplitude, that is to say the smallest 
</p>
<p>amount of energy that can be detected in the absence of any stimulation, is called 
</p>
<p>absolute threshold. Below this threshold, sensation is not possible. However, this 
</p>
<p>threshold is a point whose identification corresponds to an operational definition for 
</p>
<p>a given method. Traditional psychophysics offers several methods for estimating a 
</p>
<p>threshold. The most conventional are the method of constant stimuli, the method of 
</p>
<p>limits, and the method of adjustment. For now, only the constant method is 
</p>
<p>presented:
</p>
<p>Gustav Fechner
</p>
<p>One could say that psychophysics started in 1860 with the publication of the book Elements 
</p>
<p>of psychophysics by the German researcher Gustav Theodor Fechner (1801&ndash;1887). 
</p>
<p>Philosopher and physicist, the founder of psychophysics wanted to study the links between 
</p>
<p>the inner world and the outer world. Also known under the pseudonym of &ldquo;Dr. Mise&rdquo;, 
</p>
<p>Fechner, who worked in Leipzig, had quite a special mind. We owe him various experimen-
</p>
<p>tal methods still used in psychophysics, but he was also interested in, for example, the 
</p>
<p>properties of the electric current, experimental aesthetics, and even life after death. Note </p>
<p/>
</div>
<div class="page"><p/>
<p>2
</p>
<p>that there is an annual meeting of psychophysics, usually held in October, called Fechner 
</p>
<p>Day (October 22). This meeting is held in different locations around the world under the 
</p>
<p>supervision of the International Society for Psychophysics (http://www.ispsychophysics.
</p>
<p>org/), founded in 1985 in southern France.
</p>
<p>1.1.1  Absolute Threshold and Method of Constant Stimuli
</p>
<p>For measuring an absolute threshold with the method of constant stimuli, also called 
</p>
<p>the constant method, one must first determine the threshold roughly by locating a 
</p>
<p>region for which a stimulus is almost never perceived and for which a stimulus is 
</p>
<p>almost always perceived. Then, we generally select from five to nine stimuli located 
</p>
<p>between these regions. After this selection, the selected stimuli are presented repeat-
</p>
<p>edly in random order. The method requires an observer to make at least a hundred 
</p>
<p>judgments, but of course, increasing the number of trials for estimating a threshold 
</p>
<p>decreases the risk that the estimated value is far from what the real threshold is.
</p>
<p>At each presentation, an observer has to indicate whether or not the stimulus is 
</p>
<p>perceived. It becomes then possible to obtain a discrete (not continuous) frequency 
</p>
<p>distribution, each point representing the number of times a stimulus was detected. 
</p>
<p>These frequencies have to be transformed into probabilities. It is on the basis of these 
</p>
<p>probabilities that the threshold value will be estimated. The probability calculated for 
</p>
<p>each stimulus can be reported on a figure. As shown in Fig. 1.1, the percentage of 
</p>
<p>Fig. 1.1 Illustration of a hypothetical psychometric function for absolute threshold. On the y-axis 
</p>
<p>is the percentage of times where the observer reports perceiving the stimulus. The dotted vertical 
</p>
<p>line reaching the x-axis indicates the absolute threshold
</p>
<p>1 Psychophysics</p>
<p/>
<div class="annotation"><a href="http://www.ispsychophysics.org/">http://www.ispsychophysics.org/</a></div>
<div class="annotation"><a href="http://www.ispsychophysics.org/">http://www.ispsychophysics.org/</a></div>
</div>
<div class="page"><p/>
<p>3
</p>
<p>times the stimulus is detected is placed on the y-axis and is plotted as a function of the 
</p>
<p>magnitude of the stimuli, placed on the x-axis, in ascending order. The function that 
</p>
<p>relates the probability of detecting to the magnitude of a physical continuum is called 
</p>
<p>a psychometric function. Such a function generally has the shape of an ogive&mdash;a kind 
</p>
<p>of S&mdash;and the threshold is operationally defined as the point corresponding to an abil-
</p>
<p>ity to perceive the stimulus 50 % of the time. This value, 50 %, represents the point for 
</p>
<p>which an observer is able to detect the stimulus at a level higher than what would 
</p>
<p>provide responses made randomly in a procedure involving two responses, yes or not.
</p>
<p>For drawing a function on the basis of a series of points, it is necessary to posit 
</p>
<p>some assumptions. First, the phenomenon under investigation is assumed to be a 
</p>
<p>continuous random variable. Thus, we shall believe that the discrete distribution 
</p>
<p>obtained (series of points) is an approximation of a continuous function. Also, it is 
</p>
<p>necessary to make an assumption about the shape of this function. Mathematics 
</p>
<p>offers several possibilities, but a function often used in psychology is the normal 
</p>
<p>distribution. The reader is probably already familiar with the concept of normal dis-
</p>
<p>tribution (normal or Gaussian curve or bell-shaped curve). The function used to draw 
</p>
<p>a psychometric function is derived from the bell-shaped function (probability density 
</p>
<p>function) and is called cumulative normal function. It is after drawing this function 
</p>
<p>that it becomes possible to estimate the threshold value accurately. Besides the 
</p>
<p>cumulative Gaussian function, Weibull and logistics functions are probably the most 
</p>
<p>likely ones to be used (Macmillan &amp; Creelman, 1991).
</p>
<p>1.1.2  Signal Detection Theory
</p>
<p>Despite the rigor used to estimate the ability to detect a stimulus with the constant 
</p>
<p>stimuli method, a major problem may arise. The estimated capacity may depend not 
</p>
<p>only on the sensitivity of an observer but also on the way in which this observer 
</p>
<p>makes decisions. An observer might as well wait to be sure before making a deci-
</p>
<p>sion, before declaring that a stimulus is perceived, whereas another observer, in 
</p>
<p>spite of doubt, would tend to say &ldquo;yes, I perceive&rdquo; (Macmillan &amp; Creelman, 1991).
</p>
<p>There is a method, developed in the 1940s, to determine the sensitivity of the 
</p>
<p>observer to detect a stimulus while correcting the problem associated with the 
</p>
<p>involvement of decision making. Thus, the signal detection theory (SDT), also 
</p>
<p>known as sensory decision theory, uses two parameters to describe the performance: 
</p>
<p>one describing the sensitivity level and the other describing the way an observer 
</p>
<p>makes a decision (Macmillan &amp; Creelman, 1991).
</p>
<p>1.1.2.1  Basic Concepts
</p>
<p>To understand the SDT, we must first know two fundamental concepts: signal and 
</p>
<p>noise. Signal (S) and noise (N) are the parts of any sensory message. The stimulus 
</p>
<p>that one attempts to detect, called signal, has precise and stable characteristics. 
</p>
<p>1.1 Detection</p>
<p/>
</div>
<div class="page"><p/>
<p>4
</p>
<p>Noise is rather defined as a random variable that is constantly changing. This vari-
</p>
<p>able takes different values which are usually assumed to be normally distributed. 
</p>
<p>Noise is a background against which a signal to be detected is sometimes added. 
</p>
<p>This noise includes an external activity (controlled by the experimenter) and inter-
</p>
<p>nal physiological activity (generated by the nervous system).
</p>
<p>In a typical SDT task, an observer must make the following decision about what 
</p>
<p>was presented: was it noise only (N) or noise with the addition of a signal (S + N)? 
</p>
<p>For a given amount of noise, the more a signal generates internal activity (the stron-
</p>
<p>ger it is), the easier it is to detect it. These two concepts, N and S + N, are generally 
</p>
<p>represented with two normal frequency distributions (Fig. 1.2).
</p>
<p>An observer subjected to a signal detection task should adopt a decision crite-
</p>
<p>rion. This criterion is often measured with the index beta (&szlig;). The adoption of a 
</p>
<p>criterion generates four typical conditions (Table 1.1). From these four conditions, 
</p>
<p>two are linked to the presence of the signal and two to its absence. When the signal 
</p>
<p>is present and an observer reports to have perceived it, it is a case of correct identi-
</p>
<p>fication called a hit. When the observer does not detect the presence of a signal 
</p>
<p>when it is presented, we have a case called miss. If the signal is not presented but the 
</p>
<p>observer reports that it was, it is a false alarm. Finally, not perceiving a signal when 
</p>
<p>actually there was only noise is a condition called correct rejection. Table 1.1 sum-
</p>
<p>marizes these four typical situations.
</p>
<p>Some people prefer waiting to reach some level of certainty before reporting that 
</p>
<p>they have perceived the presence of a signal. These people are referred to as conser-
</p>
<p>vative observers, as opposed to lax observers. Two observers may eventually have 
</p>
<p>Fig. 1.2 Distributions of noise and signal + noise of the signal detection theory. The continuous 
</p>
<p>vertical line represents the criterion. The distance between dotted lines represents d&prime;, an index of 
</p>
<p>sensitivity
</p>
<p>Table 1.1 The four typical situations of the signal detection theory
</p>
<p>Signal
</p>
<p>Present Absent
</p>
<p>Response Present (yes) Hit False alarm
</p>
<p>Absent (no) Miss Correct rejection
</p>
<p>1 Psychophysics</p>
<p/>
</div>
<div class="page"><p/>
<p>5
</p>
<p>similar sensitivities, but adopt different decisional strategies. Compared with a lax 
</p>
<p>observer, the number of hits of a conservative observer might be lower, but the latter 
</p>
<p>would commit fewer false alarms. In short, for a given level of sensitivity, the num-
</p>
<p>ber of false alarms and the rate of hits may vary, and this is depending on the deci-
</p>
<p>sional style of the observer (see Appendix A).
</p>
<p>1.1.2.2  Units of Measurement
</p>
<p>There are various indices associated with SDT that allow to quantifying the sensitiv-
</p>
<p>ity of an observer and the criterion adopted. Among the performance indicators 
</p>
<p>used to measure the sensitivity, d&prime; (pronounced d prime) is probably the most com-
</p>
<p>mon. d&prime; can be defined as the difference between the means of N and S + N distribu-
</p>
<p>tions, divided by the standard deviation of the noise distribution; d&prime; is a pure index 
</p>
<p>of detectability in that it is not affected by the observer&rsquo;s criterion.
</p>
<p>One can easily calculate d&prime; on the basis of hits and false alarms obtained empiri-
</p>
<p>cally. We obtain an assessment of d&prime; with the transformation into Z-scores of the 
</p>
<p>probabilities of obtaining a hit and a false alarm:
</p>
<p> 
d Z Z&cent; = ( )- ( )Hit False Alarm
</p>
<p> 
</p>
<p>For instance, suppose an observer detects correctly the presence of a signal for 90 % 
</p>
<p>of the trials, but commits 25 % of false alarms. Given that the Z-score value for 90 % 
</p>
<p>is 1.28 and the Z-score value for 25 % is &minus;0.67, the sensitivity, d&prime; value, is 
</p>
<p>1.28 &minus; (&minus;0.67) = 1.95.
</p>
<p>It is important to emphasize that this transformation of percentages into Z-scores 
</p>
<p>is based on the assumption that the N and S + N distributions are normal. Note that 
</p>
<p>there are other performance indices, like Δm or de&prime;, for estimating sensitivity. 
</p>
<p>Another index, A&prime;, is particularly interesting because it allows to estimate sensitivity 
</p>
<p>without having to posit the hypothesis that the distributions are normal. We obtain 
</p>
<p>A&prime;, using the following equation:
</p>
<p> 
</p>
<p>A
p H p p H p
</p>
<p>p H p
&cent; = +
</p>
<p>( )&acute; +( )
</p>
<p>( )&acute; ( )
&frac12;
</p>
<p>( ) &ndash; ( ) ( ) &ndash; ( )
</p>
<p>( ) &ndash; ( )
</p>
<p>FA FA
</p>
<p>FA
</p>
<p>1
</p>
<p>4 1
 
</p>
<p>where p(H) is the probability of a hit and p(FA) the probability of a false alarm.
</p>
<p>Regarding the criterion, it may be estimated using &szlig;. This index is a ratio of the 
</p>
<p>ordinates for each distribution (N and S + N) corresponding to the location of the 
</p>
<p>criterion. Thus, the calculation of the &szlig; criterion is as follows:
</p>
<p> 
</p>
<p>Ordinate of the distribution
</p>
<p>Ordinate of the distribution
</p>
<p>S N
</p>
<p>N
</p>
<p>+
</p>
<p> 
</p>
<p>So, in the preceding example, the value of &szlig; is 0.552:
</p>
<p>1.1 Detection</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-31791-5_BM1">http://dx.doi.org/10.1007/978-3-319-31791-5_BM1</a></div>
</div>
<div class="page"><p/>
<p>6
</p>
<p>Ordinate of 90 % = 0.176 and ordinate of 25 % = 0.319.
</p>
<p>Therefore, &szlig; = 0.176/0.319 = 0.552.
</p>
<p>A high value of &szlig; means that the observer is very conservative when making 
</p>
<p>decisions, but conversely, a low &szlig; value (&lt;1), as is the case in this example, indicates 
</p>
<p>that the observer tends to be lax. Finally, note that there are also other indicators to 
</p>
<p>express the criterion, including c (Macmillan &amp; Creelman, 1991).
</p>
<p>1.2  Discrimination
</p>
<p>Another fundamental sensory ability is at play when someone tries to find out if two 
</p>
<p>stimuli are different from each other. The minimum intensity difference required for 
</p>
<p>differentiating two stimuli is called difference threshold. As was the case for the 
</p>
<p>absolute threshold, the difference threshold is defined arbitrarily; the threshold 
</p>
<p>value depends on the method used, i.e., on an operational definition. This threshold, 
</p>
<p>the point at which an observer is able to tell the difference between two stimuli, is 
</p>
<p>sometimes called the just noticeable difference (JND).
</p>
<p>1.2.1  Difference Threshold and Method of Constant Stimuli
</p>
<p>For estimating a differential threshold with the constant stimuli method, an observer 
</p>
<p>is presented with two stimuli and must determine which of the two stimuli is of 
</p>
<p>greater magnitude. The method includes the presentation on each test of a standard 
</p>
<p>stimulus and of a comparison stimulus. The comparison stimulus usually takes one 
</p>
<p>of seven to nine values distributed around the standard. The standard and one of the 
</p>
<p>comparison stimuli are presented several times, concurrently or sequentially, 
</p>
<p>depending on the nature of the sensory continuum investigated (Grondin, 2008).
</p>
<p>In the following example, the purpose is to determine the difference threshold for 
</p>
<p>a standard weight of 250 g with successive presentations of the standard and of a 
</p>
<p>comparison stimulus. The comparison stimulus may take one of the following val-
</p>
<p>ues: 230, 235, 240, 245, 250, 255, 260, 265, and 270 g. An observer has to indicate 
</p>
<p>on each trial whether the comparison stimulus is lighter or heavier than the standard. 
</p>
<p>After several judgments, it is possible to construct a psychometric function 
</p>
<p>(Fig. 1.3). On the x-axis of the function, the different values of the comparison 
</p>
<p>stimuli are placed in ascending order. On the y-axis, the probability to report that the 
</p>
<p>comparison stimulus is heavier than the standard is reported.
</p>
<p>This function enables the identification of two variables that may be important 
</p>
<p>when studying sensation: the point of subjective equality (PSE) and the difference 
</p>
<p>threshold. The PSE is the point on the x-axis corresponding to 0.50 on the y-axis: 
</p>
<p>the probability to respond that the standard is heavier than the comparison stimulus 
</p>
<p>is the same as the probability to respond that the comparison stimulus is heavier 
</p>
<p>1 Psychophysics</p>
<p/>
</div>
<div class="page"><p/>
<p>7
</p>
<p>than the standard. Furthermore, we call constant error the difference between the 
</p>
<p>PSE and the value of the standard.
</p>
<p>Two difference thresholds, one above and one below, can be extracted on this 
</p>
<p>function. For the first, we need to subtract the points on the x-axis which, on the 
</p>
<p>function, correspond to 0.75 and 0.50 on the y-axis. The rationale is the following 
</p>
<p>one: this value, 0.75, is the middle point between a perfect discrimination (100 %) 
</p>
<p>and total inability to discriminate (50 %). In the same way, there is a lower differ-
</p>
<p>ence threshold: points on the x-axis which, on the function, correspond to 0.50 and 
</p>
<p>0.25 on the y-axis. The 0.25 is in the middle of the inability to discriminate (50 %) 
</p>
<p>and a perfect discrimination (0 %). We can obtain a single threshold value by calcu-
</p>
<p>lating the mean of the two thresholds. It is also possible to calculate directly this 
</p>
<p>difference threshold by subtracting the points on the x-axis corresponding to 0.75 
</p>
<p>and 0.25 on the y-axis and then by dividing this value by two.
</p>
<p>Finally, it should be noted that classical errors can occur in the determination of 
</p>
<p>difference thresholds with the constant stimuli method. When the stimuli are pre-
</p>
<p>sented simultaneously, i.e., at the same time, there is a need to vary randomly the 
</p>
<p>side, to the left or to the right, where the standard is presented. This variation seeks 
</p>
<p>to prevent cases where there will be a strong preference for one side or the other. 
</p>
<p>This preference causes what is referred to as the spatial errors. When the stimuli to 
</p>
<p>Fig. 1.3 Illustration (hypothetical case) of a psychometric function for difference threshold for 
</p>
<p>weight (standard = 250 g). On the y-axis is the percentage of times where the observer indicates 
</p>
<p>that the comparison (Co) is heavier than the standard (St). The vertical and dotted line indicates 
</p>
<p>the point of subjective equality on the x-axis. The other two lines indicate the values that are used 
</p>
<p>for calculating the difference threshold (see text)
</p>
<p>1.2 Discrimination</p>
<p/>
</div>
<div class="page"><p/>
<p>8
</p>
<p>discriminate are compared sequentially, rather than simultaneously, there may occur 
</p>
<p>a type of bias called a temporal order error. In such a case, the observer will have a 
</p>
<p>more or less marked tendency to judge whether the first or the second stimulus has 
</p>
<p>a greater magnitude. There is often an underestimation of the value of the first stim-
</p>
<p>ulus, which could be interpreted as a decrease of the memory trace left by this 
</p>
<p>stimulus (Hellstr&ouml;m, 1985).
</p>
<p>1.2.2  Weber&rsquo;s Law of Discrimination and Its Generalized Form
</p>
<p>There is not only one difference threshold value for a particular sensory modality. 
</p>
<p>In fact, this value varies according to the magnitude of the stimuli used for a given 
</p>
<p>investigation (Grondin, 2001, 2010, 2012). According to Weber&rsquo;s law, sometimes 
</p>
<p>also called the Bouguer-Weber&rsquo;s law (Bonnet, 1986), the difference threshold 
</p>
<p>increases as a function of the intensity of the stimuli being studied. This law states 
</p>
<p>that the minimal magnitude difference, or difference threshold (Δϕ), necessary to 
</p>
<p>distinguish two stimuli, depends on their magnitude (ϕ). In other words, according 
</p>
<p>to this law, the relationship between Δϕ and ϕ is proportional:
</p>
<p> 
D Df f f f= =( )K Kor /
</p>
<p> 
</p>
<p>where K, the Weber fraction, is constant. This Weber&rsquo;s law is indeed a principle that 
</p>
<p>provides a tool for looking at the mechanisms involved in the discrimination of 
</p>
<p>sensory quantities in a given sensory modality.
</p>
<p>An example will allow grasping fully this relatively simple law. In the previous 
</p>
<p>section, a standard of 250 g was used. If it is known that the difference threshold for 
</p>
<p>a weight of 250 g is 25 g, it can be predicted, on the basis of Weber&rsquo;s law, that the 
</p>
<p>minimal difference to distinguish two weights is 50 g if the standard is 500 g. In 
</p>
<p>other words, the ratio between the difference threshold and the standard will remain 
</p>
<p>the same, 10 % (50/500 or 25/250) in this example.
</p>
<p>Although Weber&rsquo;s law may be right for a certain extent of a given sensory con-
</p>
<p>tinuum, it proves to be incorrect for some values of this continuum. This failure of 
</p>
<p>the strict form of Weber&rsquo;s law has led to a reformulation of the relationship between 
</p>
<p>the difference threshold and the magnitude of the stimulus.
</p>
<p>In fact, the Weber fraction is valid only for a limited range on a sensory contin-
</p>
<p>uum. For very low or very high values, the Weber fraction is higher. For low values, 
</p>
<p>the increase of the fraction can be easily described based on a transformation of 
</p>
<p>Weber&rsquo;s law. All of what is required is the addition of a constant, a, interpreted as 
</p>
<p>the result of sensory noise:
</p>
<p> 
Df f= +K a
</p>
<p> 
</p>
<p>Returning to the example above, we can easily understand that for low values, 
</p>
<p>a has a lot of weight in the equation, which is not the case for larger values.  
</p>
<p>1 Psychophysics</p>
<p/>
</div>
<div class="page"><p/>
<p>9
</p>
<p>If a takes a value of 10, the threshold calculated for a standard, ϕ, of 250 g, is 35 
</p>
<p>instead of 25, as it would have been the case without the additional noise (a). 
</p>
<p>Therefore, the Weber fraction goes from 10 to 14 %. However, for a standard, ϕ, 
</p>
<p>of 2500 g, the calculated threshold is 260 rather than 250. The Weber fraction 
</p>
<p>goes from 10 to 10.4 %.
</p>
<p>1.3  Other Methods for Estimating Thresholds
</p>
<p>There are many other methods for estimating the value of thresholds, absolute and 
</p>
<p>differential. We describe only two of these below, the method of adjustment and the 
</p>
<p>method of limits.
</p>
<p>1.3.1  The Method of Adjustment
</p>
<p>With the method of adjustment, the observer has an active participation. On each 
</p>
<p>trial, the observer proceeds to a change. In the case of the determination of the abso-
</p>
<p>lute threshold, the observer is presented with a stimulus whose intensity is far below 
</p>
<p>or above the threshold level. The task is to adjust the intensity of the stimulus, either 
</p>
<p>by increasing or decreasing it, so that it is just at the limit of what could be per-
</p>
<p>ceived. This method involves a series of ascending and descending trials. It is the 
</p>
<p>average of all observed transition points, between what is perceivable and what is 
</p>
<p>not, which is the estimated value of the absolute threshold. This method is also 
</p>
<p>called the &ldquo;method of mean errors.&rdquo;
</p>
<p>This method of adjustment is not really used to determine an absolute threshold; 
</p>
<p>it is rather useful for the determination of a difference threshold. In the latter case, 
</p>
<p>an observer must adjust a comparison stimulus such that it appears equal to a stan-
</p>
<p>dard stimulus. To use this method, it is imperative that the stimuli in the study may 
</p>
<p>vary continuously (for estimating both absolute and difference thresholds) and can 
</p>
<p>be presented simultaneously (for difference threshold). The choice of the method of 
</p>
<p>adjustment would not be appropriate, for example, for trying to estimate the differ-
</p>
<p>ence threshold for auditory intensity. So, after several trials, we can extract two key 
</p>
<p>pieces of information by averaging the points of equality and by calculating the 
</p>
<p>standard deviation of the distribution of points. By subtracting the standard stimulus 
</p>
<p>value from the calculated mean, the constant error is obtained; and the difference 
</p>
<p>threshold will be revealed by the standard deviation. We understand the spirit of this 
</p>
<p>operational definition of the threshold: the greater the standard deviation, the higher 
</p>
<p>the threshold (i.e., poorer discrimination or lower sensitivity). In other words, this 
</p>
<p>means that two stimuli will appear equal over a large range of values.
</p>
<p>Consider the following example where two observers, A and B, try to adjust the 
</p>
<p>intensity of a light source to the same level as another source having a fictitious 
</p>
<p>value of 100. The adjustment of each observer at each trial is reported in Table 1.2. 
</p>
<p>1.3 Other Methods for Estimating Thresholds</p>
<p/>
</div>
<div class="page"><p/>
<p>10
</p>
<p>We can see that, on average, there is little difference between them, but we under-
</p>
<p>stand that there is much more variability in the scores of Observer B. It is the esti-
</p>
<p>mate of this variability that is used to establish the sensitivity level, i.e., the difference 
</p>
<p>threshold.
</p>
<p>1.3.2  The Method of Limits
</p>
<p>One can just as easily measure an absolute threshold or a difference threshold with 
</p>
<p>the method of limits. In both cases, the method requires the presentation of two 
</p>
<p>types of series of stimuli, one ascending and the other descending. However, in 
</p>
<p>addition to presenting one stimulus at a time (absolute threshold) rather than two 
</p>
<p>(difference threshold), the moment for stopping ascending and descending series 
</p>
<p>depends on the type of threshold under investigation.
</p>
<p>Thus, for estimating an absolute threshold specifically, it is necessary to identify 
</p>
<p>in advance a series of stimuli that are more or less close to what is believed to be the 
</p>
<p>threshold. These stimuli are presented one at a time, sometimes in ascending order, 
</p>
<p>sometimes in descending order, alternating from one order to another. In a series of 
</p>
<p>ascending presentations, the first stimulus presented is significantly below the abso-
</p>
<p>lute threshold; then the intensity is increased gradually from one trial to another, 
</p>
<p>until the observer reports having perceived the stimulus. Similarly, during a series 
</p>
<p>of descending trials, we first use a stimulus that can be perceived easily, and then the 
</p>
<p>intensity is gradually decreased, until reaching the moment of a transition from a 
</p>
<p>trial where the stimulus is perceived and a trial where it is not. Note that the ascend-
</p>
<p>ing and descending series do not all begin at the same point (Table 1.3). The purpose 
</p>
<p>of this strategy is to circumvent the problem caused by the possibility of committing 
</p>
<p>the so-called anticipation and habituation errors. To determine the absolute thresh-
</p>
<p>old, it is necessary to average the transition points, from not perceived to perceived 
</p>
<p>in the ascending series and from perceived to not perceived in the descending series.
</p>
<p>We commit a habituation error when we take the habit of answering &ldquo;no&rdquo; during 
</p>
<p>an ascending series or &ldquo;yes&rdquo; during a descending series. This type of error will 
</p>
<p>result in the first case in an overestimation of the actual value of the absolute 
</p>
<p>threshold and in the second case in an underestimation. An anticipation error 
</p>
<p>occurs when an observer, knowing that there will be a transition point, passes too 
</p>
<p>quickly from &ldquo;yes&rdquo; to &ldquo;no&rdquo; (descending series) or from &ldquo;no&rdquo; to &ldquo;yes&rdquo; (ascending series). 
</p>
<p>Table 1.2 Adjusted value of the comparison stimulus obtained on each trial with a standard 
</p>
<p>having a value of 100
</p>
<p>Observer/trial 1 2 3 4 5 6 7 8 9 10
</p>
<p>A 98 99 104 97 102 103 97 102 93 101
</p>
<p>B 91 97 89 108 111 99 93 108 95 100
</p>
<p>Point of subjective equality of Observer A, 99.6; for Observer B, 99.1
</p>
<p>Difference threshold of Observer A, 3.41; for Observer B, 7.65
</p>
<p>1 Psychophysics</p>
<p/>
</div>
<div class="page"><p/>
<p>11
</p>
<p>In the first case, the anticipation error will result in an overestimation of the thresh-
</p>
<p>old value compared with the real threshold value and will result in an underestima-
</p>
<p>tion in the second case.
</p>
<p>In the case of a difference threshold estimated with the method of limits, two 
</p>
<p>stimuli are used, a standard and a comparison stimulus (Table 1.4). These stimuli 
</p>
<p>are presented in pairs, either simultaneously or successively. It is the nature of the 
</p>
<p>evaluated sensory continuum that determines the relevance of the presentation 
</p>
<p>mode. For sound, for example, it is better to present the stimuli successively.
</p>
<p>After the presentation of the two stimuli, the observer must determine if this 
</p>
<p>stimulus is smaller or larger than the other or if those stimuli appear to be equal. 
</p>
<p>Comparison stimuli vary from one trial to another so that the difficulty of discrimi-
</p>
<p>nating is gradually increased. If it is an ascending series, the magnitude of the com-
</p>
<p>parison stimuli is increased; for a descending series, the magnitude is decreased.
</p>
<p>Determining the difference threshold with the method of limits, instead of the 
</p>
<p>absolute threshold, is particular for not having a series, either ascending or descend-
</p>
<p>ing, being stopped when a transition point is observed. In fact, in the case of an 
</p>
<p>ascending series, for example, the first transition that the observer meets is when the 
</p>
<p>comparison stimulus appears to be smaller than the standard and then, the following 
</p>
<p>trial, the stimuli appear equal. It is necessary to continue to increase the value of the 
</p>
<p>comparison stimuli until the standard and comparison stimuli stop appearing equal. 
</p>
<p>It is necessary to reach the transition that leads to the impression that the compari-
</p>
<p>son stimulus is larger than the standard. Once this response is made for the first 
</p>
<p>time, the series ends (Table 1.4). The same process is followed with the descending 
</p>
<p>series. Also, just as was the case for the absolute threshold, ascending and descend-
</p>
<p>ing series have to be alternated, and the starting value of a series should also vary 
</p>
<p>from one time to another, for the ascending and for the descending series.
</p>
<p>Table 1.3 Determination of an absolute threshold with the method of limits (fictitious values) 
</p>
<p>where the observer indicates whether or not a stimulus is perceived
</p>
<p>Intensity/series
</p>
<p>Ascending Descending Ascending Descending Ascending Descending
</p>
<p>16 Yes
</p>
<p>14 Yes Yes
</p>
<p>12 Yes Yes Yes
</p>
<p>10 Yes Yes No Yes
</p>
<p>8 Yes Yes No Yes No
</p>
<p>6 No Yes No No
</p>
<p>4 No No No No
</p>
<p>2 No No No
</p>
<p>0 No No
</p>
<p>0 No
</p>
<p>Points of 
</p>
<p>transition
</p>
<p>7 5 9 11 7 9
</p>
<p>Threshold value: (7 + 5 + 9 + 11 + 7 + 9)/6 = 8
</p>
<p>1.3 Other Methods for Estimating Thresholds</p>
<p/>
</div>
<div class="page"><p/>
<p>12
</p>
<p>For each series, there are therefore two transition points. These points make it pos-
</p>
<p>sible to identify an upper limit (uL) and a lower limit (lL). For example, in the case of 
</p>
<p>a descending series, the uL is reached when, after the comparison stimulus was per-
</p>
<p>ceived as being greater than the standard, these stimuli are now perceived as equal. 
</p>
<p>Similarly, the lL is reached when, after being perceived as being equal to the standard 
</p>
<p>during a trial or several trials, the comparison stimulus is now perceived as being 
</p>
<p>lesser than the standard. An uncertainty interval can be calculated by subtracting the 
</p>
<p>average of uL from the average of lL; the difference threshold is then calculated by 
</p>
<p>dividing this uncertainty interval by 2. A PSE is estimated as follows: (uL + lL)/2.
</p>
<p>1.3.3  Adaptive Methods
</p>
<p>Although we will only touch on the subject, it should be noted that there are a series 
</p>
<p>of so-called adaptive procedures for estimating thresholds. In general, these meth-
</p>
<p>ods allow to make good estimates of thresholds in a lesser number of trials, in 
</p>
<p>Table 1.4 The difference threshold with the method of limits is based on conditions where the 
</p>
<p>observer indicates that a comparison stimulus is lesser (L) or greater (G) than a standard (of 10, 
</p>
<p>fictitious values) or of equal (E) value
</p>
<p>Intensity/series
</p>
<p>Ascending Descending Ascending Descending Ascending Descending
</p>
<p>18 G
</p>
<p>17 G G
</p>
<p>16 G G G
</p>
<p>15 G G E G
</p>
<p>14 G G E E G E
</p>
<p>13 E G E E E E
</p>
<p>12 E E E E E E
</p>
<p>11 E E E E E E
</p>
<p>10 E E E E E E
</p>
<p>9 E E E L L E
</p>
<p>8 E E L L L
</p>
<p>7 L L L L
</p>
<p>6 L L
</p>
<p>5 L L
</p>
<p>4 L L
</p>
<p>3 L
</p>
<p>2 L
</p>
<p>Upper limit 13.5 12.5 14.5 15.5 13.5 14.5 
</p>
<p>(M = 14)
</p>
<p>Lower limit 7.5 7.5 8.5 9.5 9.5 8.5 
</p>
<p>(M = 8.5)
</p>
<p>Point of subjective equality: (14 + 8.5)/2 = 11.25
</p>
<p>Uncertainty interval: 14 &minus; 8.5 = 5.5
</p>
<p>Difference threshold: 5.5/2 = 2.75
</p>
<p>1 Psychophysics</p>
<p/>
</div>
<div class="page"><p/>
<p>13
</p>
<p>particular by reducing the number of trials involving stimulus values that are far 
</p>
<p>from the threshold.
</p>
<p>One of these procedures is the staircase method (Bonnet, 1986). For using it, 
</p>
<p>it is necessary to choose a starting level (more or less close to the threshold) and 
</p>
<p>a step value allowing to change the difficulty level, by decreasing or increasing 
</p>
<p>the magnitude of the stimulus, depending on whether there is a change from &ldquo;I 
</p>
<p>do not perceive&rdquo; to &ldquo;I perceive&rdquo; or from &ldquo;I perceive&rdquo; to &ldquo;I do not perceive.&rdquo; It is 
</p>
<p>also necessary to decide whether or not the magnitude should be changed as soon 
</p>
<p>as a response indicates the transition from one state to another. Finally, it is also 
</p>
<p>necessary to decide when to stop the procedure, for example, after a number of 
</p>
<p>state changes or after a fixed number of trials. With the staircase procedure, one 
</p>
<p>can use a single staircase having only one set of variations, a double staircase 
</p>
<p>involving two independent series, a series starting well above the threshold, and 
</p>
<p>the other way below.
</p>
<p>Another well-known adaptive method is called parameter estimation by sequen-
</p>
<p>tial testing (PEST). Generally, with this procedure, at every reversal in the opposite 
</p>
<p>direction, the step value adopted at the beginning is halved. Also, this step remains 
</p>
<p>the same when there is a change in the same direction or may even increase (be 
</p>
<p>doubled) if, for example, the observer provides a response in the same direction in 
</p>
<p>three consecutive trials (Macmillan &amp; Creelman, 1991). Finally, note that there are 
</p>
<p>other adaptive methods such as those based on a Bayesian procedure or maximum 
</p>
<p>likelihood (Shen, 2013; Shen &amp; Richards, 2012).
</p>
<p>1.4  Scaling
</p>
<p>A third fundamental question in the field of psychophysics is that of the relationship 
</p>
<p>between the magnitude of a physical stimulus and its psychological magnitude. 
</p>
<p>Such a question is significantly different from that which arose in the context of 
</p>
<p>Weber&rsquo;s law that relates two physical quantities. The questioning is along the line 
</p>
<p>started by Fechner who proposed, using an indirect method, that the relationship 
</p>
<p>between the magnitude of a physical stimulus and the psychological magnitude 
</p>
<p>would necessarily be logarithmic (Appendix B).
</p>
<p>For conducting an empirical verification of a law on the relationship between 
</p>
<p>physical quantities, for a given sensory continuum, and the sensory experience that 
</p>
<p>is made, we first have to try to quantify this experience. Stanley Smith Stevens pro-
</p>
<p>poses to adopt different methods to measure the experience as directly as possible:
</p>
<p>The American Stanley Smith Stevens (1906&ndash;1973) is a prominent figure in psychophysics. 
</p>
<p>He obtained a PhD from Harvard University, where he worked for many years. He is of 
</p>
<p>course well known for Stevens&rsquo;s law and for the development of methods for studying the 
</p>
<p>link between the magnitude of a physical stimulus and its psychological magnitude. What 
</p>
<p>is less known is his contribution extending to other fields, particularly in the field of hear-
</p>
<p>ing. We owe him in particular the identification of different measurement scales.
</p>
<p>1.4 Scaling</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-31791-5_BM1">http://dx.doi.org/10.1007/978-3-319-31791-5_BM1</a></div>
</div>
<div class="page"><p/>
<p>14
</p>
<p>1.4.1  Methods
</p>
<p>The empirical demonstrations of Stevens rely on several scaling methods. 
</p>
<p>Essentially, we can distinguish the &ldquo;partition scale&rdquo; and &ldquo;ratio scale.&rdquo;
</p>
<p>Among the partition scales, there are category scales and equisection scales. In 
</p>
<p>the first case, an observer must assign each stimulus a set of stimuli in certain cate-
</p>
<p>gories (for instance, from 1 to 5). The number of stimuli in the set and the number 
</p>
<p>of categories are determined in advance. As for the equisection scales, an observer 
</p>
<p>must divide his psychological continuum into a series of distances considered as 
</p>
<p>equal. For example, the observer may need to determine that the distance between 
</p>
<p>the sensations created by stimuli A and B on a sensory continuum is smaller than, 
</p>
<p>equal to, or greater than the distance between the sensations produced between 
</p>
<p>stimuli C and D, also on this continuum. Among the method-specific equisection 
</p>
<p>scales, there is bisection. In such a case, the observer is required to select a stimulus 
</p>
<p>whose intensity is located halfway between the intensities of two other stimuli.
</p>
<p>As for the ratio scales, there are the estimation tasks and the production tasks. A 
</p>
<p>procedure often used is called &ldquo;magnitude estimation.&rdquo; When this procedure is 
</p>
<p>used, an observer is exposed to a standard stimulus, also called modulus, which is 
</p>
<p>assigned a numerical value. Then, at each presentation of a stimulus, the observer 
</p>
<p>must assign to this stimulus a numerical value relative to the standard. The observer 
</p>
<p>sets his own scale around the value of the modulus, taking care of never choosing 
</p>
<p>zero. If a stimulus appears to be twice as intense (greater) than a modulus of 50, the 
</p>
<p>observer will assign it a value of 100. Thus, it becomes possible to establish a cor-
</p>
<p>respondence between the different assigned values (psychological magnitude on the 
</p>
<p>y-axis) and the magnitude of the physical stimuli (on the x-axis).
</p>
<p>The ratio production (or fractionation) is among the various types of other ratio 
</p>
<p>scales. For example, an observer may be required to produce the intensity of a stim-
</p>
<p>ulus such that it corresponds to a percentage (e.g., half or one-third) of another 
</p>
<p>stimulus.
</p>
<p>1.4.2  Stevens&rsquo;s Law
</p>
<p>Thus, another fundamental question in psychophysics is related to identification and 
</p>
<p>quantification of the relationship between the magnitude of sensation and the physi-
</p>
<p>cal magnitude of a stimulus. This relationship is sometimes referred to as psycho-
</p>
<p>physical law.
</p>
<p>Of course, it is reasonable to expect that the relationship between the magnitude 
</p>
<p>of sensation and the physical magnitude of a stimulus will be monotonic, that is to 
</p>
<p>say, that the psychological magnitude increases continuously with the increase of 
</p>
<p>the physical magnitude. The question remains concerning the exact nature of this 
</p>
<p>increase: is it fast at the beginning, for stimuli with low amplitude, and slower when 
</p>
<p>the stimuli are of greater magnitude?
</p>
<p>1 Psychophysics</p>
<p/>
</div>
<div class="page"><p/>
<p>15
</p>
<p>In fact, this increase depends on the nature of the stimulus under study. Essentially, 
</p>
<p>as shown in Fig. 1.4 and as reported by Stevens following a very large number of 
</p>
<p>empirical studies, there are three types of growth: exponential, linear, and logarith-
</p>
<p>mic. Thus, Stevens established that the best description of the relationship between 
</p>
<p>the magnitude of perceived sensation and intensity of a stimulus is expressed using 
</p>
<p>a power function:
</p>
<p> 
S K
</p>
<p>N= f
 
</p>
<p>where S is the sensation, K is a constant whose value depends on the measurement 
</p>
<p>units used, and N is the exponent specific to a given sensory dimension. This law is 
</p>
<p>called the power law, Stevens&rsquo;s law, and sometimes Stevens&rsquo;s power law.
</p>
<p>The exponent N is the main feature of this equation, the signature of a sensory 
</p>
<p>continuum. Its value is 1 if the relationship is linear, is smaller than 1 if the relation-
</p>
<p>ship is logarithmic, and is greater than 1 if the relationship is exponential. The N 
</p>
<p>values reported by Stevens (1961) are, for example, 0.55 for smell, 0.60 for loud-
</p>
<p>ness, 1.00 for temperature, and 3.50 for electric shocks. These values however are 
</p>
<p>likely to fluctuate from one experience to another. For example, Stevens (1961) 
</p>
<p>reports a N value of 1.0 for the duration, but after a lengthy review of the literature 
</p>
<p>on the issue, Eisler (1976) came to the conclusion that 0.90 is probably a better 
</p>
<p>approximation (see Grondin &amp; Laflamme, 2015).
</p>
<p>1.4.3  Other Contributions from Stevens
</p>
<p>Stevens (1975) makes a fundamental distinction between two types of sensory expe-
</p>
<p>riences. These experiences are part of one of two sensory continua, called prothetic 
</p>
<p>and metathetic. In the case of a prothetic continuum, the sensory experiences are 
</p>
<p>Fig. 1.4 Three types of relationship, exponential (N &gt; 1), linear (N = 1), and logarithmic (N &lt; 1), 
</p>
<p>between sensation and the physical magnitude of a stimulus. Left panel: S K N= f .  Right panel 
</p>
<p>shows the same function in log-log coordinates: log log logS N K( ) = +f
</p>
<p>1.4 Scaling</p>
<p/>
</div>
<div class="page"><p/>
<p>16
</p>
<p>based on an additive physiological process, i.e., a process in which the increase in the 
</p>
<p>physical intensity of a stimulus leads to an increase of the frequency of action poten-
</p>
<p>tials by neurons responsible for receiving these stimuli. In contrast, a metathetic con-
</p>
<p>tinuum is not based on the idea of addition, but rather on that of substitution.
</p>
<p>Thus, with a prothetic continuum, it is logical to try to answer a question based 
</p>
<p>on the idea of &ldquo;how much?&rdquo; whereas with the second type, the metathetic contin-
</p>
<p>uum, the question rather consists of knowing &ldquo;of what kind?&rdquo; the sensation is. For 
</p>
<p>example, in the visual modality, a brightness change will be additive; a light source 
</p>
<p>will be more or less intense than another. Therefore, we will be dealing with a pro-
</p>
<p>thetic continuum. If we are dealing with a change in the wavelength of light, the 
</p>
<p>change will be a substitution, that is to say that what will be observed will not 
</p>
<p>depend on a quantitative sensory difference, but on a simple qualitative change in 
</p>
<p>appearance, namely, a change of color (hue).
</p>
<p>As mentioned above, Stevens is also responsible for identifying the various mea-
</p>
<p>surement scales. He had identified four: the nominal scale, which only serves to 
</p>
<p>identify an object; the ordinal scale, which indicates the rank or order of scores; the 
</p>
<p>interval scale, which includes the notion of distance between the scores; and the 
</p>
<p>ratio scale, which includes, in addition to the notion of distance, an absolute zero.
</p>
<p>That said, it is not possible to use the same scale for all the sensory qualities. 
</p>
<p>Some of these qualities can be quantified (prothetic continuum), others not (meta-
</p>
<p>thetic continuum). In the first case, the scores can be distributed on an ordinal or even 
</p>
<p>interval scale, but with a metathetic continuum, the nominal scale is appropriate.
</p>
<p>1 Psychophysics</p>
<p/>
</div>
<div class="page"><p/>
<p>17&copy; Springer International Publishing Switzerland 2016 
</p>
<p>S. Grondin, Psychology of Perception, DOI 10.1007/978-3-319-31791-5_2
</p>
<p>Chapter 2
</p>
<p>Physical and Biological Bases of Hearing
</p>
<p>Hearing relates to the sense responsible for translating a series of pressure variations 
</p>
<p>in the air into an action potential, i.e., something that the brain can recognize. Before 
</p>
<p>describing the biological bases of hearing, it is first necessary to understand what 
</p>
<p>the brain needs to recognize.
</p>
<p>2.1  Physical Characteristics of a Simple Sound Wave
</p>
<p>Sounds are produced because something vibrates in the environment. These vibra-
</p>
<p>tions are disturbances and their propagation is possible only because it happens in a 
</p>
<p>material medium. This medium is usually air, but it could also be, for example, 
</p>
<p>water or any other substance. If you are underwater and try to talk to someone, you 
</p>
<p>will find that this is possible, but the carried message is far from being as clear as it 
</p>
<p>is usually. In short, a body which vibrates produces sound, provided that the vibra-
</p>
<p>tions do not occur in a vacuum where nothing is transmitted.
</p>
<p>More specifically, the vibrations cause a series of compressions and rarefactions 
</p>
<p>of the molecules in the environment. The normal pressure in the air is successively 
</p>
<p>increased or decreased. As discussed below, the characteristics of these variations 
</p>
<p>can be represented using a simple sine wave (for pure sound).
</p>
<p>2.1.1  Frequency and Phase
</p>
<p>A key thing to consider in the analysis of sound is the speed of variations ranging 
</p>
<p>from compressions to rarefactions to compressions and so on. These changes occur 
</p>
<p>more or less rapidly. This speed of state changes is called the frequency, i.e., the 
</p>
<p>number of cycles (&ldquo;compression-rarefaction&rdquo;) completed during a given period. It </p>
<p/>
</div>
<div class="page"><p/>
<p>18
</p>
<p>was agreed to express this frequency in a number of cycles completed in 1 s. One 
</p>
<p>cycle per second is 1 hertz (Hz), the unit used to express frequency and named after 
</p>
<p>the German physicist Heinrich Hertz.
</p>
<p>The time taken to complete one cycle of the sine wave is called the period 
</p>
<p>(Fig. 2.1). As for the circular motion, a period (or a complete cycle) involves 360&deg; 
</p>
<p>(360 degrees). The beginning of the cycle is 0&deg;, whereas the maximum compression 
</p>
<p>and the maximum rarefaction occur at 90&deg; and 270&deg;, respectively. Also, the relative 
</p>
<p>position of two sounds over time is called phase. If two pure tones arrive at a given 
</p>
<p>point in time with a difference of 1/8 of a cycle, they will be described as being 45&deg; 
</p>
<p>out of phase.
</p>
<p>If a sound has a frequency of 1 Hz when a cycle is completed in 1 s, a sound 
</p>
<p>completing 500 cycles in 1 s has a 500-Hz frequency. If a cycle takes only 1 ms to 
</p>
<p>be completed, that is to say, 1000 cycles are completed in a second, it will be a 
</p>
<p>1000-Hz, or 1-kHz, sound (pronounce kHz &ldquo;kilohertz&rdquo;).
</p>
<p>Sometimes, to express the idea of frequency, we use the notion of wavelength. 
</p>
<p>This is denoted by the Greek letter lambda (λ) and consists of the linear distance 
</p>
<p>between two successive compressions. Of course, the fewer cycles traveled in a 
</p>
<p>given time, the longer the wave. However, this length is also determined by the 
</p>
<p>propagation speed of the wave. Determined by the environment in which the wave 
</p>
<p>is generated, the speed is greater in a denser medium. The speed is, for example, 
</p>
<p>340 m/s in the air and 1500 m/s in water. Thus, two waves having the same fre-
</p>
<p>quency in the air and water do not have the same length.
</p>
<p>The span of audible frequencies by the human ear ranges from about 20 Hz to 
</p>
<p>20 kHz. In fact, toward the ends of this range, the detection threshold is much 
</p>
<p>higher; in other words, to be heard, a sound of 20 Hz must be much louder than a 
</p>
<p>5000-Hz sound. Also, most often, conversations remain in a range of frequencies 
</p>
<p>Fig. 2.1 Illustration of a sound (sinusoidal) wave for a pure tone of 1000 Hz (or 1 kHz)
</p>
<p>2 Physical and Biological Bases of Hearing</p>
<p/>
</div>
<div class="page"><p/>
<p>19
</p>
<p>extending from about 100 Hz to 10 kHz. Note also that the hearing abilities vary 
</p>
<p>with age; thus, it becomes difficult with age to hear sounds above 15 kHz. In fact, 
</p>
<p>some people, even young people, are unable to hear such sounds. Humans therefore 
</p>
<p>can deal with a wide range of audible frequencies. However, this capability of hear-
</p>
<p>ing high frequencies does not compare at all to that of, for instance, mice (up to 
</p>
<p>90 kHz), bats (over 100 kHz), or dolphins (up to 200 kHz), which are therefore able 
</p>
<p>to hear ultrasounds. In the next chapter (Fig. 3.6), you will return to this notion of 
</p>
<p>frequency ranges emphasizing the ones covered by some musical instruments and 
</p>
<p>by the human voices. Note that the animals who are able to hear ultrasounds will be 
</p>
<p>unable to hear, for example, frequencies below 1000 Hz in the case of mice or 
</p>
<p>3000 Hz in the case of bats. Elephants, however, hear low-frequency sounds (up to 
</p>
<p>17 Hz), but cannot hear sounds above 10 kHz.
</p>
<p>2.1.2  Amplitude
</p>
<p>A second physical characteristic for describing sounds is called amplitude or inten-
</p>
<p>sity (Fig. 2.2). This feature refers to the fact that pressure variations may be more or 
</p>
<p>less pronounced. It was agreed to express this magnitude with a unit called the 
</p>
<p>decibel (dB&mdash;the name &ldquo;bel&rdquo; given in honor of Alexander Graham Bell). Indeed, 
</p>
<p>this unit is issued from a pressure ratio between that exerted by a given sound and 
</p>
<p>that exerted by a reference sound. In such a case, we refer more specifically to dB 
</p>
<p>SPL (SPL for sound pressure level).
</p>
<p>A pressure measurement is expressed in terms of force per unit of area. Thus, the 
</p>
<p>sound pressure used as a reference is, by convention, 0.0002 dyne/cm2, a &ldquo;dyne&rdquo; 
</p>
<p>corresponding to the force required to give a mass of 1 g an acceleration of 1 cm/s2. 
</p>
<p>It is also possible to express the pressure with a unit called pascal (named after the 
</p>
<p>scientist and philosopher Blaise Pascal), the reference sound being equal to 20 μPa 
</p>
<p>(micropascal).
</p>
<p>Amplitude Amplitude
</p>
<p>Amplitude
</p>
<p>Period Period Period
</p>
<p>Fig. 2.2 While the wave of the left and the one in the center have the same amplitude but different 
</p>
<p>frequencies, the wave in the center and the one on the right have the same frequency but different 
</p>
<p>magnitudes
</p>
<p>2.1 Physical Characteristics of a Simple Sound Wave</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-31791-5_3">http://dx.doi.org/10.1007/978-3-319-31791-5_3</a></div>
</div>
<div class="page"><p/>
<p>20
</p>
<p>More specifically, to avoid having to deal with very high numbers, it was agreed 
</p>
<p>to express amplitude as a logarithmic scale. Thus, the number, N, of decibels pro-
</p>
<p>duced by a sound can be calculated as follows:
</p>
<p> 
</p>
<p>N dB sound
</p>
<p>ref
</p>
<p>= 20 log
Pr
</p>
<p>Pr
 
</p>
<p>where Prsound is the sound pressure that is being measured and Prref is the pressure of 
</p>
<p>the reference sound (20 μPa). So, we can easily calculate the amplitude of a sound 
</p>
<p>in dB once we know the pressure this sound exerts. Thus, if a sound creates a pres-
</p>
<p>sure that is 100,000 times greater than that of the reference sound, its amplitude is 
</p>
<p>20 times the log of 100,000, that is to say, 20 &times; log (105). The log of 105 is equal to 
</p>
<p>5. Accordingly, the sound has an amplitude of &ldquo;100 dB&rdquo; (20 &times; 5).
</p>
<p>The constant &ldquo;20&rdquo; used in the calculation of the number of dB is due indeed to 
</p>
<p>two constants: multiplied by 2 and multiplied by 10. The 10 stands for the decision 
</p>
<p>made to use decibels rather than bels; this avoids having to work with decimals. The 
</p>
<p>source of the 2 is a bit more subtle. The bel is indeed a measure of power and not a 
</p>
<p>measure of pressure. Since it is agreed to express the amplitude of sound in terms of 
</p>
<p>pressure ratio, it is necessary to consider what the relationship between power and 
</p>
<p>pressure is. The acoustic power (Po) is equivalent to the acoustic pressure (Pr) 
</p>
<p>squared:
</p>
<p> 
Pu which explains where the comes from= = ( )Pr log Pr , .2 2 2
</p>
<p> 
</p>
<p>In order to have some idea of what some sound intensities represent, here are 
</p>
<p>some examples drawn from everyday life. A simple whisper or rustling leaves 
</p>
<p>reaches a loudness of about 20 dB. A library is never really completely silent, and 
</p>
<p>ambient sound may approach 40 dB, which is still well below the 60&ndash;70 dB observed 
</p>
<p>in a work office. In fact, the intensity level of normal speech is around 60 dB. A 
</p>
<p>heavy car traffic creates an amplitude level of about 80 dB, a level that reaches up 
</p>
<p>to about 90 dB with the presence of a large truck or even up to 100 dB with some 
</p>
<p>motorbikes. This remains a little weaker than the 100 dB of a jackhammer or 110 dB 
</p>
<p>(and even more) of certain night clubs, at least near to one of the sound sources. You 
</p>
<p>will understand why workers taking care of the luggage near a large airplane wear 
</p>
<p>helmets to cover their ears, now that you know that large airplanes produce sound 
</p>
<p>intensities of more than 130 dB, which might cause pain. Noises provoked by firing 
</p>
<p>a gun or a pistol can reach more than 160 dB.
</p>
<p>2.2  Physical Characteristics of a Complex Sound Wave
</p>
<p>Usually, the waves heard in the environment are not pure tones like those described 
</p>
<p>early in the previous section. Pure tones can be created easily in a laboratory, with a 
</p>
<p>tuning fork or with some electronic instruments. Most often, what is heard, whether 
</p>
<p>2 Physical and Biological Bases of Hearing</p>
<p/>
</div>
<div class="page"><p/>
<p>21
</p>
<p>it is noise, voice, or musical instruments, are complex sounds. While pure tones 
</p>
<p>consist of only a single frequency, complex sounds result from the mixing of two or 
</p>
<p>more waves of different frequencies.
</p>
<p>Complex sounds can be periodic or aperiodic. They are periodic when their com-
</p>
<p>ponents are integer multiples of the lowest frequency. The lowest frequency in a 
</p>
<p>sound is called the fundamental frequency (often abbreviated as F0). It is also called 
</p>
<p>the first harmonic. A periodic sound is said harmonic when it contains all the other 
</p>
<p>harmonics. The vowels produced by the voice and the sounds of musical instru-
</p>
<p>ments, except percussion, belong in this category (harmonic sounds). If one or a few 
</p>
<p>of these frequencies are missing, the sound is referred to as inharmonic. If a sound 
</p>
<p>is composed of different frequencies that are not multiples of the fundamental fre-
</p>
<p>quency, then it is an aperiodic sound. Partials, rather than harmonics, are used to 
</p>
<p>describe the composition of an aperiodic sound.
</p>
<p>Thus, the fundamental frequency is the lowest note generated by something 
</p>
<p>vibrating. All the frequencies generated are specific to the properties of what is 
</p>
<p>vibrating. What distinguishes one sound from another is not only the frequency and 
</p>
<p>amplitude, as seen above. The distinction may also depend on what might be called 
</p>
<p>the complexity, i.e., the harmonic series that the sound contains, including its fun-
</p>
<p>damental frequency. Why two sounds having the same fundamental frequency and 
</p>
<p>the same intensity would sound differently is because they have different 
</p>
<p>harmonics.
</p>
<p>For understanding the nuances about the complexity of sounds, one approach 
</p>
<p>consists of asking the following question: why do two &ldquo;Cs&rdquo; on the piano are &ldquo;C&rdquo;? 
</p>
<p>There are two elements of response to this question. On the one hand, two pure 
</p>
<p>tones separated by an octave seem identical. This quality is called chroma. On the 
</p>
<p>other hand, these two &ldquo;Cs&rdquo; share harmonics that are not shared by other notes. A 
</p>
<p>32.70-Hz C and a 65.41-Hz C will both have in their harmonics a C of 130.81 Hz; 
</p>
<p>there exists such a pattern for any other note (D, F, &hellip;). Note, however, that a C of 
</p>
<p>32.70 Hz has in its harmonics a frequency of 65.41 Hz, but the latter C (65.41) does 
</p>
<p>not comprise the C of 32.70 Hz, the lowest frequency of 65.41-Hz C being actually 
</p>
<p>65.41 Hz.
</p>
<p>Equally crucial is this second question: why, since it has the same fundamental 
</p>
<p>and the same harmonics, does a C of 32.70 Hz sound differently when played on a 
</p>
<p>piano rather than on a guitar? These same &ldquo;Cs&rdquo; differ because the relative impor-
</p>
<p>tance of each harmonic is not the same for both instruments. The relative contribu-
</p>
<p>tions of each harmonic depend on the vibrating properties of the instruments. The 
</p>
<p>use of an oscilloscope allows to seeing that both identical &ldquo;Cs&rdquo; played sometimes 
</p>
<p>on guitar, sometimes on the piano, have a same frequency, but the wave drawn is not 
</p>
<p>the same for each instrument. In each case, however, the configuration is more com-
</p>
<p>plicated than that of a pure tone (simple sine wave).
</p>
<p>There is a way to know the relative importance of the harmonics of a complex 
</p>
<p>periodic sound. This could be done with a Fourier analysis, named after Jean 
</p>
<p>Fourier, a French physicist of the early nineteenth century. Such an analysis allows 
</p>
<p>describing quantitatively any complex wave into a series of simple components 
</p>
<p>(sine waves). It is interesting to note, as stipulated by the acoustic law of Ohm, that 
</p>
<p>2.2 Physical Characteristics of a Complex Sound Wave</p>
<p/>
</div>
<div class="page"><p/>
<p>22
</p>
<p>the ear can somehow act as a Fourier analyzer. Thus, if a few notes are played 
</p>
<p>together, the auditory system can extract and hear each of the simple sounds con-
</p>
<p>tained in the complex sound that was produced.
</p>
<p>White noises enter in the category of aperiodic complex sounds. These sounds 
</p>
<p>are made of the mixture of all frequencies. This name, white noise, is given by anal-
</p>
<p>ogy to white light which means, as it will be discussed in Chap. 5, not the absence 
</p>
<p>of wavelengths that would allow to observe a color, but the presence of all wave-
</p>
<p>lengths. White noise gives a sound similar to the one we sometimes hear when try-
</p>
<p>ing to tune a frequency on a radio, moving through different frequencies without 
</p>
<p>being able to capture a station correctly.
</p>
<p>It is possible to create sounds by using a filter that let pass only frequencies 
</p>
<p>included within a certain range. This range is called bandwidth and can be more or 
</p>
<p>less narrow. One can also use high-pass filters that allow the passage of frequencies 
</p>
<p>above a certain value or low-pass filters that allow the passage of frequencies below 
</p>
<p>a certain value.
</p>
<p>Another phenomenon, called masking, refers to the incapacity to hear a sound 
</p>
<p>normally audible because of the presence, simultaneously or nearly, of another 
</p>
<p>sound (mask). For example, if two sounds are presented simultaneously, it is pos-
</p>
<p>sible that both are heard. In some circumstances, i.e., according to their relative 
</p>
<p>frequency and intensity, it is possible that a sound be heard and the other not. 
</p>
<p>Most often, a loud sound will mask a weaker sound; also, a sound will mask 
</p>
<p>sounds of equal frequencies or of higher frequencies. The frequency range that 
</p>
<p>may be masked by a given sound is called the critical band. The mask does not 
</p>
<p>need to be presented simultaneously to exert its influence. It can be shifted in 
</p>
<p>time, but its influence will be greater if it is presented shortly before rather than 
</p>
<p>shortly after the sound that is to be masked.
</p>
<p>It should be noted that when a pure tone is produced in a laboratory, this sound 
</p>
<p>may not be clear at the beginning (onset) and end (offset). In order to ensure that 
</p>
<p>the transitions are not too steep, a gradual rise of intensity to reach the targeted 
</p>
<p>intensity, and a gradual fall at the end of the sound, may be used. This shaping of a 
</p>
<p>sound is called the envelope. The sound will be softened even with a rise and fall 
</p>
<p>lasting only a few milliseconds each. Furthermore, if the sound is presented to each 
</p>
<p>ear, we speak of a binaural presentation, as opposed to a monaural presentation if 
</p>
<p>the sound is sent only to one ear.
</p>
<p>2.3  Subjective Characteristics of Sounds
</p>
<p>The impressions left by the sounds, especially when emitted by human voices or 
</p>
<p>music instruments, are numerous and diverse. But before evoking their potential 
</p>
<p>emotional connotation, it is first relevant to distinguish the broad categories of 
</p>
<p>psychological impressions produced by the sounds that could be linked quite 
</p>
<p>directly to the physical reality.
</p>
<p>2 Physical and Biological Bases of Hearing</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-31791-5_5">http://dx.doi.org/10.1007/978-3-319-31791-5_5</a></div>
</div>
<div class="page"><p/>
<p>23
</p>
<p>2.3.1  Pitch, Loudness, and Timbre
</p>
<p>One of the subjective characteristics closely related to a physical characteristic is 
</p>
<p>pitch (Hartmann, 1996; Yost, 2009). Pitch refers to the impression that the sound 
</p>
<p>seems low or high. While high-pitch sounds are composed of high frequencies, the 
</p>
<p>low-pitch sounds are made of low frequencies. Therefore, there is a close and direct 
</p>
<p>correspondence between pitch and frequency. However, the pitch is not perfectly 
</p>
<p>correlated with frequency. The intensity, for example, may exert some influence on 
</p>
<p>the pitch.
</p>
<p>It is difficult to measure directly a subjective dimension such as pitch. S. S. 
</p>
<p>Stevens (see Chap. 1) addressed this problem based on the responses of observers 
</p>
<p>and working on a new unit of measurement, operationally defined. Stevens thus 
</p>
<p>developed the concept of mel, 1000 mels corresponding to the pitch of a 1000-Hz 
</p>
<p>sound at 40 dB SPL.
</p>
<p>A second fundamental subjective dimension of auditory perception is called 
</p>
<p>loudness. This quality mainly refers to the sound intensity, that is to say, the impres-
</p>
<p>sion that sound seems to be soft or loud. Of course, a high-amplitude sound appears 
</p>
<p>louder than a sound of low amplitude, but this impression may vary depending on 
</p>
<p>the frequency of the sound heard. Just as he developed the mel, Stevens also devel-
</p>
<p>oped a unit of loudness, the sone, which is the loudness of a 1000-Hz sound at 
</p>
<p>40 dB SPL.
</p>
<p>The fact that loudness depends not only on the intensity of sounds but also on the 
</p>
<p>frequency has been highlighted by many psychophysical experiments that have led 
</p>
<p>to the development of equal-loudness contours. These lines, called phons and 
</p>
<p>reported in Fig. 2.3, are built on the basis of a 1-kHz standard sound. If the frequen-
</p>
<p>cies would exert no influence on loudness, the lines would remain flat. What the 
</p>
<p>figure reveals is the fact, for example, that the loudness of a sound of 200 Hz and 
</p>
<p>60 dB SPL will be the same (about 50 sones) to that of a 2-kHz sound at 50 dB 
</p>
<p>SPL. Note in conclusion that the impression of loudness is also dependent on the 
</p>
<p>120
</p>
<p>100
</p>
<p>80
</p>
<p>60
</p>
<p>40
</p>
<p>20
</p>
<p>0
</p>
<p>20 100 1000 10,000
</p>
<p>120
</p>
<p>110
</p>
<p>100
</p>
<p>90
</p>
<p>80
</p>
<p>70
</p>
<p>60
</p>
<p>50
</p>
<p>40
</p>
<p>30
</p>
<p>20
</p>
<p>10
</p>
<p>Frequency (Hz)
</p>
<p>In
te
</p>
<p>n
si
ty
</p>
<p> (
d
b
 S
</p>
<p>P
L
</p>
<p>)
</p>
<p>Fig. 2.3 Equal-loudness 
</p>
<p>contours, each expressed 
</p>
<p>as phons (Fletcher &amp; 
</p>
<p>Munson, 1933)
</p>
<p>2.3 Subjective Characteristics of Sounds</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-31791-5_1">http://dx.doi.org/10.1007/978-3-319-31791-5_1</a></div>
</div>
<div class="page"><p/>
<p>24
</p>
<p>presentation duration of the sound: with very short sounds (&lt;200 ms), the intensity 
</p>
<p>needs to be increased for generating the impression that this sound is as loud as a 
</p>
<p>sound of longer duration.
</p>
<p>A third subjective dimension of the auditory experience closely related to physi-
</p>
<p>cal reality is called timbre. As reported above, two sounds may have the same 
</p>
<p> fundamental frequency and the same amplitude, but they may nevertheless be dif-
</p>
<p>ferent perceptually. What causes this difference is their timbre, which depends on 
</p>
<p>the composition of each sound, i.e., on their respective harmonic arrangements.
</p>
<p>2.3.2  Other Subjective Characteristics
</p>
<p>Sounds can create many other subjective impressions. For example, we will have 
</p>
<p>the impression that space is more or less filled by a sound. In such a case, we refer 
</p>
<p>to volume (not to be confused with intensity). Of course, if we increase the intensity, 
</p>
<p>the impression of volume is increased; the volume also appears greater if the pitch 
</p>
<p>of a sound is low rather than high. Another subjective impression is related to the 
</p>
<p>fact that a sound may seem more or less compact, or more or less hard. This quality 
</p>
<p>of a sound is referred to as density, a loud sound dominated by high frequencies 
</p>
<p>appearing denser than a weaker sound dominated by low frequencies.
</p>
<p>In fact, the subjective impression caused by a sound can often be associated 
</p>
<p>with its spectral composition. Already in the nineteenth century, Helmholtz 
</p>
<p>reported that a sound composed only of its fundamental seems rather soft, but with 
</p>
<p>a less intense fundamental and more intense harmonics, the sound rather appears 
</p>
<p>hollow. You can also notice that some voices seem nasal and other sounds seem 
</p>
<p>strident. Also, two notes played together seem dissonant and melodious, depend-
</p>
<p>ing on distance (in Hz) between them.
</p>
<p>In closing, it should be recalled that the pleasure afforded by the sounds of music 
</p>
<p>can also depend on cultural habits and factors associated with learning. Complex 
</p>
<p>music (e.g., symphonies or operas) are more difficult to enjoy, but with repeated 
</p>
<p>exposure to a certain piece (some learning), it becomes more accessible (see 
</p>
<p>Chapter 3).
</p>
<p>2.4  Biological Bases
</p>
<p>Between the arrival of a sound wave to the ear and the capture by the brain of an 
</p>
<p>intelligible and revealing message, a long path is traveled. The waves of com-
</p>
<p>pressions and rarefactions included within the initial stimulus are translated 
</p>
<p>through various stages that constitute the path from the external ear to the inner 
</p>
<p>ear, via the middle ear.
</p>
<p>2 Physical and Biological Bases of Hearing</p>
<p/>
</div>
<div class="page"><p/>
<p>25
</p>
<p>2.4.1  Outer, Middle, and Inner Ear
</p>
<p>The outer ear includes essentially two parts, the pinna and the auditory canal 
</p>
<p>(Fig. 2.4). The function of the pinna is to collect sound waves and to direct them into 
</p>
<p>the auditory canal. However, the role of the pinna, if we consider its lack of mobil-
</p>
<p>ity, is much less important in humans than in some other vertebrates. Nevertheless, 
</p>
<p>it serves to amplify sounds, especially those falling within a range of 1.5&ndash;7 kHz and, 
</p>
<p>to a certain extent, contributes to locating the direction of sounds (Chap. 3).
</p>
<p>The ear canal is a passageway that extends for about 2.5&ndash;3 cm from pinna to the 
</p>
<p>eardrum. Throughout this duct, which has a diameter of about 0.75 cm, there are 
</p>
<p>glands that secrete a wax, technically known as cerumen, which serves as a barrier 
</p>
<p>for protecting the inner ear from dust and dirt.
</p>
<p>Between the outer ear and the middle ear, there is a thin membrane, the eardrum, 
</p>
<p>covering a surface of approximately 70 mm2. The function of the middle ear is to 
</p>
<p>ensure the transmission of the air movement from the eardrum to the inner ear. This 
</p>
<p>transmission takes place via three tiny bones, called the ossicles: the malleus (ham-
</p>
<p>mer), the incus (anvil), and the stapes (stirrup). The malleus is attached to the ear-
</p>
<p>drum; the incus is connected to the malleus and the stapes, and the stapes is attached 
</p>
<p>to a small structure, the oval window (or vestibular window), which is the gateway 
</p>
<p>through which the air vibrations are transmitted to the inner ear. The base of the 
</p>
<p>stapes has a surface area of only 3 mm2.
</p>
<p>The inner ear contains an important amount of liquid. For transmitting the wave 
</p>
<p>from an air medium to a liquid medium, it is necessary to overcome a certain amount 
</p>
<p>Fig. 2.4 General sketch of the outer ear, middle ear, and inner ear; illustrated here with the semi-
</p>
<p>circular canals, which are parts of the inner ear, but serve a function other than hearing, namely, the 
</p>
<p>sense of balance (Figure by Leila Aazari)
</p>
<p>2.4 Biological Bases</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-31791-5_3">http://dx.doi.org/10.1007/978-3-319-31791-5_3</a></div>
</div>
<div class="page"><p/>
<p>26
</p>
<p>of resistance. The fact of transmitting the vibrations from a large area, that of the 
</p>
<p>eardrum, to a small area, that is the one at the base of the stapes, results in a signifi-
</p>
<p>cant increase of the pressure and allows to transmit effectively the information pro-
</p>
<p>vided by the air vibrations. The main role of the middle ear is therefore to contribute 
</p>
<p>to the production of this pressure when the vibrations are entering into the inner ear 
</p>
<p>through the oval window.
</p>
<p>Just below the oval window is the round window (or cochlear window). This is 
</p>
<p>part of the inner ear, but its function is closely linked to the activity of the oval win-
</p>
<p>dow. With the fluid in the ear being incompressible, any pressure on the oval win-
</p>
<p>dow has to be absorbed elsewhere, which is made possible by the round window 
</p>
<p>which is actually an elastic membrane.
</p>
<p>Other structures that are parts of the middle ear contribute directly to the func-
</p>
<p>tioning of hearing. A structure called the Eustachian tube (or internal auditory 
</p>
<p>meatus) connects the middle ear to the pharynx and to the nose or mouth. Its role is 
</p>
<p>to make the air pressure in the middle ear equal to that existing in the ear canal. It is 
</p>
<p>possible to notice the need to equilibrate that pressure when climbing in altitude or 
</p>
<p>traveling in an airplane, which is made possible by swallowing or yawning. The air 
</p>
<p>may then be sent from the pharynx to the middle ear, which enables the eardrum to 
</p>
<p>vibrate normally.
</p>
<p>Two muscles also have a key role in modulating the transmission of sound energy 
</p>
<p>to the inner ear. One is called the tensor tympani muscle and the other is the stape-
</p>
<p>dius muscle. They allow the release of the stapes from the oval window. The func-
</p>
<p>tion of these two muscles is to protect the auditory system when sounds are too 
</p>
<p>intense. Thus, while the middle ear is built so as to overcome the resistance of the 
</p>
<p>liquid medium of the inner ear by increasing the pressure, it also has a security sys-
</p>
<p>tem, when sounds are too loud, for reducing the transmission of these sounds. The 
</p>
<p>contraction of these two muscles is reflex activity, namely, the acoustic reflex or 
</p>
<p>attenuation reflex.
</p>
<p>The inner ear, also called the labyrinth, contains a bone structure, the bony laby-
</p>
<p>rinth. Inside the bony labyrinth, there is a structure, the membranous labyrinth, 
</p>
<p>immersed in a liquid called the perilymph. In the inner ear, there are three main 
</p>
<p>structures. The first, the cochlea, has a crucial role in hearing which is described in 
</p>
<p>the next section and later in the chapter. The other two structures, the vestibule and 
</p>
<p>semicircular canals, have a key role in balance, but this topic will not be covered in 
</p>
<p>this book.
</p>
<p>Note that it is possible to hear without using the normal path of the outer ear and 
</p>
<p>the middle ear. Vibrations can be conducted by the bones of the skull, a phenome-
</p>
<p>non called bone conduction. For experiencing the effect of conduction, just make a 
</p>
<p>sound continuously and then cover your ears (while maintaining the sound). You 
</p>
<p>will hear that the pitch of the sound is shifting. In fact, you will keep hearing the 
</p>
<p>sound, even with plugged ears, but through bone conduction. This explains why we 
</p>
<p>often feel we do not recognize our own voice on a recording. When we speak, we 
</p>
<p>are hearing both the sounds that are transmitted via the outer ear and the middle ear 
</p>
<p>and sound transmitted by bone conduction. The sound transmitted through bone 
</p>
<p>conduction is not present when you hear a recording of your voice.
</p>
<p>2 Physical and Biological Bases of Hearing</p>
<p/>
</div>
<div class="page"><p/>
<p>27
</p>
<p>2.4.2  The Cochlea
</p>
<p>The cochlea has the shape of a spiral, a kind of snail which is completing about two 
</p>
<p>and a half turns. It contains a long membranous tube, the cochlear duct in which 
</p>
<p>flows a liquid called endolymph.
</p>
<p>Essentially, the cochlea is divided into three parts by two membranes (Fig. 2.5). 
</p>
<p>Above the cochlear duct is the vestibular canal separated from the cochlear duct by 
</p>
<p>a thin membrane called Reissner&rsquo;s membrane (or vestibular membrane). Below the 
</p>
<p>basilar membrane, there is the tympanic canal in which flows, as is the case for the 
</p>
<p>vestibular canal, the perilymph. Both canals communicate with each other through 
</p>
<p>a narrow channel, the helicotrema.
</p>
<p>When there are sound vibrations, they are transmitted to the perilymph. The fluid 
</p>
<p>movement thus transmitted travels along the vestibular canal and returns to the tym-
</p>
<p>panic canal. This movement then generates an oscillation of the basilar membrane 
</p>
<p>which thus undergoes different deformations. The basilar membrane is narrower 
</p>
<p>and stiffer at the base, close to the oval window and where the sound signals reach 
</p>
<p>the cochlea, than on its apex.
</p>
<p>It is actually on this basilar membrane that we find the spiral organ, also called 
</p>
<p>the organ of Corti. In particular, it contains receptor cells that convert sound waves 
</p>
<p>into action potentials. The organ of Corti is composed of thousands of hair cells. 
</p>
<p>These cells, lying on supporting cells called Deiters&rsquo; cells, each contain dozens of 
</p>
<p>stereocilia. There are two types of hair cells, inner and outer. There are about 3500 
</p>
<p>inner hair cells in each ear, arranged on the same row, and more than 10,000 outer 
</p>
<p>hair cells, arranged in three rows. Yet more than 90 % of the 30,000 afferent fibers 
</p>
<p>of the auditory nerve are connected with inner hair cells, whereas approximately 
</p>
<p>500 efferent fibers (from the brain) of the auditory nerve are connected to the outer 
</p>
<p>hair cells. When the basilar membrane oscillates, it is the contact of the stereocilia 
</p>
<p>with the tectorial membrane, which is located just above the sensory cells, that is the 
</p>
<p>Fig. 2.5 Cross section of the cochlea
</p>
<p>2.4 Biological Bases</p>
<p/>
</div>
<div class="page"><p/>
<p>28
</p>
<p>basis of hearing. It is at this point that all the mechanical vibration (first in air and 
</p>
<p>then in the liquid medium of the inner ear) is converted into an electrical signal, 
</p>
<p>nerve impulse, that the brain can recognize.
</p>
<p>2.4.3  Central Mechanisms
</p>
<p>Because they involve many crossings and relays, pathways bringing information 
</p>
<p>from the cochlea to the auditory cortex are relatively complex. Auditory informa-
</p>
<p>tion enters into the brain at the bulb level (see Appendix C). The nerve impulses 
</p>
<p>travel from the spiral ganglia to the brain structures by the vestibulocochlear nerves 
</p>
<p>(the eighth cranial nerve) which split into two branches. In a given ear, the informa-
</p>
<p>tion is routed to the ventral and dorsal parts of the cochlear nucleus. From the 
</p>
<p>cochlear nucleus, different routes can be followed. The neurons of the ventral part 
</p>
<p>will make connection with the superior olivary nucleus, one-half traveling in the 
</p>
<p>opposite half of the brain (contralateral side) and the other half remaining in the 
</p>
<p>ipsilateral side. Early in the auditory system, at the olivary level (at the level of the 
</p>
<p>medulla oblongata), there is a representation of the activity of both ears on each side 
</p>
<p>of the brain.
</p>
<p>The axons of the neurons in the dorsal cochlear nucleus all reach the inferior 
</p>
<p>colliculus (at the level of the midbrain) on the contralateral side. Information from 
</p>
<p>the superior olivary structure reaching the inferior colliculus originates from both 
</p>
<p>the left ventral cochlear nucleus and the right ventral cochlear nucleus. Note that 
</p>
<p>some fibers from the contralateral superior olivary structure and some fibers from 
</p>
<p>the dorsal cochlear nucleus will transit through the nucleus of the medial lemniscus 
</p>
<p>before reaching the inferior colliculus; moreover, at the level of this latter structure, 
</p>
<p>many nerve fibers are crossing.
</p>
<p>The nerve impulse is then routed to the thalamus, more specifically at the median 
</p>
<p>geniculate nucleus, for eventually arriving at the primary auditory cortex, or A1, in 
</p>
<p>the temporal lobe. Note that there are some relays between the inferior colliculus 
</p>
<p>and the superior colliculus where would be processed the information about the 
</p>
<p>location of a sound source, along with information from other sensory modalities. 
</p>
<p>Finally, it should be noted that in A1, there is a tonotopic organization, i.e., a spatial 
</p>
<p>representation of the different sound frequencies. In fact, this organization exists at 
</p>
<p>all stages of auditory information processing described above.
</p>
<p>2.5  Theories of Hearing
</p>
<p>The previous section allowed to learn the role of different biological structures in 
</p>
<p>the path of the sound wave from the pinna to the auditory cortex. However, the ques-
</p>
<p>tion remains as to how these waves can afford to hear with so many nuances. 
</p>
<p>Researchers have long addressed this yet simple question: how can we perceive 
</p>
<p>2 Physical and Biological Bases of Hearing</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-31791-5_BM1">http://dx.doi.org/10.1007/978-3-319-31791-5_BM1</a></div>
</div>
<div class="page"><p/>
<p>29
</p>
<p>pitch? What is happening exactly on the basilar membrane, in the organ of Corti? 
</p>
<p>The next subsections provide an overview of the main answers revealed by research 
</p>
<p>in the field of hearing.
</p>
<p>2.5.1  Frequency Theory
</p>
<p>The initial theoretical explanation based on the idea of the frequency was proposed 
</p>
<p>by the English physiologist William Rutherford. In the past, telephones were built 
</p>
<p>with a diaphragm, and it was the vibrations of this device, caused by the voice, that 
</p>
<p>were converted into electrical signals. Once reaching the acoustic of another tele-
</p>
<p>phone, the signals were reproduced. Rutherford tried to draw a parallel between the 
</p>
<p>basilar membrane and the diaphragm. According to him, the basilar membrane 
</p>
<p>would serve to reproduce the pressure variations transmitted by the stapes. From 
</p>
<p>such a perspective, the auditory nerve serves as a transmission cable, and the role of 
</p>
<p>the brain is to interpret the frequency.
</p>
<p>This formulation of the frequency theory was not going to hold the road. The 
</p>
<p>basilar membrane is not like the diaphragm of a telephone was. The basilar mem-
</p>
<p>brane is not of the same width throughout and rigidity changes from one place to 
</p>
<p>another. An even more serious objection to the original frequency theory is the 
</p>
<p>simple fact that the ear is sensitive to frequencies ranging up to 20 kHz. This implies 
</p>
<p>that a nerve fiber would have to be able to send 20,000 impulses per second. In fact, 
</p>
<p>even the transmission of sound of 1000 Hz is problematic because a nerve cell can-
</p>
<p>not produce 1000 impulses per second. In short, this theory cannot account for the 
</p>
<p>perception of all pitches associated with the audible frequency range. In other 
</p>
<p>words, understanding the perception of high frequencies causes problem.
</p>
<p>One solution to this problem was proposed by Wever and Bray (1937). This solu-
</p>
<p>tion, which is based on the idea of cooperation between the nerve fibers, is called the 
</p>
<p>volley principle. According to this principle, the neural activity associated with each 
</p>
<p>of the different cycles of a sound is distributed via a series of fibers. Each fiber does 
</p>
<p>not have to respond to every cycle of a sound wave. After a response to a cycle, a 
</p>
<p>fiber has a recovery period and another fiber responds to the next cycle (Fig. 2.6). 
</p>
<p>Indeed, a large number of fibers share the work. It is the grouped activity on a set of 
</p>
<p>fibers that captures all cycles of a given sound wave. Finally, the volley principle 
</p>
<p>accounts not only for the perception of pitch but also for that of loudness. The per-
</p>
<p>ception of loudness is accounted by the combined activity of more than one fiber for 
</p>
<p>each cycle of the sound wave.
</p>
<p>In fact, we now know that the activity of an auditory nerve fiber is generated 
</p>
<p>when, in a given cycle, the wave is at its highest pressure level. So there is synchro-
</p>
<p>nization between the pressure change caused by a stimulus and the beginning of 
</p>
<p>nerve activity. This phenomenon is called phase locking. Moreover, a neuron does 
</p>
<p>not have to trigger its activity in each cycle, but when it does, it always happens at 
</p>
<p>the same point in the cycle. This phenomenon also means that there is in the audi-
</p>
<p>tory nerve fiber a temporal code related to a sound wave. Due to the refractory 
</p>
<p>2.5 Theories of Hearing</p>
<p/>
</div>
<div class="page"><p/>
<p>30
</p>
<p>period required for each fiber of the auditory nerve, the temporal coding begins to 
</p>
<p>be a little less reliable for frequencies above 1000 Hz and becomes virtually useless 
</p>
<p>with frequencies above 5000 Hz.
</p>
<p>2.5.2  Theories Based on Location
</p>
<p>The idea of associating the processing of auditory information with a particular 
</p>
<p>place on the basilar membrane is not new. Already in the nineteenth century, the 
</p>
<p>German physiologist Hermann von Helmholtz proposed a theory of &ldquo;the place of 
</p>
<p>resonance&rdquo; to explain the perception of pitch. Knowing that the width of the basilar 
</p>
<p>membrane is not the same everywhere, he believed that, at a given location, the 
</p>
<p>membrane, due to its width, would give a sound of a particular pitch, just like the 
</p>
<p>strings of a piano, being of different lengths, give different notes. The analogy with 
</p>
<p>the piano was proved to be incorrect, but the idea of linking the pitch to a specific 
</p>
<p>place on the basilar membrane remains relevant. It is the basis of the place theory: 
</p>
<p>there is indeed a tonotopic organization of hair cells in the organ of Corti. In other 
</p>
<p>words, there is a spatial coding of frequency. Some frequencies are processed at 
</p>
<p>specific locations on the basilar membrane.
</p>
<p>Nobel Prize laureate in Physiology and Medicine in 1961, physicist Georg von 
</p>
<p>B&eacute;k&eacute;sy described the mechanics inside the cochlea that underlies this spatial encod-
</p>
<p>ing. As we have seen earlier, the basilar membrane is narrow and rigid at the base of 
</p>
<p>the cochlea, and, closer to its apex, it gradually widens and becomes less rigid 
</p>
<p>(Fig. 2.6). Thus, when the stapes transmits the vibrations within the inner ear, this 
</p>
<p>causes a hydrodynamic movement. The sound wave is thus propagated from one 
</p>
<p>end of the basilar membrane to the other. This wave motion along the membrane 
</p>
<p>constitutes the traveling wave.
</p>
<p>The maximum point of displacement of the wave depends on its frequency. 
</p>
<p>Indeed, this maximum point, that is the point where the basilar membrane is the 
</p>
<p>more curved (Fig. 2.7), is nearest to the helicotrema if the frequency is low. The 
</p>
<p>Fig. 2.6 Illustration of the volley principle, with all fibers (A&ndash;F) combined on the bottom curve
</p>
<p>2 Physical and Biological Bases of Hearing</p>
<p/>
</div>
<div class="page"><p/>
<p>31
</p>
<p>wave rapidly reaches its maximum amplitude and then quickly disappears. 
</p>
<p>Conversely, the maximum point of displacement is reached farther away on the 
</p>
<p>basilar membrane if the frequency is high. It is where the membrane is the most 
</p>
<p>curved that the hair cells are the most displaced and generate the highest stimula-
</p>
<p>tion. The waves of different frequencies therefore will have their maximum impact 
</p>
<p>on different parts of the basilar membrane, and the auditory nerve fibers stimulated 
</p>
<p>will transmit their specific information to the auditory cortex.
</p>
<p>This explanation of von B&eacute;k&eacute;sy based on the idea of a traveling wave allows not 
</p>
<p>only to understand the perception of pitch but also the perception of loudness. 
</p>
<p>Loudness would indeed depend on the magnitude of the traveling wave. Greater 
</p>
<p>sound intensity provokes larger movement amplitudes on the basilar membrane. 
</p>
<p>Larger amplitude affects more hair cells and produces greater inclination of these 
</p>
<p>cells; therefore, larger amplitude results in more neural activity.
</p>
<p>Note in closing this section that the frequency theory (volley principle) and the 
</p>
<p>place theory (traveling wave) are both accepted. It is generally recognized that for 
</p>
<p>low frequencies, the volley principle applies (frequency coding), and for high fre-
</p>
<p>quencies, the traveling wave hypothesis applies (spatial coding).
</p>
<p>Frequency
</p>
<p>Low
</p>
<p>Mid-range
</p>
<p>High
</p>
<p>Fig. 2.7 On top, a representation of the basilar membrane (in gray) when the cochlea is unrolled; 
</p>
<p>bottom figures illustrate the different points of maximum displacement of the traveling wave as a 
</p>
<p>function of the sound frequencies
</p>
<p>2.5 Theories of Hearing</p>
<p/>
</div>
<div class="page"><p/>
<p>32
</p>
<p>2.6  Clinical Aspects
</p>
<p>Some breaks in the transmission sequence of the sound wave from the eardrum to 
</p>
<p>the auditory cortex can cause hearing damage. Besides the fact that some diseases 
</p>
<p>can be caused by damage to central auditory pathways or different regions of the 
</p>
<p>auditory cortex&mdash;sometimes called central deafness&mdash;we generally distinguish two 
</p>
<p>categories of hearing loss, depending on the place where the deficit is caused.
</p>
<p>A first category of hearing loss is related to transmission problems (or conduction). 
</p>
<p>Essentially, this type of disorder is mechanical, i.e., the sound wave is not transmitted 
</p>
<p>efficiently to the cochlea. The causes of such a condition are therefore located at the 
</p>
<p>outer ear or in the middle ear. These causes range from an excessive accumulation of 
</p>
<p>wax to the deterioration of the ossicles. Similarly, throat infections, connected by the 
</p>
<p>Eustachian tube to the middle ear, may interfere with the pressure balance in the 
</p>
<p>middle ear and thus reduce the quality of transmission of the sound wave.
</p>
<p>The second type of hearing loss is referred to as sensorineural (or perceptive deaf-
</p>
<p>ness). This problem is caused by deterioration of the cochlea or of the auditory nerve. 
</p>
<p>This deterioration occurs for various reasons such as metabolic problems or trauma. 
</p>
<p>Some medications with toxic properties may also cause this kind of disorder.
</p>
<p>Still about sensorineural hearing loss, it is most relevant to know that this deficit 
</p>
<p>may occur as a result of deterioration of the hair cells located on the organ of Corti 
</p>
<p>in the cochlea. Such deterioration is irreversible and can be caused by exposure to 
</p>
<p>sounds of high intensity. The stronger the sounds&mdash;especially if you are close to the 
</p>
<p>sound source&mdash;the less exposure time it takes to incur permanent damage. Therefore, 
</p>
<p>there is a high price to pay when we offer ourselves this wonderful luxury of listen-
</p>
<p>ing to loud music, often directly from the source using headphones!
</p>
<p>If you are exposed, for instance, to sounds of approximately 85 dB, about 8 h per 
</p>
<p>day, at some point you will affect your hearing. Exposure to loudness causes hear-
</p>
<p>ing fatigue, i.e., a shift of the detection threshold for a given period. The effects are 
</p>
<p>the same, for example, (1) with an exposure to 88-dB sounds for 4 h per day or (2) 
</p>
<p>with an exposure to 100-dB noise for 15 min per day. However, repeated exposure 
</p>
<p>to even louder sounds may cause permanent threshold shift. Note that a loud sound 
</p>
<p>might sound weaker after a few minutes of exposure. This phenomenon is called 
</p>
<p>auditory adaptation.
</p>
<p>The hearing abilities change with age. Indeed, age causes a loss of hearing called 
</p>
<p>presbycusis. In particular, as we get older, the detection threshold for high frequen-
</p>
<p>cies becomes much higher. Consequently, it is possible for young persons to receive 
</p>
<p>an audible signal indicating the arrival of a text message on their phone without an 
</p>
<p>adult of a certain age (e.g., a teacher!) hearing it. It is unlikely that an adult over 40 
</p>
<p>years will hear a sound above 15 kHz or an adult over 50 years will hear a sound 
</p>
<p>above 12 kHz. High frequencies have even been used to get rid of noisy teenagers 
</p>
<p>loitering in a schoolyard.
</p>
<p>Finally, among the quite severe disorders connected somehow to hearing, there 
</p>
<p>is tinnitus. This problem consists of an impression that a sound or noise is present, 
</p>
<p>2 Physical and Biological Bases of Hearing</p>
<p/>
</div>
<div class="page"><p/>
<p>33
</p>
<p>even in the absence of any external auditory stimulation. Tinnitus can sound like 
</p>
<p>whistling or rustling and can be caused by several factors. The sound may be con-
</p>
<p>tinuous or intermittent and is usually rather acute. Tinnitus can indicate the presence 
</p>
<p>of a hearing disorder caused by damage to the cochlea, for example, or occur after 
</p>
<p>noise trauma or during an infection.
</p>
<p>2.6 Clinical Aspects</p>
<p/>
</div>
<div class="page"><p/>
<p>35&copy; Springer International Publishing Switzerland 2016 
</p>
<p>S. Grondin, Psychology of Perception, DOI 10.1007/978-3-319-31791-5_3
</p>
<p>    Chapter 3   
</p>
<p> Hearing                     
</p>
<p>             Understanding how we hear cannot be reduced to a mere description of facts based 
</p>
<p>on physics and on a description of the structures of the ear or brain involved in hear-
</p>
<p>ing. What we hear is full of shades and impressions. These shades come in particu-
</p>
<p>lar from the way of organizing the auditory information that reaches the ear, this 
</p>
<p>organization being based on certain principles. We also use cues to fi nd out where 
</p>
<p>sounds are coming from. Just as if all this was not mysterious enough, some sounds 
</p>
<p>appear clearly identifi able as speech sounds, while other sounds clearly appear as 
</p>
<p>part of a musical structure. The purpose of this chapter is to understand these sets of 
</p>
<p>auditory phenomena. 
</p>
<p>3.1     Perceptual Organization 
</p>
<p> As we will see in the study of vision, major principles revealing how visual percep-
</p>
<p>tion is organized have been uncovered almost a century ago. The development on 
</p>
<p>the perceptual organization in audition came a little later. Albert Bregman has con-
</p>
<p>tributed greatly to the development of this facet of the hearing, particularly with the 
</p>
<p>publication of his book  Auditory Scene Analysis , which provides a solid synthesis 
</p>
<p>of the principles underlying this organization (Bregman,  1990 ). 
</p>
<p> A series of illusions or auditory effects show that the link between what is pre-
</p>
<p>sented and what is heard is not always straightforward. The brain has to deal with 
</p>
<p>the entire context in which the stimuli are arriving. In particular, the extent to which 
</p>
<p>stimuli are similar and arrive more or less at the same time determines what is heard. </p>
<p/>
</div>
<div class="page"><p/>
<p>36
</p>
<p>3.1.1     Streaming 
</p>
<p>  The organization of  auditory   information is the perceptual integration and segrega-
</p>
<p>tion of the auditory material of the environment in signifi cant auditory representa-
</p>
<p>tions (Snyder &amp; Alain,  2007 ). When there are many sounds in the environment that 
</p>
<p>arrive simultaneously or in rapid succession, it is necessary that elements be 
</p>
<p>grouped, integrated, and merged into the same &ldquo;sound object,&rdquo; just like other com-
</p>
<p>ponents of the auditory environment that have to be segregated and assigned to dif-
</p>
<p>ferent &ldquo;objects.&rdquo; Indeed, while the sound may sometimes refer to the physical 
</p>
<p>stimulation in the environment or to the experience extracted from it by an observer, 
</p>
<p>Bregman will use the term  stream  to describe the perceptual unit forming an object. 
</p>
<p>The stream, or auditory line, is the psychological experience in audition that could 
</p>
<p>be compared to the notion of object in vision. 
</p>
<p> The auditory stream allows the grouping of related acoustical qualities; it is 
</p>
<p>based on the relationships that one perceives between successive sounds. The con-
</p>
<p>cept of grouping is central to the idea covered by this notion of stream. A musical 
</p>
<p>melody and the sounds of successive and regular footsteps are striking examples of 
</p>
<p>impressions of streams. In the environment, there are many changes of sound inten-
</p>
<p>sities and frequencies and changes of source locations and several temporal irregu-
</p>
<p>larities. However, the proximity of the frequencies of different sounds and their 
</p>
<p>patterns over time are very strong factors leading to the formation of streams 
</p>
<p>because they give the impression that the sounds go together. 
</p>
<p> So, if two sounds of different frequencies are presented in succession repeatedly, 
</p>
<p>they are spontaneously grouped and perceived as parts of the same structure, or of 
</p>
<p>the same stream, if these frequencies are not too far apart from each other (Fig.  3.1 , 
</p>
<p>upper panels). However, if these frequencies are too distant from each other 
</p>
<p>(Fig.  3.1 , lower panels), the sounds are segregated as if they would belong to distinct 
</p>
<p>streams (Miller,  1947 ).
</p>
<p>   Along the same line, it is possible to generate an impression of rhythm, like gal-
</p>
<p>loping, for instance, when the fi rst and third sounds of a sequence of three have the 
</p>
<p>same frequency, while the second one has a different frequency (Fig.  3.2 ). This 
</p>
<p>effect occurs when the three sounds are close in time (van Noorden,  1975 ). If this 
</p>
<p>sequence is heard twice, but the frequency of the fi rst and third sounds becomes 
</p>
<p>quite different from that of the second sound, the galloping impression disappears 
</p>
<p>and two distinct streams are heard. 
</p>
<p>3.1.2        Illusion of Continuity and Gap Transfer 
</p>
<p>     The  illusion of continuity is also   an important element contributing to the auditory 
</p>
<p>scene. This illusion consists of a sound interrupted by a silent gap, but a sound for 
</p>
<p>which we perceive continuity when  the   gap is fi lled with more intense noise 
</p>
<p>(Fig.  3.3 ). Thus, the presence of a loud  noise   instead of a silent gap gives the impression 
</p>
<p>3 Hearing</p>
<p/>
</div>
<div class="page"><p/>
<p>37
</p>
<p>that the sound,  though   interrupted, is continuous. This illusion is essentially a sound 
</p>
<p>restoration, and such restoration effects also occur for speech and music (Sasaki, 
</p>
<p> 1980 ; Warren,  1970 ). For instance, the missing parts in a sentence could prevent 
</p>
<p>someone from understanding its meaning, but replacing these parts by noises would 
</p>
<p>allow recovering the meaning.
</p>
<p>   Another phenomenon showing how an auditory scene is organized is called the 
</p>
<p> gap transfer  illusion. It differs from the previous illusion, although it also implies an 
</p>
<p>impression of continuity. This time, the illusion occurs when sounds are continu-
</p>
<p>ously changing in frequency. As illustrated in Fig.  3.4 , the illusion can be generated 
</p>
<p>with two sounds of different durations, having a frequency progression in opposite 
</p>
<p>directions and intersecting at their center. If the longer segment is interrupted, the 
</p>
<p>interruption is perceived as belonging to the shorter one. In other words, even if, 
</p>
<p>physically, the short sound is continuous, it is this sound that will be perceived as 
</p>
<p>  Fig. 3.1    Segregation of auditory stream as a function of the proximity of the frequencies and of 
</p>
<p>the proximity in time. Two sounds of different frequencies, which are alternately repeated, are 
</p>
<p>perceived as if they were two streams ( b ), rather than only one ( a ), when the frequencies are quite 
</p>
<p>distant from each other ( F  is large). Segregation is facilitated when the sounds of the same fre-
</p>
<p>quency are much closer to each other in time ( T  is small)       
</p>
<p>  Fig. 3.2     Left : impression of gallop caused by proximity in time and frequency.  Right : if the fre-
</p>
<p>quency of the fi rst and third sounds is too far from the frequency of the second, the gallop impres-
</p>
<p>sion is replaced by the impression that there are two separate streams       
</p>
<p> 
</p>
<p> 
</p>
<p>3.1 Perceptual Organization</p>
<p/>
</div>
<div class="page"><p/>
<p>38
</p>
<p>  Fig. 3.3    The illusion of  auditory continuity  . A sound with a silent interruption ( a ) is perceived as 
</p>
<p>being continuous when the interruption is fi lled with another sound ( b ). The occurrence of this 
</p>
<p>illusion is possible only when the sound inserted is more intense than the discontinuous sound       
</p>
<p>  Fig. 3.4    Illustration of the  gap transfer illusion  . At the perceptual level, the interruption is assigned 
</p>
<p>to the short rather than to the long segment, as is the case physically (see Nakajima et al.,  2000 )       
</p>
<p> 
</p>
<p> 
</p>
<p>3 Hearing</p>
<p/>
</div>
<div class="page"><p/>
<p>39
</p>
<p>interrupted (Nakajima et al.,  2000 ). 1  Indeed, although it is the longer sound that is 
</p>
<p>interrupted, it keeps being perceived as continuous. In brief, the long and short 
</p>
<p>sounds are physically continuous and discontinuous, respectively, but are rather per-
</p>
<p>ceptually perceived as discontinuous and continuous, respectively.
</p>
<p>   It is interesting to note the following special case of gap transfer illusion. It can 
</p>
<p>be generated with a synthetic sound, the letter /a/, where a long /a/ and a short /a/ 
</p>
<p>intersect, and where, as was the case earlier, the long sound is interrupted. Once 
</p>
<p>again, it is the long sound that appears to be continuous and the short one that seems 
</p>
<p>discontinuous. However, this illusion does not occur if different vowels intersect 
</p>
<p>(Kuroda, Nakajima, Tsunashima, &amp; Yasutake,  2009 ). If the vowel /i/ is short and 
</p>
<p>intersects with a long /a/, it is the latter that will be perceived as interrupted and the 
</p>
<p>/i/ will be perceived as continuous. In other words, there is an agreement between 
</p>
<p>the physical properties of the stimuli and what is perceived. Consequently, no gap 
</p>
<p>transfer illusion occurs. Indeed, the illusion with synthetic vowels occurs only when 
</p>
<p>both sounds are identical vowels or have the same spectral structure. 
</p>
<p> There are, of course, many other auditory special effects. One of the most classic 
</p>
<p>ones is the Shepard staircase which consists of a series of looping tones appearing 
</p>
<p>to increase in frequency continuously. The same effect can be obtained in the oppo-
</p>
<p>site direction: an impression that the frequency of the sound appears to decrease 
</p>
<p>without interruption, even if it is a sound loop that is used (see Deutsch,  2010  2 ). 
</p>
<p>Indeed, this illusion could be compared to that proposed by Penrose for vision, but 
</p>
<p>in the auditory modality (Fig.  3.5 , Penrose &amp; Penrose,  1958 ). In this visual illusion, 
</p>
<p>it is possible to imagine someone going upstairs forever or downstairs forever.    
</p>
<p>3.2         Sound Location 
</p>
<p>  For some species,  hearing is to   some extent a way to see, and this is due to the effi -
</p>
<p>ciency for localizing what is present in the environment. This capability is called 
</p>
<p>echolocation and can occur in the air, as for bats, or in water, as for dolphins. 
</p>
<p> In humans, the ability to localize sounds in space is perhaps not as critical or vital as 
</p>
<p>it is for other animals. However, this ability contributes to the production of fi ne repre-
</p>
<p>sentations of what surrounds us in the auditory environment. It is possible, by using 
</p>
<p>several cues, to obtain quite accurate information concerning which direction sounds 
</p>
<p>are coming from and, to some extent, how far away the source of these sounds is.  
</p>
<p>1   It is possible to get interesting demonstrations of different acoustical effects, for instance: 
</p>
<p> Bregman, A. S., &amp; Ahad, P. A. (1996).  Demonstrations of auditory scene analysis: The percep-
</p>
<p>tual organization of sound  [CD]. Cambridge, MA: MIT Press. 
</p>
<p> Moreover, it is possible to access these demonstrations on different web sites. We 
</p>
<p>recommend: 
</p>
<p> Nakajima, Y. (2000).  Demonstrations of auditory illusions and tricks  (2nd ed.) [ http://www.
</p>
<p>design.kyushuu.ac.jp/~ynhome/ENG/Demo/illusions2nd.html ]. 
2   The reader is invited to discover several acoustical illusions or auditory paradoxes on Diana 
</p>
<p>Deutsch&rsquo;s web site: [ http://deutsch.ucsd.edu/psychology/pages.php?i=201#Introduction.php ]. 
</p>
<p>3.2 Sound Location</p>
<p/>
<div class="annotation"><a href="http://www.design.kyushuu.ac.jp/~ynhome/ENG/Demo/illusions2nd.html">http://www.design.kyushuu.ac.jp/~ynhome/ENG/Demo/illusions2nd.html</a></div>
<div class="annotation"><a href="http://www.design.kyushuu.ac.jp/~ynhome/ENG/Demo/illusions2nd.html">http://www.design.kyushuu.ac.jp/~ynhome/ENG/Demo/illusions2nd.html</a></div>
<div class="annotation"><a href="http://deutsch.ucsd.edu/psychology/pages.php?i=201#Introduction.php">http://deutsch.ucsd.edu/psychology/pages.php?i=201#Introduction.php</a></div>
</div>
<div class="page"><p/>
<p>40
</p>
<p>3.2.1     Location of Direction 
</p>
<p>  If you close your eyes  and   listen to what is around you, localizing sounds may seem 
</p>
<p>so obvious to you that you may even wonder if there is any need to study the ques-
</p>
<p>tion. If you hear footsteps, the sound of shoes or heels on a hard surface, you will 
</p>
<p>rapidly be informed, without looking, that a person approaches or moves away from 
</p>
<p>you. As well, if someone wishes to capture your attention by calling you by your 
</p>
<p>name, you will very likely turn your head in the right direction. You will know if the 
</p>
<p>sound comes from the left or from the right, on a horizontal plane, and you will also 
</p>
<p>know if it comes from above or below. You will turn automatically in the direction of 
</p>
<p>the sound source, probably to direct your gaze toward it. This capacity is due in part 
</p>
<p>to the pinna as it contributes, for instance, to the localization of high-frequency 
</p>
<p>sounds (Musicant &amp; Butler,  1984 ) and to providing cues that the brain can interpret. 
</p>
<p> A powerful cue for knowing the direction a sound is coming from is related to 
</p>
<p>the arrival time to each ear. This cue, called   interaural time difference   , is based on 
</p>
<p>the fact that sounds from one source often arrive at a different time to each ear. 
</p>
<p>Sounds emitted from your right arrive at your right ear before reaching the left 
</p>
<p>ear. This difference may seem minimal, given the small distance between the ears 
</p>
<p>(the size of one&rsquo;s head). Nevertheless, the brain fi nds a way to use this difference 
</p>
<p>and to extract some meaning of it. If the sound reaches your left ear fi rst, the brain 
</p>
<p>will conclude that the sound source is closer to your left ear than to your right ear. 
</p>
<p>This cue is particularly effective for locating low-frequency sounds (Wightman &amp; 
</p>
<p>Kistler,  1992 ). 
</p>
<p> That said, in addition to the arrival time in each ear, per se, the brain also takes 
</p>
<p>into account, for locating sounds, the point of the cycle at which a sound reaches 
</p>
<p>each ear. This cue, called the   phase difference    to each ear, would also contribute to 
</p>
<p>the localization of low-frequency sounds. 
</p>
<p> Another important cue for localizing sounds is provided by the fact that they do 
</p>
<p>not necessarily arrive at each ear with the same intensity. This phenomenon can be 
</p>
<p>easily demonstrated. Ask someone speaking loudly to you, directly into your left or 
</p>
<p>  Fig. 3.5    Visual illustration 
</p>
<p>of  Shepard&rsquo;s auditory 
</p>
<p>illusion   with a classic 
</p>
<p>visual illusion, the 
</p>
<p>impossible Penrose stairs       
</p>
<p> 
</p>
<p>3 Hearing</p>
<p/>
</div>
<div class="page"><p/>
<p>41
</p>
<p>into your right ear. You will soon discover the need to mute the sound on one side 
</p>
<p>more than on the other side! Along the same line, if you are walking on a sidewalk 
</p>
<p>and a noisy motorcycle or a fi re truck with a high-pitch siren is near you, or if a 
</p>
<p>worker is using a jackhammer nearby, you will quickly understand that one ear, the 
</p>
<p>one closest to the noise source, needs more protection than the other. 
</p>
<p> Indeed, the intensity difference at each ear when a sound arrives directly from 
</p>
<p>one side is due to the fact that the head causes what is called a partial sound shadow. 
</p>
<p>This shadow, which allows an attenuation of sound intensity, is most effective for 
</p>
<p>higher frequencies. Moreover, because humans do not have a mobile pinna as some 
</p>
<p>other species do, it remains possible to rotate the head in one direction or another 
</p>
<p>for localizing sounds more effi ciently. Such movements produce slight variations in 
</p>
<p>relative intensities or arrival times to each ear, improving the capability to determine 
</p>
<p>where the sound comes from. 
</p>
<p> If experimental conditions are set so that the interaural time difference and the 
</p>
<p>interaural intensity difference or the pinna provide contradictory information, the 
</p>
<p>information based on the interaural time difference will prevail if the sound includes 
</p>
<p>low-frequency components. Without low frequencies, the apparent direction of 
</p>
<p>sounds will be based on the intensity differences or the pinna (Wightman &amp; Kistler, 
</p>
<p> 1992 ). The term   head transfer function    is used to describe the cues based on binau-
</p>
<p>ral perception, the differences in intensity in each ear being much greater than the 
</p>
<p>time difference when the sound source is nearby, i.e., less than one meter away 
</p>
<p>(Brungart, Durlach, &amp; Rabinowitz,  1999 ).   
</p>
<p>3.2.2     Location of Distance 
</p>
<p>  It is possible to get  quite   an accurate idea of the direction a sound is coming from; 
</p>
<p>however, estimating accurately the distance from a sound source is quite diffi cult. 
</p>
<p>Determining roughly whether the source is near or far is relatively easy, but quanti-
</p>
<p>fying the actual distance is a much more diffi cult exercise, and we rarely try. We do 
</p>
<p>try to determine, for example, whether the thunderclap we have just heard is more 
</p>
<p>or less distant. Indeed, the intensity of a sound reveals right away if it is more or less 
</p>
<p>distant, a loud sound being most often very close. If you know the intensity at the 
</p>
<p>sound source, it becomes possible to get a good approximation of the distance based 
</p>
<p>on the perceived intensity. 
</p>
<p> Indeed, the function linking the loudness and the distance,  D , between the source 
</p>
<p>and an observer is the following one: 1/ D  2 . Because sound pressure is a function of 
</p>
<p>the square root of intensity, the pressure decreases with the distance according to the 
</p>
<p>equation 1/ D . Consequently, this results in the following simple rule: sound pres-
</p>
<p>sure decreases by about 6 dB every time the distance between an observer and a 
</p>
<p>sound source is doubled. This relationship, 1/ D , holds however only under special 
</p>
<p>circumstances. First, it does not apply when an observer is very close to the source 
</p>
<p>(Butler, Levy, &amp; Neff,  1980 ). Moreover, it applies only where the sound is emitted 
</p>
<p>3.2 Sound Location</p>
<p/>
</div>
<div class="page"><p/>
<p>42
</p>
<p>from a specifi c place and in free-fi eld environments, i.e., free of obstructions. These 
</p>
<p>conditions are indeed rarely the ones encountered in daily life. 
</p>
<p> Another very important cue can be used for revealing the distance separating an 
</p>
<p>observer from a sound source. This cue is the ratio of the amount of sound arriving at 
</p>
<p>the ear directly from a sound source and the amount of sound arriving at the ear after 
</p>
<p>hitting an obstacle. Reverberations are sounds that have bounced after hitting a surface, 
</p>
<p>before reaching the ear. When the environment is fi lled with more reverberations, it 
</p>
<p>leads to an impression of echo. This is a distinctive quality that can be perceived. As the 
</p>
<p>distance between an observer and a sound source increases, the presence of obstacles 
</p>
<p>along the way becomes more likely. Thus, the ratio between the sounds coming directly 
</p>
<p>from the source and those from reverberations decreases as the distance between the 
</p>
<p>source and the observer increases (Larsen, Iyer, Lansing, &amp; Feng,  2008 ). 
</p>
<p> Indeed, sounds consisting mainly of high frequencies seem to arrive from a near- 
</p>
<p>distance source, whereas those consisting mainly of low frequencies seem to come 
</p>
<p>from farther away. This could be easily understood considering that high frequen-
</p>
<p>cies are more easily blocked when obstacles are on the way between the source and 
</p>
<p>the ear. Considering how distance affects the quality of sound, and considering the 
</p>
<p>important differences of sound intensities with distance, one can easily imagine 
</p>
<p>how diffi cult it is to build concert halls or sport centers that would preserve a high 
</p>
<p>quality of sounds for everyone seating in such buildings. 
</p>
<p> Everyday life is also fi lled with several acoustic phenomena that one might well 
</p>
<p>encounter at some moment. Frequency changes occurring with moving cars or 
</p>
<p>trucks with a siren (police or ambulance) generate a special auditory impression 
</p>
<p>called the  Doppler effect  . Indeed, sounds are rarely static. Sound sources are often 
</p>
<p>moving, and sometimes, it is the observer that is moving. As a car approaches, fre-
</p>
<p>quencies sound higher than they really are; nearby, there are no inconsistencies 
</p>
<p>between what is emitted and what is perceived, but as the car moves away, perceived 
</p>
<p>frequencies seem lower than they really are. 
</p>
<p> Considering that the perception of distance in everyday life depends heavily on 
</p>
<p>vision, it is not surprising to see the large infl uence exerted by this sensory mode on 
</p>
<p>the impression of distance or direction of sound sources. You likely know the phe-
</p>
<p>nomenon called   ventriloquism   , which refers, for instance, to the impression that a 
</p>
<p>voice comes from the mouth of a puppet moving lips, even though you know that 
</p>
<p>the voice does not come from that mouth: it comes from a source nearby, the pup-
</p>
<p>peteer. Along the same line, even though the voices in cinema or on television do 
</p>
<p>not come from the mouth of the characters&rsquo; moving lips, but from speakers located 
</p>
<p>nearby, you rarely experience the impression that the sound does not come from the 
</p>
<p>person talking, except if the movements of the lips and the arrival of the sounds are 
</p>
<p>not well synchronized. 
</p>
<p> Note fi nally that we sometimes get the impression that thunder and lightning, 
</p>
<p>which are indeed occurring together, at the same moment, are not synchronized. 
</p>
<p>That could be explained by the fact that the sound travels more slowly than light. If 
</p>
<p>lightning is far away, the gap between thunder and lightning is great. Indeed, if you 
</p>
<p>ever feel that this gap is getting smaller after a few minutes, you can conclude that 
</p>
<p>lightning is getting closer to you.    
</p>
<p>3 Hearing</p>
<p/>
</div>
<div class="page"><p/>
<p>43
</p>
<p>3.3     Hearing Music 
</p>
<p> Sometimes, a series of consecutive  sounds   simply produce noise. But on some occa-
</p>
<p>sions, a series of sounds produce what is called music. Whether or not it is music, 
</p>
<p>these sounds could be described on the basis of their pitch, loudness, and timbre. 
</p>
<p>But why do certain sounds result in an impression of music? They need to be linked 
</p>
<p>according to some specifi c structure. 
</p>
<p>3.3.1     Technical Description 
</p>
<p>  While sounds usually  vary   according to their pitch, musical pitch is particular as it 
</p>
<p>falls on a chromatic scale. The musical pitch has a certain height (for instance, a 
</p>
<p>more or less high pitch) and is located somewhere (the note) on an octave. The 
</p>
<p>octave is an interval separating eight notes and is composed of 12 semitones. For a 
</p>
<p>given note, the ratio from one octave to another in terms of frequencies is simple: it 
</p>
<p>doubles or is divided by two. In brief, sounds that are one octave apart have the same 
</p>
<p>name. 
</p>
<p> Indeed, the magic of music is that two sounds separated by one octave seem 
</p>
<p>similar. For instance, if one plays eight consecutive notes on a keyboard (do, re, mi, 
</p>
<p>fa, sol, la, ti, do or C, D, E, F, G, A, B, C), one octave is covered (note that D to D, 
</p>
<p>E to E, etc. also covers one octave). Even if the frequency of one C is much higher 
</p>
<p>than that of another C, we can recognize the similarity between these two notes. 
</p>
<p>However, although F and G are on the same octave and are very close to each other, 
</p>
<p>we do not recognize them as quite similar. But if two different Gs are played 
</p>
<p>together, they are not dissonant. When describing musical sounds, it not suffi cient 
</p>
<p>to only talk about the fact that they are more or less high pitches. There is a need to 
</p>
<p>take into account the fact that they do have some similarity, a feature referred to as 
</p>
<p>  chroma   . 
</p>
<p> Figure  3.6  illustrates the range of frequencies covered by the piano. This fi gure 
</p>
<p>identifi es the notes, their frequency, and the ranges of frequencies covered by cer-
</p>
<p>tain musical instruments and human voices. A human voice can hardly cover more 
</p>
<p>than two octaves, but humans can nevertheless hear, as indicated in Chap.   2    , sounds 
</p>
<p>ranging roughly from 20 Hz to 20 kHz, i.e., ten octaves.
</p>
<p>   A chord is the superposition of more than two sounds according to certain rules. 
</p>
<p>It is only in the middle of the sixteenth century that the notion of interval was 
</p>
<p>replaced by the notion of chord (Honegger,  1976 ). Nowadays, the impression of 
</p>
<p>music and the psychological impression left by a chord do not correspond at all to 
</p>
<p>the impression that would give only two of the notes of a chord. In other words, if a 
</p>
<p>chord consists in notes C, E, and G, it cannot be reduced to the succession of C with 
</p>
<p>G, C with E, and E with G. 
</p>
<p> We should count for instance dynamics and rhythm among the other important 
</p>
<p>concepts that contribute to shape the impression of music. The former is the difference 
</p>
<p>3.3 Hearing Music</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-31791-5_2">http://dx.doi.org/10.1007/978-3-319-31791-5_2</a></div>
</div>
<div class="page"><p/>
<p>44
</p>
<p>  F
ig
</p>
<p>. 
3
.6
</p>
<p>  
  R
</p>
<p>an
g
e 
</p>
<p>o
f 
</p>
<p>fr
eq
</p>
<p>u
en
</p>
<p>ci
es
</p>
<p> c
o
v
er
</p>
<p>ed
 b
</p>
<p>y
 t
</p>
<p>h
e 
</p>
<p>p
ia
</p>
<p>n
o
 a
</p>
<p>n
d
 c
</p>
<p>o
m
</p>
<p>p
ar
</p>
<p>is
o
n
 w
</p>
<p>it
h
 h
</p>
<p>u
m
</p>
<p>an
 v
</p>
<p>o
ic
</p>
<p>es
 a
</p>
<p>n
d
 o
</p>
<p>th
er
</p>
<p> m
u
si
</p>
<p>ca
l 
</p>
<p>in
st
</p>
<p>ru
m
</p>
<p>en
ts
</p>
<p>. 
F
</p>
<p>o
r 
</p>
<p>ea
ch
</p>
<p> n
u
m
</p>
<p>b
er
</p>
<p> (
1
&ndash;
8
8
) 
</p>
<p>u
n
d
er
</p>
<p> 
</p>
<p>th
e 
</p>
<p>k
ey
</p>
<p>b
o
ar
</p>
<p>d
, 
th
</p>
<p>er
e 
</p>
<p>is
 a
</p>
<p> n
u
m
</p>
<p>b
er
</p>
<p> i
n
d
ic
</p>
<p>at
in
</p>
<p>g
 t
</p>
<p>h
e 
</p>
<p>fr
eq
</p>
<p>u
en
</p>
<p>cy
 o
</p>
<p>f 
th
</p>
<p>e 
n
o
te
</p>
<p> (
in
</p>
<p> H
z)
</p>
<p>       
</p>
<p> 
</p>
<p>3 Hearing</p>
<p/>
</div>
<div class="page"><p/>
<p>45
</p>
<p>between the levels of loudness. Musicians sometimes refer to shade or musical contrast 
</p>
<p>when describing dynamics. Rhythm designates the perceptual organization over time; 
</p>
<p>it is closely linked to the duration of relatively short or long successive notes. Several 
</p>
<p>expressions are used in order to designate the duration of a note (e.g., quaver, quarter, 
</p>
<p>half, whole). Given the ubiquity of time in music, it is not surprising that musicians are 
</p>
<p>better than nonmusicians for detecting slight temporal differences in musical excerpts 
</p>
<p>(Grondin &amp; Laforest,  2004 ) or for keeping track of time by counting or singing 
</p>
<p>(Grondin &amp; Killeen,  2009 ). Note that rhythm and tempo should not be confused. The 
</p>
<p>latter term refers to the speed used for performing a musical piece. For instance, tempo 
</p>
<p>could be  allegro  or  adagio , the Italian terms for fast and slow tempi, respectively. 
</p>
<p> A series of very brief elements can form a leitmotiv, which provides a character-
</p>
<p>istic to what is called a musical phrase. On a more global scale, a melody is formed 
</p>
<p>by the successive pitch variations of the different notes. Consequently, a melody is 
</p>
<p>not perceived as a series of successive individual and distinct sounds, but rather as 
</p>
<p>coherent entity or whole. This idea of whole is not without reminding the principles 
</p>
<p>of sound organization, described earlier, and the organization of form that will be 
</p>
<p>described in Chap.   6     on the visual perception of form.   
</p>
<p>3.3.2     Subjective Experience 
</p>
<p>  Liking or disliking a  given   combination of sounds that can be easily recognized as 
</p>
<p>being music does not depend just on the fact of using some particular physical fea-
</p>
<p>tures. Many factors contribute to the subjective appreciation of music. The specifi c 
</p>
<p>musical tradition and habits are some of these factors. At an individual level, habits 
</p>
<p>are particularly critical, which does not prevent from remaining open to new musi-
</p>
<p>cal styles. Indeed, habit generates familiarity, which sometimes turns out to be 
</p>
<p>determinant. Just consider how many times you may not have liked a musical piece 
</p>
<p>the fi rst time you listened to it, but fi nally liked it after a few repetitions. It is much 
</p>
<p>easier to appreciate a given voice or musical style when you can recognize it. What 
</p>
<p>might sound like great music for those used to a given style may well sound disso-
</p>
<p>nant for those less familiar with this style. 
</p>
<p> Restricting music appreciation to familiarity would leave the explanation incom-
</p>
<p>plete; the concept of music complexity is also critical here. When listening to it for 
</p>
<p>the fi rst time, it is quite diffi cult to really appreciate a complex piece such as the 
</p>
<p>ones we often fi nd in the classical music repertoire without having received some 
</p>
<p>training, or education, for this musical style. Indeed, the more complex a piece is, 
</p>
<p>the more time it takes (several repetitions) before being in a position to appreciate it 
</p>
<p>fully. The good news though is that once you like it, it should last longer. It is 
</p>
<p> noteworthy that musical appreciation is tightly associated with emotion and mem-
</p>
<p>ory. In this context, it is not surprising that different forms of music therapy exist, 
</p>
<p>i.e., therapeutic approaches developed for exploiting the power of evocation of 
</p>
<p>music in clinical psychology. 
</p>
<p>3.3 Hearing Music</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-31791-5_6">http://dx.doi.org/10.1007/978-3-319-31791-5_6</a></div>
</div>
<div class="page"><p/>
<p>46
</p>
<p> Curiously enough, some people seem unable to enjoy music when they hear it. 
</p>
<p>This condition is known as   amusia    (Peretz &amp; Hyde,  2003 ). In general, amusia is a 
</p>
<p>disorder in pitch processing, but for some people, the problem is also related to 
</p>
<p>memory and music recognition defi cits. Indeed, congenital amusia and acquired 
</p>
<p>amusia should be distinguished. Approximately 4 % of the population suffer from 
</p>
<p>congenital amusia. These people are born with a kind of deafness to pitch that leads 
</p>
<p>to the inability to recognize or hum a song. That said, the most frequent cause of 
</p>
<p>amusia remains acquired, and its occurrence is due to brain damage. 
</p>
<p> Finally, among the most noticeable individual differences in music perception, 
</p>
<p>one is quite spectacular: some people are able to identify the specifi c note that is 
</p>
<p>heard when presented with a sound. They know whether it was a G or a D, for 
</p>
<p>instance, that was presented. The term used to describe this specifi c quality is   per-
</p>
<p>fect pitch   ; these people have perfect pitch.    
</p>
<p>3.4     Hearing Speech 
</p>
<p> Because we use language on a daily basis, and likely because we learn and integrate 
</p>
<p>it very early in our life, we tend to take for granted the capacity for understanding 
</p>
<p>and producing language. However, producing the sounds of language and being 
</p>
<p>capable  to   hear these sounds and extract of them something meaningful are highly 
</p>
<p>sophisticated skills. Speech sounds are often mispronounced for several reasons, 
</p>
<p>including a strong accent from a region or another country or because the person 
</p>
<p>speaking is 3 or 93 years old. Speech sounds can also be pronounced very rapidly or 
</p>
<p>in the context where there is an important background noise; nevertheless, most 
</p>
<p>often we can extract sense. 
</p>
<p>3.4.1     Linguistic Description 
</p>
<p>  The fi eld of phonetics  covers   the acoustical study of speech sounds. Each language 
</p>
<p>contains a certain number of basic useful units for communicating. These units are 
</p>
<p>called  phonemes  . A phoneme is an abstract unit, a speech segment which in itself 
</p>
<p>has no meaning but contributes with other phonemes to generating meaningful 
</p>
<p>sounds. It is neither a letter nor a syllable. Each language counts a certain number 
</p>
<p>of phonemes, but it is diffi cult to quantify precisely the exact number. For instance, 
</p>
<p>it is often reported that there are 36 phonemes in French, but some authors rather 
</p>
<p>report that there are close to 40 considering the regional disparities in the way of 
</p>
<p>pronouncing sounds. A total of 44 phonemes are reported for English, if diphthongs 
</p>
<p>are included in the count. 
</p>
<p> The way of pronouncing sounds does not always correspond to the way of spell-
</p>
<p>ing them. Consequently, there is a particular way to make a written report of pho-
</p>
<p>nemes that is referred to as the International Phonetic Alphabet. This notation was 
</p>
<p>3 Hearing</p>
<p/>
</div>
<div class="page"><p/>
<p>47
</p>
<p>devised by the International Phonetic Association. By convention, the words tran-
</p>
<p>scribed in phonetic are placed within brackets and phonemes are presented within 
</p>
<p>slashes. Phonemes of the French language are presented with the phonetic alphabet 
</p>
<p>in Table  3.1  and in Table  3.2  for English language. Although six written vowels (A, 
</p>
<p>E, I, O, U, Y) exist for French and English, there exist 16 phonetic vowels in French 
</p>
<p>and 20 in English. Note that both French and English, for instance, also use pho-
</p>
<p>neme coming from foreign languages (for instance, the &ldquo;j&rdquo; in Spanish).
</p>
<p>    It is on the basis of  phonemes   in a language that all words in that language can 
</p>
<p>be built. Thus, it becomes possible to generate all words of English language with 
</p>
<p>44 sounds, phonemes, due to the sole combination between them. There exist hun-
</p>
<p>dreds of other phonemes in other languages (for instance, there are 77 phonemes in 
</p>
<p>Lithuanian), but they are not useful for describing words in English. Also, some 
</p>
<p>distinctions like the one between /l/ and /r/, so useful in English or French, will not 
</p>
<p>be helpful in Japanese. In other words, Japanese people might not be able to distin-
</p>
<p>guish &ldquo;fried rice&rdquo; from &ldquo;fl ied lice.&rdquo; 
</p>
<p> It is also useful to know that words can be divided on the basis of the units of 
</p>
<p>sense they are made of. These units are called  morphemes  . There is only one 
</p>
<p> morpheme in a word like &ldquo;accept,&rdquo; but &ldquo;unacceptable&rdquo; includes three morphemes: 
</p>
<p>un- accept- able. Morphemes are reported to be free if they can constitute a word, as 
</p>
<p>is the case for &ldquo;accept&rdquo; but are linked if they do not form a word by themselves, as 
</p>
<p>is the case for the &ldquo;un&rdquo; of unacceptable.   
</p>
<p>   Table 3.1    Thirty-six phonemes of French language (from Le Petit Larousse illustr&eacute;  2011 )   
</p>
<p> Voyelles  Consonnes  Semi-voyelles (ou semi-consonnes) 
</p>
<p>  Voyelles orales  
</p>
<p> [i]  i  (hab i t)  [p]  p  ( p as)  [j]  y  (l i eu) 
</p>
<p> [e]  &eacute;  (th &eacute; )  [t] t (lutte)  [ɥ]  u  (l u i) 
</p>
<p> [ɛ]  &egrave;  (proc &egrave; s)  [k]  c ,  k ,  qu  ( k &eacute;pi)  [w]  ou  ( ou i) 
</p>
<p> [a]  a  ( a voir)  [b]  b  ( b eau) 
</p>
<p> [ɑ]  a  ( &acirc; ne)  [d]  d  ( d os) 
</p>
<p> [ɔ]  o  (r o be)  [g]  g  ( g are) 
</p>
<p> [o]  o (d o s)  [f]  f  ( f ou) 
</p>
<p> [u]  ou  ( ou vrir)  [v]  v  ( v ite) 
</p>
<p> [y]  u  ( u ser)  [s]  s  (cha ss e) 
</p>
<p> [&oslash;]  eu  (f eu )  [z]  z ,  s  (rai s on) 
</p>
<p> [œ]  eu  (p eu r)  [ʃ]  ch  ( ch eval) 
</p>
<p> [ə]  e  (l e )  [ʒ]  j ,  g  ( j ambe) 
</p>
<p> [l]  l  ( l arge) 
</p>
<p>  Voyelles nasales   [r]  r  ( r ude) 
</p>
<p> [ɛ̃]  in  (p ain )  [m]  m  ( m aison) 
</p>
<p> [œ ̃]  un  (parf um )  [n]  n  ( n ourrir) 
</p>
<p> [ɑ̃]  an ,  en  (bl an c)  [ɲ]  gn  (agneau) 
</p>
<p> [ɔ]̃  on  (b on ) 
</p>
<p>3.4 Hearing Speech</p>
<p/>
</div>
<div class="page"><p/>
<p>48
</p>
<p>3.4.2     Technical Analysis 
</p>
<p>  Sounds of language are  produced   by the passage of air in the nasal cavity, in the 
</p>
<p>mouth, and in the throat and by the work of the tongue and lips. An open respiratory 
</p>
<p>channel leads to the production of vowels, whereas closing movements are associ-
</p>
<p>ated with the production of consonants. Indeed, there are three characteristics for 
</p>
<p>distinguishing the types of consonants. Consonants differ as a function of the place 
</p>
<p>of articulation, the way of expulsing air, and the level of vibration (voicing) of the 
</p>
<p>vocal cords. The place of articulation is reported to be, for instance, labial (pro-
</p>
<p>nounce /b/), dental (pronounce /d/), or labiodental (pronounce /v/). The way of 
</p>
<p>expulsing air can be slow, as is the case with fricatives (pronounce /f/), or sudden, as 
</p>
<p>is the case with occlusives (pronounce /b/ or /t/). Finally, a consonant can generate a 
</p>
<p>large amount of vibration of the vocal cord (voiced consonant as in pronouncing /b/ 
</p>
<p>or /z/) or not much vibration (unvoiced consonant as in pronouncing /f/ and /s/). 
</p>
<p> It is possible to make an accurate analysis of the frequencies that compose speech 
</p>
<p>sounds by means of a spectrogram. The spectrogram makes it possible to analyze, 
</p>
<p>over a short but continuous period, the contribution of different frequencies in 
</p>
<p>speech sounds. On a spectrogram like the one illustrated in Fig.  3.7 , the intensity of 
</p>
<p>various frequencies is presented on the  y -axis as a function of time, on the  x -axis. 
</p>
<p>Horizontal dark bands in this fi gure are called formants and are produced during the 
</p>
<p>pronunciation of the letter /a/. In the fi gure, the fi rst formants are lower and corre-
</p>
<p>spond to low frequencies. 
</p>
<p>   Table 3.2    Common phonemes of the English language (from John and Sarah Free Materials 1996)       
</p>
<p>3 Hearing</p>
<p/>
</div>
<div class="page"><p/>
<p>49
</p>
<p>3.4.3        Theoretical Perspectives 
</p>
<p>   Just listening to  someone   speaking a normal rate of speech, but in a foreign lan-
</p>
<p>guage, is suffi cient for getting the impression that the fl ow of words is continuous. 
</p>
<p>If you ever had the occasion to learn a second language, you probably remember 
</p>
<p>how much easier it was to understand when people were kind enough to speak 
</p>
<p>slowly. The diffi culty occurs at the moment of segmenting all spoken sounds, seem-
</p>
<p>ingly continuous, into signifi cant units in order to identify words. Even within your 
</p>
<p>own language, it may happen that you will experience this diffi culty, either because 
</p>
<p>a child is mispronouncing a few words or because you are talking with an elderly 
</p>
<p>having a very strong regional accent. Indeed, the fundamental question emerging is 
</p>
<p>the following one: how is it possible to recognize words and understand the message 
</p>
<p>they carry when there is no clear interruption in the spectrograms corresponding to 
</p>
<p>these words? 
</p>
<p> It is tempting to attribute this capacity to the fact that there exists a mechanism 
</p>
<p>in the brain dedicated to the processing of spoken information. Some researchers 
</p>
<p>adopt this position, a modular perspective, where the central hypothesis is the 
</p>
<p>existence of neural circuits specifi cally for processing speech. On the contrary, 
</p>
<p>other researchers rather believe in the idea that there is nothing special in the pro-
</p>
<p>cessing of speech sounds; the mechanisms responsible for this processing are the 
</p>
<p>same as those involved in the processing of other auditory stimuli (Diehl, Lotto, 
</p>
<p>&amp; Holt,  2004 ). 
</p>
<p> More than 50 years ago, an interesting idea was developed according to which it 
</p>
<p>would be possible to perceive speech because we can produce it. As is the case for 
</p>
<p>the production of sounds, the motor system would operate in the perception and 
</p>
<p>  Fig. 3.7    Spectrogram of letter /a/ pronounced during 700 ms       
</p>
<p> 
</p>
<p>3.4 Hearing Speech</p>
<p/>
</div>
<div class="page"><p/>
<p>50
</p>
<p>recognition of speech (Galantucci, Fowler, &amp; Turvey,  2006 ). This involvement of 
</p>
<p>the motor system in speech perception would occur unconsciously or automatically. 
</p>
<p>This motor theory of speech perception belongs to the perspective according to 
</p>
<p>which there is something specifi c with speech processing: there is a language- 
</p>
<p>specifi c process, located in the voice channel. 
</p>
<p> This idea is certainly less popular, but other theories based on the modular per-
</p>
<p>spective have been proposed. Sounds of language would actually be distinct from 
</p>
<p>other sounds considering that the perception of it is indeed categorical. We are talk-
</p>
<p>ing about categorical perception when the discrimination of elements within the 
</p>
<p>same category is more diffi cult to do than the discrimination of elements from dif-
</p>
<p>ferent categories. Therefore, certain sounds of language belonging to a same cate-
</p>
<p>gory, like different forms of a same phoneme, would be more diffi cult to discriminate 
</p>
<p>than members of different categories like /b/ and /p/. 
</p>
<p> These two phonemes nevertheless look like each other for different reasons like 
</p>
<p>the fact that their pronunciation requires the lips to be closed before releasing air. 
</p>
<p>Moreover, both phonemes are based on the vibration of vocal chords. However, this 
</p>
<p>vibration does not occur at the same moment in each case. While vibrations occur 
</p>
<p>rapidly when air is released for the pronunciation of /b/, the ones needed for pro-
</p>
<p>nouncing /p/ occur only after 50 or 60 ms. This delay before the beginning of vibra-
</p>
<p>tions is called   voice onset time   . 
</p>
<p> Suppose now that this voice onset time is manipulated experimentally with syn-
</p>
<p>thetic sounds. For instance, participants are asked to say whether they hear &ldquo;ba&rdquo; or 
</p>
<p>&ldquo;pa.&rdquo; When the voice onset time lasts less than 25 ms, participants report hearing 
</p>
<p>&ldquo;ba&rdquo;; however, for voice onset time longer than 35 ms, they report hearing &ldquo;pa&rdquo; 
</p>
<p>(Eimas &amp; Corbit,  1973 ). Between 25 and 35 ms, there is a phonetic frontier where 
</p>
<p>the sounds cannot be distinguished. 
</p>
<p> When this categorical perception of speech sounds was discovered, it was 
</p>
<p>interpreted as a demonstration of the existence of language-specifi c neural mech-
</p>
<p>anisms. However, it eventually turned out that nonverbal sounds were also sub-
</p>
<p>jects to categorical perception. What is more, nonhuman animals, which are not 
</p>
<p>really competent in spoken language, would also show some form of categorical 
</p>
<p>perception for sound signals (Kluender, Diehl, &amp; Killeen,  1987 ; Tsunada, Lee, &amp; 
</p>
<p>Cohen,  2011 ). 
</p>
<p> The fact that brain areas that are not part of the auditory cortex contribute to 
</p>
<p>language processing can be interpreted like supporting the idea that there are 
</p>
<p>speech specifi city mechanisms. In addition to the potential left hemisphere spe-
</p>
<p>cialization of the brain for language, there are also areas dedicated to the pro-
</p>
<p>duction and to the comprehension of language. For instance, damage to Broca&rsquo;s 
</p>
<p>area located in the lower part of the frontal lobe impairs the capacity to produce 
</p>
<p>speech (Broca&rsquo;s aphasia). Damage to Wernicke&rsquo;s area, in the upper part of the 
</p>
<p>temporal lobe, causes diffi culty with language comprehension. Therefore, it is 
</p>
<p>possible for someone to have an intact auditory system, i.e., presenting no sign 
</p>
<p>of diffi culty for processing nonlinguistic auditory signals, but still suffering 
</p>
<p>from aphasia.    
</p>
<p>3 Hearing</p>
<p/>
</div>
<div class="page"><p/>
<p>51
</p>
<p>3.4.4     Intermodality 
</p>
<p> Of course, oral  communication   depends on the capacity of producing speech sounds 
</p>
<p>and of detecting and decoding them. Nevertheless, understanding speech goes 
</p>
<p>beyond the sole processing of auditory processing. A powerful demonstration of 
</p>
<p>this fact was reported by McGurk and MacDonald ( 1976 ). The McGurk effect, as it 
</p>
<p>is called now, shows the infl uence exerted by visual signals on the processing of 
</p>
<p>language. Thus, if a participant is shown, with a special experimental device, a 
</p>
<p>speaker saying &ldquo;ba ba&rdquo; but with lips pronouncing &ldquo;ga ga,&rdquo; this participant will likely 
</p>
<p>hear neither &ldquo;ba&rdquo; nor &ldquo;ga,&rdquo; but &ldquo;da&rdquo; instead. 
</p>
<p> Trying to extract the words from a song is a classical case for experiencing dif-
</p>
<p>fi culties to understand spoken language (this is especially magnifi ed if the song is in 
</p>
<p>a foreign language). These diffi culties sometimes lead to a phenomenon called a 
</p>
<p>  mondegreen    3 : not only is it diffi cult to understand the lyrics, but one may even hear 
</p>
<p>something different. Lyrics are indeed a most relevant avenue for benefi ting from 
</p>
<p>additional visual information for increasing understanding. Jesse and Massaro 
</p>
<p>( 2010 ) tested whether the fact of seeing someone signing, instead of simply seeing 
</p>
<p>someone talking, would help understand lyrics in a song. They showed that recogni-
</p>
<p>tion could be increased by 35 % compared with conditions where it was possible 
</p>
<p>only to see or to hear the singer. 
</p>
<p> The fact we can observe such a phenomenon for spoken language and singing 
</p>
<p>language indicates that both domains are linked somehow. Indeed, seeing the face 
</p>
<p>of a singer would infl uence music perception (Thompson, Russo, &amp; Livingstone, 
</p>
<p> 2010 ). More particularly, the singer&rsquo;s facial expression would contain information 
</p>
<p>about another aspect of auditory processing, namely, the relations between pitches. 
</p>
<p>In brief, beyond the question of knowing whether processing language is based on 
</p>
<p>specifi c mechanisms, the question concerning the extent to which speech and lan-
</p>
<p>guage share common characteristics remains most relevant (Patel,  2008 ).        
</p>
<p>3   This term comes from a Scottish ballad, &ldquo;The Bonnie Earl O&rsquo;Moray&rdquo;, where &ldquo;And laid him on the 
</p>
<p>green&rdquo; might well sound like &ldquo;And Lady  Mondegreen .&rdquo; 
</p>
<p>3.4 Hearing Speech</p>
<p/>
</div>
<div class="page"><p/>
<p>53&copy; Springer International Publishing Switzerland 2016 
</p>
<p>S. Grondin, Psychology of Perception, DOI 10.1007/978-3-319-31791-5_4
</p>
<p>    Chapter 4   
</p>
<p> Biological Bases of Visual Perception                     
</p>
<p>             This is the fi rst of a series of chapters on the study of visual perception. Because visual 
</p>
<p>perception has been studied for a long time and because it is easier to illustrate visual 
</p>
<p>phenomena in a book than illustrating phenomena involving any other sensory modal-
</p>
<p>ity, visual perception has traditionally taken a lot of space in textbooks dedicated to 
</p>
<p>the psychology of perception. The importance of vision in the study of perception 
</p>
<p>may also be explained by the obvious place that this sense occupies in everyday life in 
</p>
<p>humans. This chapter is dedicated to the description of the main biological structures 
</p>
<p>and of some of the mechanisms associated with visual perception. 
</p>
<p>4.1     The Eye 
</p>
<p> The  eye  , which is almost spherical and has a diameter of 2&ndash;2.5 cm, is a set of structures 
</p>
<p>which allows the transformation of the light into a code that the brain can understand. 
</p>
<p>4.1.1     The Eyeball 
</p>
<p>    Figure  4.1  shows the main parts of the  eyeball  . In its front part, there are ligaments, 
</p>
<p>which hold the lens,  and   the iris, which is controlling the amount of light entering 
</p>
<p>in the eye. In fact, it is  the   color of the iris that determines the fact of having, for 
</p>
<p>example, brown or blue eyes. With a diameter ranging from 2 to 8 mm and located 
</p>
<p>in the center of the iris, the pupil lets in more or less light, depending on the fact that 
</p>
<p>it is dilated or contracted. One can easily see the direct effect of light on the state of 
</p>
<p>the iris and pupil. Just look at someone in the eyes in the dark and then turn on a 
</p>
<p>light. You will see a refl ex activity, called the Whytt refl ex, in which the pupil diam-
</p>
<p>eter gradually decreases.</p>
<p/>
</div>
<div class="page"><p/>
<p>54
</p>
<p>   The light rays entering the eye are fi rst bent by a curved membrane, the cornea, 
</p>
<p>before crossing the pupil where they are bent again. Another adjustment of rays is 
</p>
<p>done through an automatic mechanism called accommodation, which consists of a 
</p>
<p>more or less pronounced fl attening of the lens. The lens becomes rather round if the 
</p>
<p>object on which we try to focus on is close or very fl at if the object is far. Thus, if an 
</p>
<p>object is near, the muscles contract; the lens becomes thicker and the light rays are 
</p>
<p>bent even more. 
</p>
<p> The outermost part of the eye is the  sclera  . The sclera is resistant and maintains 
</p>
<p>the shape of the eye. In its anterior part, it is transparent and covered by a thin mem-
</p>
<p>brane, the conjunctiva, which has a protecting role. Between the sclera and the ret-
</p>
<p>ina, there is an intermediate membrane, the choroid, or choroid membrane, which 
</p>
<p>allows to avoid the presence of light refl ection (internal) by absorbing light. Highly 
</p>
<p>vascularized, the choroid has a nutritive function for retinal cells. 
</p>
<p> Note that the spherical shape of the eye is made possible by the presence of two 
</p>
<p>types of fl uid. In the anterior part, between the cornea and the lens, this fl uid is 
</p>
<p>called the  aqueous humor  . In the back part, there is a large space fi lled with a rather 
</p>
<p>gelatinous substance called the  vitreous humor  . 
</p>
<p> In the posterior part of the eye, there is a blind spot (or optic disk) caused by the 
</p>
<p>presence of the optic nerve. This spot covers approximately 7.5&deg; on the vertical axis 
</p>
<p>and 5&deg; on the horizontal axis (approximately 2.1 mm &times; 1.5 mm). The brain manages 
</p>
<p>to compensate for the loss of vision caused by the blind spot (Fig.  4.2 ).
</p>
<p>   The innermost layer of the eye&rsquo;s posterior part is the retina. It is on the retina that 
</p>
<p>the image is formed. Given its importance in vision, the next subsection is devoted 
</p>
<p>to it. On the retina is a point having a diameter of about 1 o , the fovea. It is at the 
</p>
<p>fovea that we have the sharpest vision. The fovea is located 2 mm from the blind 
</p>
<p>spot in a small area, the macula lutea (or yellow spot). In this area, there is a high 
</p>
<p>concentration of cones. In fact, at the center of the fovea, there are only cones. 
</p>
<p>  Fig. 4.1    Main  structures   of the eye       
</p>
<p> 
</p>
<p>4 Biological Bases of Visual Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>55
</p>
<p> Finally, each eyeball is provided with three pairs of muscles that direct the eye in 
</p>
<p>all directions of the visual fi eld. These pairs have actually antagonistic roles. The 
</p>
<p>superior and inferior lower rectus muscles allow the eye to make movements in the 
</p>
<p>vertical direction, from top to bottom and from bottom to top; the lateral and medial 
</p>
<p>rectus muscles make possible the horizontal movements, to the left or to the right; 
</p>
<p>and the inferior (which is smaller) and superior (which is larger) oblique muscles are 
</p>
<p>responsible for torsional movements and are involved in the vertical movements.     
</p>
<p>4.1.2     The Retina 
</p>
<p>    The  retina   covers a section of about 200&deg; in the posterior part of the eye and has a 
</p>
<p>surface of about 25 cm 2  and a thickness of about 4 mm. As illustrated in Fig.  4.3 , the 
</p>
<p>retina is made essentially of three layers of cells.  There   are photoreceptor cells, 
</p>
<p>which convert the electromagnetic energy (light) into  nerve   impulses. This informa-
</p>
<p>tion is transmitted to higher centers through the other two layers: the bipolar and 
</p>
<p>ganglion cells. The retina is also made of horizontal and amacrine cells whose func-
</p>
<p>tion is to facilitate the transfer of information between neurons of the same level.
</p>
<p>   There are two types of photoreceptor cells in the retina, the rods and the cones, 
</p>
<p>which have different functions and properties. These types of cells do not have the 
</p>
<p>same sensitivity to light. There are about fi ve million cones and 120 million rods. 
</p>
<p>Because of their high response threshold, the cones are assigned to daytime vision 
</p>
<p>and form the photopic system. The cones are responsive to color and provide better 
</p>
<p>visual acuity than the rods. We fi nd a very large concentration of cones&mdash;about 
</p>
<p>35,000&mdash;at the fovea. 
</p>
<p>X
</p>
<p>X
</p>
<p>  Fig. 4.2    Demonstration about the presence of the  blind spot  . (1) You need to fi xate  X  on the  top 
</p>
<p>row  with your right eye, keeping the left eye closed. From the corner of your eye, you should still 
</p>
<p>be able to see the  black disk  located on the same row. Then, with a movement of your arm that is 
</p>
<p>holding the book, you will vary the distance between your eye and the  X . At a given distance, the 
</p>
<p>visible  black disk  in the corner of your eye should disappear, although it is possible to see it a little 
</p>
<p>further or a little closer. (2) You should repeat the demonstration with the  bottom row . This time, 
</p>
<p>if you fi xate  X , you should, at a given distance, perceive a non-interrupted  black line ; this interrup-
</p>
<p>tion, in  white , should disappear, the brain having compensate the loss of vision caused by the pres-
</p>
<p>ence of the  black spot        
</p>
<p> 
</p>
<p>4.1 The Eye</p>
<p/>
</div>
<div class="page"><p/>
<p>56
</p>
<p> For their part, the rods are more elongated than cones. Sensitive to low light 
</p>
<p>intensity, the rods are assigned to night vision (the scotopic system). Moving away 
</p>
<p>from fovea to periphery, the rods are more and more numerous, and, unlike the 
</p>
<p>cones, their shape remains almost always the same. 
</p>
<p> The rods and cones are made of  photosensitive pigments  . The pigments of the 
</p>
<p>cones are of three types in that the absorption of light of each of these types is maxi-
</p>
<p>mal at certain wavelengths, long, medium, and short (see Chap.   5     on color percep-
</p>
<p>tion). The photosensitive pigment of rods, rhodopsin, absorbs wavelengths ranging 
</p>
<p>from 400 to 600 nm. It is therefore a photochemical process that will create an 
</p>
<p>action potential which will be transmitted from the retina to the brain. 
</p>
<p> Bipolar cells, which can take different forms and different sizes, are involved in 
</p>
<p>the passage of nerve impulses from the photoreceptors to the ganglion cells.  Bipolar 
</p>
<p>cells   synapse with both rods with cones. Depending on whether it is located at 
</p>
<p>periphery or at the fovea, the number of receptors in contact with the bipolar cells 
</p>
<p>varies. Thus, the bipolar cells of the fovea may receive impulses from only one 
</p>
<p>  Fig. 4.3    Layers of retinal cells (fi gure by Leila Aazari)       
</p>
<p> 
</p>
<p>4 Biological Bases of Visual Perception</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-31791-5_5">http://dx.doi.org/10.1007/978-3-319-31791-5_5</a></div>
</div>
<div class="page"><p/>
<p>57
</p>
<p>cone, while a little further at periphery, they may receive information from several 
</p>
<p>photoreceptors. In general, bipolar cells specifi c to the cones are in contact with less 
</p>
<p>photoreceptors than bipolar cells receiving information from rods. Moreover, the 
</p>
<p>photoreceptors are in contact with each other through the horizontal cells. Some are 
</p>
<p>only in contact with cones, others only with rods; other cells may be in contact with 
</p>
<p>these two types of photoreceptors. These horizontal cells can also synapse with 
</p>
<p>bipolar cells. The reader will fi nd in DeValois and DeValois ( 1988 ) additional infor-
</p>
<p>mation about the connections between photoreceptors, horizontal cells, and bipolar 
</p>
<p>cells and about the biological mechanisms underlying vision. 
</p>
<p> Bipolar cells mainly transmit nerve impulses to the ganglion cells, but also to 
</p>
<p>amacrine cells. The role of the latter is comparable to that of the horizontal cells in 
</p>
<p>that they mainly assume a role of interaction, this time between the ganglion and 
</p>
<p> bipolar cells  . For their part, the ganglion cells receive impulses mainly from of one 
</p>
<p>or more bipolar neurons. The farther we get in periphery, the more frequent are the 
</p>
<p>contributions of bipolar and amacrine cells to the excitement of a ganglion cell. The 
</p>
<p>axons of the ganglion cells eventually form the optic nerve. For each eye, there are 
</p>
<p>about one million ganglion cells.      
</p>
<p>4.2     Receptive Fields 
</p>
<p>    It is  important   to understand that the retina has a particular organization as  it   includes 
</p>
<p>more than 125 million receptors, cones, or rods, but does transmit information to the 
</p>
<p> visual   cortex cells through only a million ganglion cells. In fact, this particular 
</p>
<p>arrangement of retinal cells refers to the idea of receptive fi eld. To each ganglion 
</p>
<p>cell corresponds a receptive fi eld, which is a surface at the photoreceptor level 
</p>
<p>where the light causes a change on the normal course of the electrical activity. 
</p>
<p> Early work in neurophysiology has shown that the light projected on the retina 
</p>
<p>causes three types of responses (Hartline,  1940 ; Hartline &amp; Ratliff,  1957 ; Kuffl er, 
</p>
<p> 1953 ). Thus, the response recorded at the ganglion cell level using an electrode can 
</p>
<p>be one of the following three (Fig.  4.4 ). Cell responses show (1) an increase in activ-
</p>
<p>ity during stimulation, and, from the beginning of the stimulation, then a return to 
</p>
<p>normal activity when the illumination ceases; (2) an interruption of any activity 
</p>
<p>while the light is on, but an acceleration of these responses when the light is turned 
</p>
<p>off; and (3) an increase in activity at the beginning, followed by a decrease, and the 
</p>
<p>repetition of this pattern (increase-decrease) when the light is off. These three types 
</p>
<p>of responses are respectively called &ldquo;on,&rdquo; &ldquo;off,&rdquo; and &ldquo;on-off.&rdquo;
</p>
<p>   The responses given by the ganglion cells depend on the stimulated location on 
</p>
<p>the retina. Stimulating the retina at a specifi c location, or nearby, can result in 
</p>
<p>responses of different types on a given ganglion cell. Indeed, to each ganglion cell 
</p>
<p>corresponds a receptive fi eld. This fi eld could be of two types: on-center or off- 
</p>
<p>center. These two types of fi eld have a circular shape (Fig.  4.5 ) and are divided in 
</p>
<p>equal number on the retina. For a type of fi eld, stimulation at center causes &ldquo;on&rdquo; 
</p>
<p>responses, and around this center, responses are &ldquo;off.&rdquo; Between these two levels, 
</p>
<p>4.2 Receptive Fields</p>
<p/>
</div>
<div class="page"><p/>
<p>58
</p>
<p>there are responses of another type, &ldquo;on-off.&rdquo; For the second type of receptive fi eld, 
</p>
<p>stimulation causes off responses in the center and around this center, on responses. 
</p>
<p>In other words, the ganglion cells are in a position to gather information on the 
</p>
<p>center of their receptive fi eld and on the surrounding region.
</p>
<p>   In fact, there is critical distinction between two types of ganglion cells: &ldquo;magno&rdquo; 
</p>
<p>versus &ldquo;parvo.&rdquo; About 80 % of  ganglion cells   are of the parvo type (P cells, some-
</p>
<p>times called &ldquo;X&rdquo;), and the magno cells (M cells or &ldquo;Y&rdquo;) represent 10 % of these 
</p>
<p>ganglion cells. There is also a third class of ganglion cells (&ldquo;W&rdquo;) which would have 
</p>
<p>a receptive fi eld different of those described above and which would have the slow-
</p>
<p>est conduction speed. 
</p>
<p> Parvo cells have a small receptive fi eld (diameter of 0.01 mm) and a conduction 
</p>
<p>speed of about 20 m/s. In contrast, magno cells have a larger receptive fi eld. For 
</p>
<p>  Fig. 4.4    Illustration of activation and inhibition patterns on ganglion cells with the arrival, main-
</p>
<p>tenance, and disappearance of the light stimulation       
</p>
<p>  Fig. 4.5    Two types of circular receptive fi elds: with an &ldquo;on&rdquo;  center  ( left ) and with an &ldquo;off&rdquo;  center  
</p>
<p>( right )       
</p>
<p> 
</p>
<p> 
</p>
<p>4 Biological Bases of Visual Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>59
</p>
<p>example, at 10 mm from the fovea, the receptive fi elds are 50 times larger (0.5 mm). 
</p>
<p>Because their body cell and axon are larger, magno cells have a much greater con-
</p>
<p>duction speed (40 m/s) than parvo cells. Table  4.1  summarizes the main features that 
</p>
<p>differentiate these two types of ganglion cells, P and M.   
</p>
<p>4.3        Central Mechanisms 
</p>
<p> The grouping of ganglion cell axons forms the optic nerve. The distance between 
</p>
<p>the exit of the eye and the optic chiasm is about 5 cm. At the optic chiasma level, a 
</p>
<p>shift occurs in the routing of a part of the information arriving from the eye. As 
</p>
<p>indicated by the word chiasma, there is a crossing of information. Approximately 
</p>
<p>50 % of the information from one eye is transferred to the opposite side of the brain. 
</p>
<p>It is the information received in the nasal portion of the retina (the part of the retina 
</p>
<p>closest to the nose) that is intersecting at the optic chiasm level. The fi bers from the 
</p>
<p>temporal region of the retina remain on the same side. Whether the optic nerve 
</p>
<p>fi bers cross or not, there is no synapse at the optic chiasm location. Also, beyond the 
</p>
<p>optic chiasm, the optic nerve is called the optic tract. 
</p>
<p> The information carried by each optical track therefore comes from each eye and 
</p>
<p>is directed to one of the following two structures, the  lateral geniculate nucleus 
</p>
<p>(LGN)   and the superior colliculus, most of the visual information being routed to 
</p>
<p>the LGN. The superior colliculi, which are a primitive structure of the brain, have 
</p>
<p>no role in the detection of the exact nature of the stimuli, but would be used to locate 
</p>
<p>their source. The superior colliculi also exert control on the movement of the eyes 
</p>
<p>when they should be moved to look at an object in periphery. 
</p>
<p> As for the LGN, this structure has a much greater contribution to the whole 
</p>
<p>visual processing. As the name suggests, they are located on each side of the brain 
</p>
<p>and have the shape of a fl exed knee. Each of the LGN, the left and right, has a 
</p>
<p>receptive fi eld similar to that of ganglion cells. They also have a retinotopic orga-
</p>
<p>nization, that is to say, that the representation on  the   retina is maintained at the 
</p>
<p>LGN level. The other features of the LGN include the fact that they are made up of 
</p>
<p>six separate layers that do receive information from only one eye, that they have a 
</p>
<p>  Table 4.1    Contrasting the 
</p>
<p>characteristics of two types 
</p>
<p>of  ganglion cells  , magno 
</p>
<p>and parvo  
</p>
<p> Magno (Y)  Parvo (X) 
</p>
<p> Represent (of total)  10 %  80 % 
</p>
<p> Body cells and 
</p>
<p>axons 
</p>
<p> Larger  Smaller 
</p>
<p> Conduction speed  40 m/s  20 m/s 
</p>
<p> Neural responses  Jerkily  Continuous 
</p>
<p> Receptive fi eld  Larger  Smaller 
</p>
<p> Contrast sensitivity  High  Low 
</p>
<p> Sensitive to  Large objects  Colors 
</p>
<p> Sensitive to  Movement  Stationary patterns 
</p>
<p>4.3 Central Mechanisms</p>
<p/>
</div>
<div class="page"><p/>
<p>60
</p>
<p>key role in the perception of form, and, more than the superior colliculi, that they 
</p>
<p>receive a lot of information from the fovea. Consequently, the LGN are involved in 
</p>
<p>the perception of color. 
</p>
<p>4.3.1     The Visual Cortex 
</p>
<p>    The  visual cortex   is located in the occipital part of the brain and has an area of 
</p>
<p>approximately 64 cm 2 . The  cerebral   organization in the brain also preserves the 
</p>
<p>spatial  organization   of retinal cells (retinotopic organization), but the amount of 
</p>
<p>space occupied in the brain depends on the location stimulated on the retina. About 
</p>
<p>65 % of the visual cortex is associated with the activity on the retina corresponding 
</p>
<p>to 10 % of the visual fi eld. 
</p>
<p> The terms V1&ndash;V5 are now used for describing the different regions of the visual 
</p>
<p>cortex, and two main sections should also be kept in mind, the primary visual cortex 
</p>
<p>and the secondary visual cortex (Table  4.2 ). The primary visual cortex, or striate 
</p>
<p>cortex, is also sometimes called area 17. This corresponds to the visual 1 (V1) area. 
</p>
<p>The V1 area receives information from LGN, which also has a spatial arrangement 
</p>
<p>corresponding to a retinotopic organization. The V1 area is divided into six layers 
</p>
<p>designated by the numbers 1&ndash;6. The information from the LGN arrives at the fourth 
</p>
<p>layer (specifi cally 4c) in V1.
</p>
<p>   The second section, the secondary visual cortex or extrastriate cortex, includes 
</p>
<p>areas V2 and V3 (or area 18) and V4 and V5 (or area 19). It is in these areas that 
</p>
<p>are routed nerve impulses coming from superior colliculi. Similarly, some infor-
</p>
<p>mation already processed in V1 will reach certain areas of the secondary visual 
</p>
<p>cortex. Finally, the processing of visual information also involves the contribution 
</p>
<p>of another part of the visual cortex called the associative cortex. It is in this part of 
</p>
<p>the visual cortex that some learning and some past associations intervene in the 
</p>
<p>overall perception. 
</p>
<p> Some other features of the visual cortex are noteworthy. The knowledge of these 
</p>
<p>features relies essentially on the pioneer work of two neurobiologists, David Hubel 
</p>
<p>and Torsten Wiesel, who won the Nobel Prize in Physiology in 1981 (Hubel &amp; 
</p>
<p>Wiesel,  1959 ,  1962 ). Essentially, Hubel and Wiesel used a technique allowing the 
</p>
<p>recording of the activity of one cell at a time in the visual cortex. They found that the 
</p>
<p>receptive fi elds in the visual cortex are not necessarily circular. For example, they are 
</p>
<p>sometimes elongated. They identifi ed three types of cells in the visual cortex to 
</p>
<p>which they gave the name of simple cells, complex cells, and hypercomplex cells. 
</p>
<p>   Table 4.2    Names given to areas in the primary  and   secondary visual cortex   
</p>
<p> Primary visual cortex  Secondary visual cortex 
</p>
<p> Other name  Striate visual cortex  Extrastriate visual cortex 
</p>
<p> Brodmann classifi cation  Area 17  Areas 18 and 19 
</p>
<p> Common nomenclature  Area V1  Areas V2, V3, V4, and V5 
</p>
<p>4 Biological Bases of Visual Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>61
</p>
<p> The response of simple cells is maximal when an observer is presented with a spe-
</p>
<p>cifi c orientation. Simple cells in layer 4c of the area V1 have for their part a circular 
</p>
<p>receptive fi eld. The selectivity for orientation (bars placed more or less vertically or 
</p>
<p>horizontally) is a fundamental feature of these simple cells. A change of a few degrees 
</p>
<p>of a bar signifi cantly reduces the electrical activity, or neural response made by a given 
</p>
<p>cell, but increases the activity of another of these simple cells located in V1. 
</p>
<p> Because it is more diffi cult to know what determines their activity, a second type 
</p>
<p>of cells is called &ldquo;complex cells.&rdquo; They are found in the layers 2, 3, 5, and 6 of V1. 
</p>
<p>It is known that they are sensitive to movement, some to movement in one direction, 
</p>
<p>the others to movement in another direction. In brief, we are referring here to a case 
</p>
<p>of selectivity for motion perception. 
</p>
<p> Even more diffi cult to understand, the hypercomplex cells appear to be end- 
</p>
<p>stopped cells. They respond only to edges having a specifi c orientation or moving in 
</p>
<p>a certain direction. 
</p>
<p> In their work, Hubel and Wiesel also identifi ed an important feature of the orga-
</p>
<p>nization of cells in V1. The visual cortex is built with architecture in columns. Thus, 
</p>
<p>when inserting an electrode vertically, beginning from layer 1 up to the layer 6, it is 
</p>
<p>always the bars of the same orientation that give maximal responses. That sequence 
</p>
<p>of six layers is called a column. When moving the electrode on a horizontal plane, 
</p>
<p>there is a gradual change about the cell preference to stimuli ranging from horizon-
</p>
<p>tal to vertical: this sequence of columns are called hypercolumn and have an area of 
</p>
<p>about 2 mm 2 . There are about 6400 hypercolumns composed of 15,000 cells each. 
</p>
<p> There are in the brain several specialized processing areas for specifi c functions 
</p>
<p>or features. In other words, there is a segregation of the various functions related to 
</p>
<p>visual processing and an assignment of these functions to specifi c areas in the visual 
</p>
<p>cortex. Areas V1 and V2 are alike as they both have small receptive fi elds and form, 
</p>
<p>according to some authors, a V1&ndash;V2 complex. In addition to the characteristics 
</p>
<p>described above, it should be noted that in V1, the segregation applies according to 
</p>
<p>shape, color, and movement. Area V2 receives some information directly from the 
</p>
<p>LGN but mostly receives information via relays from V1. 
</p>
<p> Area V3 is very closely linked to the activity at the fovea and is specialized in the 
</p>
<p>processing of form. This area however would also contain information about the 
</p>
<p>position changes of the form or object. Area V4 is specialized in the processing of 
</p>
<p>color, more specifi cally in the processing of refl ected light. Area V5 processes 
</p>
<p>movement; more specifi cally, most of the cells in this area would respond to move-
</p>
<p>ment in a particular direction.     
</p>
<p>4.3.2     Visual Pathways 
</p>
<p>    We  distinguish   two major pathways in the processing of visual information. Their 
</p>
<p> name   refers to the origin of the stimulation and where it  ends   up. Thus, the fi rst 
</p>
<p>pathway is called magnoparietal. It is also referred to as the median temporal path-
</p>
<p>way or dorsal pathway (or even  geniculostriate ). This pathway provides informa-
</p>
<p>tion about the &ldquo;where&rdquo; and &ldquo;how&rdquo; aspects of vision and requires the contribution of 
</p>
<p>4.3 Central Mechanisms</p>
<p/>
</div>
<div class="page"><p/>
<p>62
</p>
<p>10 % of ganglion cells. As this pathway passes through V5, it is not surprising that 
</p>
<p>it is associated with motion perception. 
</p>
<p> The other pathway is called  parvotemporal   or ventral ( tectopulvinar ). It is also 
</p>
<p>known as the &ldquo;what&rdquo; pathway.  This    pathway   requires the contribution of areas V2 
</p>
<p>and V4, the latter indicating that it involves color processing. In fact, this pathway 
</p>
<p>allows to scrutinize images or objects for identifying them correctly. 
</p>
<p> Finally, this chapter on the biological bases of visual perception would be incom-
</p>
<p>plete without the presentation of some principles. For example, relatively to a fi xa-
</p>
<p>tion point straight ahead, what is located on the left will be processed in the right 
</p>
<p>cerebral hemisphere, and what is located on the right will be processed in the left 
</p>
<p>hemisphere. Figure  4.6  illustrates in what position the information captured from 
</p>
<p>  Fig. 4.6    In relation to the visual fi eld, each eye receives information that is upside down and mir-
</p>
<p>rored; also, what is located to the right of the fi xation point arrives in the left cerebral hemisphere, 
</p>
<p>and what is located to the left of the fi xation point arrives in the right cerebral hemisphere       
</p>
<p> 
</p>
<p>4 Biological Bases of Visual Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>63
</p>
<p>the visual fi eld arrives on the retina and in the cerebral hemispheres. Thus, it is pos-
</p>
<p>sible to observe that, relative to the visual fi eld, the image on the retina is upside 
</p>
<p>down and mirrored. Also, the properties of the  optic chiasm   lead to (1) the passage 
</p>
<p>of information from the nasal region of the left eye (information contained in the left 
</p>
<p>side of the visual fi eld) to the right side of the brain and (2) the passage of informa-
</p>
<p>tion from the nasal region of the right eye (information contained on the right side 
</p>
<p>of the visual fi eld) to the left side of the brain. This crossover explains why each 
</p>
<p>cerebral hemisphere is responsible for processing the visual information presented 
</p>
<p>to the opposite side.   
</p>
<p>4.4         Clinical Aspects 
</p>
<p>   Different  problems   may arise that will impede the proper functioning of the visual 
</p>
<p>system. We can distinguish various categories of disorders that lead to poorer vision. 
</p>
<p>The most common are listed here. Color  vision   disorders are presented in the fol-
</p>
<p>lowing chapter. 
</p>
<p> A fi rst major category of problems, and the most frequent indeed, is related to the 
</p>
<p>capacity of focusing. Refraction problems (or refractive errors) prevent the light 
</p>
<p>rays to reach the retina so that the picture is clear. One type of refraction problem is 
</p>
<p>called   hypermetropia   . This occurs when the distance between the lens and the retina 
</p>
<p>is too short (Fig.  4.7 ). The image is formed behind the fovea. The person suffering 
</p>
<p>from hypermetropia will have diffi culty to see near objects. Glasses with a biconvex 
</p>
<p>lens allow to correcting this problem.
</p>
<p>   Conversely, a person suffers from   myopia    when the distance between the lens 
</p>
<p>and the retina is too large; the image is formed in front of the fovea. Sometimes, a 
</p>
<p>distinction is made between refractive myopia, which means that the light rays are 
</p>
<p>too defl ected by the cornea or by the lens, and axial myopia, which means that the 
</p>
<p>eyeball is too long. The person suffering from myopia, or nearsighted, does not see 
</p>
<p>clearly distant objects and will benefi t from the use of biconcave lenses. This very 
</p>
<p>common problem can be corrected by photorefractive keratectomy. This is a laser 
</p>
<p>surgery for changing the curvature of the cornea. After the operation, the light rays 
</p>
<p>reach the retina correctly and vision is in focus. 
</p>
<p> There are rarer cases where a person suffers from   astigmatism   , which means that 
</p>
<p>this person does not have clear vision in all directions of the visual fi eld. A part of 
</p>
<p>the visual fi eld always remains out of focus. This is caused by a nonspherical curva-
</p>
<p>ture of the cornea or lens. 
</p>
<p> Furthermore,   presbyopia    refers to a diffi culty to focus on an object that is nearby 
</p>
<p>and is caused by the hardening of the lens with age. It is common that people in their 
</p>
<p>forties, who until then had never experienced any vision problem whatsoever, may 
</p>
<p>need glasses. You may have noted that, without their glasses, older people tend to 
</p>
<p>hold a book at arm&rsquo;s length for reading it. The reduction of the lens&rsquo; plasticity even-
</p>
<p>tually makes reading much more diffi cult. 
</p>
<p>4.4 Clinical Aspects</p>
<p/>
</div>
<div class="page"><p/>
<p>64
</p>
<p> Sometimes, instead of being improperly refracted, the light that enters the eye is 
</p>
<p>rather blurred. This can be caused by certain injuries or diseases. It may happen that 
</p>
<p>the cornea is infected, causing vision problems. Furthermore, there are various 
</p>
<p>cases of   cataract   , which refers to the opacity of the lens. The gradual loss of lens 
</p>
<p>transparency in some cases may cause a loss of vision. Cataracts may be congenital 
</p>
<p>or caused by disease (secondary cataract) or injuries (traumatic cataracts). Most 
</p>
<p>often, cataracts are caused by aging. It affects 75 % of people aged 65 and older, and 
</p>
<p>95 % of those aged 85 and older. Problems caused by cataracts can be corrected with 
</p>
<p>a surgery when the reduction of vision becomes too severe. 
</p>
<p> Some vision problems are caused by a problem specifi c to the retina. One such 
</p>
<p>problem is the age-related macular degeneration. With such a problem, a person 
</p>
<p>sees somehow very well everywhere except where he or she is looking, i.e., where 
</p>
<p>the focus is made! There are also cases of retinopathy caused by diabetes. Problems 
</p>
<p>often develop after several years of diabetes. Older people who have long suffered 
</p>
<p>from diabetes can have serious vision problems. Also, poor vision may result from 
</p>
<p>  Fig. 4.7    Refraction problems often caused by an anormal shape of the eyeball. After passing 
</p>
<p>through the lens ( gray ), light rays arrive at the retina in front of a myopic eye or behind the hyper-
</p>
<p>metropic eye. Normal view could be recovered with a biconcave lens, for myopia, or a biconvex 
</p>
<p>lens, for hypermetropia       
</p>
<p> 
</p>
<p>4 Biological Bases of Visual Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>65
</p>
<p>a poor fl ow of information at the optic nerve; this problem might be caused by an 
</p>
<p>intoxication or infl ammation. Finally, vision can be disrupted by a displacement of 
</p>
<p>the retina. In addition, certain injuries can cause a retinal detachment and impair 
</p>
<p>severely sometimes peripheral vision, sometimes central vision. 
</p>
<p> Another group of eye problems is   glaucoma   . This is a common cause of blind-
</p>
<p>ness. Glaucoma is a degeneration of optic nerve sometimes caused by a very large 
</p>
<p>pressure within the eye. Glaucoma usually occurs in people aged over 60 years. 
</p>
<p> Note in conclusion that there are many other problems that can affect vision. 
</p>
<p>Some of these are related to muscles. That is the case of   strabismus   , which consists 
</p>
<p>of a poor centering of the image (which does not arrive at the fovea) and which 
</p>
<p>causes double vision. It is caused by a disorder in the extraocular muscles, for exam-
</p>
<p>ple, by a paralysis of the muscles of an eye.   Nystagmus   , which refers to a continuous 
</p>
<p>movement of the eyes, is another problem having of muscular origin, this time due 
</p>
<p>to the presence of plaques in the eyes. Finally,   scotoma    is the name given to visual 
</p>
<p>fi eld defects. These defi cits can be more or less important and may affect specifi c 
</p>
<p>portions of the fi eld. In rare cases, this problem can be caused by a lesion to the 
</p>
<p>visual cortex.         
</p>
<p>4.4 Clinical Aspects</p>
<p/>
</div>
<div class="page"><p/>
<p>67&copy; Springer International Publishing Switzerland 2016 
</p>
<p>S. Grondin, Psychology of Perception, DOI 10.1007/978-3-319-31791-5_5
</p>
<p>    Chapter 5   
</p>
<p> Color Perception                     
</p>
<p>             Colors are everywhere in our lives and we could not imagine life without them. 
</p>
<p>They are useful, if only to inform us about the state of ripeness of a fruit or the status 
</p>
<p>of any other food that we are about to eat. They help in basic tasks such as the detec-
</p>
<p>tion and discrimination of objects. In addition, and perhaps most importantly, they 
</p>
<p>make life enjoyable. For example, we are sensitive to the color of the walls or cloth-
</p>
<p>ing and to their arrangement. 
</p>
<p> Yet, the study of colors long remained a mystery. We will see in this chapter that 
</p>
<p>understanding the perception of colors requires the integration of the basic concepts 
</p>
<p>about the nature of physical stimuli underlying visual sensation and about retinal 
</p>
<p>physiology. These concepts are necessary if we want to understand what the brain 
</p>
<p>must deal with for providing relevant information about what is colored in the 
</p>
<p>environment. 
</p>
<p>5.1     Description of Light 
</p>
<p> Each sensory receptor is particularly sensitive to a specifi c form of stimulation. For 
</p>
<p>example, stimuli may be chemical, as in the case of taste or smell, or mechanical, as 
</p>
<p>in the case of touch. If the ear is sensitive to variations in the air pressure, the eye is 
</p>
<p>for its part sensitive to electromagnetic radiation. Light, which is a particular form 
</p>
<p>of this radiation, produces a visual response. Light can be described either by con-
</p>
<p>sidering that the irradiated energy is propagated in the form of a continuous wave or 
</p>
<p>by considering that it is composed of specifi c matter particles, the photons. </p>
<p/>
</div>
<div class="page"><p/>
<p>68
</p>
<p>5.1.1     Intensity 
</p>
<p>   Light intensity could be  expressed   in number of photons, but it is agreed to use dif-
</p>
<p>ferent photometric units. The basic unit of photometry is called  candle . A candle is 
</p>
<p>the standard value of light intensity. For example, with a wavelength of 555 nm, a 
</p>
<p>candle produces an amount of energy slightly above 0.001 W. 
</p>
<p> For understanding  color perception, it is   important fi rst to identify the nature of 
</p>
<p>what reaches the eye and to distinguish two types of sensory experiences, the inci-
</p>
<p>dent light and the refl ected light. The amount of energy that comes directly from a 
</p>
<p>light source is the radiance, or luminous fl ux, whereas the amount of light emanat-
</p>
<p>ing from that source and reaching a surface is called  incident light   or illuminance. 
</p>
<p>Meter-candle is the term used to describe the  illuminance  , and this equals the illu-
</p>
<p>mination of a 1-m 2  surface located 1 m away from a standard candle. 
</p>
<p> The light from a source rarely reaches the eye directly, unless someone looks at 
</p>
<p>this source directly. Most often, the light is refl ected from various surfaces in the 
</p>
<p>direction of the eye. This refl ected light is called  luminance  . It is sometimes referred 
</p>
<p>to as surface light. The luminance of a surface is expressed with a unit called candle 
</p>
<p>per square meter (cd/m 2 ), i.e., the amount of light refl ected in all directions by a 
</p>
<p>surface (refl ecting and diffusing light perfectly) illuminated by a meter-candle. 
</p>
<p>Because the luminance was once expressed in footlambert or millilambert (mL), 
</p>
<p>one can still fi nd these units in some textbooks. To give a rough idea of the value of 
</p>
<p>different luminances, snow in the sun provides 10 5  cd/m 2 ; an overcast sky is about 
</p>
<p>3000 cd/m 2 ; easy reading requires a luminance of 100 cd/m 2 ; and the absolute 
</p>
<p>threshold is about 10 &minus;6  cd/m 2 . 
</p>
<p> The luminance of a surface defi nitely depends on the incident light and also on 
</p>
<p>another property called refl ectance. The refl ectance of a surface is its ability to 
</p>
<p>refl ect light. Refl ectance is expressed with a coeffi cient. Thus, a surface which has 
</p>
<p>70 % refl ectance refl ects 70 % of incident light:
</p>
<p>  
reflectance luminance illuminance= ( ) &acute;/ 100
</p>
<p>   
</p>
<p>Sometimes, the concept of retinal illuminance could be useful. This is the amount 
</p>
<p>of light that reaches the retina, and this quantity is expressed in  trolands .    
</p>
<p>5.1.2     Wavelength and Spectral Composition 
</p>
<p>  As a whole, the  electromagnetic   spectrum ranges from 10 &minus;14  to 10 8  m. This, how-
</p>
<p>ever, is only the part of the spectrum that is visible. The eye can only perceive 
</p>
<p>wavelengths that lie between 400 and 700 nm (Fig.  5.1 ). A nanometer is 10 &minus;9  m. 
</p>
<p>Waves that are a little below 400 nm are called ultraviolet rays; waves above 700 nm 
</p>
<p>are referred to as infrared rays. Although at the physical level the variety of waves 
</p>
<p>ranging from 400 to 700 nm is a continuum, perceptually, the human observer rather 
</p>
<p>5 Color Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>69
</p>
<p>distinguishes color categories. We can distinguish hundreds of colors, but in every-
</p>
<p>day life, we most often refer only to a few categories. In fact, we will see in the next 
</p>
<p>section to what refers exactly the term color.
</p>
<p>   It is extremely rare that a light beam contains only one wavelength. Should this 
</p>
<p>happen, it would be called a monochromatic light. Most often, a light beam com-
</p>
<p>prises several wavelengths and thus composes a so-called polychromatic light. All 
</p>
<p>the light energy, however, will not necessarily be distributed equally among all 
</p>
<p>wavelengths. Indeed, different lights vary according to their different spectral com-
</p>
<p>positions. The relative importance of the different waves therefore varies from one 
</p>
<p>light to another. 
</p>
<p> Between a monochromatic light and a polychromatic light extending over a wide 
</p>
<p>range of waves, there are many possible variations. If a light is monochromatic, it 
</p>
<p>will be reported as being pure. Indeed, the more light is concentrated in a narrow 
</p>
<p>band, the purer it is. In contrast to the purity of the monochromatic light, there may 
</p>
<p>be a case where, for a given beam, all the light energy of all visible wavelengths is 
</p>
<p>distributed into equal proportions. In such a case, we will refer to a white light, and 
</p>
<p>the purity of this light will be null (zero). 
</p>
<p> To end this section, it is relevant to note that the composition of the light that reaches 
</p>
<p>the eye depends on two factors. Of course, it depends on the spectral composition of the 
</p>
<p>light emitted by a source. It also depends on the properties of a given surface. We refer 
</p>
<p>  Fig. 5.1    Visible 
</p>
<p>wavelength in the 
</p>
<p>electromagnetic spectrum       
</p>
<p> 
</p>
<p>5.1 Description of Light</p>
<p/>
</div>
<div class="page"><p/>
<p>70
</p>
<p>to refl ective properties, in the case of refl ected light, or to transmission properties, when 
</p>
<p>light is transmitted through something. In short, two factors determine what reaches to 
</p>
<p>the eye: the emitted light and the properties of a given surface.    
</p>
<p>5.2     Perceptual Dimensions of Color 
</p>
<p>  What is normally called  color   most often refers to one of the three basic dimensions 
</p>
<p>that make up the experience of color. This dimension often called &ldquo;color&rdquo; is indeed 
</p>
<p>hue. There are chromatic hues (green, yellow, etc.) and achromatic hues. Chromatic 
</p>
<p>hues are determined by the wavelength, but the achromatic hues rather range from 
</p>
<p>white to black, passing through the different shades of gray. In the latter case, their 
</p>
<p>hue is neutral (we can say that there is no hue). 
</p>
<p> If the different shades of gray do not differ in their hue, how can we distinguish 
</p>
<p>them? The eye can discriminate these grays, and the black and the white, on the basis 
</p>
<p>of the different degrees of lightness. The continuum extends from zero lightness (the 
</p>
<p>case of black) to maximum lightness or almost (the case of white). In between, there is 
</p>
<p>a whole continuum of gray. In the same way that there are different degrees of lightness 
</p>
<p>for distinguishing achromatic stimuli, there are different degrees of lightness for chro-
</p>
<p>matic stimuli. For either chromatic or achromatic hue, it is indeed the term brightness 
</p>
<p>that is used to refer to this concept of lightness or lightness of stimuli. More specifi -
</p>
<p>cally, brightness will be qualifi ed as light or dark when describing a surface, but when 
</p>
<p>dealing with a light source, the description will be in terms of more or less intense. 
</p>
<p> In addition to hue and brightness, there is a third perceptual dimension for describing 
</p>
<p>a visual stimulation. This third dimension is called saturation and refers to the degree of 
</p>
<p>purity of light. For example, one can have the impression that a particular green seems to 
</p>
<p>contain more or less green or, in other words, seems to contain more or less gray. When 
</p>
<p>an impression of gray is larger, it is that the light has lost purity. A light that is losing in 
</p>
<p>purity is said to be less and less saturated. On the contrary, if a green, for instance, seems 
</p>
<p>very accentuated or highly concentrated, it means that the saturation level is high. 
</p>
<p> If a color would contain a lot of gray to the point of losing the impression that 
</p>
<p>there is any color, this would mean that its saturation is null (zero). What would be 
</p>
<p>perceived then would be located somewhere between white and black. Figure  5.2  
</p>
<p>synthesizes the three fundamental dimensions to be understood to fully grasp what 
</p>
<p>can be experienced with respect to colors. 
</p>
<p>5.3        Color Mixtures 
</p>
<p> In order to effi ciently describe the experience of color perception, we must integrate 
</p>
<p>the information above about the physical bases of light stimulation, as well as other 
</p>
<p>principles. Thus, it is necessary to understand the concept of primary colors and to 
</p>
<p>distinguish between additive and subtractive color mixtures. 
</p>
<p>5 Color Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>71
</p>
<p>5.3.1     Primary Colors 
</p>
<p>  Despite the adaptive  signifi cance   of colors in many animal species, and human life 
</p>
<p>in general, it was not until the seventeenth century that new ideas allowed some 
</p>
<p>understanding of the perception of light and color. Until then, the perception of what 
</p>
<p>appeared white to people was interpreted as an absence of color. Intuitively, this 
</p>
<p>na&iuml;ve interpretation was quite appropriate. 
</p>
<p> Supported by a simple empirical demonstration, Isaac Newton reported this impor-
</p>
<p>tant idea: the white rather consists of a summation of all colors. His experience consisted 
</p>
<p>of passing beams of white light (sun rays) through a small opening and then through a 
</p>
<p>prism (Fig.  5.3 ). Beyond the prism, these rays reached a screen. On the screen, these rays 
</p>
<p>did not appeared white anymore, but rather showed the entire color spectrum, the dif-
</p>
<p>fraction of the different rays being linked to their wavelength. Newton completed his 
</p>
<p>argument by adding, reversed, a second prism which had the effect of recomposing 
</p>
<p>white light. This demonstration led Newton to conclude that all colors, that is to say, all 
</p>
<p>the wavelengths, were contained in the white light. Newton also advanced another great 
</p>
<p>principle of color perception: to any color corresponds a second color which, mixed with 
</p>
<p>the fi rst, leads to white. These colors are called complementary colors.
</p>
<p>   Another great idea would later advance our understanding of color perception: there 
</p>
<p>are primary colors, and there are three such primary colors. Primary colors are colors 
</p>
<p>whose combination allows the production of white and the whole range of other colors. 
</p>
<p>Many combinations of colors may constitute the three primary colors. The key point is 
</p>
<p>to select three colors where the mixture of two of them cannot produce the third. On the 
</p>
<p>basis of an arbitrary decision of the   Commission internationale de l&rsquo;&eacute;clairage  (CIE)  , the 
</p>
<p>three primary colors are defi ned as blue (435.8 nm), green (546.1 nm), and red (700 nm).   
</p>
<p>  Fig. 5.2    The three basic dimensions at the basis of different shades of colors. The different hues 
</p>
<p>are on the  left , and the  green squares  on the  right  have different brightness and different 
</p>
<p>saturations       
</p>
<p> 
</p>
<p>5.3 Color Mixtures</p>
<p/>
</div>
<div class="page"><p/>
<p>72
</p>
<p>5.3.2     Addition and Subtraction 
</p>
<p>  These different  concepts   relative to light and color are somewhat counterintuitive 
</p>
<p>in that they fail to explain certain phenomena observed in everyday life. For 
</p>
<p>example, working with crayons, each child has experienced the emergence of the 
</p>
<p>green when blue and yellow were mixed. This observation leads some children to 
</p>
<p>believe, wrongly, that yellow, but not green, is a primary color because green 
</p>
<p>would result from a mixture. However, the mixture of two light beams projected 
</p>
<p>on a same location, one that would previously been passed through a yellow fi lter 
</p>
<p>and the other through a blue fi lter, will not permit to obtain green. Understanding 
</p>
<p>the difference in the results obtained with crayons and with light beams requires 
</p>
<p>distinguishing between the following two basic concepts: the additive mixtures 
</p>
<p>and the subtractive mixtures. 
</p>
<p> Common experiences are examples of subtractive mixtures. They are based on 
</p>
<p>the mixture of pigments, that is to say, on the fact that different objects contain a 
</p>
<p>substance which absorbs certain wavelengths and refl ects others. Thus, the color of 
</p>
<p>objects does not depend on the properties of light, but rather on how pigments 
</p>
<p>respond to light. In other words, an additive mixture is based on the addition of 
</p>
<p>wavelengths, while a subtractive mixture prevents certain wavelengths to contribute 
</p>
<p>in the color of an object. This impediment is caused by the presence, in this object, 
</p>
<p>of pigments which absorb certain wavelengths. These absorbed waves cannot be 
</p>
<p>refl ected and, by extension, will not reach the eye and will not be perceived. With 
</p>
<p>an additive mixture of colors, the resulting color will be brighter than each of the 
</p>
<p>colors used in the mixture; in contrast, a subtractive mixture will result in a decrease 
</p>
<p>of the brightness compared to each of the colors used. Figure  5.4  illustrates the 
</p>
<p>concepts of subtractive and additive mixtures.
</p>
<p>   It is possible to predict the addition of certain colors on the basis of certain rules. 
</p>
<p>The understanding of these rules is facilitated by observing the color circle shown 
</p>
<p>in Fig.  5.5 . This circle illustrates two subjective dimensions of color: (1) the circum-
</p>
<p>ference means the hue and (2) the radius designates the saturation. The circumfer-
</p>
<p>ence covers all wavelengths of the visible spectrum from violet (about 400 nm) to 
</p>
<p>White light
</p>
<p>Violet
Indigo
Blue
Green
Yellow
Orange
Red
</p>
<p>  Fig. 5.3    Newton&rsquo;s experiment demonstrating that  white light  contains all colors of the spectrum       
</p>
<p> 
</p>
<p>5 Color Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>73
</p>
<p>red (about 700 nm). Also, the further away we get from the center of the circle, the 
</p>
<p>greater the saturation is. The center corresponds to a zero degree of saturation, i.e., 
</p>
<p>gray or even to white if the brightness is high.
</p>
<p>   On this circle, the complementary colors are diametrically opposed. Also, the 
</p>
<p>closer we get to the center, the less saturated they are. If we take two equal amounts 
</p>
<p>of light energy associated with two complementary colors which are located at 
</p>
<p>equal distances from the center, then the resulting mixture gives white (or gray). 
</p>
<p>Red
</p>
<p>Blue Green
</p>
<p>Cyan
</p>
<p>Yellow Magenta
</p>
<p>  Fig. 5.4    Illustration of the resulting color from an additive ( left ) or subtractive ( right ) mixture       
</p>
<p>  Fig. 5.5    Illustration with the  color wheel  of the resulting additive mixture. For a given pair of 
</p>
<p>points diametrically in opposition, if one provides the same amount of intensity on each side, the 
</p>
<p>resulting mixture is a point in the middle, i.e., some  gray  or  white        
</p>
<p> 
</p>
<p> 
</p>
<p>5.3 Color Mixtures</p>
<p/>
</div>
<div class="page"><p/>
<p>74
</p>
<p>However, if one of these two complementary colors is less saturated than the other, 
</p>
<p>it is necessary to increase the intensity of the light fl ux on the less saturated so that 
</p>
<p>no color persists. Also, by choosing two colors on this circle that are not comple-
</p>
<p>mentary, it will not be possible to obtain an achromatic mixture. In addition, all 
</p>
<p>colors are not present on the color circle. These are called  nonspectral colors   and 
</p>
<p>can only be obtained by mixing at least two colors. Purple is an example of non-
</p>
<p>spectral color. 
</p>
<p> The addition of color also obeys another law. If we mix equal amounts of differ-
</p>
<p>ent colors, the resulting brightness is greater than the average brightness of the 
</p>
<p>colors used in the mixture. Also, if the mixed quantities are unequal, the resulting 
</p>
<p>brightness is closest to that of the color presented in highest quantity. 
</p>
<p> Finally, note that there are other types of color mixtures. These other color mix-
</p>
<p>tures are reported below in a section about color effects and illusions.    
</p>
<p>5.4     Theories of Color Vision 
</p>
<p>  Two major views  have   long been opposed when attempting to explain color vision. 
</p>
<p>A fi rst view point, supported by Thomas Young in the early nineteenth century and 
</p>
<p>also by Hermann von Helmholtz a few decades later, is known as trichromatic 
</p>
<p>theory of Young- Helmholtz  . Essentially, this theory  states   that color vision depends 
</p>
<p>on the presence of three types of receptors in the eye. It is postulated that these 
</p>
<p>receptors are sensitive to all wavelengths, with a maximal sensitivity for a given 
</p>
<p>length. These receptor types are more sensitive to blue, green, and red. In fact, 
</p>
<p>Young and Helmholtz knew that, for a person having no color vision defi cit, an 
</p>
<p>additive mixture of red and green gives yellow. So they explained the vision of yel-
</p>
<p>low by the excitation of the receptors of red and receptors of green. Indeed, accord-
</p>
<p>ing to them, any color could be explained by different excitation levels of the three 
</p>
<p>receptor types. 
</p>
<p> Later in the nineteenth century, various observations not compatible with the 
</p>
<p>trichromatic theory led Ewald  Hering   to develop another theory of color vision. In 
</p>
<p>particular, Hering observed that people asked to choose colors that do not seem to 
</p>
<p>be a mixture tend to discern four, and not three, primary colors: blue, green, red, and 
</p>
<p>yellow. He also observed that people never report perceiving a greenish red or a yel-
</p>
<p>lowish blue. Moreover, the fact that people perceiving neither red nor green can 
</p>
<p>perceive yellow was also a major objection to the trichromatic theory of Young- 
</p>
<p>Helmholtz. Finally,  Hering   also knew that prolonged exposure to a color can create 
</p>
<p>a strange effect, as discussed below. 
</p>
<p> Thus, Hering rather proposed the  opponent process  theory to account for the 
</p>
<p>wide range of perceived colors. This theory states that color perception is based on 
</p>
<p>the operation of pairs of opponent colors. These pairs are red and green, blue and 
</p>
<p>yellow, and white and black to refl ect brightness perception. In this way, if a neu-
</p>
<p>ron is excited by the presence of a color, it will be inhibited by the presence of the 
</p>
<p>opposite color. 
</p>
<p>5 Color Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>75
</p>
<p> Interestingly,  contemporary   data from physiology provide support for both theo-
</p>
<p>ries. With a technique called microspectrophotometry, it is possible to quantify the 
</p>
<p>proportion of light, for a given wavelength, absorbed by the photoreceptors. Thus, 
</p>
<p>it was possible to observe that there are actually three types of cone, each having  a 
</p>
<p>  maximum light  absorption   for different wavelengths, as suggested by the theory of 
</p>
<p>Young and Helmholtz. The exact value of these wavelengths varies somewhat 
</p>
<p>depending on the study. For instance, maximum absorptions were reported at 420, 
</p>
<p>530, and 560 nm in macaques (Bowmaker, Dartnell, &amp; Mollon,  1980 ) and 425, 534, 
</p>
<p>and 564 nm in humans (Bowmaker &amp; Dartnell,  1980 ). Since these values loosely 
</p>
<p>correspond to red, green, and blue, respectively, some authors use the terms the red 
</p>
<p>cones, green cones, and blue cones (sometimes also called γ, α, and β fi bers). 
</p>
<p>Although it may be simpler to adopt these terms, especially in the context of the 
</p>
<p>trichromatic theory, it is more accurate to call them S, M, and L to respectively 
</p>
<p>designate the cones having maximum light absorption at short, medium, and long 
</p>
<p>wavelengths. Indeed, as the values reported above indicate, the values are closer to 
</p>
<p>the long wavelengths than to the short ones. 
</p>
<p> Other physiological data rather allow to support the other theory of color vision, 
</p>
<p>that of Hering. However, contrary to the contention of Hering, these opponent pro-
</p>
<p>cesses are not located at the receptor level. An investigation of the functions of 
</p>
<p>nerve cells beyond photoreceptors reveals that some cells actually work according 
</p>
<p>to an opponent principle. This investigation was conducted at different levels 
</p>
<p>between the photoreceptors and the striate cortex, particularly at the level of the 
</p>
<p>ganglion cells and of the lateral geniculate nucleus. In both cases, the opponent 
</p>
<p>responses are comparable. Based in particular on the wavelength at which a cell 
</p>
<p>becomes inhibited rather than excited, DeValois, Abramovet, and Jacobs ( 1966 ) 
</p>
<p>grouped the opponent cells of the lateral geniculate nucleus into four categories (see 
</p>
<p>also DeValois &amp; DeValois,  1988 ):
</p>
<p>  R G R G B Y B Y+ - - + + - - +    
</p>
<p>where R = red, G = green, B = blue, and Y = yellow and where + means that cells are 
</p>
<p>excited by the presence of the designated color and &minus; means that they are inhibited 
</p>
<p>(Fig.  5.7 ). We also fi nd two types of non-opponent cells in the lateral geniculate 
</p>
<p>nucleus. These cells respond to all stimulations, either by increasing their activity 
</p>
<p>(white+/black&minus;) or by decreasing it (black+/white&minus;). 
</p>
<p> Thus, color vision can be explained with a system that is somewhat of a compro-
</p>
<p>mise between the theories of Young-Helmholtz and Hering. Specifi cally, this sys-
</p>
<p>tem, shown schematically in Fig.  5.6 , has two levels: the three types of cones 
</p>
<p>transmit information to a more central level of processing (DeValois &amp; DeValois, 
</p>
<p> 1975 ). In the retina,  the   information  is   captured by three types of cones reacting 
</p>
<p>optimally to their wavelength: C cones to short waves, M for medium waves, and L 
</p>
<p>for long waves. At ganglion cell level, the information coming from the photorecep-
</p>
<p>tors exert an activating or inhibiting effect on some of the four types of opponent 
</p>
<p>cells or two types of non-opponent cells. For example, the cones sensitive to shorter 
</p>
<p>wavelengths would activate the B+Y&minus; system and inhibit the Y+B&minus; system.
</p>
<p>5.4 Theories of Color Vision</p>
<p/>
</div>
<div class="page"><p/>
<p>76
</p>
<p>   With such a two-level system,    it is possible to explain hue with the excitation of 
</p>
<p>the R+G&minus;, R&minus;G+, B+Y&minus; and B&minus;Y+ opponent processes. These processes also help 
</p>
<p>explain why complementary colors cannot coexist. For example, we cannot per-
</p>
<p>ceive greenish red, but perceiving greenish blue makes sense (if the S and M cones 
</p>
<p>are excited). Brightness would be explained by the activity of non-opponent white- 
</p>
<p>black and black-white cells. Finally, saturation would depend on the fact that the 
</p>
<p>activity of the opponent processes would be higher than the one of the 
</p>
<p>White + Black&minus; system. 
</p>
<p> Finally, color perception probably also depends on other complex mechanisms. 
</p>
<p>Researchers have identifi ed, in the striate cortex, clusters of cells that react only to 
</p>
<p>colors (Livingstone &amp; Hubel,  1987 ; Michael,  1978 ). A property of these cells is to 
</p>
<p>have double-opponent receptive fi elds.   
</p>
<p>5.5     Chromatic Effects 
</p>
<p>   While there are only few  defi nitive   explanations of the different perceptual phenom-
</p>
<p>ena related to color, it remains relevant to describe some of them. Some phenomena 
</p>
<p>reveal that color is not simply a matter of wavelengths or physical stimulation. It is 
</p>
<p>possible to obtain one particular color mixture depending on how these colors  are   
</p>
<p>presented. It may indeed happen that the brain makes an average synthesis of what 
</p>
<p>  Fig. 5.6    Compromise theory by De Valois and De Valois where color vision depends on the neural 
</p>
<p>activity at two levels. (1) Cones are particularly sensitive to short, medium, and long wavelengths. 
</p>
<p>(2) At the next level, there are opponent (the  four rectangles  on the  left ) and non-opponent (the two 
</p>
<p>on the  right ) processes.  B  blue,  Y  yellow,  G  green,  R  red,  Z  black,  W  white, + activation,  &minus;  inhibi-
</p>
<p>tion,  continuous line  activation,  dotted line  inhibition       
</p>
<p> 
</p>
<p>5 Color Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>77
</p>
<p>is presented. Colored portions of a visual fi eld may be confused because of their 
</p>
<p>density. For example, if small squares of two different colors alternate horizontally 
</p>
<p>and vertically, you can distinguish them from each other if you are close to the 
</p>
<p>image. You discern correctly the color of each square. However, if you suffi ciently 
</p>
<p>move away from the image, you will reach a point where you will no longer distin-
</p>
<p>guish colors correctly. The entire image will appear in a different color, which will 
</p>
<p>indeed be the synthesis of the two colors used. This phenomenon is referred to as a 
</p>
<p>spatial optical mixing. In the same vein, it is possible to create conditions leading to 
</p>
<p>a temporal optical mixing. This time, you might very well discriminate between two 
</p>
<p>colors on a circle, but if you were turning the circle (as when spinning a top), this 
</p>
<p>would lead, at a certain speed, to the inability to succinctly distinguish the two col-
</p>
<p>ors, and the brain would be forced to make an average synthesis of the two colors. 
</p>
<p> The effects caused by temporal constraints are not restricted to cases involving 
</p>
<p>colors. Sometimes, black and white arrangements, such as the one in Fig.  5.7 , can 
</p>
<p>generate different colors. If one spins such black stripes on white background, col-
</p>
<p>ors appear. Since these colors vary from one person to the other, this phenomenon 
</p>
<p>is called subjective colors. According to Henri Pi&eacute;ron, a French psychologist who 
</p>
<p>worked in the fi rst half of the twentieth century, the confi guration and the rotational 
</p>
<p>speed of the disk would infl uence selectively the receptors to red, green, and blue as 
</p>
<p>the receivers do not all have the same response speed. Other authors argue instead 
</p>
<p>that the explanation is not located in the retina itself. The stimulation would reach 
</p>
<p>the brain directly and would produce a sequence of neural events that would be 
</p>
<p>interpreted, because of its resemblance to the actual effect of colored stimuli, as a 
</p>
<p>chromatic stimulus.
</p>
<p>   The   simultaneous contrast    is a subjective enhancement of color differences. In 
</p>
<p>other words, the perceived hue depends on the context (Fig.  5.8 ), and this context 
</p>
<p>can accentuate differences. This could be caused, according to Helmholtz, by an 
</p>
<p>unconscious inference about brightness. We will return to this concept of uncon-
</p>
<p>scious inference, in the context of depth perception (Chap.   7    ). For Hering, the effect 
</p>
<p>would rather be due to lateral inhibition (which will be discussed in the next chap-
</p>
<p>ter). Essentially, this means that when a region of the reception system is excited by 
</p>
<p>  Fig. 5.7    Arrangement in 
</p>
<p> black  and  white &mdash;
</p>
<p>Benham&rsquo;s top&mdash;which 
</p>
<p>allows, when spinning 
</p>
<p>quickly, to create an 
</p>
<p>impression of color       
</p>
<p> 
</p>
<p>5.5 Chromatic Effects</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-31791-5_7">http://dx.doi.org/10.1007/978-3-319-31791-5_7</a></div>
</div>
<div class="page"><p/>
<p>78
</p>
<p>a chromatic stimulus, its neighboring regions remain insensitive to stimuli of the 
</p>
<p>same color. What is obtained is rather the activation of the response to the comple-
</p>
<p>mentary color.
</p>
<p>   In contrast to a simultaneous contrast, there are   assimilation     or    equalization 
</p>
<p>effects   . This effect is a subjective attenuation of color differences or of brightness 
</p>
<p>differences when stimuli are placed close to each other. In other words, this effect 
</p>
<p>occurs when a color borrows somehow the color of its neighbor. 
</p>
<p> A fairly spectacular phenomenon occurs when fi xating a surface, and then 
</p>
<p>another surface, rather than looking at two stimuli spontaneously as was the case for 
</p>
<p>simultaneous contrast or assimilation effect. This temporal phenomenon is called 
</p>
<p>  afterimage   . When you fi xate on a color image over a long period, say 1 min, then 
</p>
<p>immediately after fi xate on a white surface, you see an afterimage appearing. 
</p>
<p>However, rather than seeing the initial colors, i.e., the ones you have previously 
</p>
<p>been fi xating, you will eventually see the complementary colors appearing on the 
</p>
<p>white surface (Fig.  5.9 ).
</p>
<p>   According to some researchers, the prolonged exposure leading to the formation 
</p>
<p>of consecutive images is due to the fatigue of receptors specialized in the perception 
</p>
<p>of the presented color(s). If, after prolonged exposure, we look at a white surface, 
</p>
<p>  Fig. 5.8    Example of simultaneous contrast where the  pink square  in the  middle  appears  darker  on 
</p>
<p>the  right  than on the  left        
</p>
<p>  Fig. 5.9    Is it possible to 
</p>
<p>change this fl ag of Ivory 
</p>
<p>Coast into that of France? 
</p>
<p>Yes. You simply need to 
</p>
<p>fi xate on the fl ag above for 
</p>
<p>a minute and then look at a 
</p>
<p> white surface . After a few 
</p>
<p>seconds, you should see 
</p>
<p>new colors appearing       
</p>
<p> 
</p>
<p> 
</p>
<p>5 Color Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>79
</p>
<p>which contains all colors, there will be a greater response of the non-fatigued recep-
</p>
<p>tors. These receptors are indeed those responding to the complementary color(s). 
</p>
<p>The existence of such a phenomenon in which the complementary colors appear 
</p>
<p>after a fi xation period provides support to the Hering&rsquo;s position described above. 
</p>
<p> Another form of color aftereffect, called the  McCollough effect  , is particularly 
</p>
<p>fascinating (McCollough,  1965 ). The effect can be obtained by fi xating each of the 
</p>
<p>top gratings (see Fig.  5.10 ) for about fi fteen seconds and then by looking at the other 
</p>
<p>gratings below. The color of the perceived afterimage depends on the orientation of 
</p>
<p>the bars (of the gratings). The color of the afterimages will tend to be red between 
</p>
<p>the vertical bars but green between the horizontal bars. While it is believed that the 
</p>
<p>  Fig. 5.10    Images required for producing the  McCollough effect   (see text)       
</p>
<p> 
</p>
<p>5.5 Chromatic Effects</p>
<p/>
</div>
<div class="page"><p/>
<p>80
</p>
<p>consecutive images like the one described in the previous paragraph should be 
</p>
<p>attributable to the neuronal adaptation at the retina level (a low level of processing), 
</p>
<p>the McCollough effect would rather be caused at a higher processing level, i.e., 
</p>
<p>where orientation is processed (namely, in the V1 area). And what would happen if 
</p>
<p>you lean your head or if you turn the book at 90&deg;? Try it!
</p>
<p>   Finally, just as there is a constancy phenomenon for other dimensions of 
</p>
<p>visual perception, as we will see later, there is the so-called  color constancy  . 
</p>
<p>With color constancy, it remains possible to recognize the true color of objects 
</p>
<p>despite the chromatic variations of lighting,  if   these variations remain moderate. 
</p>
<p>In other words, even if the daylight starts fading, or if an interior room is dimly 
</p>
<p>lit (enough to stimulate the cones) or illuminated with light of a certain color (but 
</p>
<p>not too intense), a red sweater should continue to appear red, as it is, for exam-
</p>
<p>ple, in the light of day. Thus, the visual system probably has the property of 
</p>
<p>transmitting the differences in spectral composition, just like it can transmit 
</p>
<p>intensity differences.    
</p>
<p>5.6     Clinical Aspects 
</p>
<p>  There are several  color   vision disorders. The diffi culty of discriminating yellow and 
</p>
<p>blue affects equally men and women and touches less than 1 % of the population. 
</p>
<p>The most common color vision problems are related to the discrimination of red and 
</p>
<p>green and occur more frequently in men than in women (approximately 8 % against 
</p>
<p>less than 1 %). This difference is caused by genes. Genes associated with these col-
</p>
<p>ors are located on X chromosome. Considering that women receive two X chromo-
</p>
<p>somes instead of one as is the case with men, they will have this color vision disorder 
</p>
<p>only if both X chromosomes are defi cient. That is the reason why women are less 
</p>
<p>likely to be affected by a red-green defi cit. 
</p>
<p> There are three major categories of abnormal color vision. The fi rst is called 
</p>
<p>abnormal   trichromatism    and refers to a partial insensitivity to one of the three pri-
</p>
<p>mary colors. In this category, we distinguish the protanomaly, deuteranomaly, and 
</p>
<p>tritanomaly. People with protanomaly (approximately 1 % of men are affected) 
</p>
<p>require a greater amount of red for perceiving as yellow the red-green mixture. With 
</p>
<p>deuteranomaly, there is a need for a greater amount of green for perceiving as yel-
</p>
<p>low a red-green mixture: it affects about 5 % of men. Finally, we refer to tritanomaly 
</p>
<p>for describing the need for a greater amount of blue for perceiving as &ldquo;blue green&rdquo; 
</p>
<p>a mixture of blue green. 
</p>
<p> A second major category of color vision defi cit is called abnormal   dichromatism    
</p>
<p>and consists in a complete insensitivity to one of the three primary colors. Thus, a 
</p>
<p>protanope, who is blind to red (affecting approximately 1 % of men), sees in yellow 
</p>
<p>and blue, since red and bluish green are seen as gray. A deuteranope is blind to 
</p>
<p>green (affecting about 1 % of men) and also sees in yellow and blue since the bluish 
</p>
<p>red and green are seen as gray. Finally, a tritanope sees only red and green, but this 
</p>
<p>defi cit is very rare. Purple and yellow green are seen as gray. 
</p>
<p>5 Color Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>81
</p>
<p> The third major category is   monochromatism   . Extremely rare, this problem 
</p>
<p>means that vision is summed up in shades of gray. It is caused by the lack of func-
</p>
<p>tioning cones, and, therefore, there is no surprise that this problem results in a 
</p>
<p>decreased visual acuity. 
</p>
<p> It should also be noted that color vision disorders can be caused by damage to the 
</p>
<p>V4 area of the visual cortex and not only by a problem related to the functioning of 
</p>
<p>the cones. Finally, it is possible to detect color vision problems using the Ishihara 
</p>
<p>test. This test consists of a series of color plates on which appear through a set of 
</p>
<p>colored points, numbers, or shapes. People with color vision disorders have diffi -
</p>
<p>culty, for example, to correctly identify certain numbers when they are unable to 
</p>
<p>perceive the colors used to illustrate the numbers.        
</p>
<p>5.6 Clinical Aspects</p>
<p/>
</div>
<div class="page"><p/>
<p>83&copy; Springer International Publishing Switzerland 2016 
S. Grondin, Psychology of Perception, DOI 10.1007/978-3-319-31791-5_6
</p>
<p>    Chapter 6   
</p>
<p> Form Perception                     
</p>
<p>             We could say that we live in a world where our retinas are constantly assaulted from 
everywhere. Thousands of potential stimuli in the immediate environment may 
reach our eyes at any moment. These various stimuli result from the interactions 
between the surface properties and those coming from light sources (intensities and 
wavelengths). Moreover, our environment is sometimes stable, sometimes not; 
sometimes, things are moving and sometimes, we are moving. Therefore, there is 
constantly an incredible variety of stimuli on the retina. Nevertheless, we extract 
from all this information something intelligible; moreover, this task is completed 
without effort. This remarkable effi ciency is made possible by the functioning of 
some basic mechanisms described below. 
</p>
<p>6.1     Perception of Contours 
</p>
<p> We can extract a shape in the environment because it provides brightness variations. 
These variations are such that there are boundaries between objects. We know that 
there is somewhere a given object because we perceive delimitation, or an edge, 
between this object and its surroundings. We call this edge a contour. This contour 
could be considered the elementary unit of form perception. 
</p>
<p> To fully realize the importance of a contour, just think about what happens 
during a snowstorm. When there is too much blowing snow, it becomes no longer 
possible to see anything, even when you try to keep your eyes open, because the 
fi eld is evenly lit (in German, this phenomenon is referred to as a   ganzfeld   &mdash;i.e., 
complete fi eld). If you want to experience a ganzfeld without waiting for the next 
snowstorm, simply try the following activity. Take two white plastic spoons or 
even the two halves of a white ping-pong ball, and draw a small but clearly vis-
ible colored line on the inside of the spoons or half balls. Then, just make sure to 
completely cover the eyes with spoons or half balls so that no light can enter. 
Keep your eyes open while fi xating the inside line and avoid any eye movements. </p>
<p/>
</div>
<div class="page"><p/>
<p>84
</p>
<p>You need to maintain this fi xation activity for several seconds so that the line 
remains at the same place on the retina. 
</p>
<p> What happens after a few seconds (less than a minute)? If there was no move-
ment of your eyes, the line disappears. For perceiving form, even just a single line, 
it takes brightness variations between this form and its environment. We clearly see 
the line at fi rst, but eventually lose sight if we prevent the visual system from restor-
ing the perception of a contour. In fact, the image never remains stable for long on 
the retina. The image on the retina keeps moving because there are always small eye 
movements called microsaccades. These small involuntary eye movements create 
variations in time on the receptors of the retina. What the experiment with the 
spoons or half balls teaches us is not only that it takes contour perception to see but 
also that it is necessary, for avoiding the disappearance of the contour, that the image 
does not stabilize on the retina. 
</p>
<p>6.1.1     Edges and Subjective Contours 
</p>
<p>  The contour depends  mostly   on the presence of an edge. The latter can be defi ned 
as a change in luminance or spectral composition occurring somewhere in the envi-
ronment. Most often in the environment, contrast or texture changes will create 
edges. In other words, the contours are typically due to a physical phenomenon, 
namely, the presence of boundaries. In this case, we sometimes refer to it as the 
fi rst-degree contours (or fi rst-level contours). 
</p>
<p> As shown in Fig.  6.1 , the presence of an edge is not always necessary for the 
formation of a contour. It is possible to perceive contours without any physical 
changes. Such conditions are referred to as subjective contours or second-level 
contours. We also refer to the term emerging contours to describe these cases 
where a contour is perceived although there is absolutely no physical variation 
producing it.
</p>
<p>   In short, perceiving a form requires to perceiving contours. The detection of 
these contours depends mostly on the presence of an edge caused by the heterogene-
ity in the stimulation. The perception of these edges also requires that variations of 
this stimulation occur on the retina. These variations are made possible by eye 
</p>
<p>  Fig. 6.1    Examples of subjective contours. You can observe a  triangle  and a  square  on the  left  and 
a  horizontal line  on the  right        
</p>
<p> 
</p>
<p>6 Form Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>85
</p>
<p> microsaccades. Finally, even in the absence of edges, there may be contours, called 
subjective, but their presence still requires the presence of special conditions in the 
environment as shown in Fig.  6.1 .   
</p>
<p>6.1.2     Lateral Inhibition 
</p>
<p>   There is a basic  mechanism   in the visual system for increasing  brightness   variations 
that generate a border. When light reaches the retina at a given point, what is located 
just next to this point undergoes inhibition. The mechanism by which the activity of 
certain nerve cells affects that of its neighbors is called  lateral inhibition . This phe-
nomenon, fi rst reported by Keffer Hartline and Floyd H. Ratliff, is a fundamental 
notion of retinal physiology. 
</p>
<p> Hartline and Ratliff ( 1957 ) worked on the visual system of horseshoe crab. This 
animal has the distinction of having a series of small elementary eyes, called omma-
tidia, rather than a dense neural network. This feature makes it easier to stimulate 
each eye when the effect of lateral inhibition is demonstrated. Each ommatidium 
can somehow be compared to the ganglion cell of the human visual system. 
</p>
<p> In the work of Hartline and Ratliff, the electrical activity of a nerve fi ber, say A, 
is collected by means of an electrode. When the receptor corresponding to fi ber A 
receives light stimulation, the electrical activity increases, indicating that the activ-
ity is linked to the stimulation (Fig.  6.2 ). When only one receptor corresponding to 
a neighboring fi ber, B, is stimulated, the electrical activity collected from fi ber A is 
</p>
<p>Normal activity at A
</p>
<p>Light on A
</p>
<p>Light on B
</p>
<p>Activity at A
</p>
<p>L
ev
</p>
<p>el
 o
</p>
<p>f 
a
ct
</p>
<p>iv
it
y
 a
</p>
<p>t 
A
</p>
<p>ON
</p>
<p>ON
</p>
<p>+
</p>
<p>&ndash;
</p>
<p>  Fig. 6.2    Illustration of the lateral inhibition effect exerted on a cell,  A , previously activated by a 
light source, by the arrival of a light stimulus to a cell,  B , located close to  A        
</p>
<p> 
</p>
<p>6.1 Perception of Contours</p>
<p/>
</div>
<div class="page"><p/>
<p>86
</p>
<p>not affected. This refl ects the independence of the activity of B on A when there is 
no direct stimulation on A. In a case where light stimulation is maintained on A, and 
another light stimulation excites B, then the electrical activity observed earlier on 
fi ber A is decreased. In other words, the activity on B exerts lateral inhibition, that 
is to say, it reduced the activity of neighboring fi ber A.
</p>
<p>   The strength of this inhibition depends essentially on two factors: the proxim-
ity between the nerve cells involved and the strength of the stimulation on the 
inhibitory cell. The stronger the activity of the inhibiting cell, the greater the inhi-
bition; similarly, the closer the inhibited and inhibitory cells, the greater the inhi-
bition effect. 
</p>
<p> Mutual effects of nerve cells or fi bers on each other can be quite complicated. 
Suffi ce to say, there may be a decreased inhibitory effect in a case like the follow-
ing one: Given fi bers A, B, and C arranged in this order. B has some inhibitory 
effect on A when fi ber C is not stimulated. However, when light stimulates C, the 
activity on C inhibits the activity of B. By having a reduced activity, B exerts in 
turn a less pronounced inhibitory effect on A. Thus, the electrical activity of A is 
higher if the fi bers A, B, and C are stimulated compared to when only fi bers A and 
B are stimulated. The activity recorded from A in the condition in which A, B, and 
C are stimulated remains nevertheless below that normally observed when only 
fi ber A is excited.    
</p>
<p>6.1.3     Mach Bands 
</p>
<p>   There are many  fascinating   perceptual effects which can be explained on the  basis   
of lateral inhibition. A classic example of the effect of lateral inhibition is illustrated 
by the demonstration called Mach bands. Ernst Mach, who revealed this effect, is 
the same Austrian physicist and philosopher who gave his name to the unit used to 
express the speed of sound. 
</p>
<p> Consider the following situation where, say, black (dark gray) and white (pale 
gray) are separated by a gray gradient (upper part of Fig.  6.3 ). Although black and 
white are both uniform (even luminance), the insertion of a gray gradient changes 
the perceived brightness: the black and white are not perceived anymore as uniform. 
Most people perceive a particularly small dark line (very black) on the side where 
the luminance is low and a particularly pale line (very white) on the side where the 
luminance is high. At these locations, on each side of the gray, thus appear Mach 
bands. The main interest of this demonstration is therefore located at the two places 
where luminance changes occur.
</p>
<p>   It is possible to explain this Mach band effect with the lateral inhibition exerted 
by nerve cells on each other. For example, if we take two points close to each other, 
near to the midpoint where the luminance is uniformly black, these two points are 
subjected to similar levels of inhibition caused by neighboring cells to the left and 
to the right. Thus, their brightness is the same. If we rather take a point X where the 
luminance change begins, then the inhibition exerted by the left and by the right 
</p>
<p>6 Form Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>87
</p>
<p>cells is not the same. If the transition initiates a luminance increase, the proportion 
of white of the physical stimulus increases, and, thus, the inhibition caused by the 
cells on this side on point X is larger than that exerted by the cells on the other side. 
So this transition line appears darker as it undergoes more inhibition. The same 
reasoning can be applied to the reverse situation: where a decrease in luminance 
begins as the inhibitory effect decreases. At this point of transition appears a brighter 
thin band. 
</p>
<p> One can also observe this Mach band phenomenon in Fig.  6.4  on which are illus-
trated a series of bands with uniform brightness. These bands do not appear uniform 
when viewed as a whole. If we do look at only one band, hiding somehow the oth-
ers, then its brightness is uniform because the luminance of a given band is uniform. 
It is the activity exerted by the ones on the others that determines the level of neural 
activity of each cell and, consequently, the brightness. In brief, the fi gure shows a 
series of lateral inhibition effects.  
</p>
<p>6.1.4        Factors Infl uencing the Perception of Contours 
</p>
<p>  Many  factors may   infl uence the creation of contours. For example, contours are 
perceived more easily when the visual acuity is greater. The acuteness being greater 
at the fovea, the contours appear more  clearly   in this region. The further away an 
image is moved from the fovea, the less clear the contours are. Similarly, subjective 
contours shown in Fig.  6.1  are examples of the infl uence of the spatial context on 
the creation of contours. 
</p>
<p>  Fig. 6.3    On the  lower 
panel , changes in 
luminance ( black line ) and 
brightness ( green line ) 
corresponding to the  black  
and  white image  ( upper 
panel ).  Arrows  indicate 
Mach bands. It is a little 
darker under the  left arrow  
and a little brighter under 
the  right arrow        
</p>
<p> 
</p>
<p>6.1 Perception of Contours</p>
<p/>
</div>
<div class="page"><p/>
<p>88
</p>
<p> The formation of a contour takes a minimum of stimulation intensity. The inten-
sity depends on the number of photons absorbed by the photoreceptors. Indeed, the 
ability of these photons to produce an effect depends on how long the eye has been 
stimulated. It takes a minimum of exposure time for a stimulus to be detected. 
Photons can benefi t from a temporal summation effect. If their arrival is not suffi -
ciently close in time, they lose that benefi t. This is essentially what Bloch&rsquo;s law 
refers to. It can be summarized as follows:
</p>
<p>  I T C&acute; =    
</p>
<p>where the interaction between the intensity,  I , and the exposure time,  T , results in a 
constant visual effect,  C . If a stimulus is very intense, it can be detected even if 
presented for a very short period, whereas a weaker stimulus will be detected only 
if presented for a longer period. 
</p>
<p> In fact, the interaction between time and intensity applies only for very short 
exposure times, i.e., of less than 100 ms. Beyond this period, the only crucial factor 
is the fact that the intensity is suffi cient or not for perceiving a stimulus. This 100- 
ms value holds for rods; for cones, this value would rather be 50 ms. Note that there 
is also a law, Ricco&rsquo;s law, which applies only to the fovea. According to this law, the 
detectability of stimuli is a combination of the intensity and of the stimulated area. 
</p>
<p> There are different demonstrations which illustrate the importance of the expo-
sure duration in the perception of contours. In this regard, an old experience of 
Werner ( 1935 ) is most relevant. In this experiment, a black circle and a black ring 
are presented alternately to a participant. The outer contour of the disk corresponds 
</p>
<p>  Fig. 6.4    Another illustration of the  Mach bands   where a series of stimuli, each of uniform lumi-
nance, appear  brighter  on the  left side  and  darker  on the  right side        
</p>
<p> 
</p>
<p>6 Form Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>89
</p>
<p>exactly to the inner contour of the ring (Fig.  6.5a ). The experimenter varies the 
exposure time of stimuli and the pause time between exposures. When the time 
interval between stimuli is smaller than 100 ms, the participant perceives a full cir-
cle (Fig.  6.5b ). If the interval between stimuli is more than 200 ms, the subject sees 
alternately the disk and the ring. Pauses with a duration ranging from 100 to 200 ms 
lead the participant to perceive only the ring. Thus, depending on a temporal factor, 
a masking effect may occur. The formation of the inner contour of the ring prevents 
the contour of the disk to be seen. And if it is the disk and only a half-ring (Fig.  6.5c ) 
that are presented for 100&ndash;200 ms, only the half-disk can be detected (Fig.  6.5d ). 
</p>
<p>6.2         Gestalt: Perceptual Organization 
</p>
<p> A century ago, Max Wertheimer developed a fi ne and infl uential way of approach-
ing the study of form perception. The school of thought, known as  Gestalt  , which 
means form (or &ldquo;whole form&rdquo;), also received contributions from Wolfgang Kohler 
and Kurt Koffka, other German specialists of the psychology of sensation and per-
ception, and collaborators of Wertheimer. The aim of the Gestalt psychology, which 
encompasses all the work on perceptual structuring, was to explain how the visual 
system combines the various elements available in the visual fi eld. 
</p>
<p> There is in this notion of Gestalt the idea that perceiving is more than the sum-
mation of the sensations produced by stimuli. There is an organization of these 
stimuli. A person organizes the elements of a visual scene for extracting meaning. 
The organization of these elements includes two aspects that will be described in the 
following paragraphs. There is fi rstly the distinction between fi gure and ground and 
secondly the grouping of elements according to some characteristics sometimes 
called the laws of Gestalt. 
</p>
<p>a b
</p>
<p>c d
</p>
<p>  Fig. 6.5     Disk  and  ring  
used in the experiment 
reported by Werner ( 1935 ). 
See text for explanation       
</p>
<p> 
</p>
<p>6.2 Gestalt: Perceptual Organization</p>
<p/>
</div>
<div class="page"><p/>
<p>90
</p>
<p>6.2.1     Figure/Ground Distinction 
</p>
<p>  When looking at a  visual   fi eld, some parts are different from others. We look in a par-
ticular way in order to highlight some parts of this fi eld. In a task as simple as looking at 
a piece of art on a wall, there is a way of looking. Our gaze is focused on the dominant 
object of our visual fi eld, the piece of art, and the nearby fi eld, the wall, serves as a back-
ground. So there is a fundamental distinction, the fi gure as opposed to the ground, in our 
way of looking. These two parts of the fi eld have their own characteristics. 
</p>
<p> In a visual scene, the contour seems to belong to the fi gure rather than to the 
ground. The fi gure looks like something and appears to be closer than the ground. 
There may sometimes be an ambiguity in the fi gure, as shown in Fig.  6.6 , which can 
be solved according to the way of looking. In Fig.  6.6 , on the left, the black part is 
perceived as the ground, and, consequently, white diamonds are perceived 
 spontaneously. In Fig.  6.6 , on the right, white diamonds are much less likely to be 
perceived spontaneously. Indeed, it is much easier to imagine that the white part can 
be the ground in the right than in the left fi gure. Consequently, we perceive much 
more easily that there are black diamonds in the right fi gure.
</p>
<p>   In general, a fi gure has a shape and some meaning, whereas the background is 
rather disorganized. Indeed, several objective factors determine this fi gure/ground 
distinction. These factors are illustrated in Fig.  6.7 . These factors are reported to be 
objective because they are determined by the stimuli. An image placed in a vertical 
horizontal orientation will be more readily perceived as a fi gure than if it is placed 
in diagonal directions. Thus, it should be easier to perceive a white cross in the left 
portion of Fig.  6.7a  than it is in the right portion. In this latter case, due to  orienta-
tion , we perceive more spontaneously the gray cross than the white cross. Similarly, 
a smaller (or thinner) image is more easily perceived as a fi gure than a larger image. 
This factor is called the  relative size . Thus, in Fig.  6.7b , we perceived more easily a 
</p>
<p>  Fig. 6.6    Illustration of the propensity to see, on the  left ,  white diamonds  on a  black background  
and on the  right ,  black diamonds  on a  white background        
</p>
<p> 
</p>
<p>6 Form Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>91
</p>
<p>gray cross than a white cross on the left, but the reverse on the right. In fact, the thin 
crosses on Fig.  6.7b  are more spontaneously perceived than the crosses on Fig.  6.7a .
</p>
<p>   Another very powerful factor is  symmetry  (or regularity). When objects or fi g-
ures are symmetrical, they are more likely to be perceived as fi gures. Thus, because 
the four black pieces of Fig.  6.7c  are on a white background, they tend to be per-
ceived as fi gures. However, it would have been possible to perceive a white fi gure 
between the two black parts in the center, but being very irregular, this white fi gure 
cannot be spontaneously perceived. In addition, the two black parts on the left being 
symmetrical, they are easily perceived, more than are the two rightmost black por-
tions of the fi gure. 
</p>
<p>  Fig. 6.7    Objective characteristics of the fi gure/ground segregation: ( a ) orientation, ( b ) size, ( c ) 
symmetry, and ( d ) inclusion (see text)       
</p>
<p> 
</p>
<p>6.2 Gestalt: Perceptual Organization</p>
<p/>
</div>
<div class="page"><p/>
<p>92
</p>
<p> When an image is inside another, chances are that it will also be recognized as a 
fi gure rather than as ground. This factor is called   inclusion    (or  surroundedness ). 
Thus, the  square   in the middle of Fig.  6.7d , on the left, does not act like ground but 
is part of a complex fi gure in a circle. That said, different portions of the circle could 
have been perceived as fi gure, as illustrated in the right part of Fig.  6.7d . 
</p>
<p> Note that there are various other objective factors that may contribute to fi gure/
ground differentiation. For example, the patterns within an image can be crucial for 
perceiving a fi gure; this factor is called the   internal articulation   . Also, various sub-
jective factors are likely to infl uence this differentiation. Among these factors, there 
is the previous experience of the person perceiving, as well as the elements toward 
which attention is directed. That individual traits exert infl uence on what is extracted 
from a given visual scene is hardly surprising for clinical psychologists using pro-
jective tests.   
</p>
<p>6.2.2     Perceptual Grouping 
</p>
<p>  The visual perceptual system  tends   to group automatically, that is to say, without 
cognitive effort, certain elements present in the visual fi eld. This grouping is based 
on basic principles identifi ed by the Gestaltists. These organizational principles are 
sometimes referred to as Gestalt laws or Gestalt grouping rules. 
</p>
<p> We tend to group together elements that are close to each other. This tendency is 
called the  law of  proximity   . Thus, we perceive spontaneously, in Fig.  6.8a , four 
groups of three elements rather than 12 elements. A series of elements may be 
 equidistant from each other, but some of them can be grouped together because of 
their resemblance. This is what the  law of  similarity    stipulates (Fig.  6.8b ). A third 
</p>
<p>  Fig. 6.8    Illustration of the  Gestalt laws  : ( a ) proximity, ( b ) similarity, ( c ) good continuation, 
( d ) connectedness, ( e ) common region       
</p>
<p> 
</p>
<p>6 Form Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>93
</p>
<p>law, known as the   good continuation   , reveals that the elements of a set forming a 
continuous series, or are part of the continuity relative to each other, tend to be seen 
as if they were one unit. Two intersecting lines are perceived in Fig.  6.8c , rather than 
the two items shown just to the right of these lines.
</p>
<p>   More recently, in what might be called a modern Gestalt, other perceptual orga-
nization principles were reported. These new principles are indeed very powerful. 
The fi rst is called   connectedness    (or uniform connectedness). The fact of connecting 
elements together, as is shown in Fig.  6.8d , has more impact than the principles 
described earlier. Similarly, items that are part of the same region are seen as if they 
belong to the same entity. This principle, known as   common region   , is illustrated in 
Fig.  6.8e . 
</p>
<p> Furthermore, there are other laws of Gestalt, for example, the  law of  closure   . 
According to this law, the visual system tends to see fi gures or objects as if they 
were complete, be it fully or in part; if the fi gure is not complete, the visual  system   
manages to reach closure (see subjective contours, Fig.  6.1 ). Also, the more regular 
and symmetrical a shape is, the more it imposes itself to the perceptual system. This 
is known as the law of the   pragnanz   , also called the   law of good form    (and some-
times law of symmetry). Finally, another very powerful factor that organizes the 
visual perception is related to the fact that some elements might be in motion. If 
elements of a visual scene move in the same direction, they are perceived as being 
grouped together. This is called the  law of  common fate    (or of  common motion ).    
</p>
<p>6.3     Theory of Multiple Spatial Channels 
</p>
<p> A very original way to address the issue of form perception was proposed in the late 
1960s. This approach, developed by F. W. Campbell and J. G. Robson, is based on 
spatial frequency analysis and is sometimes referred to as the  multiple spatial chan-
nels theory   (Campbell &amp; Robson,  1968 ). 
</p>
<p>6.3.1     Basic Concepts 
</p>
<p>  The  multiple spatial channels theory is based   on a simple and clever idea: each 
image can be decomposed into a series of cyclical variations in luminance. The 
reader already familiar with the physical bases of auditory perception knows that 
sound can be interpreted as pressure variations over time. Similarly, a visual scene 
can be described as luminance variations, but instead of being described as varia-
tions as a function of time, they are described as a function of space. 
</p>
<p> A full understanding of this theory requires knowing that the size of the retinal 
image depends on the distance from which an object is viewed. For an image of a 
given size and for a given distance, the size on the retina is twice as small if the 
image is twice as far.   When we look at an image, the spatial frequency thus depends 
</p>
<p>6.3 Theory of Multiple Spatial Channels</p>
<p/>
</div>
<div class="page"><p/>
<p>94
</p>
<p>on variations in luminance (&ldquo;light/dark&rdquo;) and on the distance from which the image 
is perceived. For a given visual angle, there are a number of these variations. For 
example, an object with a diameter of 175 mm and located 10 m from the person 
subtends a visual angle of about 1&deg;. A variation of periods alternating between light 
luminance and dark luminance is called a cycle. This makes it possible to express 
what is viewed on the following terms: the number of cycles per degree of visual 
angle. That is called   spatial frequency   , which is one of the four characteristics 
allowing the understanding of Campbell and Robson&rsquo;s idea. 
</p>
<p> A visual scene&mdash;a grating&mdash;like the one shown in Fig.  6.9  can be described by 
means of a sine wave. The  spatial frequency  is higher in C than in A or B. The dif-
ference between A and B is due to a second characteristic: the  contras t. For a given 
cycle ranging from a light band to a dark band, the intensity variation is not the 
same. The light band is brighter in B than A. When the differences between light 
and dark bands are large, the contrast is high. If the contrast is too low for perceiving 
a difference between the two areas, it means that the contrast is below the visibility 
threshold. The contrast level can be quantifi ed by means of a percentage scale rang-
ing from 0 to 100 %, i.e., from the weakest (incapacity to perceive) contrast to the 
highest contrast.
</p>
<p>   Two more features complete the description of a visual scene. The gratings like 
those in Fig.  6.10  (left column) are identical, but their position is not the same. It is 
their  spatial phase  that distinguishes them. Finally, the bars of the gratings can be 
more or less inclined. Those on the left column and those on the right column differ 
on the basis of a fundamental characteristic called   orientation   .
</p>
<p>   In everyday life, visual scenes are rarely that simple or as clear-cut as described 
in Figs.  6.9  and  6.10 . Figure  6.11e , for example, is more complex. However, it con-
tains a series of simpler elements. Using a mathematical procedure known as Fourier 
analysis, it is possible to decompose a complex scene on the basis of simpler ele-
ments, in this case a series of sine waves. The gratings in Fig.  6.11a, b  are used to 
form the grating illustrated in Fig.  6.11d . If we add the grating in Fig.  6.11c  to the 
ones in Fig.  6.11a, b  (or to the grating of Fig.  6.11d ), we obtain the complex fi gure 
</p>
<p>  Fig. 6.9    Spatial frequency is much higher in ( c ) than in ( a ) or ( b ), but ( a ) and ( b ) differ because 
the contrast is higher in ( b ) than in ( a )       
</p>
<p> 
</p>
<p>6 Form Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>95
</p>
<p>reported in Fig.  6.11e . Note that the spatial frequency in Fig.  6.11c  is much higher 
than the one in Fig.  6.11b , which is itself much higher than that in Fig.  6.11a .
</p>
<p>   Although we do not consciously have the impression that they are there, each of 
the components of a grating like the one shown in Fig.  6.11e  acts on the brain. These 
components excite different sets of neurons. For each component, there is therefore 
in the visual cortex a set of neurons that are specifi c to it. At the cortical level, for 
viewing a form, it is necessary to synchronize the activity of a series of specialized 
neurons. 
</p>
<p> In the context of Campbell and Robson&rsquo;s explanation based on spatial frequen-
cies, such a set of neurons is called a channel. This channel essentially acts like a 
frequency detector. Each channel is sensitive to the spatial frequencies which extend 
over a narrowband. Also, because multiple channels are often activated at the same 
</p>
<p>  Fig. 6.10    Gratings in the 
 left column  have different 
phases, whereas those in 
the  right column  have 
different orientations       
</p>
<p>  Fig. 6.11    Grating ( e ) is complex, but is made in the end of the mixture of gratings ( a &ndash; c ); and grat-
ing ( d ) results from the mixture of gratings ( a ,  b )       
</p>
<p> 
</p>
<p> 
</p>
<p>6.3 Theory of Multiple Spatial Channels</p>
<p/>
</div>
<div class="page"><p/>
<p>96
</p>
<p>time, we talk about the theory of multiple channels, and more specifi cally about the 
multiple spatial channels theory, since it refers to spatial frequencies. 
</p>
<p> When using images made of squares like that reported in Fig.  6.12 , it is possible 
to realize that perceiving a form means fi ltering what these images are in terms of 
the spatial frequencies that they contain. Depending on the distance between the 
observer and the image, it is not the same spatial frequencies that are involved, and, 
therefore, different specialized channels are activated. The squares add noise to the 
image. When we are at a normal reading distance, the image is not clear: a series of 
small squares are perceived. When we move away, the spatial frequency is changed 
and a clearer vision is restored.
</p>
<p>   On a more practical level, this means that if an image with squares is presented 
during the news on television to hide the face of a criminal or accused, you now 
know that you have better chances to identify the person if you move away from the 
TV! You also know that when you change the angle with which you are looking at 
something, you see things differently. This information will be precious the next 
time you visit a visual art gallery or museum where paintings are exhibits. Your 
impression on a piece of art might change if you adopt different perspectives. The 
effect is even more striking in a gallery like the Orsay Museum in Paris, for exam-
ple, which exhibits the works of great Impressionist masters. Different angles and 
different distances allow to increase the appreciation of the works, for instance, of 
Van Gogh, Renoir, or Monet or of artists like Georges Seurat and Paul Signac who 
used pointillism to create impressions.   
</p>
<p>  Fig. 6.12     Block image  of 
Cosette, blurred when seen 
from up close, but clearer 
as we move away. Cosette 
is a character from Victor 
Hugo&rsquo;s  Les Mis&eacute;rables , 
drawn originally by 
illustrator &Eacute;mile Bayard       
</p>
<p> 
</p>
<p>6 Form Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>97
</p>
<p>6.3.2     Contrast Sensitivity Function 
</p>
<p>   The  multiple spatial channels theory offers   a new interpretation of the perception of 
form and, by the same occasion, a new way of approaching the study or the mea-
surement of visual abilities.    We are able to perceive images at different distances 
with the involvement of different spatial frequencies. However, for the different 
spatial frequencies, we do not have the same effi ciency for perceiving. As is the case 
for the range of audible frequencies in the fi eld of audition (Chap.   2    ), or visible 
wavelengths as we saw in the previous chapter, we are not sensitive to all spatial 
frequencies. 
</p>
<p> More specifi cally, just like it is possible to compensate some defi cit in the per-
ception of some auditory frequencies by increasing the loudness of the sound, it is 
possible to perceive an image, for certain spatial frequencies, only by increasing the 
contrast. In other words, the perception threshold has to be increased. This link 
between the spatial frequency and the perception threshold is described by what is 
called the  contrast sensibility function  (CSF). In brief, the contrast sensitivity is 
described as a function of the spatial frequency. 
</p>
<p> For humans, the sensitivity is at its maximum at about 3 cycles/degree. It is at 
this frequency that the threshold is the lowest. The extent of the sensitivity of the 
visual system varies from one animal species to another and depends on the light 
level. Given the demands of their environment, it is not surprising to learn that gold-
fi sh have a maximum sensitivity for images with a spatial frequency of about 0.3 
cycle/degree, as opposed to the hawks that are crisscrossing the sky, searching for 
prey on the ground, who have a maximum sensitivity for spatial frequencies of 
about 30 cycles/degree. 
</p>
<p> This CSF concept has interesting practical implications. In fact, it measures the 
visual abilities more completely than does the traditional visual acuity test, the 
Snellen chart (Fig.  6.13 ). With the latter, the visual ability is only tested in an opti-
mal condition, i.e., in a condition where contrast is high. Also, tests are executed 
</p>
<p>  Fig. 6.13    A few 
lines from the Snellen 
chart       
</p>
<p> 
</p>
<p>6.3 Theory of Multiple Spatial Channels</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-31791-5_2">http://dx.doi.org/10.1007/978-3-319-31791-5_2</a></div>
</div>
<div class="page"><p/>
<p>98
</p>
<p>only with high frequencies. The visibility conditions we face in everyday life are not 
always optimal. For example, it may well happen that you have to drive a car in a 
more or less thick fog or when it is snowing or raining heavily. In such occasions, 
contrast is not at all at maximum. It may well be that people with the best visual 
acuity, as measured by the Snellen chart, do not have the greatest contrast sensitivity 
for low spatial frequencies. This issue also applies to aircraft pilots who must deal 
with all kinds of weather conditions, including fl ying through the clouds (Ginsburg, 
Evans, Sekuler, &amp; Harp,  1982 ).
</p>
<p>   For historical purpose, note that the Snellen chart (or test) is a traditional eye 
examination tool for quantifying visual acuity. Developed by the Dutch Herman 
Snellen in the mid-nineteenth century, this tool is still used today. These charts are 
calibrated in different ways (different letter sizes). A conventional manner of using 
consists in reading from a distance of 20 ft (6 m in Europe). Letters have to be read 
with of a single eye, one letter at a time, down to the smallest letters that can be 
read. The goal is to determine whether a person can read at 20 ft what is normally 
read from that distance. When we say that a person has a 20/15 read, we say that 
that person reads at 20 ft what a person normally reads at 15 ft. This person has a 
good view.     
</p>
<p>6.4     Form Recognition 
</p>
<p> It is diffi cult to evoke form perception without mentioning the ability to recognize 
it. For recognizing a form, we have to have a representation of it. It therefore 
becomes necessary, for understanding the mechanisms of form perception, to refer 
to higher level concepts. This part of the chapter will not be just about what stimu-
lates the retina but rather about what is kept from these stimuli and from the differ-
ent visual scenes, objects, or faces. 
</p>
<p>6.4.1     Templates or Characteristics? 
</p>
<p>  To fully understand the  theoretical   interest of the study of recognition, it is fi rst 
necessary to understand the requirements of the task. All readers of this book know 
the letter A and can easily recognize it, whether it is a,  a ,  a , A,  A , or  A . Yet, it is 
likely that you have never seen one or some of these As. Now imagine all versions 
of A you wrote by hand or even better and all versions of A that all humans have 
written in the past year. Even having seen only a very small percentage of these As, 
you would be able to recognize most of them. This indicates that we do not have to 
have seen everything a fi rst time to make it possible to recognize some forms. 
Despite all the possible transformations of the same object, we do recognize it. This 
capability to recognize a visual stimulus in spite of the multiple changes it has 
undergone, or despite the new perspective for observing it, is called invariance. 
</p>
<p>6 Form Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>99
</p>
<p> A fi rst model to account for this ability to  recognize   is called &ldquo;template match-
ing.&rdquo; According to this model, a template is kept in memory and superimposed on a 
form in order to verify to what extent this template and the form are similar. Once 
the learning of letter A is completed, it becomes possible to attempt to match the 
template that was learned with the one that is perceived. Such a theoretical perspec-
tive is based on the need to store a vast repertoire of images and templates. This idea 
has the advantage of being simple, but does not allow to really explaining invari-
ance. We should learn everything a fi rst time, which does not seem very economical 
when considering the space in memory such learning would require for storing 
information. 
</p>
<p> Rather than learning templates, perhaps we learn features. This perspective states 
that the stimuli are rather defi ned as combinations of basic features. If we take the 
previous example, learning letters, instead of making comparison with a template, it 
would rather be a comparison with the defi nition of what is retained. For letters, 
relevant questions would be, for example, the following: &ldquo;Are there any lines with a 
vertical orientation? Are there any intersections? Are there any curves?&rdquo; Given the 
specifi city of certain cells for processing depending on the orientation (Chap.   4    ), 
this model has a certain plausibility from a physiological point of view (Hubel &amp; 
Wiesel,  1968 ). Also, in an experiment in which the task is to determine whether the 
two letters presented are identical or not (Gibson, Schapiro, &amp; Yonas,  1968 , in 
Reed,  1982 ), the response time will be longer if the letters are alike (e.g., P and R), 
than if they are not (e.g., G and W). In other words, the processing time is longer 
and must be more complete if several features are in common. 
</p>
<p> So it seems that form recognition is based on features. But how does this process 
work? Does it work in sequence, where each element is processed successively, or 
is there some simultaneous processing, i.e., a parallel processing? According to 
Selfridge ( 1959 ), who developed a theory called the pandemonium, this processing 
is done in parallel and involves three steps. The different features (curve, angles, 
etc.) are fi rst recorded, and then, specialized units (feature demons) take care of 
identifying them. Units representing letters (cognitive demons) then handle the need 
to reveal the level of agreement between the letter they represent and the recorded 
features. At a third level, units (decision demons) would be assigned to the identifi -
cation of cognitive demons having demonstrated the highest level of agreement.   
</p>
<p>6.4.2     A Computational Approach 
</p>
<p>   In the  pandemonium theory  ,  there   is a fi rst sign of a  computational theory of   form 
recognition. The goal within this approach is to develop programs (series of cal-
culations) used to make connection between what occurs on the retina and the 
representation of objects and of the physical world. If neurophysiology provides 
information about the hard drive, it does not inform us about the dynamics 
(the processes involved) allowing to perceive and recognize form. 
</p>
<p>6.4 Form Recognition</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-31791-5_4">http://dx.doi.org/10.1007/978-3-319-31791-5_4</a></div>
</div>
<div class="page"><p/>
<p>100
</p>
<p> For Marr ( 1982 ), the perceptual representation is a construction involving differ-
ent steps. There is a fi rst fi ltering step which allows the extraction of the main fea-
tures of an image. According to the fi lter properties that can be associated with 
receptor fi elds which have different sizes and allow to accentuating contours, it 
becomes possible to extract more or less rough idea of the image. For instance, nar-
rower fi lters are more sensitive to higher spatial frequencies. 
</p>
<p> The information derived from this fi ltering operation thus results in a primitive 
sketch in two dimensions (2D). This is a fundamental fi rst step in the computational 
theory of Marr. The different variations of light intensity reaching the retina are trans-
lated into features such as curves, intersections, etc. In short, the contours are detected 
and the main features of the image are drawn. This step can be compared to that of the 
draft in pencil performed by a painter. Next is a 2.5-D representation where the features 
are rather arranged according to the direction, depth, shadows, or texture. At this stage, 
the object is not yet a structured whole. All tridimensional information is not fully 
grasped. At this stage of processing, the sketch depends on the perspective of the 
observer, and, consequently, a change of perspective might prevent the recognition. 
The third stage is that of the 3-D model. It is centered on the object rather than on the 
observer&rsquo;s perspective. The surfaces are structured in volumetric components.    
</p>
<p>6.4.3     A Structural Model 
</p>
<p>   Another model to  account   for the tremendous ability to recognize form  was   proposed 
by Biederman ( 1987 ). According to this author, this recognition is based on struc-
tural components. Somewhat along the line reported earlier for describing letters 
according to structural features, one could describe the objects based on a set of basic 
structures. One could compare this viewpoint to the idea that a few dozen phonemes 
allow to produce and recognize the thousands of words in a language (see Chap.   3    ). 
Thus, the description of all objects might be reduced to a series of basic components. 
Objects in memory would therefore be represented in the form of a spatial arrange-
ment of geometric components. These components act in some way as phonemes in 
language. They are called geons, for &ldquo;geometric ions.&rdquo; According to Biederman, 
there are 36 geons; Fig.  6.14  illustrates some of these. Note that these geons resemble 
cylinders that Marr and Nishihara ( 1978 ) were using to describe different forms.
</p>
<p>Arch Cube Cylinder Pyramid
</p>
<p>  Fig. 6.14    A few examples of geons, the basic structures of the recognition-by-components model 
of Biederman ( 1987 )       
</p>
<p> 
</p>
<p>6 Form Perception</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-31791-5_3">http://dx.doi.org/10.1007/978-3-319-31791-5_3</a></div>
</div>
<div class="page"><p/>
<p>101
</p>
<p>   Geons can be extracted directly from 2D features. It is these geons and their 
relative position that determine the object. If we have a cylinder with a bow on 
the side, we have the representation of a cup; but if the bow is on top, it will be 
rather a bucket. Whatever an observer standpoint is, this description in terms of 
structures and their relationship does not change. With this model, it becomes 
possible to account for this crucial property, that is, spatial invariance. This 
model is interesting because it offers some resistance to constraints that some-
times accompany the perception of objects. For recognizing, the key point is to 
avoid the degradation of geons.    
</p>
<p>6.4.4     Agnosia 
</p>
<p>   There exists a defi cit  specifi c   to the identifi cation or recognition of objects.  This   prob-
lem is called agnosia and is diagnosed as such when it is neither an intellectual dis-
ability nor a sensory disorder or a disorder of language. In general, it is said that 
agnosia is caused by perceptual problems or problems of representations in memory. 
</p>
<p> A fi rst type of apperceptive agnosia may depend on the diffi culty of extracting 
basic features like corners or edges. In other words, this is a very serious problem. 
This case is referred to as form agnosia. Another type could occur even when the 
features can be perceived, but in such cases, it is not possible to extract a whole 
confi guration. This is called integrative agnosia. Another type of agnosia is called 
transformational. In this case, the agnosia is caused by the diffi culty to recognize 
objects presented from a new angle. 
</p>
<p> Moreover, there are two categories of agnosia related to a problem of mnemonic 
representations. There is agnosia caused by the loss of structural representations, which 
entrains imaging trouble and the loss of a sense of familiarity with the object. The other 
kind of agnosia is the so-called associative agnosia, characterized by the inability to 
fi nd the meaning of the object. This agnosia occurs because the semantic representation 
in memory is deteriorated or because it is not possible to access this representation. 
</p>
<p> Finally,  prosopagnosia   is the name given to disorder consisting of an inability to 
recognize faces, even one&rsquo;s own face. In such a case, the view of the face does not 
activate a sense of familiarity or biographical elements. In some cases, the affected 
person presented with a face is unable to identify whether the presented face is that 
of a young or of an old person, or that of a man or woman, or what facial emotion is 
expressed. Note in conclusion that face recognition is in itself a specifi c and fasci-
nating subfi eld of study of form recognition (Tsao &amp; Livingstone,  2008 ). One of the 
debated issues is related to the fact that the face would fi rst be perceived as a whole 
(holistic model) as opposed to a viewpoint where the features and their spatial orga-
nization would be analyzed before face recognition.          
</p>
<p>6.4 Form Recognition</p>
<p/>
</div>
<div class="page"><p/>
<p>103&copy; Springer International Publishing Switzerland 2016 
</p>
<p>S. Grondin, Psychology of Perception, DOI 10.1007/978-3-319-31791-5_7
</p>
<p>    Chapter 7   
</p>
<p> Depth Perception                     
</p>
<p>             The possibility to see the world in three dimensions remains quite fascinating con-
</p>
<p>sidering the following peculiar fact: images arrive on the retina in two dimensions. 
</p>
<p>Spontaneously, no one would doubt that there is a physical world that includes a 
</p>
<p>third dimension. Nevertheless, the brain has to build this third dimension. The pres-
</p>
<p>ent chapter addresses this phenomenon, that of the construction of space or, more 
</p>
<p>specifi cally, of depth. 
</p>
<p> In the preceding chapters, different aspects of visual perception sent the reader 
</p>
<p>back to fundamental concepts of physics for understanding the nature of stimuli or 
</p>
<p>to fundamental concepts of physiology or brain sciences for understanding biologi-
</p>
<p>cal bases of perception. In the present chapter, special attention is paid to psycho-
</p>
<p>logical phenomena allowing to perceiving this third dimension. After a review of 
</p>
<p>the main cues for perceiving depth, two phenomena are examined closely. The fi rst 
</p>
<p>one, perceptual constancy, is fundamental and is indeed not involved only in depth 
</p>
<p>perception. The second one reveals cases, most often fascinating and fun, where 
</p>
<p>these cues are misleading and induce illusions. 
</p>
<p>7.1     Cues for Perceiving a Third Dimension 
</p>
<p>  The capacity of  perceiving   depth is based on the availability and contribution of 
</p>
<p>several cues. These cues are kind of tricks allowing the brain to generate this impres-
</p>
<p>sion of depth. However, using these tricks requires no voluntary effort; they are 
</p>
<p>spontaneously activated by the data provided by the visual scene. 
</p>
<p> For understanding how these cues are studied in the fi eld of perception, it is 
</p>
<p>appropriate to make some distinctions between terms or concepts. First, for studying </p>
<p/>
</div>
<div class="page"><p/>
<p>104
</p>
<p>the estimated distance, for example, researchers will distinguish absolute distance 
</p>
<p>and relative distance. The idea of absolute distance, sometimes also called self-
</p>
<p>centered, refers to the estimation of the distance between an object and the one 
</p>
<p>observing this object. In contrast, reference is made to relative distance, or  exocentric 
</p>
<p>distance, to designate the distance between the objects or between parts of these 
</p>
<p>objects. If we generally fi nd it hard to precisely estimate the absolute distance, we 
</p>
<p>are rather good to decide if an object is closer to us than another object. 
</p>
<p> In addition to this absolute vs. relative distance distinction, it is important to 
</p>
<p>keep in mind that the various depth cues that can be used can be classifi ed in the 
</p>
<p>following three dichotomous categories. Cues may be extraocular (nonvisual) 
</p>
<p>rather than visual. Thus, information on depth might not be extracted specifi cally 
</p>
<p>from the visual system per se, but from a source belonging to another sensory 
</p>
<p>modality, namely, the kinesthetic system. Another useful distinction is the one 
</p>
<p>between pictorial cues, which are static, and kinematic cues, which are dynamic, 
</p>
<p>i.e., related to movement. Finally, there are binocular cues, as opposed to mon-
</p>
<p>ocular cues. The presentation of the various cues below is based on this 
</p>
<p>distinction.  
</p>
<p>7.1.1     Binocular Cues 
</p>
<p> The simple fact of having two eyes, and to have some distance between them, pro-
</p>
<p>vides a better perspective on what is happening in our environment. It is possible to 
</p>
<p>perceive depth with only one eye, but some cues require the joint operation of both 
</p>
<p>eyes. These  binocular  cues are very powerful because they add precision to our 
</p>
<p>appreciation of the third dimension. 
</p>
<p>7.1.1.1     Binocular Convergence 
</p>
<p>   A fi rst cue  involving   the contribution of both eyes is called  binocular convergence . 
</p>
<p>Looking at an object usually means that both eyes converge on it. If an object  is   far 
</p>
<p>away, the angle between the focal point (the object) and the eye is small. If the 
</p>
<p>object is close, the convergence angle is larger. According to the angle of conver-
</p>
<p>gence, the eyeballs are more or less displaced. These movements generate nonvi-
</p>
<p>sual cues. These cues are based on the kinesthetic information provided by 
</p>
<p>receptors located within the extraocular muscles, i.e., the muscles that allow the 
</p>
<p>movement of the eyes. 
</p>
<p> It is the convergence movement, rather than the state of convergence, which 
</p>
<p>would provide the kinesthetic cues. This binocular convergence provides informa-
</p>
<p>tion on the absolute distance. Also, this source of information would be more effec-
</p>
<p>tive when objects are close to the observer (say less than 6 m). Indeed, you can feel 
</p>
<p>that there is some work being done in the eyeballs when you approach a fi nger to 
</p>
<p>your nose and try to follow it with your eyes.    
</p>
<p>7 Depth Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>105
</p>
<p>7.1.1.2     Retinal Disparity 
</p>
<p>   A second binocular cue is  called    retinal disparity . The fact that there  is   some dis-
</p>
<p>tance between the eyes is not trivial at all. This means that when looking at an 
</p>
<p>object, an observer gets two points of view on it; in other words, for a given object, 
</p>
<p>two images are formed. Disparity is the term designating the fact of receiving two 
</p>
<p>images of the same thing, and binocular disparity refers to the disparity caused by 
</p>
<p>the fact of having two eyes. Perceiving depth on the basis of binocular cues is also 
</p>
<p>called stereoscopy (and sometimes binocular parallax), and the device designed to 
</p>
<p>simulate a sense of depth with two different images of the same object, one for each 
</p>
<p>eye, is called stereoscope. 
</p>
<p> It is easy to realize that each eye offers a unique point of view with the following 
</p>
<p>exercise. First, place a fi nger 15 cm in front of you at eye level. By closing one eye 
</p>
<p>and then the other alternately, you realize that different views of the fi nger appear. 
</p>
<p>Equally important is the following fact. Place a second fi nger 15 cm behind the fi rst, 
</p>
<p>in the same axis. Now focus on the nearest fi nger, but pay attention to the farthest 
</p>
<p>fi nger: it is seen in double. If you now focus on the farthest fi nger, but pay attention 
</p>
<p>to the other one, it is now the closest one that is seen in double. 
</p>
<p> This difference in the clarity of the image as a function of the focus point is very 
</p>
<p>important. It teaches us that not everything that is in our visual fi eld is seen clearly. 
</p>
<p>Horopter is the name given to the horizon line in front of us where vision is simple 
</p>
<p>(no image seen in double); this line is actually an area called the Panum area. 
</p>
<p>Depending on the distance of the fi xation point, the size and shape of the area 
</p>
<p>change slightly. Outside this area, the vision is in double. If simple vision is possible 
</p>
<p>even if we have two eyes, therefore two images for one given fi xation point, it is 
</p>
<p>because for each given location on the retina of an eye, there is a precise correspon-
</p>
<p>dence point on the retina of the other eye. 
</p>
<p> Furthermore, it is important to note that the double vision of the close fi nger and 
</p>
<p>that of the distant fi nger differ fundamentally. By placing two fi ngers as was done 
</p>
<p>earlier and on focusing on the close fi nger, the farther fi nger is seen in double. By 
</p>
<p>closing the right eye while continuing to focus on the close fi nger, the farther fi nger 
</p>
<p>is seen with the left eye to the left of the close fi nger; now, by closing the left eye 
</p>
<p>instead of the right one, the farther fi nger is seen with the right eye to the right of the 
</p>
<p>near fi nger. Thus, when both eyes are open and we are fi xating on a given point, 
</p>
<p>what is located behind this point is seen in   uncrossed disparity   . 
</p>
<p> The demonstration works in the opposite direction. Now, the fi xation point is the 
</p>
<p>farther fi nger, but attention has to be allocated to the closer fi nger. By closing one 
</p>
<p>eye and then the other alternately while keeping the fi xation on the farther fi nger, 
</p>
<p>one realizes that the closer fi nger is seen with the left eye to the right of the farther 
</p>
<p>fi nger and with the right eye to the left of the farther fi nger. This is a case of   cross 
</p>
<p>disparity   . The brain therefore benefi ts from a depth perception cue allowing to 
</p>
<p>deciding whether object is in front a focal point or behind. 
</p>
<p> Finally, it should be noted that the visual fi eld seen ahead binocularly covers a 
</p>
<p>range of 120&deg;. Added to this are approximately 40&deg; of monocular vision to the left 
</p>
<p>with the left eye and 40&deg; of monocular vision to the right with the right eye.     
</p>
<p>7.1 Cues for Perceiving a Third Dimension</p>
<p/>
</div>
<div class="page"><p/>
<p>106
</p>
<p>7.1.2     Monocular Cues 
</p>
<p>  Monocular  cues of depth   perception are sources of information about distance that 
</p>
<p>remain available even when an observer uses only one eye. There are several mon-
</p>
<p>ocular cues. Most of them are related to vision but one,  accommodation , has a kin-
</p>
<p>esthetic origin. In this case, the fact that an object is more or less distant causes a 
</p>
<p>change in the shape of the lens. For instance, if an object is far away, the lens is less 
</p>
<p>curved. Changing the shape of the lens requires changes in the contraction of the 
</p>
<p>muscles involved in the accommodation process, and these muscular changes pro-
</p>
<p>duce kinesthetic cues that the brain can interpret for assessing distance. 
</p>
<p> Because many objects have a typical size, it may happen that distance be esti-
</p>
<p>mated on the basis of this knowledge. For example, we know quite well the normal 
</p>
<p>size of a card. If we are not under specifi c conditions such as those that cause 
</p>
<p>optical- geometric illusions (see below), we can rely on the combination of this 
</p>
<p>knowledge and retinal size for estimating distance. We call this index the  familiar 
</p>
<p>size . Thus, if we look at a coin that looks like a 25-cent coin, and if we do it in an 
</p>
<p>environment where other depth perception cues are not available, we will assume 
</p>
<p>that the size of this coin is normal for estimating how far away it is. If it should hap-
</p>
<p>pen that this coin is actually smaller (because a friend is playing a trick or a 
</p>
<p>researcher in psychology of perception studies the mechanisms of depth percep-
</p>
<p>tion), this would be misleading, and the estimated distance would likely be 
</p>
<p>incorrect. 
</p>
<p>   Linear perspective    is one of the most powerful depth perception cues, a cue that 
</p>
<p>is most useful in the fi eld of visual arts. When two lines like those shown in Fig.  7.1  
</p>
<p>converge to a vanishing point, they give a sense of depth. The points that are closer 
</p>
<p>to each other appear to be farther away from the observer. The farther away is a part 
</p>
<p>of the image, the smaller is the distance between each line on the retina. What we 
</p>
<p>see in the real world in three dimensions can therefore be implemented on a two- 
</p>
<p>dimensional image by adjusting the distance between the drawn objects and their 
</p>
<p>size.
</p>
<p>   In fact, this linear perspective effect caused by the convergence could be consid-
</p>
<p>ered a special case of a more general cue that James Jerome Gibson called  texture . 
</p>
<p>This is a mixture of both the linear perspective and the relative size of objects com-
</p>
<p>posing a visual scene. Most often we talk about texture gradients to denote the fact 
</p>
<p>that the density and the size of the elements of a visual scene vary with their dis-
</p>
<p>tance. Thus, as can be seen in Fig.  7.2 , when dots are smaller and close to each 
</p>
<p>other, they appear to be farther away. If what is viewed is farther away, the elements 
</p>
<p>of the scene will be more compact.
</p>
<p>   Another visual cue for perceiving depth is called   occlusion   . This cue, also called 
</p>
<p>  interposition   , refers to the fact that objects or parts of a visual scene are often hidden 
</p>
<p>by other objects. What is covered necessarily appears to be farther away than what 
</p>
<p>is causing occlusion. This powerful cue says nothing about the distance between the 
</p>
<p>observer and the object, but gives an idea of the relative distance between objects. 
</p>
<p>Figure  7.3  illustrates how powerful this cue is.
</p>
<p>7 Depth Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>107
</p>
<p>   Another cue based on the relationship between two objects allows to draw con-
</p>
<p>clusions about their relative distance. This cue is called the   relative height   . The 
</p>
<p>nearer an object is from the horizon point, the farther away it seems. Consequently, 
</p>
<p>for the ground-related objects, i.e., below the horizon line (which is usually where 
</p>
<p>our gaze is directed), the higher in the visual fi eld an object is, the farther away it 
</p>
<p>seems (Fig.  7.4 ). Conversely, for objects located above the horizon line, the lowest 
</p>
<p>objects appear more distant.
</p>
<p>   Different arrangements of light and brightness can contribute to give an impres-
</p>
<p>sion that objects or parts of the visual fi eld are more or less close to an observer. 
</p>
<p>For example, in the dark, the brighter of two objects is perceived as being closer. 
</p>
<p>  Fig. 7.1    Although the 
</p>
<p>rails are parallel, the 
</p>
<p>distance between them 
</p>
<p>appears to decrease from 
</p>
<p>the  bottom  of the image to 
</p>
<p>the  middle , which induces 
</p>
<p>an impression of depth. 
</p>
<p>This is an example of 
</p>
<p>linear perspective       
</p>
<p>  Fig. 7.2    When texture gradients are uniform, as on the  left , no impression of depth is created; 
</p>
<p>however, compressing points and using heterogeneous point size, on the  right , give an impression 
</p>
<p>of depth       
</p>
<p> 
</p>
<p> 
</p>
<p>7.1 Cues for Perceiving a Third Dimension</p>
<p/>
</div>
<div class="page"><p/>
<p>108
</p>
<p>This cue is called   relative brightness   . Somewhat in the same vein, the use of shad-
</p>
<p>ing allows to create an impression that something is more or less distant. In the 
</p>
<p>case of Fig.  7.5 , it seems that some circles are concave and others convex. 
</p>
<p>Interestingly, this impression can be reversed by rotating the book 180&deg;. In fact, the 
</p>
<p>angle of illumination from a light source might well change the perception of an 
</p>
<p>object, of an image, or of a face.
</p>
<p>  Fig. 7.3    If we are presented only the two cards on the  left , it is easy to fi gure out that the cards 
</p>
<p>have the same size, with the fi ve of hearts being farther away than the three of clubs. It is not pos-
</p>
<p>sible to reach the same conclusion for the cards on the  right  due to the interference caused by the 
</p>
<p>occlusion factor. Because the fi ve of hearts covers part of the three of clubs, the fi ve of hearts must 
</p>
<p>necessarily be in front of the other card (i.e., closer); as a result, it is not possible to believe that 
</p>
<p>these cards are the same size       
</p>
<p>  Fig. 7.4    Relative height in 
</p>
<p>the visual fi eld is a very 
</p>
<p>strong indicator for 
</p>
<p>distance perception. When 
</p>
<p>looking at objects on the 
</p>
<p>ground, those that are high 
</p>
<p>in the fi eld are farther 
</p>
<p>away. It is therefore easy to 
</p>
<p>understand that  C  is farther 
</p>
<p>away than  B  and that  B  is 
</p>
<p>farther away than  A . When 
</p>
<p>looking at the sky, the 
</p>
<p>relative height is still a cue, 
</p>
<p>but now, objects that are 
</p>
<p>low in the visual fi eld are 
</p>
<p>farther away. Thus, cloud 
</p>
<p> D  is more distant than 
</p>
<p>cloud  E , which is itself 
</p>
<p>farther away than cloud  F        
</p>
<p> 
</p>
<p> 
</p>
<p>7 Depth Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>109
</p>
<p>   It is also known that distance creates an attenuation of contours. This cue is 
</p>
<p>called   aerial perspective    (or relative sharpness) and is  more   useful for estimating 
</p>
<p>the distance of objects that are far away. The clearer the contour of an object, the 
</p>
<p>closer the object appears because brightness contrasts are attenuated by distance. 
</p>
<p>Thus, a car or even a mountain will appear much closer in clear weather than in 
</p>
<p>fog conditions. 
</p>
<p> Another monocular cue, but linked to movement, is called   motion parallax   . The 
</p>
<p>term parallax means shifting from one position to another. Here, we are talking 
</p>
<p>about cases where a change is caused by the movement of an observer. To under-
</p>
<p>stand the relationship between the movement and the sense of distance, simply 
</p>
<p>place a fi nger in front of you, and have your gaze fi xated on it while moving your 
</p>
<p>head to the left and to the right. When the head goes left, it seems that the fi nger 
</p>
<p>goes right; when the head goes right, it seems that the fi nger goes to left. The wall 
</p>
<p>behind the fi nger seems to go in the same direction as the head, but what lies between 
</p>
<p>you and the fi nger (the fi xation point) goes in the opposite direction. This provides 
</p>
<p>an indication as to whether an object is in front or behind a fi xation point. Even 
</p>
<p>more important is the following point: the closer an object is, the greater the dis-
</p>
<p>tance covered on the retina. Thus, the objects in the visual fi eld give the impression 
</p>
<p>of not moving at the same speed. The greater the speed, the closer the objects are. 
</p>
<p>One can verify this statement by traveling on a road in the passenger seat: the gravel 
</p>
<p>on the side of the road seems to fall quickly backward, whereas the mountain at 
</p>
<p>some distance away, or a cloud, seems to follow you slowly. Now you know why it 
</p>
<p>looks as if the moon follows us when traveling by car at night! 
</p>
<p> This section can be summarized by reference to Table  7.1  in which the cues 
</p>
<p>for depth perception are classifi ed as binocular or monocular, visual or nonvi-
</p>
<p>sual, and static or dynamic and on whether they are used to assess a relative or 
</p>
<p>absolute distance.
</p>
<p>   In closing this portion of the chapter, it should be noted that the presence of cer-
</p>
<p>tain cues in a visual scene determines the way we see. However, it may happen that 
</p>
<p>  Fig. 7.5    Impressions of depth (concave versus convex) caused by shading. Images on the  left  and 
</p>
<p>on the  right  are identical, but have been rotated 180&deg;       
</p>
<p> 
</p>
<p>7.1 Cues for Perceiving a Third Dimension</p>
<p/>
</div>
<div class="page"><p/>
<p>110
</p>
<p>the scene can be interpreted in different ways; in other words, cues may lead to 
</p>
<p>some reversible images as is the case of the Necker cube (Fig.  7.6 ). On this fi gure, 
</p>
<p>depending on what surface is perceived as occluding the other, a surface will be 
</p>
<p>considered as being in the foreground or in the background. Similarly, the use in 
</p>
<p>painting of some occluding effects can lead to the construction of pretty scenes that 
</p>
<p>seem real, but could in no way be observed in nature. The Dutch artist Maurits 
</p>
<p>Cornelis Escher has mastered the development of scenes involving this kind of 
</p>
<p>deception. You may fi nd some of the works of the artist if you just type his name on 
</p>
<p>an Internet search engine. Similarly, typing &ldquo;trompe-l&rsquo;œil&rdquo; on the Internet provides 
</p>
<p>access to many other illustrations allowing to see how fi ne use of depth cues by 
</p>
<p>painters can create powerful impressions, sometimes vertiginous, of a third dimen-
</p>
<p>sion. We will return later to some particular impressions, namely, illusions, caused 
</p>
<p>by the particular use of depth cues. 
</p>
<p>  Table 7.1    Depth perception: 
</p>
<p>summary and classifi cation of 
</p>
<p>cues  
</p>
<p> Cues  Type  Distance 
</p>
<p>  Binocular  
</p>
<p>   Convergence a   K  A 
</p>
<p>   Disparity  V  R 
</p>
<p>  Monocular  
</p>
<p>   Accommodation  K  A 
</p>
<p>   Familiar size  V  A 
</p>
<p>   Relative height  V  R 
</p>
<p>   Shading  V  R 
</p>
<p>   Occlusion  V  R 
</p>
<p>   Motion parallax a   V  R 
</p>
<p>   Linear 
</p>
<p>perspective 
</p>
<p> V  R 
</p>
<p>   Texture  V  R 
</p>
<p>   a Dynamic cues (other cues are static) 
</p>
<p>  K  kinesthetic,  V  visual,  A  absolute, 
</p>
<p> R   relative  
</p>
<p>  Fig. 7.6    Necker cube, on the  left , could be perceived like the one at  center  or like the one on the 
</p>
<p> right        
</p>
<p> 
</p>
<p>7 Depth Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>111
</p>
<p>7.2         Perceptual Constancy 
</p>
<p>  This section, which deals with the notion of perceptual constancy, could have been 
</p>
<p>introduced at various places in this book, because it applies not only to size con-
</p>
<p>stancy but also to other dimensions, which will be detailed in the following para-
</p>
<p>graphs. The perceptual constancy is a basic mechanism of the perceptual system by 
</p>
<p>which almost everything seems in order.  Without   that mechanism, we could not 
</p>
<p>recognize anything. All physical stimuli would be chaos, and there would be no 
</p>
<p>basis for perceiving. 
</p>
<p> What reaches the retina is continuously changing. If a chair is presented to an 
</p>
<p>observer from an angle under which it has never been seen, the observer still man-
</p>
<p>ages to identify it as a chair. We can turn the chair in every sense and vary constantly 
</p>
<p>the patterns of light energy it sends to the retina of the observer. This chair always 
</p>
<p>maintains its objective characteristics, and the observer is able to know, without a 
</p>
<p>shadow of a doubt, that two completely different energy patterns reaching his retina 
</p>
<p>originate from the same object. In other words, seeing is not just a simple stimula-
</p>
<p>tion of retinal cells.  
</p>
<p>7.2.1     Types of Constancy 
</p>
<p>  Among the different  types   of perceptual constancy, there is   shape constancy   . 
</p>
<p>This constancy explains why an object maintains its shape even if different 
</p>
<p>inclinations in different spatial planes cause as many variations of the projective 
</p>
<p>image (see the previous chapter on form recognition). Similarly, under the   color 
</p>
<p>constancy   , it is possible for an observer to recognize the hue of an object in spite 
</p>
<p>of the fact that the light projected on this object changes its spectral composi-
</p>
<p>tion, provided however that this change is not exaggerated. Also, the brightness 
</p>
<p>of the object does not vary in spite of the differences in light intensity, and that 
</p>
<p>is due to   brightness constancy   . Similarly, despite the differences in speed of the 
</p>
<p>retinal image that can be caused by the distance in depth, it is possible to prop-
</p>
<p>erly assess the speed of a moving object through a phenomenon referred to as 
</p>
<p>  speed constancy   . 
</p>
<p> In the context of space perception, i.e., 3-D, the issue of perceptual constancy is 
</p>
<p>closely linked to   size constancy   . The constancy refers to the capacity of maintaining 
</p>
<p>the apparent size of objects or of people although the image size on the retina 
</p>
<p>decreases with an increase of the distance between these objects or people and the 
</p>
<p>observer. In other words, it is not because the retinal image of a person going away 
</p>
<p>from the observer shrinks that this person appears to shrink. Unless there is in the 
</p>
<p>environment a set of cues that may induce the observer in error, this observer con-
</p>
<p>tinues to believe that this person is the same size.   
</p>
<p>7.2 Perceptual Constancy</p>
<p/>
</div>
<div class="page"><p/>
<p>112
</p>
<p>7.2.2     Interpretations and Investigations 
</p>
<p>  A classic question  arises   about the nature of size constancy: should distance be 
</p>
<p>taken into account? In general, this question refers to the   size-distance invari-
</p>
<p>ance principle    (Kilpatrick &amp; Ittelson,  1953 ). This hypothesis of invariance 
</p>
<p>between size and distance basically states that an observer determines the appar-
</p>
<p>ent size on the basis of two combined elements of information, the perceived 
</p>
<p>distance and the size of the retinal image. This idea is expressed by several 
</p>
<p>authors in different forms. Thus, Helmholtz had already invoked the participa-
</p>
<p>tion of a mechanism, the   unconscious inference   , to refer to the fact that the dis-
</p>
<p>tance is taken into account in estimating the size of an object, this way of taking 
</p>
<p>into account being settled without the help of conscious mechanisms. This theo-
</p>
<p>retical perspective is also sometimes referred to as the algorithm theory (Epstein, 
</p>
<p> 1977 ), as opposed to a relational theory. In the latter, the estimation of the size of 
</p>
<p>an object or of person does not depend on some calculation of the distance 
</p>
<p>between the observer and the object or person but rather on the relationship 
</p>
<p>between the information available around the object or person. It is actually more 
</p>
<p>a size-size type of relationship than a size-distance type. We will briefl y return to 
</p>
<p>this point of view in the next subsection. 
</p>
<p> The hypothesis about the need of taking the distance or not into account when 
</p>
<p>size is evaluated has been tested in several empirical investigations. One way to 
</p>
<p>illustrate the potential importance of distance in the evaluation of size is to use an 
</p>
<p>afterimage. As we saw in Chap.   5     on color perception, a consecutive image is an 
</p>
<p>image that remains somehow imprinted on the retina for a few seconds after pro-
</p>
<p>longed stimulation. Remaining fi xed on the retina, the image always maintains the 
</p>
<p>same retinal size. The apparent size of this image depends on the distance of surface 
</p>
<p>on which the image is projected. The farther away from the observer the projection 
</p>
<p>surface is, the larger the image appears. This relationship between the apparent size 
</p>
<p>of an afterimage and the distance from the observer to the projection surface is 
</p>
<p>known as   Emmert&rsquo;s law   . This law illustrates the fact that the apparent size of an 
</p>
<p>object depends not only on the size of the retinal image but also on the distance from 
</p>
<p>which the object is perceived; therefore, apparent size likely depends on the fact of 
</p>
<p>taking distance into account. 
</p>
<p> Among the various studies designed to test the size-distance invariance hypoth-
</p>
<p>esis, or the algorithm theory, the most classic is probably that of Holway and Boring 
</p>
<p>( 1941 ). In this experiment, some observers, including the authors, indicated the 
</p>
<p>experimenter to adjust a comparison stimulus located about 10 ft (about 3 m) away. 
</p>
<p>This adjustment was made for matching the size of a standard stimulus located in a 
</p>
<p>long corridor at different distances, 10&ndash;120 ft (3&ndash;36 m), from the observer (Fig.  7.7 ). 
</p>
<p>The stimuli, standard and comparison, were projected on screens. The images were 
</p>
<p>uniform circular illuminations. In each experimental distance, the standard stimulus 
</p>
<p>was adjusted so that the retinal image was kept constant, i.e., constantly subtended 
</p>
<p>a visual angle of 1&deg;.
</p>
<p>7 Depth Perception</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-31791-5_5">http://dx.doi.org/10.1007/978-3-319-31791-5_5</a></div>
</div>
<div class="page"><p/>
<p>113
</p>
<p>   The idea behind the experiment was to see if the adjustment of the compari-
</p>
<p>son stimulus would be consistent with the actual size of the standard stimulus, 
</p>
<p>as  predicted by the size-distance invariance hypothesis. Thus, if the distance is 
</p>
<p>not taken into account in the adjustment, the adjustment will always remain the 
</p>
<p>same; however, if distance is taken into consideration, the adjustment will 
</p>
<p>change as a function of the actual size of the stimulus or will get close to real 
</p>
<p>size. 
</p>
<p>  Holway   and  Boring   pushed their reasoning a little further. If the distance is really 
</p>
<p>considered, then different conditions for estimating distance should have an effect 
</p>
<p>on the precision of the adjustment of the comparison stimulus. Thus, four experi-
</p>
<p>mental conditions were designed:
</p>
<p>    1.    A binocular vision condition where the adjustment was expected to be the 
</p>
<p>best   
</p>
<p>   2.    A condition where the only restriction was to use monocular vision   
</p>
<p>   3.    A monocular condition with vision through an artifi cial pupil, which was 
</p>
<p>expected to reduce the cues provided by the motion parallax   
</p>
<p>   4.    A monocular vision condition through an artifi cial pupil and with low light con-
</p>
<p>ditions in order to reduce as much as possible potential sources of information on 
</p>
<p>distance    
</p>
<p>  Holway and Boring ( 1941 ) found that in conditions where cues were avail-
</p>
<p>able for assessing distance, the adjustment of the comparison stimulus approxi-
</p>
<p>mates the actual size of the object. In other words, even if the retinal size of the 
</p>
<p>standard stimulus remains the same, the perceived size of the circular illumina-
</p>
<p>tion changes according to the distance: the greater the distance, the greater the 
</p>
<p>luminous circle, and the adjustment of the comparison stimulus is made accord-
</p>
<p>ingly. Figure  7.8  illustrates the results obtained in each condition. It should be 
</p>
<p>noted that the loss of cues leads directly, as suggested by the slope of each func-
</p>
<p>tion, to a decrease in the estimated size of the standard stimulus. All these 
</p>
<p>results can be interpreted as supporting the size-distance invariance hypothesis, 
</p>
<p>an idea often reported for explaining size constancy. 
</p>
<p>  Fig. 7.7    Illustration of the experimental setting designed by Holway and Boring ( 1941 ).  Dc  dis-
</p>
<p>tance of the comparison stimulus (10 ft ~ 3 m),  Ds  distance of standard stimulus (from 10 to 
</p>
<p>120 ft ~ de 3&ndash;36 m),  0  observer       
</p>
<p> 
</p>
<p>7.2 Perceptual Constancy</p>
<p/>
</div>
<div class="page"><p/>
<p>114
</p>
<p>7.2.3        Gibson&rsquo;s Perspective 
</p>
<p>   Despite the  elegance   of this demonstration by Holway and Boring, other authors 
</p>
<p>argue that  this   explanation based on the size-distance invariance can be faulted 
</p>
<p>(Kilpatrick &amp; Ittelson,  1953 ); it applies to the results in certain circumstances but 
</p>
<p>cannot be a generalized. In fact, by removing cues of depth perception, the quality 
</p>
<p>of the relational information is also reduced. 
</p>
<p> There is a radical position in the fi eld of visual perception stating that there is no 
</p>
<p>need for cognitive processing or inference mechanisms for estimating, for instance, 
</p>
<p>depth. According to Gibson ( 1966 ,  1979 ), all the perceptual system needs is already 
</p>
<p>available in the environment. In this Gibsonian perspective, everything that is in the 
</p>
<p>environment (surfaces or objects) reaches the observer with specifi c physical char-
</p>
<p>acteristics. The movements of the observer determine what reaches the eye, and the 
</p>
<p>material getting to this point is already organized. In the experiment by Holway and 
</p>
<p>Boring, it was not possible for the observer to benefi t from the cues normally pro-
</p>
<p>vided by movements, especially in the condition involving to looking through an 
</p>
<p>artifi cial pupil. Such an experimental design hinders the proper functioning, if not 
</p>
<p>to say connivance, between the viewer and the environment. 
</p>
<p> Gibson therefore adopts what is referred to as an   ecological position    in which 
</p>
<p>only natural situations can really contribute to our understanding of the visual 
</p>
<p>  Fig. 7.8    Results of the experiment by  Holway   and  Boring   ( 1941 &mdash;see their fi gure 22) where are 
</p>
<p>grouped four experimental conditions: ( 1 ) binocular vision, ( 2 ) monocular vision, ( 3 ) monocular 
</p>
<p>vision with artifi cial pupil, and ( 4 ) monocular vision with artifi cial pupil and reduced cues. The 
</p>
<p> broken lines  show the expected results would the perceptual constancy been perfect ( diagonal line ) 
</p>
<p>and null ( horizontal line ) (1 in. ~ 2,54 cm; 1 ft ~ 30 cm)       
</p>
<p> 
</p>
<p>7 Depth Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>115
</p>
<p> system. In this Gibsonian psychology, the environment provides us spontaneously 
</p>
<p>not only precise physical stimuli but also information relative to the function of 
</p>
<p>what is observed (e.g., when it is an object). In other words, seeing a chair also 
</p>
<p>activates in the brain of the observer what a chair is for, i.e., sitting down. In the 
</p>
<p>Gibsonian terminology, the idea that perceiving is inseparable from the function is 
</p>
<p>called   affordance    (that is to say, what is made possible by what is observed).     
</p>
<p>7.3     Illusions 
</p>
<p>   The perceptual  systems   are generally very reliable and allow to be adapted to the 
</p>
<p>requirements of the environment and its characteristics. Despite the effectiveness of 
</p>
<p>these systems,  it   happens that an observer is misled when these characteristics are 
</p>
<p>somewhat special. In the fi eld of visual perception, such misinterpretations have 
</p>
<p>quite amazing, and sometimes even spectacular, consequences. These misinterpre-
</p>
<p>tations are caused not by a system failure as the inability to maintain perceptual 
</p>
<p>constancy but by the objective characteristics of the environment. 
</p>
<p> These errors are called optical illusions or optical-geometric illusions. As they 
</p>
<p>depend on the normal functioning of the visual system, these illusions provide an 
</p>
<p>opportunity to inform us about the nature of perceptual processes. They should not 
</p>
<p>be confused with   hallucinations   , which are a phenomenon where there is an impres-
</p>
<p>sion of perception even though there is no perceptual object around (no physical 
</p>
<p>stimuli) or  mirages , which are a physical phenomenon caused by refl ections of light 
</p>
<p>rays in particular conditions.   
</p>
<p>7.3.1     Variety of Illusions 
</p>
<p>   There are of course  very   strong visual effects like  those   caused by the subjective 
</p>
<p>contours described in the previous chapter. In addition to these effects, there are 
</p>
<p>hundreds of illusions that an interested reader can discover by consulting older 
</p>
<p>books (see Coren &amp; Girgus,  1978  or Shepard,  1990 ) or some specialized websites 
</p>
<p>on the Internet. We present here only some of the most classic or of the most spec-
</p>
<p>tacular illusions. Many of these illusions were discovered in the nineteenth century, 
</p>
<p>and in most cases, a given illusion was named after the person who reported it. 
</p>
<p> The classifi cation of these illusions into a limited number of categories remains 
</p>
<p>a diffi cult exercise (Coren, Girgus, Ehrlichman, &amp; Hakstian,  1976 ). Some classifi -
</p>
<p>cations like that reported by Gregory ( 1997 ) require many distinctions; that of 
</p>
<p>Piaget is simpler. Piaget is famous for his work on the development of intelligence, 
</p>
<p>but nevertheless studied in depth the impact of perception on knowledge. Some of 
</p>
<p>his works, including those grouped in a book entitled  Les m&eacute;canismes perceptifs  
</p>
<p>(Piaget,  1961 ), concern the illusions in particular and their changes in magnitude 
</p>
<p>with age. Inspired by Alfred Binet, who is distinguishing innate vs. acquired 
</p>
<p>7.3 Illusions</p>
<p/>
</div>
<div class="page"><p/>
<p>116
</p>
<p> optical- geometric illusions, Piaget rather speaks in terms of primary illusions vs. 
</p>
<p>secondary illusions. The fundamental property of a primary illusion, also called 
</p>
<p>fi eld effect, is that it does not vary qualitatively with age. However, their quantita-
</p>
<p>tive aspect, that is to say the strength of such an illusion, does vary with age. Also, 
</p>
<p>Piaget does not say like Binet that the effect is innate. Secondary illusions are rather 
</p>
<p>those arising from perceptual activities. These activities cause a decrease in some 
</p>
<p>primary illusions and the emergence of new illusions. 
</p>
<p> Figure  7.9  reports a series of illusions based on angle effects. This category of 
</p>
<p>illusions is very powerful. Among them, you will discover the spectacular Sander&rsquo;s 
</p>
<p>illusion where the diagonal lines passing across parallelograms are surprisingly of 
</p>
<p>the same length. Zollner&rsquo;s, Hering&rsquo;s, and Poggendorff&rsquo;s illusions are also based on 
</p>
<p>angle effects.
</p>
<p>   Another example of angle effect, perhaps the best known, is the  M&uuml;ller-Lyer illu-
</p>
<p>sion   (Fig.  7.10 ). This illusion could be explained by an assimilation effect or central 
</p>
<p>tendency effect. According to this view, the EF and GH segments are taken into 
</p>
<p>account in the estimation of segment AB (Fig.  7.10 , right). Segments EF and GH 
</p>
<p>being on average shorter than segments IJ and KL, it follows that the segment AB 
</p>
<p>is perceived as being shorter than the segment CD.
</p>
<p>   For explaining the tendency to consider the segment AB to be shorter than segment 
</p>
<p>CD (Fig.  7.10 , right), some authors argue that these segments automatically generate the 
</p>
<p>depth cues frequently observed on a daily basis (Fig.  7.11 ). Indeed, this illusion would 
</p>
<p>be less pronounced with non-occidental populations less accustomed to the architecture 
</p>
<p>made of many angles and squares as is often the cases in Western countries.
</p>
<p>  Fig. 7.9    In  Sander&rsquo;s illusion   ( top left ), the  diagonal lines  crossing the parallelograms are of the 
</p>
<p>same length; in Poggendorff&rsquo;s illusion ( bottom left ), we are under the impression that, of the two 
</p>
<p>segments on the  right of the gray rectangle , it is the one on top that is in continuity with the one on 
</p>
<p>the  left of the rectangle  (the reader should check); in Zollner&rsquo;s illusion ( top right ), the  vertical lines  
</p>
<p>are really parallel; and, similarly, in Hering&rsquo;s illusion ( bottom right ), the  horizontal lines  are really 
</p>
<p>parallel       
</p>
<p> 
</p>
<p>7 Depth Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>117
</p>
<p>   Other illusions are essentially based on perspective effects. A simple case is that 
</p>
<p>of the  Ponzo illusion   (Fig.  7.12 ). Also, it is possible to create a variant of this illu-
</p>
<p>sion with the railroad track illustration used earlier and the addition on the picture 
</p>
<p>of same size segments at different locations on the track. If the size of the segments 
</p>
<p>is not adjusted for perspective, the highest segment appears longer, and the lowest 
</p>
<p>segment appears shorter.
</p>
<p>   A spectacular case involving a perspective effect is that of the Ames room. This 
</p>
<p>room is not square as would suggest our knowledge of what a normal room is. It 
</p>
<p>rather has a side (the photo in Fig.  7.13 ) deeper and higher than the other. A major 
</p>
<p>visual distortion can happen when looking at persons in such a room. If we pay 
</p>
<p>attention at the relative size of the two persons, one on the left and the other on the 
</p>
<p>right, and if we assume they are in a normal environment (in which one would think 
</p>
<p>they are at the same distance from us as would spontaneously suggest normal size 
</p>
<p>  Fig. 7.10    The  M&uuml;ller-Lyer illusion   (on the  left ), where the  horizontal line ,  bottom part , seems 
</p>
<p>longer than the  top left horizontal line ; letters on the illustration on the  right  serve an explanation 
</p>
<p>reported in the text       
</p>
<p>  Fig. 7.11    These cabinets 
</p>
<p>contain clues reminding 
</p>
<p>the  M&uuml;ller-Lyer illusion  . 
</p>
<p>The two  long vertical 
</p>
<p>black lines  appear to be of 
</p>
<p>equal length. However, the 
</p>
<p>one on the  right  is shorter 
</p>
<p>by about 15 %. Indeed, the 
</p>
<p>two  vertical lines  are not 
</p>
<p>placed in the same context. 
</p>
<p>Even by adding the length 
</p>
<p>of the wooden parts just 
</p>
<p>below and just above the 
</p>
<p>line on the  right , this line 
</p>
<p>remains shorter than the 
</p>
<p> black line  on the  left        
</p>
<p> 
</p>
<p> 
</p>
<p>7.3 Illusions</p>
<p/>
</div>
<div class="page"><p/>
<p>118
</p>
<p>constancy mechanisms), the person on the right looks oversized compared to the 
</p>
<p>person on the left. Also if one person was to move along the back wall, the size of 
</p>
<p>that person would change: the person on the right would shrink if going left, and the 
</p>
<p>one on the left would grow if going right.
</p>
<p>   There are other ways of generating strong illusions. One of them is to take images 
</p>
<p>of different sizes close to each other and to compare them. Among the illusions of 
</p>
<p>this kind, those of Delboeuf and of Titchener (Fig.  7.14 ) are noteworthy. Another 
</p>
<p>classic illusion is the Oppel-Kundt: a segment divided into several parts is perceived 
</p>
<p>to be longer than a segment of equal length but undivided (Fig.  7.15 ).
</p>
<p>    The length of a segment also depends on its orientation. Thus, a segment of a 
</p>
<p>given length appears longer vertically than horizontally (Fig.  7.16 ). According to 
</p>
<p>K&uuml;nnapas, who wrote a series of articles about this illusion in the 1950s (see 
</p>
<p>Prinzmetal &amp; Gettleman,  1993 ), a frame effect is causing the illusion. Because the 
</p>
<p>visual fi eld is elliptical, a vertical segment is closer than a horizontal segment of the 
</p>
<p>same length to the frame (i.e., closer to the ends of the visual fi eld). Coren and 
</p>
<p>Girgus ( 1978 ) rather hypothesized that the vertical appears longer because it 
</p>
<p>involves a depth cue and the horizontal does not. If you are asked to indicate the 
</p>
<p>midpoint of a vertical line, you will probably not indicate a location  dividing the 
</p>
<p>line in two equal parts, but a point located a bit higher than midpoint because higher 
</p>
<p>means farther away (more distance).  
</p>
<p>7.3.2        The Moon Illusion 
</p>
<p>   Because of its  ubiquity   and also because it has intrigued philosophers and scientists 
</p>
<p>for a long time, the moon illusion deserves we spend some time on it. This illusion 
</p>
<p>is so strong that we  forget   or even doubt that it is an illusion. This illusion is even 
</p>
<p>more interesting that a plausible explanation requires the perfect integration of the 
</p>
<p>  Fig. 7.12    Illustration of 
</p>
<p>the  Ponzo illusion         
 
</p>
<p>7 Depth Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>119
</p>
<p>fundamental notion of perceptual constancy. But what is the moon illusion? This 
</p>
<p>illusion refers to the fact that the moon appears larger when it is on the horizon than 
</p>
<p>when it is at its highest point in the sky (the zenith). This difference is estimated at 
</p>
<p>approximately 30 %, but may be sometimes smaller, sometimes much greater, 
</p>
<p>depending on the exact conditions of testing and on the observers. 
</p>
<p>  Fig. 7.13    The effect generated when two people are in the Ames room (photo on  top ). Below, a 
</p>
<p>bird&rsquo;s-eye view of the room. If an observer ( black dot ) believes that  person 2  is at  position 3 , i.e., 
</p>
<p>at the same distance as  person 1 , as suggested by the depth cues in the room, then the observer will 
</p>
<p>perceive  person 2  as much smaller because the retinal size of the latter is much smaller than that of 
</p>
<p> person 1        
</p>
<p> 
</p>
<p>7.3 Illusions</p>
<p/>
</div>
<div class="page"><p/>
<p>120
</p>
<p> Since the distance that separates us from the moon remains pretty much equiva-
</p>
<p>lent regardless of where it is located, its projective size remains the same, whether 
</p>
<p>at the zenith or horizon. According to Irvin Rock and Lloyd Kaufman (Kaufman &amp; 
</p>
<p>Rock,  1962 ; Rock &amp; Kaufman,  1962 ), the illusion is not caused by the different 
</p>
<p>angles of the observer&rsquo;s gaze, as some researchers believed until then, but to the 
</p>
<p>  Fig. 7.14    Illustration of the  Delboeuf   ( top ) and  Titchener   ( below ) illusions       
</p>
<p>  Fig. 7.15    Illustration of the  Oppel-Kundt illusion  . The distances between  1  and  2  and between  2  
</p>
<p>and  3  are the same although the distance between  2  and  3  seems larger       
</p>
<p>  Fig. 7.16    Illustrations of the   horizontal-vertical  illusion  . Is the wizard hat ( left ) wider than is tall 
</p>
<p>or taller than is wide? Or does height and width seem almost equal? Just measure it! On the  right , 
</p>
<p>do  horizontal  and  vertical lines  have equal length?       
</p>
<p> 
</p>
<p> 
</p>
<p> 
</p>
<p>7 Depth Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>121
</p>
<p>presence or absence of objects (the ground) between the observer and the moon. 
</p>
<p>Rock and Kaufman rather emphasized the importance of apparent distance, also 
</p>
<p>referred to as the size-distance invariance hypothesis. 
</p>
<p> In order to understand this explanation, it is crucial to remember the idea of per-
</p>
<p>ceptual constancy: if two objects have the same retinal size, the one that appears 
</p>
<p>farther away is perceived as larger. What would happen would the brain believe that 
</p>
<p>the moon is farther when on the horizon than at its zenith? Because we know that 
</p>
<p>the retinal image is the same in both cases, we must conclude that the brain would 
</p>
<p>interpret that the moon is larger on the horizon. In other words, we believe that the 
</p>
<p>moon is very large on the horizon because our brain believes it is far away. This may 
</p>
<p>seem counterintuitive for someone concluding that the moon appears to be so close 
</p>
<p>because it looks so big. A full understanding requires that you keep in mind the fact 
</p>
<p>we are dealing with perceptual mechanisms engaged automatically or unconsciously 
</p>
<p>by the brain. 
</p>
<p> The critical question at this point becomes the following one: are there at least 
</p>
<p>reasons to believe that the moon seems farther away on the horizon than at the 
</p>
<p>zenith? The answer is yes, according to Kaufman and Rock. Consider the following 
</p>
<p>experiment where observers were asked to point out the midpoint between the 
</p>
<p>zenith, 90&deg;, and the horizon, 0&deg;. Rather than pointing the midpoint, which is 45&deg;, 
</p>
<p>these observers rather tended to point a direction a little closer to the horizon than to 
</p>
<p>the zenith. As shown in Fig.  7.17 , observers do not point to the midpoint of a sky 
</p>
<p>that would be perceived as semicircular; they point rather to what is midpoint of a 
</p>
<p>sky perceived as being fl attened. If the sky is perceived as being fl at, the moon is 
</p>
<p>necessarily perceived as more distant when on the horizon than at the zenith.
</p>
<p>   There is a second reason to believe that the moon seems farther away on the 
</p>
<p>horizon than at the zenith. It is recognized that the perceptual system is sensitive to 
</p>
<p>  Fig. 7.17    When asking observers to indicate midpoint between the horizon and zenith, they do not 
</p>
<p>indicate Point  B  (a 45&deg; angle; see digit  1  in the fi gure); they point rather in the direction of Point  D  
</p>
<p>(angle  2 ). Point  B  is midpoint between  A  and  C ,  C  ( large white disk ) indicating the real location of 
</p>
<p>the moon,  D  being midpoint between  A  and  E , and  E  (the  small black dot ) being where the observer 
</p>
<p>believes the moon is. To an observer, indicating midpoint corresponds to pointing  D , assuming that 
</p>
<p>the sky is perceived as being fl at rather than  semicircular . The moon is therefore judged as being 
</p>
<p>closer (Point  E ) when standing at the zenith than when located at the horizon (the  large black disk ) 
</p>
<p>(Kaufman &amp; Rock,  1962 )       
</p>
<p> 
</p>
<p>7.3 Illusions</p>
<p/>
</div>
<div class="page"><p/>
<p>122
</p>
<p>the presence of benchmarks in the environment. With more landmarks ahead of us, 
</p>
<p>we tend to perceive distances as larger. When looking at the moon at its zenith, there 
</p>
<p>are no landmarks to guide the estimation of distance; however, most often the land 
</p>
<p>offers several landmarks such as trees, cars, or houses. These landmarks help give 
</p>
<p>the brain the impression that the moon on the horizon is far away from us. 
</p>
<p> In short, the moon would be perceived as being larger on the horizon than at the 
</p>
<p>zenith because the brain would believe it is farther on the horizon. This explanation 
</p>
<p>makes sense only if one understands the idea of perceptual constancy, that is, the 
</p>
<p>principle stating that perceived distance and projective size are closely connected 
</p>
<p>when estimating the size of objects. Many explanations and descriptions about the 
</p>
<p>moon illusion can be found in Hershenson ( 1989 ) or Ross and Plug ( 2002 ):
</p>
<p>  The fact that landmarks contribute to perceiving depth led to a basic rule of water safety. If 
</p>
<p>you capsize a boat after moving far from the shore of a lake, be careful before deciding to 
</p>
<p>swim back rather than trying to grab the boat. Because there are usually no benchmarks in 
</p>
<p>the water (sometimes an island, sometimes other boats), you might get the incorrect impres-
</p>
<p>sion of still being close to shore. Inadequate assessment of distance may cause exhaustion 
</p>
<p>before reaching the shore.            
</p>
<p>7 Depth Perception</p>
<p/>
</div>
<div class="page"><p/>
<p>123&copy; Springer International Publishing Switzerland 2016 
</p>
<p>S. Grondin, Psychology of Perception, DOI 10.1007/978-3-319-31791-5_8
</p>
<p>    Chapter 8   
</p>
<p> Perception and Attention                     
</p>
<p>             This fi nal chapter is dedicated to the study of attention because perception cannot be 
</p>
<p>reduced to the sole detection of stimuli. It is necessary to try to understand how what 
</p>
<p>is already in the brain determines or infl uences what is going to be perceived. This 
</p>
<p>infl uence was already noted on several occasions in the preceding chapters: when 
</p>
<p>Helmholtz&rsquo; hypothesis about unconscious inferences was referred to, or when 
</p>
<p>studying form recognition or Gestalt&rsquo;s organization principles for accounting for 
</p>
<p>visual or auditory perception. 
</p>
<p> Just for providing some idea of the impact of attention on perception, one should 
</p>
<p>consider the following facts. There exists a scientifi c society, the Psychonomic 
</p>
<p>Society, dedicated to experimental psychology and founded in the USA in 1959. 
</p>
<p>This society is responsible (now with Springer) for the publication of several scien-
</p>
<p>tifi c journals. One of these journals,  Perception and Psychophysics , was founded in 
</p>
<p>the 1960s. Dedicated to research in the fi elds of perception and psychophysics, the 
</p>
<p>journal kept the same name until 2008. Since 2009, the journal&rsquo;s name is  Attention , 
</p>
<p> Perception ,  and Psychophysics . Indeed, in 1988, 5 % of articles published in the 
</p>
<p>journal were associated somehow to the study of attention; 20 years later, it was 
</p>
<p>close to 50 %. Given that no important scientifi c journal had the word attention in its 
</p>
<p>name, it has been decided to change P&amp;P&rsquo;s name in order to better refl ect its con-
</p>
<p>tent. Indeed, this situation illustrates to what extent the processes linked to attention 
</p>
<p>are crucial when perceiving and for understanding the mechanisms of perception. 
</p>
<p> For studying attention, it is imperative to look at its main properties. Any tenta-
</p>
<p>tive for presenting the properties of attention will likely be incomplete given the 
</p>
<p>huge amount of studies on this topic. Although the study of the attentional mecha-
</p>
<p>nism founded on neuroscientifi c approaches increased considerably in the past 30 
</p>
<p>years (see Gazzaniga, Ivry, &amp; Mangun,  2009 ), the present chapter proposes only an 
</p>
<p>overview of the main concepts linked to the study of attention offered by the behav-
</p>
<p>ioral studies and developed in cognitive psychology in the past 60 years. </p>
<p/>
</div>
<div class="page"><p/>
<p>124
</p>
<p>8.1     What Is Attention? 
</p>
<p>   Attention   is the process allowing to become aware of a few things and to capture a 
</p>
<p>part, admittedly very limited, of what is going on around. Indeed, it is extremely 
</p>
<p>diffi cult to defi ne attention precisely,  although   most of us probably already know 
</p>
<p>what it is. We know that when concentrating on a sound source through noise, it is 
</p>
<p>possible to increase chances to capture the message targeted. Also, even when driv-
</p>
<p>ing a car becomes an easy task, we know that it is preferable, for the sake of atten-
</p>
<p>tion, to lower the intensity level of radio for mobilizing all resources in a situation 
</p>
<p>that would suddenly become more complicated (increased traffi c, uncertainty about 
</p>
<p>the street, direction when arriving in a new city, etc.). 
</p>
<p> Readers: &ldquo;Right now, what are you paying attention to?&rdquo; Well, certainly to the 
</p>
<p>text you are reading. Yet, there are probably several other things in your environ-
</p>
<p>ment that could have captured your attention. There is probably some noise, cer-
</p>
<p>tainly some pressure exerted by your chair on you if you are in the likely sitting 
</p>
<p>position for reading, and maybe even some odors coming from the kitchen. Before 
</p>
<p>reading the last sentence, none of these possibilities was striking you; none captured 
</p>
<p>your attention. Even so, as soon as you read about it, you asked yourself about the 
</p>
<p>potential noise in the environment, and maybe you have identifi ed more than one 
</p>
<p>source of noise. As well, you have not been thinking about an iron or a mouse, but 
</p>
<p>for having read these words, one or the other or even both probably occurred in your 
</p>
<p>mind. That is attention. There is continuously a large amount of information at the 
</p>
<p>reach of mind, or because our sensory systems give access to it, or because the 
</p>
<p>information is already there, in memory. 
</p>
<p> Sometimes, stimuli from the environment capture attention; in such cases, we are 
</p>
<p>talking about bottom-up processing (or data-driven processing). Sometimes, we 
</p>
<p>decide to pay attention to something, which is referred to as a top-down process 
</p>
<p>(concept-driven processing).  
</p>
<p>8.1.1     Blindnesses 
</p>
<p>   There are two  types   of errors, now classic in psychology, issued from the scientifi c lit-
</p>
<p>erature on attention. They are called blindness. One is change blindness and refers to the 
</p>
<p>diffi culty  that   people may have to detect what could be quite a big change on an object 
</p>
<p>that is part of a scene that is being observed. Indeed, the diffi culty to detect a change, for 
</p>
<p>instance, from one image to another one that looks like the fi rst one, when the presenta-
</p>
<p>tion of these two images is alternated, depends on the magnitude of change in the con-
</p>
<p>text of the presented image (Rensink,  2002 ; Rensink, O&rsquo;Regan, &amp; Clark,  1997 ). 
</p>
<p> Along the same line, it is sometimes diffi cult to note the presence of new objects, 
</p>
<p>or of new stimuli, occurring in a scene. This last case is called attentional blindness. 
</p>
<p>As for change blindness, attentional blindness occurs when too much attention is 
</p>
<p>allocated to a specifi c part of a scene. A classic example of such effect is the one 
</p>
<p>8 Perception and Attention</p>
<p/>
</div>
<div class="page"><p/>
<p>125
</p>
<p>where someone is asked to count the number of passes of a ball among teammates: 
</p>
<p>nearly half of the people asked to complete this relatively simple task are unable to 
</p>
<p>observe the arrival of a huge stimulus, a gorilla, in the middle of the scene at some 
</p>
<p>moment, through the passes between teammates. This demonstration is available on 
</p>
<p>the following website:   http://www.simonslab.com/videos.html    . 
</p>
<p> A phenomenon like this one leads to believe that a conscious perception of the 
</p>
<p>world is made possible only with the contribution of attention. Along the same line, 
</p>
<p>there exist recent results showing that there is also attentional deafness, i.e., a diffi -
</p>
<p>culty to detect the presence of an auditory stimulus through other auditory dynamic 
</p>
<p>stimuli (Dalton &amp; Fraenkel,  2012 ). Note also that a participant asked to complete a 
</p>
<p>diffi cult visual discrimination task is susceptible to miss the presentation of an eas-
</p>
<p>ily detectable sound presented during this visual task (Macdonald &amp; Lavie,  2011 ). 
</p>
<p>It is therefore possible to induce an effect of attentional deafness with the manipula-
</p>
<p>tion of a diffi cult visual task. 
</p>
<p> The next three parts of this chapter are dedicated to three important properties of 
</p>
<p>attentional processes. These properties are the capability to prepare attention in 
</p>
<p>space and time, for capturing more effi ciently the forthcoming information; the 
</p>
<p>capability to operate a selection of the information available around, be it delivered 
</p>
<p>visually or auditorily; and the capability of searching for specifi c information in the 
</p>
<p>visual fi eld.     
</p>
<p>8.2     Preparation and Orientation 
</p>
<p> Typically, research on attention is based on an analysis of the time necessary to 
</p>
<p>provide a response (response time) in specifi c situations (Posner,  1978 ). Inferences 
</p>
<p>about the mechanisms at play are based on the results issuing from various experi-
</p>
<p>mental situations. 
</p>
<p>8.2.1     Spatial Preparation 
</p>
<p>   The study of  the   deployment of attentional mechanisms can  be   made with a classic 
</p>
<p>strategy where, for instance, participants are asked to direct their gaze toward a 
</p>
<p>point in the center of a computer screen in front of them. The participants need to 
</p>
<p>press as rapidly as possible the appropriate key (on a keyboard) when a stimulus 
</p>
<p>occurs that will be delivered on the left or on the right of the central fi xation point. 
</p>
<p>This fi rst step provides an idea of the time it takes to do such a simple detection task. 
</p>
<p>In a next step, a cue (for instance, a little arrow pointing in the left or in the right 
</p>
<p>direction) occurs at the fi xation point, indicating where the stimulus will be pre-
</p>
<p>sented. Here, we are talking about a spatial cue. Generally, conditions are generated 
</p>
<p>where the cue is valid 80 % of the time; in the other 20 %, the cue is misleading. 
</p>
<p>With such an experimental manipulation, it is possible to show that the valid cue 
</p>
<p>8.2 Preparation and Orientation</p>
<p/>
<div class="annotation"><a href="http://www.simonslab.com/videos.html">http://www.simonslab.com/videos.html</a></div>
</div>
<div class="page"><p/>
<p>126
</p>
<p>allows a reduction of the response time; however, a nonvalid cue has the opposite 
</p>
<p>effect, and, consequently, the time taken to hit the appropriate key is increased. 
</p>
<p>Also, note that if the cue and the stimulus are presented simultaneously, there is no 
</p>
<p>effect. Moreover, the cueing effect increases when the duration between the presen-
</p>
<p>tation of the cue and the  presentation   of the stimulus ( stimulus onset asynchrony &mdash;
</p>
<p>SOA) is increased; this improvement continues up to an SOA lasting 150 ms. 
</p>
<p> Such experiments show that it is possible to prepare the attentional mechanisms 
</p>
<p>for increasing effi ciency in a task where a stimulus presented at different spatial 
</p>
<p>locations has to be detected. It is as if it is possible to shift attention from one place 
</p>
<p>to another, just like a light beam can be moved. Researchers sometimes refer to 
</p>
<p>attentional spotlight and talk about attentional displacement. We do not really know 
</p>
<p>if, strictly speaking, the spotlight moving is the best analogy for describing this 
</p>
<p>attentional mechanism. One can rather imagine a lens with which it is possible to 
</p>
<p>focus, on a point of fi xation, but that would allow an enlargement of the fi eld in such 
</p>
<p>a way that it would become possible to include stimuli located on the left and on the 
</p>
<p>right. 
</p>
<p> That said, there exists a phenomenon called the   inhibition of return   . Anticipating 
</p>
<p>the presence of an event at a certain location allows detecting it more rapidly and 
</p>
<p>with more accuracy. This inhibition of return refers to the diffi culty to send attention 
</p>
<p>back at the spatial location where attention was actually maintained during a brief 
</p>
<p>period (Klein,  2000 ). More specifi cally, the original demonstration, by Posner and 
</p>
<p>Cohen ( 1984 ), goes as follows. 
</p>
<p> Let a visual set with a central fi xation point and another point located on each 
</p>
<p>side where there may appear a signal. A participant has to react as rapidly as pos-
</p>
<p>sible to the occurrence of this signal. If a cue is fi rst given, with the illumination of 
</p>
<p>one of the two points on each side, for indicating where the signal will appear, the 
</p>
<p>participant takes less time to react to the occurrence of the signal if it appears at the 
</p>
<p>predicted location than if it appears on the opposite side. That is a  facilitation effect  . 
</p>
<p>Note that over the series of trials, there are catch trials where the cue is misleading. 
</p>
<p>Thus, the participant cannot anticipate because this would cause an increase of false 
</p>
<p>alarms and therefore a decrease of precision level. 
</p>
<p> The  facilitation effect  , measured with the difference of reaction time to the signal 
</p>
<p>target according to the fact that the signal occurs where the cue was located or on 
</p>
<p>the opposite side, is observed however only if the time difference between the arrival 
</p>
<p>of the cue and the arrival of the signal target is very small (from 0 to 100 ms). With 
</p>
<p>a 200-ms difference, reaction time is about the same, whether the target stimulus is 
</p>
<p>presented on the same side as the cue or on the opposite side (Fig.  8.1 ). But when 
</p>
<p>this difference is increased, the results become quite fascinating. With a 300- to 
</p>
<p>500-ms difference between the cue and target, it takes less time to react to the signal 
</p>
<p>target if it is presented on the side opposite to the one where the cue occurred. These 
</p>
<p>results are explained by the fact that attention was oriented toward a precise location 
</p>
<p>and then disengaged from this location. This orientation and the disengagement 
</p>
<p>prevent a new engagement of attention at the original location. Some researchers 
</p>
<p>claim that this inhibition of return is due to the involvement of mechanisms respon-
</p>
<p>sible for eye movement (Rafal, Calabresi, Brennan, &amp; Sciolto,  1989 ).  
</p>
<p>8 Perception and Attention</p>
<p/>
</div>
<div class="page"><p/>
<p>127
</p>
<p>8.2.2        Temporal Preparation 
</p>
<p>   Just like it is  possible   to be prepared to shift attention as a function of  the   arrival of a 
</p>
<p>stimulus in space, it is possible to be prepared for the arrival of a stimulus at a given 
</p>
<p>moment in time. So it is possible to learn to read the links between events in order to get 
</p>
<p>ready at the moment something occurs. Reading the warning signs allows to increasing 
</p>
<p>the effi ciency of the response to give. For instance, when driving a car, the occurrence of 
</p>
<p>a yellow light (in North America) means that one should be prepared to stop. 
</p>
<p> Once again, one can use the response time to study how we prepare in time. It 
</p>
<p>is important to understand that a simple task such as responding to the arrival of a 
</p>
<p>signal requires the contribution of a series of processing steps. The stimulus must 
</p>
<p>be detected and identifi ed; the appropriate response must be chosen; and the 
</p>
<p>motor programming that the response requires has to be engaged. In this context, 
</p>
<p>the preparation means to try to do in advance what is preceding the response. In 
</p>
<p>the following description, we will stick to cases involving simple reaction times 
</p>
<p>(Niemi &amp; N&auml;&auml;t&auml;nen,  1981 ). 
</p>
<p> Thus, a typical experiment for studying this preparation is to use a warning sig-
</p>
<p>nal before the presentation of a target stimulus to which a participant must react as 
</p>
<p>quickly as possible. This signal can reduce the uncertainty related to the moment of 
</p>
<p>occurrence of the target stimulus. After the appearance of the warning signal, the 
</p>
<p>more time passes, the more the arrival of the target stimulus becomes likely. This 
</p>
<p>information alone has the effect of reducing the reaction time when the stimulus 
</p>
<p>occurs. The interval between the warning signal and the target stimulus is called the 
</p>
<p>preparatory period. This period allows being oriented in time. 
</p>
<p>  Fig. 8.1    Results from Posner and Cohen ( 1984 ) showing the  inhibition-of-return  effect;  black 
</p>
<p>dots , target with cues;  white dots , target without cue       
</p>
<p> 
</p>
<p>8.2 Preparation and Orientation</p>
<p/>
</div>
<div class="page"><p/>
<p>128
</p>
<p> The effect of temporal preparation depends on the specifi c experimental con-
</p>
<p>ditions under which a participant has to perform. We can carry out blocks of 
</p>
<p>trials where the preparatory period remains the same (constant condition) or 
</p>
<p>vary the duration of this period from trial to trial (variable condition), using 
</p>
<p>periods identical to what is used in the constant condition. In the constant condi-
</p>
<p>tion, the longer the preparatory period, the slower the reaction time (Bausenhart, 
</p>
<p>Rolke, &amp; Ulrich,  2008 ). In contrast in the variable condition, the longer the 
</p>
<p>preparatory period, the shorter the reaction time. This applies to all kinds of 
</p>
<p>durations of preparatory periods. 
</p>
<p> This effect, in the variable condition, is explained by the following principle: the 
</p>
<p>more time passes, the more likely becomes the arrival of the target stimulus, and, 
</p>
<p>consequently, one tends to increase the preparation according to this probability. In 
</p>
<p>the constant condition, the probability is fi xed; there is no change of likelihood 
</p>
<p>being tested. One probably needs to rely on the simple calculation of the period 
</p>
<p>preceding the stimulus, after the arrival of the signal, this calculation involving 
</p>
<p>more variability as the duration increases.     
</p>
<p>8.3     Selectivity 
</p>
<p> Since a multitude of  environmental   stimuli constantly reach our sensory recep-
</p>
<p>tors, there is, within our reach, a wealth of information. What is brought to con-
</p>
<p>sciousness depends on where the focus is. It is not possible to hear everything and 
</p>
<p>see everything at the same time. We must somehow  choose   and this choice is 
</p>
<p>made through attentional selectivity. It is possible to focus on a specifi c source of 
</p>
<p>information. For example, all students know that it is possible to simulate listen-
</p>
<p>ing in class, but actually watching from the corner of the eye (to direct attention 
</p>
<p>to) another person of the class! Similarly, it is not because the person in front of 
</p>
<p>you looks at you in the eye at a dinner at the restaurant that he or she is not trying 
</p>
<p>to follow the conversation at the next table! In the following paragraphs, we will 
</p>
<p>describe how the study of selectivity in different sensory modalities, visual and 
</p>
<p>auditory, is conducted. 
</p>
<p>8.3.1     Visual Selectivity 
</p>
<p>   The stimuli  reaching   the retina are not only numerous, but they sometimes succeed 
</p>
<p>at a high speed, when reading, for example, or when looking outside by the side 
</p>
<p>window when moving by car. Also,  as   we have seen when studying the perception 
</p>
<p>of form, the trace left by the stimuli on the retina persists for some time. Playing 
</p>
<p>with the selectivity of attentional processes, it is possible to investigate the duration 
</p>
<p>and the properties of this information on the retina. 
</p>
<p>8 Perception and Attention</p>
<p/>
</div>
<div class="page"><p/>
<p>129
</p>
<p> The technique of partial report, developed by George  Sperling  , allows studying 
</p>
<p>these properties. Let us consider the following situation. A series of 12 letters are 
</p>
<p>presented simultaneously to participants on a screen and this, during 50 ms. Those 
</p>
<p>letters are arranged in three rows of four. During some trials, participants are asked 
</p>
<p>to report as many letters as they can. Generally, in such conditions (full report), 
</p>
<p>participants will report four or fi ve letters. The question that arises is why are there 
</p>
<p>only four or fi ve of the 12 letters that are recalled? One answer may lie on the fact 
</p>
<p>that we can capture no more than four or fi ve letters at the same time, which would 
</p>
<p>reveal some perceptual limit in our way of capturing information. Another explana-
</p>
<p>tion could be the following one. Maybe all the information (the 12 letters) is avail-
</p>
<p>able for a short time, but while the fi rst letters are recalled, the others disappear. 
</p>
<p> It is in order to test this second explanation that Sperling ( 1960 ) has developed 
</p>
<p>his clever strategy, the partial report. This technique is based on the idea of a pairing 
</p>
<p>between a sound and a row of letters. Thus, high-, medium-, and low-frequency 
</p>
<p>sounds are associated with the rows of four letters from the top, middle, and bottom, 
</p>
<p>which is the 12-letter set on the screen.  Immediately   after the short presentation of 
</p>
<p>letters, a sound is presented to the participant. This sound indicates which letters, 
</p>
<p>specifi cally, should be reported. If the sound is most acute (high frequency), one 
</p>
<p>must report the letters arranged on the top row. If the failure to report more than four 
</p>
<p>or fi ve letters, on average, in a global report is related to a limit on the number of 
</p>
<p>letters perceived, one should report only one or two letters per row, on average, dur-
</p>
<p>ing the partial report. However, if all the information is available for a brief period 
</p>
<p>before the information is erased, one should report more than one or two letters per 
</p>
<p>row, on average. 
</p>
<p> It appears that during the partial report, participants are much better. They can 
</p>
<p>report on average at least three letters per row. In other words, the information is 
</p>
<p>there for a short time, and, if one directs attention immediately to the information, 
</p>
<p>we have access to it. It is important to specify that the sound is presented only after 
</p>
<p>the presentation of the letters is completed. This means that participants cannot 
</p>
<p>direct in advance their attention on a row. 
</p>
<p> It is when the sound signal is  presented   immediately at the end of the visual pre-
</p>
<p>sentation that the partial report shows the most benefi ts (more letters recalled on 
</p>
<p>average). In fact, Sperling has shown that the introduction of a gap between the end 
</p>
<p>of the presentation of the letters and the sound nullifi ed the benefi ts associated with 
</p>
<p>the partial report. With an interval of 150 or even 300 ms, more letters are reminded 
</p>
<p>on average than with a global report, but this effect disappears completely if the delay 
</p>
<p>lasts 1 s. In short, the information is really there, available, but only for a short period. 
</p>
<p> In terms of cognitive psychology, we call sensory register&mdash;a kind of very short- 
</p>
<p>term memory&mdash;the initial stage of information processing where this information 
</p>
<p>persists for a short period after the disappearance of the physical stimulus. The 
</p>
<p>neural activity does not stop with the end of a stimulus; it stretches slightly over 
</p>
<p>time (Di Lollo &amp; Bischof,  1995 ; Loftus &amp; Irwin,  1998 ; Nisly &amp; Wasserman,  1989 ). 
</p>
<p>Sometimes the term iconic memory is used for referring to the sensory register in 
</p>
<p>the visual modality (as opposed to the echoic memory for auditory modality). 
</p>
<p>8.3 Selectivity</p>
<p/>
</div>
<div class="page"><p/>
<p>130
</p>
<p> In addition, another property of attentional processes that may affect the ability 
</p>
<p>to perceive is called the attentional blink (Dux &amp; Marois,  2009 ; Martensa &amp; Wybleb, 
</p>
<p> 2010 ). We can demonstrate this effect using a procedure where there are presented 
</p>
<p>successively, in one place, a series of visual stimuli rather than deploying stimuli at 
</p>
<p>different locations on the retina. If one asks a participant to report the presence of a 
</p>
<p>digit through a series of letters presented rapidly, this participant will succeed with-
</p>
<p>out diffi culty if the stimuli are not presented too quickly. For example, if the partici-
</p>
<p>pant is presented with eight to ten items per second, the task will be completed with 
</p>
<p>success and without too much diffi culty. If asked to detect a letter of a given color, 
</p>
<p>rather than a number, the participant will once again make it without diffi culty. 
</p>
<p>However, if asked to detect two targets, for example, a letter of a given color and a 
</p>
<p>digit, the ability to detect the second target will depend on how long before the fi rst 
</p>
<p>target was presented. If the second target comes between 200 and 500 ms after the 
</p>
<p>presentation of the fi rst target, the performance is affected. In fact, this reduction 
</p>
<p>occurs only if the fi rst target has been detected. Performance will be particularly 
</p>
<p>affected if the second target arrives from 200 to 300 ms after the fi rst. The atten-
</p>
<p>tional blink phenomenon is exactly this diffi culty to detect the second target, after 
</p>
<p>having paid attention to a fi rst target. The attention required for the processing of the 
</p>
<p>fi rst target would not be available for the processing of the second. 
</p>
<p> It is important to note that if the second target occurs about 100 ms after the fi rst, 
</p>
<p>there will be no decrease of the ability to capture the second, as if both targets could 
</p>
<p>be captured together, before the blink. In brief, this attentional blink phenomenon 
</p>
<p>teaches the deployment over time of processes linked to selective attention.    
</p>
<p>8.3.2     Auditory Selectivity 
</p>
<p>   When one pays  attention   to a precise source of information, what other information 
</p>
<p>available in the environment can be captured? Is it possible to extract anything else? 
</p>
<p>Yes, probably. For instance,  during   celebrations in a room where there are multiple 
</p>
<p>conversations in parallel, it is usually possible to follow effi ciently the conversation 
</p>
<p>where the attention is directed at. Although it is not possible to follow another con-
</p>
<p>versation, it is likely that you will react if someone around mentions your name. 
</p>
<p> Researchers interested in attentional selectivity often used a procedure called 
</p>
<p>dichotic listening. In a dichotic-listening task, a participant hears through  headphones 
</p>
<p>two messages at a time, one in each ear. The experimenter asks a participant to fol-
</p>
<p>low specifi cally the message sent to one ear, the left or the right one, and to ignore 
</p>
<p>the other. The participant is asked to repeat aloud the message that is followed, just 
</p>
<p>to make sure that it is actually well followed. 
</p>
<p> The work by Cherry ( 1953 ) indicates that there is a minimum of information 
</p>
<p>coming from the ear receiving no attention that remains available. The participant is 
</p>
<p>able to determine if, in this ear, a voice was heard, and when it is actually a voice, it 
</p>
<p>is possible to extract some physical features (for instance, was it a low or high 
</p>
<p>voice), but not to understand the meaning of the message. Also, if a series of digits 
</p>
<p>8 Perception and Attention</p>
<p/>
</div>
<div class="page"><p/>
<p>131
</p>
<p>are delivered simultaneously in each ear and no priority for left or right ear is 
</p>
<p>assigned to participants, they will report information coming from both ears, not in 
</p>
<p>a chronological order of arrival, but ear by ear. 
</p>
<p> This type of studies raises the question about the level where attention plays a 
</p>
<p>role in the sequence of information processing. Broadbent ( 1958 ) proposed the idea 
</p>
<p>that there exists an attentional fi lter, a kind of Y-shaped tube that can only let a lim-
</p>
<p>ited quantity of information passing through. Indeed, according to this researcher, a 
</p>
<p>central information processing system is responsible for the reception of informa-
</p>
<p>tion from different sensory channels for eventually determining the meaning on the 
</p>
<p>basis of what is already stored in memory. By letting only stimuli having some 
</p>
<p>specifi c features to enter, the fi lter would serve to avoid an overload of work to this 
</p>
<p>central system. The fi lter does not allow shifting from one channel to another. If that 
</p>
<p>would be the case, it would become possible to listen to more than one conversation 
</p>
<p>at a time. The selectivity would then operate early, i.e., at the level of acoustical 
</p>
<p>features. Therefore, the selectivity of information would occur at a low level, before 
</p>
<p>any semantic analysis would be made. 
</p>
<p> Following Broadbent&rsquo;s fi ndings, studies like the ones by Gray and Wedderburn 
</p>
<p>( 1960 ) showed that the attentional fi lter would rather operate a late selection. In one 
</p>
<p>study, participants heard simultaneously in each ear, for instance, messages like the 
</p>
<p>following ones:
</p>
<p> In the left ear  Hy&mdash;2&mdash;gen 
</p>
<p> In the right 
</p>
<p>ear 
</p>
<p> 6&mdash;dro&mdash;9 
</p>
<p>   It was therefore possible to hear simultaneously &ldquo;Hy 6,&rdquo; &ldquo;2 dro,&rdquo; and &ldquo;gen 9.&rdquo; 
</p>
<p>When participants were asked to follow what is reported in the left ear, to ignore 
</p>
<p>what is reported in the right ear, and then to report what was heard, they reported 
</p>
<p>&ldquo;Hy-dro-gen.&rdquo; In other words, participants&rsquo; attention was shifted from one ear to the 
</p>
<p>other and this, as a function of the meaning of the words. In brief, if it was once 
</p>
<p>thought that the attentional selection was made rapidly in the information process-
</p>
<p>ing sequence, it was henceforth necessary to believe that selection occurs at an 
</p>
<p>ulterior stage of processing given that there must have been some understanding of 
</p>
<p>the meaning for explaining the shifting from one ear to the other in Gray and 
</p>
<p>Wedderburn&rsquo;s study. 
</p>
<p> Anne Treisman also used dichotic listening, but rather presented segments of 
</p>
<p>sentences in each ear. Once again, the results showed that participants follow the 
</p>
<p>meaning of the message from one ear to the other, rather than to stick with the task 
</p>
<p>requiring to following what is sent to one ear specifi cally. These results support the 
</p>
<p>idea that there is a late fi lter (see Deutsch &amp; Deutsch,  1963 ) or, in the terms of 
</p>
<p>Treisman ( 1960 ), the idea that it would rather be an attenuator instead of a fi lter. 
</p>
<p> Instead of searching for the location of the fi lter or attenuator in the information 
</p>
<p> processing sequence, researchers in the fi eld of attention eventually preferred to empha-
</p>
<p>size the distinction between automatic processes and processes based on controlled 
</p>
<p>attention (Johnston &amp; Dark,  1986 ). Generally speaking, this approach shows a concern 
</p>
<p>8.3 Selectivity</p>
<p/>
</div>
<div class="page"><p/>
<p>132
</p>
<p>for attentional capacities, i.e., for the distribution of attentional resources in different 
</p>
<p>tasks. This approach goes far beyond the scope of the present book, which is focused on 
</p>
<p>perceptual processes. Attentional resources being limited, researchers in this study fi eld 
</p>
<p>wanted to know the mental load of different cognitive tasks, to what extent these tasks 
</p>
<p>solicit or not the same resources, and how these tasks can reach some automaticity. 
</p>
<p>Nowadays, in a society where everyone seems to search for time to the point of combin-
</p>
<p>ing tasks like using a cell phone and driving a car, it is easy to understand the importance 
</p>
<p>of knowing the attentional load imposed by tasks (Strayer &amp; Johnston,  2001 ). 
</p>
<p> Being exposed to the  Stroop effect   rapidly provides an idea of what the auto-
</p>
<p>matic activation of a process looks like (MacLeod,  1991 ; Stroop,  1935 ). This effect 
</p>
<p>appears when one tries to name the color with which each word is written, each 
</p>
<p>word designating a color actually. It is very diffi cult to ignore the meaning of the 
</p>
<p>word (the color designated when reading) when trying to simply name the color 
</p>
<p>used to write the word. Reading is not required in this task; just naming the color is 
</p>
<p>required. Nevertheless, reading imposes itself automatically and, consequently, 
</p>
<p>causes interference. Just to catch the strength of this effect, go to Fig.  8.2  and try see 
</p>
<p>BLUE RED GREEN YELLOW
</p>
<p>YELLOW GREEN BLUE RED
</p>
<p>GREEN BLUE YELLOW RED
</p>
<p>RED YELLOW GREEN BLUE
</p>
<p>YELLOW BLUE GREEN RED
</p>
<p>BLENU ROUGE VEBRT JAUN E
</p>
<p>JAUNE VEBRT BLEBU ROUGE
</p>
<p>VENRT BLEBU JAUNE ROUGE
</p>
<p>ROUGE JAUNE VERN  BLBE U
</p>
<p>IJAUNE BLBEU VEBRT ROUGE
</p>
<p>  Fig. 8.2    Example of a  Stroop effect  . Naming the color ( lower set ) of each of the 20  rectangles  
</p>
<p>(fi ve rows of four colors) takes much less time than naming the color ( upper set ) used for writing 
</p>
<p>each of the words. This demonstration illustrates an interference effect caused by the automatic 
</p>
<p>activation of word reading       
</p>
<p> 
</p>
<p>8 Perception and Attention</p>
<p/>
</div>
<div class="page"><p/>
<p>133
</p>
<p>how much time you need for naming each color in the lower series (colors without 
</p>
<p>letters). Then, see how much time it takes for naming each color in the upper series 
</p>
<p>(colors with letters). There should quite a large difference (several seconds). You 
</p>
<p>may also try to simply read each word of the series of words. Once again, you 
</p>
<p>should observe that it takes much less time to complete this task than it takes to 
</p>
<p>name the colors in the same series.  
</p>
<p>8.4         Visual Search 
</p>
<p>   The tasks used in  the   preceding part of the chapter on attentional selectivity are 
</p>
<p>somewhat artifi cial. For instance, in the case of visual selectivity, participants are 
</p>
<p>asked in advance where to look. In everyday life,  one rather  needs to search actively 
</p>
<p>for something in a set of stimuli. Indeed, being able to extract visually something 
</p>
<p>from the environment does not rely on the sole stimulation of the retina. When sev-
</p>
<p>eral elements are at the reach of sight, one has to search for a specifi c item for seeing 
</p>
<p>it (Wolfe &amp; Horowitz,  2004 ). 
</p>
<p> A part of the study of attentional mechanisms is dedicated to visual search. 
</p>
<p>Typical tasks to complete in this research fi eld involve the presentation of a series of 
</p>
<p>items to a participant who is asked to fi nd a specifi c item (a target). 
</p>
<p> In an experiment where a letter must be found among many others, the specifi c 
</p>
<p>features of these letters will determine how easy or diffi cult it is to spot the target 
</p>
<p>letter. Figure  8.3  illustrates visual sets like the ones used by Neisser ( 1964 ). It is 
</p>
<p>much easier to detect letter Z in the left set given the numerous features Z shares 
</p>
<p>with letters in the right set.
</p>
<p>   There are cases where the number of items determines the time needed for 
</p>
<p>detecting a target and cases where this number has no impact. For instance, in 
</p>
<p>Fig.  8.4 , it is possible to detect rapidly, in the upper set (fi ve letters), letter Z or even 
</p>
<p>both letters O. However, spotting Z in the lower left set is much easier than spotting 
</p>
<p>O in the lower right set. Indeed, increasing the number of items in conditions like 
</p>
<p>the one in the lower right set results in longer time for detecting the target letter (O). 
</p>
<p>However, increasing the number of items (O or Q) in the left set would not change 
</p>
<p>the time needed to detect letter Z: the target simply pops out. It is the fact that a 
</p>
<p>target shares more or less features with other items that determines the possibility 
</p>
<p>that a target pops out or not.
</p>
<p>   Researchers have also been interested in visual search of features besides the 
</p>
<p>strict letter framework. Different features were used like rectangles being presented 
</p>
<p>horizontally or vertically or presented in different colors. Usually, participants are 
</p>
<p>asked to detect a target on the basis of only one feature. Sometimes, the task gets a 
</p>
<p>little more complicated, as in a conjunction search where participants are asked to 
</p>
<p>detect a target involving at least two types of features. 
</p>
<p> A classic explanation of the functioning of visual search is the feature integration 
</p>
<p>theory (Treisman &amp; Gelade,  1980 ). This theory of visual attention is based on the idea 
</p>
<p>that processing an object or a visual scene involves two steps. First, at a preattentive 
</p>
<p>8.4 Visual Search</p>
<p/>
</div>
<div class="page"><p/>
<p>134
</p>
<p>stage, an object is processed as a function of its features. It is then possible to proceed 
</p>
<p>to the analysis of a certain number of features because they are processed in parallel, 
</p>
<p>i.e., in an automatic way, without the contribution of attentional resources. The theory 
</p>
<p>also posits a second stage where it is necessary to link  features to objects: that is 
</p>
<p>referred to as the  binding  problem (Treisman,  1996 ). This processing stage requires 
</p>
<p>attentional resources, attention being directed toward one item at a time. The idea that 
</p>
<p>there exist two processing stages, i.e., that there are, on the one hand, features per se 
</p>
<p>constituting an object and, on the other hand, a need to link these features, is supported 
</p>
<p>by what is observed when participants are placed in very diffi cult conditions. 
</p>
<p>Presenting illusory conjunctions generates such diffi cult conditions (Treisman &amp; 
</p>
<p>Schmidt,  1982 ). These illusory conjunctions are errors occurring when one reports 
</p>
<p>having seen, in a visual set, a letter of a certain color. This letter was presented, and 
</p>
<p>the color reported too, but this exact letter in this exact color was not presented.    
</p>
<p>ODUGQR IVMXEW
</p>
<p>QCDUGO EWVMIX
</p>
<p>CQOGRD EXWMVI
</p>
<p>QUGCDR IXEMWV
</p>
<p>URDGQO VXWEMI
</p>
<p>GRUQDO MXVEWI
</p>
<p>DUZGRO XVWMEI
</p>
<p>UCGROD MWXVIE
</p>
<p>DQRCGU VIMEXW
</p>
<p>QDOCGU EXVWIM
</p>
<p>CGUROQ VWMIEX
</p>
<p>OCDURQ VMWIEX
</p>
<p>UOCGQD XVWMEI
</p>
<p>RGQCOU WXVEMI
</p>
<p>GRUDQO XMEWIV
</p>
<p>GODUCQ MXIVEW
</p>
<p>QCURDO VEWMIX
</p>
<p>DUCOQG EMVXWI
</p>
<p>CGRDQU IVWMEX
</p>
<p>UDRCOQ IEVMWX
</p>
<p>GQCORU WVZMXE
</p>
<p>GOQUCD XEMIWV
</p>
<p>GDQUOC WXIMEV
</p>
<p>URDCGO EMWIVX
</p>
<p>GODRQC IVEMXW
</p>
<p>  Fig. 8.3    Example of 
</p>
<p>visual sets used by Neisser 
</p>
<p>( 1964 )       
</p>
<p> 
</p>
<p>8 Perception and Attention</p>
<p/>
</div>
<div class="page"><p/>
<p>135
</p>
<p>8.5     Clinical Aspects 
</p>
<p>  There exist  different   attentional problems having impact on perception. One of 
</p>
<p>these is called hemineglect. Someone suffering from parietal cortex damage might 
</p>
<p>well experience problems with visual attention. More specifi cally, if a lesion is on 
</p>
<p>the right cerebral hemisphere, the patient will not be able to pay attention to all 
</p>
<p>material located on the contralateral (opposite) side, i.e., to anything located at the 
</p>
<p>left of a fi xation point. A special case of hemineglect is called extinction. A patient 
</p>
<p>with such a defi cit would be able to see an object located on the contralateral side, 
</p>
<p>but only if there is no object at the corresponding location in the other visual hemi-
</p>
<p>fi eld (i.e., on the ipsilateral side). 
</p>
<p> Sometimes, parietal lesions can be bilateral. In these rare cases, a patient suffers 
</p>
<p>from a problem called the  Balint syndrome  . Different symptoms may result from 
</p>
<p>this problem. For instance, a patient seems able to see only one object at the time. It 
</p>
<p>is as if everything around the object one is paying attention to simply does not exist 
</p>
<p>anymore. This incapacity to perceive more than a single object at a time is some-
</p>
<p>times referred to as simultagnosia. 
</p>
<p> Finally, there are cases where, following cerebral lesions, patients report being 
</p>
<p>unable to see some objects (Weiskrantz,  1986 ). However, they do &ldquo;guess correctly&rdquo; 
</p>
<p>their location if one insists for having them pointing where they are. This phenom-
</p>
<p>enon, called   blindsight   , reveals the fact that it does not look necessary to consciously 
</p>
<p>see something for acting or reacting to this thing.        
</p>
<p>  Fig. 8.4    If one searches for letter Z in a stimulus set like the one on the  lower left part , the size of 
</p>
<p>the visual set has no impact; however, if one searches letter O in a stimulus set like the one on the 
</p>
<p> lower right part , the size of the set becomes critical. In the former case, Z emerges spontaneously 
</p>
<p>(pop-out phenomenon)       
</p>
<p> 
</p>
<p>8.5 Clinical Aspects</p>
<p/>
</div>
<div class="page"><p/>
<p>137&copy; Springer International Publishing Switzerland 2016 
S. Grondin, Psychology of Perception, DOI 10.1007/978-3-319-31791-5
</p>
<p>                        Appendix A: ROC Curves 
</p>
<p> The   receiver operating characteristic  (ROC) curves   are used to capture at a glance 
both the level of discrimination ( d&prime; ) and the decision criterion (for instance,  &szlig; ). An 
ROC curve is obtained when plotting the probabilities of a hit, on the ordinate, and 
the probabilities of a false alarm, on the abscissa (Fig.  A.1 ). 
</p>
<p> The sensitivity of an observer will be revealed by the distance of the curve from 
the diagonal, which represents the case where  d&prime;  = 0. Furthermore, the observer&rsquo;s 
response bias is revealed by the location of a point on a given curve. The perfor-
mance of a lax observer, i.e., of someone with a high rate of hits and false alarms, is 
represented by a point in the upper right of the curve, whereas the performance of a 
conservative observer is represented by a point in the lower left.
</p>
<p>   There are specifi c ways to move the decision criterion of an observer, i.e., to 
change the location of a point on a given ROC curve.  One   of these ways is to assign 
rewards (e.g., giving participant money) for each hit and to administer punishment 
(asking participant for money) for each false alarm. Depending on the value of 
rewards and punishments, the observer will adjust the criterion. If there is more 
money involved for a hit than for a false alarm, the observer will adopt a lax crite-
rion (the point will move up and to the right on the ROC curve). Conversely, observ-
ers will become much more conservative in their way of making decisions in 
conditions where it is necessary to pay more for a false alarm than what could be 
obtained for a hit. It is important to remind that the movements of the criterion do 
not affect sensitivity. 
</p>
<p> Note in conclusion that the ROC curves are also used to test some assumptions 
underlying the signal detection theory. For example, with the transformation of pro-
portions into  Z -scores, it becomes possible to determine whether the distribution 
noise and signal + noise are normal and whether their variance is the same. In the 
fi rst case (normal distributions), for a given ROC  curve   transformed into  Z -scores, 
the points should fall on or near the linear function, and in the second case (equal 
variance assumption), the slope of this function should be 1.  </p>
<p/>
</div>
<div class="page"><p/>
<p>138
</p>
<p> Fig. A.1    On this  receiver operating characteristic  (ROC) curve, sensitivity ( d&prime; ) is the same every-
where. C is a conservative observer and A is  a   lax observer. C and A would therefore have a differ-
ent criterion  
</p>
<p>      
</p>
<p> 
</p>
<p>Appendix A: ROC Curves</p>
<p/>
</div>
<div class="page"><p/>
<p>139&copy; Springer International Publishing Switzerland 2016 
S. Grondin, Psychology of Perception, DOI 10.1007/978-3-319-31791-5
</p>
<p>    Appendix B: Fechner&rsquo;s Law 
</p>
<p> Founder of psychophysics, Gustav Fechner  was   interested in the nature of the rela-
tionship between the magnitude of a stimulus and the magnitude of sensation. Fechner 
believed that this relationship was bound to be logarithmic. Indeed, to establish the 
relationship, he postulated that the magnitude of the sensation can be described by a 
unit called the  just-noticeable difference (JND)  , which itself could be quantifi ed indi-
rectly on the basis of the Weber fraction. The 0 point of his psychological scale is the 
absolute threshold. 
</p>
<p> Thus, for a sensory continuum having an absolute threshold equal to 10 (arbitrary 
units) and a Weber fraction of 0.3, the calculation of the scale is as follows:
</p>
<p> JND  Value (in log) 
</p>
<p> 1 = 10 + (10 &times; 0.3) = 13  (1.114) 
 2 = 13 + (13 &times; 0.3) = 16.9  (1.228) 
 3 = 16.9 + (16.9 &times; 0.3) = 21.97  (1.342) 
 4 = 21.97 + (21.97 &times; 0.3) = 28.56  (1.456) 
 5 = 28.56 + (28.56 &times; 0.3) = 37.13  (1.570) 
 6 = 37.13 + (37.13 &times; 0.3) = 48.27  (1.684) 
 And so on 
</p>
<p>   In short, to achieve a JND, the stimulus in  this   example must have a value of 13. 
The next JND occurs when the intensity is 16.9. Reported graphically, these values 
show that the relationship between JND, on the  y -axis, and the value of stimuli, on the 
 x -axis, increases logarithmically (Fig.  B.1 , left). If it is rather the logarithmic value of 
stimuli that is used on the  x -axis, the relationship becomes linear (Fig.  B.1 , right).
</p>
<p>   This logarithmic relationship can be summarized in the following equation:
</p>
<p>  JND = K logf    
</p>
<p>where JND is the sensation,  K  is a multiplicative constant whose value is related to 
a given modality and a given sensory dimension, and  ϕ  is the stimulus intensity 
above the absolute threshold. </p>
<p/>
</div>
<div class="page"><p/>
<p>140
</p>
<p> In the mind of Fechner, the fourth JND corresponds  to   something that is psycho-
logically twice as high as the second JND. This indirect way of establishing the link 
between sensation and the physical magnitude was incorrect, especially considering 
the fact that the Weber fraction is not constant, being higher for low physical mag-
nitudes. The direct way in which Stevens addressed the issue of the relationship 
between the magnitude of a stimulus and the sensory magnitude was proved to be 
more fruitful.  
</p>
<p>     
</p>
<p> Fig. B.1    Relationship between the value of a &ldquo;just-noticeable difference&rdquo; (JND) and the intensity 
of the stimuli on the  linear   scale (on the  left ) and on a logarithmic (on the  right )  
</p>
<p> 
</p>
<p>Appendix B: Fechner&rsquo;s Law</p>
<p/>
</div>
<div class="page"><p/>
<p>141&copy; Springer International Publishing Switzerland 2016 
S. Grondin, Psychology of Perception, DOI 10.1007/978-3-319-31791-5
</p>
<p>    Appendix C: The Nervous System 
</p>
<p> The study of the  nervous system   requires many nuances. Nevertheless, tracing the 
main lines of the anatomy of the nervous system should allow to develop a clear 
view of the link between the peripheral activity of the sensory receptors and the one 
occurring at higher levels of processing, that is, those that lead to the brain. 
</p>
<p> The nervous system is divided into the central nervous system and peripheral 
nervous system. The main parts of the central nervous system are described below. 
The peripheral nervous system includes the autonomic nervous system (which con-
sists of the sympathetic and parasympathetic systems) and the somatic nervous sys-
tem. The latter is particularly interesting because it includes the nerves. 
</p>
<p>    C.1   Nerves 
</p>
<p> Neurons are the basic units of the  nervous   system because they allow the transmis-
sion of nerve impulses and therefore the transmission of the information throughout 
the body. The nerves are groups of axons in the peripheral nervous system, the axon 
of the neuron being the prolongation of cell body up to many ramifi cations. 
</p>
<p> The nerves are in charge of the transmission of nerve impulses from receptors to 
the spinal cord. The peripheral nervous system is composed of 12 pairs of cranial 
nerves and 31 pairs of spinal nerves. Cranial nerves, which are designated by num-
bers I to XII, also have a name providing information about their function. Some 
nerves are strictly efferent, others strictly afferent, and others, like the trigeminal 
(V), have both functions. In the context of the study of sensation and perception, it 
should be emphasized that nerves I, II, and VIII are, respectively, associated with 
olfaction, vision, and hearing. In the latter case, it is more specifi cally the vestibulo-
cochlear nerve, indicating that a branch of the nerve is assigned to the vestibular 
system, which is located in the inner ear. </p>
<p/>
</div>
<div class="page"><p/>
<p>142
</p>
<p> Spinal nerves are determined according to the  height   where they are located on 
the spine: cervical (1&ndash;8), thoracic (1&ndash;12), lumbar (1&ndash;5), sacral (of 1&ndash;5), and coc-
cygeal (1) nerves. Each of these nerves innervates a band (or segmented area) of the 
skin called dermatome.  
</p>
<p>    C.2   Central Nervous System 
</p>
<p>    C.2.1 Major Divisions 
</p>
<p> The  central nervous system   includes the encephalon and spinal cord. The encepha-
lon is the general term which includes the brain, brain stem, and cerebellum. Suffi ce 
it here to recall that the brain includes the cerebral cortex (or the forebrain), in addi-
tion to important structures (the limbic system, thalamus, and hypothalamus). Just 
below the brain is the brainstem which includes, from top to bottom, the midbrain, 
the pons, and the bulb. The cerebellum is located just behind the brainstem and the 
spinal cord is located just below the brainstem. Table  C.1  summarizes the main divi-
sions of the central nervous system.
</p>
<p>       C.2.2 Cerebral Cortex 
</p>
<p> Different areas of the  cerebral cortex   are specialized in specifi c functions. For locat-
ing these areas easily, it is useful to identify, in Fig.  C.1 , the central and lateral fi s-
sures (or sulcus) on the cortex, as well as the four lobes: frontal, occipital, parietal, 
and temporal. Just before the central fi ssure are the motor cortex and premotor cor-
tex, and just behind, we fi nd the somatosensory cortex, which is itself divided into 
two areas, called primary and secondary. The primary somatosensory cortex receives 
</p>
<p>  Table C.1    Divisions of the  central   nervous system and some 
associated terms   
</p>
<p> Encephalon = brain + brain stem + cerebellum 
 Brain = cerebral cortex + limbic system + thalamus + hypothalamus 
 Brainstem = midbrain + pons + bulb 
 Telencephalon (or cerebral cortex) 
 Diencephalon (thalamus + hypothalamus) 
 Mesencephalon (or midbrain) 
 Metencephalon (pons) 
 Myelencephalon (bulb) 
 Forebrain = telencephalon + diencephalon 
 Midbrain = mesencephalon 
 Hindbrain = pons + bulb + cerebellum 
</p>
<p>Appendix C: The Nervous System</p>
<p/>
</div>
<div class="page"><p/>
<p>143
</p>
<p>information directly from the receptor organs, whereas the secondary somatosen-
sory cortex receives only information that has previously been processed elsewhere 
in the brain, including in the primary somatosensory cortex. The auditory cortex is 
located in the temporal lobe, while the different divisions of the visual cortex are 
located on the back, in the occipital lobe.
</p>
<p>       C.2.3 The Spinal Cord and Sensory Pathways 
</p>
<p> The  spinal cord   is the part of the central nervous system, protected by the spine, 
which provides communication (i.e., the transmission of nerve impulses) between 
the peripheral nervous system and the brain and between the brain and effectors 
(muscles). If one makes a  cross   section of the spinal cord, it is  possible   to observe 
several columns which are actually groups of numerous axons. These columns are 
ascendant (or afferent) when assigned to the transmission of information from the 
periphery to the brain or descendant (or efferent) when assigned to the transmission 
of nerve impulses from the brain to effectors (muscles). 
</p>
<p> Figure  C.2  allows to distinguish a ventral part (or anterior), toward the front, and 
a dorsal part (or posterior), toward the back. What is on the sides is called lateral. 
</p>
<p>      
</p>
<p> Fig. C.1    Main functional areas of the cerebral cortex  
</p>
<p> 
</p>
<p>Appendix C: The Nervous System</p>
<p/>
</div>
<div class="page"><p/>
<p>144
</p>
<p>This helps to identify the dorsal, ventral, or lateral horns, located in the gray matter 
of the spinal cord, and the dorsal, ventral, or lateral columns, located in the white 
matter.
</p>
<p>   There are two main  pathways   responsible for transmitting sensory information. 
Both systems differ by the exact location where there circulates the nerve impulse 
and by the type of information that is conveyed. To easily understand the path of the 
nerve impulse from the receptors to the brain receptors, it is important to remember 
that the information received on one side of the body, left or right, is transferred in 
the contralateral side, right or left, of the brain. The transfer of information from one 
side of the body to another sometimes occurs at the level of the spinal cord, i.e., 
immediately at the level where the sensation is produced. This is the case of the 
spinothalamic system (or extralemniscal system): information crosses from one 
hemibody to the other upon entry into the spinal cord and is routed directly to the 
thalamus where there is a relay (synapse) with another neuron. From there, the 
nerve impulse is sent to an area of the cerebral cortex specialized in somesthesia. At 
the level of the spinal cord, the infl ux travels though the anterolateral part. 
</p>
<p> A portion of the sensory  information   follows a different route to reach the 
somatosensory cortex. This other pathway is characterized in that the transfer of 
nerve impulses from one side of the body to another does not occur at the level of 
the spinal cord, but much higher in the nervous system, namely, at the bulb level. 
After crossing at the bulb, there is also a synapse, before the projection in the 
</p>
<p>      
</p>
<p> Fig. C.2    Cross section of the spinal cord  
</p>
<p> 
</p>
<p>Appendix C: The Nervous System</p>
<p/>
</div>
<div class="page"><p/>
<p>145
</p>
<p>somatosensory area, at the thalamus level. This path is called the dorsal column 
system (or lemniscal system) and is located in the posterior part of the spinal cord. 
Table  C.2  indicates which pathway (spinothalamic or lemniscal) is used by different 
sensations for reaching the brain.
</p>
<p>     C.3 Methods for Studying Brain 
</p>
<p> Even though this information  goes   slightly beyond the scope of this book, it is worth 
recalling the main techniques used to ascertain the relationships between brain 
structures and different sensory, perceptual, or cognitive functions. 
</p>
<p> As early as the nineteenth century, links were established between brain damage 
or removal of certain groups of neurons and affected functions. It is now possible to 
create lesions, in animals, to test hypotheses about the role of the specifi c brain 
areas that are damaged. Similarly, since the mid-twentieth century, neurophysiology 
techniques were developed for implanting microelectrodes to collect the activity of 
single neurons and their role in sensory physiology. 
</p>
<p> Nowadays, there are many  techniques   that allow to draw a general picture, or an 
image, of brain activity. Generally, they allow or have a fair idea of the location of a 
structure involved in the function tested or a fair idea regarding when a cerebral 
contribution occurs. Thus, for nearly 50 years, surface electrodes (on the scalp) were 
used to measure electrical activity in the brain. This method, called  electroencepha-
lography (EEG)  , refl ects the average activity of certain parts of the brain and how 
this activity changes over a given period. A particular form of this EEG activity is 
called evoked potentials. These analyses allow to linking quite precisely in time a 
change in electrical activity and the presentation of sensory stimuli. The electrical 
activity of the brain also produces small magnetic fi elds. Thus, a relatively new tech-
nique, called  magnetoencephalography (MEG)  , captures the magnetic activity and 
offers, in addition to a good temporal resolution as is the case for EEG, better spatial 
resolution since magnetic activity is less vulnerable than the electrical activity cap-
tured by the surface electrodes to the distortions caused, for example, by the skull. 
</p>
<p> Among the tools offered by technology to  researchers   in neuroscience, there is 
positron emission tomography. This technique, available for 50 years, measures the 
metabolic activity of the brain using radioactive tracers. It allows to locate some 
functions, but offers poor temporal resolution. The 1990s saw the emergence of a 
</p>
<p>    Table C.2    Central pathways used for the transmission of sensory information   
</p>
<p> Spinothalamic system  Lemniscal system 
</p>
<p> Tickling and itching  Sensations caused by vibrations 
 Pain  Sensations of friction against the skin 
 Diffuse sensations of tact or pressure  Sensation of body position in space 
 Sexual sensations  Sensations of fi ne touch 
 Thermal sensations 
</p>
<p>Appendix C: The Nervous System</p>
<p/>
</div>
<div class="page"><p/>
<p>146
</p>
<p>technique called functional magnetic resonance imaging. This technique, which 
does not require the use of radioactive substances, is based on the metabolic changes 
within the brain. It is thus possible to link the blood fl ow, as well as the amount of 
oxygen required by neurons, with some perceptual or cognitive activity. This tech-
nique allows a very high spatial resolution. 
</p>
<p> We can now count on neuromodulation techniques to better understand the prop-
erties of the brain. One of these techniques, the transcranial magnetic stimulation, 
has been available since the mid-1990s. This is a technique where one can create for 
a short time, with small magnetic pulses, a change in brain activity. One can, for 
example, create a temporary inability to use a small area of the  brain   and see how it 
affects a perceptual or cognitive ability. Even more recently, it has become possible 
to use   transcranial direct-current stimulation  (tDCS)  , a noninvasive technique 
where the application of a small current passes through two electrodes: anode and 
cathode. The effi cacy of tDCS depends on the position of the electrode and the 
intensity of the current. The anodal stimulation would increase synaptic transmis-
sion while cathodal stimulation would inhibit it.      
</p>
<p>Appendix C: The Nervous System</p>
<p/>
</div>
<div class="page"><p/>
<p>147&copy; Springer International Publishing Switzerland 2016 
S. Grondin, Psychology of Perception, DOI 10.1007/978-3-319-31791-5
</p>
<p>   References 
</p>
<p>   Bagot, J.-D. (1996).  Information, sensation et perception . Paris: Armand Colin.  
   Bausenhart, K. M., Rolke, B., &amp; Ulrich, R. (2008). Temporal preparation improves temporal reso-
</p>
<p>lution: Evidence from constant foreperiods.  Perception &amp; Psychophysics, 70 , 1504&ndash;1514.  
   Biederman, I. (1987). Recognition-by-components: A theory of human image understanding. 
</p>
<p> Psychological Review, 94 , 115&ndash;147.  
   Bonnet, C. (1986).  Manuel pratique de psychophysique . Paris: Armand Colin.  
   Bowmaker, J. K., &amp; Dartnell, H. J. A. (1980). Visual pigments of rods and cones in a human retina. 
</p>
<p> Journal of Physiology, 298 , 501&ndash;511.  
   Bowmaker, J. K., Dartnell, H. J. A., &amp; Mollon, J. D. (1980). Microspectrophotometric demonstra-
</p>
<p>tion of four classes of photoreceptor in an old world primate,  Macaca fascicularis. Journal of 
Physiology, 298 , 131&ndash;143.  
</p>
<p>   Bregman, A. S. (1990).  Auditory scene analysis (The perceptual organization of sound) . 
Cambridge, MA: MIT Press.  
</p>
<p>   Broadbent, D. (1958).  Perception and communication . London: Pergamon Press.  
   Bruce, V., Green, P. R., &amp; Georgeson, M. A. (1996).  Visual perception (physiology, psychology, 
</p>
<p>and ecology)  (3rd ed.). Sussex, England: Psychology Press.  
   Brungart, D. S., Durlach, N. I., &amp; Rabinowitz, W. M. (1999). Auditory localization of nearby 
</p>
<p>sources. II. Localization of a broadband source.  Journal of the Acoustical Society of America, 
106 , 1956&ndash;1968.  
</p>
<p>   Butler, R. A., Levy, E. T., &amp; Neff, W. D. (1980). Apparent distance of sounds recorded in echoic 
and anechoic chambers.  Journal of Experimental Psychology: Human Perception and 
Performance, 6 , 745&ndash;750.  
</p>
<p>   Calvert, G., Spence, C., &amp; Stein, B. E. (2004).  The handbook of multisensory processes . Cambridge, 
MA: MIT Press.  
</p>
<p>   Campbell, F. W., &amp; Robson, J. G. (1968). Application of Fourier analysis to the visibility of grat-
ings.  Journal of Physiology, 197 , 551&ndash;566.  
</p>
<p>   Chaudhuri, A. (2011).  Fundamentals of sensory perception . New York: Oxford University Press.  
  Cherry, C. (1953). Some experiments on the recognition of speech with one or two ears.  Journal 
</p>
<p>of the Acoustical Society of America, 25 , 975&ndash;979.  
   Coren, S., &amp; Girgus, J. S. (1978).  Seeing is deceiving: The psychology of visual illusions . Hillsdale, 
</p>
<p>NJ: Lawrence Erlbaum Associates.  
   Coren, S., Girgus, J. S., Ehrlichman, H., &amp; Hakstian, A. R. (1976). An empirical taxonomy of 
</p>
<p>visual illusions.  Perception and Psychophysics, 20 , 129&ndash;137.  
   Coren, S., Ward, L. M., &amp; Enns, J. (2004).  Sensation and perception  (6th ed.). Toronto, Ontario, 
</p>
<p>Canada: HBJ.  </p>
<p/>
</div>
<div class="page"><p/>
<p>148
</p>
<p>   Cowan, N. (1995).  Attention and memory: An integrated framework . New York: Oxford University 
Press.  
</p>
<p>   Dalton, P., &amp; Fraenkel, N. (2012). Gorillas we have missed: Sustained inattentional deafness for 
dynamic events.  Cognition, 124 , 367&ndash;372.  
</p>
<p>   Delorme, A. (1982).  Psychologie de la perception . Montr&eacute;al, Qu&eacute;bec, Canada: &Eacute;tudes Vivantes.  
   Delorme, A., &amp; Fl&uuml;ckiger, M. (2003).  Perception et r&eacute;alit&eacute; (Une introduction &agrave; la psychologie des 
</p>
<p>perceptions) . Boucherville, Qu&eacute;bec, Canada: Ga&euml;tan Morin.  
  Desrochers, A. (1990).  Langage et processus cognitifs . Manuel pour l&rsquo;&eacute;ducation &agrave; distance. 
</p>
<p>Universit&eacute; Laurentienne, Sudbury, Ontario, Canada.  
  Deutsch, D. (2010, July). The paradox of pitch circularity.  Acoustics Today , 8&ndash;15.  
   Deutsch, J. A., &amp; Deutsch, D. (1963). Attention: Some theoretical considerations.  Psychological 
</p>
<p>Review, 70 , 80&ndash;90.  
   DeValois, R. L., Abramovet, J., &amp; Jacobs, G. H. (1966). Analysis of response patterns of LGN 
</p>
<p>cells.  Journal of Optical Society of America, 56 , 966&ndash;977.  
  DeValois, R. L., &amp; DeValois, K. K. (1975). Neural coding of color. In E. C. Carterette and M. P. 
</p>
<p>Friedman (Eds.),  Handbook of perception  (Vol. 5, pp. 117&ndash;166). New York: Academic.  
   DeValois, R. L., &amp; DeValois, K. K. (1988).  Spatial vision  ( Oxford Psychology Series ). New York: 
</p>
<p>Oxford University Press.  
   Di Lollo, V., &amp; Bischof, W. F. (1995). The inverse intensity effect in duration of visible persistence. 
</p>
<p> Psychological Bulletin, 118 , 223&ndash;237.  
   Diehl, R. L., Lotto, A. J., &amp; Holt, L. L. (2004). Speech perception.  Annual Review of Psychology, 
</p>
<p>55 , 149&ndash;179.  
   Dowling, J. E., &amp; Boycott, B. B. (1966). Organization of the primate retina: Electron microscopy. 
</p>
<p> Proceedings of the Royal Society of London. Series B: Biological Sciences, 166 , 80&ndash;111.  
   Dux, P. E., &amp; Marois, R. (2009). The attentional blink: A review of data and theory.  Attention, 
</p>
<p>Perception, &amp; Psychophysics, 71 , 1683&ndash;1700.  
   Eimas, P. D., &amp; Corbit, J. D. (1973). Selective adaptation of linguistic feature detectors.  Cognitive 
</p>
<p>Psychology, 4 , 99&ndash;109.  
   Eisler, H. (1976). Experiments on subjective duration 1878-1975: A collection of power function 
</p>
<p>exponents.  Psychological Bulletin, 83 , 185&ndash;200.  
   Epstein, W. (Ed.). (1977).  Perceptual stability and constancy: Mechanisms and processes . 
</p>
<p>New York: Wiley.  
  Fechner, G. (1966).  Elements of psychophysics  (H. E. Adler, D. H. Howes &amp; E. G. Boring, Trans.). 
</p>
<p>New York: Holt, Rinehart &amp; Winston. (Original work published 1860)  
   Fletcher, H., &amp; Munson, W. A. (1933). Loudness, its defi nition, measurement and calculation. 
</p>
<p> Journal of the Acoustical Society of America, 6 , 82&ndash;108.  
   Foley, H. J., &amp; Matlin, M. W. (2010).  Sensation and perception  (5th ed.). Toronto, Ontario, Canada: 
</p>
<p>Allyn and Bacon.  
   Galantucci, B., Fowler, C. A., &amp; Turvey, M. T. (2006). The motor theory of speech perception 
</p>
<p>reviewed.  Psychonomic Bulletin &amp; Review, 13 , 361&ndash;377.  
   Gazzaniga, M. S., Ivry, R. B., &amp; Mangun, G. R. (2009).  Cognitive neuroscience&mdash;The biology of 
</p>
<p>the mind  (3rd ed.). New York: Norton.  
   Gescheider, G. A. (1997).  Psychophysics: Method, theory, and applications  (3rd ed.). Hillsdale, 
</p>
<p>NJ: Lawrence Erlbaum.  
   Gibson, J. J. (1966).  The senses considered as perceptual systems . Boston: Houghton Miffl in.  
   Gibson, J. J. (1979).  The ecological approach to visual perception . Boston: Houghton Miffl in.  
  Gibson, E. J., Schapiro, F., &amp; Yonas, A. (1968). Confusion matrices for graphic patterns obtained 
</p>
<p>with a latency measure.  The analysis of reading skill: A program of basic and applied research . 
(Final Report, Project No. 5&ndash;1213). Ithaca, NY: Cornell University and U.S. Offi ce of 
Education.  
</p>
<p>   Ginsburg, A. P., Evans, D. W., Sekuler, R., &amp; Harp, S. A. (1982). Contrast sensitivity predicts 
performance in aircraft simulators.  American Journal of Optometry and Physiological Optics, 
59 , 105&ndash;109.  
</p>
<p>References</p>
<p/>
</div>
<div class="page"><p/>
<p>149
</p>
<p>   Girgus, J. S., &amp; Coren, S. (1975). Depth cues and constancy scaling in the horizontal-vertical illu-
sion: The bisection error.  Canadian Journal of Psychology, 29 , 59&ndash;65.  
</p>
<p>   Goldstein, E. B. (2010).  Sensation and perception  (8th ed.). Belmont, CA: Wadsworth.  
   Gray, J. A., &amp; Wedderburn, A. I. (1960). Grouping strategies with simultaneous stimuli.  Quarterly 
</p>
<p>Journal of Experimental Psychology, 12 , 180&ndash;184.  
   Gregory, R. L. (1997). Knowledge in perception and illusion.  Philosophical Transactions of the 
</p>
<p>Royal Society of London, 352 , 1121&ndash;1128.  
   Grondin, S. (2001). From physical time to the fi rst and second moments of psychological time. 
</p>
<p> Psychological Bulletin, 127 , 22&ndash;44.  
   Grondin, S. (2008). Methods for studying psychological time. In S. Grondin (Ed.),  Psychology of 
</p>
<p>time  (pp. 51&ndash;74). Bingley, England: Emerald Group.  
   Grondin, S. (2010). Timing and time perception: A review of recent behavioral and neuroscience 
</p>
<p>fi ndings and theoretical directions.  Attention, Perception, &amp; Psychophysics, 72 , 561&ndash;582.  
   Grondin, S. (2012). Violation of the scalar property for time perception between 1 and 2 seconds: 
</p>
<p>Evidence from interval discrimination, reproduction, and categorization.  Journal of 
Experimental Psychology: Human Perception and Performance, 38 , 880&ndash;890.  
</p>
<p>   Grondin, S., &amp; Killeen, P. R. (2009). Tracking time with song and count: Different Weber functions 
for musicians and non-musicians.  Attention, Perception, &amp; Psychophysics, 71 , 1649&ndash;1654.  
</p>
<p>   Grondin, S., &amp; Lafl amme, V. (2015). Stevens&rsquo;s law for time: A direct comparison of prospective 
and retrospective judgments.  Attention, Perception, &amp; Psychophysics, 77 , 1044&ndash;1051.  
</p>
<p>   Grondin, S., &amp; Laforest, M. (2004). Discriminating slow tempo variations in a musical context. 
 Acoustical Science &amp; Technology, 25 , 159&ndash;162.  
</p>
<p>   Gulick, W. L., Gescheider, G. A., &amp; Frisina, R. D. (1989).  Hearing: Physiological acoustics, neu-
ral coding, and psychophysics . New York: Oxford University Press.  
</p>
<p>   Harmon, L. D., &amp; Julesz, B. (1973). Masking in visual recognition: Effects of two-dimensional 
fi ltered noise.  Science, 180 , 1194&ndash;1197.  
</p>
<p>   Hartline, H. K. (1940). The receptive fi elds of optic nerve fi bers.  American Journal of Physiology, 
130 , 690&ndash;699.  
</p>
<p>   Hartline, H. K., &amp; Ratliff, F. (1957). Inhibitory interaction of receptor units in the eye of limulus. 
 Journal of General Physiology, 40 , 357&ndash;376.  
</p>
<p>   Hartmann, W. M. (1996). Pitch, periodicity, and auditory organization.  Journal of the Acoustical 
Society of America, 100 , 3491&ndash;3502.  
</p>
<p>   Hellstr&ouml;m, &Aring;. (1985). The time-order error and its relatives: Mirrors of cognitive processes in 
comparing.  Psychological Bulletin, 97 , 35&ndash;61.  
</p>
<p>   Hershenson, M. (Ed.). (1989).  The moon illusion . Hillsdale, NJ: Lawrence Erlbaum.  
   Holway, A. H., &amp; Boring, E. G. (1941). Determinants of apparent visual size with distance variant. 
</p>
<p> American Journal of Psychology, 54 , 21&ndash;37.  
   Honegger, M. (Ed.). (1976).  Science de la musique  (Vol. 1&ndash;2). Paris: Bordas.  
   Hubel, D. H., &amp; Wiesel, T. N. (1959). Receptive fi elds of single neurones in the cat&rsquo;s striate cortex. 
</p>
<p> Journal of Physiology, 148 , 574&ndash;591.  
   Hubel, D. H., &amp; Wiesel, T. N. (1962). Receptive fi elds, binocular interaction and functional archi-
</p>
<p>tecture in the cat&rsquo;s visual cortex.  Journal of Physiology, 160 , 106&ndash;154.  
   Hubel, D. H., &amp; Wiesel, T. N. (1968). Receptive fi elds, binocular interaction, and functional archi-
</p>
<p>tecture in monkey striate cortex.  Journal of Physiology, 168 , 215&ndash;243.  
   Jesse, A., &amp; Massaro, D. W. (2010). Seeing a singer helps comprehension of the song&rsquo;s lyrics. 
</p>
<p> Psychonomic Bulletin &amp; Review, 17 , 323&ndash;328.  
   Johnston, W. A., &amp; Dark, V. J. (1986). Selective attention.  Annual Review of Psychology, 37 , 43&ndash;75.  
   Kaufman, L., &amp; Rock, I. (1962). The moon illusion.  Scientifi c American, 207 , 120&ndash;132.  
   Kilpatrick, F. P., &amp; Ittelson, W. H. (1953). The size-distance invariance hypothesis.  Psychological 
</p>
<p>Review, 60 , 223&ndash;231.  
   Klein, R. M. (2000). Inhibition of return.  Trends in Cognitive Sciences, 4 , 138&ndash;147.  
   Kluender, K. L., Diehl, R. L., &amp; Killeen, P. R. (1987). Japanese quail can learn phonetic categories. 
</p>
<p> Science, 237 , 1195&ndash;1197.  
</p>
<p>References</p>
<p/>
</div>
<div class="page"><p/>
<p>150
</p>
<p>   Kuffl er, S. W. (1953). Discharge patterns and functional organization of mammalian retina. 
 Journal of Neurophysiology, 16 , 37&ndash;68.  
</p>
<p>   Kuroda, T., Nakajima, Y., Tsunashima, S., &amp; Yasutake, T. (2009). Effects of spectra and sound 
pressure levels on the occurrence of the gap transfer illusion.  Perception, 38 , 411&ndash;428.  
</p>
<p>   Larsen, E., Iyer, N., Lansing, C. R., &amp; Feng, A. S. (2008). On the minimum audible difference in 
direct-to-reverberant energy ratio.  Journal of the Acoustical Society of America, 124 , 450&ndash;461.  
</p>
<p>   Le Petit Larousse illustr&eacute; 2011  &ndash; Dictionary (2010). Paris: Larousse.  
   Livingstone, M. S., &amp; Hubel, D. H. (1987). Psychophysical evidence for separate channels for the 
</p>
<p>perception of form, color, movement, and depth.  Journal of Neuroscience, 7 , 3416&ndash;3468.  
   Loftus, G. R., &amp; Irwin, D. E. (1998). On the relations among different measures of visible and 
</p>
<p>informational persistence.  Cognitive Psychology, 35 , 135&ndash;199.  
   Lortie, J.-Y., &amp; Parent, G. (1989).  Psychologie de la perception&mdash;Notes de cours . Sainte-Foy, 
</p>
<p>Quebec, Canada: Universit&eacute; Laval.  
   Macdonald, J. S. P., &amp; Lavie, N. (2011). Visual perceptual load induces inattentional deafness. 
</p>
<p> Attention, Perception, &amp; Psychophysics, 73 , 1780&ndash;1789.  
   Mack, A., &amp; Rock, I. (1998).  Inattentional blindness . Cambridge, MA: MIT Press.  
   MacLeod, C. M. (1991). Half a century of research on the Stroop effect: An integrative review. 
</p>
<p> Psychological Bulletin, 109 , 163&ndash;203.  
   Macmillan, N. A., &amp; Creelman, C. D. (1991).  Detection theory: A user&rsquo;s guide . New York: 
</p>
<p>Cambridge University Press.  
   Marr, D. (1982).  Vision: A computational investigation into the human representation and process-
</p>
<p>ing of visual information . New York: Freeman.  
   Marr, D., &amp; Nishihara, H. K. (1978). Representation and recognition of the spatial organization of 
</p>
<p>three-dimensional shapes.  Proceedings of the Royal Society of London B, 200 , 269&ndash;294.  
   Martensa, S., &amp; Wybleb, B. (2010). The attentional blink: Past, present, and future of a blind spot 
</p>
<p>in perceptual awareness.  Neuroscience and Biobehavioral Reviews, 34 , 947&ndash;957.  
   McCollough, C. (1965). Adaptation of edge-detectors in the human visual system.  Science, 149 , 
</p>
<p>1115&ndash;1116.  
   McGurk, H., &amp; MacDonald, J. (1976). Hearing lips and seeing voices.  Nature, 264 , 746&ndash;748.  
   Michael, C. R. (1978). Color vision mechanisms in monkey striate cortex: Dual-opponent cells 
</p>
<p>with concentric receptive fi elds.  Journal of Neurophysiology, 41 , 572&ndash;588.  
   Miller, G. A. (1947). The masking of speech.  Psychological Bulletin, 44 , 105&ndash;129.  
   Miller, G. A., &amp; Licklider, J. C. R. (1950). The intelligibility of interrupted speech.  Journal of the 
</p>
<p>Acoustical Society of America, 22 , 167&ndash;173.  
   Musicant, A. D., &amp; Butler, R. A. (1984). The infl uence of pinnae-based spectral cues on sound 
</p>
<p>localization.  Journal of the Acoustical Society of America, 75 , 1195&ndash;1200.  
   Nakajima, Y., Sasaki, T., Kanafuka, K., Miyamoto, A., Remijn, G., &amp; ten Hoopen, G. (2000). 
</p>
<p>Illusory recouplings of onsets and terminations of glide tone components.  Perception and 
Psychophysics, 62 , 1413&ndash;1425.  
</p>
<p>   Neisser, U. (1964). Visual search.  Scientifi c American, 210 (6), 94&ndash;102.  
   Niemi, P., &amp; N&auml;&auml;t&auml;nen, R. (1981). Foreperiod and simple reaction time.  Psychological Bulletin, 89 , 
</p>
<p>133&ndash;162.  
   Nisly, S. J., &amp; Wasserman, G. S. (1989). Intensity dependence of perceived duration: Data, theo-
</p>
<p>ries, and neural integration.  Psychological Bulletin, 106 , 483&ndash;496.  
   Palmer, S. E. (1992). Common regions: A new principle of perceptual grouping.  Cognitive 
</p>
<p>Psychology, 24 , 436&ndash;447.  
   Patel, A. D. (2008).  Music, language, and the brain . New York: Oxford University Press.  
   Penrose, L. S., &amp; Penrose, R. (1958). Impossible objects: A special type of visual illusion.  British 
</p>
<p>Journal of Psychology, 49 , 31&ndash;33.  
   Peretz, I., &amp; Hyde, K. L. (2003). What is specifi c to music processing? Insights from congenital 
</p>
<p>amusia.  Trends in Cognitive Sciences, 7 , 362&ndash;367.  
  Piaget, J. (1961).  Les m&eacute;canismes perceptifs . Paris: PUF.  
  Posner, M. I. (1978).  Chronometric exploration of mind . Hillsdale: Erlbaum.  
   Posner, M. I., &amp; Cohen, Y. (1984). Components of visual orienting. In H. Bouma &amp; D. Bouwhuis 
</p>
<p>(Eds.),  Attention &amp; performance X  (pp. 531&ndash;556). Hillsdale, NJ: Erlbaum.  
</p>
<p>References</p>
<p/>
</div>
<div class="page"><p/>
<p>151
</p>
<p>   Prinzmetal, W., &amp; Gettleman, L. (1993). Vertical-horizontal illusion: One eye is better than two. 
 Perception &amp; Psychophysics, 53 , 81&ndash;88.  
</p>
<p>   Rafal, R. D., Calabresi, P. A., Brennan, C. W., &amp; Sciolto, T. K. (1989). Saccade preparation inhibits 
reorienting to recently attended locations.  Journal of Experimental Psychology: Human 
Perception and Performance, 15 , 673&ndash;685.  
</p>
<p>   Reed, S. K. (1982).  Cognition: Theory and applications . Monterrey, CA: Brooks/Cole.  
   Rensink, R. A. (2002). Change detection.  Annual Review of Psychology, 53 , 245&ndash;277.  
   Rensink, R. A., O&rsquo;Regan, J. K., &amp; Clark, J. J. (1997). To see or not to see: The need for attention 
</p>
<p>to perceive changes in scenes.  Psychological Science, 8 , 368&ndash;373.  
   Rock, I., &amp; Kaufman, L. (1962). The moon illusion, II: The moon&rsquo;s apparent size is a function of 
</p>
<p>the presence or absence of terrain.  Science, 136 , 1023&ndash;1031.  
   Rosenzweig, M. R., Leiman, A. L., &amp; Breedlove, S. M. (1998).  Psychobiologie . New York: 
</p>
<p>Random House.  
   Ross, H., &amp; Plug, C. (2002).  The mystery of the moon illusion: Exploring size perception . Oxford, 
</p>
<p>England: Oxford University Press.  
   Sasaki, T. (1980). Sound restoration and temporal localization of noise in speech and music 
</p>
<p>sounds.  Tohoku Psychologica Folia, 39 , 79&ndash;88.  
   Schiffman, H. R. (2001).  Sensation and perception: An integrated approach  (5th ed.). New York: 
</p>
<p>Wiley.  
   Sekuler, R., &amp; Blake, R. (1990).  Perception  (2nd ed.). Toronto, Ontario, Canada: McGraw-Hill.  
   Selfridge, O. G. (1959). Pandemonium: A paradigm of learning. In D. V. Blake &amp; A. M. Uttley 
</p>
<p>(Eds.),  The mechanization of thought processes  (pp. 523&ndash;526). London: HM Stationery Offi ce.  
   Shen, Y. (2013). Comparing adaptive procedures for estimating the psychometric function for an 
</p>
<p>auditory gap detection task.  Attention, Perception and Psychophysics, 75 , 771&ndash;780.  
   Shen, Y., &amp; Richards, V. M. (2012). A maximum-likelihood procedure for estimating psychomet-
</p>
<p>ric functions: Thresholds, slopes, and lapses of attention.  Journal of Acoustical Society of 
America, 132 , 957&ndash;967.  
</p>
<p>   Shepard, R. N. (1964). Circularity in judgments of relative pitch.  Journal of the Acoustical Society 
of America, 36 , 2346&ndash;2353.  
</p>
<p>   Shepard, R. N. (1990).  Mind sight . New York: Freeman.  
   Simons, D. J., &amp; Chabris, C. F. (1999). Gorillas in our midst: Sustained inattentional blindness for 
</p>
<p>dynamic events.  Perception, 28 , 1059&ndash;1074.  
   Snyder, J. S., &amp; Alain, C. (2007). Toward a neurophysiology theory of auditory stream segregation. 
</p>
<p> Psychological Bulletin, 133 , 780&ndash;799.  
  Sperling, G. (1960). The information available in brief visual presentations.  Psychological 
</p>
<p>Monographs, 74 , 1&ndash;29.  
   Stevens, S. S. (1961). The psychophysics of sensory functions. In A. W. Rosenblith (Ed.),  Sensory 
</p>
<p>communication  (pp. 1&ndash;33). Cambridge, MA: MIT Press.  
   Stevens, S. S. (1975).  Psychophysics: Introduction to its perceptual, neural and social prospects . 
</p>
<p>New York: Wiley.  
   Strayer, D. L., &amp; Johnston, W. A. (2001). Driven to distraction: Dual-task studies of simulated 
</p>
<p>driving and conversing on a cellular phone.  Psychological Science, 12 , 462&ndash;466.  
   Stroop, J. R. (1935). Studies of interference in serial verbal reactions.  Journal of Experimental 
</p>
<p>Psychology, 18 , 643&ndash;662.  
   Thompson, W. F., Russo, R. A., &amp; Livingstone, S. (2010). Facial expressions of pitch structure in 
</p>
<p>music performance.  Psychonomic Bulletin &amp; Review, 17 , 317&ndash;322.  
   Treisman, A. M. (1960). Contextual cues in selective listening.  Quarterly Journal of Experimental 
</p>
<p>Psychology, 12 , 242&ndash;248.  
   Treisman, A. M. (1996). The binding problem.  Current Opinion in Neurobiology, 6 , 171&ndash;178.  
   Treisman, A. M., &amp; Gelade, G. (1980). A feature-integration theory of attention.  Cognitive 
</p>
<p>Psychology, 12 , 97&ndash;136.  
   Treisman, A. M., &amp; Schmidt, H. (1982). Illusory conjunctions in the perception of objects. 
</p>
<p> Cognitive Psychology, 14 , 107&ndash;141.  
</p>
<p>References</p>
<p/>
</div>
<div class="page"><p/>
<p>152
</p>
<p>   Tsao, D. Y., &amp; Livingstone, M. S. (2008). Mechanisms of face perception.  Annual Review of 
Neuroscience, 31 , 411&ndash;437.  
</p>
<p>   Tsunada, J., Lee, J. H., &amp; Cohen, Y. E. (2011). Representation of speech categories in the primate 
auditory cortex.  Journal of Neurophysiology, 105 , 2634&ndash;2646.  
</p>
<p>  van Noorden, L. P. A. S. (1975).  Temporal coherence in the perception of tone sequences . 
Unpublished doctoral dissertation. Eindhoven University of Technology, Eindhoven, 
Netherlands.  
</p>
<p>   Warren, R. M. (1970). Perceptual restoration of missing speech sounds.  Science, 167 , 392&ndash;393.  
   Weiskrantz, L. (1986).  Blindsight: A case study and implications . Oxford, England: Oxford 
</p>
<p>University Press.  
   Werner, H. (1935). Studies on contour: I. Quantitative analysis.  American Journal of Psychology, 
</p>
<p>47 , 40&ndash;64.  
   Wever, E. G., &amp; Bray, C. W. (1937). The perception of low tones and the resonance-volley theory. 
</p>
<p> Journal of Psychology, 3 , 101&ndash;114.  
   Wightman, F. L., &amp; Kistler, D. J. (1992). The dominant role of low-frequency interaural time dif-
</p>
<p>ferences in sound localization.  Journal of the Acoustical Society of America, 91 , 648&ndash;1661.  
   Wolfe, J. M., &amp; Horowitz, T. S. (2004). What attributes guide the deployment of visual attention 
</p>
<p>and how do they do it?  Nature Reviews Neuroscience, 5 , 1&ndash;7.  
   Wolfe, J. M., Kluender, K. R., Levi, D. M., Bartoshuk, L. M., Herz, R. S., Klatzky, R. L., et al. 
</p>
<p>(2006).  Sensation and perception . Sunderland, MA: Sinauer.  
   Yost, W. A. (2009). Pitch perception.  Attention, Perception and Psychophysics, 71 , 1701&ndash;1716.       
</p>
<p>References</p>
<p/>
</div>
<div class="page"><p/>
<p>153&copy; Springer International Publishing Switzerland 2016 
</p>
<p>S. Grondin, Psychology of Perception, DOI 10.1007/978-3-319-31791-5
</p>
<p>  A 
</p>
<p>  Absolute threshold  ,   1   
</p>
<p>  Aerial perspective  ,   109   
</p>
<p>  Affordance  ,   115   
</p>
<p>  After image  ,   78   
</p>
<p>  Agnosia  ,   101   
</p>
<p>  Amusia  ,   46   
</p>
<p>  Aqueous humor  ,   54   
</p>
<p>  Assimilation effects  ,   78   
</p>
<p>  Astigmatism  ,   63   
</p>
<p>  Attention process  ,   124&ndash;125    
</p>
<p>  Auditory adaptation  ,   32   
</p>
<p>  Auditory continuity  ,   38   
</p>
<p>  Auditory selectivity  ,   130&ndash;133     
</p>
<p> B 
</p>
<p>  Balint syndrome  ,   135   
</p>
<p>  Binocular convergence  ,   104   
</p>
<p>  Bipolar cells  ,   56   ,   57   
</p>
<p>  Blindnesses  ,   124&ndash;125   
</p>
<p>  Blindsight  ,   135   
</p>
<p>  Blind spot  ,   55   
</p>
<p>  Boring  ,   113   ,   114   
</p>
<p>  Brightness constancy  ,   111     
</p>
<p> C 
</p>
<p>  Cataract  ,   64   
</p>
<p>  Central deafness  ,   32   
</p>
<p>  Cerumen  ,   25   
</p>
<p>  Chroma  ,   43   
</p>
<p>  Chromatic effects  ,   76&ndash;80   
</p>
<p>  Cochlea  ,   27&ndash;28    
</p>
<p>  Color constancy  ,   80   ,   111    
</p>
<p>  Color perception 
</p>
<p> chromatic effects  ,   76&ndash;80  
</p>
<p> clinical aspects  ,   80&ndash;81  
</p>
<p> color mixtures 
</p>
<p> addition and subtraction  ,   72&ndash;74  
</p>
<p> primary colors  ,   71  
</p>
<p> color vision  ,   74&ndash;76  
</p>
<p> light intensity  ,   68  
</p>
<p> perceptual dimensions  ,   70  
</p>
<p> wavelength and spectral composition  ,   68&ndash;70   
</p>
<p>   Commission internationale de l&rsquo;&eacute;clairage  
</p>
<p>(CIE)  ,   71   
</p>
<p>  Common region  ,   93   
</p>
<p>  Complex sound wave  ,   20&ndash;22   
</p>
<p>  Computational theory  ,   99&ndash;100   
</p>
<p>  Connectedness  ,   93   
</p>
<p>  Contrast sensitivity function (CSF)  ,   97&ndash;98   
</p>
<p>  Cross disparity  ,   105     
</p>
<p> D 
</p>
<p>  Delboeuf illusions  ,   120   
</p>
<p>  Depth perception 
</p>
<p> constancy 
</p>
<p> Gibson&rsquo;s perspective  ,   114&ndash;115  
</p>
<p> interpretations and investigations  , 
</p>
<p>  112&ndash;114  
</p>
<p> types  ,   111  
</p>
<p> cues  ,   103  
</p>
<p> binocular convergence  ,   104  
</p>
<p> monocular  ,   106&ndash;111  
</p>
<p> retinal disparity  ,   105  
</p>
<p> illusions 
</p>
<p> classifi cation  ,   115&ndash;118  
</p>
<p> moon  ,   118&ndash;122   
</p>
<p>                        Index </p>
<p/>
</div>
<div class="page"><p/>
<p>154
</p>
<p>  Dichromatism  ,   80   
</p>
<p>  Difference threshold  ,   6   
</p>
<p>  Doppler effect  ,   42     
</p>
<p> E 
</p>
<p>  Ecological position  ,   114   
</p>
<p>  Emmert&rsquo;s law  ,   112   
</p>
<p>  Equalization effects  ,   78   
</p>
<p>  Equal-loudness contours  ,   23   
</p>
<p>  Eustachian tube  ,   26   
</p>
<p>  Eye 
</p>
<p> clinical aspects  ,   63&ndash;65  
</p>
<p> eyeball  ,   53&ndash;55  
</p>
<p> receptive fi elds  ,   57&ndash;59  
</p>
<p> retina  ,   55&ndash;57  
</p>
<p> visual cortex  ,   60&ndash;61  
</p>
<p> visual pathways  ,   61&ndash;63     
</p>
<p> F 
</p>
<p>  Facilitation effect  ,   126    
</p>
<p>  Fechner, Gustav  ,   1   
</p>
<p>  Form perception  ,   87   ,   93  
</p>
<p> agnosia  ,   101  
</p>
<p> computational approach  ,   99&ndash;100  
</p>
<p> edges and subjective contours  ,   84&ndash;85  
</p>
<p> factors  ,   87&ndash;89  
</p>
<p> Gestalt    (see  Gestalt )  
</p>
<p> lateral inhibition  ,   85&ndash;86  
</p>
<p> Mach bands  ,   86&ndash;87  
</p>
<p> multiple spatial channels    (see  Multiple 
</p>
<p>spatial channels theory )  
</p>
<p> structural model  ,   100&ndash;101  
</p>
<p> templates/characteristics  ,   98&ndash;99   
</p>
<p>  Frequency theory  ,   29&ndash;30     
</p>
<p> G 
</p>
<p>  Ganglion cells  ,   58   ,   59   
</p>
<p>  Ganzfeld  ,   83   
</p>
<p>  Gap transfer  ,   36&ndash;39   
</p>
<p>  Gestalt  ,   89  
</p>
<p> fi gure/ground distinction  ,   90&ndash;92  
</p>
<p> laws  ,   92  
</p>
<p> perceptual grouping  ,   92&ndash;93   
</p>
<p>  Gibson&rsquo;s perspective  ,   114&ndash;115   
</p>
<p>  Glaucoma  ,   65   
</p>
<p>  Good continuation  ,   93     
</p>
<p> H 
</p>
<p>  Hallucinations  ,   115   
</p>
<p>  Head transfer function  ,   41   
</p>
<p>  Hearing 
</p>
<p> central mechanisms  ,   28  
</p>
<p> clinical aspects  ,   32&ndash;33  
</p>
<p> cochlea  ,   27&ndash;28  
</p>
<p> complex sound wave  ,   20&ndash;22  
</p>
<p> gap transfer  ,   36&ndash;39  
</p>
<p> illusion of continuity  ,   36&ndash;39  
</p>
<p> music 
</p>
<p> subjective experience  ,   45&ndash;46  
</p>
<p> technical description  ,   43&ndash;45  
</p>
<p> outer, middle, and inner ear  ,   25&ndash;26  
</p>
<p> sound wave    (see  Sound wave )  
</p>
<p> speech 
</p>
<p> intermodality  ,   49&ndash;50  
</p>
<p> linguistic description  ,   46&ndash;47  
</p>
<p> technical analysis  ,   48&ndash;49  
</p>
<p> theoretical perspectives  ,   49&ndash;50  
</p>
<p> streaming  ,   36  
</p>
<p> theory 
</p>
<p> frequency  ,   29&ndash;30  
</p>
<p> location  ,   30&ndash;31   
</p>
<p>  Hering, Ewald  ,   74   ,   75     
</p>
<p>  Holway  ,   113   ,   114   
</p>
<p>  Horizontal-vertical illusion  ,   120   
</p>
<p>  Hydrodynamic movement  ,   30   
</p>
<p>  Hypermetropia  ,   63     
</p>
<p> I 
</p>
<p>  Illuminance  ,   68   
</p>
<p>  Illusions 
</p>
<p> classifi cation  ,   115&ndash;118  
</p>
<p> of continuity  ,   36&ndash;39  
</p>
<p> moon  ,   118&ndash;122   
</p>
<p>  Incident light  ,   68   
</p>
<p>  Inclusion  ,   92   
</p>
<p>  Inhibition of return  ,   126   
</p>
<p>  Interaural time difference  ,   40   
</p>
<p>  Internal articulation  ,   92   
</p>
<p>  Interposition  ,   106     
</p>
<p> J 
</p>
<p>  Just noticeable difference (JND)  ,   6     
</p>
<p> L 
</p>
<p>  Lateral geniculate nucleus (LGN)  ,   59    
</p>
<p>  Lateral inhibition  ,   85&ndash;86   
</p>
<p>  Law of closure  ,   93   
</p>
<p>  Law of common fate  ,   93   
</p>
<p>  Law of good form  ,   93   
</p>
<p>  Law of pragnanz  ,   93   
</p>
<p>  Law of proximity  ,   92   
</p>
<p>  Law of similarity  ,   92   
</p>
<p>  Light intensity  ,   68   
</p>
<p>Index</p>
<p/>
</div>
<div class="page"><p/>
<p>155
</p>
<p>  Linear perspective  ,   106   
</p>
<p>  Luminance  ,   68     
</p>
<p> M 
</p>
<p>  Mach bands  ,   86&ndash;88    
</p>
<p>  Magnitude estimation  ,   14   
</p>
<p>  McCollough effect  ,   79    
</p>
<p>  Metathetic continuum  ,   16   
</p>
<p>  Mondegreen  ,   51   
</p>
<p>  Monochromatism  ,   81   
</p>
<p>  Morphemes  ,   47   
</p>
<p>  Motion parallax  ,   109   
</p>
<p>  M&uuml;ller-Lyer illusion  ,   116   ,   117    
</p>
<p>  Multiple spatial channels theory 
</p>
<p> concepts  ,   93&ndash;96  
</p>
<p> CSF  ,   97&ndash;98   
</p>
<p>  Myopia  ,   63     
</p>
<p> N 
</p>
<p>  Nonspectral colors  ,   74   
</p>
<p>  Nystagmus  ,   65     
</p>
<p> O 
</p>
<p>  Occlusion  ,   106   
</p>
<p>  Oppel-Kundt illusion  ,   120   
</p>
<p>  Optic chiasm  ,   63   
</p>
<p>  Organ of Corti  ,   27   
</p>
<p>  Orientation  ,   94     
</p>
<p> P 
</p>
<p>  Pandemonium theory  ,   99   
</p>
<p>  Parameter estimation by sequential testing 
</p>
<p>(PEST)  ,   13   
</p>
<p>  Parvotemporal pathway  ,   62   
</p>
<p>  Perception  ,   124   ,   128  
</p>
<p> attention process    (see  Attention process )  
</p>
<p> clinical aspects  ,   135  
</p>
<p> selectivity    (see  Selectivity )  
</p>
<p> spatial preparation  ,   125&ndash;127  
</p>
<p> temporal preparation  ,   127&ndash;128  
</p>
<p> visual search  ,   133&ndash;134   
</p>
<p>  Perceptive deafness  ,   32   
</p>
<p>  Perfect pitch  ,   46   
</p>
<p>  Phase difference  ,   40   
</p>
<p>  Phase locking  ,   29   
</p>
<p>  Phonemes  ,   46   ,   47   
</p>
<p>  Photosensitive pigments  ,   56   
</p>
<p>  Point of subjective equality (PSE)  ,   6   
</p>
<p>  Ponzo illusion  ,   117   ,   118   
</p>
<p>  Presbycusis  ,   32   
</p>
<p>  Presbyopia  ,   63   
</p>
<p>  Prosopagnosia  ,   101   
</p>
<p>  Prothetic continuum  ,   15   
</p>
<p>  Psychometric function  ,   3   
</p>
<p>  Psychophysical law  ,   14   
</p>
<p>  Psychophysics 
</p>
<p> detection  ,   1&ndash;2  
</p>
<p> absolute threshold and constant stimuli  , 
</p>
<p>  2&ndash;3  
</p>
<p> SDT    (see  Signal detection theory (SDT) )  
</p>
<p> discrimination 
</p>
<p> difference threshold and constant 
</p>
<p>stimuli  ,   6&ndash;8  
</p>
<p> Weber&rsquo;s law  ,   8&ndash;9  
</p>
<p> methods for thresholds 
</p>
<p> adaptive methods  ,   12&ndash;13  
</p>
<p> method of adjustment  ,   9&ndash;10  
</p>
<p> method of limits  ,   10&ndash;12  
</p>
<p> scaling  ,   13&ndash;15      
</p>
<p> R 
</p>
<p>  Receptive fi elds  ,   57&ndash;59   
</p>
<p>  Relative brightness  ,   108   
</p>
<p>  Relative height  ,   107   
</p>
<p>  Relative sharpness  ,   109   
</p>
<p>  Retina  ,   55&ndash;57   
</p>
<p>  Retinal disparity  ,   105     
</p>
<p> S 
</p>
<p>  Sander&rsquo;s illusion  ,   116   
</p>
<p>  Sclera  ,   54   
</p>
<p>  Scotoma  ,   65   
</p>
<p>  Selectivity 
</p>
<p> auditory  ,   130&ndash;133  
</p>
<p> visual  ,   128&ndash;130   
</p>
<p>  Sensorineural deafness  ,   32   
</p>
<p>  Shape constancy  ,   111   
</p>
<p>  Shepard&rsquo;s auditory illusion  ,   40   
</p>
<p>  Signal detection theory (SDT) 
</p>
<p> concepts  ,   3&ndash;5  
</p>
<p> units of measurement  ,   5&ndash;6   
</p>
<p>  Simultaneous contrast  ,   77   
</p>
<p>  Size constancy  ,   111   
</p>
<p>  Size-distance invariance principle  ,   112   
</p>
<p>  Sound pressure level (SPL)  ,   19   
</p>
<p>  Sound wave 
</p>
<p> amplitude  ,   19&ndash;20  
</p>
<p> frequency and phase  ,   17&ndash;19  
</p>
<p> location of direction  ,   40&ndash;41  
</p>
<p> location of distance  ,   41&ndash;42  
</p>
<p> subjective characteristics  ,   23&ndash;24    
</p>
<p>  Spatial frequency  ,   94   
</p>
<p>Index</p>
<p/>
</div>
<div class="page"><p/>
<p>156
</p>
<p>  Spatial preparation  ,   125&ndash;127   
</p>
<p>  Speed constancy  ,   111   
</p>
<p>  Sperling, George  ,   129     
</p>
<p>  Stevens&rsquo;s law  ,   14&ndash;15    
</p>
<p>  Stimulus onset asynchrony (SOA)  ,   126   
</p>
<p>  Strabismus  ,   65   
</p>
<p>  Stroop effect  ,   132    
</p>
<p>  Structural model  ,   100&ndash;101   
</p>
<p>  Surroundedness  ,   92     
</p>
<p> T 
</p>
<p>  Tectopulvinar pathway  ,   62   
</p>
<p>  Template matching model  ,   99   
</p>
<p>  Temporal preparation  ,   127&ndash;128   
</p>
<p>  Titchener illusions  ,   120   
</p>
<p>  Trichromatic theory  ,   74&ndash;76     
</p>
<p>  Trichromatism  ,   80     
</p>
<p> U 
</p>
<p>  Unconscious inference  ,   112   
</p>
<p>  Uncrossed disparity  ,   105     
</p>
<p> V 
</p>
<p>  Ventral pathway  ,   62   
</p>
<p>  Ventriloquism  ,   42   
</p>
<p>  Visual perception 
</p>
<p> clinical aspects  ,   63&ndash;65  
</p>
<p> eyeball  ,   53&ndash;55  
</p>
<p> receptive fi elds  ,   57&ndash;59  
</p>
<p> retina  ,   55&ndash;57  
</p>
<p> visual cortex  ,   60&ndash;61  
</p>
<p> visual pathways  ,   61&ndash;63   
</p>
<p>  Visual search  ,   133&ndash;134   
</p>
<p>  Visual selectivity  ,   128&ndash;130   
</p>
<p>  Vitreous humor  ,   54   
</p>
<p>  Voice onset time  ,   50   
</p>
<p>  Volley principle  ,   29   ,   30     
</p>
<p> W 
</p>
<p>  Weber&rsquo;s law  ,   8&ndash;9     
</p>
<p> Y 
</p>
<p>  Young-Helmholtz  ,   74   ,   75         
</p>
<p>Index</p>
<p/>
</div>
<ul>	<li>Preface</li>
	<li>Contents</li>
	<li>About the Author</li>
	<li>Chapter 1: Psychophysics</li>
<ul>	<li>1.1 Detection</li>
<ul>	<li>1.1.1 Absolute Threshold and&nbsp;Method of&nbsp;Constant Stimuli</li>
	<li>1.1.2 Signal Detection Theory</li>
<ul>	<li>1.1.2.1 Basic Concepts</li>
	<li>1.1.2.2 Units of&nbsp;Measurement</li>
</ul>
</ul>
	<li>1.2 Discrimination</li>
<ul>	<li>1.2.1 Difference Threshold and&nbsp;Method of&nbsp;Constant Stimuli</li>
	<li>1.2.2 Weber&rsquo;s Law of&nbsp;Discrimination and&nbsp;Its Generalized Form</li>
</ul>
	<li>1.3 Other Methods for&nbsp;Estimating Thresholds</li>
<ul>	<li>1.3.1 The Method of&nbsp;Adjustment</li>
	<li>1.3.2 The Method of&nbsp;Limits</li>
	<li>1.3.3 Adaptive Methods</li>
</ul>
	<li>1.4 Scaling</li>
<ul>	<li>1.4.1 Methods</li>
	<li>1.4.2 Stevens&rsquo;s Law</li>
	<li>1.4.3 Other Contributions from&nbsp;Stevens</li>
</ul>
</ul>
	<li>Chapter 2: Physical and&nbsp;Biological Bases of&nbsp;Hearing</li>
<ul>	<li>2.1 Physical Characteristics of&nbsp;a&nbsp;Simple Sound Wave</li>
<ul>	<li>2.1.1 Frequency and&nbsp;Phase</li>
	<li>2.1.2 Amplitude</li>
</ul>
	<li>2.2 Physical Characteristics of&nbsp;a&nbsp;Complex Sound Wave</li>
	<li>2.3 Subjective Characteristics of&nbsp;Sounds</li>
<ul>	<li>2.3.1 Pitch, Loudness, and&nbsp;Timbre</li>
	<li>2.3.2 Other Subjective Characteristics</li>
</ul>
	<li>2.4 Biological Bases</li>
<ul>	<li>2.4.1 Outer, Middle, and&nbsp;Inner Ear</li>
	<li>2.4.2 The Cochlea</li>
	<li>2.4.3 Central Mechanisms</li>
</ul>
	<li>2.5 Theories of&nbsp;Hearing</li>
<ul>	<li>2.5.1 Frequency Theory</li>
	<li>2.5.2 Theories Based on&nbsp;Location</li>
</ul>
	<li>2.6 Clinical Aspects</li>
</ul>
	<li>Chapter 3: Hearing</li>
<ul>	<li>3.1 Perceptual Organization</li>
<ul>	<li>3.1.1 Streaming</li>
	<li>3.1.2 Illusion of&nbsp;Continuity and&nbsp;Gap Transfer</li>
</ul>
	<li>3.2 Sound Location</li>
<ul>	<li>3.2.1 Location of&nbsp;Direction</li>
	<li>3.2.2 Location of&nbsp;Distance</li>
</ul>
	<li>3.3 Hearing Music</li>
<ul>	<li>3.3.1 Technical Description</li>
	<li>3.3.2 Subjective Experience</li>
</ul>
	<li>3.4 Hearing Speech</li>
<ul>	<li>3.4.1 Linguistic Description</li>
	<li>3.4.2 Technical Analysis</li>
	<li>3.4.3 Theoretical Perspectives</li>
	<li>3.4.4 Intermodality</li>
</ul>
</ul>
	<li>Chapter 4: Biological Bases of&nbsp;Visual Perception</li>
<ul>	<li>4.1 The Eye</li>
<ul>	<li>4.1.1 The Eyeball</li>
	<li>4.1.2 The Retina</li>
</ul>
	<li>4.2 Receptive Fields</li>
	<li>4.3 Central Mechanisms</li>
<ul>	<li>4.3.1 The Visual Cortex</li>
	<li>4.3.2 Visual Pathways</li>
</ul>
	<li>4.4 Clinical Aspects</li>
</ul>
	<li>Chapter 5: Color Perception</li>
<ul>	<li>5.1 Description of&nbsp;Light</li>
<ul>	<li>5.1.1 Intensity</li>
	<li>5.1.2 Wavelength and&nbsp;Spectral Composition</li>
</ul>
	<li>5.2 Perceptual Dimensions of&nbsp;Color</li>
	<li>5.3 Color Mixtures</li>
<ul>	<li>5.3.1 Primary Colors</li>
	<li>5.3.2 Addition and&nbsp;Subtraction</li>
</ul>
	<li>5.4 Theories of&nbsp;Color Vision</li>
	<li>5.5 Chromatic Effects</li>
	<li>5.6 Clinical Aspects</li>
</ul>
	<li>Chapter 6: Form Perception</li>
<ul>	<li>6.1 Perception of&nbsp;Contours</li>
<ul>	<li>6.1.1 Edges and&nbsp;Subjective Contours</li>
	<li>6.1.2 Lateral Inhibition</li>
	<li>6.1.3 Mach Bands</li>
	<li>6.1.4 Factors Influencing the&nbsp;Perception of&nbsp;Contours</li>
</ul>
	<li>6.2 Gestalt: Perceptual Organization</li>
<ul>	<li>6.2.1 Figure/Ground Distinction</li>
	<li>6.2.2 Perceptual Grouping</li>
</ul>
	<li>6.3 Theory of&nbsp;Multiple Spatial Channels</li>
<ul>	<li>6.3.1 Basic Concepts</li>
	<li>6.3.2 Contrast Sensitivity Function</li>
</ul>
	<li>6.4 Form Recognition</li>
<ul>	<li>6.4.1 Templates or Characteristics?</li>
	<li>6.4.2 A Computational Approach</li>
	<li>6.4.3 A Structural Model</li>
	<li>6.4.4 Agnosia</li>
</ul>
</ul>
	<li>Chapter 7: Depth Perception</li>
<ul>	<li>7.1 Cues for&nbsp;Perceiving a&nbsp;Third Dimension</li>
<ul>	<li>7.1.1 Binocular Cues</li>
<ul>	<li>7.1.1.1 Binocular Convergence</li>
	<li>7.1.1.2 Retinal Disparity</li>
</ul>
	<li>7.1.2 Monocular Cues</li>
</ul>
	<li>7.2 Perceptual Constancy</li>
<ul>	<li>7.2.1 Types of Constancy</li>
	<li>7.2.2 Interpretations and&nbsp;Investigations</li>
	<li>7.2.3 Gibson&rsquo;s Perspective</li>
</ul>
	<li>7.3 Illusions</li>
<ul>	<li>7.3.1 Variety of&nbsp;Illusions</li>
	<li>7.3.2 The Moon Illusion</li>
</ul>
</ul>
	<li>Chapter 8: Perception and&nbsp;Attention</li>
<ul>	<li>8.1 What Is Attention?</li>
<ul>	<li>8.1.1 Blindnesses</li>
</ul>
	<li>8.2 Preparation and&nbsp;Orientation</li>
<ul>	<li>8.2.1 Spatial Preparation</li>
	<li>8.2.2 Temporal Preparation</li>
</ul>
	<li>8.3 Selectivity</li>
<ul>	<li>8.3.1 Visual Selectivity</li>
	<li>8.3.2 Auditory Selectivity</li>
</ul>
	<li>8.4 Visual Search</li>
	<li>8.5 Clinical Aspects</li>
</ul>
	<li>Appendix A: ROC Curves</li>
	<li>Appendix B: Fechner&rsquo;s Law&#13;</li>
	<li>Appendix C: The Nervous System&#13;</li>
<ul>	<li>C.1 Nerves</li>
	<li>C.2 Central Nervous System&#13;</li>
<ul>	<li>C.2.1 Major Divisions&#13;</li>
	<li>C.2.2 Cerebral Cortex&#13;</li>
	<li>C.2.3 The Spinal Cord and Sensory Pathways&#13;</li>
</ul>
	<li>C.3 Methods for&nbsp;Studying Brain</li>
</ul>
	<li>References</li>
	<li>Index</li>
</ul>
</body></html>