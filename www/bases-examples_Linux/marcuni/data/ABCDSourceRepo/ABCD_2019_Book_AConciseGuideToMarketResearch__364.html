<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>A Concise Guide to Market ResearchA Concise Guide to Market Research</title>
</head>
<body><div class="page"><p/>
</div>
<div class="page"><p/>
<p>Springer Texts in Business and Economics</p>
<p/>
</div>
<div class="page"><p/>
<p>More information about this series at http://www.springer.com/series/10099
</p>
<p>Springer Texts in Business and Economics (STBE) delivers high-quality instruc-
tional content for undergraduates and graduates in all areas of Business/Man-
agement Science and Economics. The series is comprised of self-contained books 
with a broad and comprehensive coverage that are suitable for class as well as for 
individual self-study. All texts are authored by established experts in their fields 
and offer a solid methodological background, often accompanied by problems 
and exercises.</p>
<p/>
<div class="annotation"><a href="http://www.springer.com/series/10099">http://www.springer.com/series/10099</a></div>
</div>
<div class="page"><p/>
<p>Marko Sarstedt
</p>
<p>Erik Mooi
</p>
<p>A Concise Guide to 
Market Research
The Process, Data, and Methods  
</p>
<p>Using IBM SPSS Statistics
</p>
<p>Third Edition</p>
<p/>
</div>
<div class="page"><p/>
<p>Marko Sarstedt
Faculty of Economics and Management
Otto-von-Guericke- University  
Magdeburg
Magdeburg
Germany
</p>
<p>Erik Mooi
Department of Management and  
Marketing
The University of Melbourne
Parkville
Australia
</p>
<p>ISSN 2192-4333    ISSN 2192-4341 (electronic)
Springer Texts in Business and Economics
ISBN 978-3-662-56706-7    ISBN 978-3-662-56707-4 (ebook)
https://doi.org/10.1007/978-3-662-56707-4
</p>
<p>Library of Congress Control Number: 2018940160
</p>
<p>&copy; Springer-Verlag GmbH Germany, part of Springer Nature 2011, 2014, 2019
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole 
or part of the material is concerned, specifically the rights of translation, reprinting, reuse of 
illustrations, recitation, broadcasting, reproduction on microfilms or in any other physical 
way, and transmission or information storage and retrieval, electronic adaptation, computer 
software, or by similar or dissimilar methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this 
publication does not imply, even in the absence of a specific statement, that such names are 
exempt from the relevant protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and informa-
tion in this book are believed to be true and accurate at the date of publication. Neither the 
publisher nor the authors or the editors give a warranty, express or implied, with respect to 
the material contained herein or for any errors or omissions that may have been made. The 
publisher remains neutral with regard to jurisdictional claims in published maps and institu-
tional affiliations.
</p>
<p>Printed on acid-free paper
</p>
<p>This Springer imprint is published by the registered company Springer-Verlag GmbH, DE part 
of Springer Nature.
The registered company address is: Heidelberger Platz 3, 14197 Berlin, Germany
</p>
<p>Electronic supplementary material
The online version of this book contains supplementary material that is available 
to authorized users. You can also download the &ldquo;Springer Nature More Media App&rdquo; 
from the iOS or Android App Store to stream the videos and scan the image con-
taining the &ldquo;Play button&rdquo;.</p>
<p/>
</div>
<div class="page"><p/>
<p>v
</p>
<p>To Alexandra, Charlotte, Maximilian, and Johannes
</p>
<p>&ndash; Marko Sarstedt &ndash;
</p>
<p>To Irma
</p>
<p>&ndash; Erik Mooi &ndash;</p>
<p/>
</div>
<div class="page"><p/>
<p>vii
</p>
<p>About this Book
</p>
<p>In the digital economy, data have become a valuable commodity, much in the 
way that oil is in the rest of the economy (Wedel and Kannan 2016). Data enable 
market researchers to obtain valuable and novel insights. There are many new 
sources of data, such as web traffic, social networks, sensors that track suppliers, 
customers and shipments, online surveys, and others. A Forbes (2015a) survey 
of senior executives reveals that 96&nbsp;% of the respondents consider data-driven 
marketing crucial to success. Not surprisingly, data are valuable to companies 
who spend over $44 billion a year on obtaining insights (Statista.com 2017). So 
valuable are these insights that companies go to great lengths to conceal the find-
ings. Apple, for example, is known to carefully hide that it conducts a great deal 
of research, as the insights from this enable the company to gain a competitive 
advantage (Heisler 2012).
</p>
<p>This book is about being able to supply such insights. It is a valuable skill for which 
there are abundant jobs. Forbes (2015b) shows that IBM, Cisco, and Oracle alone 
have more than 25,000 unfilled data analysis positions. Davenport and Patil (2012) 
label data scientists The Sexiest Job of the 21st Century.
</p>
<p>This book introduces market research, using commonly used quantitative tech-
niques such as regression analysis, factor analysis, and cluster analysis. These sta-
tistical methods have generated findings that have significantly shaped the way 
we see the world today. If you search for market(ing) research books on Google 
or Amazon, you will find that there is no shortage of such books. However, this 
book differs in many important ways:
</p>
<p> 4 This book is a bridge between the theory of conducting quantitative 
research and its execution, using the market research process as a 
framework. We discuss market research, starting off by identifying the 
research question, designing the data collection process, collecting, and 
describing data. We also introduce essential data analysis techniques and 
the basics of communicating the results, including a discussion on ethics. 
Each chapter on quantitative methods describes key theoretical choices and 
how these are executed in SPSS. Unlike most other books, we do not discuss 
theory or application, but link the two.
 4 This is a book for non-technical readers! All chapters are written in an 
</p>
<p>accessible and comprehensive way so that readers without a profound 
background in statistics can also understand the introduced data analysis 
methods. Each chapter on research methods includes examples to help the 
reader gain a hands-on feeling for the technique. Each chapter concludes 
with an illustrated case that demonstrates the application of a quantitative 
method.
 4 To facilitate learning, we use a single case study throughout the book. 
</p>
<p>This case deals with a customer survey of a fictitious company called 
Oddjob Airways (familiar to those who have seen the James Bond movie </p>
<p/>
</div>
<div class="page"><p/>
<p>viii About this Book
</p>
<p>Goldfinger). We also provide additional end-of-chapter cases, including 
different datasets, thus allowing the readers to practice what they have 
learnt. Other pedagogical features, such as keywords, examples, and 
end-of-chapter questions, support the contents.
 4 This book is concise, focusing on the most important aspects that a market 
</p>
<p>researcher, or manager interpreting market research, should know.
 4 Many chapters provide links to videos, further readings, and other websites. 
</p>
<p>We also include a comprehensive Web Appendix with information on 
additional analysis techniques and datasets.
 4 The book makes use of the Springer Nature More Media App (http://www.
</p>
<p>springer.com/gp/marketing/springer-multimedia-app), which allows you to scan 
an image tagged with the Play Button and stream videos directly to your 
mobile device. The App allows saving the documents on your device and 
keeps track of your 50&nbsp;most recently accessed media. This unique merger 
of offline and online content offers readers a broad spectrum of additional 
and readily accessible information. You can download the Springer Nature 
More Media App from the Apple App Store or from Google Play.
 4 Lastly, we have set up a Facebook page called Market Research: The Process, 
</p>
<p>Data, and Methods. This page provides a platform for discussions and the 
exchange of market research ideas.
</p>
<p>z How to Use this Book
The following will help you read this book:
 4 Variable and file names in the main text appear in italics to distinguish them 
</p>
<p>from the descriptions.
 4 Items from SPSS&rsquo;s interface are shown in bold, with successive menu 
</p>
<p>options separated. For example, the text could read: &ldquo;Go to ► Analyze  
► Descriptive Statistics ► Frequencies and enter the variables s1, s2, and s3 
into the Variable(s) box.&rdquo; This means that the word Variable(s) appears in the 
SPSS interface.
 4 Keywords also appear in bold when they first appear in the main text. We 
</p>
<p>have used many keywords to help you find everything quickly and define 
them in the glossary at the end of the book. Secondary keywords that are 
only in the index list appear in italics.
 4 If you see &ldquo;► Web Appendix &rarr; Downloads&rdquo; in the book, please go to  
</p>
<p>https://www.guide-market-research.com and click on Downloads.
 4 All chapters include different types of boxes and text elements that highlight 
</p>
<p>important aspects, contain tips (e.g., on using SPSS more efficiently), or 
offer further information for the interested reader.</p>
<p/>
<div class="annotation"><a href="http://www.springer.com/gp/marketing/springer-multimedia-app">http://www.springer.com/gp/marketing/springer-multimedia-app</a></div>
<div class="annotation"><a href="http://www.springer.com/gp/marketing/springer-multimedia-app">http://www.springer.com/gp/marketing/springer-multimedia-app</a></div>
<div class="annotation"><a href="https://www.guide-market-research.com">https://www.guide-market-research.com</a></div>
</div>
<div class="page"><p/>
<p>About this Book
</p>
<p>ix
</p>
<p>z For Instructors
Besides the benefits described above, this book is also designed to make teach-
ing as easy as possible when using this book. Each chapter comes with a set of 
detailed and professionally designed PowerPoint slides for educators, tailored for 
this book, which can be easily adapted to fit a specific course&rsquo;s needs. These are 
available on the website&rsquo;s instructor resources page at http://www.guide-market- 
research.com. You can gain access to the instructor&rsquo;s page by requesting login infor-
mation under Instructor Resources.
</p>
<p>Magdeburg, Germany
</p>
<p>Parkville, VIC, Australia
</p>
<p>Marko Sarstedt
</p>
<p>Erik A. Mooi
</p>
<p>The book&rsquo;s web appendices are freely available on the accompanying website 
and provide supplementary information on analysis techniques not covered in 
the book and datasets. Moreover, at the end of each chapter, there is a set of ques-
tions that can be used for in-class discussions.
</p>
<p>We also designed a separate website at http://www.oddjobairways.com, which 
includes background information on the company and videos for teaching and 
learning (e.g., on experiments and different interviews techniques). We plan on 
further extending the website, so visit the site regularly.
</p>
<p>If you have any remarks, suggestions, or ideas about this book, please drop us 
a line at erik.mooi@unimelb.edu.au (Erik Mooi) or at marko.sarstedt@ovgu.de 
(Marko Sarstedt). We appreciate any feedback on the book&rsquo;s concept and contents!</p>
<p/>
<div class="annotation"><a href="http://www.guide-market-research.com">http://www.guide-market-research.com</a></div>
<div class="annotation"><a href="http://www.guide-market-research.com">http://www.guide-market-research.com</a></div>
<div class="annotation"><a href="http://www.oddjobairways.com">http://www.oddjobairways.com</a></div>
</div>
<div class="page"><p/>
<p>xi
</p>
<p>What&rsquo;s New in the Third Edition?
</p>
<p>We&rsquo;ve revised the third edition thoroughly. Some of the major changes compared 
to the second edition are:
</p>
<p> 4 The third edition comes in a new design template, which allowed us to 
implement further pedagogical elements, such as excurses, tips, case 
studies, and review questions. We also organized chapters in a more reader-
friendly way, with more sections to facilitate navigation.
 4 Learning market research vocabulary is essential for understanding the 
</p>
<p>topic. We therefore added a glossary in which we define each keyword. 
Descriptions offer further information on selected topics.
 4 To facilitate learning, the third edition uses a single case study throughout 
</p>
<p>the book. This case deals with a customer survey of a fictitious company 
called Oddjob Airways. All illustrations of statistical methods draw on 
this one example. We also designed a separate website at http://www.
oddjobairways.com, which includes background information on the 
company and videos for teaching and learning.
 4 We fully revised the sections on survey design, which now covers the latest 
</p>
<p>research on survey administration (e.g., smartphones and tablets), item 
generation (e.g., item content and wording), and the properties of different 
scale types.
 4 The third edition contains substantial new material to reflect the latest 
</p>
<p>research on each topic. There is additional content in the context of 
regression analysis (e.g., model selection via information criteria), factor 
analysis (e.g., further details on the similarities and differences between 
principal component analysis and principal axis factoring), cluster analysis 
(e.g., sample size recommendations), results communication (e.g., how to 
present statistical data), and many more.
 4 All the examples have been updated and now use SPSS 25. All the material 
</p>
<p>reflects this new version of the program.</p>
<p/>
<div class="annotation"><a href="http://www.oddjobairways.com">http://www.oddjobairways.com</a></div>
<div class="annotation"><a href="http://www.oddjobairways.com">http://www.oddjobairways.com</a></div>
</div>
<div class="page"><p/>
<p>Acknowledgments
</p>
<p>Thanks to all the students who have inspired us with their feedback and con-
stantly reinforce our choice to stay in academia. We have many people to thank 
for making this book possible. First, we would like to thank Springer, and partic-
ularly Barbara Fess and Ruth Milewski for all their help and for their willingness 
to publish this book. Ilse Evertse has done a wonderful job (again!) proofreading 
the chapters. She is a great proofreader and we cannot recommend her enough! 
Drop her a line atstpubus@gmail.com if you need proofreading help. In addition, 
we would like to thank the team of current and former doctoral students and 
research fellows at the Otto-von-Guericke-University, namely Kati Barth, Janine 
Dankert, Frauke K&uuml;hn, Sebastian Lehmann, Marcel Lichters, Doreen Neubert, 
Mandy Pick, Victor Schliwa, and Fiorella Vera. Finally, we would like to acknowl-
edge the many insights and suggestions provided by many our colleagues and stu-
dents. We would like to thank the following:
</p>
<p>Ralf Aigner of Wishbird, Mexico City, Mexico
Carolin Bock of Technische Universit&auml;t Darmstadt, Darmstadt, Germany
Cees J. P. M. de Bont of Hong Kong Polytechnic, Hung Hom, Hong Kong
Bernd Erichson of Otto-von-Guericke-Universit&auml;t Magdeburg, Magdeburg, 
Germany
Andrew M. Farrell of Southhampton University, Southampton, UK
Sebastian Fuchs of BMW Group, M&uuml;nchen, Germany
David I. Gilliland of Colorado State University, Fort Collins, CO, USA
Joe F. Hair Jr. of University of South Alabama, Mobile, AL, USA
J&ouml;rg Henseler of University of Twente, Enschede, The Netherlands
Alok Kumar of University of Nebraska&ndash;Lincoln, Lincoln, NE, USA
Emile F. J. Lanc&eacute;e of Vrije Universiteit Amsterdam, Amsterdam, The Netherlands
Peter S.H. Leeflang of University of Groningen, Groningen, The Netherlands
Tim F. Liao of University of Illinois Urbana-Champaign, USA
Marcel Lichters of Otto-von-Guericke-Universit&auml;t Magdeburg, Magdeburg, 
Germany
Arjen van Lin of Vrije Universiteit Amsterdam, Amsterdam, The Netherlands
Leonard J. Paas of Massey University, Albany, New Zealand
Sascha Raithel of FU Berlin, Berlin, Germany
Edward E. Rigdon of Georgia State University, Atlanta, GA, USA
Christian M. Ringle of Technische Universit&auml;t Hamburg-Harburg, Hamburg, 
Germany
John Rudd of Warwick University, Coventry, UK
Sebastian Scharf of Campus M21, M&uuml;nchen, Germany
Tobias Sch&uuml;tz of ESB Business School Reutlingen, Reutlingen, Germany
Philip Sugai of International University of Japan, Minami-Uonuma, Niigata, Japan
Charles R. Taylor of Villanova University, Philadelphia, PA, USA
Andr&eacute;s Trujillo-Barrera of Wageningen University &amp; Research
Stefan Wagner of European School of Management and Technology, Berlin, 
Germany</p>
<p/>
</div>
<div class="page"><p/>
<p>Acknowledgments
</p>
<p>xiii
</p>
<p>Eelke Wiersma of Vrije Universiteit Amsterdam, Amsterdam, The Netherlands
Caroline Wiertz of Cass Business School, London, UK
Michael Zyphur of University of Melbourne, Parkville, Australia
</p>
<p>References
</p>
<p>Davenport, T. H., &amp; Patil, D. J. (2012). Data scientist. The sexiest job of the 21st century. Harvard 
</p>
<p>Business Review, 90(October), 70&ndash;76.
</p>
<p>Forbes (2015a). Data driven and customer centric: Marketers turning insights into impact. 
</p>
<p>http://www.forbes.com/forbesinsights/data-driven_and_customer-centric/. Accessed 03 
</p>
<p>May 2018.
</p>
<p>Forbes (2015b). Where big data jobs will be in 2016. http://www.forbes.com/sites/louiscolum-
</p>
<p>bus/2015/11/16/where-big-data-jobs-will-be-in-2016/#68fece3ff7f1/. Accessed 03 May 
</p>
<p>2018.
</p>
<p>Heisler, Y. (2012). How Apple conducts market research and keeps iOS source code locked 
</p>
<p>down. Networkworld. http://www.networkworld.com/article/2222892/wireless/how-ap-
</p>
<p>ple-conducts-market-research-and-keeps-ios-source-code-locked-down.html. Accessed 
</p>
<p>03 May 2018.
</p>
<p>Statista.com. (2017). Market research industry/market &ndash; Statistics &amp; facts. https://www.statista.
</p>
<p>com/topics/1293/market-research/. Accessed 03 May 2018.
</p>
<p>Wedel, M., &amp; Kannan, P. K. (2016). Marketing analytics for data-rich environments. Journal of 
</p>
<p>Marketing, 80(6), 97&ndash;121.</p>
<p/>
<div class="annotation"><a href="http://www.forbes.com/forbesinsights/data-driven_and_customer-centric/">http://www.forbes.com/forbesinsights/data-driven_and_customer-centric/</a></div>
<div class="annotation"><a href="http://www.forbes.com/sites/louiscolumbus/2015/11/16/where-big-data-jobs-will-be-in-2016/#68fece3ff7f1/">http://www.forbes.com/sites/louiscolumbus/2015/11/16/where-big-data-jobs-will-be-in-2016/#68fece3ff7f1/</a></div>
<div class="annotation"><a href="http://www.forbes.com/sites/louiscolumbus/2015/11/16/where-big-data-jobs-will-be-in-2016/#68fece3ff7f1/">http://www.forbes.com/sites/louiscolumbus/2015/11/16/where-big-data-jobs-will-be-in-2016/#68fece3ff7f1/</a></div>
<div class="annotation"><a href="http://www.networkworld.com/article/2222892/wireless/how-apple-conducts-market-research-and-keeps-ios-source-code-locked-down.html">http://www.networkworld.com/article/2222892/wireless/how-apple-conducts-market-research-and-keeps-ios-source-code-locked-down.html</a></div>
<div class="annotation"><a href="http://www.networkworld.com/article/2222892/wireless/how-apple-conducts-market-research-and-keeps-ios-source-code-locked-down.html">http://www.networkworld.com/article/2222892/wireless/how-apple-conducts-market-research-and-keeps-ios-source-code-locked-down.html</a></div>
<div class="annotation"><a href="https://www.statista.com/topics/1293/market-research/">https://www.statista.com/topics/1293/market-research/</a></div>
<div class="annotation"><a href="https://www.statista.com/topics/1293/market-research/">https://www.statista.com/topics/1293/market-research/</a></div>
</div>
<div class="page"><p/>
<p>xv
</p>
<p> 1 Introduction to Market Research  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  1
</p>
<p> 2 The Market Research Process  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  11
</p>
<p> 3 Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  25
</p>
<p> 4 Getting Data  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  47
</p>
<p> 5 Descriptive Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  91
</p>
<p> 6 Hypothesis Testing and ANOVA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   151
</p>
<p> 7 Regression Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   209
</p>
<p> 8 Principal Component and Factor Analysis . . . . . . . . . . . . . . . . . . . . . . . . .   257
</p>
<p> 9 Cluster Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   301
</p>
<p>10 Communicating the Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   355
</p>
<p> Supplementary Information
</p>
<p> Glossary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   378
</p>
<p> Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   392
</p>
<p>Contents</p>
<p/>
</div>
<div class="page"><p/>
<p>Marko Sarstedt
</p>
<p>is chaired professor of Marketing at the Otto-von-Guer-
icke-University Magdeburg (Germany). His main research 
is in the application and advancement of structural equation 
modeling methods to further the understanding of con-
sumer behavior and to improve marketing decision-mak-
ing. His research has been published in journals such as 
Journal of Marketing Research, Journal of the Academy 
of Marketing Science, Organizational Research Methods, 
MIS Quarterly, and International Journal of Research in 
Marketing. Marko has co-edited several special issues of 
leading journals and co-authored several widely adopted 
textbooks, including &ldquo;A Primer on Partial Least Squares 
Structural Equation Modeling (PLS-SEM)&rdquo; (together with 
Joe F. Hair, G. Tomas M. Hult, and Christian M. Ringle).
</p>
<p>Erik Mooi
</p>
<p>Is senior lecturer at the University of Melbourne (Australia). 
His main interest is in business-to-business marketing and 
works on topics such as outsourcing, inter-firm contract-
ing, innovation, technology licensing, and franchising using 
advanced econometrics. His research has been published in 
journals such as Journal of Marketing, the Journal of Mar-
keting Research, the International Journal of Research in 
Marketing, and the Journal of Business Research. He is also 
program director at the Centre for Workplace Leadership, 
a fellow at the EU centre for shared complex challenges, as 
well as a fellow at the Centre for Business Analytics at Mel-
bourne Business School.
</p>
<p>About the Authors</p>
<p/>
</div>
<div class="page"><p/>
</div>
<div class="page"><p/>
<p>1
</p>
<p>Introduction to Market 
Research
</p>
<p>1.1 Introduction &ndash; 2
</p>
<p>1.2 What Is Market and Marketing Research? &ndash; 3
</p>
<p>1.3 Market Research by Practitioners and Academics &ndash; 4
</p>
<p>1.4 When Should Market Research (Not)  
Be Conducted? &ndash; 5
</p>
<p>1.5 Who Provides Market Research? &ndash; 5
</p>
<p>1.6 Review Questions &ndash; 8
</p>
<p> References &ndash; 8
</p>
<p>1
</p>
<p>&copy; Springer-Verlag GmbH Germany, part of Springer Nature 2019 
</p>
<p>M. Sarstedt, E. Mooi, A Concise Guide to Market Research, Springer Texts in Business  
</p>
<p>and Economics, https://doi.org/10.1007/978-3-662-56707-4_1
</p>
<p>Electronic supplementary material
</p>
<p>The online version of this chapter (https://doi.org/10.1007/978-3-662-56707-4_1) contains 
</p>
<p>additional material that is available to authorized users. You can also download the &ldquo;Springer 
</p>
<p>Nature More Media App&rdquo; from the iOS or Android App Store to stream the videos and scan the 
</p>
<p>image containing the &ldquo;Play button&rdquo;.</p>
<p/>
<div class="annotation"><a href="https://crossmark.crossref.org/dialog/?doi=10.1007/978-3-662-56707-4_1&amp;amp;domain=pdf&amp;amp;date_stamp=2018-9-17">https://crossmark.crossref.org/dialog/?doi=10.1007/978-3-662-56707-4_1&amp;amp;domain=pdf&amp;amp;date_stamp=2018-9-17</a></div>
</div>
<div class="page"><p/>
<p>2 Chapter 1 &middot; Introduction to Market Research
</p>
<p>Keywords
</p>
<p>American Marketing Association (AMA) &bull; ESOMAR &bull; Field service firms &bull; Full-service providers &bull; Limited- 
</p>
<p>service providers &bull; Segment specialists &bull; Specialized service firms &bull; Syndicated data
</p>
<p>1.1 Introduction
</p>
<p>When Toyota developed the Prius&mdash;a highly fuel-efficient car using a hybrid petrol/electric 
engine&mdash;it took a gamble on a grand scale. Honda and General Motors&rsquo; previous attempts 
to develop frugal (electric) cars had not worked well. Just like Honda and General Motors, 
Toyota had also been working on developing a frugal car but focused on a system inte-
grating a petrol and electric engine. These development efforts led Toyota to start the G21 
project, which aimed at developing a car with a fuel economy that was at least 50&nbsp;% better 
than similar-sized cars. This project nearly came to a halt in 1995&nbsp;when Toyota encoun-
tered substantial technological problems. The company solved these problems, using nearly 
a thousand engineers, and launched the car, called the Prius, in Japan in 1997. Internal 
Toyota predictions suggested that the car was either going to be an instant hit, or that the 
product&rsquo;s acceptance would be slow, as it takes time to teach dealers and consumers about 
the technology. In 1999, Toyota decided to start working on launching the Prius in the 
US. Initial market research showed that it was going to be a difficult task. Some consumers 
thought it was too small for the US and some thought the positioning of the controls was 
poor for US drivers. There were other issues too, such as the design, which many thought 
was too strongly geared towards Japanese drivers.
</p>
<p>While preparing for the launch, Toyota conducted further market research, which 
could, however, not reveal who the potential car buyers would be. Initially, Toyota thought 
the car might be tempting for people concerned with the environment, but market research 
dispelled this belief. Environmentalists dislike technology in general and money is a big 
issue for this group. A technologically complex and expensive car such as the Prius was 
therefore unlikely to appeal to them. Additional market research did little to identify any 
other good market segment. Despite the lack of conclusive findings, Toyota decided to sell 
the car anyway and to await the public&rsquo;s reaction. Before the launch, Toyota put a market 
research system in place to track the initial sales and identify where customers bought 
the car. After the formal launch in 2000, this system quickly found that celebrities were 
buying the car to demonstrate their concern for the environment. Somewhat later, Toyota 
noticed substantially increased sales figures when ordinary consumers became aware of 
</p>
<p>Learning Objectives
After reading this chapter, you should understand:
</p>
<p> 5 What market and marketing research are and how they differ.
 5 How practitioner and academic market(ing) research differ.
 5 When market research should be conducted.
 5 Who provides market research and the importance of the market research industry.
</p>
<p>1</p>
<p/>
</div>
<div class="page"><p/>
<p>13
1.2 &middot; What Is Market and Marketing Research?
</p>
<p>the car&rsquo;s appeal to celebrities. It appeared that consumers were willing to purchase cars 
that celebrities endorse.
</p>
<p>CNW Market Research, a market research company specializing in the automotive 
industry, attributed part of the Prius&rsquo;s success to its unique design, which clearly demon-
strated that Prius owners were driving a different car. After substantial increases in the 
petrol price and changes to the car (based on extensive market research) to increase its 
appeal, Toyota&rsquo;s total Prius sales reached about four million and the company is now the 
market leader in hybrid petrol/electric cars.
</p>
<p>This example shows that while market research occasionally helps, sometimes it con-
tributes little, or even fails. There are many reasons for market research&rsquo;s success varying. 
These reasons include the budget available for research, the support for market research 
in the organization, the implementation, and the market researchers&rsquo; research skills. In 
this book, we will guide you step by step through the practicalities of the basic market 
research process. These discussions, explanations, facts, and methods will help you carry 
out successful market research.
</p>
<p>1.2 What Is Market and Marketing Research?
</p>
<p>Market research can mean several things. It can be the process by which we gain insight 
into how markets work. Market research is also a function in an organization, or it can 
refer to the outcomes of research, such as a database of customer purchases, or a report 
that offers recommendations. In this book, we focus on the market research process, 
starting by identifying and formulating the problem, continuing by determining the 
research design, determining the sample and method of data collection, collecting the 
data, analyzing the data, interpreting, discussing, and presenting the findings, and ending 
with the follow-up.
</p>
<p>Some people consider marketing research and market research to be synonymous, 
whereas others regard these as different concepts. The American Marketing Association 
(AMA), the largest marketing association in North America, defines marketing research 
as follows:
</p>
<p>The function that links the consumer, customer, and public to the marketer through 
</p>
<p>information&mdash;information used to identify and define marketing opportunities and 
</p>
<p>problems; generate, refine, and evaluate marketing actions; monitor marketing 
</p>
<p>performance; and improve understanding of marketing as a process. Marketing  
</p>
<p>research specifies the information required to address these issues, designs the  
</p>
<p>method for collecting information, manages and implements the data collection 
</p>
<p>process, analyzes the results, and communicates the findings and their implications 
</p>
<p>(American Marketing Association 2004).
</p>
<p>On the other hand, ESOMAR, the world organization for market, consumer and societal 
research, defines market research as:</p>
<p/>
</div>
<div class="page"><p/>
<p>4 Chapter 1 &middot; Introduction to Market Research
</p>
<p>Both definitions overlap substantially, but the AMA definition focuses on marketing 
research as a function (e.g., a department in an organization), whereas the ESOMAR 
definition focuses on the process. In this book, we focus on the process and, thus, on 
market research.
</p>
<p>1.3 Market Research by Practitioners and Academics
</p>
<p>Practitioners and academics are both involved in marketing and market research. Aca-
demic and practitioner views of market(ing) research differ in many ways, but also have 
many communalities.
</p>
<p>There is, however, a key difference in their target groups. Academics almost exclusively 
undertake research with the goal of publishing in academic journals. Highly esteemed 
journals include the Journal of Marketing, Journal of Marketing Research, Journal of the 
Academy of Marketing Science, and the International Journal of Research in Marketing. 
Such Journals emphasize methodological rigor and consistency. Academic journals are 
often difficult to read and understand, while practitioner reports should be easy to read. 
Moreover, practitioners&rsquo; target group is the client, whose needs and standards include 
relevance, practicality, generalizability, and timeliness of insights.
</p>
<p>Academics and practitioners differ greatly in their use of and focus on methods. Prac-
titioners have adapted and refined some of the methods, such as cluster analysis and factor 
analysis, which academics developed originally.1 Developing methods is often a goal in 
itself for academics. Practitioners are more concerned about the value of applying specific 
methods. Standards also differ. Clear principles and professional conduct as advocated 
by ESOMAR and the AMSRS (for examples, see https://www.esomar.org/uploads/public/
knowledge-and-standards/codes-and-guidelines/ICCESOMAR-International-Code_English.pdf  
</p>
<p>and https://www.amsrs.com.au/professionalstandards/code-of-professional-behaviour) mostly 
guide practitioners&rsquo; methods. Universities and schools sometimes impose data collec-
tion and analysis standards on academics, but these tend not to have the level of detail 
advocated by ESOMAR or the AMSRS. Interestingly, many practitioners claim that their 
methods meet academic standards, but academics never claim that their methods are 
based on practitioner standards.
</p>
<p>1 Roberts et al. (2014) and Hauser (2017) discuss the impact of marketing science tools on marketing 
</p>
<p>practice.
</p>
<p>The systematic gathering and interpretation of information about individuals and 
</p>
<p>organisations. It uses the statistical and analytical methods and techniques of the 
</p>
<p>applied social, behavioural and data sciences to generate insights and support 
</p>
<p>decision-making by providers of goods and services, governments, non-profit 
</p>
<p>organisations and the general public. (ICC/ESOMAR 2016).
</p>
<p>1</p>
<p/>
<div class="annotation"><a href="https://www.esomar.org/uploads/public/knowledge-and-standards/codes-and-guidelines/ICCESOMAR-International-Code_English.pdf">https://www.esomar.org/uploads/public/knowledge-and-standards/codes-and-guidelines/ICCESOMAR-International-Code_English.pdf</a></div>
<div class="annotation"><a href="https://www.esomar.org/uploads/public/knowledge-and-standards/codes-and-guidelines/ICCESOMAR-International-Code_English.pdf">https://www.esomar.org/uploads/public/knowledge-and-standards/codes-and-guidelines/ICCESOMAR-International-Code_English.pdf</a></div>
<div class="annotation"><a href="https://www.amsrs.com.au/professionalstandards/code-of-professional-behaviour">https://www.amsrs.com.au/professionalstandards/code-of-professional-behaviour</a></div>
</div>
<div class="page"><p/>
<p>15
1.5 &middot; Who Provides Market Research?
</p>
<p>Besides these differences, there are also many similarities. For example, good mea-
surement is paramount for academics and practitioners. Furthermore, academics and 
practitioners should be interested in each other&rsquo;s work; academics can learn much from 
the practical issues that practitioners faced, while practitioners can gain much from 
understanding the tools, techniques, and concepts that academics develop. Reibstein 
et&nbsp;al. (2009), who issued an urgent call for the academic marketing community to focus 
on relevant business problems, underlined the need to learn from each other. Several 
other researchers, such as Lee and Greenley (2010), Homburg et al. (2015), and Tellis 
(2017), have echoed this call.
</p>
<p>1.4 When Should Market Research (Not) Be Conducted?
</p>
<p>Market research serves several useful roles in organizations. Most importantly, market 
research can help organizations by providing answers to questions firms may have about 
their customers and competitors; answers that could help such firms improve their perfor-
mance. Specific questions related to this include identifying market opportunities, mea-
suring customer satisfaction, and assessing market shares. Some of these questions arise ad 
hoc, perhaps due to issues that the top management, or one of the departments or divisions, 
has identified. Much market research is, however, programmatic; it arises because firms 
systematically evaluate market elements. Subway, the restaurant chain, systematically mea-
sures customer satisfaction, which is an example of programmatic research. This type of 
research does not usually have a distinct beginning and end (contrary to ad hoc research), 
but is executed continuously over time and leads to daily, weekly, or monthly reports.
</p>
<p>The decision to conduct market research may be made when managers face an uncer-
tain situation and when the costs of undertaking good research are (much) lower than good 
decisions&rsquo; expected benefits. Researching trivial issues or issues that cannot be changed 
is not helpful.
</p>
<p>Other issues to consider are the politics within the organization because if the decision 
to go ahead has already been made (as in the Prius example in the introduction), market 
research is unnecessary. If market research is conducted and supports the decision, it is 
of little value&mdash;and those undertaking the research may have been biased in favor of the 
decision. On the other hand, market research is ignored if it rejects the decision.
</p>
<p>Moreover, organizations often need to make very quick decisions, for example, when 
responding to competitive price changes, unexpected changes in regulation, or to the eco-
nomic climate. In such situations, however, market research may only be included after 
decisions have already been made. Consequently, research should typically not be under-
taken for urgent decisions.
</p>
<p>1.5 Who Provides Market Research?
</p>
<p>Many organizations have people, departments, or other companies working for them to 
provide market research. In . Fig.&nbsp;1.1, we show who these providers of market research are.
</p>
<p>Most market research is provided internally by specialized market research depart-
ments, or people tasked with this function. It appears that about 75&nbsp;% of organizations have </p>
<p/>
</div>
<div class="page"><p/>
<p>6 Chapter 1 &middot; Introduction to Market Research
</p>
<p>at least one person tasked with carrying out market research. This percentage is similar in 
most industries, although it is much less in government sectors and, particularly, in health 
care (Churchill and Iacobucci 2015).
</p>
<p>In larger organizations, a sub-department of the marketing department usually under-
takes internally provided market research. Sometimes this sub-department is not con-
nected to a marketing department, but to other organizational functions, such as corpo-
rate planning or sales (Rouzi&egrave;s and Hulland 2014). Many large organizations even have a 
separate market research department. This system of having a separate market research 
department, or merging it with other departments, seems to become more widespread, 
with the marketing function devolving increasingly into other functions within organi-
zations (Sheth and Sisodia 2006).
</p>
<p>The external providers of market research are a powerful economic force. In 2015, the 
Top 50 external providers had a collective turnover of about $21.78 billion (Honomichl 
2016). The market research industry has also become a global field with companies such as 
The Nielsen Company (USA), Kantar (UK), GfK (Germany), and Ipsos (France), playing 
major roles outside their home markets. External providers of market research are either 
full-service providers or limited-service providers.
</p>
<p>Full-service providers are large market research companies such as The Nielsen 
Company (http://www.nielsen.com), Kantar (http://www.kantar.com), and GfK (http://
www.gfk.com). These large companies provide syndicated data and customized services. 
 Syndicated data are data collected in a standard format and not specifically collected for 
a single client. These data, or analyses based on the data, are then sold to multiple clients. 
Large marketing research firms mostly collect syndicated data, as they have the resources 
to collect large amounts of data and can spread the costs of doing so over a number of 
clients. For example, The Nielsen Company collects syndicated data in several forms: 
Nielsen&rsquo;s Netratings, which collects information on digital media; Nielsen Ratings, which 
details the type of consumer who listens to the radio, watches TV, or reads print media; 
and Nielsen Homescan, which collects panel information on the purchases consumers 
make. These large firms also offer customized services by conducting studies for a spe-
cific client. These customized services can be very specific, such as helping a client carry 
out specific analyses.
</p>
<p>Providers of
</p>
<p>market research
</p>
<p>Internal External 
</p>
<p>Syndicated data 
</p>
<p>Full service 
</p>
<p>Segment specialists
</p>
<p>Limited service 
</p>
<p>Specialized service Customized services Field service 
</p>
<p>. Fig.&nbsp;1.1 The providers of market research
</p>
<p>1</p>
<p/>
<div class="annotation"><a href="http://www.nielsen.com">http://www.nielsen.com</a></div>
<div class="annotation"><a href="http://www.kantar.com">http://www.kantar.com</a></div>
<div class="annotation"><a href="http://www.gfk.com">http://www.gfk.com</a></div>
<div class="annotation"><a href="http://www.gfk.com">http://www.gfk.com</a></div>
</div>
<div class="page"><p/>
<p>17
1.5 &middot; Who Provides Market Research?
</p>
<p>Contrary to full-service providers, which undertake nearly all market research activities, 
limited-service providers specialize in one or more services and tend to be smaller compa-
nies. In fact, many of the specialized market research companies are one-man businesses 
and the owner&mdash;after (or beside) a practitioner or academic career&mdash;offers specialized ser-
vices. Although there are many different types of limited-service firms, we only discuss 
three of them: those focused on segmentation, field service, and specialized services.
</p>
<p>Segment specialists concentrate on specific market segments. Skytrax (http://www.air-
linequality.com/), which focuses on market research in the airline and airport sector, is an 
example of such specialists. Other segment specialists do not focus on a particular indus-
try, but on a type of customer; for example, Ethnic Focus (http://www.ethnicfocus.com/), a 
UK-based market research firm, focuses on understanding ethnic minorities.
</p>
<p>Field service firms, such as Research Now SSI (http://www.surveysampling.com/), focus 
on executing surveys, determining samples, sample sizes, and collecting data. Some of 
these firms also translate surveys or provide addresses and contact details.
</p>
<p>Nielsen&rsquo;s Total Audience Measurement
</p>
<p>In today&rsquo;s media environment, consumers have endless options for consuming their 
</p>
<p>favorite content, and it's fundamentally changing the business of TV, advertising, and 
</p>
<p>measurement. The need for fair comparisons between digital and TV is greater than 
</p>
<p>ever. Nielsen&rsquo;s Total Audience Measurement provides metrics that enable compara-
</p>
<p>bility between traditional viewing on a television set and media consumption that 
</p>
<p>occurs on other devices and platforms. These metrics allow marketers to compare 
</p>
<p>their options to put their ads in front of the right consumer, on the right platform, at 
</p>
<p>the right time.
</p>
<p>In the following video, Jessica Hogue, Senior Vice President of Product Leadership 
</p>
<p>at Nielsen discusses the company&rsquo;s Total Audience Measurement approach.
</p>
<p>&copy; franckreporter/Getty Images/istock
</p>
<p>https://www.youtube.com/watch?v=KBir1BqeZ6U</p>
<p/>
<div class="annotation"><a href="http://www.airlinequality.com/">http://www.airlinequality.com/</a></div>
<div class="annotation"><a href="http://www.airlinequality.com/">http://www.airlinequality.com/</a></div>
<div class="annotation"><a href="http://www.ethnicfocus.com/">http://www.ethnicfocus.com/</a></div>
<div class="annotation"><a href="http://www.surveysampling.com/">http://www.surveysampling.com/</a></div>
<div class="annotation"><a href="https://www.youtube.com/watch?v=KBir1BqeZ6U">https://www.youtube.com/watch?v=KBir1BqeZ6U</a></div>
</div>
<div class="page"><p/>
<p>8 Chapter 1 &middot; Introduction to Market Research
</p>
<p>Specialized service firms are a catch-all term for those companies with specific techni-
cal skills, thus only focusing on specific products, or aspects of products, such as market 
research on taste and smell. Specialized firms may also concentrate on a few highly spe-
cific market research techniques, or may focus on one or more highly specialized analy-
sis techniques, such as time series analysis, panel data analysis, or quantitative text analy-
sis. Envirosell (http://www.envirosell.com), a research and consultancy firm that analyzes 
consumer behavior in commercial environments, is a well-known example of a special-
ized service firm.
</p>
<p>A choice between these full-service and limited-service market research firms boils 
down to a tradeoff between what they can provide (if this is highly specialized, you may not 
have much choice) and the price of doing so. In addition, if you have to combine several 
studies to gain further insight, full-service firms may be better than multiple limited- 
service firms. The fit and feel with the provider are obviously also highly important!
</p>
<p>1.6 Review Questions
</p>
<p>1. What is market research? Try to explain what market research is in your own words.
2. Imagine you are the head of a division of Procter &amp; Gamble. You are just about ready 
</p>
<p>to launch a new shampoo but are uncertain about who might buy it. Is it useful to 
conduct a market research study? Should you delay the launch of the product?
</p>
<p>3. Please read the press excerpt Taco Bell issued on https://www.tacobell.com/news/
american-consumers-would-rather-pay-less. Do you feel retrospectively that, keeping 
the findings in mind, market research should have been conducted?
</p>
<p>4. Try to find the websites of a few market research firms. Look, for example, at the 
services provided by GfK and the Nielsen Company, and compare the extent of their 
offerings to those of specialized firms such as those listed on, for example,  
http://www.greenbook.org
</p>
<p>5. If you have a specialized research question, such as what market opportunities there 
are for selling music to ethnic minorities, would you use a full-service or limited- 
service firm (or both)? Please discuss the benefits and drawbacks.
</p>
<p>References
</p>
<p>AMA Definition of Marketing. (2004). http://www.Marketingpower.com/AboutAMA/pages/definition-
</p>
<p>ofmarketing.aspx
</p>
<p>Hauser, J. R. (2017). Phenomena, theory, application, data, and methods all have impact. Journal of the 
</p>
<p>Academy of Marketing Science, 45(1), 7&ndash;9.
</p>
<p>Homburg, C., Vomberg, A., Enke, M., &amp; Grimm, P. H. (2015). The loss of the marketing department&rsquo;s influ-
</p>
<p>ence: Is it happening? And why worry? Journal of the Academy of Marketing Science, 43(1), 1&ndash;13.
</p>
<p>Honomichl, J. (2016). 2016&nbsp;Honomichl Gold Top 50. https://www.ama.org/publications/MarketingNews/
</p>
<p>Pages/2016-ama-gold-top-50-report.aspx. Accessed 03 May 2018.
</p>
<p>Iaccobucci, D., &amp; Churchill, G. A. (2015). Marketing research: Methodological foundations (11th ed.). Nash-
</p>
<p>ville, TN: CreateSpace Independent Publishing Platform.
</p>
<p>ICC/ESOMAR (2016). ICC/ESOMAR international code on market, opinion, and social research and data 
</p>
<p>analytics. https://www.esomar.org/uploads/public/knowledge-and-standards/codes-and-guide-
</p>
<p>lines/ICCESOMAR_Code_English_.pdf. Accessed 03 May 2018.
</p>
<p>1</p>
<p/>
<div class="annotation"><a href="http://www.envirosell.com">http://www.envirosell.com</a></div>
<div class="annotation"><a href="https://www.tacobell.com/news/american-consumers-would-rather-pay-less">https://www.tacobell.com/news/american-consumers-would-rather-pay-less</a></div>
<div class="annotation"><a href="https://www.tacobell.com/news/american-consumers-would-rather-pay-less">https://www.tacobell.com/news/american-consumers-would-rather-pay-less</a></div>
<div class="annotation"><a href="http://www.greenbook.org">http://www.greenbook.org</a></div>
<div class="annotation"><a href="http://www.Marketingpower.com/AboutAMA/pages/definitionofmarketing.aspx">http://www.Marketingpower.com/AboutAMA/pages/definitionofmarketing.aspx</a></div>
<div class="annotation"><a href="http://www.Marketingpower.com/AboutAMA/pages/definitionofmarketing.aspx">http://www.Marketingpower.com/AboutAMA/pages/definitionofmarketing.aspx</a></div>
<div class="annotation"><a href="https://www.ama.org/publications/MarketingNews/Pages/2016-ama-gold-top-50-report.aspx">https://www.ama.org/publications/MarketingNews/Pages/2016-ama-gold-top-50-report.aspx</a></div>
<div class="annotation"><a href="https://www.ama.org/publications/MarketingNews/Pages/2016-ama-gold-top-50-report.aspx">https://www.ama.org/publications/MarketingNews/Pages/2016-ama-gold-top-50-report.aspx</a></div>
<div class="annotation"><a href="https://www.esomar.org/uploads/public/knowledge-and-standards/codes-and-guidelines/ICCESOMAR_Code_English_.pdf">https://www.esomar.org/uploads/public/knowledge-and-standards/codes-and-guidelines/ICCESOMAR_Code_English_.pdf</a></div>
<div class="annotation"><a href="https://www.esomar.org/uploads/public/knowledge-and-standards/codes-and-guidelines/ICCESOMAR_Code_English_.pdf">https://www.esomar.org/uploads/public/knowledge-and-standards/codes-and-guidelines/ICCESOMAR_Code_English_.pdf</a></div>
</div>
<div class="page"><p/>
<p>19
References
</p>
<p>Lee, N., &amp; Greenley, G. (2010). The theory-practice divide: Thoughts from the editors and senior advisory 
</p>
<p>board of EJM. European Journal of Marketing, 44(1/2), 5&ndash;20.
</p>
<p>Reibstein, D. J., Day, G., &amp; Wind, J. (2009). Guest editorial: Is marketing academia losing its way? Journal of 
</p>
<p>Marketing, 73(4), 1&ndash;3.
</p>
<p>Roberts, J. H., Kayand, U., &amp; Stremersch, S. (2014). From academic research to marketing practice: Explor-
</p>
<p>ing the marketing science value chain. International Journal of Research in Marketing, 31(2), 128&ndash;140.
</p>
<p>Rouzi&egrave;s, D., &amp; Hulland, J. (2014). Does marketing and sales integration always pay off? Evidence from a 
</p>
<p>social capital perspective. Journal of the Academy of Marketing Science, 42(5), 511&ndash;527.
</p>
<p>Sheth, J. N., Sisodia, R. S. (Eds.). (2006). Does marketing need reform? In J. N. Sheth, &amp; R. S. Sisodia (Eds.), 
</p>
<p>Does marketing need reform? Fresh perspective on the future (pp. 3&ndash;12). Armonk, NY: M.E. Sharpe.
</p>
<p>Tellis, G. J. (2017). Interesting and impactful research: On phenomena, theory, and writing. Journal of the 
</p>
<p>Academy of Marketing Science, 45(1), 1&ndash;6.
</p>
<p>Further Reading
</p>
<p>American Marketing Association at http://www.marketingpower.com
</p>
<p>British Market Research Society at http://www.mrs.org.uk
</p>
<p>ESOMAR at http://www.esomar.org
</p>
<p>GreenBook Directory at http://www.greenbook.org
</p>
<p>Insights Association at http://www.insightsassociation.org/</p>
<p/>
<div class="annotation"><a href="http://www.marketingpower.com">http://www.marketingpower.com</a></div>
<div class="annotation"><a href="http://www.mrs.org.uk">http://www.mrs.org.uk</a></div>
<div class="annotation"><a href="http://www.esomar.org">http://www.esomar.org</a></div>
<div class="annotation"><a href="http://www.greenbook.org">http://www.greenbook.org</a></div>
<div class="annotation"><a href="http://www.insightsassociation.org/">http://www.insightsassociation.org/</a></div>
</div>
<div class="page"><p/>
<p>11
</p>
<p>The Market Research 
Process
</p>
<p>2.1 Introduction &ndash; 12
</p>
<p>2.2 Identify and Formulate the Problem &ndash; 13
</p>
<p>2.3 Determine the Research Design &ndash; 13
2.3.1 Exploratory Research &ndash; 14
</p>
<p>2.3.2 Uses of Exploratory Research &ndash; 15
</p>
<p>2.3.3 Descriptive Research &ndash; 17
</p>
<p>2.3.4 Uses of Descriptive Research &ndash; 17
</p>
<p>2.3.5 Causal Research &ndash; 18
</p>
<p>2.3.6 Uses of Causal Research &ndash; 20
</p>
<p>2.4 Design the Sample and Method of Data  
Collection &ndash; 22
</p>
<p>2.5 Collect the Data &ndash; 22
</p>
<p>2.6 Analyze the Data &ndash; 22
</p>
<p>2.7 Interpret, Discuss, and Present the Findings &ndash; 23
</p>
<p>2.8 Follow-Up &ndash; 23
</p>
<p>2.9 Review Questions &ndash; 23
</p>
<p> References &ndash; 23
</p>
<p>2
</p>
<p>Electronic supplementary material
</p>
<p>The online version of this chapter (https://doi.org/10.1007/978-3-662-56707-4_2) contains 
</p>
<p>additional material that is available to authorized users. You can also download the &ldquo;Springer 
</p>
<p>Nature More Media App&rdquo; from the iOS or Android App Store to stream the videos and scan the 
</p>
<p>image containing the &ldquo;Play button&rdquo;.
</p>
<p>&copy; Springer-Verlag GmbH Germany, part of Springer Nature 2019 
</p>
<p>M. Sarstedt, E. Mooi, A Concise Guide to Market Research, Springer Texts in Business  
</p>
<p>and Economics, https://doi.org/10.1007/978-3-662-56707-4_2</p>
<p/>
<div class="annotation"><a href="https://crossmark.crossref.org/dialog/?doi=10.1007/978-3-662-56707-4_2&amp;amp;domain=pdf&amp;amp;date_stamp=2018-9-17">https://crossmark.crossref.org/dialog/?doi=10.1007/978-3-662-56707-4_2&amp;amp;domain=pdf&amp;amp;date_stamp=2018-9-17</a></div>
</div>
<div class="page"><p/>
<p>12 Chapter 2 &middot; The Market Research Process
</p>
<p>Keywords
</p>
<p>Causal research &bull; Descriptive research &bull; Ethnographies &bull; Exploratory research &bull; Field experiments &bull; Focus 
</p>
<p>groups &bull; Hypotheses &bull; In-depth interviews &bull; Lab experiments &bull; Market segments &bull; Observational studies &bull; 
</p>
<p>Projective techniques &bull; Research design &bull; Scanner data &bull; Test markets
</p>
<p>2.1 Introduction
</p>
<p>How do organizations plan for market research processes? In this chapter, we explore 
the market research process and various types of research. We introduce the planning 
of market research projects, starting with identifying and formulating the problem and 
ending with presenting the findings and the follow-up (see . Fig.&nbsp;2.1). This chapter is also 
an outline of the chapters to come.
</p>
<p>Identify and formulate the problem 
</p>
<p>Determine the research design 
</p>
<p>Design the sample and method of data collection 
</p>
<p>Collect the data 
</p>
<p>Analyze the data 
</p>
<p>Interpret, discuss, and present the findings 
</p>
<p>Follow-up 
</p>
<p>. Fig.&nbsp;2.1 The market research process
</p>
<p>Learning Objectives
After reading this chapter, you should understand:
</p>
<p> 5 How to determine an appropriate research design.
 5 The differences between exploratory research, descriptive research, and causal 
research.
</p>
<p> 5 What causality is.
 5 The market research process.
</p>
<p>22</p>
<p/>
</div>
<div class="page"><p/>
<p>213
2.3 &middot; Determine the Research Design
</p>
<p>2.2 Identify and Formulate the Problem
</p>
<p>The first step in setting up a market research process involves identifying and formulating 
the research problem. Identifying the research problem is valuable, but also difficult. To 
identify the &ldquo;right&rdquo; research problem, we should first identify the marketing symptoms or 
marketing opportunities. The marketing symptom is a problem that an organization faces. 
Examples of marketing symptoms include declining market shares, increasing numbers of 
complaints, or new products that consumers do not adopt. In some cases, there is no real 
problem, but instead a marketing opportunity, such as the potential benefits that new chan-
nels and products offer, or emerging market opportunities that need to be explored. Explor-
ing marketing symptoms and marketing opportunities require asking questions such as:
</p>
<p> 4 Why is our market share declining?
 4 Why is the number of complaints increasing?
 4 Why are our new products not successful?
 4 How can we enter the market for 3D printers?
 4 How can we increase our online sales?
</p>
<p>The research problems that result from such questions can come in different forms. Gen-
erally, we distinguish three types of research problems:
 4 Ambiguous problems,
 4 somewhat defined problems, and
 4 clearly defined problems.
</p>
<p>Ambiguous problems occur when we know very little about the issues that need to be 
solved. For example, ambiguity often surrounds (if not clouds) the introduction of radi-
cally new technologies or products. When Toyota planned to launch the Prius many years 
ago, critical, but little understood, issues arose, such as the features that were essential and 
even who the potential buyers of such a car were.
</p>
<p>When we face somewhat defined problems, we know the issues (and variables) that 
are important for solving the problem, but not how they are related. For example, when an 
organization wants to export products, it is relatively easy to obtain all sorts of information 
on market sizes, economic development, and the political and legal system. However, how 
these variables impact the exporting success may be very uncertain.
</p>
<p>When we face clearly defined problems, the important issues and variables, as well 
as their relationships, are clear. However, we do not know how to make the best possible 
choice. We therefore face the problem of how the situation should be optimized. A clearly 
defined problem may arise when organizations want to change their prices. While organi-
zations know that increasing (or decreasing) prices generally leads to decreased (increased) 
demand, the precise relationship (i.e., how many units do we sell less when the price is 
increased by $1?) is unknown.
</p>
<p>2.3 Determine the Research Design
</p>
<p>The research design is related to the identification and formulation of the problem. 
Research problems and research designs are interrelated. If we start working on an issue 
that has never been researched before, we seem to enter a funnel where we initially ask </p>
<p/>
</div>
<div class="page"><p/>
<p>14 Chapter 2 &middot; The Market Research Process
</p>
<p>exploratory questions, because we as yet know little about the issues we face. These explor-
atory questions are best answered using an exploratory research design. Once we have a 
clearer picture of the research issue after our exploratory research, we move further into 
the funnel. Generally, we want to learn more by describing the research problem in terms 
of descriptive research. Once we have a reasonably complete picture of all the issues, it 
may be time to determine exactly how key variables are linked. We then move to the nar-
rowest part of the funnel. We do this through causal (not casual!) research (see . Fig.&nbsp;2.2).
</p>
<p>Each research design has different uses and requires the application of different anal-
ysis techniques. For example, whereas exploratory research can help formulate problems 
exactly or structure them, causal research provides exact insights into how variables relate. 
In . Fig.&nbsp;2.3, we provide several examples of different types of research, which we will 
discuss in the following paragraphs.
</p>
<p>2.3.1 Exploratory Research
</p>
<p>As its name suggests, the objective of exploratory research is to explore a problem or situ-
ation. As such, exploratory research has several key uses regarding the solving of ambigu-
ous problems. It can help organizations formulate their problems exactly. Through initial 
research, such as interviewing potential customers, the opportunities and pitfalls may be 
identified that help determine or refine the research problem. It is crucial to discuss this 
information with the client to ensure that your findings are helpful. Such initial research 
also helps establish priorities (what is nice to know and what is important to know?) and 
eliminate impractical ideas. For example, market research helped Toyota dispel the belief 
</p>
<p>Clearly-defined problems: 
</p>
<p>Causal research
</p>
<p>Ambiguous problems:
</p>
<p>Exploratory research  
</p>
<p>Somewhat defined problems:
</p>
<p>Descriptive research 
</p>
<p>. Fig.&nbsp;2.2 The relationship between the marketing problem and the research design
</p>
<p>22</p>
<p/>
</div>
<div class="page"><p/>
<p>215
2.3 &middot; Determine the Research Design
</p>
<p>that people concerned with the environment would buy the Prius, as this target group has 
an aversion to high technology and lacks spending power.
</p>
<p>2.3.2 Uses of Exploratory Research
</p>
<p>Exploratory research can be used to formulate problems precisely. For example, focus 
groups, in-depth interviews, projective techniques, observational studies, and ethnogra-
phies are often used to achieve this. In the following, we briefly introduce each technique 
and provide more detailed descriptions in 7 Chap.&nbsp;4.
</p>
<p>Focus groups usually have between 6 and 10&nbsp;participants, who discuss a defined topic 
under the leadership of a moderator. The key difference between a depth interview and 
focus group is that focus group participants can interact with one another (e.g., &ldquo;What do 
you mean by &hellip; ?,&rdquo; &ldquo;How does this differ from &hellip; .&rdquo;), thereby providing insight into group 
dynamics.
</p>
<p>In-depth interviews consist of an interviewer asking an interviewee several questions. 
In-depth interviews allow probing on a one-to-one basis, which fosters interaction between 
the interviewer and the respondent. In-depth interviews are required when the topic needs 
to be adjusted for each interviewee, for sensitive topics, and/or when the person inter-
viewed has high status.
</p>
<p>Projective techniques present people with pictures, words, or other stimuli to which 
they respond. For example, a researcher could ask what people think of BMW owners 
(&ldquo;A&nbsp;BMW owner is someone who &hellip; .&rdquo;) or could show them a picture of a BMW and 
ask them what they associate the picture with. Moreover, when designing new products, 
market researchers can use different pictures and words to create analogies to existing 
products and product categories, thus making the adoption of new products more attrac-
tive (Feiereisen et al. 2008).
</p>
<p>Exploratory 
</p>
<p>research 
</p>
<p>Descriptive 
</p>
<p>research 
</p>
<p>Causal  
</p>
<p>research 
</p>
<p>Uses
</p>
<p>Understand structure 
</p>
<p>Formulate problems 
</p>
<p>precisely 
</p>
<p>Generate   
</p>
<p>hypotheses 
</p>
<p>Develop 
</p>
<p>measurement scales  
</p>
<p>Describe customers 
</p>
<p>or competitors 
</p>
<p>Understand market 
</p>
<p>size 
</p>
<p>Segment markets 
</p>
<p>Measure 
</p>
<p>performance (e.g., 
</p>
<p>share of wallet, 
</p>
<p>brand awareness) 
</p>
<p>Uncover causality 
</p>
<p>Understand the 
</p>
<p>performance effects 
</p>
<p>of marketing mix 
</p>
<p>elements 
</p>
<p>Ambiguous
</p>
<p>problems 
</p>
<p>Somewhat 
</p>
<p>defined problems
</p>
<p>Clearly defined
</p>
<p>problems 
</p>
<p>. Fig.&nbsp;2.3 Uses of exploratory, descriptive, and causal research</p>
<p/>
</div>
<div class="page"><p/>
<p>16 Chapter 2 &middot; The Market Research Process
</p>
<p>Observational studies are frequently used to refine research questions and clarify issues. 
Observational studies require an observer to monitor and interpret participants&rsquo; behavior. 
For example, someone could monitor how consumers spend their time in shops or how 
they walk through the aisles of a supermarket. These studies require a person, a camera or 
other tracking devices, such as radio frequency identification (RFID) chips, to monitor 
behavior. Other observational studies may comprise click stream data that track infor-
mation on the web pages people have visited. Observational studies can also be useful to 
understand how people consume and/or use products. New technology is being devel-
oped in this area, for example, market research company Almax (also see 7 Chap.&nbsp;4) has 
developed the EyeSee Mannequin, which helps observe who is attracted by store windows 
and reveals important details about customers, such as their age range, gender, ethnicity, 
and dwell time.
</p>
<p>In the award-winning paper &ldquo;An Exploratory Look at Supermarket Shopping Paths,&rdquo; Larson et al. 
</p>
<p>(2005) analyze the paths individual shoppers take in a grocery store, which the RFID tags located 
</p>
<p>on their shopping carts provide. The results provide new perspectives on many long-standing 
</p>
<p>perceptions of shopper travel behavior within a supermarket, including ideas related to aisle 
</p>
<p>traffic, special promotional displays, and perimeter shopping patterns (.&nbsp;Fig.&nbsp;2.4). Before this 
study, most retailers believed that customers walked through the aisles systematically. Larson 
</p>
<p>et&nbsp;al.&rsquo;s (2005) research reveals this rarely happens.
</p>
<p>. Fig.&nbsp;2.4 Supermarket shopping paths
</p>
<p>Ethnographies (or ethnographic studies) originate from anthropology. In ethnograph-
ic research, a researcher interacts with consumers over a period to observe and ask 
questions. Such studies can consist of, for example, a researcher living with a family to 
observe how they buy, consume, and use products. For example, the market research 
company BBDO used ethnographies to understand consumers&rsquo; rituals. The company 
found that many consumer rituals are ingrained in consumers in certain countries, 
but not in others. For example, women in Colombia, Brazil, and Japan are more than 
twice as likely to apply make-up when in their cars, than women in other countries. 
Miele, a German whitegoods producer, used ethnographies to understand how people 
with allergies do their washing and developed washing machines based on the insights 
gathered (Burrows 2014).
</p>
<p>22</p>
<p/>
</div>
<div class="page"><p/>
<p>217
2.3 &middot; Determine the Research Design
</p>
<p>Exploratory research can also help establish research priorities. What is important to 
know and what is less important? For example, a literature search may reveal that there 
are useful previous studies and that new market research is not necessary. Exploratory 
research may also lead to the elimination of impractical ideas. Literature searches, just 
like interviews, may again help eliminate impractical ideas.
</p>
<p>Another helpful aspect of exploratory research is the generation of hypotheses. 
A&nbsp;hypothesis is a claim made about a population, which can be tested by using sample 
results. For example, one could hypothesize that at least 10&nbsp;% of people in France are aware 
of a certain product. Marketers frequently suggest hypotheses, because they help them 
structure and make decisions. In 7 Chap.&nbsp;6, we discuss hypotheses and how they can be 
tested in greater detail.
</p>
<p>Another use of exploratory research is to develop measurement scales. For example, 
what questions can we use to measure customer satisfaction? What questions work best 
in our context? Do potential respondents understand the wording, or do we need to make 
changes? Exploratory research can help us answer such questions. For example, an explor-
atory literature search may use measurement scales that tell us how to measure important 
concepts such as corporate reputation and service quality.
</p>
<p>2.3.3 Descriptive Research
</p>
<p>As its name implies, descriptive research is all about describing certain phenomena, char-
acteristics, or functions. It can focus on one variable (e.g., profitability) or on two or more 
variables at the same time (&ldquo;what is the relationship between market share and profitabil-
ity?&rdquo; and &ldquo;how does temperature relate to the sale of ice cream?&rdquo;). Descriptive research 
often builds on previous exploratory research. After all, to describe something, we must 
have a good idea of what we need to measure and how we should measure it. Key ways in 
which descriptive research can help us include describing customers, competitors, market 
segments, and measuring performance.
</p>
<p>2.3.4 Uses of Descriptive Research
</p>
<p>Market researchers conduct descriptive research for many purposes. These include, for 
example, describing customers or competitors. For instance, how large is the UK market 
for pre-packed cookies? How large is the worldwide market for cruises priced $10,000 
and more? How many new products did our competitors launch last year? Descriptive 
research helps us answer such questions. Much data are available for descriptive purposes, 
particularly on durable goods and fast moving consumer goods. One source of such data 
are scanner data, which are collected at the checkout of a supermarket where details about 
each product sold are entered into a vast database. By using scanner data, it is, for example, 
possible to describe the market for pre-packed cookies in the UK.
</p>
<p>Descriptive research is frequently used to define market segments, or simply segments. 
Since companies can seldom connect with all their (potential) customers individually, they 
divide markets into groups of (potential) customers with similar needs and wants. Firms 
can then target each of these segments by positioning themselves in a unique segment </p>
<p/>
</div>
<div class="page"><p/>
<p>18 Chapter 2 &middot; The Market Research Process
</p>
<p>(such as Ferrari in the high-end sports car market). Many market research companies 
specialize in market segmentation; an example is Claritas, which developed a segmenta-
tion scheme for the US market called Claritas MyBestSegments. This segments consumers 
along a multitude of attitudinal, behavioral, and demographic characteristics; companies 
can use these segments to better target their customers. Segments have names, such as 
Young Digerati (tech-savvy singles and couples living in fashionable urban fringe neigh-
borhoods) and Heartlanders (older couples with working-class jobs living in unpreten-
tious homes who prefer a rustic lifestyle).
</p>
<p>Another important function of descriptive market research is to measure performance. 
Nearly all companies regularly track their sales across specific product categories to eval-
uate the performance of the firm, the managers, or specific employees. Such descriptive 
work overlaps with the finance or accounting departments&rsquo; responsibilities. However, 
market researchers also frequently measure performance using measures that are quite 
specific to marketing, such as share of wallet (i.e., how much do people spend on a certain 
brand or company in a product category?) and brand awareness (i.e., do you know brand/
company X?), or the Net Promotor Score, a customer loyalty metric for brands or firms 
(see 7 Chap.&nbsp;3 for more information).
</p>
<p>2.3.5 Causal Research
</p>
<p>Causal research is used to understand the relationships between two or more variables. 
For example, we may wish to estimate how changes in the wording of an advertisement 
impact recall. Causal research provides exact insights into how variables relate and may be 
useful as a test run to try out changes in the marketing mix. Market researchers undertake 
causal research less frequently than exploratory or descriptive research. Nevertheless, it is 
important to understand the delicate relationships between important marketing variables 
and the outcomes they help create. The key usage of causal research is to uncover causality. 
Causality is the relationship between an event (the cause) and a second event (the effect) 
when the second event is a consequence of the first. To claim causality, we need to meet 
the following four requirements:
 4 Relationship between cause and effect,
 4 time order,
 4 controlling for other factors, and
 4 an explanatory theory.
</p>
<p>First, the cause needs to be related to the effect. For example, if we want to determine 
whether price increases cause sales to drop, there should be a negative relationship or cor-
relation between price increases and sales decreases (see 7 Chap.&nbsp;5). Note that people often 
confuse correlation and causality. Just because there is some type of relationship between 
two variables does not mean that the one caused the other (see Box 2.1).
</p>
<p>Second, the cause needs to come before the effect. This is the requirement of time order. 
A price increase can obviously only have a causal effect on the sales if it occurred before 
the sales decrease.
</p>
<p>Third, we need to control for other factors. If we increase the price, sales may go up, 
because competitors increase their prices even more. Controlling for other factors is 
</p>
<p>22</p>
<p/>
</div>
<div class="page"><p/>
<p>219
2.3 &middot; Determine the Research Design
</p>
<p>Box 2.1&nbsp;Correlation does not automatically imply causation
</p>
<p>Correlation does not automatically imply causality. For example, . Fig.&nbsp;2.5 plots US fatal motor 
vehicle crashes (per 100,000 people) against the harvested area of melons (in 1000 acres) 
</p>
<p>between 2000 and 2015.
</p>
<p>Clearly, the picture shows a trend. If the harvested area of melons increases, the number 
</p>
<p>of US fatal motor vehicle crashes increases. The resulting correlation of 0.839 is very high (we 
</p>
<p>discuss how to interpret correlations in 7 Chap.&nbsp;5). While this correlation is the first requirement 
to determine causality, the story falls short when it comes to explanatory theory. What possible 
</p>
<p>mechanism could explain the findings? This is likely a case of a spurious correlation, which is 
</p>
<p>simply due to coincidence.
</p>
<p>In the above situation, most people would be highly skeptical and would not interpret the 
</p>
<p>correlation as describing a causal mechanism; in other instances, the situation is much less clear-
</p>
<p>cut. Think of claims that are part of everyday market research, such as &ldquo;the new advertisement 
</p>
<p>campaign caused a sharp increase in sales,&rdquo; &ldquo;our company&rsquo;s sponsorship activities helped improve 
</p>
<p>our company&rsquo;s reputation,&rdquo; or &ldquo;declining sales figures are caused by competitors&rsquo; aggressive price 
</p>
<p>policies.&rdquo; Even if there is a correlation, the other requirements for causality may not be met. Causal 
</p>
<p>research helps us determine if causality can be claimed.
</p>
<p>Some of these and other examples can be found in Huff (1993) or on Wikipedia (https://
</p>
<p>en.wikipedia.org/wiki/Correlation_does_not_imply_causation). Furthermore, check http://www.
</p>
<p>tylervigen.com/spurious-correlations for more entertaining examples of spurious correlations&mdash;
</p>
<p>see also Vigen (2015).
</p>
<p>110
</p>
<p>2014
</p>
<p>2013
2011
</p>
<p>2012
</p>
<p>2009
</p>
<p>2015
</p>
<p>2008
</p>
<p>2007
</p>
<p>2006
</p>
<p>2004
2003
</p>
<p>20012000
2002
</p>
<p>2005
</p>
<p>2010
</p>
<p>US harvested melons (in 1000 acres)
</p>
<p>U
S
</p>
<p> f
a
</p>
<p>ta
li
</p>
<p>ty
 r
</p>
<p>a
te
</p>
<p> in
 m
</p>
<p>o
to
</p>
<p>r 
v
</p>
<p>e
h
</p>
<p>ic
le
</p>
<p> c
ra
</p>
<p>sh
e
</p>
<p>s
</p>
<p>10
</p>
<p>11
</p>
<p>12
</p>
<p>13
</p>
<p>14
</p>
<p>15
</p>
<p>120 130 140 150 160 170
</p>
<p>. Fig.&nbsp;2.5 Correlation and causation (the data were taken from the NHTSA Traffic Safety Facts, 
DOT HS 810 780, and the United States Department of Agriculture, National Agricultural Statistics 
</p>
<p>Service)</p>
<p/>
<div class="annotation"><a href="https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation">https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation</a></div>
<div class="annotation"><a href="https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation">https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation</a></div>
<div class="annotation"><a href="http://www.tylervigen.com/spurious-correlations">http://www.tylervigen.com/spurious-correlations</a></div>
<div class="annotation"><a href="http://www.tylervigen.com/spurious-correlations">http://www.tylervigen.com/spurious-correlations</a></div>
</div>
<div class="page"><p/>
<p>20 Chapter 2 &middot; The Market Research Process
</p>
<p>difficult, but not impossible. In experiments, we design studies so that external factors&rsquo; 
effect is nil, or as close to nil as possible. This is achieved by, for example, conducting exper-
iments in labs where environmental factors, such as the conditions, are constant (controlled 
for). We can also use statistical tools that account for external influences to control for 
other factors. These statistical tools include an analysis of variance (see 7 Chap.&nbsp;6), regres-
sion analysis (see 7 Chap.&nbsp;7), and structural equation modeling (see the end of 7 Chap.&nbsp;8).
</p>
<p>Fourth, the need for a good explanatory theory is an important criterion. Without a 
theory, our effects may be due to chance and no &ldquo;real&rdquo; effect may be present. For example, 
we may observe that when we advertise, sales decrease. Without a good explanation of 
this effect (such as people disliking the advertisement), we cannot claim that there is a 
causal relationship.
</p>
<p>2.3.6 Uses of Causal Research
</p>
<p>Experiments are a key type of causal research and come in the form of either lab or field 
experiments.
</p>
<p>Lab experiments are performed in controlled environments (usually in a company or 
academic lab) to isolate the effects of one or more variables on a certain outcome. To do 
so, researchers impose a treatment (e.g., a new advertisement) that induces changes in one 
variable (e.g., the type of advertising appeal) and evaluate its impact on an outcome vari-
able (e.g., product choice). Field experiments are like lab experiments in that they examine 
the impact of one or more variables on a certain outcome. However, field experiments 
are conducted in real-life settings (not set up in controlled environments), thus reducing 
(or even eliminating) plausible claims of causality (Gneezy 2017). On the plus side, their 
realism makes them attractive for market research purposes, as the observed effects can 
probably be generalized to similar settings. For example, isi (https://www.isi-goettingen.de/
en), a German sensory market research company, regularly runs product acceptance tests 
</p>
<p>&copy; brazzo/Getty Images/iStock
</p>
<p>https://www.youtube.com/watch?v=8B271L3NtAw
</p>
<p>22</p>
<p/>
<div class="annotation"><a href="https://www.isi-goettingen.de/en">https://www.isi-goettingen.de/en</a></div>
<div class="annotation"><a href="https://www.isi-goettingen.de/en">https://www.isi-goettingen.de/en</a></div>
<div class="annotation"><a href="https://www.youtube.com/watch?v=8B271L3NtAw">https://www.youtube.com/watch?v=8B271L3NtAw</a></div>
</div>
<div class="page"><p/>
<p>221
2.3 &middot; Determine the Research Design
</p>
<p>in which consumers sequentially evaluate different products, interrupted by short breaks 
to neutralize their senses. These tests are traditionally run in sensory labs under controlled 
conditions. However, isi also runs field experiments in actual consumption environments. 
. Fig.&nbsp;2.6 shows a photo of a field experiment the company ran in a coffeehouse to evalu-
ate consumer ratings of different cappuccino products. We discuss experimental set-ups 
in more detail in 7 Chap.&nbsp;4.
</p>
<p>. Fig.&nbsp;2.6 Field experiment (&copy; isi GmbH)
</p>
<p>Field experiments are not always a good idea. In the city of Rotterdam, the local council tried to 
</p>
<p>reduce bike accidents by turning the traffic lights at bike crossings at a very busy intersection 
</p>
<p>green at the same time. While the idea was that bicyclists would pay more attention, it took less 
</p>
<p>than a minute for two accidents to happen. Needless to say, the experiment was canceled. (see 
</p>
<p>https://www.youtube.com/watch?v=QIsLSmbfaiQ, in Dutch only).
</p>
<p>Test markets are a form of field experiment in which organizations in a geographically 
defined area introduce new products and services, or change the marketing mix to 
gauge consumer reactions. Test markets help marketers learn about consumer response, 
thus reducing the risks of a nationwide rollout of new products/services or changes in 
the marketing mix. For example, gps dataservice (http://www.gps-dataservice.de/en) 
runs several test markets for a series of major European retailers to evaluate the effect 
of treatments, such as new product launches, price changes, promotions, or product 
placements, on purchasing behavior. The company uses data from scanners, customer 
cards, and other sources (e.g., surveys, observations) to investigate their effects on sales. </p>
<p/>
<div class="annotation"><a href="https://www.youtube.com/watch?v=QIsLSmbfaiQ">https://www.youtube.com/watch?v=QIsLSmbfaiQ</a></div>
<div class="annotation"><a href="http://www.gps-dataservice.de/en">http://www.gps-dataservice.de/en</a></div>
</div>
<div class="page"><p/>
<p>22 Chapter 2 &middot; The Market Research Process
</p>
<p>For example, shelf tests involve placing dummy packages in the usual shelves in selected 
stores, and determining the reactions to these new packages by means of shopper obser-
vations (e.g., eye or physical contact with the product; . Fig.&nbsp;2.7), surveys, and scanner 
data. In 7 Chap.&nbsp;4, we discuss test markets in more depth.
</p>
<p>2.4 Design the Sample and Method of Data Collection
</p>
<p>Having determined the research design, we need to design a sampling plan and choose a 
data-collecting method. This involves deciding whether to use existing (secondary) data 
or to conduct primary research. We discuss this in more detail in 7 Chap.&nbsp;3.
</p>
<p>2.5 Collect the Data
</p>
<p>Collecting data is a practical, but sometimes difficult, part of the market research process. 
How do we design a survey? How do we measure attitudes toward a product, brand, or 
company if we cannot observe these attitudes directly? How do we get CEOs to respond? 
Dealing with such issues requires careful planning and knowledge of the marketing 
process. We discuss related key issues in 7 Chap.&nbsp;4.
</p>
<p>2.6 Analyze the Data
</p>
<p>Analyzing data requires technical skills. We discuss how to enter, clean, and describe data in 
7 Chap.&nbsp;5. After this, we introduce key techniques, such as hypothesis testing and analysis of 
variance (ANOVA), regression analysis, principal component analysis, factor analysis, and 
cluster analysis in 7 Chap.&nbsp;6&ndash;9. In each of these chapters, we discuss the key theoretical choices 
and issues that market researchers face when using these techniques. We also illustrate how 
researchers can practically deal with these theoretical choices and issues by means of SPSS.
</p>
<p>. Fig.&nbsp;2.7 Shelf test (&copy; IWD 
market research GmbH)
</p>
<p>22</p>
<p/>
</div>
<div class="page"><p/>
<p>223
References
</p>
<p>2.7 Interpret, Discuss, and Present the Findings
</p>
<p>When executing the market research process, researchers&rsquo; immediate goals are interpret-
ing, discussing, and presenting the findings. Consequently, researchers should provide 
detailed answers and actionable suggestions based on data and analysis techniques. The 
last step is to clearly communicate the findings and recommendations to help decision 
making and implementation. This is further discussed in 7 Chap.&nbsp;10.
</p>
<p>2.8 Follow-Up
</p>
<p>Market researchers often stop when the results have been interpreted, discussed, and 
presented. However, following up on the research findings is important too. Implement-
ing market research findings sometimes requires further research, because suggestions 
or recommendations may not be feasible or practical and market conditions may have 
changed. From a market research firm&rsquo;s perspective, follow-up research on previously 
conducted research can be a good way of entering new deals for further research. Some 
market research never ends, for example, many firms track customer satisfaction contin-
uously, but such research can also have specific follow-ups, for example, because the man-
agement may wish to know the causes of drops in customer satisfaction.
</p>
<p>2.9 Review Questions
</p>
<p>1. Why do we follow a structured process when conducting market research? Are 
there any shortcuts you can take? Compare, for example, Qualtrics&rsquo; market research 
process (http://www.qualtrics.com/blog/marketing-research-process) with the process 
discussed above. What are the similarities and differences?
</p>
<p>2. Describe what exploratory, descriptive, and causal research is and how they are 
related to one another. Provide an example of each type of research.
</p>
<p>3. What are the four requirements for claiming causality? Do we meet these require-
ments in the following situations?
</p>
<p> 4 Good user design led to Google&rsquo;s Android becoming the market leader.
 4 When Rolex charges a higher price, this increases sales.
 4 More advertising causes greater sales.
</p>
<p>References
</p>
<p>Burrows, D. (2014). How to use ethnography for in-depth consumer insight. Marketing Week, May 9, 
</p>
<p>2014, https://www.marketingweek.com/2014/05/09/how-to-use-ethnography-for-in-depth- 
</p>
<p>consumer-insight/. Accessed 03 May 2018.
</p>
<p>Feiereisen, S., Wong, V., &amp; Broderick, A. J. (2008). Analogies and mental simulations in learning for  
</p>
<p>really new products: The role of visual attention. Journal of Product Innovation Management, 25(6),  
</p>
<p>593&ndash;607.
</p>
<p>Gneezy, A. (2017). Field experimentation in marketing research. Journal of Marketing Research, 54(1), 
</p>
<p>140&ndash;143.</p>
<p/>
<div class="annotation"><a href="http://www.qualtrics.com/blog/marketing-research-process">http://www.qualtrics.com/blog/marketing-research-process</a></div>
<div class="annotation"><a href="https://www.marketingweek.com/2014/05/09/how-to-use-ethnography-for-in-depth-consumer-insight/">https://www.marketingweek.com/2014/05/09/how-to-use-ethnography-for-in-depth-consumer-insight/</a></div>
<div class="annotation"><a href="https://www.marketingweek.com/2014/05/09/how-to-use-ethnography-for-in-depth-consumer-insight/">https://www.marketingweek.com/2014/05/09/how-to-use-ethnography-for-in-depth-consumer-insight/</a></div>
</div>
<div class="page"><p/>
<p>24 Chapter 2 &middot; The Market Research Process
</p>
<p>Huff, D. (1993). How to lie with statistics. New York, NJ: W. W. Norton &amp; Company.
</p>
<p>Larson, J. S., Bradlow, E. T., &amp; Fader, P. S. (2005). An exploratory look at supermarket shopping paths. 
</p>
<p>International Journal of Research in Marketing, 22(4), 395&ndash;414. http://papers.ssrn.com/sol3/papers.
</p>
<p>cfm?abstract_id=723821.
</p>
<p>Vigen, T. (2015). Spurious correlations. New York, NJ: Hachette Books.
</p>
<p>Further Reading
</p>
<p>Claritas MyBestSegments at https://segmentationsolutions.nielsen.com/mybestsegments/
</p>
<p>Levitt, S. D., &amp; Dubner, S. J. (2005). Freakonomics. A rogue economist explores the hidden side of everything. 
</p>
<p>New York, NY: HarperCollins.
</p>
<p>Levitt, S. D., &amp; Dubner, S. J. (2009). Superfreakonomics. New York, NY: HarperCollins.
</p>
<p>Nielsen Retail Measurement at http://www.nielsen.com/us/en/solutions/measurement/retailmeasure-
</p>
<p>ment.html
</p>
<p>Pearl, J. (2009). Causality, models, reasoning, and inference. New York, NY: Cambridge University Press.
</p>
<p>22</p>
<p/>
<div class="annotation"><a href="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=723821">http://papers.ssrn.com/sol3/papers.cfm?abstract_id=723821</a></div>
<div class="annotation"><a href="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=723821">http://papers.ssrn.com/sol3/papers.cfm?abstract_id=723821</a></div>
<div class="annotation"><a href="https://segmentationsolutions.nielsen.com/mybestsegments/">https://segmentationsolutions.nielsen.com/mybestsegments/</a></div>
<div class="annotation"><a href="http://www.nielsen.com/us/en/solutions/measurement/retailmeasurement.html">http://www.nielsen.com/us/en/solutions/measurement/retailmeasurement.html</a></div>
<div class="annotation"><a href="http://www.nielsen.com/us/en/solutions/measurement/retailmeasurement.html">http://www.nielsen.com/us/en/solutions/measurement/retailmeasurement.html</a></div>
</div>
<div class="page"><p/>
<p>25
</p>
<p>Data
</p>
<p>3.1 Introduction &ndash; 26
</p>
<p>3.2 Types of Data &ndash; 26
3.2.1 Primary and Secondary Data &ndash; 29
</p>
<p>3.2.2 Quantitative and Qualitative Data &ndash; 30
</p>
<p>3.3 Unit of Analysis &ndash; 31
</p>
<p>3.4 Dependence of Observations &ndash; 32
</p>
<p>3.5 Dependent and Independent Variables &ndash; 33
</p>
<p>3.6 Measurement Scaling &ndash; 33
</p>
<p>3.7 Validity and Reliability &ndash; 35
3.7.1 Types of Validity &ndash; 37
</p>
<p>3.7.2 Types of Reliability &ndash; 38
</p>
<p>3.8 Population and Sampling &ndash; 38
3.8.1 Probability Sampling &ndash; 41
</p>
<p>3.8.2 Non-probability Sampling &ndash; 42
</p>
<p>3.8.3 Probability or Non-probability Sampling? &ndash; 43
</p>
<p>3.9 Sample Sizes &ndash; 43
</p>
<p>3.10 Review Questions &ndash; 44
</p>
<p> References &ndash; 44
</p>
<p>3
</p>
<p>Electronic supplementary material
</p>
<p>The online version of this chapter (https://doi.org/10.1007/978-3-662-56707-4_3) contains 
</p>
<p>additional material that is available to authorized users. You can also download the &ldquo;Springer 
</p>
<p>Nature More Media App&rdquo; from the iOS or Android App Store to stream the videos and scan the 
</p>
<p>image containing the &ldquo;Play button&rdquo;.
</p>
<p>&copy; Springer-Verlag GmbH Germany, part of Springer Nature 2019 
</p>
<p>M. Sarstedt, E. Mooi, A Concise Guide to Market Research, Springer Texts in Business  
</p>
<p>and Economics, https://doi.org/10.1007/978-3-662-56707-4_3</p>
<p/>
<div class="annotation"><a href="https://crossmark.crossref.org/dialog/?doi=10.1007/978-3-662-56707-4_3&amp;amp;domain=pdf&amp;amp;date_stamp=2018-9-17">https://crossmark.crossref.org/dialog/?doi=10.1007/978-3-662-56707-4_3&amp;amp;domain=pdf&amp;amp;date_stamp=2018-9-17</a></div>
</div>
<div class="page"><p/>
<p>26 Chapter 3 &middot; Data
</p>
<p>Keywords
</p>
<p>Armstrong and Overton procedure &bull; Case &bull; Census &bull; Constant &bull; Construct &bull; Construct validity &bull; Content 
</p>
<p>validity &bull; Criterion validity &bull; Dependence of observations &bull; Discriminant validity &bull; Equidistance &bull; Face 
</p>
<p>validity &bull; Formative constructs &bull; Index &bull; Index construction &bull; Internal consistency reliability &bull; Inter-rater 
</p>
<p>reliability &bull; Items &bull; Latent concept &bull; Latent variable &bull; Measurement scaling &bull; Multi-item constructs &bull; Net 
</p>
<p>Promoter Score (NPS) &bull; Nomological validity &bull; Non-probability sampling &bull; Observation &bull; Operationaliza-
</p>
<p>tion &bull; Population &bull; Predictive validity &bull; Primary data &bull; Probability sampling &bull; Qualitative data &bull; Quantitative 
</p>
<p>data &bull; Reflective constructs &bull; Reliability &bull; Sample size &bull; Sampling &bull; Sampling error &bull; Scale development &bull; 
</p>
<p>Secondary data &bull; Single-item constructs &bull; Test-retest reliability &bull; Unit of analysis &bull; Validity &bull; Variable
</p>
<p>3.1 Introduction
</p>
<p>Data are at the heart of market research. By data we mean a collection of facts that can 
be used as a basis for analysis, reasoning, or discussions. Think, for example, of peo-
ple&rsquo;s answers to surveys, existing company records, or observations of shoppers&rsquo; behav-
iors. &ldquo;Good&rdquo; data are vital because they form the basis of useful market research. In this 
chapter, we discuss different types of data. This discussion will help you explain the data 
you use and why you do so. Subsequently, we introduce strategies for collecting data in 
7 Chap.&nbsp;4.
</p>
<p>3.2 Types of Data
</p>
<p>Before we start discussing data, it is a good idea to introduce the terminology we will use. 
In the next sections, we will discuss the following four concepts:
 4 Variables,
 4 constants,
 4 cases, and
 4 constructs.
</p>
<p>Learning Objectives
After reading this chapter you should understand:
</p>
<p> 5 How to explain what kind of data you use.
 5 The differences between primary and secondary data.
 5 The differences between quantitative and qualitative data.
 5 What the unit of analysis is.
 5 When observations are independent and when dependent.
 5 The difference between dependent and independent variables.
 5 Different measurement scales and equidistance.
 5 Validity and reliability from a conceptual viewpoint.
 5 How to set up different sampling designs.
 5 How to determine acceptable sample sizes.
</p>
<p>3</p>
<p/>
</div>
<div class="page"><p/>
<p>327
3.2 &middot; Types of Data
</p>
<p>A variable is an attribute whose value can change. For example, the price of a product is 
an attribute of that product and generally varies over time. If the price does not change, it 
is a constant. A case (or observation) consists of all the variables that belong to an object 
such as a customer, a company, or a country.
</p>
<p>The relationship between variables and cases is that within one case we usually find 
multiple variables. . Table 3.1 includes five variables: car type, age, as well as brand_1, 
brand_2, and brand_3, which capture statements related to brand trust. In the lower rows, 
you see four observations.
</p>
<p>Another important and frequently used term in market research is construct, which 
refers to a variable that is not directly observable (i.e., a latent variable). More precisely, 
a&nbsp;construct is used to represent latent concepts in statistical analyses. Latent concepts rep-
resent broad ideas or thoughts about certain phenomena that researchers have established 
and want to measure in their research (e.g., Bollen 2002). However, constructs cannot be 
measured directly, as respondents cannot articulate a single response that will completely 
and perfectly provide a measure of that concept. For example, constructs such as satis-
faction, loyalty, and brand trust cannot be measured directly. However, we can measure 
satisfaction, loyalty, and brand trust by means of several items. The term items (or indica-
tors) is normally used to indicate posed survey questions. Measuring constructs requires 
combining items to form a multi-item scale, an example of which appears in . Table 3.1 
in the form of three items brand_1 (This brand&rsquo;s product claims are believable), brand_2 
(This brand delivers what it promises), and brand_3 (This brand has a name that you can 
trust). Bear in mind that not all items relate to constructs; for example, the variables car 
type and age in . Table 3.1 are not constructs, as these are observable and a single response 
can measure it accurately and fully.
</p>
<p>Like constructs, an index also consists of sets of variables. The difference is that an 
index is created by the variable&rsquo;s &ldquo;causes.&rdquo; For example, we can create an index of informa-
tion search activities, which is the sum of the information that customers acquire from 
</p>
<p>. Table 3.1 Quantitative data
</p>
<p>Variable 
name
</p>
<p>Car type Customer&rsquo;s age brand_1 brand_2 brand_3
</p>
<p>Description Type of car 
bought
</p>
<p>Customer&rsquo;s 
age in years
</p>
<p>This brand&rsquo;s 
product 
claims are 
 believable
</p>
<p>This brand 
delivers 
what it 
promises
</p>
<p>This brand 
has a name 
that you can 
trust
</p>
<p>Customer 1 BMW 328i 29 6 5 7
</p>
<p>Customer 2 Mercedes 
</p>
<p>C180K
</p>
<p>45 6 6 6
</p>
<p>Customer 3 VW Passat 
</p>
<p>2.0 TFSI
</p>
<p>35 7 5 5
</p>
<p>Customer 4 BMW 525ix 61 5 4 5
</p>
<p>Coding for brand_1, brand_2, and brand_3: 1&nbsp;=&nbsp;fully disagree, 7&nbsp;=&nbsp;fully agree</p>
<p/>
</div>
<div class="page"><p/>
<p>28 Chapter 3 &middot; Data
</p>
<p>Box 3.1 Types of constructs
</p>
<p>In reflective constructs, the items are considered to be manifestations of an underlying 
construct (i.e., the items reflect the construct). Our brand trust example suggests a reflective 
</p>
<p>construct, as the items reflect trust. Thus, if a respondent changes his assessment of brand trust 
</p>
<p>(e.g., due to a negative brand experience), this is reflected in the answers to the three items. 
</p>
<p>Reflective constructs typically use multiple items (3 or more) to increase the measurement 
</p>
<p>stability and accuracy. If we have multiple items, we can use analysis techniques to inform us 
</p>
<p>about the measurement quality, such as factor analysis and reliability analysis (discussed in 
</p>
<p>7 Chap.&nbsp;8). Formative constructs consist of several items that define a construct. A typical 
example is socioeconomic status, which is formed by a combination of education, income, 
</p>
<p>occupation, and residence. If any of these measures increases, the socioeconomic status would 
</p>
<p>increase (even if the other items did not change). Conversely, if a person&rsquo;s socioeconomic status 
</p>
<p>increases, this would not necessarily go hand in hand with an increase in all four measures. The 
</p>
<p>distinction between reflective and formative constructs is that they require different approaches 
</p>
<p>to decide on the type and number of items. For example, reliability analyses (discussed in 
</p>
<p>7 Chap.&nbsp;8) should not be run on formative measures (Diamantopoulos 2006). For an overview of 
this distinction, see Bollen and Diamantopoulos (2017), Diamantopoulos et al. (2008), or Sarstedt 
</p>
<p>et al. (2016c).
</p>
<p>dealers, the promotional materials, the Internet, and other sources. This measure of infor-
mation search activities is also referred to as a composite measure, but, unlike a construct, 
the items in an index define what we want to measure. For example, the Retail Price Index 
consists of a &ldquo;shopping&rdquo; bag of common retail products multiplied by their price. Unlike 
a construct, each item in a scale captures a part of the index perfectly.
</p>
<p>The procedure of combining several items is called scale development, operationaliza-
tion, or, in the case of an index, index construction. These procedures involve a combina-
tion of theory and statistical analysis, such as factor analysis (discussed in 7 Chap.&nbsp;8) aimed 
at developing an appropriate construct measure. For example, in . Table 3.1, brand_1, 
brand_2, and brand_3 are items that belong to a construct called brand trust (as defined 
by Erdem and Swait 2004). The construct is not an individual item that you see in the list, 
but it is captured by calculating the average of several related items. Thus, in terms of brand 
trust, the score of customer 1 is (6&nbsp;+&nbsp;5&nbsp;+&nbsp;7)/3&nbsp;=&nbsp;6.
</p>
<p>But how do we decide which and how many items to use when measuring specific 
constructs? To answer these questions, market researchers make use of scale development 
procedures. These procedures follow an iterative process with several steps and feedback 
loops. For example, DeVellis (2017) provides a thorough introduction to scale develop-
ment. Unfortunately, scale development requires much (technical) expertise. Describ-
ing each step is therefore beyond this book&rsquo;s scope. However, many scales do not require 
this procedure, as existing scales can be found in scale handbooks, such as the Handbook 
of Marketing Scales by Bearden et al. (2011). Furthermore, marketing and management 
journals frequently publish research articles that introduce new scales or indices, such as 
for measuring the reputation of non-profit organizations (e.g., Sarstedt and Schloderer 
2010) or for refining existing scales (e.g., Kuppelwieser and Sarstedt 2014). In Box 3.1, we 
introduce two distinctions that are often used to discuss constructs.
</p>
<p>3</p>
<p/>
</div>
<div class="page"><p/>
<p>329
3.2 &middot; Types of Data
</p>
<p>Instead of using multiple items to measure constructs (i.e., multi-item constructs), 
researchers and practitioners frequently use single items (i.e., single-item constructs). For 
example, we may only use &ldquo;This brand has a name that you can trust&rdquo; to measure brand trust, 
</p>
<p>instead of using three items. A popular single-item measure is the Net Promoter Score (NPS), 
which aims to measure loyalty by using the single question: &ldquo;How likely are you to recommend 
</p>
<p>our company/product/service to a friend or colleague?&rdquo; (Reichheld 2003). While this is a good 
</p>
<p>way of making the questionnaire shorter, it also reduces the quality of your measures (e.g., 
</p>
<p>Diamantopoulos et al. 2012; Sarstedt et al. 2016a, b). You should therefore avoid using single 
</p>
<p>items to measure constructs unless you only need a rough proxy measure of a latent concept.
</p>
<p>3.2.1 Primary and Secondary Data
</p>
<p>Generally, we can distinguish between primary data and secondary data. While primary 
data are data that a researcher has collected for a specific purpose, another researcher col-
lected the secondary data for another purpose.
</p>
<p>The US Consumer Expenditure Survey (www.bls.gov/cex), which makes data avail-
able on what people in the US buy, such as insurance, personal care items, and food, is 
an example of secondary data. It also includes the prices people pay for these products 
and services. Since these data have already been collected, they are secondary data. If a 
researcher sends out a survey with various questions to find an answer to a specific issue, 
the collected data are primary data. If primary data are re-used to answer another research 
question, they become secondary data.
</p>
<p>Secondary and primary data have their own specific advantages and disadvantages, 
which we illustrate in . Table 3.2. The most important reasons for using secondary data 
are that they tend to be cheaper and quick to obtain access to (although lengthy processes 
may be involved). For example, if you want to have access to the US Consumer Expenditure 
</p>
<p>&copy; stanciuc/stock.adobe.com
</p>
<p>https://www.youtube.com/watch?v=qWKipJefrN8&amp;t=70s</p>
<p/>
<div class="annotation"><a href="http://www.bls.gov/cex">http://www.bls.gov/cex</a></div>
<div class="annotation"><a href="https://www.youtube.com/watch?v=qWKipJefrN8&amp;t=70s ">https://www.youtube.com/watch?v=qWKipJefrN8&amp;t=70s </a></div>
</div>
<div class="page"><p/>
<p>30 Chapter 3 &middot; Data
</p>
<p>. Table 3.2 The advantages and disadvantages of secondary and primary data
</p>
<p>Secondary data Primary data
</p>
<p>Advantages &ndash; Tend to be cheaper
</p>
<p>&ndash; Sample sizes tend to be greater
</p>
<p>&ndash; Tend to have more authority
</p>
<p>&ndash; Are usually quick to access
</p>
<p>&ndash;  Are easier to compare to other research using the 
</p>
<p>same data
</p>
<p>&ndash;  Are sometimes more accurate (e.g., data on 
</p>
<p>competitors)
</p>
<p>&ndash; Are recent
</p>
<p>&ndash;  Are specific for the 
</p>
<p>purpose
</p>
<p>&ndash; Are proprietary
</p>
<p>Disadvantages &ndash; May be outdated
</p>
<p>&ndash; May not fully fit the problem
</p>
<p>&ndash;  There may be hidden errors in the data &ndash; difficult to 
</p>
<p>assess the data quality
</p>
<p>&ndash; Usually contain only factual data
</p>
<p>&ndash; No control over data collection
</p>
<p>&ndash;  May not be reported in the required form (e.g., 
</p>
<p>different units of measurement, definitions, 
</p>
<p>aggregation levels of the data)
</p>
<p>&ndash;  Are usually more 
</p>
<p>expensive
</p>
<p>&ndash;  Take longer to 
</p>
<p>collect
</p>
<p>Survey, all you have to do is to use your web browser to go to www.bls.gov/cex and to down-
load the required files. However, the authority and competence of some research organi-
zations could be a factor. For example, the claim that Europeans spend 9&nbsp;% of their annual 
income on health may be more believable if it comes from Eurostat (the statistical office of 
the European Community) rather than from a single, primary research survey.
</p>
<p>However, important secondary data drawbacks are that they may not answer your 
research question. If you are, for example, interested in the sales of a specific product (and 
not in a product or service category), the US Consumer Expenditure Survey may not help 
much. In addition, if you are interested in the reasons for people buying products, this type 
of data may not help answer your question. Lastly, as you did not control the data collec-
tion, there may be errors in the data.
</p>
<p>In contrast, primary data tend to be highly specific, because the researcher (you!) can 
influence what the research comprises. In addition, research to collect primary data can 
be carried out when and where required and competitors cannot access it. However, gath-
ering primary data often requires much time and effort and is therefore usually expensive 
compared to secondary data.
</p>
<p>As a rule, start looking for secondary data first. If they are available, and of acceptable 
quality, use them! We will discuss ways to gather primary and secondary data in 7 Chap.&nbsp;4.
</p>
<p>3.2.2 Quantitative and Qualitative Data
</p>
<p>Data can be quantitative or qualitative. Quantitative data are presented in values, whereas 
qualitative data are not. Qualitative data can take many forms, such as words, stories, obser-
vations, pictures, and audio. The distinction between qualitative and quantitative data 
is not as black-and-white as it seems. Quantitative data may be the result of quantifying 
</p>
<p>3</p>
<p/>
<div class="annotation"><a href="http://www.bls.gov/cex">http://www.bls.gov/cex</a></div>
</div>
<div class="page"><p/>
<p>331
3.3 &middot; Unit of Analysis
</p>
<p>qualitative data. For example, Twitter feeds or Facebook posts, produce qualitative data. 
Market researchers can code attributes of the data, which describe a particular character-
istic, thereby turning it into quantitative data. Think, for example, of how people respond 
to a new product in an interview. We can code the data by setting neutral responses to 0, 
somewhat positive responses to 1, positive responses to 2, and very positive responses 
to 3. We have therefore turned qualitative data into quantitative data. Box 3.2 shows an 
example of how to code qualitative data. Also see  7 Chap.&nbsp;5 for more information on 
qualitative coding.
</p>
<p>Qualitative data&rsquo;s biggest strength is their richness, as they have the potential to offer 
detailed insights into respondents&rsquo; perceptions, attitudes, and intentions. However, their 
downside is that qualitative data can be interpreted in many ways. Thus, the process 
of interpreting qualitative data is subjective. To reduce subjectivity, (multiple) trained 
researchers should code qualitative data. The distinction between quantitative and qual-
itative data is closely related to that between quantitative and qualitative research, which 
we discuss in Box 3.3. Most people think of quantitative data as being more factual and 
precise than qualitative data, but this is not necessarily true. Rather, how well qualitative 
data have been collected and/or coded into quantitative data is important.
</p>
<p>3.3 Unit of Analysis
</p>
<p>The unit of analysis is the level at which a variable is measured. Researchers often ignore 
this aspect, but it is crucial because it determines what we can learn from the data. Typical 
measurement levels include that of the respondents, customers, stores, companies, or coun-
tries. It is best to use data at the lowest possible level, because this provides more detail. If 
we need these data at another level, we can aggregate them. Aggregating data means that 
we sum up a variable at a lower level to create a variable at a higher level. For example, if we 
know how many cars all car dealers in a country sell, we can take the sum of all the dealer 
</p>
<p>Box 3.2&nbsp;Coding qualitative data
</p>
<p>In 2016 Toyota launched new Prius, the Prius Prime (www.toyota.com/priusprime/) and Facebook 
</p>
<p>reactions were divided. Here are some examples of Facebook posts:
</p>
<p> 5 &ldquo;Love it! But why only 2 seats at the back? Is there any technical reason for that?&rdquo;
 5 &ldquo;Wondering if leather seats are offered? The shape of the seats looks super comfy!&rdquo;
 5 &ldquo;Here&rsquo;s that big black grill on yet another Toyota. Will be very glad when this &lsquo;fashion faze&rsquo; is over.&rdquo;
</p>
<p>One way of structuring these responses is to consider the attributes mentioned in the posts. After 
</p>
<p>reading them, you may find that, for example, the seat and styling are attributes. You can then 
</p>
<p>categorize in respect of each post whether the response was negative, neutral, or positive. If you 
</p>
<p>add the actual response, this can later help identify the aspect the posts liked (or disliked). As you 
</p>
<p>can see, we have now turned qualitative data into quantitative data!
</p>
<p>Attribute Negative Neutral Positive
</p>
<p>Seats 1-why only two seats? 2-are leather seats 
</p>
<p>offered?
</p>
<p>2-shape looks super comfy!
</p>
<p>Styling 3-big black grill 1-love it!</p>
<p/>
<div class="annotation"><a href="http://www.toyota.com/priusprime/">http://www.toyota.com/priusprime/</a></div>
</div>
<div class="page"><p/>
<p>32 Chapter 3 &middot; Data
</p>
<p>sales, to create a variable measuring countrywide car sales. Aggregation is not possible if 
we have incomplete or missing data at the lower levels.
</p>
<p>3.4 Dependence of Observations
</p>
<p>A key issue for any data is the degree to which observations are related, or the dependence 
of observations. If we have exactly one observation from each individual, store, company, 
or country, we label the observations independent. That is, the observations are unre-
lated. If we have multiple observations of each individual, store, company, or country, we 
label them dependent. For example, we could ask respondents to rate a type of Cola, then 
show them an advertisement, and again ask them to rate the same type of Cola. Although 
the advertisement may influence the respondents, it is likely that the first response and 
second response will be related. That is, if the respondents first rated the Cola negatively, 
the chance is higher that they will continue to rate the Cola negative rather than positive 
after the advertisement. If the observations are dependent, this often impacts the type of 
analysis we should use. For example, in 7 Chap.&nbsp;6, we discuss the difference between the 
independent samples t-test (for independent observations) and the paired samples t-test 
(for dependent observations).
</p>
<p>Box 3.3 Quantitative research and qualitative research
</p>
<p>Market researchers often label themselves as either quantitative or qualitative researchers. 
</p>
<p>The two types of researchers use different methodologies, different types of data, and focus 
</p>
<p>on different research questions. Most people regard the difference between qualitative and 
</p>
<p>quantitative as the difference between numbers and words, with quantitative researchers 
</p>
<p>focusing on numbers and qualitative researchers on words. This distinction is not accurate, 
</p>
<p>as many qualitative researchers use numbers in their analyses. The distinction should instead 
</p>
<p>depend on when the information is quantified. If we know the values that may occur in the 
</p>
<p>data even before the research starts, we conduct quantitative research. If we only know this 
</p>
<p>after the data have been collected, we conduct qualitative research. Think of it in this way: If we 
</p>
<p>ask survey questions and use a few closed questions, such as &ldquo;Is this product of good quality?,&rdquo; 
</p>
<p>and the respondents can either choose &ldquo;Completely disagree,&rdquo; &ldquo;Somewhat disagree,&rdquo; &ldquo;Neutral,&rdquo; 
</p>
<p>&ldquo;Somewhat agree,&rdquo; and &ldquo;Completely agree,&rdquo; we know that the data we will obtain from this  
</p>
<p>will&mdash;at most&mdash;contain five different values. Because we know all possible values beforehand, 
</p>
<p>the data are quantified beforehand. If, on the other hand, we ask someone &ldquo;Is this product 
</p>
<p>of good quality?,&rdquo; he or she could give many different answers, such as &ldquo;Yes,&rdquo; &ldquo;No,&rdquo; &ldquo;Perhaps,&rdquo; 
</p>
<p>&ldquo;Last time yes, but lately &hellip; &rdquo;. This means we have no idea what the possible answer values 
</p>
<p>are. Therefore, these data are qualitative. We can, however, recode these qualitative data, for 
</p>
<p>example, as described in Box 3.2, and assign values to each response. Thus, we quantify the data, 
</p>
<p>allowing further statistical analysis.
</p>
<p>Qualitative research accounts for 15&nbsp;% of money spent in the market research industry, with 
</p>
<p>quantitative research making up the rest (ESOMAR 2017). Practically, market research is often 
</p>
<p>hard to categorize as qualitative or quantitative, as it may include elements of both. Research 
</p>
<p>that includes both elements is sometimes called hybrid market research, fused market research, or 
</p>
<p>simply mixed methodology.
</p>
<p>3</p>
<p/>
</div>
<div class="page"><p/>
<p>333
3.6 &middot; Measurement Scaling
</p>
<p>3.5 Dependent and Independent Variables
</p>
<p>Dependent variables represent the outcome that market researchers study, while indepen-
dent variables are those used to explain the dependent variable(s). For example, if we use 
the amount of advertising to explain sales, then advertising is the independent variable 
and sales the dependent.
</p>
<p>This distinction is artificial, as all variables depend on other variables. For example, 
the amount of advertising depends on how important the product is for a company, the 
company&rsquo;s strategy, and other factors. However, this distinction is frequently used in the 
application of statistical methods. When researching relationships between variables, we, 
on the basis of theory and practical considerations, need to distinguish between the depen-
dent and the independent variables beforehand.
</p>
<p>3.6 Measurement Scaling
</p>
<p>Not all data are equal! For example, we can calculate the respondents&rsquo; average age in 
.&nbsp;Table&nbsp;3.1. However, if we would have coded the color of a car as black&nbsp;=&nbsp;1, blue&nbsp;=&nbsp;2, 
silver&nbsp;=&nbsp;3 it would not make any sense to calculate the average. Why is this? The values 
that we have assigned 1, 2, and 3 are arbitrary; we could just as well have changed these 
value for any other. Therefore, choosing a different coding would lead to different results, 
which is meaningless. Measurement scaling refers to two things: the variables we use for 
measuring a certain construct (see discussion above) and the level at which a variable is 
measured, which we discuss in this section. This can be highly confusing! There are four 
levels of measurement :
</p>
<p> 4 Nominal scale,
 4 ordinal scale,
 4 interval scale, and
 4 ratio scale.
</p>
<p>These scales relate to how we quantify what we measure. It is vital to know the scale on 
which something is measured, because, as the gender example above illustrates, the mea-
surement scale determines the analysis techniques we can, or cannot, use. For example, 
if the consumer preference for the color of an airline seat is coded as blue&nbsp;=&nbsp;0, black&nbsp;=&nbsp;1, 
brown&nbsp;=&nbsp;2, it makes no sense to calculate respondents&rsquo; average preference. We will return 
to this issue in 7 Chap.&nbsp;5 and beyond. However, even when we know the scale, be aware 
that, as . Fig.&nbsp;3.1 shows, meaningful calculations are not always possible!
</p>
<p>The nominal scale is the most basic level at which we can measure something. Essen-
tially, if we use a nominal scale, we substitute a word for a numerical value. For example, 
we could code the color of each Prius sold: black&nbsp;=&nbsp;1, blue&nbsp;=&nbsp;2, silver&nbsp;=&nbsp;3. In this example, 
the numerical values represent nothing more than a label.
</p>
<p>The ordinal scale provides more information. If a variable is measured on an ordinal 
scale, increases or decreases in values give meaningful information. For example, if we 
code the Prius version people bought as the first generation&nbsp;=&nbsp;1, second generation&nbsp;=&nbsp;2, </p>
<p/>
</div>
<div class="page"><p/>
<p>34 Chapter 3 &middot; Data
</p>
<p>third generation&nbsp;=&nbsp;3, and fourth generation&nbsp;=&nbsp;4, we know whether the model is more 
recent. The ordinal scale provides information about the order of our observations. 
However, we do not know if the differences in the order are equally spaced. That is, we 
do not know if the difference between first generation and second generation is the same 
as between second and third generation, even though the difference in values (1&ndash;2 and 
2&ndash;3) is equal.
</p>
<p>If something is measured on an interval scale, we have precise information on the rank 
order at which something is measured and we can interpret the magnitude of the differ-
ences in values directly. For example, if the temperature in a car showroom is 23&deg;C, we 
know that if it drops to 20&deg;C, the difference is exactly 3&deg;C. This difference of 3&deg;C is the 
same as the increase from 23 to 26&deg;C. This exact &ldquo;spacing&rdquo; is called equidistance. Equidis-
tant scales are necessary for some analysis techniques, such as factor analysis (discussed in 
7 &nbsp;Chap.&nbsp;8). What the interval scale does not give us, is an absolute zero point. If the tem-
perature is 0&deg;C it may feel cold, but the temperature can drop further. The value of 0 does 
not therefore mean that there is no temperature at all.
</p>
<p>The ratio scale provides the most information. If something is measured on a ratio 
scale, we know that a value of 0&nbsp;means that that the attribute of that particular variable is 
not present. For example, if a dealer sells zero Prius cars (value&nbsp;=&nbsp;0) then he or she really 
sells none. Or, if we spend no money on advertising a Prius (value&nbsp;=&nbsp;0), we really spend no 
money. Therefore, the origin of the variable is equal to 0.
</p>
<p>While it is relatively easy to distinguish between the nominal and the interval scales, it 
is sometimes hard to see the difference between the interval and the ratio scales. The differ-
ence between the interval and the ratio scales can be ignored in most statistical methods. 
. Table 3.3 shows the differences between the four scales we just discussed.
</p>
<p>. Fig.&nbsp;3.1 Meaningless! 
(Picture by MikeGogulski)
</p>
<p>3</p>
<p/>
</div>
<div class="page"><p/>
<p>335
3.7 &middot; Validity and Reliability
</p>
<p>3.7 Validity and Reliability
</p>
<p>In any market research process, it is paramount to use &ldquo;good&rdquo; measures. Good measures 
are those that measure what they are supposed to measure and do so consistently. For 
example, if we are interested in knowing whether customers like a new TV commercial, 
we could show a commercial and ask the following two questions afterwards:
1. &ldquo;Did you enjoy watching the commercial?,&rdquo; and
2. &ldquo;Did the commercial provide the essential information required for a purchase 
</p>
<p>decision?&rdquo;
</p>
<p>How do we know if these questions really measure whether or not the viewers liked the 
commercial? We can think of this as a measurement problem through which we relate 
what we want to measure&mdash;whether existing customers like a new TV commercial&mdash;with 
what we actually measure in terms of the questions we ask. If these relate perfectly, our 
actual measurement is equal to what we intend to measure and we have no measurement 
error. If these do not relate perfectly, we have measurement error.
</p>
<p>This measurement error can be divided into a systematic error and a random error. We 
can express this as follows, where XO stands for the observed score (i.e., what the custom-
ers indicated), XT for the true score (i.e., what the customers&rsquo; true liking of the commer-
cial is), ES for the systematic error, and ER for the random error.
</p>
<p>X
O
</p>
<p>X
T
</p>
<p>E
S
</p>
<p>E
R
</p>
<p>= + +
</p>
<p>The systematic error is a measurement error through which we consistently measure higher 
or lower than we want to measure. If we were to ask customers, for example, to evaluate 
a TV commercial and offer them remuneration in return, they may provide more favor-
able information than they would otherwise have. This may cause us to think that the TV 
commercial is systematically more enjoyable than it is in reality. There may also be random 
errors. Some customers may be having a good day and indicate that they like a commer-
cial, whereas others, who are having a bad day, may do the opposite.
</p>
<p>Systematic errors cause the actual measurement to be consistently higher or lower than 
what it should be. On the other hand, random error causes (random) variation between 
what we actually measure and what we want to measure.
</p>
<p>. Table 3.3 Measurement Scaling
</p>
<p>Label Order Differences Origin is 0
</p>
<p>Nominal scale ✓
</p>
<p>Ordinal scale ✓ ✓
</p>
<p>Interval scale ✓ ✓ ✓
</p>
<p>Ratio scale ✓ ✓ ✓ ✓</p>
<p/>
</div>
<div class="page"><p/>
<p>36 Chapter 3 &middot; Data
</p>
<p>The systematic and random error concepts are important because they relate to a mea-
sure&rsquo;s validity and reliability. Validity refers to whether we are measuring what we want to 
measure and, therefore, to a situation where the systematic error ES is small. Reliability is 
the degree to which what we measure is free from random error and therefore relates to 
a situation where the ER is zero. In . Fig.&nbsp;3.2, we illustrate the difference between reliabil-
ity and validity by means of a target comparison. In this analogy, different measurements 
(e.g., of a customer&rsquo;s satisfaction with a specific service) are compared to arrows shot at a 
target. To measure each score, we have five measurements (indicated by the black circles), 
which correspond to, for example, questions asked in a survey. The cross indicates their 
average. Validity describes the cross&rsquo;s proximity to the bull&rsquo;s eye at the target center. The 
closer the average to the true score, the higher the validity. If several arrows are fired, reli-
ability is the degree to which the arrows are apart. If all the arrows are close together, the 
measure is reliable, even though it is not necessarily near the bull&rsquo;s eye. This corresponds 
to the upper left box where we have a scenario in which the measure is reliable, but not 
valid. In the upper right box, both reliability and validity are given. In the lower left box, 
though, we have a situation in which the measure is neither reliable nor valid. This is obvi-
ously because the repeated measurements are scattered around and the average does not 
match the true score. However, even if the latter were the case (i.e., if the cross were in the 
bull&rsquo;s eye), we would still not consider the measure valid. An unreliable measure can never 
be valid. If we repeated the measurement, say, five more times, the random error would 
probably shift the cross to a different position. Reliability is, therefore, a necessary condi-
tion for validity. This is also why the scenario that is not reliable/valid (lower right box) is 
not included, as it is not possible for a measure to be valid but not reliable.
</p>
<p>R
e
</p>
<p>li
a
</p>
<p>b
le
</p>
<p>N
o
</p>
<p>t 
re
</p>
<p>li
a
</p>
<p>b
le
</p>
<p>Not valid Valid
</p>
<p>. Fig.&nbsp;3.2 Validity and 
reliability
</p>
<p>3</p>
<p/>
</div>
<div class="page"><p/>
<p>337
3.7 &middot; Validity and Reliability
</p>
<p>3.7.1 Types of Validity
</p>
<p>For some variables, such as length or income, we can objectively verify what the true score 
is. For constructs, such as satisfaction, loyalty and brand trust, this is impossible. From a 
philosophical point of view, one could even argue that there is no &ldquo;true&rdquo; score for a con-
struct. So how do we know if a measure is valid? Because there is no objective way of veri-
fying what we are measuring, several forms of validity have been developed, including face, 
content, predictive, criterion, and discriminant validity (Netemeyer et al. 2003). Research-
ers frequently summarize these validity types under the umbrella term construct validity, 
which relates to the correspondence between a measure at the conceptual level and a pur-
ported measure. The different types of validity help us understand the association between 
what we should measure and what we actually measure, thereby increasing the likelihood 
of adequately measuring the latent concept under consideration.
</p>
<p> 4 Face validity is an absolute minimum requirement for a variable to be valid and 
refers to whether a variable reflects what you want to measure. Essentially, face 
validity subjectively assesses if a measure makes sense. For example, if you want to 
measure trust, using items such as &ldquo;this company is honest and truthful&rdquo; makes a lot 
of sense, whereas &ldquo;this company is not well known&rdquo; makes little sense. Researchers 
should agree on face validity before starting the actual measurement. Face validity 
is usually determined by using a sample of experts who discuss and agree on the 
degree of face validity (this is also referred to as expert validity).
 4 Content validity is strongly related to face validity but is more formalized. To assess 
</p>
<p>content validity, researchers need to first define what they want to measure and 
discuss what is included in the definition and what not. For example, trust between 
businesses is often defined as the extent to which a firm believes that its exchange 
partner is honest and/or benevolent (Geyskens et al. 1998). This definition clearly 
indicates what should be mentioned in the questions used to measure trust (honesty 
and benevolence). After researchers have defined what they want to measure, items 
have to be developed that relate closely to the definition. Consequently, content 
validity is mostly achieved prior to the actual measurement.
 4 Predictive validity requires a measure to be highly correlated (see 7 Chap.&nbsp;5 for an 
</p>
<p>introduction to correlations) with an outcome variable, measured at a later point in 
time, to which it is conceptually strongly related. For example, loyalty should lead to 
people purchasing a product in the future. Similarly, a measure of satisfaction should 
be predictive future purchases. Assessing predictive validity requires collecting data 
at two points in time and therefore requires a greater effort. If both measures (i.e., 
the one to be evaluated and the outcome variable) are measured at the same point in 
time, we call this criterion validity.
 4 Discriminant validity ensures that a measure is empirically unique and represents 
</p>
<p>phenomena of interest that other measures in a model do not capture (e.g., Henseler 
et al. 2015). For example, customer satisfaction and customer loyalty are two distinct 
latent concepts. Discriminant validity requires the constructs used to measure 
these two concepts to also be empirically distinct (i.e., they should not correlate too 
highly).</p>
<p/>
</div>
<div class="page"><p/>
<p>38 Chapter 3 &middot; Data
</p>
<p> 4 Nomological validity is the degree to which a construct behaves as it should in a 
system of related constructs. For example, customer expectations, perceived quality, 
and value have a significant influence on customer satisfaction. Similarly, satis-
faction generally relates positively to customer loyalty. As such, you would expect 
the measure of satisfaction that you are evaluating to correlate with this measure.
</p>
<p>3.7.2 Types of Reliability
</p>
<p>How do we know if a measure is reliable? Three key factors are used to assess reliability: 
test-retest reliability, internal consistency reliability, and inter-rater reliability (Mitchell 
and Jolley 2013).
</p>
<p>Test&ndash;retest reliability means that if we measure something twice (also called the stability 
of the measurement), we expect similar outcomes. The stability of measurement requires 
a market researcher to have collected two data samples, is therefore costly, and could 
prolong the research process. Operationally, researchers administer the same test to the 
same sample on two different occasions and evaluate how strongly the measurements are 
correlated. We would expect the two measurements to correlate highly if a measure is reli-
able. This approach is not without problems, as it is often hard, if not impossible, to survey 
the same people twice. Furthermore, respondents may learn from past surveys, leading 
to practice effects. In addition, it may be easier to recall events the second time a survey is 
administered. Moreover, test&ndash;retest approaches do not work if a survey concentrates on 
specific time points. If we ask respondents to provide information on their last restaurant 
experience, the second test might relate to a different restaurant experience. Thus, test&ndash;
retest reliability can only be assessed in terms of variables that are stable over time.
</p>
<p>Internal consistency reliability is by far the most common way of assessing reliability. 
Internal consistency reliability requires researchers to simultaneously use multiple items 
to measure the same concept. Think, for example, of the set of questions commonly used 
to measure brand trust (i.e., &ldquo;This brand&rsquo;s product claims are believable,&rdquo; &ldquo;This brand deliv-
ers what it promises,&rdquo; and &ldquo;This brand has a name that you can trust&rdquo;). If these items relate 
strongly, there is a considerable degree of internal consistency. There are several ways to 
calculate indices of internal consistency, including split-half reliability and Cronbach&rsquo;s α 
(pronounced as alpha), which we discuss in 7 Chap.&nbsp;8.
</p>
<p>Inter-rater reliability is used to assess the reliability of secondary data or qualitative 
data. If you want to identify, for example, the most ethical organizations in an industry, 
you could ask several experts to provide a rating and then calculate the degree to which 
their answers relate.
</p>
<p>3.8 Population and Sampling
</p>
<p>A population is the group of units about which we want to make judgments. These units 
can be groups of individuals, customers, companies, products, or just about any subject 
in which you are interested. Populations can be defined very broadly, such as the people 
</p>
<p>3</p>
<p/>
</div>
<div class="page"><p/>
<p>339
3.8 &middot; Population and Sampling
</p>
<p>living in Canada, or very narrowly, such as the directors of large hospitals in Belgium. 
Both the conducted research and the research goal determine the population&rsquo;s structure.
</p>
<p>Sampling is the process by which we select cases from a population. The most import-
ant aspect of sampling is that the selected sample is representative of the population. Rep-
resentative means that the characteristics of the sample closely match those of the popu-
lation. In Box 3.4, we discuss how to determine whether a sample is representative of the 
population. When we develop a sampling strategy, we have three key choices:
 4 Census,
 4 probability sampling, and
 4 non-probability sampling.
</p>
<p>If we are lucky and somehow manage to include every unit of the population in our study, 
we have conducted a census. Thus, strictly speaking, this is not a sampling strategy. Census 
studies are rare, because they are very costly and because missing just a small part of the 
population can have dramatic consequences. For example, if we were to conduct a census 
study of directors of Luxemburg banks, we may miss a few because they were too busy to 
</p>
<p>Box 3.4 Do I have a representative sample?
</p>
<p>It is important for market researchers that their sample is representative of the population. How 
</p>
<p>can we determine whether this is so?
</p>
<p> 5 The best way to test whether the sample relates to the population is to use a database with 
information on the population (or to draw the sample from such databases). For example, 
</p>
<p>the Amadeus database (https://www.bvdinfo.com/) provides information on public and 
</p>
<p>private companies around the world at the population level. We can (statistically) compare 
</p>
<p>the information from these databases to the selected sample. However, this approach 
</p>
<p>can only support the tested variables&rsquo; representativeness; that is, the specific representa-
</p>
<p>tiveness. Conversely, global representativeness&mdash;that is, matching the distribution of all the 
</p>
<p>characteristics of interest to the research question, but which lie outside their scope&mdash;cannot 
</p>
<p>be achieved without a census (Kaplan 1964).
</p>
<p> 5 You can use (industry) experts to judge the quality of your sample. They may look at issues 
such as the type and proportion of organizations in your sample and population.
</p>
<p> 5 To check whether the responses of people included in your research differ significantly from 
those of non-respondents (which would lead to your sample not being representative), 
</p>
<p>you can use the Armstrong and Overton procedure. This procedure calls for comparing 
the first 50&nbsp;% of respondents to the last 50&nbsp;% in respect of key demographic variables. The 
</p>
<p>idea behind this procedure is that later respondents more closely match the characteristics 
</p>
<p>of non-respondents. If these differences are not significant (e.g., through hypothesis tests, 
</p>
<p>discussed in 7 Chap.&nbsp;6), we find some support for there being no significant response bias 
(see Armstrong and Overton 1977). When the survey design includes multiple waves (e.g., 
</p>
<p>the first wave of the survey is web-based and the second wave is by phone), this procedure 
</p>
<p>is generally amended by comparing the last wave of respondents in a survey design to the 
</p>
<p>earlier waves. There is some evidence that this procedure is better than Armstrong and 
</p>
<p>Overton&rsquo;s original procedure (Lindner et al. 2001).
</p>
<p> 5 Using follow-up procedures, a small sample of randomly chosen non-respondents can again 
be contacted to request their cooperation. This small sample can be compared against the 
</p>
<p>responses obtained earlier to test for differences.</p>
<p/>
<div class="annotation"><a href="https://www.bvdinfo.com/">https://www.bvdinfo.com/</a></div>
</div>
<div class="page"><p/>
<p>40 Chapter 3 &middot; Data
</p>
<p>participate. If these busy directors happen to be those of the very largest companies, any 
information we collect would underestimate the effects of variables that are more import-
ant at large banks. Census studies work best if the population is small, well-defined, and 
accessible. Sometimes census studies are also conducted for specific reasons. For example, 
the US Census Bureau is required to hold a census of all people resident in the US every 
10&nbsp;years. Check out the US Census Bureau&rsquo;s YouTube channel (Box 3.5) to find out more 
about the US Census Bureau.
</p>
<p>If we select part of the population, we can distinguish two types of approaches: prob-
ability sampling and non-probability sampling. . Fig.&nbsp;3.3 provides an overview of the 
 different sampling procedures, which we will discuss in the following sections.
</p>
<p>Box 3.5 The US census
</p>
<p>&copy; tattywelshie/Getty Images/iStock
</p>
<p>https://www.youtube.com/watch?v=eBk3oanOfdY
</p>
<p>Probability sampling 
</p>
<p>Sampling procedures 
</p>
<p>Simple random sampling 
</p>
<p>Systematic sampling 
</p>
<p>Stratified sampling 
</p>
<p>Cluster sampling 
</p>
<p>Non-probability sampling 
</p>
<p>Judgmental sampling 
</p>
<p>Snowball sampling 
</p>
<p>Quota sampling 
</p>
<p>Other types of convenience
</p>
<p>sampling 
</p>
<p>. Fig.&nbsp;3.3 Sampling 
procedures
</p>
<p>3</p>
<p/>
<div class="annotation"><a href="https://www.youtube.com/watch?v=eBk3oanOfdY">https://www.youtube.com/watch?v=eBk3oanOfdY</a></div>
</div>
<div class="page"><p/>
<p>341
3.8 &middot; Population and Sampling
</p>
<p>3.8.1 Probability Sampling
</p>
<p>Probability sampling approaches provide every individual in the population with a chance 
(not equal to zero) of being included in the sample (Levy and Lemeshow 2013). This is 
often achieved by using an accurate sampling frame, which is a list of individuals in the 
population. There are various sampling frames, such as Dun &amp; Bradstreet&rsquo;s Selectory 
database (includes executives and companies), the Mint databases (includes companies 
in North and South America, Italy, Korea, the Netherlands, and the UK), and telephone 
directories. These sampling frames rarely cover the population of interest completely 
and often include outdated information, but are frequently used due to their ease of use 
and availability. If the sampling frame and population are very similar, we have little sam-
pling error, which is the degree to which sample frames represent the population. Start-
ing with a good-quality sampling frame, we can use several methods to select units from 
it (Sarstedt et al. 2018).
</p>
<p>The easiest way is to use simple random sampling, which is achieved by randomly 
selecting the number of cases required. This can be achieved by using specialized 
software.
</p>
<p>Systematic sampling uses a different procedure. We first randomize the order of all the 
observations, number them and, finally, select every nth observation. For example, if our 
sampling frame consists of 1000 firms and we wish to select just 100 firms, we could select 
the 1st observation, the 11th, the 21st, etc. until we reach the end of the sampling frame 
and have our 100 observations.
</p>
<p>Stratified sampling and cluster sampling are more elaborate techniques of probability 
sampling requiring us to divide the sampling frame into different groups. When we use 
stratified sampling, we divide the population into several homogeneous groups called 
strata. These strata are based on key sample characteristics, such as different depart-
ments in organizations, or the areas in which consumers live. Subsequently, we draw a 
random number of observations from each stratum. While stratified sampling is more 
complex and requires accurate knowledge of the sampling frame and population, it also 
helps ensure that the sampling frame&rsquo;s characteristics are similar to those of the sample.
</p>
<p>Cluster sampling requires dividing the population into different heterogeneous groups, 
with each group&rsquo;s characteristics similar to those of the population. For example, we can 
divide a country&rsquo;s consumers into different provinces, counties, and councils. Several of 
these groups could have key characteristics (e.g., income, political preference, household 
composition) in common, which are very similar (representative of) to those of the pop-
ulation. We can select one or more of these representative groups and use random sam-
pling to select observations that represent this group. This technique requires knowledge 
of the sampling frame and population, but is convenient because gathering data from one 
group is cheaper and less time-consuming.
</p>
<p>Generally, all probability sampling methods allow for drawing representative samples 
from the target population. However, simple random sampling and stratified sampling 
are considered superior in terms of drawing representative samples. For a detailed discus-
sion, see Sarstedt et al. (2018).</p>
<p/>
</div>
<div class="page"><p/>
<p>42 Chapter 3 &middot; Data
</p>
<p>3.8.2 Non-probability Sampling
</p>
<p>Non-probability sampling procedures do not give every individual in the population 
an equal chance of being included in the sample (Levy and Lemeshow 2013). This is a 
drawback because the resulting sample is most certainly not representative of the pop-
ulation, which may bias the subsequent analyses&rsquo; results. Nevertheless, non-probability 
sampling procedures are frequently used as they are easily executed, and are normally 
less costly than probability sampling methods. Popular non-probability sampling pro-
cedures include judgmental sampling, snowball sampling, and quota sampling (Sarst-
edt et al. 2018).
</p>
<p>Judgmental sampling is based on researchers taking an informed guess regarding which 
individuals should be included. For example, research companies often have panels of 
respondents who are continuously used in research. Asking these people to participate in 
a new study may provide useful information if we know, from experience, that the panel 
has little sampling frame error.
</p>
<p>Snowball sampling involves existing study participants to recruit other individuals 
from among their acquaintances. Snowball sampling is predominantly used if access to 
individuals is difficult. People such as directors, doctors, and high-level managers often 
have little time and are, consequently, difficult to involve. If we can ask just a few of them 
to provide the names and the details of others in a similar position, we can expand our 
sample quickly and then access them. Similarly, if you post a link to an online questionnaire 
on your LinkedIn or Facebook page (or send out a link via email) and ask your friends to 
share it with others, this is snowball sampling.
</p>
<p>Quota sampling occurs when we select observations for the sample that are based 
on pre-specified characteristics, resulting in the total sample having the same distri-
bution of characteristics assumed to exist in the population being studied. In other 
words, the researcher aims to represent the major characteristics of the population by 
sampling a proportional amount of each (which makes the approach similar to strat-
ified sampling). Let&rsquo;s say, for example, that you want to obtain a quota sample of 100 
people based on gender. First, you need to find what proportion of the population is 
men and what women. If you find that the larger population is 40&nbsp;% women and 60&nbsp;% 
men, you need a sample of 40&nbsp;women and 60&nbsp;men for a total of 100 respondents. You 
then start sampling and continue until you have reached exactly the same proportions 
and then stop. Consequently, if you already have 40&nbsp;women in your sample, but not yet 
60&nbsp;men, you continue to sample men and discard any female respondents that come 
along. However, since the selection of the observations does not occur randomly, this 
makes quota sampling a non-probability technique. That is, once the quota has been 
fulfilled for a certain characteristic (e.g., females), you no longer allow any observa-
tions with this specific characteristic in the sample. This systematic component of the 
sampling approach can introduce a sampling error. Nevertheless, quota sampling is 
very effective and inexpensive, making it the most important sampling procedure in 
practitioner market research.
</p>
<p>Convenience sampling is a catch-all term for methods (including the three non-prob-
ability sampling techniques just described) in which the researcher draws a sample from 
that part of the population that is close at hand. For example, we can use mall intercepts to 
ask people in a shopping mall if they want to fill out a survey. The researcher&rsquo;s control over 
who ends up in the sample is limited and influenced by situational factors.
</p>
<p>3</p>
<p/>
</div>
<div class="page"><p/>
<p>343
3.9 &middot; Sample Sizes
</p>
<p>3.8.3 Probability or Non-probability Sampling?
</p>
<p>Probability sampling methods are recommended, as they result in representative samples. 
Nevertheless, judgmental and, especially, quota sampling might also lead to (specific) rep-
resentativeness (e.g., Moser and Stuart 1953; Stephenson 1979). However, both methods&rsquo; 
ability to be representative depends strongly on the researcher&rsquo;s knowledge (Kukull and 
Ganguli 2012). Only when the researcher considers all the factors that have a significant 
bearing on the effect under study, will these methods lead to a representative sample. 
However, snowball sampling never leads to a representative sample, as the entire process 
depends on the participants&rsquo; referrals. Likewise, convenience sampling will almost never 
yield a representative sample, because observations are only selected if they can be accessed 
easily and conveniently. See Sarstedt et al. (2018) for further details.
</p>
<p>3.9 Sample Sizes
</p>
<p>After determining the sampling procedure, we have to determine the sample size. Larger 
sample sizes increase the precision of the research but are also much more expensive to 
collect. The gains in precision decrease as the sample size increases (in Box 6.3&nbsp;we discuss 
the question whether a sample size can be too large in the context of significance testing). 
It may seem surprising that relatively small sample sizes are precise, but the strength 
of samples comes from selecting samples accurately, rather their size. Furthermore, the 
required sample size has very little relation to the population size. That is, a sample of 100 
employees from a company with 100,000 employees can be nearly as accurate as selecting 
100 employees from a company with 1000 employees.
</p>
<p>There are some problems with selecting sample sizes. The first is that market research 
companies often push their clients to accept large sample sizes. Since the fee for market 
research services, such as those offered by Qualtrics or Toluna, is often directly depen-
dent on the sample size, increasing the sample size benefits the market research company. 
Second, if we want to compare different groups, we need to multiply the required sample by 
the number of groups included. That is, if 150 observations are sufficient to measure how 
much people spend on organic food, 2 times 150 observations are necessary to compare 
singles and couples&rsquo; expenditure on organic food.
</p>
<p>The figures mentioned above are net sample sizes; that is, these are the actual (usable) 
number of observations we should have. Owing to non-response (discussed in 7 Chaps.&nbsp;4 
and 5), a multiple of the initial sample size is normally necessary to obtain the desired 
sample size. Before collecting data, we should have an idea of the percentage of respon-
dents we are likely to reach (often high), a percentage estimate of the respondents willing 
to help (often low), as well as a percentage estimate of the respondents likely to fill out the 
survey correctly (often high). For example, if we expect to reach 80&nbsp;% of the identifiable 
respondents, and if 25&nbsp;% are likely to help, and 75&nbsp;% of those who help are likely to fully fill 
out the questionnaire, only 15&nbsp;% (0.80&nbsp;&middot;&nbsp;0.25&nbsp;&middot;&nbsp;0.75) of identifiable respondents are likely 
to provide a usable response. Thus, if we wish to obtain a net sample size of 100, we need 
</p>
<p>to send out
desired sample size
</p>
<p>likely usable responses
</p>
<p>
</p>
<p>

</p>
<p>
</p>
<p>
 = =100 0 15 667/ . surveys. In 7 Chap.&nbsp;4, we will 
</p>
<p>discuss how we can increase response rates (the percentage of people willing to help).</p>
<p/>
</div>
<div class="page"><p/>
<p>44 Chapter 3 &middot; Data
</p>
<p>3.10 Review Questions
</p>
<p> 1. Explain the difference between items and constructs.
 2. What is the difference between reflective and formative constructs?
 3. Explain the difference between quantitative and qualitative data and give examples 
</p>
<p>of each type.
 4. What is the scale on which the following variables are measured?
</p>
<p> 4 The amount of money a customer spends on shoes.
 4 A product&rsquo;s country-of-origin.
 4 The number of times an individual makes a complaint.
 4 A test&rsquo;s grades.
 4 The color of a mobile phone.
</p>
<p> 5. Try to find two websites offering secondary data and discuss the kind of data 
described. Are these qualitative or quantitative data? What is the unit of analysis and 
how are the data measured?
</p>
<p> 6. What are &ldquo;good data&rdquo;?
 7. Discuss the concepts reliability and validity. How do they relate to each other?
 8. Please comment on the following statement: &ldquo;Face and content validity are essen-
</p>
<p>tially the same.&rdquo;
 9. What is the difference between predictive and criterion validity?
10. Imagine you have just been asked to execute a market research study to estimate 
</p>
<p>the market for notebooks priced $300 or less. What sampling approach would you 
propose to the client?
</p>
<p>11. Imagine that a university decides to evaluate their students&rsquo; satisfaction. To do so, 
employees issue every 10th student at the student cafeteria on one weekday with 
a questionnaire. Which type of sampling is conducted in this situation? Can the 
resulting sample be representative of the student population?
</p>
<p>References
</p>
<p>Armstrong, J. S., &amp; Overton, T. S. (1977). Estimating nonresponse bias in mail surveys. Journal of Marketing 
</p>
<p>Research, 14(3), 396&ndash;403.
</p>
<p>Bearden, W. O., Netemeyer, R. G., &amp; Haws, K. L. (2011). Handbook of marketing scales. Multi-item measures 
</p>
<p>for marketing and consumer behavior research (3rd ed.). Thousand Oaks, CA: Sage.
</p>
<p>Bollen, K. A. (2002). Latent variables in psychology and the social sciences. Annual Review of Psychology, 
</p>
<p>53(1), 605&ndash;634.
</p>
<p>Bollen, K. A., &amp; Diamantopoulos, A. (2017). In defense of causal-formative indicators: A minority report. 
</p>
<p>Psychological Methods, 22(3), 581&ndash;596.
</p>
<p>DeVellis, R. F. (2017). Scale development: Theory and applications (4th ed.). Thousand Oaks, CA: Sage.
</p>
<p>Diamantopoulos, A. (2006). The error term in formative measurement models: Interpretation and model-
</p>
<p>ing implications. Journal of Modelling in Management, 1(1), 7&ndash;17.
</p>
<p>Diamantopoulos, A., Riefler, P., &amp; Roth, K. P. (2008). Advancing formative measurement models. Journal of 
</p>
<p>Business Research, 61(12), 1203&ndash;1218.
</p>
<p>Diamantopoulos, A., Sarstedt, M., Fuchs, C., Wilczynski, P., &amp; Kaiser, S. (2012). Guidelines for choosing 
</p>
<p>between multi-item and single-item scales for construct measurement: A predictive validity per-
</p>
<p>spective. Journal of the Academy of Marketing Science, 40(3), 434&ndash;449.
</p>
<p>3</p>
<p/>
</div>
<div class="page"><p/>
<p>345
References
</p>
<p>Erdem, T., &amp; Swait, J. (2004). Brand credibility, brand consideration, and choice. Journal of Consumer 
</p>
<p>Research, 31(1), 191&ndash;198.
</p>
<p>ESOMAR (2017). Global market research report. Available at: https://www.esomar.org/knowledge-cen-
</p>
<p>ter/library?publication=2892. Accessed 03 May 2018.
</p>
<p>Geyskens, I., Steenkamp, J.-B. E. M., &amp; Kumar, N. (1998). Generalizations about trust in marketing channel 
</p>
<p>relationships using meta-analysis. International Journal of Research in Marketing, 15(3), 223&ndash;248.
</p>
<p>Henseler, J., Ringle, C. M., &amp; Sarstedt, M. (2015). A new criterion for assessing discriminant validity in vari-
</p>
<p>ance-based structural equation modeling. Journal of the Academy of Marketing Science, 43(1), 115&ndash;135.
</p>
<p>Kaplan, A. (1964). The conduct of inquiry: San Francisco, CA: Chandler.
</p>
<p>Kukull, W. A., &amp; Ganguli, M. (2012). Generalizability. The trees, the forest, and the low-hanging fruit. Neu-
</p>
<p>rology, 78(23), 1886&ndash;1891.
</p>
<p>Kuppelwieser, V., &amp; Sarstedt, M. (2014). Confusion about the dimensionality and measurement specifica-
</p>
<p>tion of the future time perspective scale. International Journal of Advertising, 33(1), 113&ndash;136.
</p>
<p>Levy, P. S., &amp; Lemeshow, S. (2013). Sampling of populations: Methods and applications (5th ed.). Hoboken, 
</p>
<p>NJ: John Wiley &amp; Sons.
</p>
<p>Lindner, J. R., Murphy, T. H., &amp; Briers, G. E. (2001). Handling nonresponse in social science research. Journal 
</p>
<p>of Agricultural Education, 42(4), 43&ndash;53.
</p>
<p>Mitchell, M. L., &amp; Jolley, J. M. (2013). Research design explained (8th ed.). Belmont, CA: Wadsworth.
</p>
<p>Moser, C. A., &amp; Stuart, A. (1953). An experimental study of quota sampling. Journal of the Royal Statistical 
</p>
<p>Society. Series A General, 116(4), 349&ndash;405.
</p>
<p>Netemeyer, R. G., Bearden, W. O., &amp; Sharma, S. (2003). Scaling procedures: Issues and applications. Thousand 
</p>
<p>Oaks, CA: Sage.
</p>
<p>Reichheld, F. F. (2003). The one number you need to grow. Harvard Business Review, 81(12), 46&ndash;55.
</p>
<p>Sarstedt, M., &amp; Schloderer, M. P. (2010). Developing a measurement approach for reputation of nonprofit 
</p>
<p>organizations. International Journal of Nonprofit and Voluntary Sector Marketing, 15(3), 276&ndash;299.
</p>
<p>Sarstedt, M., Diamantopoulos, A., Salzberger, T., &amp; Baumgartner, P. (2016a). Selecting single items to mea-
</p>
<p>sure doubly-concrete constructs: A cautionary tale. Journal of Business Research, 69(8), 3159&ndash;3167.
</p>
<p>Sarstedt, M., Diamantopoulos, A., &amp; Salzberger, T. (2016b). Should we use single items? Better not. Journal 
</p>
<p>of Business Research, 69(8), 3199&ndash;3203.
</p>
<p>Sarstedt, M., Hair, J. F., Ringle, C. M., Thiele, K. O., &amp; Gudergan, S. P. (2016c). Estimation issues with PLS and 
</p>
<p>CBSEM: Where the bias lies! Journal of Business Research, 69(10), 3998&ndash;4010.
</p>
<p>Sarstedt, M., Bengart, P., Shaltoni, A. M., &amp; Lehmann, S. (2018). The use of sampling methods in advertising 
</p>
<p>research: A gap between theory and practice. International Journal of Advertising, 37(4), 650&ndash;663.
</p>
<p>Stephenson, C. B. (1979). Probability sampling with quotas: An experiment. Public Opinion Quarterly, 
</p>
<p>43(4), 477&ndash;496.
</p>
<p>Further Reading
</p>
<p>Churchill, G. A. (1979). A paradigm for developing better measures for marketing constructs. Journal of 
</p>
<p>Marketing Research, 16(1), 64&ndash;73.
</p>
<p>Cochran, W. G. (1977). Sampling techniques (3rd ed.). New York, NY: John Wiley and Sons.
</p>
<p>Diamantopoulos, A., &amp; Winklhofer, H. M. (2001). Index construction with formative indicators: an alterna-
</p>
<p>tive to scale development. Journal of Marketing Research, 38(2), 269&ndash;277.
</p>
<p>DeVellis, R. F. (2017). Scale development: Theory and applications (4th ed.). Thousand Oaks, CA: Sage.
</p>
<p>Marketing Scales Database at www.marketingscales.com/search/search.php
</p>
<p>Mitchell, M. L., &amp; Jolley, J. M. (2013). Research design explained (8th ed.). Belmont, CA: Wadsworth.
</p>
<p>Netemeyer, R. G., Bearden, W. O., &amp; Sharma, S. (2003). Scaling procedures: Issues and applications. Thousand 
</p>
<p>Oaks, CA: Sage.
</p>
<p>Paas, L.J., &amp; Morren, M. (2018). Please do not answer if you are reading this: Respondent attention in 
</p>
<p>online panels. Marketing Letters, 29(1), 13&ndash;21.
</p>
<p>Revilla, M., &amp; Ochoa, C. (2018). Alternative methods for selecting web survey samples. International Jour-
</p>
<p>nal of Maret Research, 60(4), 352-265.</p>
<p/>
<div class="annotation"><a href="https://www.esomar.org/knowledge-center/library?publication=2892.">https://www.esomar.org/knowledge-center/library?publication=2892.</a></div>
<div class="annotation"><a href="https://www.esomar.org/knowledge-center/library?publication=2892.">https://www.esomar.org/knowledge-center/library?publication=2892.</a></div>
<div class="annotation"><a href="http://www.marketingscales.com/search/search.php">http://www.marketingscales.com/search/search.php</a></div>
</div>
<div class="page"><p/>
<p>47
</p>
<p>Getting Data
</p>
<p>4.1 Introduction &ndash; 49
</p>
<p>4.2 Secondary Data &ndash; 49
4.2.1 Internal Secondary Data &ndash; 50
</p>
<p>4.2.2 External Secondary Data &ndash; 51
</p>
<p>4.3 Conducting Secondary Data Research &ndash; 55
4.3.1 Assess Availability of Secondary Data &ndash; 55
</p>
<p>4.3.2 Assess Inclusion of Key Variables &ndash; 56
</p>
<p>4.3.3 Assess Construct Validity &ndash; 57
</p>
<p>4.3.4 Assess Sampling &ndash; 57
</p>
<p>4.4 Conducting Primary Data Research &ndash; 58
4.4.1 Collecting Primary Data Through Observations &ndash; 58
</p>
<p>4.4.2 Collecting Quantitative Data: Designing Surveys &ndash; 61
</p>
<p>4.5 Basic Qualitative Research &ndash; 77
4.5.1 In-depth Interviews &ndash; 78
</p>
<p>4.5.2 Projective Techniques &ndash; 79
</p>
<p>4.5.3 Focus Groups &ndash; 80
</p>
<p>4.6 Collecting Primary Data through Experimental 
Research &ndash; 81
</p>
<p>4.6.1 Principles of Experimental Research &ndash; 82
</p>
<p>4.6.2 Experimental Designs &ndash; 83
</p>
<p>4
</p>
<p>Electronic supplementary material
</p>
<p>The online version of this chapter (https://doi.org/10.1007/978-3-662-56707-4_4) contains 
</p>
<p>additional material that is available to authorized users. You can also download the &ldquo;Springer 
</p>
<p>Nature More Media App&rdquo; from the iOS or Android App Store to stream the videos and scan the 
</p>
<p>image containing the &ldquo;Play button&rdquo;.
</p>
<p>&copy; Springer-Verlag GmbH Germany, part of Springer Nature 2019 
</p>
<p>M. Sarstedt, E. Mooi, A Concise Guide to Market Research, Springer Texts in Business  
</p>
<p>and Economics, https://doi.org/10.1007/978-3-662-56707-4_4</p>
<p/>
<div class="annotation"><a href="https://crossmark.crossref.org/dialog/?doi=10.1007/978-3-662-56707-4_4&amp;amp;domain=pdf&amp;amp;date_stamp=2018-9-17">https://crossmark.crossref.org/dialog/?doi=10.1007/978-3-662-56707-4_4&amp;amp;domain=pdf&amp;amp;date_stamp=2018-9-17</a></div>
</div>
<div class="page"><p/>
<p>4.7 Oddjob Airways (Case Study) &ndash; 85
</p>
<p>4.8 Review Questions &ndash; 86
</p>
<p> References &ndash; 87</p>
<p/>
</div>
<div class="page"><p/>
<p>449
4.2 &middot; Secondary Data
</p>
<p>Keywords
Back-translation &bull; Balanced scale &bull; Big data &bull; Closed-ended questions &bull; Constant sum scale &bull; Customer 
</p>
<p>relationship management &bull; Double-barreled questions &bull; Equidistant scale &bull; Ethnography &bull; Experiments &bull; 
</p>
<p>Experimental design &bull; External secondary data &bull; External validity &bull; Face-to-face interviews &bull; Focus groups&nbsp;&bull; 
</p>
<p>Forced-choice scale &bull; Free-choice scale &bull; In-depth interviews &bull; Internal secondary data &bull; Internal validity&nbsp;&bull;  
</p>
<p>Laddering &bull; Likert scale &bull; Mail surveys &bull; Manipulation checks &bull; Means-end approach &bull; Mixed mode &bull; 
</p>
<p>Mystery shopping &bull; Observational studies &bull; Open-ended questions &bull; Personal interviews &bull; Primary data &bull; 
</p>
<p>Projective techniques &bull; Qualitative research &bull; Rank order scales &bull; Reverse-scaled items &bull; Secondary data &bull; 
</p>
<p>Semantic differential scales &bull; Sentence completion &bull; Social desirability bias &bull; Social media analytics &bull; Social 
</p>
<p>networking data &bull; Surveys &bull; Syndicated data &bull; Telephone interviews &bull; Test markets &bull; Treatments &bull; Unbal-
</p>
<p>anced scale &bull; Verbatim items &bull; Visual analogue scale &bull; Web surveys
</p>
<p>4.1 Introduction
</p>
<p>In the previous chapter, we discussed some of the key theoretical concepts and choices 
associated with collecting data. These concepts and choices include validity, reliability, sam-
pling, and sample sizes. We also discussed different types of data. Building on 7&nbsp;Chap.&nbsp;3, this 
chapter discusses the practicalities of collecting data. First, we discuss how to work with 
secondary data. Before collecting primary data, market researchers should always consider 
secondary data, which are often available and do not depend on respondents&rsquo; willingness 
to participate. Although secondary data have already been collected, you usually need to 
spend considerable effort preparing them for analysis, which we discuss first. If you find 
that the required secondary data are unavailable, outdated, or very costly, you may have 
to collect primary data. In the sections that follow, we discuss how to collect primary data 
through observations, surveys, and experiments. In . Fig.&nbsp;4.1, we provide an overview of 
some types of secondary and primary data.
</p>
<p>4.2 Secondary Data
</p>
<p>Secondary data are data that have already been gathered, often for a different research 
purpose and some time ago. Secondary data comprise internal secondary data, external 
secondary data, or a mix of both.
</p>
<p>Learning Objectives
After reading this chapter, you should understand:
</p>
<p> 5 How to find secondary data and decide on their suitability
 5 How to collect primary data
 5 How to design a basic questionnaire
 5 How to design basic experiments
 5 How to design basic qualitative research</p>
<p/>
</div>
<div class="page"><p/>
<p>50 Chapter 4 &middot; Getting Data
</p>
<p>4.2.1 Internal Secondary Data
</p>
<p>Internal secondary data are data that companies compiled for various reporting and analy-
sis purposes. Much of these data have been collected and stored because &ldquo;you can&rsquo;t manage 
what you don&rsquo;t measure.&rdquo;1 Large companies have systems in place, such as Enterprise 
Resource Planning systems (usually abbreviated as ERP systems), in which vast amounts 
of customer, transaction, and performance data are stored. In general, internal secondary 
data comprise the following:
 4 Company records,
 4 sales reports, and
 4 existing research studies.
</p>
<p>Company records are a firm&rsquo;s repository of information. They may contain data from dif-
ferent business functions, such as finance, or Customer Relationship Management (CRM). 
The finance function may provide internal reviews of an organization&rsquo;s financial well- 
being and strategic advice, as it has access to the organization&rsquo;s financial and operational 
</p>
<p>Data collection procedures 
</p>
<p>Primary 
</p>
<p>Ask Observe 
</p>
<p>Secondary 
</p>
<p>External Internal 
</p>
<p>Company  
records 
</p>
<p>Sales reports 
</p>
<p>Existing  
research studies 
</p>
<p>Governments 
</p>
<p>Trade  
associations 
</p>
<p>Market  
research firms 
</p>
<p>Consulting firms 
</p>
<p>(Literature)  
databases 
</p>
<p>Internet &amp; 
social networks  
</p>
<p>Focus groups 
</p>
<p>In-depth  
interviews 
</p>
<p>Test markets 
</p>
<p>Projective  
techniques 
</p>
<p>Experiments  
(mix of observe and ask) 
</p>
<p>Observational  
studies 
</p>
<p>Surveys 
</p>
<p>. Fig.&nbsp;4.1 Types of primary and secondary data sources
</p>
<p>1 This quote has been attributed to Peter F. Drucker.
</p>
<p>4</p>
<p/>
</div>
<div class="page"><p/>
<p>451
4.2 &middot; Secondary Data
</p>
<p>data. The term CRM refers to a system of databases and analysis software that tracks and 
predicts customer behavior. Firms such as IBM, Microsoft, and Oracle market the data-
base systems that the analysis software utilizes. These database management systems often 
include information on, for example, purchasing behavior, (geo-)demographic customer 
data, and the after-sales service. This information is compiled to allow marketers to track 
individual customers over different sales channels and types of products in order to tailor 
their offerings to these customers&rsquo; needs. Several information technology companies, such 
as SAP, Oracle, and Salesforce.com sell the analysis software that utilizes these databases. 
Companies use this software to, for example, identify customer trends, calculate their 
profitability per customer, or identify opportunities to sell new or different products. The 
CRM market is substantial, generating about $37 billion in 2017.
</p>
<p>Sales reports are created when products and services are sold to business-to-business 
clients. Many of these reports detail discussions held with clients, as well as the prod-
ucts and services sold. The reports therefore provide insights into customers&rsquo; needs. Sales 
reports are also a means of retaining customers&rsquo; suggestions regarding products and ser-
vices, and can be a productive source of information. For example, DeMonaco et al. (2005) 
found that 59&nbsp;% of existing drugs had uses other than those that the producing company 
described. Because it is important to be aware of a drug&rsquo;s uses, sales discussions with 
doctors, hospitals, and research institutes can help this company market these drugs. When 
sales reports are available, they are often part of a CRM system.
</p>
<p>Existing research studies are a good source of secondary data. You should, however, 
carefully consider whether existing research studies are still useful and what you can learn 
from them. Even if you believe their findings are outdated, their measures may be very 
useful. Consequently, if you wish to use existing research studies, it is important that you 
ascertain that enough of their details are available to make them useful.
</p>
<p>4.2.2 External Secondary Data
</p>
<p>External secondary data have been compiled outside a company for a variety of purposes. 
Important sources of secondary data, which we discuss next, include:
 4 Governments,
 4 trade associations,
 4 market research firms,
 4 consulting firms,
 4 (literature) databases, and
 4 Internet &amp; social networks.
</p>
<p>Governments often provide data that can be used for market research purposes. For 
example, The CIA World Fact Book provides information on the economy, politics, and 
other issues of nearly every country in the world. Eurostat (the statistics office of the Euro-
pean Union) provides detailed information on the economy and different market sectors 
of the European Union. Much of this information is free of charge and is an easy starting 
point for market research studies.
</p>
<p>Trade associations are organizations representing different companies whose purpose 
is to promote their common interests. For example, the Auto Alliance&mdash;which consists </p>
<p/>
</div>
<div class="page"><p/>
<p>52 Chapter 4 &middot; Getting Data
</p>
<p>of US automakers&mdash;provides information on the sector and lists the key issues it faces. 
The European Federation of Pharmaceutical Industries and Associations represents 1900 
pharmaceutical companies operating in Europe. The federation provides a detailed list of 
key figures and facts, and regularly offers statistics on the industry. Most of the other trade 
associations also provide lists of their members&rsquo; names and addresses. These can be used, 
for example, as a sampling frame (see 7 Chap.&nbsp;3). Most trade associations regard ascertain-
ing their members&rsquo; opinions a key task and therefore collect data regularly. These data are 
often included in reports that researchers can download from the organization&rsquo;s website. 
Such reports can be a short-cut to identifying key issues and challenges in specific indus-
tries. Sometimes, these reports are free of charge, but non-members usually need to pay 
a (mostly substantial) fee.
</p>
<p>Market research firms are another source of secondary data. Especially large market 
research firms provide syndicated data that different clients can use (see 7 Chap.&nbsp;1). 
 Syndicated data are standardized, processed information made available to multiple 
(potential) clients, usually for a substantial fee. Syndicated data often allow the client&rsquo;s 
key measures (such as satisfaction or market share) to be compared against the rest of the 
market. Examples of syndicated data include the J.D. Power Initial Quality Study, which 
provides insights into the initial quality of cars in the US, and the J.D. Power Vehicle Own-
ership Satisfaction Study, which contains similar data on other markets, such as New 
Zealand and Germany. GfK&rsquo;s Spex, which we introduce in Box 4.1, is another important 
example of syndicated data.
</p>
<p>Consulting firms are a rich source of secondary data. Most firms publish full reports or 
summaries of reports on their website. For example, McKinsey &amp; Company publish the 
McKinsey Quarterly, a business journal that includes articles on current business trends, 
issues, problems, and solutions. Oliver Wyman publishes regular reports on trends and 
issues across many different industries. Other consulting firms, such as Gartner and For-
rester, provide data on various topics. These data can be purchased and used for secondary 
analysis. For example, Forrester maintains databases on market segmentation, the allo-
cation of budgets across firms, and the degree to which consumers adopt various innova-
tions. Consulting firms provide general advice, information, and knowledge, while market 
research firms only focus on marketing-related applications. In practice, there is some 
overlap in the activities that consulting and market research firms undertake.
</p>
<p>(Literature) databases comprise professional and academic journals, newspapers, 
and books. Two important literature databases are ProQuest (http://www.proquest.com) 
</p>
<p>Box 4.1&nbsp;GfK Spex Retail
</p>
<p>GfK is a large market research company. One of its databases, Spex Retail, provides resellers, 
</p>
<p>distributors, manufacturers, and website portals with product data. In 20&nbsp;languages, it offers 
</p>
<p>aggregated data on more than 7&nbsp;million products from 20,000&nbsp;manufacturers in 30&nbsp;countries. This 
</p>
<p>database provides details on IT, consumer electronics, household appliances, and other products. 
</p>
<p>Spex Retail also provides insight into new products being launched by providing 70,000&nbsp;new 
</p>
<p>information sheets that describe new products or product changes every month. The data 
</p>
<p>can also be used to map product categories. Such information helps its clients understand the 
</p>
<p>market structure, or identify cross-selling or up-selling possibilities. See http://www.etilize.com/
</p>
<p>retailers/#product-content for more details, including a demo of its products.
</p>
<p>4</p>
<p/>
<div class="annotation"><a href="http://www.proquest.com">http://www.proquest.com</a></div>
<div class="annotation"><a href="http://www.etilize.com/retailers/#product-content">http://www.etilize.com/retailers/#product-content</a></div>
<div class="annotation"><a href="http://www.etilize.com/retailers/#product-content">http://www.etilize.com/retailers/#product-content</a></div>
</div>
<div class="page"><p/>
<p>453
4.2 &middot; Secondary Data
</p>
<p>and JSTOR (https://www.jstor.org). ProQuest contains over 9000 trade journals, business 
 publications, and leading academic journals, including highly regarded publications such as  
the Journal of Marketing and the Journal of Marketing Research. A subscription is needed to 
gain access, although some papers are published as open access. Academic institutions often 
allow their students and, sometimes, their alumni to access these journals. JSTOR is like 
ProQuest, but is mostly aimed at academics. Consequently, it provides access to nearly all 
leading academic journals. A helpful feature of JSTOR is that the first page of academic arti-
cles (which contains the abstract) can be read free of charge. In addition, JSTOR&rsquo;s informa-
tion is searchable via Google Scholar (discussed in Box 4.2). Certain database firms provide 
firm-level data, such as names and addresses. For example, Bureau van Dijk (https://www.
bvdinfo.com/en-gb), as well as Dun and Bradstreet (http://www.dnb.com), publish exten-
sive lists of firm names, the industry in which they operate, their profitability, key activities, 
and address information. This information is often used as a sampling frame for surveys.
</p>
<p>Internet data is a catch-all term that refers to data stored to track peoples&rsquo; behavior 
on the Internet. Such data consist of page requests and sessions. A page request refers to 
people clicking on a link or entering a specific Internet address. A session is a series of these 
requests and is often identified by the IP number, a specific address that uniquely identi-
fies the receiver for a period of time, or by means of a tracking cookie. With this informa-
tion, researchers can calculate when and why people move from one page to another. The 
conversion rate is a specific type of information, namely the ratio of the number of pur-
chases made on a website relative to the number of unique visitors, which often interests 
researchers. Facebook, Instagram, and LinkedIn, provide valuable information in the form 
of social networking profiles, which include personal details and information. These social 
networking data reflect how people would like others to perceive them and, thus, indicate 
consumers&rsquo; intentions. Product or company-related user groups are of specific interest to 
market researchers. Take, for example, comments posted on a Facebook group site such 
as that of BMW or Heineken. An analysis of the postings helps provide an understand-
ing of how people perceive these brands. Interpretations of such postings usually include 
analyzing five elements: the agent (who is posting?), the act (what happened, i.e., what 
aspect does the posting refer to?), the agency (what media is used to perform the action?), 
the scene (what is the background situation?), and the purpose (why do the agents act?). 
By analyzing this qualitative information, market researchers can gain insight into con-
sumers&rsquo; motives and actions. Casteleyn et al. (2009), for example, show that the Heineken 
Facebook posts reveal that the brand has a negative image in Belgium. The task of collect-
ing, processing, analyzing, and storing social networking data is very challenging, due to 
the data&rsquo;s complexity and richness. To enable these tasks, researchers have combined the-
ories and methods from a variety of disciplines (e.g., computer science, linguistics, statis-
tics) in the emerging research field of social media analytics to develop new approaches to 
and method for analyzing social networking data. These include (1) text mining to derive 
high-quality information from text, (2) social network analysis to study the structure of 
the relationships between persons, organizations, or institutions in social networks, and 
(3) trend analysis to predict emerging topics in, for example, Twitter tweets or Facebook 
posts (Stieglitz et al. 2014). Several companies, such as Talkwalker (www.talkwalker.com), 
aggregate data from different websites including blogs and social media platforms, such 
as Twitter, Facebook, and Instagram, which they then analyze. These sites also provide 
statistics, such as the number of mentions or complaints, thereby providing insight into </p>
<p/>
<div class="annotation"><a href="https://www.jstor.org">https://www.jstor.org</a></div>
<div class="annotation"><a href="https://www.bvdinfo.com/en-gb">https://www.bvdinfo.com/en-gb</a></div>
<div class="annotation"><a href="https://www.bvdinfo.com/en-gb">https://www.bvdinfo.com/en-gb</a></div>
<div class="annotation"><a href="http://www.dnb.com">http://www.dnb.com</a></div>
<div class="annotation"><a href="http://www.talkwalker.com">http://www.talkwalker.com</a></div>
</div>
<div class="page"><p/>
<p>54 Chapter 4 &middot; Getting Data
</p>
<p>. Fig.&nbsp;4.2 Snapshot of sentiment analysis via www.talkwalker.com
</p>
<p>people, brands, and products rated on various dimensions. Talkwalker, for example, uses 
AI to power it&rsquo;s sentiment detection and conducted a sentiment analysis of a major product 
recall by Toyota. Toyota found that its social media mentions increased sharply and were 
far more negative in the US and Europe than in Indonesia and Japan (see https://www.
talkwalker.com/blog/navigate-the-automotive-recall-storm-with-social-media-monitoring). 
. Fig.&nbsp;4.2 shows a snapshop of a sentiment analysis via Talkwater.
</p>
<p>Social websites also provide quantitative information. For example, Facebook&rsquo;s Ad 
Manager provides information on the effectiveness of advertising on Facebook, includ-
ing on measures, such as the click-through-rate, and on demographics, such as gender 
or location.
</p>
<p>Big data is an important term in the context of Internet and social networking data. The 
term big data describes very large datasets, generally a mix of quantitative and qualitative 
data in very large volumes, which are automatically analyzed, often with the aim of making 
predictions. There is no commonly accepted definition of the term, but the use of big data 
has become very important very quickly. Big data&rsquo;s use is not unique to market research, 
but spans boundaries and often includes IT, operations, and other parts of organizations. 
Netflix, a provider of videos and movies, relies on big data. Netflix faces the challenge that 
it pays upfront for the videos and the movies it purchases, and therefore needs to under-
stand which, and how many, of its customers will watch them. Netflix analyzes 2 billion 
hours of video each month in an endeavor to understand its customers&rsquo; viewing behavior 
and to determine which videos and movies will become hits. Walmart, the largest retailer 
in the world, also uses big data. One of Walmart&rsquo;s challenges is to proactively suggest prod-
ucts and services to its customers. Using big data, Walmart connects information from 
many sources, including their location, and uses a product database to find related prod-
ucts. This helps Walmart make online recommendations.
</p>
<p>4</p>
<p/>
<div class="annotation"><a href="http://www.talkwalker.com">http://www.talkwalker.com</a></div>
<div class="annotation"><a href="https://www.talkwalker.com/blog/navigate-the-automotive-recall-storm-with-social-media-monitoring">https://www.talkwalker.com/blog/navigate-the-automotive-recall-storm-with-social-media-monitoring</a></div>
<div class="annotation"><a href="https://www.talkwalker.com/blog/navigate-the-automotive-recall-storm-with-social-media-monitoring">https://www.talkwalker.com/blog/navigate-the-automotive-recall-storm-with-social-media-monitoring</a></div>
</div>
<div class="page"><p/>
<p>455
4.3 &middot; Conducting Secondary Data Research
</p>
<p>Box 4.2 Using Google to searching for secondary data
</p>
<p>Most people use Google daily, so why not use it for market research purposes too? Google has an 
</p>
<p>easy interface, but if you use the standard search box, you may not find the data you are looking 
</p>
<p>for. What must you then do to find useful data?
</p>
<p> 5 You could use Google Scholar (https://scholar.google.com) if you are looking for scholarly 
information such as that found in academic journals. While you can search for any 
</p>
<p>information, specific search items can usually only be accessed if you have an organizational, 
</p>
<p>university, or library password.
</p>
<p> 5 By using Google Books (https://books.google.com/books), you can enter several keywords to 
easily search through a very large catalogue of books. Google clearly indicates the books in 
</p>
<p>which the search results are found and the pages on which the keywords occur. The Ngram 
</p>
<p>Viewer (https://books.google.com/ngrams/) shows the relative frequency with which words 
</p>
<p>are used and is a cool Google books tool.
</p>
<p> 5 If you cannot find what you are looking for, Google allows you to refine your search. After you 
have searched you can typically select All, Images, Videos, News, Maps, and More to select the 
</p>
<p>type of result you are interested in. Under Tools, you can select the country and time range 
</p>
<p>from which results are to be shown.
</p>
<p> 5 Google Public Data Explorer (https://www.google.com/publicdata/directory) facilitates 
exploration of a variety of public-interest datasets. These include the US Census Bureau, 
</p>
<p>Eurostat, and the OECD datasets. This site is particularly useful if you want to obtain visualized 
</p>
<p>data on economic indicators.
</p>
<p> 5 Try using operators, which are signs that you use to restrict your research. For example, 
putting a minus symbol (&minus;) (without a space) before a search word excludes this word from 
</p>
<p>your findings. Putting a sequence of words, or an entire sentence in quotation marks (e.g., 
</p>
<p>&ldquo;a concise guide to market research&rdquo;) indicates that Google should only search for exact 
</p>
<p>matches.
</p>
<p>4.3 Conducting Secondary Data Research
</p>
<p>In 7 Chap.&nbsp;2, we discussed the market research process, starting with identifying and for-
mulating the research question, followed by determining the research design. Once these 
two have been done, your attention should turn to designing the sample and the method of 
data collection. In respect of secondary data, this task involves the steps shown in . Fig.&nbsp;4.3.
</p>
<p>4.3.1 Assess Availability of Secondary Data
</p>
<p>Search engines (such as Google or Bing) provide easy access to many sources of the sec-
ondary data we have just discussed. Furthermore, many (specialist) databases also provide 
access to secondary data.
</p>
<p>Search engines crawl through the Internet, regularly updating their contents. Algo-
rithms, which include how websites are linked, and other peoples&rsquo; searches evaluate this 
content and present a set of results. Undertaking searches by means of search engines 
requires careful thought. For example, the word order is important (put keywords first) 
and operators (such as +, &minus;, and ~) may have to be added to restrict searches. In Box 4.2, 
we discuss the basics of using Google to search the Internet.</p>
<p/>
<div class="annotation"><a href="https://scholar.google.com">https://scholar.google.com</a></div>
<div class="annotation"><a href="https://books.google.com/books">https://books.google.com/books</a></div>
<div class="annotation"><a href="https://books.google.com/ngrams/">https://books.google.com/ngrams/</a></div>
<div class="annotation"><a href="https://www.google.com/publicdata/directory">https://www.google.com/publicdata/directory</a></div>
</div>
<div class="page"><p/>
<p>56 Chapter 4 &middot; Getting Data
</p>
<p>Databases contain existing data that can be used for market research purposes, which 
we discussed in the 7 Sect.&nbsp;4.2.2. Lightspeed Research (http://www.lightspeedresearch.
com), for example, maintains several databases, such as a B2B and Millenial Panel, pro-
viding details on selected market segments. GfK provides several databases that track 
retail sales. Nielsen maintains a large consumer panel of some 250,000&nbsp;households in 
27&nbsp;countries. It is clearly not possible to provide an exhaustive list of the databases avail-
able, but an online search, a market research agency, or an expert should help you iden-
tify the options quickly.
</p>
<p>Once a potential secondary data source has been located, the next task is to evaluate the 
available data. It is important to critically assess the (potential) data&rsquo;s fit with your needs. 
. Fig.&nbsp;4.3 provides a set of criteria to help evaluate this fit.
</p>
<p>4.3.2 Assess Inclusion of Key Variables
</p>
<p>Measurement is the first element to assess. It consists of a set of criteria. You should first 
check whether the desired variables are included in the source. The key variables in which 
you are interested, or could use, should obviously be part of the data. Also check if these 
variables are included at the required level of analysis, which is called the aggregation 
level (see 7 Chap.&nbsp;3). For example, the American Customer Satisfaction Index (ACSI) sat-
isfaction dataset reports on satisfaction at the company level;2 therefore, if researchers 
need the measurement of satisfaction at a product, service, or store level, these data are 
inappropriate.
</p>
<p>Assess construct validity 
</p>
<p>Assess sampling 
Assess representativeness of the sample 
</p>
<p>Assess recency,  time frame, and future data collection 
</p>
<p>What is the consistency of the measurement over time? 
</p>
<p>Specify the
</p>
<p>construct
</p>
<p>theoretically 
</p>
<p>Assess ability of secondary data
</p>
<p>items to measure the construct 
</p>
<p>Assess
</p>
<p>nomological
</p>
<p>validity 
</p>
<p>Assess inclusion of key variables 
</p>
<p>Assess availability of secondary data 
</p>
<p>. Fig.&nbsp;4.3 Assessing secondary data
</p>
<p>2 See https://www.theacsi.org for a detailed description of how ACSI data are collected.
</p>
<p>4</p>
<p/>
<div class="annotation"><a href="http://www.lightspeedresearch.com">http://www.lightspeedresearch.com</a></div>
<div class="annotation"><a href="http://www.lightspeedresearch.com">http://www.lightspeedresearch.com</a></div>
<div class="annotation"><a href="https://www.theacsi.org">https://www.theacsi.org</a></div>
</div>
<div class="page"><p/>
<p>457
4.3 &middot; Conducting Secondary Data Research
</p>
<p>4.3.3 Assess Construct Validity
</p>
<p>After checking that the desired variables are included in the source, the construct validity 
should be assessed (see 7 Chap.&nbsp;3 for a discussion of validity). Validity relates to whether 
variables measure what they should measure (see 7 Chap.&nbsp;3). Construct validity is a general 
term relating to how a variable is defined conceptually and its suggested (empirical) 
measure. Houston (2002) establishes a three-step method to assess the construct validity 
of secondary data measures.
</p>
<p> 4 First, specify the theoretical definition of the construct in which you are interested. 
Satisfaction is, for example, often defined as the degree to which an experience 
conforms to expectations and the ideal.
 4 Second, compare your intended measure against this theoretical definition (or 
</p>
<p>another acceptable definition of satisfaction). Conceptually, the items should fit 
closely.
 4 Third, assess if these items have nomological validity (see 7 Chap.&nbsp;3). For example, 
</p>
<p>customer expectations, perceived quality, and value have a significant influence on 
customer satisfaction. Similarly, satisfaction generally relates positively to customer 
loyalty. As such, you would expect the measure of satisfaction that you are evaluating 
to correlate with these measures (if included in the database).
</p>
<p>Taking these three steps is important, as the construct validity is often poor when second-
ary data are used.3 See Raithel et al. (2012) for an application of this three-step process.
</p>
<p>If there are multiple sources of secondary data, identical measures can be correlated 
to assess the construct validity. For example, the Thomson Reuter SDC Platinum and the 
Bioscan database of the American Health Consultants both include key descriptors of firms 
and financial information; they therefore have a considerable overlap regarding the mea-
sures included. This may raise questions regarding which databases are the most suitable, 
particularly if the measures do not correlate highly. Fortunately, databases have been com-
pared; for example, Schilling (2009) compares several databases, including SDC Platinum.
</p>
<p>4.3.4 Assess Sampling
</p>
<p>Next, the sampling process of the collected secondary data should be assessed. First assess 
the population and the representativeness of the sample drawn from it. For example, the 
sampling process of Nielsen Homescan&rsquo;s data collection effort is based on probability 
sampling, which can lead to representative samples (see 7 Chap.&nbsp;3). Sellers of secondary 
data often emphasize the size of the data collected, but good sampling is more important 
than sample size! When sampling issues arise, these can be difficult to detect in secondary 
data, because the documents explaining the methodology behind secondary data (bases) 
rarely discuss the data collection&rsquo;s weaknesses. For example, in many commercial mailing 
lists 25% (or more) of the firms included routinely have outdated contact information, are 
</p>
<p>3 Issues related to construct validity in business marketing are discussed by, for example, Rindfleisch 
</p>
<p>and Heide (1997). A more general discussion follows in Houston (2002).</p>
<p/>
</div>
<div class="page"><p/>
<p>58 Chapter 4 &middot; Getting Data
</p>
<p>bankrupt, or otherwise not accurately recorded. This means that the number of contactable 
firms is much lower than the number of firms listed in the database. In addition, many firms 
may not be listed in the database. Whether these issues are problematic depends on the 
research purpose. For example, descriptive statistics may be inaccurate if data are missing.
</p>
<p>The recency of the data, the time period over which the data were collected, and future 
intentions to collect data should be assessed next. The data should be recent enough to 
allow decisions to be based on them. The data collection&rsquo;s timespan and the intervals at 
which the data were collected (in years, months, weeks, or in even more detail) should 
match the research question. For example, when introducing new products, market com-
petitors&rsquo; market share is an important variable, therefore such data must be recent. Also 
consider whether the data will be updated in the future and the frequency with which such 
updates will done. Spending considerable time on getting to know data that will not be 
refreshed can be frustrating! Other measurement issues include definitions that change 
over time. For example, many firms changed their definitions of loyalty from behavioral 
(actual purchases) to attitudinal (commitment or intentions). Such changes make compar-
isons over time difficult, as measures can only be compared if the definitions are consistent.
</p>
<p>4.4 Conducting Primary Data Research
</p>
<p>Primary data are gathered for a specific research project or task. There are two ways of gath-
ering primary data. You can observe consumers&rsquo; behavior, for example, by means of obser-
vational studies, or test markets. Alternatively, you can ask consumers directly by means 
of surveys, in-depth interviews, predictive techniques, or focus groups. Experiments are 
a special type of research, which is normally a combination of observing and asking. We 
provide an overview of the various types of primary data collection methods in . Fig.&nbsp;4.1.
</p>
<p>Next, we briefly introduce observing as a method of collecting primary data. We 
proceed by discussing how to conduct surveys. Since surveys are the main means of col-
lecting primary data by asking, we discuss the process of undertaking survey research in 
enough detail to allow you to set up your own survey-based research project. We then 
discuss in-depth interviews, including a special type of test used in these interviews (pro-
jective techniques). Last, we discuss combinations of observing and asking&mdash;the basics of 
conducting experimental research.
</p>
<p>4.4.1 Collecting Primary Data Through Observations
</p>
<p>Observational studies can provide important insights that other market research tech-
niques do not. Observational techniques shed light on consumers&rsquo; and employees&rsquo; behav-
ior and can help answer questions such as: How do consumers walk through supermar-
kets?; how do they consume and dispose of products?; and how do employees spend their 
working day? Observational techniques are normally used to understand what people are 
doing rather than why they are doing it. They work well when people find it difficult to 
put what they are doing into words, such as shoppers from different ethnic backgrounds.
</p>
<p>Most observational studies use video recording equipment, or trained researchers, 
who unobtrusively observe what people do (e.g., through one-way mirrors or by using 
</p>
<p>4</p>
<p/>
</div>
<div class="page"><p/>
<p>459
4.4 &middot; Conducting Primary Data Research
</p>
<p>recording equipment). Another example is the use of eyetracking equipment that measure 
what catches customers&rsquo; eyes and how long their gaze remains (see Box 4.3 for a video on 
how market researchers use eyetracking for studies in supermarkets).
</p>
<p>Recently, researchers started using computer chips (called RFIDs) as observational 
equipment to trace consumers&rsquo; shopping paths within a supermarket 7 Chap.&nbsp;2. Almax, 
an Italian company, has developed a special type of observational equipment. Their EyeSee 
product is an in-store mannequin equipped with a camera and audio recording equipment. 
The product also comprises software that analyze the camera recordings and provides sta-
tistical and contextual information, such as the shoppers&rsquo; demographics. Such informa-
tion is useful for developing targeted marketing strategies. For example, a retail company 
found that Chinese visitors prefer to shop in Spanish stores after 4 p.m., prompting these 
stores to increase their Chinese-speaking staff at these hours. . Fig.&nbsp;4.4 shows what the 
EyeSee Mannequin looks like.
</p>
<p>Mystery shopping, when a trained researcher is asked to visit a store or restaurant and 
consume the products or services, is a specific type of observational study. For example, 
McDonalds and Selfridges, a UK retail chain, both use mystery shoppers to ensure the 
quality of their services and products (see Box 4.4 for an MSNBC video on mystery 
shopping).
</p>
<p>Sometimes observational studies are conducted in households, with researchers par-
ticipating in them to see how the inhabitants buy, consume, and dispose of products or 
services. The type of study in which the researcher is a participant is called an ethnography. 
An example of an ethnography is Volkswagen&rsquo;s Moonraker project, in which several Volk-
swagen employees followed American drivers to gain an understanding of how their usage 
of and preferences for automobiles differ from those of European drivers (Kurylko 2005).
</p>
<p>Box 4.3 Eyetracking study in a supermarket
</p>
<p>&copy; gopixa/Getty Images/iStock
</p>
<p>https://www.youtube.com/watch?v=Hatmm84sqm0&amp;index=3&amp;list=
</p>
<p>PLMM7ZjFcpspWOBnq-rdg7P1fBXcJY7tWL</p>
<p/>
<div class="annotation"><a href="https://www.youtube.com/watch?v=Hatmm84sqm0&amp;index=3&amp;list=PLMM7ZjFcpspWOBnq-rdg7P1fBXcJY7tWL">https://www.youtube.com/watch?v=Hatmm84sqm0&amp;index=3&amp;list=PLMM7ZjFcpspWOBnq-rdg7P1fBXcJY7tWL</a></div>
<div class="annotation"><a href="https://www.youtube.com/watch?v=Hatmm84sqm0&amp;index=3&amp;list=PLMM7ZjFcpspWOBnq-rdg7P1fBXcJY7tWL">https://www.youtube.com/watch?v=Hatmm84sqm0&amp;index=3&amp;list=PLMM7ZjFcpspWOBnq-rdg7P1fBXcJY7tWL</a></div>
</div>
<div class="page"><p/>
<p>60 Chapter 4 &middot; Getting Data
</p>
<p>. Fig.&nbsp;4.4 The EyeSee 
mannequin. (&copy; almax)
</p>
<p>https://www.youtube.com/
</p>
<p>watch?v=NA-fFv1uB-c
</p>
<p>Box 4.4 Using mystery shopping to improve customer service
</p>
<p>&copy; andresr/Getty Images/iStock
</p>
<p>https://www.youtube.com/watch?v=ErfUVt0fyK0
</p>
<p>Test markets are a useful, but costly, type of market research in which a company intro-
duces a new product or service to a specific geographic market. Test markets are some-
times also used to understand how consumers react to different marketing mix instru-
ments, such as changes in pricing, distribution, or advertising and communication. Test 
marketing is therefore about changing a product or service offering in a real market and 
gauging consumers&rsquo; reactions. While the results from such studies provide important 
insights into consumer behavior in a real-world setting, they are expensive and difficult 
to conduct. Some frequently used test markets include Hassloch in Germany, as well as 
Indianapolis and Nashville in the US.
</p>
<p>4</p>
<p/>
<div class="annotation"><a href="https://www.youtube.com/watch?v=NA-fFv1uB-c">https://www.youtube.com/watch?v=NA-fFv1uB-c</a></div>
<div class="annotation"><a href="https://www.youtube.com/watch?v=NA-fFv1uB-c">https://www.youtube.com/watch?v=NA-fFv1uB-c</a></div>
<div class="annotation"><a href="https://www.youtube.com/watch?v=ErfUVt0fyK0">https://www.youtube.com/watch?v=ErfUVt0fyK0</a></div>
</div>
<div class="page"><p/>
<p>461
4.4 &middot; Conducting Primary Data Research
</p>
<p>4.4.2 Collecting Quantitative Data: Designing Surveys
</p>
<p>There is little doubt that surveys are the mainstay of primary market research. While it 
may seem easy to conduct a survey (just ask what you want to know, right?), there are 
many issues that could turn good intentions into bad results. In this section, we discuss 
the key design choices for good surveys. Designing a good survey requires several steps. 
First, determine the survey goal. Next, determine the type of questionnaire required and 
the administration method. Thereafter, decide on the questions and the scale, as well as 
the design of the questionnaire. Conclude by pretesting and administering the question-
naire. We show these steps in . Fig.&nbsp;4.5.
</p>
<p>4.4.2.1 Set the Survey Goal
</p>
<p>Before you start designing the questionnaire, it is vital to consider the survey goal. Is it to 
collect quantitative data on customers&rsquo; background, to assess customer satisfaction, or do 
you want to understand why and how customers complain? These different goals influence 
the type of questions asked (such as open-ended or closed-ended questions), the method 
of administration (e.g., by mail or on the Web), and other design issues discussed below. 
Two aspects are particularly relevant when designing surveys:
</p>
<p>First, consider the information or advice you want to emerge from the study for which 
the survey is required. Say you are asked to help understand check-in waiting times at an 
airport. If the specific study question is to gain an understanding of how many minutes 
travelers are willing to wait before becoming dissatisfied, you should be able to provide 
an answer to the question: How much does travelers&rsquo; satisfaction decrease with increased 
waiting time? If, on the other hand, the specific question is to understand how people 
</p>
<p>Design the questionnaire 
</p>
<p>Set the survey goal 
</p>
<p>Determine the type of questionnaire and method of administration 
</p>
<p>Design the items 
</p>
<p>Pretest the questionnaire 
</p>
<p>Execution 
</p>
<p>Set the scale 
</p>
<p>. Fig.&nbsp;4.5 Steps in designing surveys</p>
<p/>
</div>
<div class="page"><p/>
<p>62 Chapter 4 &middot; Getting Data
</p>
<p>perceive waiting time (short or long), your questions should focus on how travelers per-
ceive this time and, perhaps, what influences their perception. Thus, the information or 
advice you want to provide influences the questions that you should pose in a survey.
</p>
<p>Second, consider the method required for the study early in the design process. For 
example, if a study&rsquo;s goal is to determine market segments, you should probably use cluster 
analysis (see 7 Chap.&nbsp;9). Similarly, if the study&rsquo;s goal is to develop a way to systemati-
cally measure customer satisfaction, you are likely to use factor analysis (see 7 Chap.&nbsp;8). 
This approach is crucial, as each method requires different types of data. Cluster analysis, 
for example, generally requires variables that are not too highly correlated, meaning that 
researchers need to use a type of questionnaire that can produce these data. On the other 
hand, factor analysis requires data that include different, but highly correlated, variables. If 
you use factor analysis to distinguish between the different aspects of consumer satisfaction, 
you need to design a survey that will produce data allowing you to conduct factor analysis.
</p>
<p>4.4.2.2  Determine the Type of Questionnaire and Method 
of&nbsp;Administration
</p>
<p>After determining the survey goal, you need to decide on the type of questionnaire you 
should use and how it should be administered. There are four key ways of administering 
a survey:
 4 Personal interviews,
 4 telephone interviews,
 4 web surveys, and
 4 mail surveys.
</p>
<p>In some cases, researchers combine different ways of administering surveys. This is called 
a mixed mode.
</p>
<p>z Personal Interviews
Personal interviews (or face-to-face interviews) can obtain high response rates, since 
engagement with the respondents are maximized, allowing rich information (visual 
expressions, etc.) to be collected. Moreover, since people find it hard to walk away from 
interviews, it is possible to collect answers to a reasonably lengthy set of questions. Con-
sequently, personal interviews can support long surveys. It is also the best type of data 
collection for open-ended responses. In situations where the respondent is initially 
unknown, this may be the only feasible data collection type. Consequently, in-depth 
interviews may be highly preferable, but they are also the costliest per respondent. This 
is less of a concern if only small samples are required (in which case personal interview-
ing could be the most efficient). Other issues with personal interviews include the pos-
sibility of interviewer bias (i.e., a bias resulting from the interviewer&rsquo;s behavior, e.g., in 
terms of his/her reactions or presentation of the questions), respondent bias to sensitive 
items, and the data collection usually takes more time. Researchers normally use personal 
interviewing when they require an in-depth exploration of opinions. Such interviewing 
may also help if drop out is a key concern. For example, if researchers collect data from 
executives around the globe, using methods other than face-to-face interviewing may 
lead to excessive non-response in countries such as Russia or China where face-to-face 
interviews are a sign of respect for and appreciation of the time taken. CAPI, which is 
the abbreviation of computer-assisted personal interviews, is a frequently used term in 
</p>
<p>4</p>
<p/>
</div>
<div class="page"><p/>
<p>463
4.4 &middot; Conducting Primary Data Research
</p>
<p>the context of in-depth interviewing. CAPI involve using computers during the inter-
viewing process to, for example, route the interviewer through a series of questions, or 
to enter responses directly. Similarly, in CASI (computer-assisted self-interviews), the 
respondent uses a computer to complete the survey questionnaire without an inter-
viewer administering it.
</p>
<p>z Telephone Interviews
Telephone interviews allow researchers to collect data quickly. These interviews also 
support open-ended responses, although not as well as personal interviews. Moreover, 
interviewer bias can only be controlled moderately, since the interviewers follow pre-
determined protocols, and the respondent&rsquo;s interactions with others during the inter-
view is strongly controlled. Telephone interviewing can be a good compromise between 
mailed interviews&rsquo; low cost and the richness of in-depth interviews. CATI refers to com-
puter-assisted telephone interviews, which are an important method of administering 
surveys. Until the 1990s, telephone interviews were generally conducted via landlines, 
but mobile phone usage has soared in the meantime. In many countries, mobile phone 
adoption rates are higher than landline adoption. This holds especially for African coun-
tries, India, and many European countries if younger consumers are the targeted inter-
viewees (Vincente and Reis 2010). Consequently, mobile phone surveys have become 
dominant in market research.
</p>
<p>A decade ago, the differences between landline and mobile phone surveys could be large, with 
</p>
<p>younger and richer individuals being overrepresented in mobile phone surveys (Vincente et&nbsp;al. 
</p>
<p>2008). As the adoption of mobile phones increased, the use of landlines decreased, which intro-
</p>
<p>duced new problems in terms of sampling errors (Stern et al. 2014). For example, younger people 
</p>
<p>are now less likely to have landlines. An additional issue is that landlines are fixed to a geograph-
</p>
<p>ical area whereas mobile phones are not. As people move or travel, mobile phones are far less 
</p>
<p>likely to give useful information about geographic areas. While recent research has shown that 
</p>
<p>differences in response accuracy between mobile phone and landline surveys are small (e.g., with 
</p>
<p>regard to social desirability bias), especially for questions that are not cognitively demanding (e.g., 
</p>
<p>Kennedy and Everett 2011; Lynn and Kaminska 2013), the samples from which they are drawn can 
</p>
<p>be very different in practice. There are some other differences as well. For example, the likelihood 
</p>
<p>of full completion of surveys is higher for mobile calling, even though completion takes around 
</p>
<p>10&ndash;15&nbsp;% longer (Lynn and Kaminska 2013).
</p>
<p>z Web Surveys
Web surveys (sometimes referred to as CAWI, or computer-assisted web interviews) are 
often the least expensive to administer and can be set up very quickly. Researchers can 
administer web surveys to very large populations, even internationally, because, besides 
the fixed costs of setting up a survey, the marginal costs of administering additional web 
surveys are relatively low.</p>
<p/>
</div>
<div class="page"><p/>
<p>64 Chapter 4 &middot; Getting Data
</p>
<p>Many firms specializing in web surveys will ask $0.30 (or more) for each respondent, 
which is substantially lower than the costs of personal interviews, telephone interviews, 
and mail surveys. It is also easy to obtain precise quotes quickly. Qualtrics (http://www.
qualtrics.com) is a leading web service provider that allows a specific type of respondent 
and a desired sample size to be chosen. For example, using Qualtrics&rsquo;s sample to survey 
500&nbsp;current owners of cars to measure their satisfaction costs $2500 for a 10-minute survey. 
This cost increases sharply if samples are hard to access and/or require compensation for 
their time. For example, surveying 500 purchasing managers by means of a 10-minute 
survey costs approximately $19,500.
</p>
<p>Web surveys also support complex survey designs with elaborate branching and skip 
patterns that depend on the response. For example, web surveys allow different surveys to 
be created for different types of products. Further, since web surveys reveal the questions 
progressively to the respondents, there is an option to channel them to the next question 
based on their earlier responses. This procedure is called adaptive questioning. In addi-
tion, web surveys can be created that allow respondents to automatically skip questions if 
they do not apply. For example, if a respondent has no experience with an iPad, research-
ers can create surveys that do not ask questions about this product. However, web surveys 
impose similar burdens on the respondents as mail surveys do (see below), which they 
may experience as an issue. This makes administering long web surveys difficult. More-
over, open-ended questions tend to be problematic, because few respondents are likely 
to provide answers, leading to a low item response. There is evidence that properly con-
ducted web surveys lead to data as good as those obtained from mail surveys; in addition, 
the lack an interviewer, which can result in interviewer bias, means they can provide better 
results than personal interviews (Bronner and Ton 2007; Deutskens et al. 2006). In web 
surveys, the respondents are also less exposed to evaluation apprehension and less inclined 
to respond with socially desirable behavior.4
</p>
<p>To complete web surveys, most respondents still use their personal computers, but the 
popularity of mobile devices (i.e., smartphones and tablets) has risen significantly in recent 
years. Brosnan et al. (2017) have found that survey completion rates vary across devices 
with personal computers yielding the highest rate (83&nbsp;%), followed by tablets (66&nbsp;%) and 
smartphones (63&nbsp;%). In addition, since device use is significantly associated with specific 
socio-demographic characteristics, you should not limit respondents to use a specific 
device for completing a survey as this may negatively affect representativity.
</p>
<p>! It is important to distinguish between true web-based surveys used for collecting 
information on which marketing decisions will be based and polls, or very short 
</p>
<p>surveys, on websites used to increase interactivity. These polls/short surveys 
</p>
<p>are used to attract and keep people interested in websites and are not part of 
</p>
<p>market research. For example, USA Today (http://www.usatoday.com), an American 
</p>
<p>newspaper, regularly publishes short polls on their main website.
</p>
<p>4 For a comparison of response behavior between CASI, CAPI, and CATI, see Bronner and Ton (2007).
</p>
<p>4</p>
<p/>
<div class="annotation"><a href="http://www.qualtrics.com">http://www.qualtrics.com</a></div>
<div class="annotation"><a href="http://www.qualtrics.com">http://www.qualtrics.com</a></div>
<div class="annotation"><a href="http://www.usatoday.com">http://www.usatoday.com</a></div>
</div>
<div class="page"><p/>
<p>465
4.4 &middot; Conducting Primary Data Research
</p>
<p>z Mail Surveys
Mail surveys are paper-based surveys sent out to respondents. They are a more expensive 
type of survey research and are best used for sensitive items. Since no interviewer is present, 
there is no interviewer bias. However, mail surveys are a poor choice for complex survey 
designs, such as when respondents need to skip a large number of questions depending 
on previously asked questions, as this means that the respondent needs to correctly inter-
pret the survey structure. Open-ended items are also problematic, because few people are 
likely to provide answers to such questions if the survey is administered on paper. Other 
problems include a lack of control over the environment in which the respondent fills out 
the survey and that mail surveys take longer than telephone or web surveys. However, in 
some situations, mail surveys are the only way to gather data. For example, while execu-
tives rarely respond to web-based surveys, they are more likely to respond to paper-based 
surveys. Moreover, if the participants cannot easily access the web (such as employees 
working in supermarkets, cashiers, etc.), handing out paper surveys is likely to be more 
successful.
</p>
<p>The method of administration also has a significant bearing on a survey&rsquo;s maximum 
</p>
<p>duration (Vesta Research 2016). As a rule of thumb, telephone interviews should 
</p>
<p>be no longer than 20&nbsp;minutes. When calling a on a mobile phone, however, the 
</p>
<p>survey should not exceed 5&nbsp;minutes. The maximum survey duration of web surveys 
</p>
<p>is 20&nbsp;minutes&mdash;10&nbsp;minutes for social media-based surveys. Personal interviews and 
</p>
<p>mail surveys can be much longer, depending on the context. For example, surveys 
</p>
<p>comprising personal interviews on topics that respondents find important, could take 
</p>
<p>up to 2&nbsp;hours. However, when topics are less important, mail surveys and personal 
</p>
<p>interviews need to be considerably shorter.
</p>
<p>Tip
</p>
<p>Market researchers are increasingly using mixed mode approaches. An example of a mixed 
mode survey is when potential respondents are first approached by phone, asked to partic-
ipate and confirm their email addresses, after which they are given access to a web survey. 
Mixed mode approaches are also used when people are first sent a paper survey and then 
called if they fail to respond.
</p>
<p>Mixed mode approaches may help, because they signal that the survey is important. 
They may also help improve response rates, as people who are more visually oriented 
prefer mail and web surveys, whereas those who are aurally oriented prefer telephone 
surveys. However, there is only evidence of increased response rates when modes are 
offered sequentially and of mixed modes reducing response rates when offered simultane-
ously (Stern et al. 2014). By providing different modes, people can use the mode they most 
prefer. A downside of mixed mode surveys is that they are expensive and require a detailed 
address list (including a telephone number and matching email address). However, sys-
tematic (non)response is the most serious mixed mode survey issue. For example, when 
filling out mail surveys, the respondents have more time than when providing answers </p>
<p/>
</div>
<div class="page"><p/>
<p>66 Chapter 4 &middot; Getting Data
</p>
<p>by telephone. If respondents need this time to think about their answers, the responses 
obtained from mail surveys may differ systematically from those obtained from tele-
phone surveys.
</p>
<p>4.4.2.3 Design the Items
</p>
<p>Designing the items, whether for a personal interview, web survey, or mail survey, requires 
a great deal of thought. Take, for example, the survey item shown in . Fig.&nbsp;4.6:
</p>
<p>It is unlikely that people can give meaningful answers to such an item. First, using a 
negation (&ldquo;not&rdquo;) in sentences makes questions hard to understand. Second, the reader may 
not have an iPhone, or may not have experience using it. Third, the answer categories are 
unequally distributed. That is, there is one category above neutral while there are two below. 
These issues are likely to create difficulties with understanding and answering questions, 
which may, in turn, cause validity and reliability issues. While the last aspect relates to the 
properties of the scale (see 7 Sect. 4.4.2.4), the first two issues refer to the item content and 
wording, which we will discuss next (see . Table&nbsp;4.1 for a summary).
</p>
<p>z Item content
When deciding on the item content, there are at least three essential rules you should keep 
in mind.
</p>
<p>As a first rule, ask yourself whether everyone will be able to answer each item. If the 
item is, for example, about the quality of train transport and the respondent always travels 
by car, his or her answers will be meaningless. However, the framing of items is important, 
since, for example, questions about why the specific respondent does not use the train can 
yield important insights.
</p>
<p>As a second rule, you should check whether respondents can construct or recall an 
answer. If you require details that possibly occurred a long time ago (e.g., what informa-
tion did the real estate agent provide when you bought/rented your current house?), the 
respondents may have to &ldquo;make up&rdquo; an answer, which leads to validity and reliability issues.
</p>
<p>As a third rule, assess whether the respondents are willing to answer an item. If con-
tents are considered sensitive (e.g., referring to sexuality, money, etc.), respondents may 
provide more socially desirable answers (e.g., by reporting higher or lower incomes than 
are actually true). Most notably, respondents might choose to select a position that they 
believe society favors (e.g., not to smoke or drink, or to exercise), inducing a social desir-
ability bias. They may also not answer such questions at all. You should determine whether 
these items are necessary to attain the research objective. If they are not, omit them from 
the survey. The content that respondents may regard as sensitive is subjective and differs 
across cultures, age categories, and other variables. Use your common sense and, if neces-
sary, use experts to decide whether the items are appropriate. In addition, make sure you 
pretest the survey and ask the pretest participants whether they were reluctant to provide 
certain answers. To reduce respondents&rsquo; propensity to give socially desirable answers, use 
</p>
<p>. Fig.&nbsp;4.6 Example of a bad survey item
</p>
<p>4</p>
<p/>
</div>
<div class="page"><p/>
<p>467
4.4 &middot; Conducting Primary Data Research
</p>
<p>indirect questioning (e.g., &ldquo;What do you believe other people think about &hellip; ?&rdquo;), frame 
questions as neutrally as possible, and suggest that many people exhibit behavior differ-
ent from the norm (e.g., Brace 2004). Adjusting the response categories also helps when 
probing sensitive topics. For example, instead of directly asking about respondents&rsquo; dispos-
able income, you can provide various answering categories, which will probably increase 
their willingness to answer this question.
</p>
<p>Designing the items also requires deciding whether to use open-ended or closed-ended 
questions. Open-ended questions (also called verbatim items) provide little or no struc-
ture for respondents&rsquo; answers. Generally, the researcher asks a question and the respon-
dent writes down his or her answer in a box. Open-ended questions are flexible and allow 
for explanation, making them particularly suitable for exploratory research. However, the 
drawback is that the respondents may be reluctant to provide detailed information. Fur-
thermore, answering open-ended questions is more difficult and time consuming. In addi-
tion, their interpretation requires substantial coding. Coding issues arise when respon-
dents provide many different answers (such as &ldquo;sometimes,&rdquo; &ldquo;maybe,&rdquo; &ldquo;occasionally,&rdquo; or 
&ldquo;once in a while&rdquo;) and the researcher has to divide these into categories (such as very infre-
quently, infrequently, frequently, and very frequently) for further statistical analysis. This 
coding is very time-consuming, subjective, and difficult. Closed-ended questions provide 
respondents with only a few categories from which to choose, which drastically reduces 
their burden, thereby inducing much higher response rates compared to open-ended ques-
tions. Closed-ended questions also facilitate immediate statistical analysis of the responses 
as no ex post coding is necessary. However, researchers need to identify answer categories 
in advance and limit this number to a manageable amount. Closed-ended questions are 
dominant in research and practice.
</p>
<p>z Item wording
The golden rule of item wording is to keep it short and simple. That is, use simple words 
and avoid using jargon or slang as some respondents may misunderstand these. Simi-
larly, keep grammatical complexities to a minimum by using active rather than passive 
voice, repeat the nouns instead of using pronouns, and avoiding possessive forms (Lietz 
2010). Use short sentences (20&nbsp;words max; Oppenheim 1992) to minimize the cognitive 
demands required from the respondents (Holbrook et al. 2006) and to avoid the risk of 
double-barreled questions, causing respondents to agree with one part of the question 
but not the other, or which they cannot answer without accepting a particular assump-
tion. An example of such a double-barreled question is: &ldquo;In general, are you satisfied with 
the products and services of the company?&rdquo; A more subtle example is: &ldquo;Do you have the 
time to read the newspaper every day?&rdquo; This question also contains two aspects, namely 
&ldquo;having time&rdquo; and &ldquo;reading the paper every day.&rdquo; The question &ldquo;Do you read the newspa-
per every day?&rdquo; followed by another about the reasons for a negative or a positive answer 
would be clearer (Lietz 2010).
</p>
<p>Moreover, avoid using the word not or no where possible. This is particularly import-
ant when other words in the same sentence are negative, such as &ldquo;unable,&rdquo; or &ldquo;unhelpful,&rdquo; 
because sentences with two negatives (called a double negative) are hard to understand. 
For example, a question such as &ldquo;I do not use the email function on my iPhone because it is 
unintuitive&rdquo; is quite hard to follow and takes longer to process (Peng and Finn 2016). Also, 
avoid using vague quantifiers, such as &ldquo;frequent&rdquo; or &ldquo;occasionally&rdquo; (Dillman et al. 2014), 
which make it difficult for respondents to answer questions (what exactly is meant by </p>
<p/>
</div>
<div class="page"><p/>
<p>68 Chapter 4 &middot; Getting Data
</p>
<p>&ldquo;occasionally&rdquo;?). They also make comparing responses difficult. After all, what one person 
considers &ldquo;occasionally,&rdquo; may be &ldquo;frequent&rdquo; for another.5 Instead, it is better to use frames 
that are precise (&ldquo;once a week&rdquo;).
</p>
<p>Never suggest an answer. For example, a question like &ldquo;Company X has done very well, 
how do you rate it?&rdquo; is highly suggestive and would shift the mean response to the posi-
tive end of the scale.
</p>
<p>Many researchers recommend including reverse-scaled items in surveys. Reverse-scaled 
means the question, statement (if a Likert scale is used), or word pair (if a semantic dif-
ferential scale is used) are reversed compared to the other items in the set. Box 4.5 shows 
an example of a five-item scale for measuring consumers&rsquo; attitude toward the brand (e.g., 
Sarstedt et al. 2016) with one reverse-scaled item printed in bold. Reverse-scaled items act 
as cognitive &ldquo;speed bumps&rdquo; that alert inattentive respondents that the content varies (Wei-
jters and Baumgartner 2012) and help reduce the effect of acquiescence, which relates to 
a respondent&rsquo;s tendency to agree with items regardless of the item content (Baumgartner 
and Steenkamp 2001; see also 7 Chap.&nbsp;5). Furthermore, reverse-scaled items help identify 
straight-lining, which occurs when a respondent marks the same response in almost all the 
items (7 Chap.&nbsp;5). However, numerous researchers have shown that reverse-scaled items 
create problems, for example, by generating artificial factors, as respondents have greater 
difficulty verifying the item. This creates misresponse rates of 20&nbsp;% and higher (e.g., Swain 
et&nbsp;al. 2008; Weijters et al. 2013). Given these results, we suggest employing reverse-scaled 
items sparingly (Weijters and Baumgartner 2012), for example, only to identify straight-lin-
ing. If used, reverse-scaled items should not contain a particle negation such as &ldquo;not&rdquo; or &ldquo;no.&rdquo;
</p>
<p>Finally, when you undertake a survey in different countries (or adapt a scale from a 
different language), use professional translators, because translation is a complex process. 
Functionally, translating one language into another seems quite easy, as there are many 
websites, such as Google translate (translate.google.com), that do this. However, translating 
surveys requires preserving the conceptual equivalence of whole sentences and paragraphs; 
current software applications and websites cannot ensure this. In addition, cultural differ-
ences normally require changes to the instrument format or procedure. Back-translation is 
a technique to establish conceptual equivalence across languages. Back-translation requires 
translating a survey instrument into another language, after which another translator takes 
</p>
<p>5 Foddy (1993) reported 445 interpretations of the word &ldquo;usually,&rdquo; with the meaning assigned to the 
</p>
<p>word varying, depending on, for example, the type of activity or who was asked about the activity.
</p>
<p>Box 4.5 An example of a scale with reverse-scaled items (in bold).
</p>
<p>Please rate the brand in the advertisement on the following dimensions:
</p>
<p>Dislike 1 2 3 4 5 6 7 Like
</p>
<p>Unpleasant 1 2 3 4 5 6 7 Pleasant
</p>
<p>Good 1 2 3 4 5 6 7 Bad
</p>
<p>Expensive 1 2 3 4 5 6 7 Inexpensive
</p>
<p>Useless 1 2 3 4 5 6 7 Useful
</p>
<p>4</p>
<p/>
<div class="annotation"><a href="http://translate.google.com">http://translate.google.com</a></div>
</div>
<div class="page"><p/>
<p>469
4.4 &middot; Conducting Primary Data Research
</p>
<p>the translated survey instrument and translates it back into the original language (Brislin 
1970). After the back-translation, the original and back-translated instruments are com-
pared and points of divergence are noted. The translation is then corrected to more accu-
rately reflect the intent of the wording in the original language.
</p>
<p>4.4.2.4 Set the Scale
</p>
<p>When deciding on scales, two separate decisions need to be made. First, you need to decide 
on the type of scale. Second, you need to set the properties of the scale you choose.
</p>
<p>z Type of Scale
Marketing research and practice have provided a variety of scale types. In the following, 
we discuss the most important (and useful) ones:
 4 Likert scales,
 4 semantic differential scales, and
 4 rank order scales.
</p>
<p>The most popular scale type used in questionnaires is the Likert scale (Liu et al. 2016). 
Likert scales are used to establish the degree of agreement with a specific statement. Such 
a statement could be &ldquo;I am very committed to Oddjob Airways.&rdquo; The degree of agreement 
is usually set by scale endpoints ranging from strongly disagree to strongly agree. Likert 
scales are used very frequently and are relatively easy to administer. Bear in mind that if 
the statement is too positive or negative, it is unlikely that the endings of the scale will be 
used, thereby reducing the number of answer categories actually used. We show an example 
of three Likert-scale-type items in . Fig.&nbsp;4.7, in which respondents assess the personality 
of the Oddjob Airways brand.
</p>
<p>The semantic differential scale is another scale type that features prominently in market 
research. Semantic differential scales use an opposing pair of words, normally adjectives 
(e.g., young/old, masculine/feminine) constituting the endpoint of the scale. Respondents 
then indicate how well one of the word in each pair describes how he or she feels about 
the object to be rated (e.g., a company or brand). These scales are widely used in market 
research. As with Likert scales, 5 or 7 answer categories are commonly used (see the next 
section on the number of answer categories you should use). We provide an example of 
the semantic differential scale in . Fig.&nbsp;4.8, in which respondents provide their view of 
Oddjob Airways.
</p>
<p>Rank order scales are a unique type of scale, as they force respondents to compare alter-
natives. In its basic form, a rank order scale allows respondents to indicate which alter-
native they rank highest, which alternative they rank second highest, etc. . Fig.&nbsp;4.9 shows 
an example. The respondents therefore need to balance their answers instead of merely 
</p>
<p>. Fig.&nbsp;4.7 Example of a 7-point Likert scale</p>
<p/>
</div>
<div class="page"><p/>
<p>70 Chapter 4 &middot; Getting Data
</p>
<p>stating that everything is important. In a more complicated form, rank order scales ask 
respondents to allocate a certain total number of points (often 100) to a number of alter-
natives. This is called the constant sum scale. Constant sum scales work well when a small 
number of answer categories are used (normally up to 5). Generally, respondents find con-
stant scales that have 6 or 7 answer categories somewhat challenging, while constant scales 
that have 8 or more categories are very difficult to answer. The latter are thus best avoided.
</p>
<p>. Fig.&nbsp;4.8 Example of a 7-point semantic differential scale
</p>
<p>. Fig.&nbsp;4.9 Example of a rank order scale
</p>
<p>In addition to these types of scaling, there are other types, such as graphic rating scales, which 
</p>
<p>use pictures to indicate categories, and the MaxDiff scale, in which respondents indicate the most 
</p>
<p>and least important items. We introduce the MaxDiff scale in the &darr; ̱Web Appendix (&rarr; Downloads). 
The MaxDiff scale is a form of Best-Worst scaling.
</p>
<p>&copy; EtiAmmos/Getty Images/iStock
</p>
<p>https://www.guide-market-research.com/app/download/13488664327/
</p>
<p>SPSS+3rd_Chapter+4_MaxDiff+scales.pdf?t=1516713250
</p>
<p>4</p>
<p/>
<div class="annotation"><a href="https://www.guide-market-research.com/app/download/13488664327/SPSS+3rd_Chapter+4_MaxDiff+scales.pdf?t=1516713250">https://www.guide-market-research.com/app/download/13488664327/SPSS+3rd_Chapter+4_MaxDiff+scales.pdf?t=1516713250</a></div>
<div class="annotation"><a href="https://www.guide-market-research.com/app/download/13488664327/SPSS+3rd_Chapter+4_MaxDiff+scales.pdf?t=1516713250">https://www.guide-market-research.com/app/download/13488664327/SPSS+3rd_Chapter+4_MaxDiff+scales.pdf?t=1516713250</a></div>
</div>
<div class="page"><p/>
<p>471
4.4 &middot; Conducting Primary Data Research
</p>
<p>z Properties of the Scale
After selecting the type of scale, we need to set the scale properties, which involves making 
several decisions:
 4 Decide on the number of response categories,
 4 choose between forced-choice scale and free-choice scales,
 4 design the response categories,
 4 label the response categories,
 4 decide whether to use a &ldquo;don&rsquo;t know&rdquo; option, and
 4 choose between a balanced and unbalanced scale.
</p>
<p>Decide on the number of response categories: When using closed-ended questions, the 
number of answer categories needs to be determined. In its simplest form, a survey could 
use just two answer categories (yes/no). Multiple categories (such as, &ldquo;completely disagree,&rdquo; 
&ldquo;disagree,&rdquo; &ldquo;neutral,&rdquo; &ldquo;agree,&rdquo; &ldquo;completely agree&rdquo;) are used more frequently to allow for 
more nuances. When determining how many scale categories to use, we face a trade-off 
between having more variation and differentiation in the responses versus burdening the 
respondents too much, which can trigger different types of response biases (e.g., Weijters 
et al. 2010). Because 5-point scales and 7-point scales are assumed to achieve this trade-
off well, their use has become common in marketing research (e.g., Fink 2003; Peterson 
1997). Research on these two scale types in terms of their reliability and validity is incon-
clusive, but the differences between them are generally not very pronounced (e.g., Lietz 
2010; Peng and Finn 2016; Weijters et al. 2010). Ten-point scales are often used in market 
research practice. However, scales with many answer categories often confuse respondents, 
because the wording differences between the scale points become trivial. For example, the 
difference between &ldquo;tend to agree&rdquo; and &ldquo;somewhat agree&rdquo; are subtle and respondents may 
not be able to differentiate between them. In such a case, respondents tend to choose cat-
egories in the middle of the scale (Rammstedt and Krebs 2007). Given this background, 
we recommend using 5-point or 7-point scales.
</p>
<p>Finally, many web surveys now use levers that allow scaling on a continuum without 
providing response categories. This scale type is called a visual analogue scale and is espe-
cially recommended if small differences in response behavior need to be detected. Visual 
analogue scales are well known in paper-and-pencil-based research (especially in the 
medical sector) and have become increasingly popular in web surveys. A visual analogue 
scale consists of a line and two anchors, one at each end. The anchors often consist of verbal 
materials that mark opposite ends of a semantic dimension (e.g., good and bad). However, 
the anchors may also be pictures, or even sound files. Visual anchors, such as smileys, are 
often used with participants who may not fully grasp the meaning of verbal materials&mdash;for 
example, preschool children (Reips and Funke 2008). Compared to ordinal scales, mea-
surement by means of visual analogue scales is more exact, leading to more narrow con-
fidence intervals, and higher power statistical tests. This exactness helps detect smaller 
effects that may be unobservable with ordinal scales (Reips and Funke 2008). However, 
although not all web survey platforms offer visual analogue scales, you should use them if 
possible. . Fig.&nbsp;4.10 shows an example of a visual analogue scale that measures customers&rsquo; 
expectations of Oddjob Airways.
</p>
<p>Choose between a forced-choice scale and a free-choice scale: Sometimes, researchers and 
practitioners use 4-point or 6-point scales that omit the neutral category, thereby forcing 
the respondents to be positive or negative. Using such a forced-choice scale could bias the </p>
<p/>
</div>
<div class="page"><p/>
<p>72 Chapter 4 &middot; Getting Data
</p>
<p>answers, leading to validity issues.6 By providing a neutral category choice (i.e., a free-
choice scale), the respondents are not forced to give a positive or negative answer. Many 
respondents feel more comfortable about participating in a survey using a free-choice scale 
(Nowlis et al. 2002). Furthermore, research has shown that including a neutral category 
minimizes response bias (Weijters et al. 2010). Therefore, we strongly suggest using free-
choice scales and including a neutral category.
</p>
<p>Design the response categories: When designing response categories for categorical 
variables, use response categories that are exclusive, so that answers do not overlap (e.g., 
age categories 0&ndash;4, 5&ndash;10, etc.). The question here is: How do we decide on the spacing 
between the categories? For example, should we divide US household income in the cat-
egories 0&ndash;$9999, $10,000&ndash;$19,999, $20,000-higher, or use another way to set the catego-
ries? One suggestion is to use narrower categories if the respondent can recall the variable 
easily. A second suggestion is to space the categories so that we, as researchers, expect 
an approximately equal number of observations per category. In the example above, we 
may find that most households have an income of $20,000 or higher and that categories 
0&ndash;$9999 and $10,000&ndash;$19,999 are infrequently used. It is best to choose categories where 
equal percentages are expected such as 0&ndash;$24,999, $25,000&ndash;$44,999, $45,000&ndash;$69,999, 
$70,000&ndash;$109,999, $110,000&ndash;and higher. Although the range in each category differs, we 
can reasonably expect each category to hold about 20&nbsp;% of the responses if we sample US 
households randomly (https://en.wikipedia.org/wiki/Household_income_in_the_United_
States#Household_income_over_time). Box 4.6 shows a real-life example of oddly chosen 
response categories (and there are a few other issues too!).
</p>
<p>Note that the response categories also give the respondents the range of acceptable 
answers. Respondents generally view the middle of the scale as normal, or most common, 
and position themselves in relation to this (e.g., Revilla 2015). For example, Tourangeau 
and Smith (1996) found that the reported number of sexual partners in an open-ended 
question is more than twice as high when the answer category labels used in a previously 
asked closed-ended question on the same topic shifted to indicate higher numbers (from 
0, 1, 2, 3, 4, 5 or more to 0, 1&ndash;4, 5&ndash;9, 10&ndash;49, 50&ndash;99, 100 or more).
</p>
<p>. Fig.&nbsp;4.10 Example of a visual analogue scale
</p>
<p>6 Forced-choice scales can, of course, also be used for uneven response categories such as 5-point or 
</p>
<p>7-point Likert scales.
</p>
<p>4</p>
<p/>
<div class="annotation"><a href="https://en.wikipedia.org/wiki/Household_income_in_the_United_States#Household_income_over_time">https://en.wikipedia.org/wiki/Household_income_in_the_United_States#Household_income_over_time</a></div>
<div class="annotation"><a href="https://en.wikipedia.org/wiki/Household_income_in_the_United_States#Household_income_over_time">https://en.wikipedia.org/wiki/Household_income_in_the_United_States#Household_income_over_time</a></div>
</div>
<div class="page"><p/>
<p>473
4.4 &middot; Conducting Primary Data Research
</p>
<p>Label the response categories: A common way of labeling response categories is to 
use endpoint labels only, omitting intermediary labels. For example, instead of label-
ing all five points of a Likert scale (e.g., &ldquo;completely disagree,&rdquo; &ldquo;disagree,&rdquo; &ldquo;neutral,&rdquo; 
&ldquo;agree,&rdquo; and &ldquo;completely agree&rdquo;), we only label the endpoints (e.g., &ldquo;completely disagree&rdquo; 
and &ldquo;completely agree&rdquo;). While this approach makes response category labeling easy, 
it also amplifies acquiescence 7&nbsp;Chap.&nbsp;5, because the endpoints reinforce the respon-
dents&rsquo; agreement (Weijters et al. 2010). Conversely, if all the categories are labeled, this 
helps the respondents interpret and differentiate, making the midpoint more salient 
and accessible. Labeling the response categories fully also increases the scale reliability 
(Weng 2004), but reduces criterion validity. Drawing on Weijters et al. (2010), we gen-
erally recommend only labeling the endpoints. However, when using the items for pre-
diction-type analyses, such as in correlation and regression analyses, it is beneficial to 
label all the categories.7
</p>
<p>Decide whether or not to use a &ldquo;don&rsquo;t know&rdquo; option: Another important choice to make 
is whether or not to include a &ldquo;don&rsquo;t know&rdquo; option in the scaling (Lietz 2010). Using a 
&ldquo;don&rsquo;t know&rdquo; option allows the researcher to distinguish between those respondents who 
have a clear opinion and those who do not. Moreover, the respondents may find that 
answering the survey is slightly easier. While these are good reasons for including this 
category, the drawback is that there will then be missing observations. If many respon-
dents choose not to answer, this will substantially reduce the number of surveys that 
can be used for analysis. Generally, when designing surveys, you should only include 
a &ldquo;don&rsquo;t know&rdquo; (or &ldquo;undecided&rdquo;) option as an answer to questions that the respondents 
might genuinely not know, for example, when requiring answers to factual questions. 
If included, the option should appear at the end of the scale. The &ldquo;don&rsquo;t know&rdquo; option 
should not be included in other types of questions (such as on attitudes or preferences), 
as researchers are interested in the respondents&rsquo; perceptions regardless of their knowl-
edge of the subject matter.
</p>
<p>7 Sometimes, researchers number the response options. For example, when numbering the response 
</p>
<p>options of a 7-point scale you can use only positive numbers (1 to 7), or positive and negative num-
</p>
<p>bers (-3 to +3). For recommendations, see Cabooter et al. (2016).
</p>
<p>Box 4.6 Oddly chosen response categories</p>
<p/>
</div>
<div class="page"><p/>
<p>74 Chapter 4 &middot; Getting Data
</p>
<p>Choose between a balanced and unbalanced scale: A balanced scale has an equal number 
of positive and negative scale categories. For example, in a 5-point Likert scale, we may 
have two negative categories (completely disagree and disagree), a neutral option, and two 
positive categories (agree and completely agree). Besides this, the wording in a balanced 
scale should reflect equal distances between the scale items. This is called an equidistant 
scale, which is a requirement for analysis techniques such as factor analysis (7 Chap.&nbsp;8). 
Consequently, we strongly recommend using a balanced scale instead of an unbalanced 
scale. A caveat of balanced scales is that many constructs cannot have negative values. For 
example, one can have some trust in a company or very little trust, but negative trust is 
highly unlikely. If a scale item cannot be negative, you will have to resort to an unbalanced 
scale in which the endpoints of the scales are unlikely to be exact opposites. . Table&nbsp;4.1 
summarizes the key choices we have to make when designing survey items.
</p>
<p>4.4.2.5 Design the Questionnaire
</p>
<p>After determining the individual questions, you have to integrate these, together with other 
elements, to create the questionnaire. Questionnaire design involves the following elements:
</p>
<p> 4 Designing the starting pages of the questionnaire,
 4 choosing the order of the questions, and
 4 designing the layout and format.
</p>
<p>Starting pages of the questionnaire: At the beginning of each questionnaire, the importance 
and goal are usually described to stress that the results will be treated confidentially, and to 
mention what they will be used for. This is usually followed by an example question (and 
answer), to demonstrate how the survey should be filled out. Keep this page very short 
when using mobile surveys.
</p>
<p>If questions relate to a specific issue, moment, or transaction, you should indicate this 
clearly at the very beginning. For example, &ldquo;Please provide answers to the following ques-
tions, keeping the purchase of product X in mind.&rdquo; If applicable, you should also point out 
that your survey is conducted in collaboration with a university, a recognized research 
institute, or a known charity, as this generally increases respondents&rsquo; willingness to partic-
ipate. Moreover, do not forget to provide a name and contact details for those participants 
who have questions, or if technical problems should arise. Consider including a photo of 
the research team, as this increases response rates. Lastly, you should thank the respondents 
for their time and describe how the questionnaire should be returned (for mail surveys).
</p>
<p>Order of the questions: Choosing an appropriate question order is crucial, because it 
determines the questionnaire&rsquo;s logical flow and therefore contributes to high response 
rates. The order of questions is usually as follows:
1. Screening questions (typically simply referred to as screeners) come first. These 
</p>
<p>questions determine what parts of the survey a respondent should fill out.
2. Next, ask questions relating to the study&rsquo;s key variables. This includes the dependent 
</p>
<p>variables, followed by the independent variables.
3. Use a funnel approach. That is, ask questions that are more general first and then 
</p>
<p>move on to details. This makes answering the questions easier as the order helps the 
respondents recall. Make sure that sensitive questions are put at the very end of this 
section.
</p>
<p>4. Questions related to demographics are placed last if they are not part of the 
screening questions. If you ask demographic questions, always check whether 
</p>
<p>4</p>
<p/>
</div>
<div class="page"><p/>
<p>475
4.4 &middot; Conducting Primary Data Research
</p>
<p>. Table 4.1 A summary of some of the key choices when designing survey items
</p>
<p>Aspect Recommendation
</p>
<p>Item content
</p>
<p>Can all the respondents 
</p>
<p>answer the question 
</p>
<p>asked?
</p>
<p>Ensure that all potential respondents can answer all items. If they 
</p>
<p>cannot, ask screener questions to direct them. If the respondents 
</p>
<p>cannot answer questions, they should be able to skip them.
</p>
<p>Can the respondents 
</p>
<p>construct or recall the 
</p>
<p>answers?
</p>
<p>If the answer is no, you should use other methods to obtain 
</p>
<p>information (e.g., secondary data or observations).
</p>
<p>Moreover, you should ask the respondents about major aspects before 
</p>
<p>zooming in on details to help them recall answers.
</p>
<p>Do the respondents 
</p>
<p>want to answer each 
</p>
<p>question?
</p>
<p>If the questions concern &ldquo;sensitive&rdquo; subjects, check whether they 
</p>
<p>can be omitted. If not, stress the confidentiality of the answers 
</p>
<p>and mention why these answers are useful for the researcher, the 
</p>
<p>respondent, or society before introducing them.
</p>
<p>Open-ended or closed-
</p>
<p>ended questions?
</p>
<p>Keep the subsequent coding in mind. If easy coding is possible 
</p>
<p>beforehand, design a set of exhaustive answer categories. Further, 
</p>
<p>remember that open-ended scale items have a much lower response 
</p>
<p>rate than closed-ended items.
</p>
<p>Item wording
</p>
<p>Grammar and 
</p>
<p>sentences
</p>
<p>Use simple wording and grammar. Keep sentences short. Avoid 
</p>
<p>negations, vague quantifiers, and double-barreled questions. Employ 
</p>
<p>reverse-scaled items sparingly. Use back-translation if necessary.
</p>
<p>Type of scale
</p>
<p>Number of response 
</p>
<p>categories
</p>
<p>Use visual analogue scales. If not available, use 5-point or 7-point 
</p>
<p>scales.
</p>
<p>Forced-choice or free-
</p>
<p>choice scale?
</p>
<p>Use a free-choice scale by including a neutral category.
</p>
<p>Design of the response 
</p>
<p>categories
</p>
<p>Ensure that the response categories are exclusive and that each 
</p>
<p>category has approximately the same percentage of responses.
</p>
<p>What scaling categories 
</p>
<p>should you use (closed-
</p>
<p>ended questions only)?
</p>
<p>Use visual analogue scales if possible, otherwise Likert scales. If the 
</p>
<p>question requires this, use semantic differential scales, or rank order 
</p>
<p>scales.
</p>
<p>Labeling of response 
</p>
<p>categories
</p>
<p>Label endpoints only. When using the items for prediction-type 
</p>
<p>analyses, label all categories.
</p>
<p>Inclusion of a &ldquo;Don&rsquo;t 
</p>
<p>know&rdquo; option
</p>
<p>Include a &ldquo;Don&rsquo;t know&rdquo; option only for items that the respondent 
</p>
<p>might genuinely not know. If included, place this at the end of the 
</p>
<p>scale.
</p>
<p>Balanced or 
</p>
<p>unbalanced scale?
</p>
<p>Always use a balanced scale. There should be an exact number of 
</p>
<p>positive and negative wordings in the scale items. The words at the 
</p>
<p>ends of the scale should be exact opposites.</p>
<p/>
</div>
<div class="page"><p/>
<p>76 Chapter 4 &middot; Getting Data
</p>
<p>they are relevant to the research goal and if they are not already known.8 In 
addition, check if these demographics are likely to lead to non-response. Asking 
about demographics, like income, educational attainment, or health, may result 
in a substantial number of respondents refusing to answer. If such sensitive 
demographics are not necessary, omit them from the survey. Note that in certain 
countries asking about a respondent&rsquo;s demographic characteristics means you must 
adhere to specific laws, such as the Data Protection Act 1998 in the UK.
</p>
<p>If your questionnaire comprises several sections (e.g., in the first section, you ask about the 
respondents&rsquo; buying attitudes and, in the following section, about their satisfaction with 
the company&rsquo;s services), you should make the changing context clear to the respondents.
</p>
<p>Layout and format of the survey: The layout of both mail and web-based surveys should 
be concise and should conserve space where possible, particularly in respect of mobile 
surveys. Avoid using small and colored fonts, which reduce readability. Booklets work well 
for mail-based surveys, since postage is often cheaper if surveys fit in standard envelopes. 
If this is not possible, single-sided stapled paper can also work. When using web-based 
surveys, it is good to have a counter that tells the respondents what percentage of the ques-
tions they have already filled out. This gives them some indication of how much time they 
are likely to need to complete the survey. Make sure the layout is simple and compatible 
with mobile devices and tablets. Qualtrics and other survey tools offer mobile-friendly 
display options, which should always be ticked.
</p>
<p>4.4.2.6 Pretest the Questionnaire and Execution
</p>
<p>We have already mentioned the importance of pretesting the survey several times. Before 
any survey is sent out, you should pretest the questionnaire to enhance its clarity and to 
ensure the client&rsquo;s acceptance of the survey. Once the questionnaire is in the field, there 
is no way back! You can pretest questionnaires in two ways. In its simplest form, you can 
use a few experts (say 3&ndash;6) to read the survey, fill it out, and comment on it. Many web-
based survey tools allow researchers to create a pretested version of their survey, in which 
there is a text box for comments behind every question. Experienced market researchers 
can spot most issues right away and should be employed to pretest surveys. If you aim for 
a very high quality survey, you should also send out a set of preliminary (but proofread) 
questionnaires to a small sample of 50&ndash;100 respondents. The responses (or lack thereof) 
usually indicate possible problems and the preliminary data can be analyzed to determine 
the potential results. Never skip pretesting due to time issues, since you are likely to run 
into problems later!
</p>
<p>Motivating potential respondents to participate is an increasingly important aspect 
of survey research. In addition to Dillman et al.&rsquo;s (2014) recommendations on how to 
increase response rates (Box 4.7), incentives are used. A simple example of such an incen-
tive is to provide potential respondents with a cash reward. In the US, one-dollar bills are 
often used for this purpose. Respondents who participate in (online) research panels often 
receive points that can be exchanged for products and services. For example, Research 
</p>
<p>8 The demographics of panels (see 7 Sect.&nbsp;4.4.2.2) are usually known.
</p>
<p>4</p>
<p/>
</div>
<div class="page"><p/>
<p>477
4.5 &middot; Basic Qualitative Research
</p>
<p>Now, a market research company, gives its Canadian panel members AirMiles that can be 
exchanged for, amongst others, free flights. A special type of incentive is to indicate that 
some money will be donated to a charity for every returned survey. ESOMAR, the world 
organization for market and social research (see 7 Chap.&nbsp;10), suggests that incentives for 
interviews or surveys should &ldquo;be kept to a minimum level proportionate to the amount of 
their time involved, and should not be more than the normal hourly fee charged by that 
person for their professional consultancy or advice.&rdquo;
</p>
<p>Another incentive is to give the participants a chance to win a product or service. For 
example, you could randomly give a number of participants gifts. The participants then 
need to disclose their name and address in exchange for a chance to win a gift so that 
they can be reached. While this is not part of the research itself, some respondents may 
feel uncomfortable providing their contact details, which could potentially reduce the 
response rate.
</p>
<p>Finally, reporting the findings to the participants is an incentive that may help par-
ticipation (particularly in professional settings). This can be done by providing a general 
report of the study and its findings, or by providing a customized report detailing the par-
ticipant&rsquo;s responses and comparing them with all the other responses (Winkler et al. 2015). 
Obviously, anonymity needs to be assured so that the participants cannot compare their 
answers to those of other individual responses.
</p>
<p>4.5 Basic Qualitative Research
</p>
<p>Qualitative research is mostly used to gain an understanding of why certain things happen. 
It can be used in an exploratory context by defining problems in more detail, or by devel-
oping hypotheses to be tested in subsequent research. Qualitative research also allows 
researchers to learn about consumers&rsquo; perspectives and vocabulary, especially if they are 
not familiar with the context (e.g., the industry). As such, qualitative research offers impor-
tance guidance when little is known about consumers&rsquo; attitudes and perceptions, or the 
market (Barnham 2015).
</p>
<p>As discussed in 7 Chap.&nbsp;3, qualitative research leads to the collection of qualitative 
data. One can collect qualitative data by explicitly informing the participants that you are 
</p>
<p> Box 4.7 Dillman et al.&rsquo;s (2014) recommendations on how to increase response rates
</p>
<p>It is becoming increasingly difficult to get people to fill out surveys. This may be due to over-
</p>
<p>surveying, dishonest firms that disguise sales as research, and a lack of time. Dillman et al. (2014) 
</p>
<p>discuss four steps to increase response rates:
</p>
<p>1. Send out a pre-notice letter indicating the importance of the study and announcing that a 
</p>
<p>survey will be sent out shortly.
</p>
<p>2. Send out the survey with a sponsor letter, again indicating the importance of the study.
</p>
<p>3. Follow up after 3&ndash;4&nbsp;weeks with a thank you note (for those who responded) and the same 
</p>
<p>survey, plus a reminder (for those who did not respond).
</p>
<p>4. Call or email those who have still not responded and send out a thank you note to those who 
</p>
<p>replied during the second round.</p>
<p/>
</div>
<div class="page"><p/>
<p>78 Chapter 4 &middot; Getting Data
</p>
<p>doing research (directly observed qualitative data), or you can simple observe the par-
ticipants&rsquo; behavior without them being explicitly aware of the research goals (indirectly 
observed qualitative data). There are ethical issues associated with conducting research 
if the participants are not aware of the research purpose. Always check the regulations 
regarding what is allowed in your context and what not. It is, in any case, good practice 
to brief the participants on their role and the goal of the research once the data have been 
collected.
</p>
<p>The two key forms of directly observed qualitative data are in-depth interviews and 
focus groups. Together, they comprise most of the conducted qualitative market research. 
First, we will discuss in-depth interviews, which are&mdash;as the terms suggests&mdash;interviews 
conducted with one participant at a time, allowing for high levels of personal interaction 
between the interviewer and respondent. Next, we will discuss projective techniques, a 
frequently used type of testing procedure in in-depth interviews. Lastly, we will introduce 
focus group discussions, which are conducted with multiple participants.
</p>
<p>4.5.1 In-depth Interviews
</p>
<p>In-depth interviews are qualitative conversations with participants on a specific topic. 
These participants are often consumers, but, in a market research study, they may also 
be the decision-makers, who are interviewed to gain an understanding of their clients&rsquo; 
needs. They may also be government or company representatives. The structure levels 
of interviews vary. In their simplest form, interviews are unstructured and the partic-
ipants talk about a topic in general. This works well if you want to obtain insight into a 
topic, or as an initial step in a research process. Interviews can also be fully structured, 
meaning all the questions and possible answer categories are decided beforehand. This 
way allows you to collect quantitative data. However, most in-depth interviews for 
gathering qualitative data are semi-structured and contain a series of questions that 
need to be addressed, but have no specific format regarding what the answers should 
look like. The person interviewed can make additional remarks, or discuss somewhat 
related issues, but is not allowed to wander off too far. In these types of interviews, the 
interviewer often asks questions like &ldquo;that&rsquo;s interesting, could you explain?,&rdquo; or &ldquo;how 
come &hellip; ?&rdquo; to gain more insight into the issue. In highly structured interviews, the 
interviewer has a fixed set of questions and often a fixed amount of time for each per-
son&rsquo;s response. The goal of structured interviews is to maximize the comparability of 
the answers. Consequently, the set-up of the questions and the structure of the answers 
need to be similar.
</p>
<p>In-depth interviews are unique in that they allow probing on a one-to-one basis, thus 
fostering an interaction between the interviewer and interviewee. In-depth interviews 
also work well when those being interviewed have very little time and when they do not 
want the information to be shared with the other study participants. This is, for example, 
probably the case when you discuss marketing strategy decisions with CEOs. The draw-
backs of in-depth interviews include the amount of time the researcher needs to spend on 
the interview itself and on traveling (if the interview is conducted face-to-face and not via 
the telephone), as well as on transcribing the interview.
</p>
<p>4</p>
<p/>
</div>
<div class="page"><p/>
<p>479
4.5 &middot; Basic Qualitative Research
</p>
<p>When conducting in-depth interviews, a set format is usually followed. First, the 
interview details are discussed, such as confidentiality issues, the interview topic, 
the structure, and the duration. Moreover, the interviewer should disclose whether 
the interview is being recorded and inform the interviewee that there is no right or 
wrong answer, just opinions on the subject. The interviewer should also try to be open 
and maintain eye contact with the interviewee. Interviewers can end an interview by 
informing their respondents that they have reached the last question and thanking 
them for their time.
</p>
<p>Interviews are often used to investigate means-end issues, in which researchers try to understand 
</p>
<p>what ends consumers aim to satisfy and which means (consumption) they use to do so. A means-
end approach involves first determining a product&rsquo;s attributes. These are the functional product 
features, such as the speed a car can reach or its acceleration. Subsequently, researchers look at 
</p>
<p>the functional consequences that follow from the product benefits. This could be driving fast. 
</p>
<p>The psychosocial consequences, or personal benefits, are derived from the functional benefits 
</p>
<p>and, in this example, could include an enhanced status, or being regarded as successful. Finally, 
</p>
<p>the psychosocial benefits are linked to people&rsquo;s personal values or life goals, such as a desire for 
</p>
<p>success or acceptance. Analyzing and identifying the relationships between these steps is called 
</p>
<p>laddering.
</p>
<p>4.5.2 Projective Techniques
</p>
<p>Projective techniques describe a special type of testing procedure, usually used as 
part of in-depth interviews. These techniques provide the participants with a stim-
ulus and then gauge their responses. Although participants in projective techniques 
know that they are participating in a market research study, they may not be aware of 
the research&rsquo;s specific purpose. The stimuli that the projective techniques provide are 
ambiguous and require a response from the participants. Sentence completion is a key 
form of projective techniques.
</p>
<p>An iPhone user is someone who: ...................................................................
</p>
<p>The Apple brand makes me think of: ...................................................................
</p>
<p>iPhones are most liked by: ...................................................................
</p>
<p>In this example, the respondents are asked to express their feelings, ideas, and opinions 
in a free format.
</p>
<p>Projective techniques&rsquo; advantage is that they allow for responses when people are 
unlikely to respond if they were to know the study&rsquo;s exact purpose. Thus, projective 
techniques can overcome self-censoring and allow expression and fantasy. In addi-
tion, they can change a participant&rsquo;s perspective. Think of the previous example. If the 
participants are iPhone users, the sentence completion example asks them how they 
think other people regard them, not what they think of the iPhone. A drawback is that 
projective techniques require the responses to be interpreted and coded, which can 
be difficult.</p>
<p/>
</div>
<div class="page"><p/>
<p>80 Chapter 4 &middot; Getting Data
</p>
<p>4.5.3 Focus Groups
</p>
<p>Focus groups are interviews conducted with a number of respondents at the same time 
and led by a moderator. This moderator leads the interview, structures it, and often plays 
a central role in transcribing the interview later. Focus groups are usually semi or highly 
structured. The group usually comprises between 6 and 10 people to allow for interaction 
between the participants and to ensure that all the participants have a say. The duration 
of a focus group interview varies, but is often between 30 and 90&nbsp;minutes for company 
employee focus groups and between 60 to 120&nbsp;minutes for consumers. When focus groups 
are held with company employees, moderators usually travel to the company and conduct 
their focus group in a room. When consumers are involved, moderators often travel to a 
market research company, or hotel, where the focus group meets in a conference room. 
Market research companies often have specially equipped conference rooms with, for 
example, one-way mirrors, built-in microphones, and video recording devices.
</p>
<p>Learn more about focus groups in this TED-Ed video.
</p>
<p>&copy; ALotOfPeople/Getty Images/iStock
</p>
<p>https://www.youtube.com/watch?v=3TwgVQIZPsw
</p>
<p>How are focus groups structured? They usually start with the moderator introducing the 
topic and discussing the background. Everyone in the group is introduced to all the others 
to establish rapport. Subsequently, the moderator encourages the members of the focus 
group to speak to one another, instead of asking the moderator for confirmation. Once 
the focus group members start discussing topics with one another, the moderator tries to 
stay in the background, merely ensuring that the discussions stay on-topic. Afterwards, 
the participants are briefed and the discussions are transcribed for further analysis.
</p>
<p>Focus groups have distinct advantages: they are relatively cheap compared to in-depth 
interviews, work well with issues that are socially important, or which require spontaneity. 
They are also useful for developing new ideas. On the downside, focus groups do not offer 
</p>
<p>4</p>
<p/>
<div class="annotation"><a href="https://www.youtube.com/watch?v=3TwgVQIZPsw">https://www.youtube.com/watch?v=3TwgVQIZPsw</a></div>
</div>
<div class="page"><p/>
<p>481
4.6 &middot; Collecting Primary Data through Experimental Research
</p>
<p>the same opportunity for probing as interviews do, and also run a greater risk of going 
off-topic. Moreover, a few focus group members may dominate the discussion and, espe-
cially in larger focus groups, &ldquo;voting&rdquo; behavior may occur, hindering real discussions and 
the development of new ideas. . Table&nbsp;4.2 summarizes the key differences between focus 
groups and in-depth interviews.
</p>
<p>4.6 Collecting Primary Data through Experimental Research
</p>
<p>In 7 Chap.&nbsp;2, we discussed causal research and briefly introduced experiments as a means 
of conducting research. The goal of experiments is to avoid unintended influences through 
the use of randomization. Experiments are typically conducted by manipulating one vari-
able, or a few, at a time. For example, we can change the price of a product, the type of 
product, or the package size to determine whether these changes affect important out-
comes such as attitudes, satisfaction, or intentions. Simple field observations are often 
</p>
<p>. Table 4.2 Comparing focus groups and in-depth interviews
</p>
<p>Focus groups In-depth interviews
</p>
<p>Group 
</p>
<p>interactions
</p>
<p>Group interaction, which may 
</p>
<p>stimulate the respondents to produce 
</p>
<p>new thoughts.
</p>
<p>There is no group interaction. 
</p>
<p>The interviewer is responsible for 
</p>
<p>stimulating the respondents to 
</p>
<p>produce new ideas.
</p>
<p>Group/peer 
</p>
<p>pressure
</p>
<p>Group pressure and stimulation may 
</p>
<p>clarify and challenge thinking.
</p>
<p>In the absence of group pressure, 
</p>
<p>the respondents&rsquo; thinking is not 
</p>
<p>challenged.
</p>
<p>Peer pressure and role playing. With just one respondent, role playing 
</p>
<p>is minimized and there is no peer 
</p>
<p>pressure.
</p>
<p>Respondent 
</p>
<p>competition
</p>
<p>Respondents compete with one 
</p>
<p>another for time to talk. There is less 
</p>
<p>time to obtain in-depth details from 
</p>
<p>each participant.
</p>
<p>Individuals are alone with the 
</p>
<p>interviewer and can express their 
</p>
<p>thoughts in a non-competitive 
</p>
<p>environment. There is more time to 
</p>
<p>obtain detailed information.
</p>
<p>Peer 
</p>
<p>influence
</p>
<p>Responses in a group may be biased by 
</p>
<p>other group members&rsquo; opinions.
</p>
<p>With one respondent, there is no 
</p>
<p>potential of other respondents 
</p>
<p>influencing this person.
</p>
<p>Subject 
</p>
<p>sensitivity
</p>
<p>If the subject is sensitive, respondents 
</p>
<p>may be hesitant to talk freely in the 
</p>
<p>presence of other people.
</p>
<p>If the subject is sensitive, respondents 
</p>
<p>may be more likely to talk.
</p>
<p>Stimuli The volume of stimulus materials that 
</p>
<p>can be used is somewhat limited.
</p>
<p>A fairly large amount of stimulus 
</p>
<p>material can be used.
</p>
<p>Interviewer 
</p>
<p>schedule
</p>
<p>It may be difficult to assemble between 
</p>
<p>6 and 10 respondents if they are a 
</p>
<p>difficult type to recruit (such as busy 
</p>
<p>executives).
</p>
<p>Individual interviews are easier to 
</p>
<p>schedule.</p>
<p/>
</div>
<div class="page"><p/>
<p>82 Chapter 4 &middot; Getting Data
</p>
<p>unable to establish these relationships, as inferring causality is problematic. Imagine a 
company that wants to introduce a new type of soft drink aimed at health-conscious con-
sumers. If the product were to fail, the managers would probably conclude that the con-
sumers did not like the product. However, many (usually unobserved) variables, such as 
competitors&rsquo; price cuts, changing health concerns, and a lack of availability, can also influ-
ence new products&rsquo; success.
</p>
<p>4.6.1 Principles of Experimental Research
</p>
<p>Experiments deliberately impose one or more treatments and then observe the outcome of a 
specific treatment (Mitchell and Jolley 2013). This way, experiments attempt to isolate how 
one change affects an outcome. The outcome(s) is (are) the dependent variable(s) and the 
independent variable(s) (also referred to as factors) are used to explain the outcomes. To 
examine the influence of the independent variable(s) on the dependent variable(s), the par-
ticipants are subjected to treatments. These are supposed to manipulate the participants by 
putting them in different situations. A simple form of treatment could be an advertisement 
with and without humor. In this case, the humor is the independent variable, which can take 
two levels (i.e., with or without humor). If we manipulate, for example, the price between 
low, medium, and high, we have three levels. When selecting independent variables, we 
normally include those that marketers care about and which are related to the marketing 
and design of the products and services. To assure that the participants do indeed perceive 
differences, manipulation checks are conducted. For example, if two different messages 
with and without humor are used as stimuli, we could ask the respondents which of the 
two is more humorous. Such manipulation checks help establish an experiment&rsquo;s validity.
</p>
<p>Experiments can be incredibly useful but conducting experiments without user consent can result 
</p>
<p>in a consumer backlash, ethics concerns, or may even be illegal as Facebook found out.
</p>
<p>&copy; bombuscreative/Getty Images/iStock
</p>
<p>https://www.youtube.com/watch?v=VmQAdsCSonA
</p>
<p>4</p>
<p/>
<div class="annotation"><a href="https://www.youtube.com/watch?v=VmQAdsCSonA">https://www.youtube.com/watch?v=VmQAdsCSonA</a></div>
</div>
<div class="page"><p/>
<p>483
4.6 &middot; Collecting Primary Data through Experimental Research
</p>
<p>Care should be taken not to include too many of these variables in order to keep the 
experiment manageable. An experiment that includes four independent variables, each 
of which has three levels and includes every possible combination (called a full factorial 
design) requires 43 &nbsp;=&nbsp; 64 treatments. Large numbers of levels (5 or more) will dramatically 
increase the complexity and cost of the research. Finally, extraneous variables, such as the 
age or income of the experiment participant, are not changed as part of the experiment. 
However, it might be important to control for their influence when setting up the exper-
imental design.
</p>
<p>Experiments can run in either a lab or field environment. Lab experiments are per-
formed in controlled environments (usually in a company or academic lab), thereby allow-
ing for isolating the effects of one or more variables on a certain outcome. Extraneous 
variables&rsquo; influence can also be controlled for. Lab experiments stand out in terms of inter-
nal validity, which is the extent to which we can make causal claims based on the study. 
However, as they take place in controlled experimental settings, which typically ignore 
real-world business conditions, they therefore usually lack external validity, which is the 
extent to which the study results can be generalized to similar settings. Field experiments, 
on the other hand, are performed in natural environments (e.g., in a supermarket or in 
home) and, as such, generally exhibit high degrees of external validity. However, since con-
trolling for extraneous variables&rsquo; impact is difficult in natural environments, field experi-
ments usually lack internal validity (Gneezy 2017).
</p>
<p>4.6.2 Experimental Designs
</p>
<p>Experimental design refers to an experiment&rsquo;s structure. There are various types of exper-
imental designs. To clearly separate the different experimental designs, researchers have 
developed the following notation:
</p>
<p>O: A formal observation or measurement of the dependent variable. Subscripts below an 
</p>
<p>observation O such as 1 or 2, indicate measurements at different points in time.
</p>
<p>X: The test participants&rsquo; exposure to an experimental treatment.
</p>
<p>R: The random assignment of participants. Randomization ensures control over extraneous 
</p>
<p>variables and increases the experiment&rsquo;s reliability and validity.
</p>
<p>In the following, we will discuss the most prominent experimental designs:
 4 One-shot case study,
 4 before-after design,
 4 before-after design with a control group, and
 4 Solomon four-group design.
</p>
<p>The simplest form of experiment is the one-shot case study. This type of experiment is 
structured as follows:9
</p>
<p>9 If one symbol precedes another, it means that the first symbol precedes the next one in time.</p>
<p/>
</div>
<div class="page"><p/>
<p>84 Chapter 4 &middot; Getting Data
</p>
<p>X O1
</p>
<p>This means we have one treatment (indicated by X), such as a new advertising campaign. 
After the treatment, we await reactions to it and then measure the outcome of the manip-
ulation (indicated by O1), such as the participants&rsquo; willingness to purchase the advertised 
product. This type of experimental set-up is common, but does not tell us if the effect is 
causal. One reason for this is that we did not measure anything before the treatment and 
therefore cannot assess what the relationship between the treatment and outcome is. The 
participants&rsquo; willingness to purchase the product was perhaps higher before they were 
shown the advertisement, but since we did not measure their willingness to purchase 
before the treatment, this cannot be ruled out. Consequently, this design does not allow 
us to establish causality.
</p>
<p>The simplest type of experiment that allows us to make causal inferences&mdash;within 
certain limits&mdash;is the before-after design used for one group. The notation for this design is:
</p>
<p>O1 X O2
</p>
<p>We have one measurement before (O1) and one after a treatment (O2). Thus, this type of 
design can be used to determine whether an advertisement has a positive, negative, or no 
effect on the participants&rsquo; willingness to purchase a product.
</p>
<p>A problem with this type of design is that we do not have a standard of comparison 
with which to contrast the change between O1 and O2. While the advertisement may have 
increased the participants&rsquo; willingness to purchase, this might have been even higher if 
they had not seen the advertisement. The reason for this is that the before-after-design 
does not control for influences occurring between the two measurements. For example, 
negative publicity after the initial measurement could influence the subsequent measure-
ment. These issues make the &ldquo;real&rdquo; effect of the advertisement hard to assess.
</p>
<p>If we want to have a much better chance of identifying the &ldquo;real&rdquo; effect of a treatment, 
we need a more complex setup, called the before-after design with a control group. In this 
design, we add a control group who is not subjected to the treatment X. The notation of 
this type of experiment is:
</p>
<p>Experimental group (R) O1 X O2
</p>
<p>Control group (R) O3 O4
</p>
<p>The effect attributed to the experiment is the difference between O1 and O2 minus the 
difference between O3 and O4. For example, if the participants&rsquo; willingness to purchase 
increases much stronger in the experimental group (i.e., O2 is much higher than O1) than 
in the control group (i.e., O4 is slightly higher than or equal to O3), the advertisement has 
had an impact on the participants.
</p>
<p>The random assignment of the participants to the experimental and the control 
groups (indicated by R), is an important element of this experimental design. This means 
that, for any given treatment, every participant has an equal probability of being chosen 
for one of the two groups. This ensures that participants with different characteristics 
</p>
<p>4</p>
<p/>
</div>
<div class="page"><p/>
<p>485
4.7 &middot; Oddjob Airways (Case Study)
</p>
<p>are spread randomly (and, it is hoped, equally) between the treatment(s), which will 
neutralize self-selection. Self-selection occurs when participants can select themselves 
into either the experimental or the control group. For example, if participants who like 
sweets participate in a cookie tasting test, they will certainly try to give the treatment 
(cookie) a try! See Mooi and Gilliland (2013) for an example of self-selection and an 
analysis method.
</p>
<p>However, the before-after experiment with a control group does have limitations. The 
initial measurement O1 may alert the participants that they are being studied, which may 
bias the post measurement O2. This effect is also referred to as the before measurement 
effect, or the testing effect (Campbell and Stanley 1966). Likewise, the initial measure-
ment O1 may incite the participants to drop out of the experiment, leading to no recorded 
response for O2. If there is a systematic reason for the participants to drop out, this will 
threaten the experiment&rsquo;s validity.
</p>
<p>The Solomon four-group design is an experimental design accounting for before mea-
surement effects and is structured as follows (Campbell and Stanley 1966):
</p>
<p>Experimental group 1 (R) O1 X O2
</p>
<p>Control group 1 (R) O3 O4
</p>
<p>Experimental group 2 (R) X O5
</p>
<p>Control group 2 (R) O6
</p>
<p>The design is much more complex, because we need to measure the effects six times and 
administer two treatments. This method provides an opportunity to control for the before 
measurement effect of O1 on O2. The design also provides several measures of the treat-
ment&rsquo;s effect (i.e., (O2&ndash;O4), (O2&ndash;O1)&ndash;(O4&ndash;O3), and (O6&ndash;O5)). If these measures agree, the 
inferences about the treatment&rsquo;s effect are much stronger.
</p>
<p>In 7 Chap.&nbsp;6, we discuss how to analyze experimental data using ANOVA and various 
other tests.
</p>
<p>4.7 Oddjob Airways (Case Study)
</p>
<p>Case Study
</p>
<p>Oddjob Airways</p>
<p/>
<div class="annotation"><a href="https://www.oddjobairways.com/market-research/">https://www.oddjobairways.com/market-research/</a></div>
</div>
<div class="page"><p/>
<p>86 Chapter 4 &middot; Getting Data
</p>
<p>4.8 Review Questions
</p>
<p>1. What is the difference between primary and secondary data? Can primary data 
become secondary data?
</p>
<p>2. Please search for and download two examples of secondary data sources found on 
the Internet. Discuss two potential market research questions that each dataset can 
answer.
</p>
<p>3. Imagine you are asked to understand what consumer characteristics make these 
consumers likely to buy a BMW i3 (http://www.bmw.com). How would you collect 
the data? Would you start with secondary data, or would you start collecting 
primary data directly? Do you think it is appropriate to collect qualitative data? If so, 
at what stage of the process should you do so?
</p>
<p>4. What are the different reasons for choosing interviews rather than focus groups? 
What choice would you make if you want to understand CEOs&rsquo; perceptions of the 
economy, and what would seem appropriate when you want to understand how 
consumers feel about a newly introduced TV program?
</p>
<p>5. Consider the following examples of survey items relating to how satisfied iPhone 
users are with their performance, reliability, and after-sales service. Please assess 
their adequacy and make suggestions on how to revise the items, if necessary.
</p>
<p>10 All chapters dealing with research methods (i.e., Chapters&nbsp;5-9) also draw on the Oddjob Airways case 
</p>
<p>study. We introduce the case study in greater detail in section 5.8.
</p>
<p>Founded in 1962 by the 
</p>
<p>Korean businessman 
</p>
<p>Toshiyuki Sakata, Oddjob 
</p>
<p>Airways is a small premium 
</p>
<p>airline, mainly operating in 
</p>
<p>Europe, but also offering 
</p>
<p>flights to the US.10 The 
</p>
<p>company regularly conducts 
</p>
<p>market research in order to 
</p>
<p>monitor its service quality 
</p>
<p>and to improve customer 
</p>
<p>satisfaction. The market 
</p>
<p>research department 
</p>
<p>has uploaded a series of 
</p>
<p>videos on https://www.
</p>
<p>oddjobairways.com/market-
</p>
<p>research/, which document 
</p>
<p>some of the recent projects. 
</p>
<p>Please help the department 
</p>
<p>by answering the following 
</p>
<p>questions:
</p>
<p>1. Go to https://www.
</p>
<p>oddjobairways.com/
</p>
<p>market-research/
</p>
<p>interviews/ and watch 
</p>
<p>the three videos. Try to 
</p>
<p>identify all errors that the 
</p>
<p>interviewer made. You 
</p>
<p>can find the solutions 
</p>
<p>under &bdquo;Corrections.&ldquo;
</p>
<p>2. Under https://www.
</p>
<p>oddjobairways.com/
</p>
<p>market-research/
</p>
<p>experiments/, you will 
</p>
<p>find two videos, which 
</p>
<p>show safety videos 
</p>
<p>with male and female 
</p>
<p>voice-overs. Carry out 
</p>
<p>an experiment, which 
</p>
<p>contrasts viewers&rsquo; 
</p>
<p>perceptions of the safety 
</p>
<p>video (e.g., in terms of 
</p>
<p>satisfaction) when the 
</p>
<p>voice-over is male vs. 
</p>
<p>female. Compute the 
</p>
<p>mean values (7 Chap.&nbsp;5) 
for each group. In a 
</p>
<p>further step, carry out 
</p>
<p>independent samples 
</p>
<p>t-tests (7 Chap.&nbsp;6) to 
check for significant 
</p>
<p>differences between the 
</p>
<p>two groups.
</p>
<p>3. Go to https://www.
</p>
<p>oddjobairways.com/
</p>
<p>market-research/
</p>
<p>focus-group/ and watch 
</p>
<p>the video on focus 
</p>
<p>groups. Would you have 
</p>
<p>spotted all errors?
</p>
<p>4</p>
<p/>
<div class="annotation"><a href="http://www.bmw.com">http://www.bmw.com</a></div>
<div class="annotation"><a href="https://www.oddjobairways.com/market-research/">https://www.oddjobairways.com/market-research/</a></div>
<div class="annotation"><a href="https://www.oddjobairways.com/market-research/">https://www.oddjobairways.com/market-research/</a></div>
<div class="annotation"><a href="https://www.oddjobairways.com/market-research/">https://www.oddjobairways.com/market-research/</a></div>
<div class="annotation"><a href="https://www.oddjobairways.com/market-research/interviews/">https://www.oddjobairways.com/market-research/interviews/</a></div>
<div class="annotation"><a href="https://www.oddjobairways.com/market-research/interviews/">https://www.oddjobairways.com/market-research/interviews/</a></div>
<div class="annotation"><a href="https://www.oddjobairways.com/market-research/interviews/">https://www.oddjobairways.com/market-research/interviews/</a></div>
<div class="annotation"><a href="https://www.oddjobairways.com/market-research/interviews/">https://www.oddjobairways.com/market-research/interviews/</a></div>
<div class="annotation"><a href="https://www.oddjobairways.com/market-research/experiments/">https://www.oddjobairways.com/market-research/experiments/</a></div>
<div class="annotation"><a href="https://www.oddjobairways.com/market-research/experiments/">https://www.oddjobairways.com/market-research/experiments/</a></div>
<div class="annotation"><a href="https://www.oddjobairways.com/market-research/experiments/">https://www.oddjobairways.com/market-research/experiments/</a></div>
<div class="annotation"><a href="https://www.oddjobairways.com/market-research/experiments/">https://www.oddjobairways.com/market-research/experiments/</a></div>
<div class="annotation"><a href="https://www.oddjobairways.com/market-research/focus-group/">https://www.oddjobairways.com/market-research/focus-group/</a></div>
<div class="annotation"><a href="https://www.oddjobairways.com/market-research/focus-group/">https://www.oddjobairways.com/market-research/focus-group/</a></div>
<div class="annotation"><a href="https://www.oddjobairways.com/market-research/focus-group/">https://www.oddjobairways.com/market-research/focus-group/</a></div>
<div class="annotation"><a href="https://www.oddjobairways.com/market-research/focus-group/">https://www.oddjobairways.com/market-research/focus-group/</a></div>
</div>
<div class="page"><p/>
<p>487
References
</p>
<p>Strongly  
disagree
</p>
<p>Somewhat  
disagree
</p>
<p>Some-
what  
agree
</p>
<p>Agree Completely 
agree
</p>
<p>I am satisfied 
</p>
<p>with the 
</p>
<p>performance 
</p>
<p>and reliability 
</p>
<p>of my iPhone
</p>
<p>□ □ □ □ □
</p>
<p>Strongly  
disagree
</p>
<p>Somewhat  
disagree
</p>
<p>Neutral Somewhat  
agree
</p>
<p>Completely 
agree
</p>
<p>I am satisfied 
</p>
<p>with the after-
</p>
<p>sales service 
</p>
<p>of my iPhone
</p>
<p>□ □ □ □ □
</p>
<p>Which of the 
following 
iPhone fea-
tures do you 
find most 
 important?
</p>
<p>Not at all  
important
</p>
<p>Not 
important
</p>
<p>Neutral Important Very 
important
</p>
<p>Camera □ □ □ □ □
</p>
<p>Music player □ □ □ □ □
</p>
<p>App store □ □ □ □ □
</p>
<p>Web browser □ □ □ □ □
</p>
<p>Mail □ □ □ □ □
</p>
<p>6. Make recommendations regarding the following aspects of scale design: the number 
of response categories, the design and labeling of response categories, and the 
inclusion of a &ldquo;don&rsquo;t know&rdquo; option.
</p>
<p>7. Describe the Solomon four-group design and explain which of the simpler experi-
mental design problems it controls for.
</p>
<p>8. If you were to set up an experiment to ascertain what type of product package (new 
or existing) customers prefer, what type of experiment would you choose? Please 
discuss.
</p>
<p>References
</p>
<p>Barnham, C. (2015). Quantitative and qualitative research: Perceptual foundations. International Journal 
</p>
<p>of Market Research, 57(6), 837&ndash;854.
</p>
<p>Baumgartner, H., &amp; Steenkamp, J. B. E. M. (2001). Response styles in marketing research: A cross-national 
</p>
<p>investigation. Journal of Marketing Research, 38(2), 143&minus;156.</p>
<p/>
</div>
<div class="page"><p/>
<p>88 Chapter 4 &middot; Getting Data
</p>
<p>Brace, I. (2004). Questionnaire design. How to plan, structure and write survey material for effective market 
</p>
<p>research. London: Kogan Page.
</p>
<p>Brislin, R. W. (1970). Back-translation for cross-cultural research. Journal of Cross-Cultural Psychology, 1(3), 
</p>
<p>185&ndash;216.
</p>
<p>Bronner, F., &amp; Ton, K. (2007). The live or digital interviewer. A comparison between CASI, CAPI and CATI 
</p>
<p>with respect to differences in response behaviour. International Journal of Market Research, 49(2), 
</p>
<p>167&ndash;190.
</p>
<p>Brosnan, K., Grpn, B., &amp; Dolnicar, S. (2017). PC, phone or tablet? Use, preference and completion rates for 
</p>
<p>web surveys. International Journal of Market Research, 59(1), 35&ndash;55.
</p>
<p>Cabooter, E., Weijters, B., Geuens, M., &amp; Vermeir, E. (2016). Scale format effects on response option inter-
</p>
<p>pretation and use. Journal of Business Research, 69(7), 2574&ndash;2584.
</p>
<p>Casteleyn, J., Andr&eacute;, M., &amp; Kris, R. (2009). How to use facebook in your market research. International Jour-
</p>
<p>nal of Market Research, 51(4), 439&ndash;447.
</p>
<p>DeMonaco, H. J., Ayfer, A., &amp; Hippel, E. V. (2005). The major role of clinicians in the discovery of off-label 
</p>
<p>drug therapies. Pharmacotherapy, 26(3), 323&ndash;332.
</p>
<p>Deutskens, E., De Jong, A., De Ruyter, K., &amp; Martin, W. (2006). Comparing the generalizability of online and 
</p>
<p>mail surveys in cross-national service quality research. Marketing Letters, 17(2), 119&ndash;136.
</p>
<p>Dillman, D. A., Smyth, J. D., &amp; Christian, L. M. (2014). Internet, phone, mail, and mixed-mode surveys: The tai-
</p>
<p>lored design method (4th ed.). Hoboken, NJ: John Wiley &amp; Sons.
</p>
<p>Fink, A. (2003) How to ask survey questions. Thousand Oaks, CA: Sage.
</p>
<p>Foddy, W. (1993). Constructing questions for interviews and questionnaires. Theory and practice in social sci-
</p>
<p>ence research. Cambridge: Cambridge University Press.
</p>
<p>Gneezy, A. (2017). Field experimentation in marketing research. Journal of Marketing Research, 54(1), 
</p>
<p>140&ndash;143.
</p>
<p>Holbrook, A., Cho, Y. I. K., &amp; Johnson, T. (2006). The impact of question and respondent characteristics on 
</p>
<p>comprehension and mapping difficulties. Public Opinion Quarterly, 70(4), 565&ndash;595.
</p>
<p>Houston, M. B. (2002). Assessing the validity of secondary data proxies for marketing constructs. Journal 
</p>
<p>of Business Research, 57(2), 154&ndash;161.
</p>
<p>Kennedy, C., &amp; Everett, S. E. (2011). Use of cognitive shortcuts in landline and cell phone surveys. Public 
</p>
<p>Opinion Quarterly, 75(2), 336&ndash;348.
</p>
<p>Kurylko, D. T. (2005). Moonraker project seeks marketing savvy for VW. Automotive News Europe, 10(17), 22.
</p>
<p>Lietz, P. (2010). Research into questionnaire design. A summary of the literature. International Journal of 
</p>
<p>Market Research, 52(2), 249&ndash;272.
</p>
<p>Liu, M., Lee, S., &amp; Conrad, F. G. (2016). Comparing extreme response styles between agree-disagree and 
</p>
<p>item-specific scales. Public Opinion Quarterly, 79(4), 952&ndash;975.
</p>
<p>Lynn, P., &amp; Kaminska, O. (2013). The impact of mobile phones on survey measurement error. Public Opin-
</p>
<p>ion Quarterly, 77(2), 586&ndash;605.
</p>
<p>Mooi, E., &amp; Gilliland, D. I. (2013). How contracts and enforcement explain transaction outcomes. Interna-
</p>
<p>tional Journal of Research in Marketing, 30(4), 395&ndash;405.
</p>
<p>Mitchell, M. L., &amp; Jolley, J. M. (2013). Research design explained (8th ed.). Belmont, CA: Wadsworth.
</p>
<p>Nowlis, S. M., Kahn, B. E., &amp; Dhar, R. (2002). Coping with ambivalence: The effect of removing a neutral 
</p>
<p>option on consumer attitude and preference judgments. Journal of Consumer Research, 29(3), 
</p>
<p>319&ndash;334.
</p>
<p>Oppenheim, A. N. (1992). Questionnaire design, Interviewing and attitude measurement. London: Pinter.
</p>
<p>Peng, L., &amp; Finn, A. (2016). Assessing response format effects on the scaling of marketing stimuli. Interna-
</p>
<p>tional Journal of Market Research, 58(4), 595&ndash;619.
</p>
<p>Peterson, R. A. (1997). A quantitative analysis of rating-scale response variability. Marketing Letters, 8(1), 
</p>
<p>9&ndash;21.
</p>
<p>Raithel, S., Sarstedt, M., Scharf, S., &amp; Schwaiger, M. (2012). On the value relevance of customer satisfaction. 
</p>
<p>Multiple drivers in multiple markets. Journal of the Academy of Marketing Science, 40(4), 509&ndash;525.
</p>
<p>Rammstedt, B., &amp; Krebs, D. (2007) Does response scale format affect the answering of personality scales? 
</p>
<p>European Journal of Psychological Assessment, 23(1), 32&ndash;38.
</p>
<p>Reips, U.-D., &amp; Funke, F. (2008). Interval-level measurement with visual analogue scales in Internet-based 
</p>
<p>research: VAS generator. Behavior Research Methods, 40(3), 699&ndash;704.
</p>
<p>4</p>
<p/>
</div>
<div class="page"><p/>
<p>489
References
</p>
<p>Revilla, M. (2015). Effect of using different labels for the scales in a web survey. International Journal of 
</p>
<p>Market Research, 57(2), 225&ndash;238.
</p>
<p>Rindfleisch, A., &amp; Heide, J. B. (1997). Transaction cost analysis: Past, present, and future applications. Jour-
</p>
<p>nal of Marketing, 61(4), 30&ndash;54.
</p>
<p>Sarstedt, M., Diamantopoulos, A., Salzberger, T., &amp; Baumgartner, P. (2016). Selecting single items to mea-
</p>
<p>sure doubly concrete constructs: A cautionary tale. Journal of Business Research, 69(8), 3159-3167.
</p>
<p>Schilling, M. A. (2009). Understanding the alliance data. Strategic Management Journal, 30(3), 233&ndash;260.
</p>
<p>Stern, M. J., Bilgen, I., &amp; Dillman, D. A. (2014). The state of survey methodology challenges, dilemmas, and 
</p>
<p>new frontiers in the era of the tailored design, Field Methods, 26(3), 284&ndash;301.
</p>
<p>Stieglitz, S., Dang-Xuan, L., Bruns, A., &amp; Neuberger, C. (2014). Social media analytics, An interdisciplinary 
</p>
<p>approach and its implications for information systems. Business &amp; Information Systems Engineering, 
</p>
<p>6(2), 89&minus;96.
</p>
<p>Swain, S. D., Weathers, D., &amp; Niedrich, R. W. (2008). Assessing three sources of misresponse to reversed 
</p>
<p>Likert items. Journal of Marketing Research, 45(1), 116&minus;131.
</p>
<p>Tourangeau, R., &amp; Smith, T. W. (1996). Asking sensitive questions: the impact of data collection mode, 
</p>
<p>question format, and question context. Public Opinion Quarterly, 60(2), 275&ndash;304.
</p>
<p>Vesta Research. (2016). Rules of thumb for survey length. Vesta Research Blog. &nbsp; Available at: http://www.
</p>
<p>verstaresearch.com/blog/rules-of-thumb-for-survey-length/
</p>
<p>Vicente, P., &amp; Reis, E. (2010). Marketing research with telephone surveys: Is it time to change? Journal of 
</p>
<p>Global Marketing, 23(4), 321&minus;332.
</p>
<p>Vincente, P., Reis, E., &amp; Santos, M. (2008). Using mobile phones for survey research. International Journal of 
</p>
<p>Market Research, 51(5), 613&ndash;633.
</p>
<p>Weijters, B., &amp; Baumgartner, H. (2012). Misresponse to reversed and negated items in surveys: A review. 
</p>
<p>Journal of Marketing Research, 49(5), 737&ndash;747.
</p>
<p>Weijters, B., Cabooter, E., &amp; Schillewaert, N. (2010). The effect of rating scale format on response styles: 
</p>
<p>The number of response categories and response category labels. International Journal of Research in 
</p>
<p>Marketing, 27(3), 236&ndash;247.
</p>
<p>Weijters, B., Baumgartner, H., &amp; Schillewaert, N. (2013). Reversed item bias: An integrative model. Psycho-
</p>
<p>logical Methods, 18(3), 320&ndash;334.
</p>
<p>Weng, L.-J. (2004). Impact of the number of response categories and anchor labels on coefficient alpha 
</p>
<p>and test-retest reliability. Educational and Psychological Measurement, 64(6), 956&ndash;972.
</p>
<p>Winkler, T. J., Sarstedt, M., Keil, M., &amp; Rost, P. (2015). Selfsurvey.org: A platform for prediction-based bench-
</p>
<p>marking and feedback-enabled survey research. Proceedings of the European Conference on Infor-
</p>
<p>mation Systems, Paper 204, M&uuml;nster, Germany.
</p>
<p>Further Reading
</p>
<p>Barnham, C. (2015). Quantitative and qualitative research: Perceptual foundations. International Journal 
</p>
<p>of Market Research, 57(6), 837&ndash;854.
</p>
<p>Campbell, D. T., &amp; Stanley, J. C. (1966). Experimental and quasi-experimental designs for research. Chicago: 
</p>
<p>Wadsworth Publishing.
</p>
<p>Cook, T. D., &amp; Campbell, D. T. (1979). Quasi-experimentation: Design and analysis issues for field settings. 
</p>
<p>Chicago, IL: Wadsworth Publishing.
</p>
<p>Dillman, D. A., Smyth, J. D., &amp; Christian, L. M. (2014). Internet, phone, mail, and mixed-mode surveys: The tai-
</p>
<p>lored design method (4th ed.). Hoboken, NJ: John Wiley &amp; Sons.
</p>
<p>FocusGroupTips.com.
</p>
<p>Gideon, L. (2012). The art of questionnaire phrasing. In: L. Gideon (Ed.), Handbook of survey methodology 
</p>
<p>for the social sciences (pp. 91&ndash;108). New York, NJ: Springer.
</p>
<p>Hulland, J., Baumgartner, H., &amp; Smith, K.M. (2018). Marketing survey research best practices: Evidence and 
</p>
<p>recommendations from a review of JAMS articles. Journal of the Academy of Marketing Science, 46(1), 
</p>
<p>92&ndash;108.
</p>
<p>Lichters, M., Sarstedt, M., &amp; Vogt, B. (2015). On the practical relevance of the attraction effect: a cautionary 
</p>
<p>note and guidelines for context effect experiments. AMS Review, 5(1-2), 1&ndash;19.
</p>
<p>Lietz, P. (2010). Current state of the art in questionnaire design: a review of the literature. International 
</p>
<p>Journal of Market Research, 52(2), 249&ndash;272.</p>
<p/>
<div class="annotation"><a href="http://www.verstaresearch.com/blog/rules-of-thumb-for-survey-length/">http://www.verstaresearch.com/blog/rules-of-thumb-for-survey-length/</a></div>
<div class="annotation"><a href="http://www.verstaresearch.com/blog/rules-of-thumb-for-survey-length/">http://www.verstaresearch.com/blog/rules-of-thumb-for-survey-length/</a></div>
</div>
<div class="page"><p/>
<p>90 Chapter 4 &middot; Getting Data
</p>
<p>Morales, A. C., Amir, O., &amp; Lee, L. (2017). Keeping it real in experimental research. Understanding when, 
</p>
<p>where, and how to enhance realism and measure consumer behavior. Journal of Consumer Research, 
</p>
<p>44(2), 465&ndash;476.
</p>
<p>Mystery Shopping Providers Association (www.mysteryshop.org).
</p>
<p>Norman, G. (2010). Likert scales, levels of measurement and the &ldquo;laws&rdquo; of statistics. Advances in Health 
</p>
<p>Sciences Education, 15(5), 625&ndash;632.
</p>
<p>Smyth, J.D., Olson, K., &amp; Burke, A. (2018). Comparing survey ranking question formats in mail surveys. 
</p>
<p>International Journal of Market Research, forthcoming.
</p>
<p>Veludo-de-Oliveira, T. M., Ikeda, A. A., &amp; Campomar, M. C. (2006). Laddering in the practice of marketing 
</p>
<p>research: Barriers and solutions. Qualitative Market Research: An International Journal, 9(3), 297&ndash;306.
4</p>
<p/>
<div class="annotation"><a href="http://www.mysteryshop.org">http://www.mysteryshop.org</a></div>
</div>
<div class="page"><p/>
<p>91
</p>
<p>Descriptive Statistics
</p>
<p>5.1 The Workflow of Data &ndash; 93
</p>
<p>5.2 Create Structure &ndash; 93
</p>
<p>5.3 Enter Data &ndash; 97
</p>
<p>5.4 Clean Data &ndash; 97
5.4.1 Interviewer Fraud &ndash; 97
</p>
<p>5.4.2 Suspicious Response Patterns &ndash; 98
</p>
<p>5.4.3 Data Entry Errors &ndash; 99
</p>
<p>5.4.4 Outliers &ndash; 99
</p>
<p>5.4.5 Missing Data &ndash; 101
</p>
<p>5.5 Describe Data &ndash; 106
5.5.1 Univariate Graphs and Tables &ndash; 108
</p>
<p>5.5.2 Univariate Statistics &ndash; 110
</p>
<p>5.5.3 Bivariate Graphs and Tables &ndash; 112
</p>
<p>5.5.4 Bivariate Statistics &ndash; 114
</p>
<p>5.6 Transform Data (Optional) &ndash; 116
5.6.1 Variable Respecification &ndash; 117
</p>
<p>5.6.2 Scale Transformation &ndash; 118
</p>
<p>5.7 Create a Codebook &ndash; 120
</p>
<p>5.8 The Oddjob Airways Case Study &ndash; 121
5.8.1 Introduction to SPSS &ndash; 123
</p>
<p>5.8.2 Finding Your Way in SPSS &ndash; 124
</p>
<p>5
</p>
<p>&copy; Springer-Verlag GmbH Germany, part of Springer Nature 2019 
</p>
<p>M. Sarstedt, E. Mooi, A Concise Guide to Market Research, Springer Texts in Business  
</p>
<p>and Economics, https://doi.org/10.1007/978-3-662-56707-4_5
</p>
<p>Electronic supplementary material
</p>
<p>The online version of this chapter (https://doi.org/10.1007/978-3-662-56707-4_5) contains 
</p>
<p>additional material that is available to authorized users. You can also download the &ldquo;Springer 
</p>
<p>Nature More Media App&rdquo; from the iOS or Android App Store to stream the videos and scan the 
</p>
<p>image containing the &ldquo;Play button&rdquo;.</p>
<p/>
<div class="annotation"><a href="https://crossmark.crossref.org/dialog/?doi=10.1007/978-3-662-56707-4_5&amp;amp;domain=pdf&amp;amp;date_stamp=2018-9-17">https://crossmark.crossref.org/dialog/?doi=10.1007/978-3-662-56707-4_5&amp;amp;domain=pdf&amp;amp;date_stamp=2018-9-17</a></div>
</div>
<div class="page"><p/>
<p>5.8.3 SPSS Statistics Data Editor &ndash; 125
</p>
<p>5.8.4 SPSS Statistics Viewer &ndash; 127
</p>
<p>5.8.5 SPSS Menu Functions &ndash; 128
</p>
<p>5.9 Data Management in SPSS &ndash; 130
5.9.1 Split File &ndash; 130
</p>
<p>5.9.2 Select Cases &ndash; 132
</p>
<p>5.9.3 Compute Variables &ndash; 132
</p>
<p>5.9.4 Recode Variables &ndash; 133
</p>
<p>5.10 Example &ndash; 135
5.10.1 Clean Data &ndash; 136
</p>
<p>5.10.2 Describe Data &ndash; 137
</p>
<p>5.11 Cadbury and the UK Chocolate Market (Case 
Study)&nbsp;&ndash; 149
</p>
<p>5.12 Review Questions &ndash; 149
</p>
<p> References &ndash; 150</p>
<p/>
</div>
<div class="page"><p/>
<p>593
5.2 &middot; Create Structure
</p>
<p>Keywords
Acquiescence &bull; Aggregation &bull; Bar chart &bull; Bivariate statistics &bull; Box plot &bull; Codebook &bull; Construct score &bull; 
</p>
<p>Correlation &bull; Covariance &bull; Crosstabs &bull; Data entry errors &bull; Dummy variables &bull; Extreme response styles &bull; 
</p>
<p>Frequency table &bull; Histogram &bull; Inconsistent answers &bull; Index &bull; Interquartile range &bull; Interviewer fraud &bull; Item 
</p>
<p>non-response &bull; Line chart &bull; Listwise deletion &bull; Little&rsquo;s MCAR test &bull; Log transformation &bull; Mean &bull; Measures 
</p>
<p>of centrality &bull; Measures of dispersion &bull; Median &bull; Middle response styles &bull; Missing (completely or not) 
</p>
<p>at random &bull; Missing data &bull; Multiple imputation &bull; Outliers &bull; Pie chart &bull; Range &bull; Range standardization &bull; 
</p>
<p>Scale transformation &bull; Scatter plot &bull; Skewed data &bull; SPSS &bull; Standard deviation &bull; Standardizing variables &bull; 
</p>
<p>Straight-lining &bull; Survey non-response &bull; Suspicious response patterns &bull; Transforming data &bull; Univariate sta-
</p>
<p>tistics &bull; Variable respecification &bull; Variance &bull; Workflow &bull; z-standardization.
</p>
<p>5.1 The Workflow of Data
</p>
<p>Market research projects involving data become more efficient and effective if they have 
a proper workflow, which is a strategy to keep track of entering, cleaning, describing, 
and transforming data. These data may have been collected through surveys or may be 
secondary data (7 Chap.&nbsp;3). Entering, cleaning, and analyzing bits of data haphazardly 
is not a (good) strategy, since it increases the likelihood of making mistakes and makes 
it hard to replicate results. Moreover, without a good data workflow, it becomes hard 
to document the research process and to cooperate on projects. For example, how can 
you outsource the data analysis if you cannot indicate what the data are about or what 
specific values mean? Finally, a lack of a good workflow increases the risk of duplicat-
ing work or even losing data. In . Fig.&nbsp;5.1, we show the steps required to create and 
describe a dataset after the data have been collected. We subsequently discuss each step 
in greater detail.
</p>
<p>5.2 Create Structure
</p>
<p>The basic idea of setting up a good workflow is that good planning saves the researcher 
time, allows researchers to share the analysis, and/or allows replicating the research. 
After the data collection phase, the first step is to save the available data. We recommend 
keeping track of the dataset by providing data and data-related files in separate directories. 
</p>
<p>Learning Objectives
After reading this chapter, you should understand:
</p>
<p> 5 The workflow involved in a market research study.
 5 Univariate and bivariate descriptive graphs and statistics.
 5 How to deal with missing values.
 5 How to transform data (z-transformation, log transformation, creating dummies, 
aggregating variables).
</p>
<p> 5 How to identify and deal with outliers.
 5 What a codebook is.
 5 The basics of using SPSS.</p>
<p/>
</div>
<div class="page"><p/>
<p>94 Chapter 5 &middot; Descriptive Statistics
</p>
<p>This&nbsp;directory should have subdirectories for at least: (1) the data files, (2) commands, (3) 
a temporary directory, and (4) related files; that is, a directory with files that are directly 
related to a project, such as the survey used to collect the data.1
</p>
<p>In . Table 5.1, we show an example of a directory structure. Within the main directory, 
there are four subdirectories, each with distinct files. Notice that in the Data files subdirec-
tory, we have the original dataset, two modified datasets (one without missing data and 
one which includes several transformations of the data), as well as a zip file that contains 
the original dataset. If the data file is contained in a zip or other archive file, it is stored and 
unlikely to be modified, but can be easily opened if the working file is accidentally over-
written or deleted. In the Data files subdirectories, we distinguish between two files with the 
suffix rev1 and rev2. We use rev (abbreviation of revision), but you however, choose another 
file name as long as it clearly indicates the revision on which you are working. In the Syntax 
files subdirectory, we store all syntax code that were used to manage and analyze our data. 
These commands may relate to different project phases, including a missing data analy-
sis, descriptives, factor analysis, and other methods used over the course of the project. 
The Output files subdirectory includes a series of files with results from different statistical 
</p>
<p>Create structure 
</p>
<p>Enter data 
</p>
<p>Clean data 
</p>
<p>Describe data 
</p>
<p>Transform data (optional) 
</p>
<p>Create a codebook 
</p>
<p>Interviewer fraud 
Suspicious response patterns 
</p>
<p>Data entry errors 
Outliers 
</p>
<p>Missing data 
</p>
<p>. Fig.&nbsp;5.1 The workflow of data
</p>
<p>1 Alternatively, you could also choose one of the many control system versions, including Subversion, 
</p>
<p>Git, and Mecurial, which enable simple branching and project management. These systems work 
</p>
<p>well with version control in centralized and in distributed environments.
</p>
<p>5</p>
<p/>
</div>
<div class="page"><p/>
<p>595
5.2 &middot; Create Structure
</p>
<p>analyses. As the name indicates, Temporary files serve as intermediary files that are kept 
until the final data or command files are established, after which they are removed. Finally, 
in the Related Files subdirectory, we have a codebook (more on this later), the survey, two 
presentations, and two documents containing recommendations.
</p>
<p>Another aspect of creating a structure is setting up the variables for your study prop-
erly. This involves making decisions on the following elements:
</p>
<p> 4 Variable names,
 4 variable labels,
 4 data type, and
 4 coding of variables.
</p>
<p>. Table 5.1 Example of a directory structure for saving market-research-related files
</p>
<p>Directory name Subdirectory name Example file names
</p>
<p>Oddjob Data files oddjob.sav
</p>
<p>oddjob.zip
</p>
<p>oddjob rev1.sav
</p>
<p>oddjob rev2.sav
</p>
<p>Syntax files Missing data analysis.sps
</p>
<p>Descriptives.sps
</p>
<p>Factor analysis.sps
</p>
<p>Regression analysis.sps
</p>
<p>Output files Missing data analysis.spv
</p>
<p>Descriptives.spv
</p>
<p>Factor analysis.spv
</p>
<p>Regression analysis.spv
</p>
<p>Temporary files Missing data analysis rev1.spv
</p>
<p>Descriptives rev1.spv
</p>
<p>Factor analysis rev1.spv
</p>
<p>Regression analysis rev1.spv
</p>
<p>Related files Codebook.docx
</p>
<p>Survey.pdf
</p>
<p>Initial findings&ndash;presentation to client.pptx
</p>
<p>Findings&ndash;presentation to client.pptx
</p>
<p>Recommendations rev1.docx
</p>
<p>Recommendations rev2.docx</p>
<p/>
</div>
<div class="page"><p/>
<p>96 Chapter 5 &middot; Descriptive Statistics
</p>
<p>The variable names should be clear and short so that they can be read in the dialog boxes. 
For example, if you have three questions on product satisfaction, three on loyalty, and 
several descriptors (age and gender), you could code these variables as satisfaction1, sat-
isfaction2, satisfaction3, loyalty1, loyalty2, loyalty3, age, and gender.
</p>
<p>In SPSS, and most other statistical software programs, you can include variable labels 
that describe what each variable denotes. The description generally includes the original 
question if the data were collected using surveys. Another point to consider is variable 
coding. Coding means assigning values to a variable. When collecting quantitative data, 
the task is relatively easy; we use values that correspond with the answers for Likert and 
semantic differential scales. For example, when using a 7-point Likert scale, responses can 
be coded as 1&ndash;7 or as 0&ndash;6 (with 0 being the most negative and 6 being the most positive 
response). Open-ended questions (qualitative data) require more effort, usually involv-
ing a three-step process. First, we collect all the responses. In the second step, we group 
these responses. Determining the number of groups and the group to which a response 
belongs is the major challenge in this step. Two or three market researchers usually code 
the responses independently to prevent the process from becoming too subjective and 
thereafter discuss the differences that may arise. The third step is providing a value for each 
group. Please see Krippendorff (2012) for more details about coding qualitative variables.
</p>
<p>The following video gives a brief introduction into qualitative coding.
</p>
<p>&copy; vgajic/Getty Images/iStock
</p>
<p>https://www.youtube.com/watch?v=DRL4PF2u9XA
</p>
<p>Once a system has been set up to keep track of your progress, you need to consider safe-
guarding your files. Large companies usually have systems for creating backups (extra 
copies as a safeguard). If you are working alone or for a small company, you are probably 
responsible for this. You should save your most recent and second most recent version of 
your file on a separate drive and have multiple copies of your entire drive! Always keep at 
least two copies and never keep both backups in the same place, because you could still 
</p>
<p>5</p>
<p/>
<div class="annotation"><a href="https://www.youtube.com/watch?v=DRL4PF2u9XA">https://www.youtube.com/watch?v=DRL4PF2u9XA</a></div>
</div>
<div class="page"><p/>
<p>597
5.4 &middot; Clean Data
</p>
<p>lose all your work through theft, fire, or an accident! You can use cloud storage services, 
such as Amazon&rsquo;s storage services, or Dropbox, Google Drive, or Microsoft&rsquo;s OneDrive for 
small projects to prevent loss. Always read the terms of the cloud storage services carefully 
to determine whether your data&rsquo;s privacy is guaranteed.
</p>
<p>5.3 Enter Data
</p>
<p>How do we enter survey or experimental data into a dataset? Specialized software is often 
used for large datasets, or datasets created by professional firms. For example, Epidata 
(http://www.epidata.dk, freely downloadable) is frequently used to enter data from paper-
based surveys, Confirmit&rsquo;s mobile survey (http://www.confirmit.com) to enter data from 
personal intercepts or face-to-face interviewing, and Voxco&rsquo;s Interviewer CATI for tele-
phone interviewing. The SPSS Data Collection Family (http://www.spss.com.hk/software/
data-collection/) is a suite of different software packages specifically designed to collect 
and (automatically) enter data collected from online, telephone, and paper-based surveys.
</p>
<p>Such software may not be available for smaller projects, in which case data should be 
entered directly into SPSS. A significant drawback of direct data entry is the risk of typing 
errors, for which SPSS cannot check. Professional software, such as Epidata, can directly 
check if values are admissible. For example, if a survey question has only two answer cate-
gories, such as gender (coded 0/1), Epidata (and other packages) can directly check if the 
value entered is 0 or 1, and not any other value. The software also allows for using multiple 
typists when very large amounts of data need to be entered simultaneously.
</p>
<p>5.4 Clean Data
</p>
<p>Cleaning data is the next step in the workflow. It requires checking for:
 4 Interviewer fraud,
 4 suspicious response patterns,
 4 data entry errors,
 4 outliers, and
 4 missing data.
</p>
<p>These issues require researchers to make decisions very carefully. In the following, we 
discuss each issue in greater detail. . Table 5.3 summarizes the key recommendations dis-
cussed in the following sections.
</p>
<p>5.4.1 Interviewer Fraud
</p>
<p>Interviewer fraud is a difficult and serious issue. It ranges from interviewers &ldquo;helping&rdquo; 
respondents provide answers to entire surveys being falsified. Interviewer fraud often 
leads to incorrect results. Fortunately, we can avoid and detect interviewer fraud in various 
ways. First, never base interviewers&rsquo; compensation on the number of completed responses 
they submit. Second, check and control for discrepancies in respondent selection and </p>
<p/>
<div class="annotation"><a href="http://www.epidata.dk">http://www.epidata.dk</a></div>
<div class="annotation"><a href="http://www.confirmit.com">http://www.confirmit.com</a></div>
<div class="annotation"><a href="http://www.spss.com.hk/software/data-collection/">http://www.spss.com.hk/software/data-collection/</a></div>
<div class="annotation"><a href="http://www.spss.com.hk/software/data-collection/">http://www.spss.com.hk/software/data-collection/</a></div>
</div>
<div class="page"><p/>
<p>98 Chapter 5 &middot; Descriptive Statistics
</p>
<p>responses. If multiple interviewers were used, each of whom collected a reasonably large 
number of responses (n&nbsp;&gt;&nbsp;100), a selection of the respondents should be similar. This 
means that the average responses obtained should also be similar. In 7 Chap.&nbsp;6&nbsp;we will 
discuss techniques to test this. Third, if possible, contact a random number of respon-
dents afterwards for their feedback on the survey. If a substantial number of people claim 
they were not interviewed, interviewer fraud is likely. Furthermore, if people were pre-
viously interviewed on a similar subject, the factual variables collected, such as their 
gender, should not change (or no more than a trivial percentage), while variables such as 
a respondent&rsquo;s age and highest education level should only move up. We can check this 
using descriptive statistics. If substantial interviewer fraud is suspected, the data should 
be discarded. You should check for interviewer fraud during the data collection process 
to safeguard the quality of data collection and minimize the risk of having to discard the 
data in the end.
</p>
<p>5.4.2 Suspicious Response Patterns
</p>
<p>Before analyzing data, we need to identify suspicious response patterns. There are two 
types of response patterns we need to look for:
 4 Straight-lining, and
 4 inconsistent answers.
</p>
<p>Straight-lining occurs when a respondent marks the same response in almost all the 
items. For example, if a 7-point scale is used to obtain answers and the response 
pattern is 4 (the middle response), or if the respondent selects only 1s, or only 7s in all 
the items. A common way of identifying straight-lining is by including one or more 
reverse-scaled items in a survey (see 7 Chap.&nbsp;4). By evaluating the response patterns, 
we can differentiate between those respondents who are not consistent for the sake 
of consistency and those who are merely mindlessly consistent. Note, however, that 
this only applies if respondents do not tick the middle option. Straight-lining is very 
common, especially in web surveys where respondents generally pay less attention 
to the answers. Likewise, long surveys and those with many similarly worded items 
trigger straight-lining (Drolet and Morrison 2001). An alternative is to note potential 
straight-lined responses and include this as a separate category in the subsequent sta-
tistical analyses. This step avoids the need to reduce the sample and indicates the size 
and direction of any bias.
</p>
<p>However, straight-lining can also be the result of culture-specific response styles. For 
example, respondents from different cultures have different tendencies regarding select-
ing the mid points (middle response styles) or the end points of a response scale (extreme 
response styles). Similarly, respondents from different cultures have different tendencies 
regarding agreeing with statements, regardless of the item content; this tendency is also 
referred to as acquiescence (Baumgartner and Steenkamp 2001). For example, respon-
dents from Spanish-speaking countries tend to show higher extreme response styles 
and high acquiescence, while East Asian (Japanese and Chinese) respondents show a 
relatively high level of middle response style. Within Europe, the Greeks stand out as 
having the highest level of acquiescence and a tendency towards an extreme response 
</p>
<p>5</p>
<p/>
</div>
<div class="page"><p/>
<p>599
5.4 &middot; Clean Data
</p>
<p>style. Harzing (2005) and Johnson et al. (2005) provide reviews of culture effects on 
response behavior.
</p>
<p>Inconsistent answers also need to be addressed before analyzing your data. Many 
surveys start with one or more screening questions. The purpose of a screening question 
is to ensure that only individuals who meet the prescribed criteria complete the survey. For 
example, a survey of mobile phone users may screen for individuals who own an iPhone. 
If an individual indicates that he/she does not have an iPhone, this respondent should be 
removed from the dataset.
</p>
<p>Surveys often ask the same question with slight variations, especially when reflective 
measures (see Box 3.1 in 7 Chap.&nbsp;3) are used. If a respondent gives a different answer to 
very similar questions, this may raise a red flag and could suggest that the respondent did 
not read the questions closely, or simply marked answers randomly to complete the survey 
as quickly as possible.
</p>
<p>5.4.3 Data Entry Errors
</p>
<p>When data are entered manually, data entry errors occur routinely. Fortunately, such errors 
are easy to spot if they happen outside the variable&rsquo;s range. That is, if an item is measured 
using a 7-point scale, the lowest value should be 1 (or 0) and the highest 7 (or 6). We can 
check if this is true by using descriptive statistics (minimum, maximum, and range; see 
next section). Data entry errors should always be corrected by going back to the original 
survey. If we cannot go back (e.g., because the data were collected using face-to-face inter-
views), we need to delete this specific observation for this specific variable.
</p>
<p>More subtle errors&mdash;for example, incorrectly entering a score of 4 as 3&mdash;are difficult to 
detect using statistics. One way to check for these data entry errors is to randomly select 
observations and compare the entered responses with the original survey. We do, of course, 
expect a small number of errors (below 1&nbsp;%). If many data entry errors occur, the dataset 
should be entered again.
</p>
<p>Manual double data entry is another method to detect data entry errors. That is, once 
the data has been entered manually, a second data checker enters the same data a second 
time and the two separate entries are compared to ensure they match. Entries that deviate 
from one another or values that fall outside the expected range of the scales (e.g., 7-point 
Likert scales should have values that fall within this range) are then indicative of data entry 
errors (Barchard and Verenikina 2013). Various studies reveal that&mdash;although double 
data entry is more laborious and expensive&mdash;it detects errors better than single data entry 
(Barchard and Pace 2011; Paulsen et al. 2012).
</p>
<p>5.4.4 Outliers
</p>
<p>Data often contain outliers, which are values situated far from all the other observations 
that may influence results substantially. For example, if we compare the average income of 
20&nbsp;households, we may find that the incomes range between $20,000 and $100,000, with 
the average being $45,000. If we considered an additional household with an income of, 
say, $1&nbsp;million, this would increase the average substantially.</p>
<p/>
</div>
<div class="page"><p/>
<p>100 Chapter 5 &middot; Descriptive Statistics
</p>
<p>5.4.4.1 Types of Outliers
</p>
<p>Outliers must be interpreted in the context of the study and this interpretation should be 
based on the types of information they provide. Depending on the source of their unique-
ness, outliers can be classified into three categories:
 4 The first type of outlier is produced by data collection or entry errors. For example, if 
</p>
<p>we ask people to indicate their household income in thousands of US dollars, some 
respondents may just indicate theirs in US dollars (not thousands). Obviously, there 
is a substantial difference between $30 and $30,000! Moreover, (as discussed before) 
data entry errors occur frequently. Outliers produced by data collection or entry 
errors should be deleted, or we need to determine the correct values by, for example, 
returning to the respondents.
 4 A second type of outlier occurs because exceptionally high or low values are a 
</p>
<p>part of reality. While such observations can influence results significantly, they are 
sometimes highly important for researchers, because the characteristics of outliers 
can be insightful. Think, for example, of extremely successful companies, or users 
with specific needs long before most of the relevant marketplace also needs them 
(i.e., lead users). Deleting such outliers is not appropriate, but the impact that they 
have on the results must be discussed.
 4 A third type of outlier occurs when combinations of values are exceptionally rare. 
</p>
<p>For example, if we look at income and expenditure on holidays, we may find 
someone who earns $1,000,000 and spends $500,000 of his/her income on holidays. 
Such combinations are unique and have a very strong impact on the results (partic-
ularly the correlations that we discuss later in this chapter). In such situations, the 
outlier should be retained, unless specific evidence suggests that it is not a valid 
member of the population under study. It is very useful to flag such outliers and 
discuss their impact on the results.
</p>
<p>5.4.4.2 Detecting Outliers
</p>
<p>In a simple form, outliers can be detected using univariate or bivariate graphs and statis-
tics.2 When searching for outliers, we need to use multiple approaches to ensure that we 
detect all the observations that can be classified as outliers. In the following, we discuss 
both routes to outlier detection:
</p>
<p>2 There are multivariate techniques that consider three, or more, variables simultaneously in order 
</p>
<p>to detect outliers. See Hair et al. (2019) for an introduction, and Agarwal (2013) for a more detailed 
</p>
<p>methodological discussion.
</p>
<p>Malcolm Gladwell&rsquo;s (2008) book &ldquo;Outliers: The Story of Success&rdquo; is an entertaining study 
</p>
<p>of how some people became exceptionally successful (outliers).
</p>
<p>Tip
</p>
<p>5</p>
<p/>
</div>
<div class="page"><p/>
<p>5101
5.4 &middot; Clean Data
</p>
<p>z Univariate Detection
The univariate detection of outliers examines the distribution of observations of each vari-
able with the aim of identifying those cases falling outside the range of the &ldquo;usual&rdquo; values. 
In other words, finding outliers means finding observations with very low or very high 
variable values. This can be achieved by calculating the minimum and maximum value of 
each variable, as well as the range. Another useful option for detecting outliers is through 
box plots, which visualize the distribution of a variable and pinpoint those observations 
that fall outside the range of the &ldquo;usual&rdquo; values. We introduce the above statistics and box 
plots in greater detail in the Describe Data section.
</p>
<p>z Bivariate Detection
We can also examine pairs of variables to identify observations whose combinations of 
variables are exceptionally rare. This is done by using a scatter plot, which plots all obser-
vations in a graph where the x-axis represents the first variable and the y-axis the second 
(usually dependent) variable (see 7 Sec. 5.5). Observations that fall markedly outside the 
range of the other observations will show as isolated points in the scatter plot.
</p>
<p>A drawback of this approach is the number of scatter plots that we need to draw. For 
example, with 10&nbsp;variables, we need to draw 45 scatter plots to map all possible combina-
tions of variables! Consequently, we should limit the analysis to only a few relationships, 
such as those between a dependent and independent variable in a regression. Scatterplots 
with large numbers of observations are often problematic when we wish to detect outli-
ers, as there is usually not just one dot, or a few isolated dots, just a cloud of observations 
where it is difficult to determine a cutoff point.
</p>
<p>5.4.4.3 Dealing with Outliers
</p>
<p>In a final step, we need to decide whether to delete or retain outliers, which should be 
based on whether we have an explanation for their occurrence. If there is an explanation 
(e.g., because some exceptionally wealthy people were included in the sample), outliers 
are typically retained, because they are part of the population. However, their impact on 
the analysis results should be carefully evaluated. That is, one should run an analysis with 
and without the outliers to assess if they influence the results. If the outliers are due to a 
data collection or entry error, they should be deleted. If there is no clear explanation, out-
liers should be retained.
</p>
<p>5.4.5 Missing Data
</p>
<p>Market researchers often have to deal with missing data. There are two levels at which 
missing data occur:
 4 Entire surveys are missing (survey non-response), and 
 4 Respondents have not answered all the items (item non-response)
</p>
<p>Survey non-response (also referred to as unit non-response) occurs when entire surveys 
are missing. Survey non-response is very common and regularly 75&ndash;95%, suggesting 
only 5%&ndash;25% of surveys are filled out. Issues such as inaccurate address lists, a lack of </p>
<p/>
</div>
<div class="page"><p/>
<p>102 Chapter 5 &middot; Descriptive Statistics
</p>
<p>interest and time, people confusing market research with selling, privacy issues, and 
respondent fatigue also lead to dropping response rates. The issue of survey response is 
best solved by designing proper surveys and survey procedures (see Box 4.7 in 7 Chap.&nbsp;4 
for suggestions).
</p>
<p>Item non-response occurs when respondents do not provide answers to certain 
questions. There are different forms of missingness, including people not filling out or 
refusing to answer questions. Item non-response is common and 2&ndash;10&nbsp;% of questions 
usually remain unanswered. However, this number greatly depends on factors, such as 
the subject matter, the length of the questionnaire, and the method of administration. 
Non-response can be much higher in respect of questions that people consider sensitive 
and varies from country to country. In some countries, for instance, reporting incomes 
is a sensitive issue.
</p>
<p>The key issue with item non-response is the type of pattern that the missing data 
follow. Do the missing values occur randomly, or is there some type of underlying system?3 
.&nbsp;Fig.&nbsp;5.2 illustrates the process of missing data treatment, which we will discuss next.
</p>
<p>3 For more information on missing data, see https://www.iriseekhout.com
</p>
<p> Use one of the following: 
</p>
<p>listwise deletion if &lt; 10%
</p>
<p>missing;  
</p>
<p>multiple imputation with
</p>
<p>m = 5 if  &gt;10% missing.   
</p>
<p>Carry out
</p>
<p>Little&rsquo;s test
</p>
<p>Check whether the 
</p>
<p>missingness depends on 
</p>
<p>one or more variable(s) in 
</p>
<p>the dataset  
</p>
<p>Data are missing
</p>
<p>completely at
</p>
<p> random (MCAR)    
</p>
<p>Data are missing
</p>
<p>at random (MAR)    
</p>
<p>Data are missing
</p>
<p>not at random
</p>
<p>(MNAR)  
</p>
<p>Use listwise deletion 
</p>
<p>and acknowledge 
</p>
<p>limitations arising from 
</p>
<p>the missing data. 
</p>
<p>Use multiple imputation
</p>
<p>method with m = 5.  
</p>
<p>Do Not Reject H0 Reject H0
</p>
<p>NoYes
</p>
<p>. Fig.&nbsp;5.2 Guideline for 
treating missing data
</p>
<p>5</p>
<p/>
<div class="annotation"><a href="https://www.iriseekhout.com">https://www.iriseekhout.com</a></div>
</div>
<div class="page"><p/>
<p>5103
5.4 &middot; Clean Data
</p>
<p>5.4.5.1  The Three Types of Missing Data: Paradise, Purgatory,  
and Hell
</p>
<p>We generally distinguish between three types of missing data:
 4 Missing completely at random (&ldquo;paradise&rdquo;),
 4 missing at random (&ldquo;purgatory&rdquo;), and
 4 non-random missing (&ldquo;hell&rdquo;).
</p>
<p>Data are missing completely at random (MCAR) when the probability of data being 
missing is unrelated to any other measured variable and is unrelated to the variable with 
missing values. MCAR data occur when there is no systematic reason for certain data 
points being missing. For example, MCAR may happen if the Internet server hosting the 
web survey broke down temporarily. Why is MCAR paradise? When data are MCAR, 
observations with missing data are indistinguishable from those with complete data. 
If this is the case and little data are missing (typically less than 10&nbsp;% in each variable) 
listwise deletion can be used. Listwise deletion means that we only analyze complete 
cases; in most statistical software, such as SPSS, this is a default option. Note that this 
default option in SPSS only works when estimating models and only applies to the vari-
ables included in the model. When more than 10&nbsp;% of the data are missing, we can use 
multiple imputation (Eekhout et al. 2014), a more complex approach to missing data 
treatment that we discuss in the section Dealing with Missing Data.
</p>
<p>Unfortunately, data are rarely MCAR. If the missingness of a variable&rsquo;s observation 
depends on one or more other variable(s) for which we have complete information (i.e., 
there are no missing observations for these variables), we consider the data missing at 
random (MAR). In this case, the probability that a data point is missing depends on the 
respondents&rsquo; traits (e.g., age, gender, or income) or their answering behavior regarding 
other variables in the dataset. An example of MAR is when women are less likely to reveal 
their income. That is, the probability of missing data depends on the gender and not on 
the actual level of the respondent&rsquo;s income.
</p>
<p>! The term MAR is quite confusing. Many researchers confuse MAR with MCAR 
but&nbsp;the label has stuck.
</p>
<p>Why is MAR purgatory? When data are MAR, the missing value pattern is not random, but 
this can be handled by more sophisticated missing data techniques such as multiple impu-
tation, which use information in other variables in the dataset to impute the missing data 
points. On the downside, however, the missingness can typically not be fully accounted 
for by other variables in the dataset. Hence, we must also rely on its substantive reason-
ableness to verify whether or not the data are MAR.
</p>
<p>Finally, data are missing not at random (MNAR) when the probability that a data point 
(e.g., xi) is missing depends on the variable x. For example, very affluent and poor people 
are generally less likely to indicate their income even when having the exact same observed 
values of race, education, and other observed background variables. That is, the missing 
income values depend on the income variable itself! This is the most severe type of missing 
data (&ldquo;hell&rdquo;). Even sophisticated missing data techniques do not provide satisfactory </p>
<p/>
</div>
<div class="page"><p/>
<p>104 Chapter 5 &middot; Descriptive Statistics
</p>
<p>solutions as it is impossible to estimate the missing observations from other known obser-
vations in the dataset. Thus, any result based on MNAR data should be considered with 
caution. MNAR data can best be prevented by extensive pretesting and consultations with 
experts to avoid surveys that cause problematic response behavior. For example, we could 
use income categories instead of querying the respondents&rsquo; income directly, or we could 
simply omit the income variable.
</p>
<p>The following website offers a nice visualization of these three typed of missing data.
</p>
<p>&copy; 1001Love/Getty Images/iStock
</p>
<p>https://iriseekhout.shinyapps.io/missingmechanisms/
</p>
<p>5.4.5.2 Testing for the Type of Missing Data
</p>
<p>When dealing with missing data, we must ascertain the missing data&rsquo;s type. If the dataset 
is small, we can browse through the data for obvious nonresponse patterns. However, 
missing data patterns become more difficult to identify with an increasing sample size and 
number of variables. Similarly, when we have few observations, patterns should be diffi-
cult to spot. In these cases, we should use one (or both) of the following diagnostic tests 
to identify missing data patterns:
</p>
<p> 4 Little&rsquo;s MCAR test, and
 4 mean difference tests.
</p>
<p>Little&rsquo;s MCAR test (Little 1998) analyzes the pattern of the missing data by comparing the 
observed data with the pattern expected if the data were randomly missing. If the test indi-
cates no significant differences between the two patterns, the missing data can be classified 
as MCAR. Put differently, the null hypothesis is that the data are MCAR. Thus,
</p>
<p> 4 if we do not reject the null hypothesis, we assume that the data are MCAR, and
 4 if we reject the null hypothesis, the data are either MAR or MNAR.
</p>
<p>5</p>
<p/>
<div class="annotation"><a href="https://iriseekhout.shinyapps.io/missingmechanisms/">https://iriseekhout.shinyapps.io/missingmechanisms/</a></div>
</div>
<div class="page"><p/>
<p>5105
5.4 &middot; Clean Data
</p>
<p>If the data cannot be assumed to be MCAR, we need to test whether the missing pattern is 
caused by another variable in the dataset by using the procedures discussed in 7 Chap.&nbsp;6. 
For example, we can run a two independent samples t-test to explore whether there is a sig-
nificant difference in the mean of a continuous variable (e.g., income) between the group 
with missing values and the group without missing values. If we find a significant differ-
ence between these two groups, we would conclude that the data are MAR. For nominal 
or ordinal variables, we would tabulate the occurrence of non-responses against different 
groups&rsquo; responses. If we put the (categorical) variable about which we have concerns in one 
column of a table (e.g., income category), and the number of (non-)responses in another, 
we obtain a table similar to . Table 5.2.
</p>
<p>We can use the χ2-test (pronounced as chi-square), discussed in the ⤓ Web Appen-
dix (&rarr; Downloads &rarr; 7 Chap.&nbsp;6), to test if there is a significant relationship between the 
respondents&rsquo; (non-)responses of a certain variable and their income. In this example, the 
test yields a χ2 value of 28.88, indicating that there is a significant relationship between 
the respondents&rsquo; income and the (non-)response behavior, supporting the assumption 
that the data are MAR.
</p>
<p>. Table 5.2 Example of response issues
</p>
<p>Low income Medium income High income
</p>
<p>Response 65 95 70
</p>
<p>Non-response 35 5 30
</p>
<p>N&nbsp;=&nbsp;300
</p>
<p>In the ⤓ Web Appendix (&rarr; Downloads), we illustrate details of Little&rsquo;s MCAR test, together with 
missing data analysis and imputation procedures.
</p>
<p>&copy; MicroStockHub/Getty Images/iStock
</p>
<p>https://www.guide-market-research.com/app/download/13488666227/
</p>
<p>SPSS+3rd_Chapter+5_Multiple+Imputation.pdf?t=1516712968</p>
<p/>
<div class="annotation"><a href="https://www.guide-market-research.com/app/download/13488666227/SPSS+3rd_Chapter+5_Multiple+Imputation.pdf?t=1516712968">https://www.guide-market-research.com/app/download/13488666227/SPSS+3rd_Chapter+5_Multiple+Imputation.pdf?t=1516712968</a></div>
<div class="annotation"><a href="https://www.guide-market-research.com/app/download/13488666227/SPSS+3rd_Chapter+5_Multiple+Imputation.pdf?t=1516712968">https://www.guide-market-research.com/app/download/13488666227/SPSS+3rd_Chapter+5_Multiple+Imputation.pdf?t=1516712968</a></div>
</div>
<div class="page"><p/>
<p>106 Chapter 5 &middot; Descriptive Statistics
</p>
<p>5.4.5.3 Dealing with Missing Data
</p>
<p>Research has suggested a broad range of approaches for dealing with missing data. We 
discuss the listwise deletion and the multiple imputation method.
</p>
<p>Listwise deletion uses only those cases with complete responses in respect of all the 
variables considered in the analysis. If any of the variables used have missing values, the 
observation is omitted from the computation. If many observations have some missing 
responses, this decreases the usable sample size substantially and hypotheses are tested 
with less power (the power of a statistical test is discussed in 7 Chap.&nbsp;6).
</p>
<p>Multiple imputation is a more complex approach to missing data treatment (Rubin 
1987; Carpenter and Kenward 2013). It is a simulation-based statistical technique that 
facilitates inference by replacing missing observations with a set of possible values (as 
opposed to a single value) representing the uncertainty about the missing data&rsquo;s true value 
(Schafer 1997). The missing values are replaced by a set of plausible values not once, but 
m times (e.g., 5 times). This procedure yields m imputed datasets, each of which reflects 
the uncertainty about the missing data&rsquo;s correct value (Schafer 1997). Using these m data-
sets as input, SPSS then analyzes each dataset separately. Depending on the type of sta-
tistical analysis, the program additionally analyzes a pooled dataset that combines the m 
datasets into one. According to the literature, deciding on the number of imputations, m, 
can be very challenging, especially when the patterns of the missing data are unclear. As 
a rule of thumb, an m of at least 5 should be sufficient to obtain valid inferences (Rubin, 
1987; White et al. 2011).
</p>
<p>Now that we have briefly reviewed the most common approaches for handling missing 
data, there is still one unanswered question: Which one should you use? As shown in 
.&nbsp;Fig.&nbsp;5.2, if the data are MCAR, listwise deletion is recommended (Graham 2012) when 
the missingness is less than 10&nbsp;% and multiple imputation when this is greater than 10&nbsp;%. 
When the data are not MCAR but MAR, listwise deletion yields biased results. You should 
therefore use the multiple imputation method with an m of 5 (White et al. 2011). Finally, 
when the data are MNAR, the multiple imputation method provides inaccurate results. 
Consequently, you should choose listwise deletion and acknowledge the limitations 
arising from the missing data. . Table 5.3 summarizes the data cleaning issues discussed 
in this section.
</p>
<p>5.5 Describe Data
</p>
<p>Once we have performed the previous steps, we can turn to the task of describing the data. 
Data can be described one variable at a time (univariate descriptives) or in terms of the 
relationship between two variables (bivariate descriptives). We further divide univariate 
and bivariate descriptives into graphs and tables, as well as statistics.
</p>
<p>The choice between the two depends on the information we want to convey. Graphs 
and tables can often tell a non-technical person a great deal. On the other hand, sta-
tistics require some background knowledge, but have the advantage that they take up 
little space and are exact. We summarize the different types of descriptive statistics in 
. Fig.&nbsp;5.3.
</p>
<p>5</p>
<p/>
</div>
<div class="page"><p/>
<p>5107
5.5 &middot; Describe Data
</p>
<p>. Table 5.3 Data cleaning issues and how to deal with them
</p>
<p>Problem Action
</p>
<p>Interviewer 
</p>
<p>fraud
</p>
<p>&ndash;  Check with respondents whether they were interviewed and correlate with 
</p>
<p>previous data if available.
</p>
<p>Suspicious 
</p>
<p>response 
</p>
<p>patterns
</p>
<p>&ndash; Check for straight lining.
</p>
<p>&ndash; Include reverse-scaled items.
</p>
<p>&ndash; Consider removing the cases with straight-lined responses.
</p>
<p>&ndash;  Consider cultural differences in response behavior (middle and extreme 
</p>
<p>response styles, acquiescence).
</p>
<p>&ndash; Check for inconsistencies in response behavior.
</p>
<p>Data entry errors &ndash;  Use descriptive statistics (minimum, maximum, range) to check for obvious 
</p>
<p>data entry errors.
</p>
<p>&ndash;  Compare a subset of surveys to the dataset to check for inconsistencies.
</p>
<p>Outliers &ndash;  Identify outliers using univariate descriptive statistics (minimum, maximum, 
</p>
<p>range), box plots, and scatter plots.
</p>
<p>&ndash; Outliers are usually retained unless they &hellip;
</p>
<p> - &hellip; Are a result of data entry errors,
</p>
<p> - &hellip; do not fit the objective of the research, or
</p>
<p> - &hellip;  influence the results severely (but report results with and without 
</p>
<p>outliers for transparency).
</p>
<p>Missing data &ndash;  Check the type of missing data by running Little&rsquo;s MCAR test and, if 
</p>
<p>necessary, mean differences tests.
</p>
<p>&ndash;  When the data are MCAR, use either listwise deletion or the multiple 
</p>
<p>imputation method with an m of 5.
</p>
<p>&ndash;  When the data are MAR, use the multiple imputation method with an m of 5.
</p>
<p>&ndash;  When the data are MNAR, use listwise deletion and acknowledge the 
</p>
<p>limitations arising from the missing data.
</p>
<p>Univariate Bivariate 
</p>
<p>Graphs &amp; tables Statistics 
</p>
<p>Measures of centrality: 
</p>
<p> Mode 
</p>
<p> Median 
</p>
<p> Mean 
</p>
<p>Scatter plots 
</p>
<p>Measures of dispersion 
</p>
<p> Range 
</p>
<p> Interquartile Range 
</p>
<p> Variance 
</p>
<p> Standard deviation 
</p>
<p>Covariance 
</p>
<p>Statistics Graphs &amp; tables 
</p>
<p>Bar chart 
</p>
<p>Histogram 
</p>
<p>Box plot 
</p>
<p>Pie chart 
</p>
<p>Crosstabs 
</p>
<p>Frequency table 
</p>
<p>Describe Data 
</p>
<p>Correlation 
</p>
<p>. Fig.&nbsp;5.3 The different types of descriptive statistics</p>
<p/>
</div>
<div class="page"><p/>
<p>108 Chapter 5 &middot; Descriptive Statistics
</p>
<p>5.5.1 Univariate Graphs and Tables
</p>
<p>In this section, we discuss the most common univariate graphs and univariate tables:
 4 Bar chart,
 4 histogram,
 4 box plot,
 4 pie chart, and the
 4 frequency table.
</p>
<p>. Figure&nbsp;5.4 draws on these different types of charts and tables to provide information 
on the characteristics of travelers taken from the Oddjob Airways dataset that we use 
throughout this book.
</p>
<p>A bar chart (. Fig.&nbsp;5.4 top left) is a graphical representation of a single categorical vari-
able indicating each category&rsquo;s frequency of occurrence. However, each bar&rsquo;s height can 
also represent other indices, such as centrality measures or the dispersion of different data 
groups (see next section). Bar charts are primarily useful for describing nominal or ordinal 
variables. Histograms should be used for interval or ratio-scaled variables.
</p>
<p>A histogram (. Fig.&nbsp;5.4 top middle) is a graph that shows how frequently catego-
ries made from a continuous variable occur. Differing from the bar chart, the variable 
categories on the x-axis are divided into (non-overlapping) classes of equal width. For 
example, if you create a histogram for the variable age, you can use classes of 21&ndash;30, 
31&ndash;40, etc. A histogram is commonly used to examine the distribution of a variable. 
For this purpose, a curve following a specific distribution (e.g., normal) is typically 
superimposed on the bars to assess the correspondence of the actual distribution to the 
</p>
<p>600
</p>
<p>400
</p>
<p>C
o
</p>
<p>u
n
</p>
<p>t
</p>
<p>200
</p>
<p>Germany Switzerland
0
</p>
<p>Austria France USA
</p>
<p>60
</p>
<p>Traveler
</p>
<p>Status
</p>
<p>Home country
</p>
<p>Blue
</p>
<p>Silver
</p>
<p>Gold
</p>
<p>80
</p>
<p>40
</p>
<p>20
</p>
<p>0
0
</p>
<p>695 65.3 65.3 65.3
</p>
<p>66
</p>
<p>Valid Germany
</p>
<p>Frequency Percent Valid Percent
</p>
<p>Cumulative
</p>
<p>Percent
</p>
<p>20 40 60
</p>
<p>Age
</p>
<p>country
</p>
<p>80 100 120
</p>
<p>120
</p>
<p>100
</p>
<p>80
</p>
<p>60
</p>
<p>A
g
</p>
<p>e
</p>
<p>F
re
</p>
<p>q
u
</p>
<p>e
n
</p>
<p>c
y
</p>
<p>40
</p>
<p>20
</p>
<p>0
</p>
<p>Mean = 50.42
</p>
<p>Std. Dev. = 12.275
</p>
<p>N = 1,065
</p>
<p>659
993
909
</p>
<p>Switzerland
</p>
<p>Austria
</p>
<p>France
</p>
<p>USA
</p>
<p>Total
</p>
<p>108
1
</p>
<p>195
</p>
<p>1065
</p>
<p>6.2
10.1
</p>
<p>.1
18.3
</p>
<p>100.0
</p>
<p>6.2 71.5
10.1
</p>
<p>.1
18.3
</p>
<p>100.0
</p>
<p>81.6
81.7
</p>
<p>100.0
</p>
<p>. Fig.&nbsp;5.4 From top left to bottom right; the bar chart, histogram, box plot, pie chart, and frequency 
table
</p>
<p>5</p>
<p/>
</div>
<div class="page"><p/>
<p>5109
5.5 &middot; Describe Data
</p>
<p>desired (e.g., normal) distribution. Given that overlaying a normal curve makes most 
symmetric distributions look more normal then they are, you should be cautious when 
assessing normality using histograms. In 7 Chap.&nbsp;6&nbsp;we will discuss several options for 
checking the normality of data.
</p>
<p>! Histograms plot continuous variables with ranges of the variables grouped into 
intervals (bins), while bar charts plot nominal and ordinal variables.
</p>
<p>Another way of displaying the distribution of a (continuous) variable is the box plot 
(.&nbsp;Fig.&nbsp;5.4 top right) (also referred to as a box-and-whisker plot). The box plot is a graph 
representing a variable&rsquo;s distribution and consists of elements expressing the dispersion 
of the data. Note that several elements refer to terminologies discussed in the Univariate 
Statistics section (7 Sect. 5.5.2). . Fig.&nbsp;5.5 shows a box plot for the variable age based on 
the Oddjob Airways dataset.
</p>
<p> 4 The bottom and top of the box describe the first and third quartiles. That is, the box 
contains the middle 50&nbsp;% of the data, which is equivalent to the interquartile range 
(see 7 Sect. 5.5.2).
 4 The solid line inside the box represents the median.
 4 The upper line extending the box (whisker) represents the distance to the largest 
</p>
<p>observation that is within the following range: 3rd quartile + interquartile range. 
If there are no observations within this range, the line is equal to the maximum 
value.
</p>
<p>Median 
</p>
<p>1st quartile
</p>
<p>3rd quartile
</p>
<p>Whisker 
</p>
<p>Whisker 
</p>
<p>Outlier
</p>
<p>A
g
e
</p>
<p>659
</p>
<p>120
</p>
<p>100
</p>
<p>993
909
</p>
<p>80
</p>
<p>60
</p>
<p>40
</p>
<p>20
</p>
<p>0
</p>
<p>. Fig.&nbsp;5.5 Elements of the box plot</p>
<p/>
</div>
<div class="page"><p/>
<p>110 Chapter 5 &middot; Descriptive Statistics
</p>
<p> 4 The lower line extending the box (whisker) represents the distance to the smallest 
observation that is within the following range: 1st quartile&mdash;interquartile range. If 
there are no obervations within this range, the line is equal to the minimum value.
 4 Outliers (observations that range between 1.0 and 3.0 interquartile ranges away from 
</p>
<p>the box) and extreme values (observations that range more than 3.0 interquartile 
ranges away from the box) are depicted by symbols outside the whiskers.
</p>
<p>We can make statements about the dispersion of the data with a box plot. The larger the 
box, the greater the observations&rsquo; variability. Furthermore, the box plot helps us identify 
outliers in the data.
</p>
<p>The pie chart (i.e., . Fig.&nbsp;5.4 bottom left) visualizes how a variable&rsquo;s different values 
are distributed. Pie charts are particularly useful for displaying percentages of variables, 
because people interpret the entire pie as being 100&nbsp;%, and can easily see how often values 
occur. The limitation of the pie chart is, however, that it is difficult to determine the size 
of segments that are very similar.
</p>
<p>A frequency table (i.e., . Fig.&nbsp;5.4 bottom right) is a table that includes all possible 
values of a variable in absolute terms (i.e., frequency), how often they occur relatively 
(i.e., percentage), and the percentage of the cumulative frequency, which is the sum of 
all the frequencies from the minimum value to the category&rsquo;s upper bound (i.e., cumula-
tive frequency). It is similar to the histogram and pie chart in that it shows the distribu-
tion of a variable&rsquo;s possible values. However, in a frequency table, all values are indicated 
exactly. Like pie charts, frequency tables are primarily useful if variables are measured on 
a nominal or ordinal scale.
</p>
<p>5.5.2 Univariate Statistics
</p>
<p>Univariate statistics fall into two groups: those describing centrality and those describing 
the dispersion of variables. Box 5.2&nbsp;at the end of this section shows sample calculation of 
the statistics used on a small set of values.
</p>
<p>5.5.2.1 Measures of Centrality
</p>
<p>Measures of centrality (also referred to as measures of central tendency) are statistical indices 
of a &ldquo;typical&rdquo; or &ldquo;average&rdquo; score. There are two main types of measures of centrality, the 
median and the mean.4
</p>
<p>The median is the value that occurs in the middle of the set of scores if they are ranked 
from the smallest to the largest, and it therefore separates the lowest 50&nbsp;% of cases from 
the highest 50&nbsp;% of cases. For example, if 50&nbsp;% of the products in a market cost less than 
$1000, then this is the median price. Identifying the median requires at least ordinal data 
(i.e., it cannot be used with nominal data).
</p>
<p>4 The mode is another measure. However, unlike the median and mean, it is ill-defined, because it can 
</p>
<p>take on multiple values. Consequently, we do not discuss the mode.
</p>
<p>5</p>
<p/>
</div>
<div class="page"><p/>
<p>5111
5.5 &middot; Describe Data
</p>
<p>The most commonly used measure of centrality is the mean (also called the arithmetic 
mean or, simply, the average). The mean (abbreviated as x ) is the sum of each observa-
tion&rsquo;s value divided by the number of observations:
</p>
<p>x
Sum x
</p>
<p>n n
x
</p>
<p>i
</p>
<p>n
</p>
<p>i=
( )
=
</p>
<p>=
&sum;1
</p>
<p>1
</p>
<p>In the above formula, xi refers to the value of observation i of variable x and n refers to the 
total number of observations. The mean is only useful for interval or ratio-scaled vari-
ables. SPSS also allows computing the 5&nbsp;% trimmed mean, which is the mean that would 
be obtained if the lower and upper 5&nbsp;% of values of the variable were deleted.
</p>
<p>Each measure of centrality has its own use. The mean is most frequently used, but 
</p>
<p>is sensitive to very small or large values. Conversely, the median is not sensitive to 
</p>
<p>outliers. Consequently, the relationship between the mean and the median provides 
</p>
<p>us with valuable information about a variable&rsquo;s distribution. If the mean and the 
</p>
<p>median are about the same, the variable is likely to be symmetrically distributed (i.e., 
</p>
<p>the left side of the distribution mirrors the right side). If the mean differs from the 
</p>
<p>median, this suggests that the variable is asymmetrically distributed and/or contains 
</p>
<p>outliers. This is the case when we examine the prices of a set of products valued $500, 
</p>
<p>$530, $530, and $10,000; the median is $530, while the mean is $2890. This example 
</p>
<p>illustrates why a single measure of centrality can be misleading. We also need to 
</p>
<p>consider the variable&rsquo;s dispersion to gain a more complete picture.
</p>
<p>Tip
</p>
<p>5.5.2.2 Measures of Dispersion
Measures of dispersion provide researchers with information about the variability of the 
data; that is, how far the values are spread out. We differentiate between four types of mea-
sures of dispersion:
 4 Range,
 4 interquartile range,
 4 variance, and
 4 standard deviation.
</p>
<p>The range is the simplest measure of dispersion. It is the difference between the highest 
and the lowest value in a dataset and can be used on data measured at least on an ordinal 
scale. The range is of limited use as a measure of dispersion, because it provides infor-
mation about extreme values and not necessarily about &ldquo;typical&rdquo; values. However, the 
range is valuable when screening data, as it allows for identifying data entry errors. For 
example, a range of more than 6 on a 7-point Likert scale would indicate an incorrect 
data entry.
</p>
<p>The interquartile range is the difference between the 3rd and 1st quartile. The 1st quar-
tile corresponds to the value separating the 25&nbsp;% lowest values from the 75&nbsp;% largest values 
if the values are ordered sequentially. Correspondingly, the 3rd quartile separates the 75&nbsp;% </p>
<p/>
</div>
<div class="page"><p/>
<p>112 Chapter 5 &middot; Descriptive Statistics
</p>
<p>lowest from the 25&nbsp;% highest values. The interquartile range is particularly important for 
drawing box plots.
</p>
<p>The variance (generally abbreviated as s2) is a common measure of dispersion. The vari-
ance is the sum of the squared differences of each value and a variable&rsquo;s mean, divided by 
the sample size minus 1. The variance is only useful if the data are interval or ratio-scaled:
</p>
<p>s
x x
</p>
<p>n
i
</p>
<p>n
</p>
<p>i2 1
2
</p>
<p>1
=
</p>
<p>&minus;
</p>
<p>&minus;
=&sum; ( )
</p>
<p>The variance tells us how strongly observations vary around the mean. A low variance 
indicates that the observations tend to be very close to the mean; a high variance indicates 
that the observations are spread out. Values far from the mean increase the variance more 
than those close to the mean.
</p>
<p>The most commonly used measure of dispersion is the standard deviation (usually 
abbreviated as s). It is the square root of&mdash;and, therefore, a variant of&mdash;the variance:
</p>
<p>s s
x x
</p>
<p>n
i
</p>
<p>n
</p>
<p>i
= =
</p>
<p>&minus;
</p>
<p>&minus;
=&sum;2 1
</p>
<p>2
</p>
<p>1
</p>
<p>( )
</p>
<p>The variance and standard deviation provide similar information, but while the variance 
is expressed on the same scale as the original variable, the standard deviation is standard-
ized. Consequently, the following holds for normally distributed variables (this will be 
discussed in the following chapters in more detail):
 4 66&nbsp;% of all observations are between plus and minus one standard deviation units 
</p>
<p>from the mean,
 4 95&nbsp;% of all observations are between plus and minus two standard deviation units 
</p>
<p>from the mean, and
 4 99&nbsp;% of all observations are between plus and minus three standard deviation units 
</p>
<p>from the mean.
</p>
<p>Thus, if the mean price is $1000 and the standard deviation is $150, then 66&nbsp;% of all the 
prices fall between $850 and $1150, 95&nbsp;% fall between $700 and $1300, and 99&nbsp;% of all the 
observations fall between $550 and $1450.
</p>
<p>5.5.3 Bivariate Graphs and Tables
</p>
<p>There are several bivariate graphs and bivariate tables, of which the scatter plot and the 
crosstab are the most important. Furthermore, several of the graphs, charts, and tables dis-
cussed in the context of univariate analysis can be used for bivariate analysis. For example, 
box plots can be used to display the distribution of a variable in each group (category) of 
nominal variables.
</p>
<p>5</p>
<p/>
</div>
<div class="page"><p/>
<p>5113
5.5 &middot; Describe Data
</p>
<p>5 A similar type of chart is the line chart. In a line chart, measurement points are ordered (typically by 
their x-axis value) and joined with straight line segments.
</p>
<p>A scatter plot (see . Fig.&nbsp;5.6) uses both the y and x-axis to show how two variables relate 
to each other. If the observations almost form a straight diagonal line in a scatter plot, the 
two variables are strongly related.5 Sometimes, a third variable is included, adding another 
dimension to the plot. Corresponding variants of the scatter plot include the bubble plot 
or 3-D scatter plot.
</p>
<p>Crosstabs (also referred to as contingency tables) are tables in a matrix format that show 
the frequency distribution of nominal or ordinal variables. They are the equivalent of a 
scatter plot used to analyze the relationship between two variables. While crosstabs are 
generally used to show the relationship between two variables, they can also be used for 
three or more variables, which, however, makes them difficult to grasp.
</p>
<p>r = 1.0 
1.00
</p>
<p>.80
</p>
<p>r = &ndash;1.0 
</p>
<p>r = 0 r = 0 
</p>
<p>.60
</p>
<p>y
y
</p>
<p>x x
</p>
<p>x x
</p>
<p>.40
</p>
<p>.20
</p>
<p>.00
</p>
<p>1.00
</p>
<p>.80
</p>
<p>.60
</p>
<p>y
y
</p>
<p>.40
</p>
<p>.20
</p>
<p>.00
</p>
<p>.80
</p>
<p>.50
</p>
<p>.00 .20 .40 .60 .80 1.00 .00 .20 .40 .60 .80 1.00
</p>
<p>.00 .20 .40 .60 .80 1.00
</p>
<p>.60
</p>
<p>.40
</p>
<p>.20
</p>
<p>.00
</p>
<p>&minus;.20
</p>
<p>&minus;.40
</p>
<p>&minus;.50 &minus;.25 &minus;.05 .25 .50
</p>
<p>. Fig.&nbsp;5.6 Scatter plots and correlations</p>
<p/>
</div>
<div class="page"><p/>
<p>114 Chapter 5 &middot; Descriptive Statistics
</p>
<p>5.5.4 Bivariate Statistics
</p>
<p>Bivariate statistics involve the analysis of two variables to determine the empirical relation-
ship between them. There are two key measures that indicate (linear) associations between 
two variables; we illustrate their computation in Box 5.2:
 4 covariance, and
 4 correlation.
</p>
<p>The covariance is the degree to which two variables vary together. If the covariance is zero, 
then two variables do not vary together. The covariance is the sum of the multiplication 
of the differences between each value of the xi and yi variables and their means, divided 
by the sample size minus 1:
</p>
<p>Cov x y
n
</p>
<p>x x y yi i
i
</p>
<p>n
</p>
<p>i i,( )= &minus;
&minus;( )&sdot; &minus;( )
</p>
<p>=
&sum;1
</p>
<p>1
1
</p>
<p> 
</p>
<p>Crosstabs are also part of the χ2-test, which we discuss in the ⤓ Web Appendix (&rarr; Downloads &rarr; 
7&nbsp;Chap.&nbsp;6).
</p>
<p>&copy; NiseriN/Getty Images/iStock
</p>
<p>https://www.guide-market-research.com/app/download/13488667027/SPSS+3rd_Chapter+6_
</p>
<p>Chi-square+test.pdf?t=1516713011
</p>
<p>5</p>
<p/>
<div class="annotation"><a href="https://www.guide-market-research.com/app/download/13488667027/SPSS+3rd_Chapter+6_Chi-square+test.pdf?t=1516713011">https://www.guide-market-research.com/app/download/13488667027/SPSS+3rd_Chapter+6_Chi-square+test.pdf?t=1516713011</a></div>
<div class="annotation"><a href="https://www.guide-market-research.com/app/download/13488667027/SPSS+3rd_Chapter+6_Chi-square+test.pdf?t=1516713011">https://www.guide-market-research.com/app/download/13488667027/SPSS+3rd_Chapter+6_Chi-square+test.pdf?t=1516713011</a></div>
</div>
<div class="page"><p/>
<p>5115
5.5 &middot; Describe Data
</p>
<p>The correlation (typically abbreviated as r) is a common measure of how strongly two vari-
ables relate to each other. The most common type of correlation, the Pearson&rsquo;s correlation 
coefficient, is calculated as follows:
</p>
<p>r
Cov x y
</p>
<p>s s
</p>
<p>x x y y
</p>
<p>x x y y
</p>
<p>i i
</p>
<p>x y
</p>
<p>i
</p>
<p>n
</p>
<p>i i
</p>
<p>i
</p>
<p>n
</p>
<p>i i
</p>
<p>n
</p>
<p>i
</p>
<p>=
( )
&sdot;
</p>
<p>=
&minus; &sdot; &minus;( )
</p>
<p>&minus;( ) &sdot; &minus;
</p>
<p>&sum;
</p>
<p>&sum; &sum;
=
</p>
<p>= =
</p>
<p>, ( )
1
</p>
<p>1
</p>
<p>2
</p>
<p>1
(( )
</p>
<p>2
</p>
<p> 
</p>
<p>The numerator contains the covariance of xi and yi Cov x yi i,( )( ) , while the denomina-
tor contains the product of the standard deviations of xi and yi.
</p>
<p>6 Thus, the correlation 
is the covariance divided by the product of the standard deviations. As a result, the 
correlation is standardized and, unlike the covariance, is no longer dependent on the 
variables&rsquo; original measurement. More precisely, the correlation coefficient ranges from 
&minus;1 to 1, where &minus;1 indicates a perfect negative relationship and 1 indicates the contrary. 
A correlation coefficient of 0 indicates that there is no relationship, also implying that 
their covariance is zero.
</p>
<p>6 Note that the terms n&minus;1 in the numerator and denominator cancel each other and are therefore not 
</p>
<p>shown here.
</p>
<p>Box 5.2 Sample calculation of univariate and bivariate statistics
</p>
<p>Consider the following list of values for variables x and y, which we treat as ratio-scaled:
</p>
<p>x 6 6 7 8 8 8 12 14 14
</p>
<p>y 7 6 6 9 8 5 10 9 9
</p>
<p>Measures of centrality for x:
</p>
<p>Median&nbsp;=&nbsp;8
</p>
<p>Mean x =
1
</p>
<p>9
6 + 6 + + 14 + 14 =
</p>
<p>83
</p>
<p>9
9.22&hellip;( ) &asymp;
</p>
<p>Measures of dispersion for x:
</p>
<p>Minimum&nbsp;=&nbsp;6
</p>
<p>Maximum&nbsp;=&nbsp;14
</p>
<p>Range&nbsp;=&nbsp;14&nbsp;&ndash;&nbsp;6&nbsp;=&nbsp;8
</p>
<p>Interquartile range&nbsp;=&nbsp;6.5
</p>
<p>Variance ( ) =
(6 9.22) + + (14 9.22)
</p>
<p>9 1
=
</p>
<p>83.56
</p>
<p>8
10.442
</p>
<p>2 2
</p>
<p>s
&minus; &minus;
</p>
<p>&minus;
</p>
<p>&hellip;
</p>
<p>
 ] &asymp;
</p>
<p>Standard deviation (s)&nbsp;= s = 10.44 3.232 &asymp;
Measures of association between x and y:
</p>
<p>Covariance ( ( , )) =
1
</p>
<p>9 1
[ 6 9.22 7 7.67 + +
</p>
<p>14 9.22 9 7.67 ] =
31
</p>
<p>cov x y
&minus;
</p>
<p>&minus; &minus;
</p>
<p>&minus; &minus;
</p>
<p>( )&sdot;( )
</p>
<p>( )&sdot;( )
</p>
<p>&hellip;
</p>
<p>..67
</p>
<p>8
3.9&asymp;
</p>
<p>Correlation r( )
&sdot;
</p>
<p>&asymp;=
3.96
</p>
<p>3.23 1.73
0.71</p>
<p/>
</div>
<div class="page"><p/>
<p>116 Chapter 5 &middot; Descriptive Statistics
</p>
<p>! Strong relationships are not necessarily better than weak relationships. Strong 
relationships are typically well-established which means they lack novelty. 
</p>
<p>Furthermore, strong relationships may not be actionable. For example, knowing 
</p>
<p>that high net worth is a predictor of sports car sales does not help if we do not have 
</p>
<p>good information on high net worth for targeting purposes.
</p>
<p>The scatter plots in . Fig.&nbsp;5.6 illustrate several correlations between two variables x and y. 
If the observations almost form a straight diagonal line in the scatter plot (upper left and 
right in . Fig.&nbsp;5.6), the two variables have a high (absolute) correlation. If the observations 
are uniformly distributed in the scatter plot (lower right in . Fig.&nbsp;5.6), or one variable is a 
constant (lower left in . Fig.&nbsp;5.6), the correlation is zero.
</p>
<p>Pearson&rsquo;s correlation coefficient is the most common and is generally simply referred to 
as the correlation (Agresti and Finlay 2014). Pearson&rsquo;s correlation is appropriate for calcu-
lating correlations between two variables that are both interval or ratio-scaled. However, it 
can also be used when one variable is interval or ratio-scale and the other is, for example, 
binary. There are other correlation coefficients for variables measured on lower scale levels. 
Some examples are:
</p>
<p> 4 Spearman&rsquo;s correlation coefficient and Kendall&rsquo;s tau when at least one variable for 
determining the correlation is measured on an ordinal scale.
 4 Contingency coefficient, Cramer&rsquo;s V, and Phi for variables measured on a nominal 
</p>
<p>scale. These statistical measures are used with crosstabs; we discuss these in the 
context of the χ2-test in the ⤓ Web Appendix (&rarr; Downloads &rarr; 7 Chap.&nbsp;6).
</p>
<p>In . Table 5.4, we indicate which descriptive statistics are useful for differently scaled vari-
ables. The brackets X indicate that the use of a graph, table, or statistic is potentially useful 
while (X) indicates that use is possible, but less likely useful, because this typically requires 
collapsing data into categories, resulting in a loss of information.
</p>
<p>5.6 Transform Data (Optional)
</p>
<p>Transforming data is an optional step in the workflow. Researchers transform data as 
certain analysis techniques require this: it might help interpretation or might help meet 
the assumptions of techniques that will be discussed in subsequent chapters. We distin-
guish two types of data transformation:
 4 variable respecification, and
 4 scale transformation.
</p>
<p>As a rule of thumb (Cohen 1988), an absolute correlation &hellip;
</p>
<p> 5 &hellip; below 0.30 indicates a weak relationship,
 5 &hellip; between 0.30 and 0.49 indicates a moderate relationship, and
 5 &hellip; above 0.49 indicates a strong relationship.
</p>
<p>Tip
</p>
<p>5</p>
<p/>
</div>
<div class="page"><p/>
<p>5117
5.6 &middot; Transform Data (Optional)
</p>
<p>. Table 5.4 Types of descriptive statistics for differently scaled variables
</p>
<p>Nominal Ordinal Interval &amp; ratio
</p>
<p>Univariate graphs &amp; tables
</p>
<p>Bar chart X X
</p>
<p>Histogram X
</p>
<p>Box plot X
</p>
<p>Pie chart X X (X)
</p>
<p>Frequency table X X (X)
</p>
<p>Univariate statistics: Measures of centrality
</p>
<p>Median X X
</p>
<p>Mean X
</p>
<p>Univariate statistics: Measures of dispersion
</p>
<p>Range (X) X
</p>
<p>Interquartile range (X) X
</p>
<p>Variance X
</p>
<p>Standard deviation X
</p>
<p>Bivariate graphs/tables
</p>
<p>Scatter plot X
</p>
<p>Crosstab X X (X)
</p>
<p>Bivariate statistics
</p>
<p>Contingency coefficient X
</p>
<p>Cramer&rsquo;s V X
</p>
<p>Phi X
</p>
<p>Spearman&rsquo;s correlation X
</p>
<p>Kendall&rsquo;s tau X
</p>
<p>Pearson&rsquo;s correlation X
</p>
<p>5.6.1 Variable Respecification
</p>
<p>Variable respecification involves transforming data to create new variables or to modify 
existing ones. The purpose of respecification is to create variables that are consistent 
with the study&rsquo;s objective. Recoding a continuous variable into a categorical variable is 
an example of a simple respecification. For example, if we have a variable that measures a 
respondent&rsquo;s number of flights per year, we could code those flights below 5 as low (=1), 
between 5 and 10&nbsp;flights as medium (=2), and everything above 11 as high (=3). Recoding </p>
<p/>
</div>
<div class="page"><p/>
<p>118 Chapter 5 &middot; Descriptive Statistics
</p>
<p>a variable in such a way always results in a loss of information, since the newly created vari-
able contains less detail than the original. While there are situations that require recoding 
(e.g., we might be asked to give advice based on different income groups where income is 
continuous), we should generally avoid recoding.
</p>
<p>Another example of respecification is swapping the polarity of a question. If you have a 
variable measured on a 5-point Likert-scale where: 1&nbsp;=&nbsp;strongly agree; 2&nbsp;=&nbsp;agree; 3&nbsp;=&nbsp;unde-
cided; 4&nbsp;=&nbsp;disagree; 5&nbsp;=&nbsp;strongly disagree and you wish to switch the polarity of the values 
so that value 1 reverses to 5, value 2 becomes 4, and so on.
</p>
<p>Creating a dummy variable is a special way of recoding data. Dummy variables (or 
simply dummies) are binary variables that indicate if a certain trait is present or not. For 
example, we can use a dummy variable to indicate that advertising was used during a 
period (value of the dummy is 1) or not (value of the dummy is 0). We can also use mul-
tiple dummies to capture categorical variables&rsquo; effects. For example, three levels of flight 
intensity (low, medium, and high) can be represented by two dummy variables: The first 
takes a value of 1 if the intensity is high (0 else), the second also takes a value of 1 if the 
intensity is medium (0 else). If both dummies take the value 0, this indicates low flight 
intensity. We always construct one dummy less than the number of categories. We show 
how to create dummy variables in SPSS in the example illustrating the use of regression 
analysis in 7 Sect.&nbsp;7.4.
</p>
<p>The creation of constructs is a frequently used type of variable respecification. As 
described in 7 Chap.&nbsp;3, a construct is a concept that cannot be observed, but can be mea-
sured by using multiple items, none of which relate perfectly to the construct. To compute 
a construct measure, we need to calculate the average (or the sum) of several related items. 
For example, a traveler&rsquo;s commitment to fly with an airline can be measured by using the 
following three items:
</p>
<p> 4 I am very committed to Oddjob Airways.
 4 My relationship with Oddjob Airways means a lot to me.
 4 If Oddjob Airways would no longer exist, it would be a true loss for me.
</p>
<p>By calculating the average of these three items, we can form a composite of commitment. If 
one respondent indicated 4, 3, and 4 on the three items&rsquo; scale, we calculate a construct score 
(also referred to as a composite score) for this person as follows: (4&nbsp;+&nbsp;3&nbsp;+&nbsp;4)/3&nbsp;=&nbsp;3.67. Note 
that we should take the average over the number of nonmissing responses. In 7 Chap.&nbsp;8&nbsp;we 
discuss more advanced methods of doing this by, for example, creating factor scores.
</p>
<p>Similar to creating constructs, we can create an index of sets of variables. For example, 
we can create an index of information search activities, which is the sum of the informa-
tion that customers require from promotional materials, the Internet, and other sources. 
This measure of information search activities is also referred to as a composite measure, 
but, unlike a construct, the items in an index define the trait to be measured.
</p>
<p>5.6.2 Scale Transformation
</p>
<p>Scale transformation involves changing the variable values to ensure comparability with 
other variables or to make the data suitable for analysis. Different scales are often used to 
measure different variables. For example, we may use a 5-point Likert scale for one set of 
</p>
<p>5</p>
<p/>
</div>
<div class="page"><p/>
<p>5119
5.6 &middot; Transform Data (Optional)
</p>
<p>7 The logarithm is calculated as follows: If x&nbsp;=&nbsp;yb, then y&nbsp;=&nbsp;logb(x) where x is the original variable, b the 
</p>
<p>logarithm&rsquo;s base, and y the exponent. For example, log 10 of 100 is 2. Logarithms cannot be calculat-
</p>
<p>ed for negative values (such as household debt) and for the value of zero.
</p>
<p>variables and a 7-point Likert scale for a different set of variables in our survey. Owing to 
the differences in scaling, it would not be meaningful to make comparisons across any 
respondent&rsquo;s measurement scales. These differences can be corrected by standardizing 
variables.
</p>
<p>A popular way of standardizing data is by rescaling these to have a mean of 0 and a 
variance of 1. This type of standardization is called the z-standardization. Mathematically, 
standardized scores zi (also called z-scores) can be obtained by subtracting the mean x  of 
every observation xi and dividing it by the standard deviation s. That is:
</p>
<p>z
x x
</p>
<p>si
i=
&minus;( )
</p>
<p> 
</p>
<p>Range standardization ri( )  is another standardization technique which scales the data 
in a specific range. For example, standardizing a set of values to a range of 0 to 1 requires 
subtracting the minimum value of every observation xi and then dividing it by the range 
(i.e., the difference between the maximum and minimum value).
</p>
<p>r
x x
</p>
<p>x xi
i min
</p>
<p>max min
</p>
<p>=
&minus;( )
&minus;( )  
</p>
<p>The range standardization is particularly useful if the mean, variance, and ranges of differ-
ent variables vary strongly and are used for some forms of cluster analysis (see 7 Chap.&nbsp;9.)
</p>
<p>A log transformation&mdash;another type of transformation&mdash;is commonly used if we 
have skewed data. Skewed data occur if we have a variable that is asymmetrically dis-
tributed and can be positive or negative. A positive skew (also called right-skewed data 
or skewed to the right) occurs when many observations are concentrated on the left side 
of the distribution, producing a long right tail. When data are right-skewed, the mean 
will be higher than the median. A negative skew (also called left-skewed data or skewed 
to the left) is the opposite, meaning that many observations are concentrated on the 
right of the distribution, producing a long left tail. When data are negatively skewed, 
the mean will be lower than the median. A histogram will quickly show whether data 
are skewed. Skewed data can be undesirable in analyses. Log transformations are com-
monly used to transform data closer to a normal distribution when the data are right-
skewed (i.e., the data are non-negative). Taking a natural logarithm will influence the 
size of the coefficient related to the transformed variable, but will not influence the 
value of its outcome.7
</p>
<p>Finally, aggregation is a special type of transformation. Aggregation means that we 
take variables measured at a lower level to a higher level. For example, if we know the 
average customer&rsquo;s satisfaction with an airline and the distribution channels from which 
they buy (i.e., the Internet or a travel agent), we can calculate the average satisfaction at 
the channel level. Aggregation only works from lower to higher levels and is useful if we 
want to compare groups at a higher level.</p>
<p/>
</div>
<div class="page"><p/>
<p>120 Chapter 5 &middot; Descriptive Statistics
</p>
<p>! While transforming data is often necessary to ensure comparability between 
variables or to make the data suitable for analysis, there are also drawbacks to this 
</p>
<p>procedure. Most notably, we may lose information during most transformations. 
</p>
<p>For example, recoding the ticket price (measured at the ratio scale) as a &ldquo;low,&rdquo; 
</p>
<p>&ldquo;medium,&rdquo; and &ldquo;high&rdquo; ticket price will result in an ordinal variable. In the 
</p>
<p>transformation process, we have therefore lost information by going from a ratio to 
</p>
<p>an ordinal scale. Another drawback is that transformed data are often more difficult 
</p>
<p>to interpret. For example, the log (ticket price) is far more difficult to interpret and 
</p>
<p>less intuitive than simply using the ticket price.
</p>
<p>5.7 Create a Codebook
</p>
<p>After all the variables have been organized and cleaned, and some initial descriptive sta-
tistics have been calculated, we can create a codebook, containing essential details of the 
data collection and data files, to facilitate sharing. Codebooks usually have the following 
structure:
 4 Introduction: The introduction discusses the goal of the data collection, why the data 
</p>
<p>are useful, who participated, and how the data collection effort was conducted (mail, 
Internet, etc.).
 4 Questionnaire(s): It is common practice to include copies of all the types of question-
</p>
<p>naires used. Thus, if different questionnaires were used for different respondents 
(e.g., for French and Chinese respondents), a copy of each original questionnaire 
should be included. Differences in wording may afterwards explain the results of 
the study, particularly those of cross-national studies, even if a back-translation was 
used (see 7 Chap.&nbsp;4). These are not the questionnaires received from the respondents 
themselves, but blank copies of each type of questionnaire used. Most codebooks 
include details of each variable as comments close to the actual items used. If a 
dataset was compiled using secondary measures (or a combination of primary and 
secondary data), the secondary datasets are often briefly discussed (the version that 
was used, when it was accessed, etc.).
 4 Description of the variables: This section includes a verbal description of each 
</p>
<p>variable used. It is useful to provide the variable name as used in the data file, a 
description of what the variable is supposed to measure, and whether the measure 
has previously been used. You should also describe the measurement level (see 
7&nbsp;Chap.&nbsp;3).
 4 Summary statistics: This section includes descriptive statistics of each variable. 
</p>
<p>The average (only for interval and ratio-scaled data), minimum, and maximum 
are often shown. In addition, the number of observations and usable observations 
(excluding observations with missing values) are included, just like a histogram 
(if&nbsp;applicable).
 4 Datasets: This last section includes the names of the datasets and sometimes the 
</p>
<p>names of all the revisions of the used datasets. Codebooks sometimes include the file 
date or a data signature, to ensure that the right files are used.
</p>
<p>5</p>
<p/>
</div>
<div class="page"><p/>
<p>5121
5.8 &middot; The Oddjob Airways Case Study
</p>
<p>5.8 The Oddjob Airways Case Study
</p>
<p>The most effective way of learning statistical methods is to apply them to a set of data. Before 
introducing SPSS and how to use it, we present the dataset from a fictitious company called 
Oddjob Airways (but with a real website, http://www.oddjobairways.com) that will guide the 
examples throughout this book. The dataset Oddjob.sav (⤓ Web Appendix &rarr; Downloads) 
stems from a customer survey of Oddjob Airways. Founded in 1962 by the Korean business-
man Toshiyuki Sakata, Oddjob Airways positions itself as a low-cost carrier, targeting young 
customers who prefer late or overnight flights. However, the actual customer base is very 
diverse with many older customers appreciating the offbeat onboard services, high-speed 
Wi-Fi, and tablet computers on every seat. In an effort to improve its customers&rsquo; satisfaction, 
the company&rsquo;s marketing department contacted all the customers who had flown with the 
airline during the last 12&nbsp;months and were registered on the company website. A total of 1065 
customers who had received an email with an invitation letter completed the survey online.
</p>
<p>In the Web Appendix (⤓ Web Appendix &rarr; Downloads), we briefly discuss how to create a 
codebook using SPSS.
</p>
<p>&copy; Sezeryadigar/Getty Images/iStock
</p>
<p>https://www.guide-market-research.com/app/download/13488664927/
</p>
<p>SPSS+3rd_Chapter+5_Codebook.pdf?t=1516712939
</p>
<p>Learn more about Oddjob Airways at www.oddjobairways.com. The site not only offers 
</p>
<p>background on the airline but also lots of learning material relevant to this book.
</p>
<p>Oddjob Airways</p>
<p/>
<div class="annotation"><a href="http://www.oddjobairways.com">http://www.oddjobairways.com</a></div>
<div class="annotation"><a href="https://www.guide-market-research.com/app/download/13488664927/SPSS+3rd_Chapter+5_Codebook.pdf?t=1516712939">https://www.guide-market-research.com/app/download/13488664927/SPSS+3rd_Chapter+5_Codebook.pdf?t=1516712939</a></div>
<div class="annotation"><a href="https://www.guide-market-research.com/app/download/13488664927/SPSS+3rd_Chapter+5_Codebook.pdf?t=1516712939">https://www.guide-market-research.com/app/download/13488664927/SPSS+3rd_Chapter+5_Codebook.pdf?t=1516712939</a></div>
<div class="annotation"><a href="http://www.oddjobairways.com">http://www.oddjobairways.com</a></div>
<div class="annotation"><a href="https://www.oddjobairways.com/market-research/">https://www.oddjobairways.com/market-research/</a></div>
</div>
<div class="page"><p/>
<p>122 Chapter 5 &middot; Descriptive Statistics
</p>
<p>. Table 5.5 Variable description and label names of the Oddjob Dataset
</p>
<p>Variables Variable description Variable name 
in the dataset
</p>
<p>Demographic measures
</p>
<p>Age of the 
customer
</p>
<p>Numerical variable ranging between the ages of 19 and 
</p>
<p>101.
</p>
<p>age
</p>
<p>Customer&rsquo;s gender Dichotomous variable, where 1&nbsp;=&nbsp;female; 2&nbsp;=&nbsp;male. gender
</p>
<p>Language of 
customer
</p>
<p>Categorical variable, where 1&nbsp;=&nbsp;Germany; 2&nbsp;=&nbsp;English; 
</p>
<p>3&nbsp;=&nbsp;French.
</p>
<p>language
</p>
<p>Home country Categorical variable, whereby: 1&nbsp;=&nbsp;Germany (de), 
2&nbsp;=&nbsp;Switzerland (ch); 3&nbsp;=&nbsp;Austria (at); 4&nbsp;=&nbsp;France (fr), 
</p>
<p>5&nbsp;=&nbsp;the United States (us).
</p>
<p>country
</p>
<p>Flight behavior measures
</p>
<p>Flight class Categorical variable distinguishing between 
the following categories: 1&nbsp;=&nbsp;First; 2&nbsp;=&nbsp;Business; 
</p>
<p>3&nbsp;=&nbsp;Economy.
</p>
<p>flight_class
</p>
<p>Latest flight Categorical variable querying when the customer last 
flew with Oddjob Airways. Categories are: 1&nbsp;=&nbsp;Within the 
</p>
<p>last 2&nbsp;days; 2&nbsp;=&nbsp;Within the last week; 3&nbsp;=&nbsp;Within the last 
</p>
<p>month; 4&nbsp;=&nbsp;Within the last 3&nbsp;months; 5&nbsp;=&nbsp;Within the last 
</p>
<p>6&nbsp;months; 6&nbsp;=&nbsp;Within the last 12&nbsp;months.
</p>
<p>flight_latest
</p>
<p>Flight purpose Dichotomous variable distinguishing between: 
1&nbsp;=&nbsp;Business; 2&nbsp;=&nbsp;Leisure.
</p>
<p>flight_purpose
</p>
<p>Flight type Dummy variable, where: 1&nbsp;=&nbsp;Domestic; 2&nbsp;=&nbsp;International. flight_type
</p>
<p>Number of flights Numeric variable ranging between 1 and 457&nbsp;flights per 
year.
</p>
<p>nflights
</p>
<p>Traveler&rsquo;s status Categorical variable, where membership status is 
defined in terms of: 1&nbsp;=&nbsp;Blue; 2&nbsp;=&nbsp;Silver; 3&nbsp;=&nbsp;Gold.
</p>
<p>status
</p>
<p>Perception and satisfaction measures
</p>
<p>Recommendation Item on whether a customer is likely to recommend the 
airline to a friend or colleague. This item is measured on 
</p>
<p>an 11-point Likert-scale ranging from 1&nbsp;very unlikely to 
</p>
<p>11&nbsp;very likely.
</p>
<p>nps
</p>
<p>Reputation One item stating &ldquo;Oddjob Airways is a reputable airline.&rdquo; 
This item is measured on a 7-point Likert-scale ranging 
</p>
<p>from 1 fully disagree to 7 fully agree.
</p>
<p>reputation
</p>
<p>General 
satisfaction
</p>
<p>3 items reflecting a customer&rsquo;s overall satisfaction with 
</p>
<p>the airline. All items are measured on a 7-point Likert 
</p>
<p>scale ranging from 1 fully disagree to 7 fully agree .
</p>
<p>sat1 to sat3
</p>
<p>Overall price/
performance 
satisfaction
</p>
<p>One item stating &ldquo;Overall I am satisfied with the price 
</p>
<p>performance ratio of Oddjob Airways.&rdquo; This item is 
</p>
<p>measured on a 7-point Likert-scale ranging from 1 fully 
</p>
<p>disagree to 7 fully agree.
</p>
<p>overall_sat
</p>
<p>5</p>
<p/>
</div>
<div class="page"><p/>
<p>5123
5.8 &middot; The Oddjob Airways Case Study
</p>
<p>Variables Variable description Variable name 
in the dataset
</p>
<p>Loyalty 5 items reflecting a customer&rsquo;s loyalty to the airline. All 
items are measured on a 7-point Likert-scale ranging 
</p>
<p>from 1 fully disagree to 7 fully agree.
</p>
<p>loy1 to loy5
</p>
<p>Commitment 3 items reflecting a customer&rsquo;s commitment to fly with 
the airline. All items are measured on a 7-point Likert-
</p>
<p>scale ranging from 1 fully disagree to 7 fully agree. The 
</p>
<p>dataset also contains the variable commitment, which is 
</p>
<p>the mean of com1 to com3.
</p>
<p>com1 to com3
</p>
<p>and
</p>
<p>commitment
</p>
<p>Traveler&rsquo;s 
expectations
</p>
<p>23 items reflecting a customer&rsquo;s expectations with the 
</p>
<p>airline: &ldquo;How high are your expectations that &hellip; &rdquo; All 
</p>
<p>items are measured on a continuous scale ranging from 
</p>
<p>1&nbsp;very low to 100&nbsp;very high.
</p>
<p>e1 to e23
</p>
<p>Traveler&rsquo;s 
satisfaction
</p>
<p>23 items reflecting a customer&rsquo;s satisfaction with 
</p>
<p>Oddjob Airways regarding the features asked in the 
</p>
<p>expectation items (e1-e23) on a continuous scale 
</p>
<p>ranging from 1&nbsp;=&nbsp;very unsatisfied to 100&nbsp;=&nbsp;very satisfied.
</p>
<p>s1 to s23
</p>
<p>The survey resulted in a rich dataset with information about travelers&rsquo; demographic char-
acteristics, flight behavior, as well as their price/product satisfaction with and expectations 
in respect of Oddjob Airways. . Table 5.5 describes the variables in detail.
</p>
<p>5.8.1 Introduction to SPSS
</p>
<p>SPSS is a computer package specializing in quantitative data analysis. It is widely used 
by market researchers. It is powerful, able to deal with large datasets, and relatively easy 
to use.
</p>
<p>In this book, we use version 25 of IBM SPSS Statistics for Mac (which we simply refer 
to as SPSS). Prior versions (21 or higher) for Microsoft Windows, Mac, or Linux can also 
be used for almost all examples throughout the book. The differences between the versions 
are small enough so that all examples in the book work with all versions.
</p>
<p>The regular SPSS package is available at a substantial fee for commercial use. However, 
large discounts are available for educational use. To obtain these discounts, it is best to 
go to your university&rsquo;s IT department and enquire if you can purchase a special student 
license. You can also download a trial version from www.spss.com.
</p>
<p>&gt; In the next sections, we will use the ► sign to indicate that you should click on 
something. Options, menu items or drop-down lists that you should look up in 
</p>
<p>dialog boxes are printed in bold. Variable names, data files or data formats are 
</p>
<p>printed in italics to differentiate them from the rest of the text.
</p>
<p>. Table 5.5 (Continued)</p>
<p/>
<div class="annotation"><a href="http://www.spss.com">http://www.spss.com</a></div>
</div>
<div class="page"><p/>
<p>124 Chapter 5 &middot; Descriptive Statistics
</p>
<p>. Fig.&nbsp;5.7 The start-up screen of SPSS
</p>
<p>SPSS uses multiple file formats. The .sav and .zsav file format contains data only. SPSS 
</p>
<p>also allows you to open other file formats such as Excel (.xls and .xlsx), Stata files (.dta), 
</p>
<p>and text files (such as .txt and .dat). Once these files are open, they can be conveniently 
</p>
<p>saved into SPSS&rsquo;s own .sav file format. If you are on SPSS&rsquo;s main screen (see . Fig.&nbsp;5.8) 
simply go to File ► Open ► Data ►&nbsp;Files of type (select the file format) and double 
</p>
<p>click on the file you wish to open.
</p>
<p>Tip
</p>
<p>5.8.2 Finding Your Way in SPSS
</p>
<p>If you start up SPSS for the first time, it presents a screen similar to . Fig.&nbsp;5.7, unless a pre-
vious user has ticked the Don&rsquo;t show this dialog in the future box. In that case, you will see 
a screen similar to . Fig.&nbsp;5.8, but without an active dataset.
</p>
<p>In the startup screen, SPSS indicates several options to create or open datasets. The 
options that you should use are either Recent Files, under which you can find a list with 
recently opened data files, or New Files. To open an unlisted file, simply choose Open 
another file&hellip; and click OK (alternatively, you can click Close, and then go to ► File  
► Open ► Data). Then search for the directory in which you keep your files, click on 
Oddjob.sav, followed by Open.
</p>
<p>SPSS uses two windows. The SPSS Statistics Data Editor contains the data and information 
on the variables in the dataset and the SPSS Statistics Viewer, which contains the output 
produced by the analyses. In the following, we will discuss these two windows separately.
</p>
<p>5</p>
<p/>
</div>
<div class="page"><p/>
<p>5125
5.8 &middot; The Oddjob Airways Case Study
</p>
<p>. Fig.&nbsp;5.8 The SPSS data editor
</p>
<p>The notation you will see in this book follows the US style. That is, commas are used to 
</p>
<p>separate ten thousands (e.g., 10,000) while decimal points are used to separate whole 
</p>
<p>values from fractions. If you want to change the notation to US style, go to SPSS, then 
</p>
<p>► File ► New ► Syntax and type in SET LOCALE&nbsp;=&nbsp;&lsquo;English&rsquo;. You also need to type in 
</p>
<p>the last point. Now press enter and type in EXECUTE. (again, including the point) in the 
</p>
<p>next line. Now run the syntax by choosing Run ► All in the syntax window. SPSS will 
</p>
<p>then permanently apply the US style notation the next time you use SPSS.
</p>
<p>Tip
</p>
<p>5.8.3 SPSS Statistics Data Editor
</p>
<p>In the SPSS Statistics Data Editor (. Fig.&nbsp;5.8), you will find the dataset Oddjob. sav. This 
dataset&rsquo;s variables are included in the columns and their names are indicated at the top of 
each column. The cases are in the rows, which are numbered from 1 onwards.
</p>
<p>If you click on the Variable View tab at the bottom of the screen, SPSS will show you a 
screen similar to . Fig.&nbsp;5.9. In the Variable View, SPSS provides information on the vari-
ables included in your dataset:
 4 Name: Here you can indicate the name of the variable. It is best to provide very short 
</p>
<p>names. Variable names must begin with letters (A to Z) or one of the following 
special characters (@, # or $). Subsequent characters can include letters (A to Z), 
numbers (0&ndash;9), a dot (.), and _, @, #, or $. Note that neither spaces nor other special 
characters (e.g., %, &amp;,/) are allowed.</p>
<p/>
</div>
<div class="page"><p/>
<p>126 Chapter 5 &middot; Descriptive Statistics
</p>
<p> 4 Type: Here you can specify what your variable represents. Numeric refers to values 
and String refers to words. String is useful if you want to include open- ended 
answers, email addresses or any other type of information that cannot be adequately 
captured by numbers. With Dollar or Custom Currency, you can indicate that your 
variable represents money.
 4 Width and Decimals: These elements indicate the amount of space available for your 
</p>
<p>variables values.
 4 Labels: Here you can provide a longer description of your variables (called variable 
</p>
<p>labels). This can either be the definition of the variables or the original survey 
question.
 4 Values: Here you can indicate what a certain value represents (called value labels). 
</p>
<p>For example, for the nominal variable gender, 1 represents females and 2&nbsp;males.
 4 Missing: Here you can indicate one or more missing value(s). Generally, SPSS deals 
</p>
<p>with missing values in two ways. If you have blanks in your variables (i.e., you 
haven&rsquo;t entered any data for a specific observation), SPSS treats these as system-
missing values. These are indicated in SPSS as a dot (&bull;). Alternatively, you can specify 
user-defined missing values that are meant to signify a missing observation. By 
explicitly defining missing values, we can indicate why specific scores are missing 
(e.g., the question didn&rsquo;t apply to the respondent or the respondent refused to 
answer). In SPSS, you should preferably specify user-defined missing values as 
this at least allows the true missing values to be separated from data that were not 
recorded (i.e., no value was entered). Under Missing, we can select among three 
</p>
<p>. Fig.&nbsp;5.9 Variable view
</p>
<p>5</p>
<p/>
</div>
<div class="page"><p/>
<p>5127
5.8 &middot; The Oddjob Airways Case Study
</p>
<p>options to indicate user-defined missing values. The first option, No missing values, 
is the default setting and indicates that no values are user-defined missing. The other 
two options, Discrete missing values and Range plus one optional discrete missing 
value, provide a means to express user-defined missing values. To do so, simply 
enter values that record that an observation is missing. Each separate value should 
indicate separate reasons for missing values. For example &minus;99&nbsp;may record that a 
respondent could not answer, and &minus;98 that the respondent was unwilling to answer, 
and &minus;97&nbsp;might record &ldquo;other&rdquo; reasons. Thus, missing values can provide us with 
valuable information. More importantly, observations with user-defined missing 
values (just like with system-missing values) are excluded from data transformations 
and analyses. This is of course essential as, for example, including a user-missing 
value of &minus;99 in descriptive analyses would greatly distort the results.
</p>
<p>When picking user-defined missing values, take those that would not otherwise occur 
</p>
<p>in the data. For example, for a variable age, 1000&nbsp;might be an acceptable value, as that 
</p>
<p>response cannot occur. However, the same missing value for a variable income might 
</p>
<p>lead to problems, as a respondent might have an income of 1000. If 1000 is indicated 
</p>
<p>as a (user-defined) missing value, this observation would be excluded from further 
</p>
<p>analysis. By convention, researchers usually choose (high) negative values to designate 
</p>
<p>missing such as &minus;99 or &minus;999.
</p>
<p>Tip
</p>
<p> 4 Columns and Align: These are rarely necessary, so we will skip these.
 4 Measure: Here you can specify the measurement level of your variable. SPSS 
</p>
<p>provides you with the option to indicate whether your variable is nominal, ordinal, 
or whether it is interval or ratio-scaled. The combination of the last two categories 
is called Scale in SPSS. Note that several procedures such as creating graphs require 
that all measurement levels are specified correctly.
 4 The last Role option is not necessary for basic analysis.
</p>
<p>5.8.4 SPSS Statistics Viewer
</p>
<p>The SPSS Statistics Viewer is a separate window, which opens after you carry out an action 
in SPSS. The viewer contains the output that you may have produced. If you are used to 
working with software such as Microsoft Excel, where the data and output are included in 
a single screen, this may be a little confusing at first. Another aspect of the viewer screen 
is that it does not change your output once made. Unlike, for example, Microsoft Excel, 
changing the data after an analysis does not dynamically update the results.
</p>
<p>The output produced in SPSS can be saved using the .spv file format that is particu-
lar to SPSS. To partially remedy this, SPSS provides the option to export the output to 
Microsoft Word, Excel, or PowerPoint, PDF, HTML, or text. It is also possible to export 
output as a picture. You can find these export options in the Statistics Viewer under File 
► Export.</p>
<p/>
</div>
<div class="page"><p/>
<p>128 Chapter 5 &middot; Descriptive Statistics
</p>
<p>5.8.5 SPSS Menu Functions
</p>
<p>In SPSS, you find a number of commands in the menu bar. These include File, ► Edit, 
►&nbsp;View, ► Data, ► Transform, ► Analyze, and ► Graphs. In this section, we will briefly 
discuss these commands. The commands ► Analyze and ► Graphs will be discussed  
in greater detail in the example, later in this chapter. The last four commands are  
► Utilities, ► Add-ons, ► Windows, and ► Help. You are unlikely to need the first 
three functions but the help function may come in handy if you need further guidance. 
Under help, you also find a set of tutorials that can show you how to use most of the com-
mands included in SPSS.
</p>
<p>In addition to the menu functionalities, we can run SPSS by using its command language, called 
</p>
<p>SPSS syntax. You can think of it as a programming language that SPSS uses to translate those ele-
ments on which you have clicked in the menus into commands that SPSS can understand. Syntax 
</p>
<p>can be saved (as a .sps file) for later use. This is particularly useful if you conduct the same analyses 
</p>
<p>over different datasets. Think, for example, of standardized marketing reports on daily, weekly, or 
</p>
<p>monthly sales. Discussing the syntax in great detail is beyond the scope of this book but we offer a 
</p>
<p>brief introduction in the Web appendix (⤓ Web Appendix &rarr; Downloads). Grotenhuis and Visscher 
(2014) provide a thorough introduction into this subject.
</p>
<p>&copy; zokara/Getty Images/iStock
</p>
<p>https://www.guide-market-research.com/app/download/13488667727/
</p>
<p>SPSS+3rd_Chapter+5_SPSS+Syntax.pdf?t=1516713038
</p>
<p>Under ► File, you find all the commands that deal with the opening and closing of files. 
Under this command, you will find subcommands that you can use to open different types 
of files, save files, and create files. If you open a dataset, you will notice that SPSS also opens 
a new screen. Note that SPSS can open several datasets simultaneously. You can easily 
switch from dataset to dataset by just clicking on the one which you would like to activate.
</p>
<p>5</p>
<p/>
<div class="annotation"><a href="https://www.guide-market-research.com/app/download/13488667727/SPSS+3rd_Chapter+5_SPSS+Syntax.pdf?t=1516713038">https://www.guide-market-research.com/app/download/13488667727/SPSS+3rd_Chapter+5_SPSS+Syntax.pdf?t=1516713038</a></div>
<div class="annotation"><a href="https://www.guide-market-research.com/app/download/13488667727/SPSS+3rd_Chapter+5_SPSS+Syntax.pdf?t=1516713038">https://www.guide-market-research.com/app/download/13488667727/SPSS+3rd_Chapter+5_SPSS+Syntax.pdf?t=1516713038</a></div>
</div>
<div class="page"><p/>
<p>5129
5.8 &middot; The Oddjob Airways Case Study
</p>
<p>Under ► Edit, you will find subcommands to copy and paste data. Moreover, you 
will find two options to insert cases or variables. If you have constructed a dataset but 
need to enter additional data, you can use this to add an additional variable and sub-
sequently add data. Edit also contains the Find subcommand with which you can look 
for specific cases or observations. Finally, under ► Edit ► Options, you find a large 
number of options, including how SPSS formats tables, and where the default file direc-
tories are located.
</p>
<p>Under ► View, you find several options, of which the Value Labels option is the most 
useful. Value labels are words or short sentences used to indicate what each value rep-
resents. For example, value lablels for status include blue, silver, and gold. SPSS shows 
value labels in the SPSS Data Editor window if you click on ► View, and then on Value 
Labels.
</p>
<p>Under the ► Data command, you will find many subcommands to change or restruc-
ture your dataset. The most prominent option is the ► Sort Cases subcommand with 
which you can sort your data based on the values of a variable. You could, for example, 
sort the data based on the respondents&rsquo; age. The ► Split File subcommand is useful if 
we want to compare output across different groups such as flight class, purpose, or type. 
In addition, we can carry out separate analyses over different groups using the Split File 
command. Another very useful command is ► Data ► Select Cases, which allows you to 
restruct the observations that you want to analyze. Under ► Transform, we find several 
options to create new variables from existing variables. For example, the first subcom-
mand is Compute Variable. This command allows you to create a new variable from one 
(or more) existing variables. Also included under the ► Transform command are two 
subcommands to recode variables (i.e., ► Recode into Same Variables and ► Recode into 
Different Variables). These commands allow you to recode variable values or to summa-
rize sets of values into one value. For example, using the Recode into Different Variables 
command, you could generate a new variable that takes the value 1 if age is higher than 
40, and 0 else.
</p>
<p>Under ► Analyze, you find numerous analysis procedures, several of which we will 
discuss in the remainder of the book. For example, under Descriptive Statistics, you can 
request univariate and bivariate statistics. Under Regression, SPSS provides numerous 
types of regression techniques.
</p>
<p>Finally, under ► Graphs, you can chose among different options to create graphics. For 
example, the Chart Builder is an interactive tool that allows you to design basic and more 
complex charts. Note that in order to use the Chart Builder, all variables&rsquo; measurement levels 
must be correctly specified. The same holds for the Graphboard Template Chooser, which 
lets you select the variables to be visualized and suggests different charts that conform to 
the measurement levels of the variable(s). Finally, the Legacy Dialogs command allows for 
a menu-driven selection of different chart types.
</p>
<p>Some of the previous commands are also accessible as shortcut symbols in Data View 
screen&rsquo;s menu bar. As these are very convenient, we present the most frequently used 
shortcuts in . Table 5.6.</p>
<p/>
</div>
<div class="page"><p/>
<p>130 Chapter 5 &middot; Descriptive Statistics
</p>
<p>5.9 Data Management in SPSS
</p>
<p>In this section, we will illustrate the use of some of the most commonly used commands 
for managing data in SPSS using the Oddjob.sav dataset. These include the following:
 4 Split file,
 4 select cases,
 4 compute variables, and
 4 recode into same/different variables.
</p>
<p>5.9.1 Split File
</p>
<p>The split file command allows you to split the dataset on the basis of grouping variables. If 
the split file function is activated, all subsequent analyses will be done separately for each 
group of data, as defined by the grouping variable.
</p>
<p>. Table 5.6 Toolbar icons
</p>
<p>Symbol Action
</p>
<p>Open dataset
</p>
<p>Save the active dataset
</p>
<p>Recall recently used dialogs
</p>
<p>Undo a user action
</p>
<p>Find
</p>
<p>Split file
</p>
<p>Select cases
</p>
<p>Show value labels
</p>
<p>5</p>
<p/>
</div>
<div class="page"><p/>
<p>5131
5.9 &middot; Data Management in SPSS
</p>
<p>By clicking on ► Data ► Split File, a dialog box similar to . Fig.&nbsp;5.11 will open. All you 
need to do is to enter the variable that indicates the grouping (select Compare groups) 
and move the grouping variable (e.g., status) into the Groups Based on box. Note that we 
chose to display the variable names in the variables box at the left side of the dialog box. 
By right-clicking on a variable name you can switch between Display Variable Names and 
Display Variable Labels. Once you have specified the grouping variable and clicked on OK, 
SPSS will automatically carry out all subsequent analyses of each status group (i.e., blue, 
silver, and gold) separately. If you want to revert to analyzing the whole dataset, you need 
to go to ► Data ► Split File, then click on Analyze all cases, do not create groups.
</p>
<p>A very useful option, which we have adopted in this book throughout, is to show 
</p>
<p>the variable names (instead of the variable labels). The variable names are typically 
</p>
<p>short and the variable labels long. To make it easier to see the variables used, go to 
</p>
<p>SPSS Statistics ► Preferences ► General (for Apple) or Edit ► Options ► General 
</p>
<p>(for PC) and tick Display names. We show this in . Fig.&nbsp;5.10. Under SPSS Statistics 
►&nbsp;Preferences ► Language (Apple) or Edit ► Options ► Language (PC) you can 
</p>
<p>change the output and user interface languages.
</p>
<p>Tip
</p>
<p>. Fig.&nbsp;5.10 How to display names</p>
<p/>
</div>
<div class="page"><p/>
<p>132 Chapter 5 &middot; Descriptive Statistics
</p>
<p>! It&rsquo;s a common mistake to forget to turn off the split file command. Failing to do 
so results in all subsequent analyses being carried out for each group separately!
</p>
<p>5.9.2 Select Cases
</p>
<p>The select cases command allows us to restrict certain observations from the analyses 
through a pre-set condition (e.g., display the summary statistics only for those older than 
40). To run the command, go to ► Data ► Select Cases and click on If condition is satisfied, 
followed by If. SPSS shows a screen similar to . Fig.&nbsp;5.12 in which you can set the condi-
tions for restricting observations. For example, to select respondents who are older than 
40, enter age&gt;40 in the corresponding box. Next, click on Continue and OK.
</p>
<p>SPSS will only use the selected observations in subsequent analyses, and will omit 
the others (these are crossed out in the Data View screen). Remember to turn the selec-
tion off if you do not need it by going back to ► Data ► Select Cases and then click on 
All&nbsp;cases. Since we use the full dataset, please turn this selection off so that you can follow 
the remainder of the example.
</p>
<p>5.9.3 Compute Variables
</p>
<p>The compute variable command allows you to create a new variable from one (or more) 
existing variables. For example, if you want to create a composite score of some type (see 
7 Chap.&nbsp;3), you need to calculate the average of several variables. In the following, we will 
use the command to compute a new index variable from the mean of the following three 
</p>
<p>. Fig.&nbsp;5.11 Split file dialog box
</p>
<p>5</p>
<p/>
</div>
<div class="page"><p/>
<p>5133
5.9 &middot; Data Management in SPSS
</p>
<p>items related to travelers&rsquo; satisfaction: sat1, sat2, and sat3. Go to ► Transform ► Compute 
Variable, which will open a dialog box similar to . Fig.&nbsp;5.13.
</p>
<p>Next, enter the name of the new variable (e.g., rating_index) in the Target Variable box 
on the upper left part of the screen and select Statistical from the Function group menu, 
followed by Mean from the Functions and Special Variables menu. SPSS will now show the 
corresponding function in the Numeric Expression box as MEAN(?,?). Enter sat1, sat2, sat3 
in the round brackets as in . Fig.&nbsp;5.13 and click on OK. You have now created a new vari-
able called rating_index that appears at the bottom of the Variable View.
</p>
<p>5.9.4 Recode Variables
</p>
<p>Changing or transforming the values of an existing variable according to a number of rules 
is a key data management activity. Numeric variables can be changed using the recode 
command, which comes in two forms. You can either overwrite an existing variable or 
generate a new variable, which includes the new variable coding. We recommend using 
the recode into different variables option. If you were to use recode into the same vari-
ables, any changes you make to the variable will result in the deletion of the original vari-
able. Thus, if you ever want to go back to the original data, you either need to have saved 
a previous version, or have to enter all the data again as SPSS cannot undo these actions! 
The recode subcommands allow you to change the scaling of a variable. This is useful if 
you want to create dummies or create categories of existing variables.
</p>
<p>. Fig.&nbsp;5.12 Select cases dialog box</p>
<p/>
</div>
<div class="page"><p/>
<p>134 Chapter 5 &middot; Descriptive Statistics
</p>
<p>In the following, we want to use the recode option to generate a new variable age_
dummy, which should be 1 if a respondent is 40 or younger, and 0 else. To do so, go to 
►&nbsp;Transform ► Recode into Different Variables, which will open a dialog box similar to 
. Fig.&nbsp;5.14.
</p>
<p>First, move age into the Numeric Variable &rarr; Output Variable box. Next, specify the 
name of the variable that you want to recode (i.e., age_dummy) under Output Variable 
and add a label such as Dummy variable age. After clicking on Change, SPSS will draw 
an arrow between the original and new variables (. Fig.&nbsp;5.14). The next step is to tell 
SPSS what values need to be recoded. After clicking on Old and New Values, SPSS will 
open a dialog box similar to . Fig.&nbsp;5.15. On the left of this dialog box, you should indi-
cate the values of the original variable that you want to recode. In our example, we used 
the option Range, LOWEST through value to specify that we want to recode all values of 
40 or less. Select this option and enter 40 into the box below. Next, go to the right side of 
the menu and enter 1 under New Value and click on Add. To indicate that age_dummy 
should take the value 0 if age is greater than 40, select All other values and enter 0 under 
New Value, followed by Add. Finally, confirm your changes by clicking on Continue and 
OK. You have now created a new dichotomous variable (i.e., age_dummy) located at the 
bottom of the Variable View.
</p>
<p>. Fig.&nbsp;5.13 Compute variables dialog box
</p>
<p>5</p>
<p/>
</div>
<div class="page"><p/>
<p>5135
5.10 &middot; Example
</p>
<p>5.10 Example
</p>
<p>We will now examine the dataset Oddjob.sav in closer detail by following all the steps in 
. Fig.&nbsp;5.1. Cleaning the data generally requires checking for interviewer fraud, suspicious 
response patterns, data entry errors, outliers, and missing data. Several of these steps rely 
on statistics and graphs, which we discussed in the context of descriptive statistics (e.g.,&nbsp;box 
plots and scatter plots). We illustrate the use of Little&rsquo;s MCAR test and multiple imputation 
of Oddjob.sav in the Web Appendix (&rarr; Downloads).
</p>
<p>. Fig.&nbsp;5.15 Recode options dialog box
</p>
<p>. Fig.&nbsp;5.14 Recode into different variables dialog box</p>
<p/>
</div>
<div class="page"><p/>
<p>136 Chapter 5 &middot; Descriptive Statistics
</p>
<p>5.10.1 Clean Data
</p>
<p>Since the data were cleaned earlier, we need not check for interviewer fraud or suspicious 
response patterns. Beside double data entries to detect and minimize errors in the process 
of data entry, exploratory data analysis is required to spot data entry errors that have been 
overlooked.
</p>
<p>A first step in this procedure is to look at the minimum and maximum values of the 
relevant variables to detect values that are not plausible (i.e., fall outside the expected range 
of scale categories). To do so, go to ► Analyze ► Descriptive Statistics ► Descriptives, 
which will open a dialog box similar to . Fig.&nbsp;5.16. We will focus our analyses on the first 
ten variables (i.e., country, language, status, age, gender, nflights, flight_latest, flight_type, 
flight_purpose, and flight_class). Enter these variables into the Variable(s) box and click on 
OK. . Table 5.7 shows the resulting output.
</p>
<p>. Table 5.7 lists the minimum, maximum, mean, and standard deviation values of all 
the variables. Under N, we can see that all the listed variables are observed across all 1065 
respondents, meaning that none of the selected variables suffer from missing observa-
tions. Among others, it appears that the age of the travelers varies between 19 and 101, 
while the number of flights (variable nflights) varies between 1 and 457&nbsp;flights over the past 
12&nbsp;months. Particularly the maximum value in number of flights appears to be implausi-
ble. While this observation could represent a flight attendant, it appears more reasonable 
to consider this observation an outlier and eliminate it from further analyses that draw 
on the nflights variable.
</p>
<p>. Fig.&nbsp;5.16 Descriptives dialog box
</p>
<p>5</p>
<p/>
</div>
<div class="page"><p/>
<p>5137
5.10 &middot; Example
</p>
<p>. Table 5.7 Descriptives statistics
</p>
<p>Descriptive Statistics
</p>
<p>N Minimum Maximum Mean Std. Deviation
</p>
<p>country 1065 1 5 2.00 1.552
</p>
<p>language 1065 1 3 1.24 .447
</p>
<p>status 1065 1 3 1.50 .720
</p>
<p>age 1065 19 101 50.42 12.275
</p>
<p>gender 1065 1 2 1.74 .440
</p>
<p>nflights 1065 1 457 13.42 20.226
</p>
<p>flight_latest 1065 1 6 3.79 1.369
</p>
<p>flight_type 1065 1 2 1.48 .500
</p>
<p>flight_purpose 1065 1 2 1.51 .500
</p>
<p>flight_class 1065 1 3 2.80 .435
</p>
<p>Valid N (listwise) 1065
</p>
<p>5.10.2 Describe Data
</p>
<p>In the next step, we describe the data in more detail, focusing on those statistics and graphs 
that were not part of the previous step. To do so, we make use of graphs, tables, and descrip-
tive statistics. In . Fig.&nbsp;5.17, we show how you can request each of the previously discussed 
graphs and tables using the ► Graphs ► Legacy Dialogs menu. The figure also shows, 
which menu options to use to request univariate and bivariate statistics. We will not use 
the Legacy Dialogs option as the SPSS Chart Builder and Graphboard Template Chooser offer 
users more options when selecting a graph.
</p>
<p>5.10.2.1 Univariate Graphs and Tables
</p>
<p>z Bar Charts
To produce a bar chart that plots the age of respondents against their country of residence, 
go to ► Graphs ► Chart Builder. In the dialog box that opens (. Fig.&nbsp;5.18), select Bar under 
Choose from and drag the first element into the chart builder box. Next, drag and drop age 
from the Variables menu to the y-axis and country to the x-axis. Clicking on OK, SPSS will 
produce a chart similar to . Fig.&nbsp;5.19.
</p>
<p>z Histograms
Histograms are useful for summarizing numerical variables. We will use the Graphboard 
Template Chooser to generate a histogram of the age variable. By going to ► Graphs 
► Graphboard Template Chooser, SPSS will open a dialog box as shown in . Fig.&nbsp;5.20.  </p>
<p/>
</div>
<div class="page"><p/>
<p>138 Chapter 5 &middot; Descriptive Statistics
</p>
<p>. Fig.&nbsp;5.18 Chart builder (bar charts)
</p>
<p>Univariate Bivariate 
</p>
<p>Graphs &amp; tables Statistics 
</p>
<p>Measures of centrality: 
</p>
<p> Mode 
</p>
<p> Median 
</p>
<p> Mean 
</p>
<p> Analyze 
</p>
<p>Frequencies under 
Statistics, select Mode,  
Median, and Mean  
</p>
<p>Scatter plots 
</p>
<p>Graphs  Legacy 
Dialogs  Scatter/Dot 
</p>
<p>Measures of dispersion 
</p>
<p> Range 
</p>
<p> Variance 
</p>
<p> Standard deviation 
</p>
<p>Analyze  Descriptive
Statistics  Frequencies 
under Statistics, select
Range, Variance, and
Std. deviation
</p>
<p> Interquartile range 
</p>
<p>Analyze  Descriptive 
Statistics  Explore
</p>
<p>Correlation 
</p>
<p> Analyze  Correlate 
 Bivariate 
</p>
<p>Statistics Graphs &amp; tables 
</p>
<p>Bar chart 
</p>
<p>Graphs  Legacy 
Dialogs  Bar 
</p>
<p>Histogram 
</p>
<p>Graphs  Legacy 
Dialogs   Histogram 
</p>
<p>Box plot 
</p>
<p>Graphs  Legacy 
Dialogs  Pie 
</p>
<p>Pie chart 
</p>
<p>Graphs  Legacy 
Dialogs Pie 
</p>
<p>Crosstabs 
</p>
<p> Analyze  Descriptive 
Statistics  Crosstabs 
</p>
<p>Covariance 
</p>
<p> Analyze  Correlate 
 Bivariate 
</p>
<p>Under Options, select
Cross-product deviations 
and covariances 
</p>
<p>Frequency table 
</p>
<p>Analyze  Descriptive
Statistics  Frequencies 
</p>
<p>. Fig.&nbsp;5.17 How to request graphs, tables, and statistics in SPSS
</p>
<p>5</p>
<p/>
</div>
<div class="page"><p/>
<p>5139
5.10 &middot; Example
</p>
<p>Simple Bar Mean of Age by Home country
</p>
<p>Home country
</p>
<p>60.00
</p>
<p>M
e
</p>
<p>a
n
</p>
<p> A
g
</p>
<p>e
</p>
<p>50.00
</p>
<p>40.00
</p>
<p>30.00
</p>
<p>20.00
</p>
<p>10.00
</p>
<p>0.00
DE CH AT FR US
</p>
<p>. Fig.&nbsp;5.19 A bar chart
</p>
<p>. Fig.&nbsp;5.20 Graphboard template chooser (histogram)</p>
<p/>
</div>
<div class="page"><p/>
<p>140 Chapter 5 &middot; Descriptive Statistics
</p>
<p>When selecting the relevant variable age on the left side of the dialog box, SPSS will show 
different graph options to choose from. Select Histogram with Normal Distribution and 
click on OK. SPSS will produce a histogram as shown in . Fig.&nbsp;5.21.
</p>
<p>z Box Plot
To ask for a box plot, go to ► Graphs ► Chart Builder and select Boxplot from the Choose 
from list. SPSS allows you to choose among three boxplot types; select the one to the very 
right (1-D Boxplot) and drag this to the chart builder. Then drop age to the y-axis. When 
clicking on OK, SPSS will produce output similar to . Fig.&nbsp;5.22.
</p>
<p>z Pie Charts
Pie charts are useful for displaying categorical or binary variables. We will create a pie chart 
for the status variable by going to ► Graphs ► Chart Builder. Select Pie/Polar from the 
Choose from list and drag this to the chart builder. Then drag and drop status to the x-axis. 
When clicking on OK, SPSS will show a pie chart. By double-clicking on the pie chart, we 
can open the Chart Editor, which allows changing the format and adding further statistics. 
For example, by selecting the target symbol and clicking on a slice of the chart, SPSS will 
display the relative frequencies (. Fig.&nbsp;5.23).
</p>
<p>Age
</p>
<p>0 20 40 60 80 100 120
</p>
<p>60
</p>
<p>40
</p>
<p>20
</p>
<p>80
</p>
<p>0
</p>
<p>. Fig.&nbsp;5.21 A histogram
</p>
<p>5</p>
<p/>
</div>
<div class="page"><p/>
<p>5141
5.10 &middot; Example
</p>
<p>659
</p>
<p>120
</p>
<p>993
</p>
<p>909
</p>
<p>100
</p>
<p>80
</p>
<p>60
</p>
<p>A
g
e
</p>
<p>40
</p>
<p>20
</p>
<p>0
</p>
<p>. Fig.&nbsp;5.22 A box plot
</p>
<p>. Fig.&nbsp;5.23 Pie chart in the chart editor</p>
<p/>
</div>
<div class="page"><p/>
<p>142 Chapter 5 &middot; Descriptive Statistics
</p>
<p>z Frequency Tables
We can produce a frequency table by clicking on ► Analyze ► Descriptive Statistics 
►&nbsp; Frequencies. Move the variable country into the Variable(s) box and then click on OK. 
This operation will produce . Table 5.8, which displays the value of each country with 
the corresponding absolute number of observations (i.e., Frequency), the relative values, 
including and excluding missing values (i.e., Percent and Valid Percent), as well as the 
cumulative relative values (i.e., Cumulative Percent). It shows that 65.3&nbsp;% of our sample 
consists of travelers who reside in Germany, followed by travelers from the United States 
(18.3&nbsp;%), Austria (10.1&nbsp;%), Switzerland (6.2&nbsp;%), and, finally, France (0.1&nbsp;%).
</p>
<p>5.10.2.2 Univariate Statistics
</p>
<p>Another useful way of examining your data is through the Explore option, which you can 
find under ► Analyze ► Descriptive Statistics ► Explore. Selecting this menu option 
opens a dialog box similar to that in . Fig.&nbsp;5.24. We will use this option to request a series 
of statistics for age, differentiated by gender. To do so, move age into the Dependent List box 
and gender into the Factor List box, which indicates the grouping variable. Under Display, 
select Statistics and click on OK.
</p>
<p>SPSS will produce an output similar to . Table 5.9, which includes a variety of mea-
sures of centrality and dispersion, such as the 95&nbsp;% confidence interval, the 5&nbsp;% trimmed 
mean, the variance, or the interquartile range.
</p>
<p>5.10.2.3 Bivariate Graphs and Tables
z Scatter Plots
Scatter plots can be easily displayed in SPSS using the Chart Builder or the Graphboard Tem-
plate Chooser. For example, to generate a scatter plot, go to ► Graphs ► Chart Builder and 
select Scatter/Dot from the Choose from list and drag the upper leftmost (simple scatter) 
into the chart builder box. Next, drag and drop nps to the y-axis and age to the x-axis. 
Clicking on OK will produce a scatter plot like in . Fig.&nbsp;5.25.
</p>
<p>. Table 5.8 Example of a frequency table in SPSS
</p>
<p>country
</p>
<p>Frequency Percent Valid Percent
</p>
<p>Cumulative 
</p>
<p>Percent
</p>
<p>Valid Germany 695 65.3 65.3 65.3
</p>
<p>Switzerland 66 6.2 6.2 71.5
</p>
<p>Austria 108 10.1 10.1 81.6
</p>
<p>France 1 .1 .1 81.7
</p>
<p>USA 195 18.3 18.3 100.0
</p>
<p>Total 1065 100.0 100.0
</p>
<p>5</p>
<p/>
</div>
<div class="page"><p/>
<p>5143
5.10 &middot; Example
</p>
<p>. Fig.&nbsp;5.24 Explore dialog box
</p>
<p>. Table 5.9 Example of a summary table using the explore option
</p>
<p>Descriptives
</p>
<p>gender Statistic Std. Error
</p>
<p>age female Mean 50.81 .761
</p>
<p>95&nbsp;% Confidence 
</p>
<p>Interval for Mean
</p>
<p>Lower Bound 49.32
</p>
<p>Upper Bound 52.31
</p>
<p>5&nbsp;% Trimmed Mean 50.88
</p>
<p>Median 51.00
</p>
<p>Variance 162.188
</p>
<p>Std. Deviation 12.735
</p>
<p>Minimum 22
</p>
<p>Maximum 78
</p>
<p>Range 56
</p>
<p>Interquartile Range 18
</p>
<p>Skewness &minus;.133 .146
</p>
<p>Kurtosis &minus;.591 .290</p>
<p/>
</div>
<div class="page"><p/>
<p>144 Chapter 5 &middot; Descriptive Statistics
</p>
<p>male Mean 50.28 .432
</p>
<p>95&nbsp;% Confidence 
</p>
<p>Interval for Mean
</p>
<p>Lower Bound 49.43
</p>
<p>Upper Bound 51.13
</p>
<p>5&nbsp;% Trimmed Mean 50.19
</p>
<p>Median 50.00
</p>
<p>Variance 146.684
</p>
<p>Std. Deviation 12.111
</p>
<p>Minimum 19
</p>
<p>Maximum 101
</p>
<p>Range 82
</p>
<p>Interquartile Range 16
</p>
<p>Skewness .151 .087
</p>
<p>Kurtosis .065 .174
</p>
<p>H
o
</p>
<p>w
 li
</p>
<p>k
e
</p>
<p>ly
 is
</p>
<p> it
 t
</p>
<p>h
a
</p>
<p>t 
yo
</p>
<p>u
 w
</p>
<p>o
u
</p>
<p>ld
 r
</p>
<p>e
co
</p>
<p>m
m
</p>
<p>e
n
</p>
<p>d
</p>
<p>o
u
</p>
<p>r 
co
</p>
<p>m
p
</p>
<p>a
n
</p>
<p>y
 t
</p>
<p>o
 a
</p>
<p> f
ri
</p>
<p>e
n
</p>
<p>d
 o
</p>
<p>r 
co
</p>
<p>ll
e
</p>
<p>a
g
</p>
<p>u
e
</p>
<p>? very likely
</p>
<p>9
</p>
<p>8
</p>
<p>7
</p>
<p>6
</p>
<p>5
</p>
<p>4
</p>
<p>3
</p>
<p>2
</p>
<p>1
</p>
<p>Simple Scatter of How likely is it that you would recommend our company to a friends or colleague?
</p>
<p>by Age
</p>
<p>.00
</p>
<p>very unlikely
</p>
<p>20.00 40.00 60.00
</p>
<p>Age
</p>
<p>80.00 100.00 120.00
</p>
<p>. Fig.&nbsp;5.25 A scatter plot
</p>
<p>. Table 5.9 (Continued)
</p>
<p>5</p>
<p/>
</div>
<div class="page"><p/>
<p>5145
5.10 &middot; Example
</p>
<p>Similarly, we can request a bubble plot that considers a third variable in the scatter 
plot. Go to Graphs ► Graphboard Template Chooser and select the variables age, nps, 
and status from the variable list.
</p>
<p>. Fig.&nbsp;5.26 Graphboard template chooser (bubble plot)
</p>
<p>To select multiple variables, simply hold the STRG key (PC) or cmd (or Command) key 
</p>
<p>(Mac) and left-click on the variables you want to select..
</p>
<p>Tip
</p>
<p>SPSS shows several graph types to choose from, including a 3-D Area plot, 3-D Scatterplot, 
and a Bubble Plot (. Fig.&nbsp;5.26). Choose the latter and click on OK.
</p>
<p>! The design of the bubble plot depends on the order in which you select the 
variables. The first variable defines the x-axis, the second variable defines the 
y-axis, and the third variable defines the size of the bubbles.</p>
<p/>
</div>
<div class="page"><p/>
<p>146 Chapter 5 &middot; Descriptive Statistics
</p>
<p>This will produce the bubble plot shown in . Fig.&nbsp;5.27. The graph shows the relationship 
between the respondents&rsquo; age (x-axis) and the net promoter score (y-axis) differentiated 
by the travelers&rsquo; status (size of the dots). Note that for illustrative purposes, the plot shown 
in . Fig.&nbsp;5.27 does not show the entire data but only a subset of 25&nbsp;%, which we drew ran-
domly using the select cases command (► Data ► Select Cases).
</p>
<p>z Cross tabulation
Cross tabulation is useful for understanding the relationship between two variables scaled 
on a nominal or ordinal scale. To create a crosstab, go to ► Analyze ► Descriptive Statis-
tics ► Crosstabs. It is important that you specify which variable goes in the column and 
which in the rows. Choose country under Row(s) and gender under Column(s). Next, click 
on Cells and choose Row and Column under Percentages. Clicking on Continue and OK 
will produce a table similar to the one in . Table 5.10.
</p>
<p>5.10.2.4 Bivariate Statistics: Correlations and Covariances
</p>
<p>In SPSS, we can calculate bivariate correlations by going to ► Analyze ► Correlate ► 
Bivariate. In the dialog box that opens (. Fig.&nbsp;5.28), select the variables to be considered 
in the analysis. For example, enter s1, s2, s3, and s4 in the Variables box. When clicking on 
OK, SPSS will produce a correlation matrix like the one in . Table 5.11.
</p>
<p>Traveler
</p>
<p>Status
</p>
<p>H
o
</p>
<p>w
 li
</p>
<p>k
e
</p>
<p>ly
 is
</p>
<p> it
 t
</p>
<p>h
a
</p>
<p>t 
 y
</p>
<p>o
u
</p>
<p> w
o
</p>
<p>u
ld
</p>
<p> r
e
</p>
<p>co
m
</p>
<p>m
e
</p>
<p>n
d
</p>
<p>o
u
</p>
<p>r 
co
</p>
<p>m
p
</p>
<p>a
n
</p>
<p>y
 t
</p>
<p>o
 a
</p>
<p> f
ri
</p>
<p>e
n
</p>
<p>d
 o
</p>
<p>r 
co
</p>
<p>ll
e
</p>
<p>a
g
</p>
<p>u
e
</p>
<p>?
</p>
<p>Blue
</p>
<p>Silver
</p>
<p>Gold
</p>
<p>20
</p>
<p>10
</p>
<p>30 40 50
</p>
<p>Age
</p>
<p>60 70 80
</p>
<p>8
</p>
<p>6
</p>
<p>4
</p>
<p>2
</p>
<p>. Fig.&nbsp;5.27 Bubble plot for a subset of data
</p>
<p>5</p>
<p/>
</div>
<div class="page"><p/>
<p>5147
5.10 &middot; Example
</p>
<p>. Table 5.10 Example of a crosstab
</p>
<p>country * gender Crosstabulation
</p>
<p>gender
</p>
<p>Totalfemale male
</p>
<p>country Germany Count 180 515 695
</p>
<p>% within country 25.9&nbsp;% 74.1&nbsp;% 100.0&nbsp;%
</p>
<p>% within gender 64.3&nbsp;% 65.6&nbsp;% 65.3&nbsp;%
</p>
<p>Switzerland Count 17 49 66
</p>
<p>% within country 25.8&nbsp;% 74.2&nbsp;% 100.0&nbsp;%
</p>
<p>% within gender 6.1&nbsp;% 6.2&nbsp;% 6.2&nbsp;%
</p>
<p>Austria Count 25 83 108
</p>
<p>% within country 23.1&nbsp;% 76.9&nbsp;% 100.0&nbsp;%
</p>
<p>% within gender 8.9&nbsp;% 10.6&nbsp;% 10.1&nbsp;%
</p>
<p>France Count 1 0 1
</p>
<p>% within country 100.0&nbsp;% 0.0&nbsp;% 100.0&nbsp;%
</p>
<p>% within gender 0.4&nbsp;% 0.0&nbsp;% 0.1&nbsp;%
</p>
<p>USA Count 57 138 195
</p>
<p>% within country 29.2&nbsp;% 70.8&nbsp;% 100.0&nbsp;%
</p>
<p>% within gender 20.4&nbsp;% 17.6&nbsp;% 18.3&nbsp;%
</p>
<p>Total Count 280 785 1065
</p>
<p>% within country 26.3&nbsp;% 73.7&nbsp;% 100.0&nbsp;%
</p>
<p>% within gender 100.0&nbsp;% 100.0&nbsp;% 100.0&nbsp;%
</p>
<p>The correlation matrix shows the correlation between each pairwise combination of 
three variables. For example, the correlation between s1 (&ldquo; &hellip; with Oddjob Airways you 
will arrive on time.&rdquo;) and s2 (&ldquo; &hellip; the entire journey with Oddjob Airways will occur as 
booked.&rdquo;) is 0.739, which indicates a strong relationship according to Cohen (1988). As 
indicated by the two asterisks, the correlation is significant at a 1&nbsp;% level.
</p>
<p>Alternatively, you can let SPSS display a covariance matrix. To do so, go to ► Analyze 
► Correlate ► Bivariate and click on Options. Under Statistics, tick the box Cross-prod-
uct deviations and covariances and run the analysis.</p>
<p/>
</div>
<div class="page"><p/>
<p>148 Chapter 5 &middot; Descriptive Statistics
</p>
<p>. Fig.&nbsp;5.28 Correlate dialog box
</p>
<p>. Table 5.11 Correlation matrix
</p>
<p>Correlations
</p>
<p>s1 s2 s3 s4
</p>
<p>s1 Pearson Correlation 1 .739** .619** .717**
</p>
<p>Sig. (2-tailed) .000 .000 .000
</p>
<p>N 1038 1037 952 1033
</p>
<p>s2 Pearson Correlation .739** 1 .694** .766**
</p>
<p>Sig. (2-tailed) .000 .000 .000
</p>
<p>N 1037 1040 952 1034
</p>
<p>s3 Pearson Correlation .619** .694** 1 .645**
</p>
<p>Sig. (2-tailed) .000 .000 .000
</p>
<p>N 952 952 954 951
</p>
<p>s4 Pearson Correlation .717** .766** .645** 1
</p>
<p>Sig. (2-tailed) .000 .000 .000
</p>
<p>N 1033 1034 951 1035
</p>
<p>** Correlation is significant at the 0.01&nbsp;level (2-tailed).
</p>
<p>5</p>
<p/>
</div>
<div class="page"><p/>
<p>5149
5.12 &middot; Review Questions
</p>
<p>5.11 Cadbury and the UK Chocolate Market (Case Study)
</p>
<p>The UK chocolate market is 
</p>
<p>expected to be &pound;6.46&nbsp;billion 
</p>
<p>in 2019. Six subcategories 
</p>
<p>of chocolates are used 
</p>
<p>to identify the different 
</p>
<p>chocolate segments: boxed 
</p>
<p>chocolate, molded bars, 
</p>
<p>seasonal chocolate, count 
</p>
<p>lines, straight lines, and 
</p>
<p>&ldquo;other.&rdquo;
</p>
<p>To understand the UK 
</p>
<p>chocolate market for molded 
</p>
<p>chocolate bars, we have a 
</p>
<p>dataset (chocolate.sav) that 
</p>
<p>includes a large supermarket&rsquo;s 
</p>
<p>weekly sales of 100&nbsp;g molded 
</p>
<p>chocolate bars from January 
</p>
<p>2016 onwards. This data file 
</p>
<p>can be downloaded from the 
</p>
<p>book&rsquo;s ⤓ Web Appendix (&rarr; 
Downloads). This file contains 
</p>
<p>a set of variables. Once you 
</p>
<p>have opened the dataset, you 
</p>
<p>will see the set of variables.
</p>
<p>The first variable is week, 
</p>
<p>indicating the week of the 
</p>
<p>year and starts with Week 
</p>
<p>1 of January 2016. The last 
</p>
<p>observation for 2016 ends 
</p>
<p>with observation 52, but the 
</p>
<p>variable continues to count 
</p>
<p>onwards for 16&nbsp;weeks in 2017. 
</p>
<p>The next variable is sales, 
</p>
<p>which indicates the weekly 
</p>
<p>sales of 100&nbsp;g Cadbury bars 
</p>
<p>in &pound;. Next, four price variables 
</p>
<p>are included, price1-price4, 
</p>
<p>which indicate the price of 
</p>
<p>Cadbury, Nestl&eacute;, Guylian, and 
</p>
<p>Milka in &pound;. Next, advertising1-
</p>
<p>advertising4 indicate the 
</p>
<p>amount of &pound; the supermarket 
</p>
<p>spent on advertising each 
</p>
<p>product during that week. 
</p>
<p>A subsequent block of 
</p>
<p>variables, pop1-pop4, indicate 
</p>
<p>whether the products were 
</p>
<p>promoted in the supermarket 
</p>
<p>by means of point of 
</p>
<p>purchase advertising. This 
</p>
<p>variable is measured as yes/
</p>
<p>no. Variables promo1-promo4 
</p>
<p>indicate whether the product 
</p>
<p>was put at the end of the 
</p>
<p>supermarket aisle, where it 
</p>
<p>is more noticeable. Lastly, 
</p>
<p>temperature indicates the 
</p>
<p>weekly average temperature 
</p>
<p>in degrees Celsius.
</p>
<p>You have been tasked 
</p>
<p>with providing descriptive 
</p>
<p>statistics for a client by means 
</p>
<p>of this dataset. To help you 
</p>
<p>with this task, the client 
</p>
<p>has prepared a number of 
</p>
<p>questions:
</p>
<p>1. Do Cadbury&rsquo;s chocolate 
</p>
<p>sales vary substantially 
</p>
<p>across different weeks? 
</p>
<p>When are Cadbury&rsquo;s sales 
</p>
<p>at their highest? Please 
</p>
<p>create an appropriate 
</p>
<p>graph to illustrate any 
</p>
<p>patterns.
</p>
<p>2. Please tabulate point-of-
</p>
<p>purchase advertising for 
</p>
<p>Cadbury against point-of-
</p>
<p>purchase advertising for 
</p>
<p>Nestl&eacute;. In addition, create 
</p>
<p>a few more crosstabs. 
</p>
<p>What are the implications 
</p>
<p>of these crosstabs?
</p>
<p>3. How do Cadbury&rsquo;s 
</p>
<p>sales relate to the price 
</p>
<p>of Cadbury? What is 
</p>
<p>the strength of the 
</p>
<p>relationship?
</p>
<p>4. Which descriptive 
</p>
<p>statistics are appropriate 
</p>
<p>for describing the usage 
</p>
<p>of advertising? Which 
</p>
<p>statistics are appropriate 
</p>
<p>for describing point-of-
</p>
<p>purchase advertising?
</p>
<p>Case Study
</p>
<p>5.12 Review Questions
</p>
<p>1. Imagine you are given a dataset on car sales in different regions and are asked to 
calculate descriptive statistics. How would you set up the analysis procedure?
</p>
<p>2. What summary statistics could best be used to describe the change in profits over 
the last five years? What types of descriptive statistics work best to determine the 
market shares of five different types of insurance providers? Should we use just one 
or multiple descriptive statistics?
</p>
<p>3. What information do we need to determine if a case is an outlier? What are the 
benefits and drawbacks of deleting outliers?
</p>
<p>4. Download a codebook of the Household Income and Labour Dynamics in Australia 
(HILDA) Survey at: http://melbourneinstitute.unimelb.edu.au/hilda/for-data-users/
user-manuals. Is this codebook clear? What do you think of its structure?</p>
<p/>
<div class="annotation"><a href="http://melbourneinstitute.unimelb.edu.au/hilda/for-data-users/user-manuals">http://melbourneinstitute.unimelb.edu.au/hilda/for-data-users/user-manuals</a></div>
<div class="annotation"><a href="http://melbourneinstitute.unimelb.edu.au/hilda/for-data-users/user-manuals">http://melbourneinstitute.unimelb.edu.au/hilda/for-data-users/user-manuals</a></div>
</div>
<div class="page"><p/>
<p>150 Chapter 5 &middot; Descriptive Statistics
</p>
<p>References
</p>
<p>Agarwal, C. C. (2013). Outlier analysis. New York, NY: Springer.
</p>
<p>Agresti, A., &amp; Finlay, B. (2014). Statistical methods for the social sciences (4th ed). Upper Saddle River, NJ: 
</p>
<p>Pearson.
</p>
<p>Barchard, K. A., &amp; Verenikina, Y. (2013). Improving data accuracy: Electing the best data checking tech-
</p>
<p>nique. Computers in Human Behavior, 29(50), 1917&ndash;1912.
</p>
<p>Barchard, K. A., &amp; Pace, L. A. (2011). Preventing human error: The impact of data entry methods on data 
</p>
<p>accuracy and statistical results. Computers in Human Behavior, 27(5), 1834&ndash;1839.
</p>
<p>Baumgartner, H., &amp; Steenkamp, J.-B. E. M. (2001). Response styles in marketing research: A cross-national 
</p>
<p>investigation. Journal of Marketing Research, 38(2), 143&ndash;156.
</p>
<p>Carpenter, J. &amp; Kenward, M. (2013). Multiple imputation and its application. New York, NJ: John Wiley.
</p>
<p>Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Hillsdale, NJ: Lawrence 
</p>
<p>Erlbaum Associates.
</p>
<p>Drolet, A. L., &amp; Morrison, D. G. (2001). Do we really need multiple-item measures in service research? Jour-
</p>
<p>nal of Service Research, 3(3), 196&ndash;204.
</p>
<p>Eekhout, I., de Vet, H. C. W., Twisk, J. W. R., Brand, J. P. L., de Boer, M. R., &amp; Heymans, M. W. (2014). Missing 
</p>
<p>data in a multi-item instrument were best handled by multiple imputation at the item score level. 
</p>
<p>Journal of Clinical Epidemiology, 67(3), 335&ndash;342.
</p>
<p>Gladwell, M. (2008). Outliers: The story of success. New York, NY: Little, Brown, and Company.
</p>
<p>Graham, J. W. (2012). Missing data: Analysis and design. Berlin et al.: Springer.
</p>
<p>Grotenhuis, M., &amp; Visscher, C. (2014). How to use SPSS syntax: An overview of common commands. Thou-
</p>
<p>sand Oaks, CA: Sage.
</p>
<p>Hair, J. F., Jr., Black, W. C., Babin, B. J., &amp; Anderson, R. E. (2019). Multivariate data analysis (8th ed.). Boston, 
</p>
<p>MA: Cengage.
</p>
<p>Harzing, A. W. (2005). Response styles in cross-national survey research: A 26-country study. International 
</p>
<p>Journal of Cross Cultural Management, 6(2), 243&ndash;266.
</p>
<p>Johnson, T., Kulesa, P., Lic, I., Cho, Y. I., &amp; Shavitt, S. (2005). The relation between culture and response 
</p>
<p>styles. Evidence from 19 countries. Journal of Cross-Cultural Psychology, 36(2), 264&ndash;277.
</p>
<p>Krippendorff, K. (2012). Content analysis: An introduction to its methodology. Thousand Oaks, CA: Sage.
</p>
<p>Little, R. J. A. (1998). A test of missing completely at random for multivariate data with missing values. 
</p>
<p>Journal of the American Statistical Association, 83(404), 1198&ndash;1202.
</p>
<p>Paulsen, A., Overgaard, S., &amp; Lauritsen, J. M. (2012). Quality of data entry using single entry, double entry 
</p>
<p>and automated forms processing&mdash;An example based on a study of patient-reported outcomes. PloS 
</p>
<p>ONE, 7(4), e35087.
</p>
<p>Rubin, D. B. (1987). Multiple imputation for nonresponse in surveys. New York, NJ: Wiley.
</p>
<p>Sarstedt, M., Diamantopoulos, A., Salzberger, T., &amp; Baumgartner, P. (2016). Selecting single items to mea-
</p>
<p>sure doubly-concrete constructs: A cautionary tale. Journal of Business Research, 69(8), 3159&ndash;3167.
</p>
<p>Schafer, J. L. (1997). Analysis of incomplete multivariate data. London, UK: Chapman &amp; Hall.
</p>
<p>White, I. R., Royston, P., &amp; Wood, A. M. (2011). Multiple imputation using chained equations: Issues and 
</p>
<p>guidance for practice. Statistics in Medicine, 30(4), 377&ndash;399.
</p>
<p>Further Reading
</p>
<p>Huck, S. W. (2014). Reading statistics and research (6th ed.). Harlow: Pearson Education.
</p>
<p>Levesque, R., Programming and data management for IBM SPSS Statistics 20. Chicago, SPSS, Inc. Avail-
</p>
<p>able at http://www.spsstools.net/en/resources/spss-programming-book/
</p>
<p>SticiGui at http://www.stat.berkeley.edu/~stark/SticiGui/Text/correlation.htm
</p>
<p>5</p>
<p/>
<div class="annotation"><a href="http://www.spsstools.net/en/resources/spss-programming-book/">http://www.spsstools.net/en/resources/spss-programming-book/</a></div>
<div class="annotation"><a href="http://www.stat.berkeley.edu/~stark/SticiGui/Text/correlation.htm">http://www.stat.berkeley.edu/~stark/SticiGui/Text/correlation.htm</a></div>
</div>
<div class="page"><p/>
<p>151
</p>
<p>Hypothesis Testing  
and ANOVA
</p>
<p>6.1 Introduction &ndash; 153
</p>
<p>6.2 Understanding Hypothesis Testing &ndash; 153
</p>
<p>6.3 Testing Hypotheses on One Mean &ndash; 156
6.3.1 Formulate the Hypothesis &ndash; 156
</p>
<p>6.3.2 Choose the Significance Level &ndash; 158
</p>
<p>6.3.3 Select the Appropriate Test &ndash; 160
</p>
<p>6.3.4 Calculate the Test Statistic &ndash; 166
</p>
<p>6.3.5 Make the Test Decision &ndash; 168
</p>
<p>6.3.6 Interpret the Results &ndash; 172
</p>
<p>6.4 Two-Samples t-test &ndash; 173
6.4.1 Comparing Two Independent Samples &ndash; 173
</p>
<p>6.4.2 Comparing Two Paired Samples &ndash; 174
</p>
<p>6.5 Comparing More Than Two Means: Analysis of  
Variance (ANOVA) &ndash; 176
</p>
<p>6.5.1 Check the Assumptions &ndash; 179
</p>
<p>6.5.2 Calculate the Test Statistic &ndash; 180
</p>
<p>6.5.3 Make the Test Decision &ndash; 183
</p>
<p>6.5.4 Carry Out Post Hoc Tests &ndash; 184
</p>
<p>6.5.5 Measure the Strength of the Effects &ndash; 185
</p>
<p>6.5.6 Interpret the Results &ndash; 186
</p>
<p>6
</p>
<p>Electronic supplementary material
</p>
<p>The online version of this chapter (https://doi.org/10.1007/978-3-662-56707-4_6) contains 
</p>
<p>additional material that is available to authorized users. You can also download the &ldquo;Springer 
</p>
<p>Nature More Media App&rdquo; from the iOS or Android App Store to stream the videos and scan the 
</p>
<p>image containing the &ldquo;Play button&rdquo;.
</p>
<p>&copy; Springer-Verlag GmbH Germany, part of Springer Nature 2019 
</p>
<p>M. Sarstedt, E. Mooi, A Concise Guide to Market Research, Springer Texts in Business  
</p>
<p>and Economics, https://doi.org/10.1007/978-3-662-56707-4_6</p>
<p/>
<div class="annotation"><a href="https://crossmark.crossref.org/dialog/?doi=10.1007/978-3-662-56707-4_6&amp;amp;domain=pdf&amp;amp;date_stamp=2018-9-17">https://crossmark.crossref.org/dialog/?doi=10.1007/978-3-662-56707-4_6&amp;amp;domain=pdf&amp;amp;date_stamp=2018-9-17</a></div>
</div>
<div class="page"><p/>
<p>6.6 Example &ndash; 193
6.6.1 Research Question 1 &ndash; 194
</p>
<p>6.6.2 Research Question 2 &ndash; 198
</p>
<p>6.7 Customer Spending Analysis with IWD Market  
Research (Case Study) &ndash; 206
</p>
<p>6.8 Review Questions &ndash; 207
</p>
<p> References &ndash; 208</p>
<p/>
</div>
<div class="page"><p/>
<p>6153
6.2 &middot; Understanding Hypothesis Testing
</p>
<p>Keywords
α-Inflation &bull; α error &bull; Adjusted R2 &bull; Alternative hypothesis &bull; Analysis of variance (ANOVA) &bull; β error &bull; Bon-
</p>
<p>ferroni correction &bull; Confidence interval &bull; Degrees of freedom &bull; Directional hypothesis &bull; Effect size &bull; Eta 
</p>
<p>squared &bull; Explained variation &bull; Factor level &bull; Factor variable &bull; F-test &bull; F-test of sample variance &bull; Familywise 
</p>
<p>error rate &bull; Grand mean &bull; Independent samples &bull; Independent samples t-test &bull; Kruskal-Wallis rank test&nbsp;&bull; 
</p>
<p>Left-tailed hypothesis &bull; Levene&rsquo;s test &bull; Mann-Whitney U test &bull; Marginal mean &bull; Noise &bull; Nonparametric test 
</p>
<p>&bull; Non-directional hypothesis &bull; Null hypothesis &bull; Omega squared &bull; One-sample t-test &bull; One-tailed test &bull; 
</p>
<p>One-way ANOVA &bull; p-value &bull; Paired samples &bull; Paired samples t-test &bull; Parametric test &bull; Post hoc tests &bull; Power 
</p>
<p>analysis &bull; Power of a statistical test &bull; Practical significance &bull; Quantile plot &bull; Random noise &bull; R2 &bull; Right-tailed 
</p>
<p>hypothesis &bull; Sampling error &bull; Shapiro-Wilk test &bull; Significance level &bull; Standard error &bull; Statistical signifi-
</p>
<p>cance &bull; t-test &bull; Test statistic &bull; Tukey&rsquo;s honestly significant difference test &bull; Two-samples t-test &bull; Two-tailed 
</p>
<p>test &bull; Two-way ANOVA &bull; Type I error &bull; Type II error &bull; Unexplained variation &bull; Welch&rsquo;s correction &bull; Wilcoxon 
</p>
<p>matched-pairs signed-rank test &bull; Wilcoxon signed-rank test &bull; z-test.
</p>
<p>6.1 Introduction
</p>
<p>Do men or women spend more money on the Internet? Assume that the mean amount that a 
sample of men spends online is $200 per year against a women sample&rsquo;s mean of $250. When 
we compare mean values such as these, we always expect some difference. But, how can we 
determine if such differences are statistically significant? Establishing statistical significance 
requires ascertaining whether such differences are attributable to chance or not. If the dif-
ference is so large that it is unlikely to have occurred by chance, this indicates statistical sig-
nificance. Whether results are statistically significant depends on several factors, including 
the difference, variation in the sample data, and the number of observations. In this chapter, 
we will introduce hypothesis testing and how this helps determine statistical significance.
</p>
<p>6.2 Understanding Hypothesis Testing
</p>
<p>A hypothesis is a statement about a certain condition or parameter (such as a mean or dif-
ference) that can be tested using a sample drawn from the population. A hypothesis may 
comprise a claim about the difference between two sample parameters (e.g., there is a dif-
ference between males&rsquo; and females&rsquo; mean spending). It can also be a test of a judgment 
(e.g., teenagers spend an average of four hours per day on the Internet). Data from the 
sample are used to obtain evidence against, or in favor of, the statement.
</p>
<p>Learning Objectives
After reading this chapter you should understand:
</p>
<p> 5 The logic of hypothesis testing.
 5 The steps involved in hypothesis testing.
 5 What a test statistic is.
 5 Types of error in hypothesis testing.
 5 Common types of t-tests, one-way ANOVA.
 5 How to interpret SPSS output.</p>
<p/>
</div>
<div class="page"><p/>
<p>154 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>Hypothesis testing is performed to infer that the stated hypothesis is likely true in the 
population of interest (Agresti and Finlay 2014). When drawing a sample from the pop-
ulation, there is always some probability that we might reach the wrong conclusion due 
to sampling error, which is the difference between the sample and the population charac-
teristics. To determine whether the claim is true, we start by setting an acceptable prob-
ability (called the significance level) that we could incorrectly conclude there is an effect 
when, in fact, there is none. This significance level is typically set at 5&nbsp;% in market research. 
Next, subject to the claim made in the hypothesis, we should decide on the correct type of 
test to perform. This involves making decisions regarding four aspects. First, we should 
understand the testing situation. What exactly are we testing: Are we comparing one value 
against a fixed value, or are we comparing groups, and, if so, how many? Second, we need 
to specify the nature of the samples: Is our comparison based on paired samples or inde-
pendent samples (the difference is discussed later in this chapter)? Third, we should check 
assumptions about the distribution of our data to determine whether parametric or non-
parametric tests are appropriate. Parametric tests make assumptions about the properties 
of the population distributions from which the data are drawn, while nonparametric tests 
are not based on any distributional assumptions. Fourth, we need to decide on the region 
where we can reject our hypothesis; that is, whether the region of rejection will be on one 
side or both sides of the sampling distribution.
</p>
<p>Once these four aspects are sorted, we calculate the test statistic, which identifies 
whether the sample supports or rejects the claim stated in the hypothesis. Once we have 
calculated the test statistic, we can decide to either reject or support the hypothesis. This 
decision enables us to draw market research conclusions in the final step. . Fig.&nbsp;6.1 illus-
trates the six steps involved in hypothesis testing.
</p>
<p>Formulate the hypothesis 
</p>
<p>Select the appropriate test 
</p>
<p>Calculate the test statistic 
</p>
<p>Make the test decision 
</p>
<p>Interpret the results 
</p>
<p>Choose the significance level 
</p>
<p>1. Define the testing situation 
2. Determine if samples are paired or independent 
</p>
<p>3. Check assumptions and choose the test 
4. Specify the region of rejection 
</p>
<p>. Fig.&nbsp;6.1 Steps involved in hypothesis testing
</p>
<p>6</p>
<p/>
</div>
<div class="page"><p/>
<p>6155
6.2 &middot; Understanding Hypothesis Testing
</p>
<p>To illustrate the process of hypothesis testing, consider the following example: A 
department store chain wants to evaluate the effectiveness of three different in-store 
promotion campaigns that drive the sales of a specific product. These campaigns 
include: (1) a point of sale display, (2) a free tasting stand, and (3) in-store announce-
ments. To help with the evaluation, the management decides to conduct a one-week 
experiment during which 30 stores are randomly assigned to each campaign type. This 
random assignment is important because randomization should equalize the effect 
of systematic factors not accounted for in the experimental design (see 7 Chap.&nbsp;4).  
. Table&nbsp;6.1 shows the sales of the three different in-store promotion campaigns. The 
table also contains information on the service type (personal or self-service). The 
marginal mean represents the means of sales within stores in the last column. Finally, 
the very last cell shows the grand mean, which is the overall average across all service 
types and campaigns.
</p>
<p>We will use these data to carry out tests to compare the different in-store promotion 
campaigns&rsquo; mean sales separately, or in comparison to each other. We first discuss each 
test theoretically (including the formulas), followed by an illustration. You will realize that 
the formulas are not as complicated as you might have thought! These formulas contain 
Greek characters and we have included a table describing each Greek character in the ⤓ 
Web Appendix (&rarr; Downloads).
</p>
<p>. Table 6.1 Sales data
</p>
<p>Sales (units)
</p>
<p>Service 
type
</p>
<p>Point of sale dis-
play (stores 1&ndash;10)
</p>
<p>Free tasting stand 
(stores 11&ndash;20)
</p>
<p>In-store  
announcements 
(stores 21&ndash;30)
</p>
<p>Marginal mean
</p>
<p>Personal 50 55 45 50.00
</p>
<p>Personal 52 55 50 52.33
</p>
<p>Personal 43 49 45 45.67
</p>
<p>Personal 48 57 46 50.33
</p>
<p>Personal 47 55 42 48.00
</p>
<p>Self-service 45 49 43 45.67
</p>
<p>Self-service 44 48 42 44.67
</p>
<p>Self-service 49 54 45 49.33
</p>
<p>Self-service 51 54 47 50.67
</p>
<p>Self-service 44 44 42 43.33
</p>
<p>Marginal 
</p>
<p>mean
</p>
<p>47.30 52.00 44.7 48.00
</p>
<p>Grand mean</p>
<p/>
</div>
<div class="page"><p/>
<p>156 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>6.3 Testing Hypotheses on One Mean
</p>
<p>6.3.1 Formulate the Hypothesis
</p>
<p>Hypothesis testing starts with the formulation of a null and alternative hypothesis. A null 
hypothesis (indicated as H0) is a statement expecting no difference or effect. Conversely, an 
alternative hypothesis (indicated as H1) is the hypothesis against which the null hypothesis 
is tested (Everitt and Skrondal 2010). Examples of potential null and alternative hypoth-
eses on the campaign types are:
1. H0: The mean sales in stores that installed a point of sale display are equal to or lower 
</p>
<p>than 45&nbsp;units.
 H1: The mean sales in stores that installed a point of sale display are higher than 45&nbsp;units.
2. H0: There is no difference in the mean sales of stores that installed a point of sale 
</p>
<p>display and those that installed a free tasting stand (statistically, the average sales of 
the point of sale display&nbsp;=&nbsp;the average sales of the free tasting stand).
</p>
<p> H1: There is a difference in the mean sales of stores that installed a point of sale 
display and those that installed a free tasting stand (statistically, the average sales of 
the point of sale display &ne; the average sales of the free tasting stand).
</p>
<p>Hypothesis testing can have two outcomes: a first outcome may be that we do not reject 
the null hypothesis. This suggests there is no effect or no difference and that the null 
hypothesis can be retained. However, it would be incorrect to conclude from this that 
the null hypothesis is true, as it is not possible to &ldquo;prove&rdquo; the non-existence of a certain 
effect or condition. For example, one can examine any number of crows and find that 
they are all black, yet that would not make the statement &ldquo;There are no white crows&rdquo; 
</p>
<p>&copy; neyro2008/Getty Images/iStock.
</p>
<p>https://www.guide-market-research.com/app/download/13488685427/SPSS+3rd_
</p>
<p>Greek+Characters.pdf?t=1516714139
</p>
<p>6</p>
<p/>
<div class="annotation"><a href="https://www.guide-market-research.com/app/download/13488685427/SPSS+3rd_Greek+Characters.pdf?t=1516714139">https://www.guide-market-research.com/app/download/13488685427/SPSS+3rd_Greek+Characters.pdf?t=1516714139</a></div>
<div class="annotation"><a href="https://www.guide-market-research.com/app/download/13488685427/SPSS+3rd_Greek+Characters.pdf?t=1516714139">https://www.guide-market-research.com/app/download/13488685427/SPSS+3rd_Greek+Characters.pdf?t=1516714139</a></div>
</div>
<div class="page"><p/>
<p>6157
6.3 &middot; Testing Hypotheses on One Mean
</p>
<p>true. Only sighting one white crow will prove its existence. A second outcome may be 
that we reject the null hypothesis, thus finding support for the alternative hypothesis in 
which some effect is expected. This outcome is, of course, desirable in most analyses, as 
we generally want to show that something (such as a promotion campaign) is related to 
a certain outcome (e.g., sales). Therefore, we frame the effect that we want to investigate 
as the alternative hypothesis.
</p>
<p>&gt; Inevitably, each hypothesis test has a certain degree of uncertainty so that even if 
we reject a null hypothesis, we can never be totally certain that this was the correct 
</p>
<p>decision. Consequently, market researchers should use terms such as &ldquo;find support 
</p>
<p>for the alternative hypothesis&rdquo; when they discuss their findings. Terms like &ldquo;prove&rdquo; 
</p>
<p>should never be part of hypotheses testing.
</p>
<p>Returning to example 1, the management only considers a campaign effective if the sales 
it generates are higher than the 45 units normally sold (you can choose any other value, 
the idea is to test the sample mean against a given standard). One way of formulating the 
null and alternative hypotheses of this expectation is:
</p>
<p>H0 45:&micro;&le;  
</p>
<p>H1 45:&micro;&gt;  
</p>
<p>In words, the null hypothesis H0 states that the population mean, indicated by μ (pro-
nounced as mu), is equal to or smaller than 45, whereas the alternative hypothesis H1 
states that the population mean is larger than 45. It is important to note that the hypothe-
sis always refers to a population parameter, in this case, the population mean, represented 
by μ. It is practice for Greek characters to represent population parameters and for Latin 
characters to indicate sample statistics (e.g., the Latin  x ). In this example, we state a direc-
tional hypothesis as the alternative hypothesis, which is expressed in a direction (higher) 
relative to the standard of 45 units. Since we presume that during a campaign, the product 
sales are higher, we posit a right-tailed hypothesis (as opposed to a left-tailed hypothesis) 
for the alternative hypothesis H1.
</p>
<p>Alternatively, presume we are interested in determining whether the mean sales of the 
point of sale display are equal to the mean sales of the free tasting stand (example 2). This 
implies a non-directional hypothesis, which can be written as:
</p>
<p>H0 1 2:&micro; &micro;=  
</p>
<p>H1 1 2:&micro; &micro;&ne;  
</p>
<p>The difference between the two general types of hypotheses is that a directional hypothe-
sis looks for an increase or a decrease in a parameter (such as a population mean) relative 
to a specific standard. A non-directional hypothesis tests for any difference in the param-
eter, whether positive or negative.</p>
<p/>
</div>
<div class="page"><p/>
<p>158 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>6.3.2 Choose the Significance Level
</p>
<p>No type of hypothesis testing can evaluate the validity of a hypothesis with absolute cer-
tainty. In any study that involves drawing a sample from the population, there is always 
some probability that we will erroneously retain or reject the null hypothesis due to sam-
pling error. In statistical testing, two types of errors can occur (. Fig.&nbsp;6.2):
1. a true null hypothesis is incorrectly rejected (type I or α error), and
2. a false null hypothesis is not rejected (type II or β error).
</p>
<p>In our example, a type I error occurs if we conclude that the point of sale displays increased 
the sales beyond 45 units, when in fact it did not increase the sales, or may have even 
decreased them. This situation is also referred to as false positive. A type II error occurs if 
we do not reject the null hypothesis, which suggests there was no increase in sales, even 
though the sales increased significantly. This situation is also referred to as false negative.
</p>
<p>A problem with hypothesis testing is that we don&rsquo;t know the true state of the null 
hypothesis. Fortunately, we can establish a level of confidence that a true null hypothesis 
will not be erroneously rejected. This is the maximum probability of a type I error that we 
want to allow. The Greek character α (pronounced as alpha) represents this probability 
and is called the significance level. In market research reports, this is indicated by phrases 
such as &ldquo;this test result is significant at a 5&nbsp;% level.&rdquo; This means that the researcher allowed 
for a maximum chance of 5&nbsp;% of mistakenly rejecting a true null hypothesis.
</p>
<p>The selection of an α level depends on the research setting and the costs associated 
with a type I error. Usually, α is set to 0.05, which corresponds to a 5&nbsp;% error probability. 
However, when researchers want to be conservative or strict in their testing, such as when 
conducting experiments, α is set to 0.01 (i.e., 1&nbsp;%). In exploratory studies, an α of 0.10 (i.e., 
10&nbsp;%) is commonly used. An α-level of 0.10&nbsp;means that if you carry out ten tests and reject 
the null hypothesis every time, your decision in favor of the alternative hypothesis was, on 
</p>
<p>True state of H0 
</p>
<p>H0 true H0 false
</p>
<p>T
e
</p>
<p>s
t 
</p>
<p>d
e
</p>
<p>c
is
</p>
<p>io
n
</p>
<p> H
0
</p>
<p> r
e
</p>
<p>je
ct
</p>
<p>e
d
</p>
<p>H
0
</p>
<p> n
o
</p>
<p>t 
re
</p>
<p>je
ct
</p>
<p>e
d
</p>
<p>Type II  
</p>
<p>error
</p>
<p>Type I  
</p>
<p>error
</p>
<p>. Fig.&nbsp;6.2 Type I and type 
II errors
</p>
<p>6</p>
<p/>
</div>
<div class="page"><p/>
<p>6159
6.3 &middot; Testing Hypotheses on One Mean
</p>
<p>average, wrong once. This might not sound too high a probability, but when much is at stake 
(e.g., withdrawing a product because of low satisfaction ratings) then 10&nbsp;% may be too high.
</p>
<p>Why don&rsquo;t we simply set α to 0.0001&nbsp;% to really minimize the probability of a type I 
error? Setting α to such a low level would obviously make the erroneous rejection of the null 
hypothesis very unlikely. Unfortunately, this approach introduces another problem. The 
probability of a type I error is inversely related to that of a type II error, so that the smaller 
the risk of a type I error, the higher the risk of a type II error! However, since a type I error 
is considered more severe than a type II error, we control the former directly by setting α 
to a desired level (Lehmann 1993).
</p>
<p>&gt; Sometimes statistical significance can be established even when differences are 
very small and have little or no managerial implication. Practitioners, usually refer 
</p>
<p>to &ldquo;significant&rdquo; as being practically significant rather than statistically significant. 
</p>
<p>Practical significance refers to differences or effects that are large enough to 
</p>
<p>influence the decision-making process. It is important to note that statistical 
</p>
<p>significance is required to establish practical significance. If we cannot reject that 
</p>
<p>an effect is likely due to chance, such an effect is also not meaningful managerially. 
</p>
<p>Whether results are practically significant depends on the management&rsquo;s 
</p>
<p>perception of the difference or effect and whether this warrants action. For 
</p>
<p>example, a statistical difference of 10&nbsp;% in sales due to packaging differences, 
</p>
<p>could be practically significant if the packaging change is possible, not too costly, 
</p>
<p>accepted by the retailer etc. In sum, statistical significance does not imply practical 
</p>
<p>significance but practical significance does require statistical significance.
</p>
<p>Another important concept related to this is the power of a statistical test (defined by 1&minus;β, 
where β is the probability of a type II error). Power is the probability of rejecting a null hypoth-
esis when it is, in fact, false. In other words, the power of a statistical test is the probability of 
rendering an effect significant when it is indeed significant. Researchers want the power of 
a test to be as high as possible, but when maximizing the power and, therefore, reducing the 
probability of a type II error, the occurrence of a type I error increases (Everitt and Skrondal 
2010). Researchers generally view a statistical power of 0.80 (i.e., 80&nbsp;%) as satisfactory, because 
this level is assumed to achieve a balance between acceptable type I and II errors. A test&rsquo;s 
statistical power depends on many factors, such as the significance level, the strength of the 
effect, and the sample size. In Box 6.1&nbsp;we discuss the statistical power concept in greater detail.
</p>
<p>Box 6.1 Statistical power of a test
</p>
<p>How to calculate what sample size you need? Computing the required sample size (called a 
</p>
<p>power analysis) can be complicated, depending on the test or procedure used. Fortunately, 
SPSS provides an add-on module called &ldquo;Sample Power,&rdquo; which can be used to carry out such 
</p>
<p>analyses. In addition, the Internet offers a wide selection of downloadable applications and 
</p>
<p>interactive Web programs to conduct power analyses. One particular sophisticated and easy-
</p>
<p>to-use program is G*Power 3.0&nbsp;which is available at no charge from http://www.psycho.uni-
</p>
<p>duesseldorf.de/abteilungen/aap/gpower3/.
</p>
<p>If these tools are too advanced, Cohen (1992) suggests required sample sizes for different types 
</p>
<p>of tests. For example, detecting the presence of differences between two independent sample 
</p>
<p>means for α&nbsp;=&nbsp;0.05 and a power of β&nbsp;=&nbsp;0.80 requires a sample size (n) of n&nbsp;=&nbsp;26 for large differences, 
</p>
<p>n&nbsp;=&nbsp;64 for medium differences, and n&nbsp;=&nbsp;393 for small differences. This demonstrates that sample size 
</p>
<p>requirements increase disproportionally when the effect that needs to be detected becomes smaller.</p>
<p/>
<div class="annotation"><a href="http://www.psycho.uni-duesseldorf.de/abteilungen/aap/gpower3/">http://www.psycho.uni-duesseldorf.de/abteilungen/aap/gpower3/</a></div>
<div class="annotation"><a href="http://www.psycho.uni-duesseldorf.de/abteilungen/aap/gpower3/">http://www.psycho.uni-duesseldorf.de/abteilungen/aap/gpower3/</a></div>
</div>
<div class="page"><p/>
<p>160 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>6.3.3 Select the Appropriate Test
</p>
<p>Selecting an appropriate statistical test is based on four aspects. First, we need to assess 
the testing situation: What are we comparing? Second, we need to assess the nature of the 
samples that are being compared: Do we have one sample with observations from the same 
object, firm or individual (paired), or do we have two different sets of samples (i.e., inde-
pendent)? Third, we need to check the assumptions for normality to decide which type of 
test to use: Parametric (if we meet the test conditions) or non-parametric (if we fail to meet 
the test conditions)? This step may involve further analysis, such as testing the homoge-
neity of group variances. Fourth, we should decide on the region of rejection: Do we want 
to test one side or both sides of the sampling distribution? . Table&nbsp;6.2 summarizes these 
four aspects with the recommended choice of test indicated in the grey shaded boxes. In 
the following we will discuss each of these four aspects.
</p>
<p>6.3.3.1 Define the Testing Situation
</p>
<p>When we test hypotheses, we may find ourselves in one of three situations. First, we may 
test if we want to compare a group to a hypothetical value (test #1 in . Table&nbsp;6.2). In our 
example, this can be a pre-determined target of 45&nbsp;units to establish whether a promotion 
campaign has been effective or not. Second, we may want to compare the outcome variable 
(e.g., sales) across two groups (tests #2 or #3 in . Table&nbsp;6.2). Third, we may wish to compare 
whether the outcome variable differs between three or more levels of a categorical variable 
with three or more sub-groups (test #4 in . Table&nbsp;6.2). The factor variable is the categor-
ical variable that we use to define the groups (e.g., three types of promotion campaigns). 
</p>
<p>. Table 6.2 Selecting an appropriate test
</p>
<p>Test 
#
</p>
<p>Testing 
situation
</p>
<p>Nature of 
samples
</p>
<p>Choice of test Region of 
rejection
</p>
<p>What do 
</p>
<p>we  
</p>
<p>compare
</p>
<p>Paired vs.  
</p>
<p>independent
</p>
<p>Assumptions Parametric Non-para-
</p>
<p>metric
</p>
<p>One or 
</p>
<p>two-sided 
</p>
<p>test
</p>
<p>1 One 
group 
</p>
<p>against 
</p>
<p>a fixed 
</p>
<p>value
</p>
<p>Not 
</p>
<p>applicable
</p>
<p>Shapiro-Wilk 
</p>
<p>test&nbsp;=&nbsp;normal
</p>
<p>One-sample 
</p>
<p>t-test
</p>
<p>One or 
</p>
<p>two-sided
</p>
<p>Shapiro-Wilk 
</p>
<p>test &ne; normal
</p>
<p>Wilcoxon 
</p>
<p>signed-
</p>
<p>rank test
</p>
<p>One or 
</p>
<p>two-sided
</p>
<p>2 Outcome 
variable 
</p>
<p>across 
</p>
<p>two 
</p>
<p>groups
</p>
<p>Paired 
</p>
<p>samples
</p>
<p>If either 
</p>
<p>Levene&rsquo;s test:  
</p>
<p>σ σ1
2
</p>
<p>2
2=  or 
</p>
<p>Shapiro-Wilk 
</p>
<p>test&nbsp;=&nbsp;normal
</p>
<p>Paired 
</p>
<p>samples  
</p>
<p>t-test
</p>
<p>One or 
</p>
<p>two-sided
</p>
<p>Levene&rsquo;s test:  
</p>
<p>σ σ1
2
</p>
<p>2
2&ne;  &amp; 
</p>
<p>Shapiro-Wilk 
</p>
<p>test &ne; normal
</p>
<p>Wilcoxon 
</p>
<p>matched-
</p>
<p>pairs 
</p>
<p>signed-
</p>
<p>rank test
</p>
<p>One or 
</p>
<p>two-sided
</p>
<p>6</p>
<p/>
</div>
<div class="page"><p/>
<p>6161
6.3 &middot; Testing Hypotheses on One Mean
</p>
<p>Test 
#
</p>
<p>Testing 
situation
</p>
<p>Nature of 
samples
</p>
<p>Choice of test Region of 
rejection
</p>
<p>What do 
</p>
<p>we  
</p>
<p>compare
</p>
<p>Paired vs.  
</p>
<p>independent
</p>
<p>Assumptions Parametric Non-para-
</p>
<p>metric
</p>
<p>One or 
</p>
<p>two-sided 
</p>
<p>test
</p>
<p>3 Outcome 
variable 
</p>
<p>across 
</p>
<p>two 
</p>
<p>groups
</p>
<p>Independent 
</p>
<p>samples
</p>
<p>Levene&rsquo;s test:  
</p>
<p>σ σ1
2
</p>
<p>2
2=
</p>
<p>Independent 
</p>
<p>samples
</p>
<p>t-test
</p>
<p>One or 
</p>
<p>two-sided
</p>
<p>Shapiro-Wilk 
</p>
<p>test&nbsp;=&nbsp;normal &amp;
</p>
<p>Levene&rsquo;s test:  
</p>
<p>σ σ1
2
</p>
<p>2
2&ne;
</p>
<p>Independent 
</p>
<p>samples
</p>
<p>t-test with 
</p>
<p>Welch's 
</p>
<p>correction
</p>
<p>One or 
</p>
<p>two-sided
</p>
<p>Shapiro-Wilk 
</p>
<p>test &ne; normal &amp;
</p>
<p>Levene&rsquo;s test:  
</p>
<p>σ σ1
2
</p>
<p>2
2&ne;
</p>
<p>Mann-
</p>
<p>Whitney U 
</p>
<p>test
</p>
<p>One or 
</p>
<p>two-sided
</p>
<p>4 Outcome 
variable 
</p>
<p>across 
</p>
<p>three 
</p>
<p>or more 
</p>
<p>groups
</p>
<p>One factor 
</p>
<p>variable,
</p>
<p>independent 
</p>
<p>samples
</p>
<p>Shapiro-Wilk 
</p>
<p>test&nbsp;=&nbsp;normal &amp;
</p>
<p>Levene&rsquo;s test:  
</p>
<p>σ σ1
2
</p>
<p>2
2=
</p>
<p>One-way 
</p>
<p>ANOVA:
</p>
<p>F-test
</p>
<p>Two-
</p>
<p>sided*
</p>
<p>Shapiro-Wilk 
</p>
<p>test &ne; normal &amp;
</p>
<p>Levene&rsquo;s test:  
</p>
<p>σ σ1
2
</p>
<p>2
2=
</p>
<p>One-way 
</p>
<p>ANOVA:
</p>
<p>F-test
</p>
<p>Two-
</p>
<p>sided*
</p>
<p>Shapiro-Wilk 
</p>
<p>test&nbsp;=&nbsp;normal &amp;
</p>
<p>Levene&rsquo;s test:  
</p>
<p>σ σ1
2
</p>
<p>2
2&ne;
</p>
<p>One-way 
</p>
<p>ANOVA:
</p>
<p>F-test with 
</p>
<p>Welch&rsquo;s 
</p>
<p>correction
</p>
<p>Two-
</p>
<p>sided*
</p>
<p>Shapiro-Wilk 
</p>
<p>test &ne; normal &amp;
</p>
<p>Levene&rsquo;s test:  
</p>
<p>σ σ1
2
</p>
<p>2
2&ne;
</p>
<p>Kruskal-
</p>
<p>Wallis 
</p>
<p>rank test
</p>
<p>Two-
</p>
<p>sided*
</p>
<p>* Note that although the underlying alternative hypothesis in ANOVA is two-sided, its F-statistic 
</p>
<p>is based on the F-distribution, which is right-skewed with extreme values only in the right tail of 
</p>
<p>the distribution.
</p>
<p>. Table&nbsp;6.2 (Continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>162 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>Each of these situations leads to different tests. When assessing the testing situation, we 
also need to establish the nature of the dependent variable and whether it is measured 
on an interval or ratio scale. This is important, because parametric tests are based on the 
assumption that the dependent variable is measured on an interval or ratio scale. Note that 
we only discuss situations when the test variable is interval or ratio-scaled (see 7 Chap.&nbsp;3).
</p>
<p>6.3.3.2 Determine if Samples Are Paired or Independent
</p>
<p>Next, we need to establish whether the samples being compared are paired or independent. 
The rule of thumb for determining the samples&rsquo; nature is to ask if a respondent (or object) 
was sampled once or multiple times. If a respondent was sampled only once, this means 
that the values of one sample reveal no information about the values of the other sample. 
If we sample the same respondent or object twice, it means that the reported values in one 
period may affect the values of the sample in the next period.1 Ignoring the &ldquo;nested&rdquo; nature 
of the data is the most serious threat to increases the probability of type I errors (Van Belle 
2008). We therefore need to understand the nature of our samples in order to select a test 
that takes the dependency between observations (i.e., paired versus independent samples 
tests) into account. In . Table&nbsp;6.2, test #2 deals with paired samples, whereas tests #3 and 
#4 deal with independent samples.
</p>
<p>6.3.3.3 Check Assumptions and Choose the Test
</p>
<p>Subsequently, we need to check the distributional properties and variation of our data 
before deciding whether to select a parametric or a non-parametric test.
</p>
<p>z Normality test
To test whether the data are normally distributed, we conduct the Shapiro-Wilk test (Shapiro 
and Wilk 1965) that formally tests for normality. Without going into too much detail, the 
Shapiro-Wilk test compares the correlation between the observed sample scores (which 
take the covariance between the sample scores into account) with the scores expected 
under a standard normal distribution. Large deviations will therefore relate to p-values 
smaller than 0.05, suggesting that the sample scores are not normally distributed. An alter-
native strategy to check visually for normality, which we discuss in Box 6.2.
</p>
<p>1 In experimental studies, if respondents were paired with others (as in a matched case control sam-
</p>
<p>ple), each person would be sampled once, but it still would be a paired sample.
</p>
<p>Box 6.2&nbsp;Visual check for normality
</p>
<p>You can also use plots to visually check for normality. The quantile plot (or Q&ndash;Q plot in SPSS) is 
a type of probability plot, which compares the quantiles of the sorted sample values with the 
</p>
<p>quantiles of a standard normal distribution. Plotted data that do not follow the straight line reveal 
</p>
<p>departures from normality. The quantile plot is useful to spot non-normality in the tails of the 
</p>
<p>distribution. It is also possible to plot a histogram with a normal curve (discussed in 7 Sect.&nbsp;5.5.1) 
which is typically most useful when distribution is not quite symmetrical. Note that visual checks 
</p>
<p>are subjective and should always be used in combination with more tests for normality such as 
</p>
<p>the Shapiro-Wilk test.
</p>
<p>6</p>
<p/>
</div>
<div class="page"><p/>
<p>6163
6.3 &middot; Testing Hypotheses on One Mean
</p>
<p>z Equality of variances test
We can use Levene&rsquo;s test (Levene 1960), also known as the F-test of sample variance, to test 
for the equality of the variances between two or more groups of data. The null hypothesis 
is that population variances across the sub-samples are the same, whereas the alternative 
hypothesis is that they differ. If the p-value associated with Levene&rsquo;s statistic is lower than 
0.05, we reject the null hypothesis, which implies that the variances are heterogeneous. 
Conversely, a p-value larger than 0.05 indicates homogeneous variances.
</p>
<p>z Parametric tests
It is clear-cut that when the normality assumption is met, we should choose a paramet-
ric test. The most popular parametric test for examining one or two means is the t-test, 
which can be used for different purposes. For example, the t-test can be used to compare 
one mean with a given value (e.g., do males spend more than $150 a year online?). The 
one-sample t-test is an appropriate test. Alternatively, we can use a t-test to test the mean 
difference between two samples (e.g., do males spend more time online than females?). In 
this case, a two-samples t-test is appropriate. Independent samples t-tests consider two dis-
tinct groups, such as males versus females, or users versus non-users. The paired samples 
t-tests is used to test for differences between the same set of twice observed objects (usually 
respondents). When we are interested in differences between the means of more than two 
groups of respondents, we should use the Analysis of Variance (ANOVA). The ANOVA is 
useful when three or more means are compared and, depending on how many variables 
define the groups to be compared (will be discussed later in this chapter), can come in dif-
ferent forms. For example, we might be interested in evaluating the differences between the 
point of sale display, the free tasting stand, and the in-store announcements&rsquo; mean sales.
</p>
<p>The parametric tests introduced in this chapter are very robust against normality 
assumption violations, especially when the data are distributed symmetrically. That is, 
small departures from normality usually translate into marginal differences in the p-val-
ues, particularly when using sample sizes greater than 30 (Boneau 1960). Therefore, when 
the Shapiro&mdash;Wilk test suggests the data are not normally distributed, we don&rsquo;t have to be 
concerned that the parametric test results are far off (Norman, 2010), provided we have 
sample sizes greater than 30. The same holds for the ANOVA in cases where the sample 
sizes per group exceed 30. Nevertheless, if non-normality is an issue, you should use a 
non-parametric test that is not based on the normality assumption.
</p>
<p>We may also have a situation in which the data are normally distributed, but the vari-
ances between two or more groups of data are unequal. This issue is generally unproblem-
atic as long as the group-specific sample sizes are (nearly) equal. If group-size sample sizes 
are different, we recommend using parametric tests, such as the two-samples t-tests and 
the ANOVA, in combination with tests that withstand or correct the lack of equal group 
variances, such as Welch&rsquo;s correction. Welch&rsquo;s modified test statistic (Welch 1951) adjusts 
the underlying parametric tests if the variances are not homogenous in order to control 
for a type I error. This is particularly valuable when population variances differ and groups 
comprise very unequal sample sizes. In sum, when samples are normally distributed, but 
the equality of the variance assumption is violated (i.e., the outcome variable is not dis-
tributed equally across three or more groups), we choose a parametric test with Welch&rsquo;s 
correction. Depending on the testing situation this can be: an independent samples t-test 
with Welch's correction or a one-way ANOVA F-test with Welch&rsquo;s correction.</p>
<p/>
</div>
<div class="page"><p/>
<p>164 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>Finally, when both the normality and equality of variance assumptions are violated, 
non-parametric tests can be chosen directly. In the following, we briefly discuss these 
non-parametric tests.
</p>
<p>z Non-parametric tests
As indicated in . Table&nbsp;6.2, there is a non-parametric equivalent for each parametric test. 
This would be important if the distributions are not symmetric. For single samples, the 
Wilcoxon signed-rank test is the equivalent of one sample t-test, which is used to test the 
hypothesis that the population median is equal to a fixed value. For two group comparisons 
with independent samples, the Mann-Whitney U test (also called the Wilcoxon rank-sum 
test, or Wilcoxon&mdash;Mann&mdash;Whitney test) is the equivalent of the independent t-test, while, 
for paired samples, this is the Wilcoxon matched-pairs signed-rank test. The Mann-Whitney 
U test uses the null hypothesis that the distributions of the two independent groups being 
considered (e.g., randomly assigned high and low performing stores) have the same shape 
(Mann and Whitney 1947). In contrast to an independent samples t-test, the Mann-Whit-
ney U test does not compare the means, but the two groups&rsquo; median scores. Although we 
will not delve into the statistics behind the test, it is important to understand its logic.2 The 
Mann-Whitney U test is based on ranks and measures the differences in location (Liao 
2002). The test works by first combining the separate groups into a single group. Subse-
quently, each outcome variable score (e.g., sales) is sorted and ranked in respect of each 
condition based on the values, with the lowest rank assigned to the smallest value. The 
ranks are then averaged based on the conditions (e.g., high versus low performing stores) 
and the test statistic U calculated. The test statistic represents the difference between the 
two rank totals. That is, if the distribution of the two groups is identical, then the sum of the 
ranks in one group will be the same as in the other group. The smaller the p-value (which 
will be discussed later in this chapter), the lower the likelihood that the two distributions&rsquo; 
similarities have occurred by chance; the opposite holds if otherwise.
</p>
<p>The Kruskal-Wallis rank test (labelled Kruskal-Wallis H in SPSS) is the non-paramet-
ric equivalent of the ANOVA. The null hypothesis of the Kruskal-Wallis rank test is that 
the distribution of the test variable across group sub-samples is identical (Schuyler 2011). 
Given that the emphasis is on the distribution rather than on a point estimate, rejecting 
the null hypothesis implies that such distributions vary in their dispersion, central ten-
dency and/or variability. According to Schuyler (2011) and Liao (2002), the following are 
the steps when conducting this test: First, single group categories are combined into one 
group with various categories. Next, objects in this variable (e.g., stores/campaigns) are 
sorted and ranked based on their associations with the dependent variable (e.g., sales), 
with the lowest rank assigned to the smallest value. Subsequently, the categorical variable 
is subdivided to reestablish the original single comparison groups. Finally, each group&rsquo;s 
sum of its ranks is entered into a formula that yields the calculated test statistic. If this cal-
culated statistic is higher than the critical value, the null hypothesis is rejected. The test 
statistic of the Kruskal-Wallis rank follows a χ2 distribution with k&minus;1&nbsp;degrees of freedom. 
In the ⤓ Web Appendix (&rarr; Downloads), we discuss the χ2-tests.
</p>
<p>2 The exact calculation of this test is shown on https://www.ibm.com/support/knowledgecenter/en/
</p>
<p>SSLVMB_20.0.0/com.ibm.spss.statistics.help/alg_npar_tests_mannwhitney.htm
</p>
<p>6</p>
<p/>
<div class="annotation"><a href="https://www.ibm.com/support/knowledgecenter/en/SSLVMB_20.0.0/com.ibm.spss.statistics.help/alg_npar_tests_mannwhitney.htm">https://www.ibm.com/support/knowledgecenter/en/SSLVMB_20.0.0/com.ibm.spss.statistics.help/alg_npar_tests_mannwhitney.htm</a></div>
<div class="annotation"><a href="https://www.ibm.com/support/knowledgecenter/en/SSLVMB_20.0.0/com.ibm.spss.statistics.help/alg_npar_tests_mannwhitney.htm">https://www.ibm.com/support/knowledgecenter/en/SSLVMB_20.0.0/com.ibm.spss.statistics.help/alg_npar_tests_mannwhitney.htm</a></div>
</div>
<div class="page"><p/>
<p>6165
6.3 &middot; Testing Hypotheses on One Mean
</p>
<p>6.3.3.4 Specify the Region of Rejection
</p>
<p>Finally, depending on the formulated hypothesis (i.e., directional versus non-directional), 
we should decide on whether the region of rejection is on one side (a one-tailed test) or on 
both sides (a two-tailed test) of the sampling distribution. In statistical significance testing, 
a one-tailed test and a two-tailed test are alternative ways of computing the statistical sig-
nificance of a test statistic, depending on whether the hypothesis is expressed direction-
ally (i.e., &lt; or &gt; in case of a one-tailed test) or not (i.e., &ne; in case of a two-tailed test). The 
word tail is used, because the extremes of distributions are often small, as in the normal 
distribution or bell curve shown in . Fig.&nbsp;6.3 later in this chapter.
</p>
<p>Even for directional hypotheses, researchers typically use two-tailed tests (Van Belle 
2008). This is because two-tailed tests have strong advantages; they are stricter (and there-
fore generally considered more appropriate) and can also reject a hypothesis when the 
effect is in an unexpected direction. The use of two-tailed testing for a directional hypoth-
esis is also valuable, as it identifies significant effects that occur in the opposite direction 
from the one anticipated. Imagine that you have developed an advertising campaign that 
you believe is an improvement on an existing campaign. You wish to maximize your ability 
to detect the improvement and opt for a one-tailed test. In doing so, you do not test for 
the possibility that the new campaign is significantly less effective than the old campaign. 
As discussed in various studies (e.g., Ruxton and Neuhaeuser 2010; Van Belle 2008), one-
tailed tests should only be used when the opposite direction is theoretically meaningless 
or impossible (e.g., Field 2013; Kimmel 1957). For example, when testing if sales number 
</p>
<p>&copy; NiseriN/Getty Images/iStock
</p>
<p>https://www.guide-market-research.com/app/download/13488667027/SPSS+3rd_Chapter+6_Chi-
</p>
<p>square+test.pdf?t=1516713011</p>
<p/>
<div class="annotation"><a href="https://www.guide-market-research.com/app/download/13488667027/SPSS+3rd_Chapter+6_Chi-square+test.pdf?t=1516713011">https://www.guide-market-research.com/app/download/13488667027/SPSS+3rd_Chapter+6_Chi-square+test.pdf?t=1516713011</a></div>
<div class="annotation"><a href="https://www.guide-market-research.com/app/download/13488667027/SPSS+3rd_Chapter+6_Chi-square+test.pdf?t=1516713011">https://www.guide-market-research.com/app/download/13488667027/SPSS+3rd_Chapter+6_Chi-square+test.pdf?t=1516713011</a></div>
</div>
<div class="page"><p/>
<p>166 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>of innovations are greater than zero, it does not make sense to consider negative values as 
negative sales cannot occur. In such a situation testing for negative outcomes is meaningless 
because such possibilities are ruled out beforehand. The use of two-tailed tests can seem 
counter to the idea of hypothesis testing, because two-tailed tests, by their very nature, 
do not reflect any directionality in a hypothesis. However, in many situations when we 
have clear expectations (e.g., sales are likely to increase), the opposite is also a possibility.
</p>
<p>Overall, the region of rejection for the one-sample t-test and the two-samples t-test can 
either be one or two-tailed (however, we recommend the use of two-tailed tests). Although 
the alternative hypothesis in the ANOVA analysis is non-directional by nature, the under-
lying F-statistic&mdash;used to make inferences about group differences&mdash;is based on the F-dis-
tribution that is right-skewed. Specifically, the F-statistic is a ratio of two variances and as 
variances are always positive, the F-ratio is never negative. This means that although the 
underlying alternative hypothesis for the ANOVA analysis is two-sided, all the group dif-
ferences are assumed to be in the same side of the sampling distribution. We discuss this 
point in more detail later in this chapter.
</p>
<p>6.3.4 Calculate the Test Statistic
</p>
<p>Having formulated the study&rsquo;s main hypothesis, the significance level, and the type of test, 
we can now proceed with calculating the test statistic by using the sample data at hand. 
The test statistic is calculated by using the sample data, to assess the strength of evidence 
in support of the null hypothesis (Agresti and Finlay 2014). In our example, we want to 
compare the mean with a given standard of 45&nbsp;units. Hence, we make use of a one-sample 
t-test, whose test statistic is computed as follows:
</p>
<p>t
x
</p>
<p>sx
=
&minus;&micro;
</p>
<p> 
</p>
<p>Here x  is the sample mean, &micro; is the hypothesized population mean, and sx the standard 
error (i.e., the standard deviation of the sampling distribution). Let&rsquo;s first look at the for-
mula&rsquo;s numerator, which describes the difference between the sample mean x  and the 
hypothesized population mean &micro;. If the point of sale display was highly successful, we 
would expect x  to be higher than  &micro;, leading to a positive difference between the two in the 
formula&rsquo;s numerator. Alternatively, if the point of sale display was not effective, we would 
expect the opposite to be true. This means that the difference between the hypothesized 
population mean and the sample mean can go either way, implying a two-sided test. Using 
the data from the second column of . Table&nbsp;6.1, we can compute the marginal mean of  
the point of sales display campaign as follows:
</p>
<p>x
n
</p>
<p>x
</p>
<p>i
</p>
<p>n
</p>
<p>i= = + +&hellip;+ +( )=
=
&sum;1 1
</p>
<p>10
50 52 51 44 47 30
</p>
<p>1
</p>
<p>.  
</p>
<p>When comparing the calculated sample mean (47.30) with the hypothesized value of 45, 
we obtain a difference of 2.30:
</p>
<p>x&minus; = &minus; =&micro; 47 30 45 2 30. .  
</p>
<p>6</p>
<p/>
</div>
<div class="page"><p/>
<p>6167
6.3 &middot; Testing Hypotheses on One Mean
</p>
<p>At first sight, it appears as if the campaign was effective as sales during the time of the cam-
paign were higher than those that the store normally experiences. However, as discussed 
before, we have not yet considered the variation in the sample. This variation is accounted 
for by the standard error of  x  (indicated as  sx ), which represents the uncertainty of the 
sample estimate.
</p>
<p>This sounds very abstract, so what does it mean? The sample mean is used as an esti-
mator of the population mean; that is, we assume that the sample mean can be a substi-
tute for the population mean. However, when drawing different samples from the same 
population, we are likely to obtain different sample means. The standard error tells us 
how much variance there probably is in the mean across different samples from the same 
population.
</p>
<p>Why do we have to divide the difference  x&minus;&micro;  by the standard error  sx ? We do this 
because when the standard error is very low (there is a low level of variation or uncertainty 
in the data), the value in the test statistic&rsquo;s denominator is also small, which results in a 
higher value for the t-test statistic. Higher t-values favor the rejection of the null hypoth-
esis. In other words, the lower the standard error  sx , the greater the probability that the 
population represented by the sample truly differs from the hypothesized value of 45.
</p>
<p>But how do we compute the standard error? We do so by dividing the sample standard 
deviation (s) by the square root of the number of observations (n), as follows:
</p>
<p>s
s
</p>
<p>n
</p>
<p>n
x x
</p>
<p>n
x
</p>
<p>i
</p>
<p>n
</p>
<p>i
= = &minus;
</p>
<p>&minus;&sum; =
1
</p>
<p>1 1
2( )
</p>
<p> 
</p>
<p>As we can see, a low standard deviation s decreases the standard error (which means less 
ambiguity when making inferences from these data). That is, less variation in the data 
decreases the standard error, thus favoring the rejection of the null hypothesis. Note that 
the standard error also depends on the sample size n. By increasing the number of obser-
vations, we have more information available, thus reducing the standard error.
</p>
<p>If you understand this basic principle, you will have no problems understanding most 
other statistical tests. Let&rsquo;s go back to the example and compute the standard error as 
follows:
</p>
<p>sx =
&minus;
</p>
<p>&minus;( ) +&hellip;+ &minus;( )

</p>
<p>
 = &asymp;
</p>
<p>1
</p>
<p>10 1
50 47 30 44 47 30
</p>
<p>10
</p>
<p>3 199
</p>
<p>10
1 012
</p>
<p>2 2
. .
</p>
<p>.
.  
</p>
<p>Thus, the result of the test statistic is:
</p>
<p>t
x
</p>
<p>sx
=
&minus;
= &asymp;
&micro; 2 30
</p>
<p>1 012
2 274
</p>
<p>.
</p>
<p>.
.  
</p>
<p>This test statistic applies when we compute a sample&rsquo;s standard deviation. In some situ-
ations, however, we might know the population&rsquo;s standard deviation, which requires the 
use of a different test, the z-test (see Box 6.3).</p>
<p/>
</div>
<div class="page"><p/>
<p>168 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>6.3.5 Make the Test Decision
</p>
<p>Once we have calculated the test statistic, we can decide how likely it is that the claim stated 
in the hypothesis is correct. This is done by comparing the test statistic with the critical 
value that it must exceed (Option 1). Alternatively, we can calculate the actual probability 
of making a mistake when rejecting the null hypothesis and compare this value with the 
significance level (Option 2). In the following, we discuss both options.
</p>
<p>6.3.5.1 Option 1: Compare the Test Statistic with the Critical Value
</p>
<p>To make a test decision, we must first determine the critical value, which the test statistic 
must exceed for the null hypothesis to be rejected. In our case, the critical value comes 
from a t-distribution and depends on three parameters:
1. The significance level,
2. the degrees of freedom, and
3. one-tailed versus two-tailed testing.
</p>
<p>We have already discussed the first point, so let&rsquo;s focus on the second. The degrees of 
freedom (usually abbreviated as df) represent the amount of information available to esti-
mate the test statistic. In general terms, an estimate&rsquo;s degrees of freedom are equal to the 
amount of independent information used (i.e., the number of observations) minus the 
number of parameters estimated. Field (2013) provides a great explanation, which we 
adapted and present in Box 6.4.
</p>
<p>In our example, we count n&minus;1 or 10&minus;1&nbsp;=&nbsp;9&nbsp;degrees of freedom for the t-statistic to test a 
two-sided hypothesis of one mean. Remember that for a two-tailed test, when α is 0.05, the 
cumulative probability distribution is 1&minus;α/2 or 1&minus;0.05/2&nbsp;=&nbsp;0.975. We divide the significance 
</p>
<p>3 The fundamental difference between the z- and t-distributions is that the t-distribution is dependent 
</p>
<p>on sample size n (which the z-distribution is not). The distributions become more similar with larger 
</p>
<p>values of n.
</p>
<p>Box 6.3 The z-test
</p>
<p>In the previous example, we used sample data to calculate the standard error  sx . If we know the 
population&rsquo;s standard deviation beforehand, we should use the z-test. The z-test follows a normal 
</p>
<p>(instead of a t-distribution).3 The z-test is also used in situations when the sample size exceeds 30, 
</p>
<p>because the t-distribution and normal distribution are similar for n&nbsp;&gt;&nbsp;30. As the t-test is slightly 
</p>
<p>more accurate (also when the sample size is greater than 30), SPSS uses the t-test. The z-test&rsquo;s 
</p>
<p>statistic closely resembles the t-test and is calculated as follows:
</p>
<p>z
x
</p>
<p>x
</p>
<p>=
&minus;&micro;
</p>
<p>σ
 
</p>
<p>The only minor difference is that we do not write  sx  but  σx in the denominator. It&rsquo;s the same 
principle, but the Greek symbol indicates that the measure refers to a (known) population value 
</p>
<p>and not to the sample. If, for example, we assumed that standard deviation in the population is 
</p>
<p>2.5, we would obtain the following test statistic:
</p>
<p> 
σx = =
</p>
<p>2 5
</p>
<p>10
0 791
</p>
<p>.
.
</p>
<p> 
and, finally,
</p>
<p>  
z= =
</p>
<p>2 30
</p>
<p>0 791
2 909
</p>
<p>.
</p>
<p>.
.
</p>
<p>6</p>
<p/>
</div>
<div class="page"><p/>
<p>6169
6.3 &middot; Testing Hypotheses on One Mean
</p>
<p>level by two, because half of our alpha tests the statistical significance in the lower tail of 
the distribution (bottom 2.5&nbsp;%) and half in the upper tail of the distribution (top 2.5&nbsp;%). If 
the value of the test statistic is greater than the critical value, we can reject the H0.
</p>
<p>We can find critical values for combinations of significance levels and degrees 
of freedom in the t-distribution table, shown in Table A1 in the ⤓ Web Appendix  
(&rarr; Downloads). For 9&nbsp;degrees of freedom and using a significance level of, for example, 
5&nbsp;%, the critical value of the t-statistic is 2.262. Remember that we have to look at the 
α&nbsp;=&nbsp;0.05/2&nbsp;=&nbsp;0.025 column, because we use a two-tailed test. This means that for the prob-
ability of a type I error (i.e., falsely rejecting the null hypothesis) to be less than or equal 
to 5&nbsp;%, the value of the test statistic must be 2.262 or greater. In our case, the test statistic 
(2.274) exceeds the critical value (2.262), which suggests that we should reject the null 
hypothesis.4 Even though the difference between the values is very small, bear in mind 
that hypothesis testing is binary&mdash;we either reject or don&rsquo;t reject the null hypothesis. This 
is also the reason why a statement such as &ldquo;the result is highly significant&rdquo; is inappropriate.
</p>
<p>. Figure&nbsp;6.3 summarizes this concept graphically. In this figure, you can see that the crit-
ical value tcritical for an α-level of 5&nbsp;% with 9&nbsp;degrees of freedoms equals &plusmn; 2.262 on both sides 
of the distribution. This is indicated by the two rejection regions left and right on the inter-
section of the vertical line and the curve. These two rejection areas are the upper 2.5&nbsp;% and 
bottom 2.5&nbsp;% while the remaining 95&nbsp;% non-rejection region is in the middle. Since the test 
statistic ttest (indicated by the line saying ttest 2.274) falls in the right rejection area, we reject 
the null hypothesis.
</p>
<p>. Table&nbsp;6.3 summarizes the decision rules for rejecting the null hypothesis for differ-
ent types of t-tests, where ttest describes the test statistic and tcritical the critical value for a 
specific significance level α. Depending on the test&rsquo;s formulation, test values may well be 
negative (e.g., &minus;2.262). However, due to the symmetry of the t-distribution, only positive 
critical values are displayed.
</p>
<p>Box 6.4&nbsp;Degrees of freedom
</p>
<p>Suppose you have a soccer team and 11 slots on the playing field. When the first player arrives, 
</p>
<p>you have the choice of 11 positions in which you can place him or her. By allocating the player to a 
</p>
<p>position, this occupies one position. When the next player arrives, you can choose from 10 positions. 
</p>
<p>With every additional player who arrives, you have fewer choices where to position him or her. With 
</p>
<p>the very last player, you no longer have the freedom to choose where to put him or her&mdash;there is 
</p>
<p>only one spot left. Thus, there are 10&nbsp;degrees of freedom. You have some degree of choice with 10 
</p>
<p>players, but for 1 player you don&rsquo;t. The degrees of freedom are the number of players minus 1.
</p>
<p>4 To obtain the critical value, you can also use the TINV function provided in Microsoft Excel, whose 
</p>
<p>general form is &ldquo;TINV(α, df).&rdquo; Here, α represents the desired Type I error rate and df the degrees of free-
</p>
<p>dom. To carry out this computation, open a new Excel spreadsheet and type in &ldquo;&nbsp;=&nbsp;TINV(2*0.025,9).&rdquo; 
</p>
<p>Note that we have to specify &ldquo;2*0.025&rdquo; (or, directly 0.05) under α, because we are applying a two-
</p>
<p>tailed instead of a one-tailed test.
</p>
<p>Figure&nbsp;6.3 is static but using the animation on https://homepage.divms.uiowa.edu/~mbognar/
</p>
<p>applets/normal.html, you can change, for example, the rejection areas and/or toggle between 
</p>
<p>one- and two-sided rejection regions.</p>
<p/>
<div class="annotation"><a href="https://homepage.divms.uiowa.edu/~mbognar/applets/normal.html">https://homepage.divms.uiowa.edu/~mbognar/applets/normal.html</a></div>
<div class="annotation"><a href="https://homepage.divms.uiowa.edu/~mbognar/applets/normal.html">https://homepage.divms.uiowa.edu/~mbognar/applets/normal.html</a></div>
</div>
<div class="page"><p/>
<p>170 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>6.3.5.2 Option 2: Compare the p-Value with the Significance Level
</p>
<p>The above might make you remember your introductory statistics course with horror. The 
good news is that we do not have to bother with statistical tables when working with SPSS. 
SPSS automatically calculates the probability of obtaining a test statistic that is at least as 
extreme as the actually observed one if the null hypothesis is supported. This probability 
is also referred to as the p-value or the probability of observing a more extreme departure 
from the null hypothesis (Everitt and Skrondal 2010).
</p>
<p>&copy; Wittayayut/Getty Images/iStock
</p>
<p>https://homepage.divms.uiowa.edu/~mbognar/applets/normal.html
</p>
<p>The t-distribution for 9 degrees of freedom
Two-tailed test and a=0.05
</p>
<p>95% of area
</p>
<p>under the curve
</p>
<p>   = 2.5% to
the right
</p>
<p>  = 2.5%
to the left
</p>
<p>t
test
</p>
<p>2.274
</p>
<p>&ndash;2.262
</p>
<p>t
critical
</p>
<p>t-value
2.262
</p>
<p>t
critical
</p>
<p>. Fig.&nbsp;6.3 Relationship between test value, critical value, and p-value
</p>
<p>6</p>
<p/>
<div class="annotation"><a href="https://homepage.divms.uiowa.edu/~mbognar/applets/normal.html">https://homepage.divms.uiowa.edu/~mbognar/applets/normal.html</a></div>
</div>
<div class="page"><p/>
<p>6171
6.3 &middot; Testing Hypotheses on One Mean
</p>
<p>In the previous example, the p-value is the answer to the following question: If the 
population mean is not equal to 45 (i.e., therefore, the null hypothesis holds), what is the 
probability that random sampling could lead to a test statistic value of at least &plusmn; 2.274? 
This description shows that there is a relationship between the p-value and the test statis-
tic. More precisely, these two measures are inversely related; the higher the absolute value 
of the test statistic, the lower the p-value and vice versa (see . Fig.&nbsp;6.3).
</p>
<p>&gt; The description of the p-value is similar to the significance level α, which describes 
the acceptable probability of rejecting a true null hypothesis. However, the difference 
</p>
<p>is that the p-value is calculated using the sample, and that α is set by the researcher 
</p>
<p>before the test outcome is observed.5 The p-value is not the probability of the null 
</p>
<p>hypothesis being supported! Instead, we should interpret it as evidence against the 
</p>
<p>null hypothesis. The α-level is an arbitrary and subjective value that the researcher 
</p>
<p>assigns to the level of risk of making a type I error; the p-value is calculated from the 
</p>
<p>available data. Related to this subjectivity, there has been a revived discussion in 
</p>
<p>the literature on the usefulness of p-values (e.g., Nuzzo 2014; Wasserstein and Lazar 
</p>
<p>2016) and a suitable threshold (Benjamin et al. 2017; Lakens et al. 2017).
</p>
<p>The comparison of the p-value and the significance level allows the researcher to decide 
whether or not to reject the null hypothesis. Specifically, if the p-value is smaller than 
the significance level, we reject the null hypothesis. Thus, when examining test results, 
we should make use of the following decision rule&mdash;this should become second nature!6
</p>
<p> 4 p-value &le; α &rarr; reject H0
 4 p-value &gt; α &rarr; do not reject H0
</p>
<p>Note that this decision rule applies to two-tailed tests. If you apply a one-tailed test, you need 
to divide the p-value in half before comparing it to α, leading to the following decision rule:7
</p>
<p> 4 p-value/2&nbsp;&le;&nbsp;α &rarr; reject H0
 4 p-value/2&nbsp;&gt;&nbsp;α &rarr; do not reject H0
</p>
<p>. Table 6.3 Decision rules for testing decisions
</p>
<p>Type of test Null hypothesis (H0) Alternative hypothesis 
(H1)
</p>
<p>Reject H0 if
</p>
<p>Right-tailed test μ &le; value μ &gt; value  t ttest critical&gt; ( )α
</p>
<p>Left-tailed test μ &ge; value μ &lt; value  t ttest critical&gt; ( )α
</p>
<p>Two-tailed test μ&nbsp;=&nbsp;value μ &ne; value
t ttest critical&gt;
</p>
<p>





α
</p>
<p>2
</p>
<p>5 Unfortunately, there is some confusion about the difference between the α and p-value. See Hub-
</p>
<p>bard and Bayarri (2003) for a discussion.
</p>
<p>6 Note that this is convention and most textbooks discuss hypothesis testing in this way. Originally, 
</p>
<p>two testing procedures were developed, one by Neyman and Pearson and another by Fisher (for 
</p>
<p>more details, see Lehmann 1993). Agresti and Finlay (2014) explain the differences between the con-
</p>
<p>vention and the two original procedures.
</p>
<p>7 Note that this rule doesn't always apply such as for exact tests of probabilities.</p>
<p/>
</div>
<div class="page"><p/>
<p>172 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>In our example, the actual two-tailed p-value is 0.049 for a test statistic of &plusmn; 2.274, just 
below the significance level of 0.05. We can therefore reject the null hypothesis and find 
support for the alternative hypothesis.8
</p>
<p>8 We don&rsquo;t have to conduct manual calculations and tables when working with SPSS. However, we 
</p>
<p>can calculate the p-value using the TDIST function in Microsoft Excel. The function has the general 
</p>
<p>form &ldquo;TDIST(t, df, tails)&rdquo;, where t describes the test value, df the degrees of freedom, and tails specifies 
</p>
<p>whether it&rsquo;s a one-tailed test (tails&nbsp;=&nbsp;1) or two-tailed test (tails&nbsp;=&nbsp;2). Just open a new spreadsheet for 
</p>
<p>our example and type in &ldquo;&nbsp;=&nbsp;TDIST(2.274,9,1)&rdquo;. Likewise, there are several webpages with Java-based 
</p>
<p>modules (e.g., https://graphpad.com/quickcalcs/pvalue1.cfm) that calculate p-values and test statis-
</p>
<p>tic values.
</p>
<p>6.3.6 Interpret the Results
</p>
<p>The conclusion reached by hypothesis testing must be expressed in terms of the market 
research problem and the relevant managerial action that should be taken. In our example, 
we conclude that there is evidence that the point of sale display influenced the number of 
sales significantly during the week it was installed.
</p>
<p>There is another way of hypothesis testing without applying a significance test. Instead 
</p>
<p>of following the steps just described, we can construct a 100(1&minus;α)% confidence interval 
</p>
<p>for μ. The confidence interval is a range of values calculated, which includes the desired 
</p>
<p>true parameter (here, the population mean μ) with a certain probability that we need 
</p>
<p>to define in advance. The confidence interval has a number of critical ingredients, the 
</p>
<p>estimate itself, the standard deviation of the sample, the sample size, the distribution 
</p>
<p>belonging to these estimates, and the confidence level (typically 95&nbsp;% but 90&nbsp;% or 99&nbsp;% 
</p>
<p>are also common). The boundaries of the mean&rsquo;s confidence interval are defined as:
</p>
<p> 5 Lower boundary:  x t scritical x&minus;





&sdot;
α
</p>
<p>2
</p>
<p> 5 Upper boundary:  x t scritical x+





&sdot;
α
</p>
<p>2
</p>
<p>In other words, the confidence interval is defined as:  
</p>
<p>x t s x t scritical x critical x&minus;





&sdot; +
</p>
<p>




&sdot;
</p>
<p>
</p>
<p>

</p>
<p>α α
</p>
<p>2 2
;
</p>
<p>
</p>
<p>
 . In our case, the confidence interval looks like this:
</p>
<p>47 3 2 262 1 012 47 3 2 262 1 012 45 01 49 59. . . ; . . . . ; .&minus; &sdot; + &sdot;( )= ( )  
</p>
<p>From this, we would conclude that the true population mean, with 95&nbsp;% certainty, lies 
</p>
<p>in the range of 45.01 and 49.59. As we can see, the 95&nbsp;% confidence interval does not 
</p>
<p>include 45. Hence, we reject the null hypothesis and conclude that the population 
</p>
<p>mean is not 45. Indeed, from the lower and upper boundaries, we can see that the 
</p>
<p>population mean is likely larger than 45.
</p>
<p>Tip
</p>
<p>6</p>
<p/>
<div class="annotation"><a href="https://graphpad.com/quickcalcs/pvalue1.cfm">https://graphpad.com/quickcalcs/pvalue1.cfm</a></div>
</div>
<div class="page"><p/>
<p>6173
6.4 &middot; Two-Samples t-test
</p>
<p>6.4 Two-Samples t-test
</p>
<p>6.4.1 Comparing Two Independent Samples
</p>
<p>Testing the relationship between two independent samples is very common in market 
research. Some common research questions are:
 4 Do heavy and light users&rsquo; satisfaction with a product differ?
 4 Do male customers spend more money online than female customers?
 4 Do US teenagers spend more time on Facebook than Australian teenagers?
</p>
<p>Each of these hypotheses aim at evaluating whether two populations (e.g., heavy and light 
users), represented by samples, are significantly different in terms of certain key variables 
(e.g., satisfaction ratings).
</p>
<p>To understand the principles of a two independent samples t-test, let&rsquo;s reconsider the 
previous example of a promotion campaign in a department store. Specifically, we want 
to test whether the population mean of the point of sale display&rsquo;s sales (&micro;1) differs in any 
(positive or negative) way from that of the free tasting stand (&micro;2). The resulting two-sided 
null and alternative hypotheses are now:
</p>
<p>H0 1 2:&micro; &micro;=  
</p>
<p>H1 1 2:&micro; &micro;&ne;  
</p>
<p>The test statistic of the two independent samples t-test&mdash;which is now distributed with 
n1&nbsp;+&nbsp;n2 &minus;2&nbsp;degrees of freedom&mdash;is similar to the one-sample t-test:
</p>
<p>t
x x
</p>
<p>sx x
=
</p>
<p>&minus;( )&minus; &minus;( )
</p>
<p>&minus;
</p>
<p>1 2 1 2
</p>
<p>1 2
</p>
<p>&micro; &micro;
,
 
</p>
<p>where  x1  is the mean of the first sample (with n1 numbers of observations) and  x2  is the 
mean of the second sample (with n2 numbers of observations). The term  &micro; &micro;1 2&minus; descri
bes the hypothesized difference between the population means. In this case,  &micro; &micro;1 2&minus;  is 
zero, as we assume that the means are equal, but we could use any other value to hypothe-
size a specific difference in population means. Lastly,  sx x1 2&minus;
</p>
<p>describes the standard error, 
which comes in two forms:
</p>
<p> 4 If we assume that the two populations have the same variance (i.e.,  σ σ1
2
</p>
<p>2
2= ), we 
</p>
<p>compute the standard error based on the so called pooled variance estimate:
</p>
<p>s
n n
</p>
<p>n nx x1 2
1 1
</p>
<p>2
2 2
</p>
<p>2
</p>
<p>1 2 1 2
</p>
<p>1 1
</p>
<p>2
</p>
<p>1 1
&minus; =
</p>
<p>&minus;( )&sdot; + &minus;( )&sdot;


</p>
<p>+ &minus;
+
</p>
<p>s s
</p>
<p>n n  
</p>
<p> 4 Alternatively, if we assume that the population variances differ (i.e., σ σ1
2
</p>
<p>2
2&ne; ), we 
</p>
<p>compute the standard error, using Welch's correction, as follows:
</p>
<p>sx x1 2
1
2
</p>
<p>1
</p>
<p>2
2
</p>
<p>2
&minus; = +
</p>
<p>s
</p>
<p>n
</p>
<p>s
</p>
<p>n  </p>
<p/>
</div>
<div class="page"><p/>
<p>174 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>How do we determine whether the two populations have the same variance? As discussed 
previously, this is done using Levene&rsquo;s test, which tests the following hypotheses:
</p>
<p>H0 1
2
</p>
<p>2
2:σ σ=  
</p>
<p>H1 1
2
</p>
<p>2
2:σ σ&ne;  
</p>
<p>The null hypothesis is that the two population variances are the same and the alterna-
tive hypothesis is that they differ. In this example, Levene&rsquo;s test provides support for the 
assumption that the variances in the population are equal, which allows us to proceed 
with the pooled variance estimate. First, we estimate the variances of the first and second 
group as follows:
</p>
<p>s
n
</p>
<p>x x
</p>
<p>i
</p>
<p>1
2
</p>
<p>1 1
</p>
<p>10
</p>
<p>1 1
</p>
<p>2 2 21
</p>
<p>1
</p>
<p>1
</p>
<p>10 1
50 47 30 44 47 30=
</p>
<p>&minus;
&minus;( ) =
</p>
<p>&minus;
&minus;( ) +&hellip;+ &minus;( )
</p>
<p>

</p>
<p>=
&sum; . .  &asymp;10 233.
</p>
<p> 
</p>
<p>s
n
</p>
<p>x x
</p>
<p>i
</p>
<p>2
2
</p>
<p>2 1
</p>
<p>10
</p>
<p>2 2
</p>
<p>2 2 21
</p>
<p>1
</p>
<p>1
</p>
<p>10 1
55 52 44 52 17=
</p>
<p>&minus;
&minus;( ) =
</p>
<p>&minus;
&minus;( ) +&hellip;+ &minus;( )
</p>
<p>


&asymp;
</p>
<p>=
&sum; .5556.  
</p>
<p>Using the variances as input, we can compute the standard error:
</p>
<p>sx x1 2
</p>
<p>10 1 10 233 10 1 17 556
</p>
<p>10 10 2
</p>
<p>1
</p>
<p>10
</p>
<p>1
</p>
<p>10
1 667&minus; =
</p>
<p>&minus; &sdot; + &minus; &sdot;
</p>
<p>+ &minus;
+ &asymp;
</p>
<p>[( ) . . ]
&bull; .
</p>
<p> ( )
 
</p>
<p>Inserting the estimated standard error into the test statistic results in:
</p>
<p>t
x x
</p>
<p>sx x
=
</p>
<p>&minus;( )&minus; &minus;( )
=
</p>
<p>&minus;( )&minus;
&asymp;&minus;
</p>
<p>&minus;
</p>
<p>1 2 1 2
</p>
<p>1 2
</p>
<p>47 30 52 0
</p>
<p>1 667
2 819
</p>
<p>&micro; &micro; .
</p>
<p>.
.
</p>
<p> 
</p>
<p>The test statistic follows a t-distribution with n1&ndash;n2 degrees of freedom. In our case, we 
have 10&nbsp;+&nbsp;10&ndash;2&nbsp;=&nbsp;18&nbsp;degrees of freedom. Looking at the statistical Table A1 in the ⤓ Web 
Appendix (&rarr; Downloads), we can see that the critical value of a two-sided test with a sig-
nificance level of 5&nbsp;% is 2.101 (note that we need to look at the column labeled α&nbsp;=&nbsp;0.025 
and the line labeled df&nbsp;=&nbsp;18). The absolute value of &minus;2.819 is greater than 2.101 and, thus, 
falls within the bottom 2.5&nbsp;% of the distribution (. Table&nbsp;6.3). We can therefore reject the 
null hypothesis at a significance level of 5&nbsp;% and conclude that the absolute difference 
between means of the point of sale display&rsquo;s sales (μ1) and those of the free tasting stand 
(μ2) is significantly different from 0.
</p>
<p>6.4.2 Comparing Two Paired Samples
</p>
<p>In the previous example, we compared the mean sales of two independent samples. If 
the management wants to compare the difference in the units sold before and after they 
started the point of sale display campaign we have a paired-samples case as the sample is 
the same before and after. . Table&nbsp;6.4 shows the sales of the 10 stores before and after the 
point of display and in each case showing the sales in units. You can again assume that the 
data are normally distributed.
</p>
<p>6</p>
<p/>
</div>
<div class="page"><p/>
<p>6175
6.4 &middot; Two-Samples t-test
</p>
<p>At first sight, it appears that the point of sale display generated higher sales: The mar-
ginal mean of the sales in the week during which the point of sale display was installed 
(48) is slightly higher than in the week when it was not (46.10). However, the question is 
whether this difference is statistically significant.
</p>
<p>We cannot assume that we are comparing two independent samples, as each set of two 
samples originates from the same set of stores, but at different points in time and under 
different conditions. Hence, we should use a paired samples t-test. In this example, we want 
to test whether the sales differ significantly with or without the installation of the point of 
sale display. We can express this by using the following hypotheses, where μd describes the 
population difference in sales; the null hypothesis assumes that the point of sale display 
made no difference, while the alternative hypothesis assumes a difference in sales:
</p>
<p>H
</p>
<p>H
</p>
<p>0
</p>
<p>1
</p>
<p>:
</p>
<p>:
</p>
<p>&micro;
</p>
<p>&micro;
</p>
<p>d
</p>
<p>d
</p>
<p>=
</p>
<p>&ne;
</p>
<p>0
</p>
<p>0
 
</p>
<p>To carry out this test, we define a new variable di, which captures the differences in sales 
between the two conditions (point of sale display&mdash;no point of sale display) in each of the 
stores. Thus:
</p>
<p>d
</p>
<p>d
</p>
<p>d
</p>
<p>d
</p>
<p>1
</p>
<p>2
</p>
<p>9
</p>
<p>10
</p>
<p>= =
</p>
<p>= =
</p>
<p>&hellip;
</p>
<p>= =
</p>
<p>= =
</p>
<p>50 46 4
</p>
<p>53 51 2
</p>
<p>51 49 2
</p>
<p>44 43 1
</p>
<p>&ndash;
</p>
<p>&ndash;
</p>
<p>&ndash;
</p>
<p>&ndash;
</p>
<p> 
</p>
<p>. Table 6.4 Sales data (extended)
</p>
<p>Store Sales (units)
</p>
<p>Point of sale display No point of sale display
</p>
<p>1 50 46
</p>
<p>2 53 51
</p>
<p>3 43 40
</p>
<p>4 50 48
</p>
<p>5 47 46
</p>
<p>6 45 45
</p>
<p>7 44 42
</p>
<p>8 53 51
</p>
<p>9 51 49
</p>
<p>10 44 43
</p>
<p>Marginal mean 48 46.10</p>
<p/>
</div>
<div class="page"><p/>
<p>176 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>Based on these results, we calculate the mean difference:
</p>
<p>d
n
</p>
<p>d
</p>
<p>i
</p>
<p>i= = + + + + =
=
&sum;1 1
</p>
<p>10
4 2 2 1 1 9
</p>
<p>1
</p>
<p>10
</p>
<p>( ) .
 
</p>
<p>as well as the standard error of this difference:
</p>
<p>s n
d d
</p>
<p>nd
i i
</p>
<p>= &minus;
&minus;( )&sum; =
</p>
<p>1
</p>
<p>1 1
</p>
<p>10 2
</p>
<p> 
</p>
<p>=
&minus; + &minus; + + &minus; + &minus;
</p>
<p>&asymp;
</p>
<p>1
</p>
<p>9
4 1 9 2 1 9 2 1 9 1 1 9
</p>
<p>10
0 383
</p>
<p>2 2 2 2[( . ) ( . ) ( . ) ( . ) ]
.
</p>
<p>
 
</p>
<p>Next, we compare the mean difference d  in our sample with the difference expected under 
the null hypothesis μd and divide this difference by the standard error sd . Thus, the test 
statistic is:
</p>
<p>t
d
</p>
<p>s
d
</p>
<p>d
</p>
<p>=
&minus;
</p>
<p>=
&minus;
&asymp;
</p>
<p>&micro; 1 9 0
</p>
<p>0 383
4 960
</p>
<p>.
</p>
<p>.
. .  
</p>
<p>The test statistic follows a t-distribution with n&minus;1&nbsp;degrees of freedom, where n is the 
number of pairs that we compare. Recall that for a two-tailed test, when α is 0.05, we need 
to look at the column labeled α&nbsp;=&nbsp;0.025. Looking at Table A1 in the ⤓ Web Appendix (&rarr; 
Downloads), we can see that the critical value of a two-sided test with a significance level 
of 5&nbsp;% is 2.262 for 9&nbsp;degrees of freedom. Since the test value (4.960) is larger than the crit-
ical value, we can reject the null hypothesis and presume that the point of sale display 
makes a difference.
</p>
<p>6.5 Comparing More Than Two Means: Analysis of Variance 
(ANOVA)
</p>
<p>Researchers are often interested in examining differences in the means between more than 
two groups. For example:
</p>
<p> 4 Do light, medium, and heavy internet users differ in their monthly disposable 
income?
 4 Do customers across four different types of demographic segments differ in their 
</p>
<p>attitude towards a certain brand?
 4 Is there a significant difference in hours spent on Facebook between US, UK, and 
</p>
<p>Australian teenagers?
</p>
<p>Continuing with our previous example on promotion campaigns, we might be interested 
in whether there are significant sales differences between the stores in which the three dif-
ferent types of campaigns were launched. One way to tackle this research question would 
be to carry out multiple pairwise comparisons of all the groups under consideration. In 
this example, doing so would require the following comparisons:
</p>
<p>6</p>
<p/>
</div>
<div class="page"><p/>
<p>6177
6.5 &middot; Comparing More Than Two Means: Analysis of Variance (ANOVA)
</p>
<p>1. The point of sale display versus the free tasting stand,
2. the point of sale display versus the in-store announcements, and
3. the free tasting stand versus the in-store announcements.
</p>
<p>While three comparisons are doable, you can imagine the difficulties when a greater 
number of groups are compared. For example, with ten groups, we would have to carry 
out 45&nbsp;group comparisons.9
</p>
<p>Making large numbers of comparisons induces the severe problem of α-inflation. This 
inflation refers to the more tests that you conduct at a certain significance level, the more 
likely you are to claim a significant result when this is not so (i.e., an increase or inflation 
in the type I error). Using a significance level of α&nbsp;=&nbsp;0.05 and making all possible pairwise 
comparisons of ten groups (i.e., 45 comparisons), the increase in the overall probability 
of a type I error (also referred to as the familywise error rate) is:
</p>
<p>α α* . .= &minus; &minus;( ) = &minus; &minus;( ) =1 1 1 1 0 05 0 901
45 45
</p>
<p> 
</p>
<p>That is, there is a 90.1&nbsp;% probability of erroneously rejecting your null hypothesis in 
at least some of your 45&nbsp;t-tests&mdash;far greater than the 5&nbsp;% for a single comparison! The 
problem is that you can never tell which of the comparisons&rsquo; results are wrong and which 
are correct.
</p>
<p>9 The number of pairwise comparisons is calculated as follows: k&middot;(k&nbsp;&minus;&nbsp;1)/2, with k the number of groups 
</p>
<p>to compare.
</p>
<p>&copy; domin_domin/Getty Images/iStock
</p>
<p>https://www.guide-market-research.com/app/download/13488670527/
</p>
<p>SPSS+3rd_Chapter+6_Two-way+ANOVA.pdf?t=1516713104
</p>
<p>Instead of carrying out many pairwise tests, market researchers use ANOVA, which 
allows a comparison of three or more groups&rsquo; averages. In ANOVA, the variable that dif-
ferentiates the groups is referred to as the factor variable (don&rsquo;t confuse this with the factors </p>
<p/>
<div class="annotation"><a href="https://www.guide-market-research.com/app/download/13488670527/SPSS+3rd_Chapter+6_Two-way+ANOVA.pdf?t=1516713104">https://www.guide-market-research.com/app/download/13488670527/SPSS+3rd_Chapter+6_Two-way+ANOVA.pdf?t=1516713104</a></div>
<div class="annotation"><a href="https://www.guide-market-research.com/app/download/13488670527/SPSS+3rd_Chapter+6_Two-way+ANOVA.pdf?t=1516713104">https://www.guide-market-research.com/app/download/13488670527/SPSS+3rd_Chapter+6_Two-way+ANOVA.pdf?t=1516713104</a></div>
</div>
<div class="page"><p/>
<p>178 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>of factor analysis discussed in 7 Chap.&nbsp;8!). The values of a factor (i.e., as found in respect of 
the different groups under consideration) are also referred to as factor levels.
</p>
<p>In the previous example of promotion campaigns, we considered only one factor vari-
able with three levels, indicating the type of campaign. This is the simplest form of an 
ANOVA and is called a one-way ANOVA. However, ANOVA allows us to consider more 
than one factor variable. For example, we might be interested in adding another grouping 
variable (e.g., the type of service offered), thus increasing the number of treatment con-
ditions in our experiment. ANOVA is even more flexible, because you can also integrate 
interval or ratio-scaled independent variables and even multiple dependent variables as 
well as more than one factor variable (Two-way ANOVA). 
</p>
<p>We now know that the one-way ANOVA is used to examine the mean differences 
between more than two groups. In more formal terms, the objective of the one-way 
ANOVA is to test the null hypothesis that the population means of the groups (defined by 
the factor and its levels) are equal. If we compare three groups, as in the promotion cam-
paign example, the null hypothesis is:
</p>
<p>H : 0 &micro; &micro; &micro;1 2 3= =  
</p>
<p>This hypothesis implies that the population means of all three promotion campaigns are 
identical (which is the same as saying, that the campaigns have the same effect on the mean 
sales). The alternative hypothesis is:
</p>
<p>H1 1 2 3: , , .At least twoof and are unequal&micro; &micro; &micro;  
</p>
<p>Before we even think of running an ANOVA, we should, of course, produce a problem for-
mulation, which requires us to identify the dependent variable and the factor variable, as 
well as its levels. Once this task is done, we can dig deeper into ANOVA by following the 
steps described in . Fig.&nbsp;6.4. We next discuss each step in more detail.
</p>
<p>Calculate the test statistic 
</p>
<p>Check the assumptions 
</p>
<p>Make the test decision 
</p>
<p>Carry out post hoc tests 
</p>
<p>Measure the strength of the effects 
</p>
<p>Interpret the results 
</p>
<p>. Fig.&nbsp;6.4 Steps in conducting an ANOVA
</p>
<p>6</p>
<p/>
</div>
<div class="page"><p/>
<p>6179
6.5 &middot; Comparing More Than Two Means: Analysis of Variance (ANOVA)
</p>
<p>We already touched upon Levene&rsquo;s test and you can learn more about it in ⤓ Web Appendix (&rarr; 
Downloads).
</p>
<p>&copy; virtualphoto/Getty Images/iStock
</p>
<p>https://www.guide-market-research.com/app/download/13488668127/SPSS+3rd_Chapter+6_
</p>
<p>Levene%27s+test.pdf?t=1516713071
</p>
<p>10 In fact, these two assumptions are interrelated, since unequal group sample sizes result in a greater 
</p>
<p>probability that we will violate the homogeneity assumption.
</p>
<p>6.5.1 Check the Assumptions
</p>
<p>ANOVA is a parametric test that relies on the same distributional assumptions as dis-
cussed in 7 Sect.&nbsp;6.3. We may use ANOVA in situations when the dependent variable is 
measured on an ordinal scale and is not normally distributed, but we should then ensure 
that the group-specific sample sizes are similar. Thus, if possible, it is useful to collect 
samples of a similar size for each group. As discussed previously, ANOVA is robust to 
departures from normality with sample sizes greater than 30 per group, meaning that it 
can be performed even when the data are not normally distributed. Even though ANOVA 
is rather robust in this respect, violations of the assumption of the equality of variances 
can bias the results significantly, especially when the groups are of very unequal sample 
size.10 Consequently, we should always test for the equality of variances by using Lev-
ene&rsquo;s test.</p>
<p/>
<div class="annotation"><a href="https://www.guide-market-research.com/app/download/13488668127/SPSS+3rd_Chapter+6_Levene%27s+test.pdf?t=1516713071">https://www.guide-market-research.com/app/download/13488668127/SPSS+3rd_Chapter+6_Levene%27s+test.pdf?t=1516713071</a></div>
<div class="annotation"><a href="https://www.guide-market-research.com/app/download/13488668127/SPSS+3rd_Chapter+6_Levene%27s+test.pdf?t=1516713071">https://www.guide-market-research.com/app/download/13488668127/SPSS+3rd_Chapter+6_Levene%27s+test.pdf?t=1516713071</a></div>
</div>
<div class="page"><p/>
<p>180 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>Finally, like any data analysis technique, the sample size must be sufficiently high to have 
sufficient statistical power. There is general agreement that the bare minimum sample 
size per group is 20. However, 30 or more observations per group are desirable. For more 
detail, see Box 6.1.
</p>
<p>6.5.2 Calculate the Test Statistic
</p>
<p>ANOVA examines the dependent variable&rsquo;s variation across groups and, based on this 
variation, determines whether there is reason to believe that the population means of the 
groups differ. Returning to our example, each store&rsquo;s sales are likely to deviate from the 
overall sales mean, as there will always be some variation. The question is therefore whether 
a specific promotion campaign is likely to cause the difference between each store&rsquo;s sales 
and the overall sales mean, or whether this is due to a natural variation in sales. To disen-
tangle the effect of the treatment (i.e., the promotion campaign type) and the natural vari-
ation, ANOVA separates the total variation in the data (indicated by SST) into two parts:
1) the between-group variation (SSB), and
2) the within-group variation (SSW).
</p>
<p>11
</p>
<p>These three types of variation are estimates of the population variation. Conceptually, the 
relationship between the three types of variation is expressed as:
</p>
<p>SS SS SST B W= +  
</p>
<p>However, before we get into the math, let&rsquo;s see what SSB and SSW are all about.
</p>
<p>z The Between-Group Variation (SSB)
SSB refers to the variation in the dependent variable as expressed in the variation in the 
group means. In our example, it describes the variation in the mean values of sales across 
the three treatment conditions (i.e., point of sale display, free tasting stand, and in-store 
announcements) relative to the overall mean. What does SSB tell us? Imagine a situation 
in which all mean values across the treatment conditions are the same. In other words, 
regardless of which campaign we choose, the sales are the same, we cannot claim that the 
promotion campaigns had differing effects. This is what SSB expresses: it tells us how much 
variation the differences in observations that stem from different groups can explain. Since 
SSB is the explained variation (explained by the grouping of data) and thus reflects differ-
ent effects, we would want it to be as high as possible. However, there is no given standard 
of how high SSB should be, as its magnitude depends on the scale level used (e.g., are we 
looking at 7-point Likert scales or income in US$?). Consequently, we can only interpret 
the explained variation expressed by SSB in relation to the variation that the grouping of 
data does not explain. This is where SSW comes into play.
</p>
<p>11 SS is an abbreviation of &ldquo;sum of squares,&rdquo; because the variation is calculated using the squared differ-
</p>
<p>ences between different types of values.
</p>
<p>6</p>
<p/>
</div>
<div class="page"><p/>
<p>6181
6.5 &middot; Comparing More Than Two Means: Analysis of Variance (ANOVA)
</p>
<p>z The Within-Group Variation (SSW)
As the name already suggests, SSW describes the variation in the dependent variable within 
each of the groups. In our example, SSW simply represents the variation in sales in each of 
the three treatment conditions. The smaller the variation within the groups, the greater 
the probability that the grouping of data can explain all the observed variation. It is obvi-
ously the ideal for this variation to be as small as possible. If there is much variation within 
some or all the groups, then some extraneous factor, not accounted for in the experiment, 
seems to cause this variation instead of the grouping of data. For this reason, SSW is also 
referred to as unexplained variation.
</p>
<p>Unexplained variation can occur if we fail to account for important factors in our 
experimental design. While some unexplained variation will always be present, regard-
less of how sophisticated our experimental design is and how many factors we consider. If 
the unexplained variation cannot be explained, it is called random noise or simply noise.
</p>
<p>z Combining SSB and SSW into an Overall Picture
The comparison of SSB and SSW tells us whether the variation in the data is attributable to 
the grouping, which is desirable, or due to sources of variation not captured by the group-
ing, which is not desirable. . Figure&nbsp;6.5 shows this relationship across the stores featuring 
our three different campaign types:
 4 Point of sale display (&bull;),
 4 free tasting stand (▪), and
 4 in-store announcements (▲).
</p>
<p>2 4 6 8 10 12 14 16 18 20 22 24 26 28 30
</p>
<p>45
</p>
<p>50
</p>
<p>55
</p>
<p>60
</p>
<p>40
</p>
<p>Point of sale display
Free tasting stand
</p>
<p>In-store announcements
</p>
<p>S
a
</p>
<p>le
s
</p>
<p>Store
</p>
<p>. Fig.&nbsp;6.5 Scatter plot of stores with different campaigns vs. sales</p>
<p/>
</div>
<div class="page"><p/>
<p>182 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>We indicate the group mean of each level by dashed lines. If the group means are all the 
same, the three dashed lines are horizontally aligned and we then conclude that the cam-
paigns have identical sales. Alternatively, if the dashed lines are very different, we conclude 
that the campaigns differ in their sales.
</p>
<p>At the same time, we would like the variation within each of the groups to be as small 
as possible; that is, the vertical lines connecting the observations and the dashed lines 
should be short. In the most extreme case, all observations would lie on their group-spe-
cific dashed lines, implying that the grouping explains the variation in sales perfectly. This, 
however, hardly ever occurs.
</p>
<p>If the vertical bars were all, say, twice as long, it would be difficult to draw any conclu-
sions about the effects of the different campaigns. Too great a variation within the groups 
then swamps the variation between the groups. We can calculate the three types of vari-
ation as follows:
1. The total variation, computed by comparing each store&rsquo;s sales with the overall mean  
</p>
<p>x , which is equal to 48 in our example:12
</p>
<p> SS x xT
i
</p>
<p>n
</p>
<p>i= &minus;( ) = &minus;( ) + &minus;( ) +&hellip;+ &minus;( ) + &minus;( ) =
=
&sum;
</p>
<p>1
</p>
<p>2 2 2 2 2
50 48 52 48 47 48 42 48 584
</p>
<p> 
</p>
<p>2. The between-group variation, computed by comparing each group&rsquo;s mean sales with 
the overall mean, is:
</p>
<p>SS n x xB
j
</p>
<p>k
</p>
<p>j j= &minus;
</p>
<p>=
</p>
<p>&sum;
1
</p>
<p>2( )  
</p>
<p>As you can see, besides index i, as previously discussed, we also have index j to represent 
the group sales means. Thus,  x j  describes the mean in the j-th group and nj the number 
of observations in that group. The overall number of groups is denoted with k. The term nj 
is used as a weighting factor: Groups that have many observations should be accounted for 
to a higher degree relative to groups with fewer observations. Returning to our example, 
the between-group variation is then given by:
</p>
<p> 
SSB = &sdot; &minus;( ) + &sdot; &minus;( ) + &sdot; &minus;( ) =10 47 30 48 10 52 48 10 44 70 48 273 80
</p>
<p>2 2 2
. . .
</p>
<p> 
</p>
<p>3. The within-group variation, computed by comparing each store&rsquo;s sales with its group 
sales mean is:
</p>
<p>SS x xw
j
</p>
<p>k
</p>
<p>i
</p>
<p>n
</p>
<p>ij j
</p>
<p>j
</p>
<p>= &minus;( )
= =
&sum;&sum;
</p>
<p>1 1
 
</p>
<p>12 Note that the group-specific sample size in this example is too small to draw conclusions and is only 
</p>
<p>used to show the calculation of the statistics.
</p>
<p>6</p>
<p/>
</div>
<div class="page"><p/>
<p>6183
6.5 &middot; Comparing More Than Two Means: Analysis of Variance (ANOVA)
</p>
<p>Here, we should use two summation signs, because we want to compute the squared dif-
ferences between each store&rsquo;s sales and its group sales&rsquo; mean for all k groups in our set-up. 
In our example, this yields the following:
</p>
<p> 
</p>
<p>SSW = &minus;( ) +&hellip;+ &minus;( )


</p>
<p>

+ &minus;( ) +&hellip;+ &minus;( )

</p>
<p>50 47 30 44 47 30 55 52 44 52
2 2 2 2
</p>
<p>. . 

</p>
<p>+ &minus;( ) +&hellip;+ &minus;( )

</p>
<p>

=45 44 70 42 44 70 310 20
</p>
<p>2 2
. . .  
</p>
<p>In the previous steps, we discussed the comparison of the between-group and within-group 
variation. The higher the between-group variation is in relation to the within-group varia-
tion, the more likely it is that the grouping of the data is responsible for the different levels 
in the stores&rsquo; sales instead of the natural variation in all the sales.
</p>
<p>A suitable way to describe this relation is by forming an index with SSB in the numer-
ator and SSW in the denominator. However, we do not use SSB and SSW directly, because 
they are based on summed values and the scaling of the variables used therefore influence 
them. Therefore, we divide the values of SSB and SSW by their degrees of freedom to obtain 
the true mean square values MSB (called between-group mean squares) and MSW (called 
within-group mean squares). The resulting mean square values are:
</p>
<p>MS
SS
</p>
<p>k
MS
</p>
<p>SS
</p>
<p>n kB
B
</p>
<p>W
W=
</p>
<p>&minus;
=
&minus;1
</p>
<p>,and  
</p>
<p>We use these mean squares to compute the following test statistic, which we then compare 
with the critical value:
</p>
<p>F
MS
</p>
<p>MS
B
</p>
<p>W
</p>
<p>=  
</p>
<p>Turning back to our example, we calculate the test statistic as follows:
</p>
<p>F
MS
</p>
<p>MS
</p>
<p>SS
k
</p>
<p>SS
n k
</p>
<p>B
</p>
<p>W
</p>
<p>B
</p>
<p>W
</p>
<p>= = &minus;
</p>
<p>&minus;
</p>
<p>= &minus;
</p>
<p>&minus;
</p>
<p>&asymp;1
273 80
</p>
<p>3 1
310 20
</p>
<p>30 3
</p>
<p>11 916
.
</p>
<p>.
.  
</p>
<p>6.5.3 Make the Test Decision
</p>
<p>Making the test decision in ANOVA is like the t-tests discussed earlier, with the difference 
that the test statistic follows an F-distribution (as opposed to a t-distribution). Different 
from before, however, we don&rsquo;t have to divide α by 2&nbsp;when looking up the critical value, 
even though the underlying alternative hypothesis in ANOVA is two-sided! The reason 
for this is that an F-test statistic is the ratio of the variation explained by systematic vari-
ance (i.e., between-group mean squares) to the unsystematic variance (i.e., within-group 
mean squares), which is always equal to or greater than 0, but never lower than 0. For this 
reason, and given that no negative values occur, it makes no sense to split the significance 
level in half (Van Belle 2008).</p>
<p/>
</div>
<div class="page"><p/>
<p>184 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>Unlike the t-distribution, the F-distribution depends on two degrees of freedom: One 
corresponding to the between-group mean squares (k&nbsp;&minus;&nbsp;1) and the other referring to 
the within-group mean squares (n&nbsp;&minus;&nbsp;k). The degrees of freedom of the promotion cam-
paign example are 2 and 27; therefore, on examining Table A2 in the ⤓ Web Appendix  
(&rarr; Downloads), we see a critical value of 3.354 for α&nbsp;=&nbsp;0.05. In our example, we reject the 
null hypothesis, because the F-test statistic of 11.916 is greater than the critical value of 
3.354. Consequently, we can conclude that at least two of the population sales means of 
the three types of promotion campaigns differ significantly.
</p>
<p>At first sight, it appears that the free tasting stand is most successful, as it exhibits 
the highest mean sales (x2 52= ) compared to the point of sale display (x1 47 30= . ) and 
the in-store announcements (x3 44 70= . ). However, rejecting the null hypothesis does not 
mean that all the population means differ&mdash;it only means that at least two of the population 
means differ significantly! Market researchers often assume that all means differ signifi-
cantly when interpreting ANOVA results, but this is wrong. How then do we determine 
which of the mean values differ significantly from the others? We deal with this problem 
by using post hoc tests, which is done in the next step of the analysis.
</p>
<p>6.5.4 Carry Out Post Hoc Tests
</p>
<p>Post hoc tests perform multiple comparison tests on each pair of groups and tests which 
of the groups differ significantly from each other. The basic idea underlying post hoc 
tests is to perform tests on each pair of groups and to correct the level of significance 
of each test. This way, the overall type I error rate across all the comparisons (i.e., the 
familywise error rate) remains constant at a certain level, such as at α&nbsp;=&nbsp;0.05 (i.e., α-in-
flation is avoided).
</p>
<p>There are several post hoc tests, the easiest of which is the Bonferroni correction. This 
correction maintains the familywise error rate by calculating a new pairwise alpha that 
divides the statistical significance level of α by the number of comparisons made. How does 
this correction work? In our example, we can compare three groups pairwise: (1) Point 
of sale display vs. free tasting stand, (2) point of sale display vs. in-store announcements, 
and (3) free tasting stand vs. in-store announcements. Hence, we would use 0.05/3&nbsp;&asymp;&nbsp;0.017 
as our criterion for significance. Thus, to reject the null hypothesis that the two popula-
tion means are equal, the p-value would have to be smaller than 0.017 (instead of 0.05!). 
The Bonferroni adjustment is a very strict way of maintaining the familywise error rate. 
However, there is a trade-off between controlling the familywise error rate and increasing 
the type II error. By reducing the type I error rate, the type II error increases. Hence the 
statistical power decreases, potentially causing us to miss significant effects.
</p>
<p>The good news is that there are alternatives to the Bonferroni method. The bad news is 
that there are numerous types of post hoc tests&mdash;SPSS provides no less than 18! Generally, 
these tests detect pairs of groups whose mean values do not differ significantly (homoge-
neous subsets). However, all these tests are based on different assumptions and designed 
for different purposes, whose details are clearly beyond the scope of this book. Check out 
the SPSS help function for an overview and references.
</p>
<p>The most widely used post hoc test in market research is Tukey&rsquo;s honestly significant dif-
ference test (usually simply called Tukey&rsquo;s HSD). Tukey&rsquo;s HSD is a very versatile test which 
controls for the type I error and is conservative in nature. A less conservative alternative is 
</p>
<p>6</p>
<p/>
</div>
<div class="page"><p/>
<p>6185
6.5 &middot; Comparing More Than Two Means: Analysis of Variance (ANOVA)
</p>
<p>the Ryan/Einot-Gabriel/Welsch Q (REGWQ) procedure, which also controls for the type 
I error rate but has a higher statistical power. These post hoc tests share two important 
properties:
1. they require an equal number of observations for each group (differences of a few 
</p>
<p>observations are not problematic), and
2. they assume that the population variances are equal.
</p>
<p>Fortunately, research has provided alternative post hoc tests for situations in which these 
properties are not met. When sample sizes differ clearly, it is advisable to use Hochberg&rsquo;s 
GT2, which has good power and can control the type I error. However, when population 
variances differ, this test becomes unreliable. Thus, in cases where our analysis suggests 
that population variances differ, it is best to use the Games-Howell procedure because it 
generally seems to offer the best performance. . Fig.&nbsp;6.6 provides a guideline for choosing 
the appropriate post hoc test.
</p>
<p>While post hoc tests provide a suitable way of carrying out pairwise comparisons 
among the groups while maintaining the familywise error rate, they do not allow making 
any statements regarding the strength of a factor&rsquo;s effects on the dependent variable. This 
is something we have to evaluate in a separate analysis step, which is discussed next.
</p>
<p>6.5.5 Measure the Strength of the Effects
</p>
<p>We can compute the η2 (the eta squared) coefficient manually to determine the strength 
of the effect (also referred to as the effect size) that the factor variable exerts on the depen-
dent variable. The eta squared is the ratio of the between-group variation (SSB) to the total 
</p>
<p>Use the Games-Howell 
</p>
<p>procedure 
</p>
<p>Carry out Levene&rsquo;s test to
</p>
<p>assess whether the 
</p>
<p>population variances  
</p>
<p>are equal 
</p>
<p>Check the group-specific
</p>
<p>sample sizes 
</p>
<p>Population 
</p>
<p>variances differ 
</p>
<p>Population 
</p>
<p>variances are 
</p>
<p>equal 
</p>
<p>Sample sizes are 
</p>
<p>(approximately) 
</p>
<p>the same 
</p>
<p>Sample sizes 
</p>
<p>differ 
</p>
<p>Use the REGWQ 
</p>
<p>procedure 
</p>
<p>Use Hochberg&rsquo;s GT2
</p>
<p>. Fig.&nbsp;6.6 Guidelines for 
choosing the appropriate 
</p>
<p>post hoc test</p>
<p/>
</div>
<div class="page"><p/>
<p>186 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>variation (SST) and therefore indicates the variance accounted for by the sample data. 
Since η2 is equal to the coefficient of determination (R2), known from regression analysis 
(7 Chap.&nbsp;7). η2 can take on values between 0 and 1. If all groups have the same mean value, 
and we can thus assume that the factor has no influence on the dependent variable, η2 is 
0. Conversely, a high value implies that the factor exerts a strong influence on the depen-
dent variable. In our example, η2 is:
</p>
<p>η2
273 80
</p>
<p>584
0 469= = &asymp;
</p>
<p>SS
</p>
<p>SS
B
</p>
<p>T
</p>
<p>.
.  
</p>
<p>The outcome indicates that 46.9&nbsp;% of the total variation in sales is explained by the pro-
motion campaigns. The η2 is often criticized as being too high for small sample sizes of 
50 or less. We can compute ω&sup2; (pronounced omega squared), which corresponds to the 
Adjusted R2 from regression analysis (7 Chap.&nbsp;7), to compensate for small sample sizes:
</p>
<p>ω2
1 273 80 3 1 11 916
</p>
<p>584 11 916
0 42=
</p>
<p>&minus; &minus;( )&sdot;
+
</p>
<p>=
&minus; &minus;( )&sdot;
+
</p>
<p>&asymp;
SS k MS
</p>
<p>SS MS
B W
</p>
<p>T W
</p>
<p>. .
</p>
<p>.
. 11  
</p>
<p>This result indicates that 42.1&nbsp;% of the total variation in sales is accounted for by the pro-
motion campaigns. Generally, you should use ω&sup2; for n&nbsp;&le;&nbsp;50 and η2 for n&nbsp;&gt;&nbsp;50.
</p>
<p>. Table 6.5 Steps involved in carrying out one, two, or more group comparisons with SPSS
</p>
<p>Theory (number in brackets 
referring to . Table&nbsp;6.2)
</p>
<p>Action
</p>
<p>(1) One-sample t-test
</p>
<p>Formulate the hypothesis
</p>
<p>Formulate the study&rsquo;s 
</p>
<p>hypothesis:
</p>
<p>For example:
</p>
<p> H  0 : #&micro;=
 H  1 : #&micro;&ne;
</p>
<p>It is difficult to provide firm rules of thumb regarding when η2 or ω&sup2; is 
appropriate, as this varies from research area to research area. However, since 
the η2 resembles Pearson&rsquo;s correlation coefficient (7 Chap.&nbsp;7), we follow the 
suggestions provided in 7 Chap.&nbsp;7. Thus, we can consider values below 0.30&nbsp;weak, 
values from 0.31 to 0.49&nbsp;moderate, and values of 0.50 and higher strong.
</p>
<p>Tip
</p>
<p>6.5.6 Interpret the Results
</p>
<p>Just as in any other type of analysis, the final step is to interpret the results. Based on our 
results, we conclude that not all promotional activities have the same effect on sales. An 
analysis of the strength of the effects revealed that this association is moderate.
</p>
<p>. Table&nbsp;6.5 provides an overview of steps involved when carrying out the following 
tests in SPSS: One-sample t-test, independent samples t-test, paired samples t-test, and 
the one-way ANOVA.
</p>
<p>6</p>
<p/>
</div>
<div class="page"><p/>
<p>6187
6.5 &middot; Comparing More Than Two Means: Analysis of Variance (ANOVA)
</p>
<p>. Table&nbsp;6.5 (Continued)
</p>
<p>Theory (number in brackets 
referring to . Table&nbsp;6.2)
</p>
<p>Action
</p>
<p>Choose the significance level
</p>
<p>Usually, α is set to 0.05, but:
</p>
<p>&ndash; if you want to be conservative, α is set to 0.01, and:
</p>
<p>&ndash;  in exploratory studies, α is set to 0.10. We choose a significance 
</p>
<p>level of 0.05.
</p>
<p>Select an appropriate test
</p>
<p>What is the testing situation? Determine the fixed value again which that you are comparing.
</p>
<p>Is the test variable measured 
</p>
<p>on an interval or ratio scale?
</p>
<p>Check 7 Chap.&nbsp;3 to determine the measurement level of the 
variables.
</p>
<p>Are the observations 
</p>
<p>independent?
</p>
<p>Consult 7 Chap.&nbsp;3 to determine whether the observations are 
independent.
</p>
<p>Is the test variable normally 
</p>
<p>distributed?
</p>
<p>Check for normality
</p>
<p>Go to ► Analyze ► Descriptive Statistics ► Explore. Then add 
the test variable(s) to the Dependent list box. Click on Plots, 
uncheck Stem-and-leaf and check Normality plots with tests 
and click on Continue and then OK. Interpret the Tests of 
Normality table and check in the Tests of Normality table under 
Sig. of Shapiro-Wilk if p&nbsp;&gt;&nbsp;0.05, which suggests normality.
</p>
<p>Specify the type of t-test
</p>
<p>Is the test one or two-sided? Determine the region of rejection, one-sided (left or right) or 
</p>
<p>two-sided.
</p>
<p>Calculate the test statistic
</p>
<p>Specify the test variable and 
</p>
<p>the fixed value
</p>
<p>Either normally distributed or equal group variances (one sample 
</p>
<p>t-test): Go to ► Analyze ► Compare Means ► One-Sample T test. 
Put the test variable(s) under Test Variable(s):. Then enter under 
Test Value the mean value you want to compare the test variable(s) 
against. Note: it is possible to compare multiple test variables but 
</p>
<p>no Bonferroni correction is applied and it may not be appropriate 
</p>
<p>to compare multiple test variables against one test value.
</p>
<p>Consider selecting a different confidence interval different from 
</p>
<p>the default 95&nbsp;% by clicking on Options and to enter the desired 
confidence interval (e.g. 99 or 90) under Confidence Interval 
percentage:.
</p>
<p>Not normally distributed and unequal group variances (Wilcoxon 
</p>
<p>signed-rank test): First you will need to compute a new variable 
</p>
<p>with the fixed value you want to test for. Do this by going to ► 
Transform ► Compute variable and as the target variable type 
(for example) testval and enter the value you want to test for 
</p>
<p>under Numeric Expression. Click on OK.
</p>
<p>Then go to ► Analyze ► Nonparametric Tests ► Legacy Dialogs 
► 2 Related Samples. Then add the variable you want to test for 
to Test Pairs: and also add the variable you just constructed (e.g. 
</p>
<p>testval). Make sure only Wilcoxon is ticked and click on OK.</p>
<p/>
</div>
<div class="page"><p/>
<p>188 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>Theory (number in brackets 
referring to . Table&nbsp;6.2)
</p>
<p>Action
</p>
<p>Interpret the results
</p>
<p>Look at the test results One sample t-test: In the output tables, check in the One-Sample 
Test table if Sig. (2-tailed) is less than .05. For two-sided tests, you 
need to multiply the value under Sig. (2-tailed) by two.
</p>
<p>Wilcoxon signed-rank test, check under Test Statistics under the 
row Asymp. Sig. (2-tailed) if the value is less than .05.
</p>
<p>What is your conclusion? Reject the null hypothesis that the population mean of the test 
</p>
<p>variable is equal to the mean value you want to compare the test 
</p>
<p>variable(s) against if the p-value is lower than 0.05.
</p>
<p>(2) Paired samples t-test
</p>
<p>Formulate the hypothesis
</p>
<p>Formulate the study&rsquo;s 
</p>
<p>hypothesis:
</p>
<p>For example:
</p>
<p> H   0 1 2: &micro; &micro;=
 H   1 1 2: &micro; &micro;&ne;
</p>
<p>Choose the significance level
</p>
<p>Usually, α is set to 0.05, but:
</p>
<p>&ndash; if you want to be conservative, α is set to 0.01, and:
</p>
<p>&ndash;  in exploratory studies, α is set to 0.10. We choose a significance 
</p>
<p>level of 0.05.
</p>
<p>Select an appropriate test
</p>
<p>What is the testing situation? Determine the number of groups you are comparing.
</p>
<p>Are the test variables 
</p>
<p>measured on an interval or 
</p>
<p>ratio scale?
</p>
<p>Check 7 Chap.&nbsp;3 to determine the measurement level of the 
variables.
</p>
<p>Are the observations 
</p>
<p>dependent?
</p>
<p>Next, consult 7 Chap.&nbsp;3 to determine whether the observations 
are independent.
</p>
<p>Are the test variables 
</p>
<p>normally distributed in each 
</p>
<p>of the groups?
</p>
<p>Check for normality
</p>
<p>Go to ► Analyze ► Descriptive Statistics ► Explore. Then add 
the test variable(s) to the Dependent list: and under Factor List: 
add the variable that indicates the two groups. Then click on 
</p>
<p>Plots, uncheck Stem-and-leaf and check Normality plots with 
tests and click on Continue and then OK. Interpret the Tests of 
Normality table and check in the Tests of Normality table under 
Sig. of Shapiro-Wilk if p&nbsp;&gt;&nbsp;0.05, which suggests normality.
</p>
<p>Specify the type of t-test If the data appear to be normally distributed across all groups 
</p>
<p>or have equal group variances, we can proceed with the paired 
</p>
<p>samples t-test. If the data are non-normally distributed and have 
</p>
<p>unequal variances, we should apply the Wilcoxon matched-pairs 
</p>
<p>signed-rank test.
</p>
<p>. Table&nbsp;6.5 (Continued)
</p>
<p>6</p>
<p/>
</div>
<div class="page"><p/>
<p>6189
6.5 &middot; Comparing More Than Two Means: Analysis of Variance (ANOVA)
</p>
<p>Theory (number in brackets 
referring to . Table&nbsp;6.2)
</p>
<p>Action
</p>
<p>Is the test one or two-sided? Determine the region of rejection.
</p>
<p>Calculate the test statistic
</p>
<p>Select the paired test 
</p>
<p>variables
</p>
<p>Normally distributed or equal group variances (Paired t-test): Go 
</p>
<p>to ► Analyze ► Compare Means ► Paired-Samples T test. Put the 
test variables into the Paired Variable(s) box. Note: it is possible 
to compare multiple test variables but no Bonferroni correction is 
</p>
<p>applied.
</p>
<p>Consider selecting a different confidence interval different from 
</p>
<p>the default 95&nbsp;% by clicking on Options and to enter the desired 
confidence interval (e.g. 99 or 90) under Confidence Interval 
percentage.
</p>
<p>&ndash;  Not normally distributed and unequal variances (Wilcoxon 
</p>
<p>matched-pairs signed-rank test): Go to  
</p>
<p>► Analyze ► Nonparametric tests ► Related Samples and click 
on Customize analysis. Under Fields click on Use custom field 
assignments first. Then add the variable you want to test to 
the Test Fields: box. Then click on Settings and tick Customize 
tests: and then Wilcoxon matched-pair signed-rank (2 
samples) and click on Run.
</p>
<p>Interpret the results
</p>
<p>Look at the test results &ndash;  Paired t-test: test in the Paired Samples Test table if Sig. 
(2-tailed) is below .05.
</p>
<p>&ndash;  Wilcoxon matched-pairs signed-rank test: in the Hypothesis 
</p>
<p>Test Summary, check if the p-value under Sig. is below .05.
</p>
<p>What is your conclusion? Reject the null hypothesis that the population mean of the test 
</p>
<p>variables are equal if the p-value under Sig. (2-tailed) is below 
0.05.
</p>
<p>(3) Independent samples t-test
</p>
<p>Formulate the hypothesis
</p>
<p>Formulate the study&rsquo;s 
</p>
<p>hypothesis:
</p>
<p>For example:
</p>
<p> 
H   0 1 2: &micro; &micro;=
</p>
<p> 
H1 1 2:&micro; &micro;&ne;
</p>
<p>Choose the significance level
</p>
<p>Usually, α is set to 0.05, but:
</p>
<p>&ndash; if you want to be conservative, α is set to 0.01, and:
</p>
<p>&ndash;  in exploratory studies, α is set to 0.10. We choose a significance 
</p>
<p>level of 0.05.
</p>
<p>. Table&nbsp;6.5 (Continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>190 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>Theory (number in brackets 
referring to . Table&nbsp;6.2)
</p>
<p>Action
</p>
<p>Select an appropriate test
</p>
<p>What is the testing situation? Determine the number of groups you are comparing.
</p>
<p>Are the test variables 
</p>
<p>measured on an interval or 
</p>
<p>ratio scale?
</p>
<p>Check 7 Chap.&nbsp;3 to determine the measurement level of the 
variables.
</p>
<p>Are the observations 
</p>
<p>dependent?
</p>
<p>Next, consult 7 Chap.&nbsp;3 to determine whether the observations 
are independent.
</p>
<p>Are the test variables 
</p>
<p>normally distributed in each 
</p>
<p>of the groups and are the 
</p>
<p>group variances the same?
</p>
<p>Check for normality
</p>
<p>Go to ► Analyze ► Descriptive Statistics ► Explore. Then add 
the test variable(s) to the Dependent list:. Click on Plots, uncheck 
Stem-and-leaf and check Normality plots with tests and click 
on Continue and then OK. Interpret the Tests of Normality table 
and check in the Tests of Normality table under Sig. of Shapiro-
Wilk if p&nbsp;&gt;&nbsp;.05, which suggests normality.
</p>
<p>SPSS conducts the group variances equality test automatically as 
</p>
<p>part of the Paired samples t-test.
</p>
<p>Specify the type of t-test
</p>
<p>Is the test one or two-sided? Determine the region of rejection.
</p>
<p>Calculate the test statistic
</p>
<p>Select the test variable and 
</p>
<p>the grouping variable
</p>
<p>Normally or non-normally distributed but equal group variances 
</p>
<p>(independent samples t-test): Go to ► Analyze ► Compare 
Means ► Independent Samples T test. Put the test variable 
into the Test Variable(s) box and add the variable indicating 
the grouping into the Grouping Variable box. Click on Define 
Groups and under Use specified values enter which values 
indicate the two groups you want to compare. Note: it is possible 
</p>
<p>to compare multiple test variables but no Bonferroni correction 
</p>
<p>is applied.
</p>
<p>Consider selecting a confidence interval different from the 
</p>
<p>default 95&nbsp;% by clicking on Options and to enter the desired 
confidence interval (e.g. 99 or 90) under Confidence Interval 
percentage.
</p>
<p>Not normally distributed and unequal variances (Mann-Whitney 
</p>
<p>U test): Go to ► Analyze ► Nonparametric tests ► Independent 
Samples. Under Objective tick Customize analysis. Under 
Fields, click on Use customer field assignments and move the 
test variable into the Test Fields box. Under Settings click on 
Customize tests and click on Mann-Whitney U (2-samples). 
Followed by Run.
</p>
<p>. Table&nbsp;6.5 (Continued)
</p>
<p>6</p>
<p/>
</div>
<div class="page"><p/>
<p>6191
6.5 &middot; Comparing More Than Two Means: Analysis of Variance (ANOVA)
</p>
<p>Theory (number in brackets 
referring to . Table&nbsp;6.2)
</p>
<p>Action
</p>
<p>Interpret the results
</p>
<p>Look at the test results If the data appear to be normally or non-normally distributed 
</p>
<p>with equal group variances then from the Independent Samples 
Test table we should read the row saying Equal variance 
assumed. If they come from normally distributed data but 
unequal variances we should use the row saying Equal variances 
not assumed. For both situations, check if Sig. (2-tailed) is less 
than 0.05. For two-sided tests, you need to multiply the value 
</p>
<p>under Sig. (2-tailed) by two.
</p>
<p>For the Mann-Whitney U test, we should check in the Hypothesis 
Test Summary table if Sig. (2-tailed) is less than 0.05. For two-
sided tests, you need to multiply the value under Sig. (2-tailed) 
by two.
</p>
<p>What is your conclusion? Reject the null hypothesis that the population mean of the test 
</p>
<p>variables are equal if the p-value under Sig. (2-tailed) is lower 
than 0.05.
</p>
<p>(4) One-way ANOVA
</p>
<p>Formulate the hypothesis
</p>
<p>Formulate the study&rsquo;s 
</p>
<p>hypothesis:
</p>
<p>For example:
</p>
<p>H   0 1 2 3:&micro; &micro; &micro;= =
</p>
<p>H1: At least two of the population means are different.
</p>
<p>Choose the significance level
</p>
<p>Usually, α is set to 0.05, but:
</p>
<p>&ndash; if you want to be conservative, α is set to 0.01, and:
</p>
<p>&ndash;  in exploratory studies, α is set to 0.10. We choose a significance 
</p>
<p>level of 0.05.
</p>
<p>Select an appropriate test
</p>
<p>What is the testing situation? Determine the number of groups you are comparing.
</p>
<p>Are there at least 20 
</p>
<p>observations per group?
</p>
<p>Check 7 Chap.&nbsp;5 to determine the sample size in each group.
</p>
<p>Is the dependent variable 
</p>
<p>measured on an interval or 
</p>
<p>ratio scale?
</p>
<p>Determine the type of test that you need to use for your analyses 
</p>
<p>by checking the underlying assumptions first. Check 7 Chap.&nbsp;3 to 
determine the measurement level of the variables.
</p>
<p>Are the observations 
</p>
<p>independent?
</p>
<p>Next, consult 7 Chap.&nbsp;3 to determine whether the observations 
are independent.
</p>
<p>. Table&nbsp;6.5 (Continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>192 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>Theory (number in brackets 
referring to . Table&nbsp;6.2)
</p>
<p>Action
</p>
<p>Is the test variable normally 
</p>
<p>distributed and are the group 
</p>
<p>variances the same?
</p>
<p>Check for normality
</p>
<p>Go to ► Analyze ► Descriptive Statistics ► Explore. Then move 
the test variable into the Dependent list box and under Factor 
List: add the variable that indicates the two groups. Click on 
Plots, uncheck Stem-and-leaf and check Normality plots with 
tests and click on Continue and then OK. Interpret the Tests 
of Normality table for all groups and check in the Tests of 
Normality table under Sig. of Shapiro-Wilk if p&nbsp;&gt;&nbsp;0.05, which 
suggests normality.
</p>
<p>Check for Equality of Variances Assumption
</p>
<p>This test is included in the ANOVA analysis (in the ANOVA dialog 
</p>
<p>box go to Options and tick Homogeneity of variance test and 
click on Continue.
</p>
<p>Select the type of the test If the assumption of normality and equality of the variance are 
</p>
<p>met, proceed with the one-way ANOVA analysis. If not, conduct 
</p>
<p>the Kruskal-Wallis rank test.
</p>
<p>Calculate the test statistic
</p>
<p>Specify the dependent 
</p>
<p>variable and the factor 
</p>
<p>(grouping variable)
</p>
<p>Normally or non-normally distributed but equal group variances 
</p>
<p>(One-way ANOVA: F-test): Go to ► Analyze ► Compare Means ► 
One-Way ANOVA. Put the test variable into the Dependent List 
box and add the variable indicating the grouping into the Factor 
box. Click on Options and also tick Homogeneity of variance 
test.
</p>
<p>Normally or non-normally distributed but equal group variances 
</p>
<p>(One-way ANOVA: F-test with Welch&rsquo;s correction): Go to ► 
Analyze ► Compare Means ► One-Way ANOVA. Put the test 
variable into the Dependent List box and add the variable 
indicating the grouping into the Factor box. Click on Options 
and tick Homogeneity of variance test and Welch.
</p>
<p>Not normally distributed and unequal variances (Kruskal-Wallis 
</p>
<p>rank test): Go to ► Analyze ► Nonparametric Tests ► Legacy 
Dialogs ► K Independent Samples. Put the test variable into 
the Test Variable List box. Add the factor into the Grouping 
Variable box after which you should click on Define Range to 
set the Minimum and Maximum value of the factor and click on 
Continue. Make sure also Kruskal-Wallis H is ticked (only). Click 
on OK.
</p>
<p>. Table&nbsp;6.5 (Continued)
</p>
<p>6</p>
<p/>
</div>
<div class="page"><p/>
<p>6193
6.6 &middot; Example
</p>
<p>Theory (number in brackets 
referring to . Table&nbsp;6.2)
</p>
<p>Action
</p>
<p>Interpret the results
</p>
<p>Look at the test results Compare the p-value in the ANOVA table with the significance 
level under Sig. The p-value should be lower than 0.05 to reject 
the null hypothesis.
</p>
<p>For the One-way ANOVA: F-test with Welch&rsquo;s correction, check the 
</p>
<p>table Robust Tests of Equality of Means under Sig. The p-value 
should be lower than 0.05 to reject the null hypothesis.
</p>
<p>For the Kruskal-Wallis rank test, check the table Test Statistics 
under Asymp. Sig. is lower than 0.05 to reject the null hypothesis.
</p>
<p>Carry out pairwise 
</p>
<p>comparisons
</p>
<p>You can carry out post hoc tests as part of the ANOVA analysis. 
</p>
<p>In the Univariate dialog box, click on Post Hoc and move the 
factor(s) to the Post Hoc Tests for: box. If you found evidence of 
equal variances, tick Tukey. If you found unequal variances, tick 
Games-Howell.
</p>
<p>Look at the strength of the 
</p>
<p>effects
</p>
<p>In the Univariate dialog box, go to ► Options and tick Estimates 
of effect size. Check for the strengths of the effects under 
R-squared and Adjusted R-squared in the output.
</p>
<p>What is your conclusion? Based on pairwise comparisons: Check which pairs differ 
</p>
<p>significantly from each other in the Paired Comparisons table. If 
the p-values under Sig. tied to the pairwise mean comparisons 
are &lt; 0.05, reject the null hypothesis that the mean comparisons 
</p>
<p>between the two groups are equal.
</p>
<p>Based on the output from the Tests of Between Subjects Effects 
table, reject the null hypothesis that at least two population 
</p>
<p>means are equal if the p-value is lower than 0.05 for the corrected 
</p>
<p>model.
</p>
<p>. Table&nbsp;6.5 (Continued)
</p>
<p>6.6 Example
</p>
<p>Let&rsquo;s now turn to the Oddjob Airways case study and apply what we discussed in this 
chapter. Our aim is to identify the factors that influence customers&rsquo; overall price/perfor-
mance satisfaction with the airline and explore the relevant target groups for future adver-
tising campaigns. Based on discussions with the Oddjob Airways management, answering 
the following three research questions will help achieve this aim:
(1) Does the overall price/performance satisfaction differ by gender?
(2) Does the overall price/performance satisfaction differ according to the traveler&rsquo;s 
</p>
<p>status?</p>
<p/>
</div>
<div class="page"><p/>
<p>194 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>The following variables (variable names in parentheses) from the Oddjob Airways dataset 
(⤓ Web Appendix &rarr; Downloads) are central to this example:
 4 overall price/performance satisfaction (overall_sat),
 4 respondent&rsquo;s gender (gender), and
 4 traveler&rsquo;s status (status).
</p>
<p>6.6.1 Research Question 1
</p>
<p>6.6.1.1 Formulate the Hypothesis
We start by formulating a non-directional hypothesis. The null hypothesis of the first 
research question is that the overall price/performance satisfaction means of male and 
female travelers are the same (H0), while the alternative hypothesis (H1) expects that the 
overall price/performance satisfaction means of male and female travelers differs.
</p>
<p>6.6.1.2 Choose the Significant Level
</p>
<p>Next, we decide to use a significance level (α) of 0.05, which means that we allow a 
maximum chance of 5&nbsp;% of mistakenly rejecting a true null hypothesis.
</p>
<p>6.6.1.3 Select the Appropriate Test
</p>
<p>We move to the next step to determine the type of test, which involves assessing the testing 
situation, the nature of the measurements, checking the assumptions, and selecting the 
region of rejection. We start by defining the testing situation of our analysis, which is to 
compare the mean overall price/performance satisfaction scores (measured on a ratio 
scale) of male and female travelers. In our example, we know that the sample is a random 
subset of the population and we also know that they are independent. Next, we need 
to check if the dependent variable overall_sat is normally distributed. To do this go to  
► Analyze ► Descriptive Statistics ► Explore. Then put the test variable overall_sat into 
the Dependent list box. Under Factor List: enter the gender variable as you want to assess 
normality within each of the two groups. For the ANOVA example that follows, we also 
need the status variable so please add this as well as it avoids having to redo the analysis 
later. All of this is shown in . Fig.&nbsp;6.7. Next, click on Plots, which will open a dialog box 
similar to . Fig.&nbsp;6.8, uncheck Stem-and-leaf, check Normality plots with tests and click on 
Continue and then OK.
</p>
<p>. Table&nbsp;6.6 displays the Tests of Normality table for both gender and status. SPSS 
also reports both the Kolmogorov-Smirnov test (which we do not need) and the Sha-
piro-Wilk test with its corresponding p-values under (Sig.). The results show that the 
p-values of the Shapiro-Wilk test (.000) are smaller than 0.05, indicating that the nor-
mality assumption is violated for both gender groups and all tree status groups. SPSS 
also produces five quantile plots in . Fig.&nbsp;6.9 as discussed in Box 6.2. In every plot, the 
dots appear to follow the straight line reasonably well and do not clearly suggest where 
the normality is off.
</p>
<p>6</p>
<p/>
</div>
<div class="page"><p/>
<p>6195
6.6 &middot; Example
</p>
<p>. Fig.&nbsp;6.8 Normality plots 
with tests
</p>
<p>. Fig.&nbsp;6.7 Testing for normality
</p>
<p>6.6.1.4 Calculate the Test Statistic and Make the Test Decision
As we find no support for normality, we may have to use the independent samples t-test or 
the Mann-Whitney U test. The decision on which to choose depends on whether the vari-
ances are equal. To do this, go to ► Analyze ► Compare Means ► Independent Samples 
T test, which will open a dialog box similar to . Fig.&nbsp;6.10.</p>
<p/>
</div>
<div class="page"><p/>
<p>196 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>Put the test variable overall_sat into the Test Variable(s) box and add gender into the 
Grouping Variable box. Next, click on Define Groups and enter 1 next to Group 1 and 2 next 
to Group 2. Proceed by clicking on Continue and then OK.
</p>
<p>. Table 6.6 Tests of normality
</p>
<p>Tests of Normality
</p>
<p>Gender Kolmogorov-Smirnova Shapiro-Wilk
</p>
<p>Statistic df Sig. Statistic df Sig.
</p>
<p>Overall, I am 
</p>
<p>satisfied with 
</p>
<p>the price 
</p>
<p>performance 
</p>
<p>ratio of 
</p>
<p>Oddjob 
</p>
<p>Airways.
</p>
<p>female .201 280 .000 .929 280 .000
</p>
<p>male .167 785 .000 .941 785 .000
</p>
<p>a Lilliefors Significance Correction
</p>
<p>Tests of Normality
</p>
<p>Traveler 
</p>
<p>Status
</p>
<p>Kolmogorov-Smirnova Shapiro-Wilk
</p>
<p>Statistic df Sig. Statistic df Sig.
</p>
<p>Overall, I am 
</p>
<p>satisfied with 
</p>
<p>the price 
</p>
<p>performance 
</p>
<p>ratio of 
</p>
<p>Oddjob 
</p>
<p>Airways.
</p>
<p>Blue .181 677 .000 .930 677 .000
</p>
<p>Silver .161 245 .000 .947 245 .000
</p>
<p>Gold .183 143 .000 .941 143 .000
</p>
<p>a Lilliefors Significance Correction
</p>
<p>To indicate different groups, you can also specify a Cut point, which is particularly useful 
</p>
<p>when you want to compare two groups based on an ordinal or continuous variable. For 
</p>
<p>example, if you want to compare younger vs. older members you could put all members 
</p>
<p>below 30&nbsp;years of age into one category and all who are 30 or above into the other 
</p>
<p>category. When you indicate a cut point, observations with values less than the cut point 
</p>
<p>form one group, while observations with values greater than or equal to the cut point 
</p>
<p>form the other group.
</p>
<p>Tip
</p>
<p>6</p>
<p/>
</div>
<div class="page"><p/>
<p>6197
6.6 &middot; Example
</p>
<p>Normal Q-Q Plot of Overall, I am satisfied with the price performance ratio
</p>
<p>of Oddjob Airways.
</p>
<p>for gender = male
</p>
<p>Normal Q-Q Plot of Overall, I am satisfied with the price performance ratio
</p>
<p>of Oddjob Airways.
</p>
<p>for gender = male
</p>
<p>Normal Q-Q Plot of Overall, I am satisfied with the price performance ratio
</p>
<p>of Oddjob Airways.
</p>
<p>Normal Q-Q Plot of Overall, I am satisfied with the price performance ratio
</p>
<p>of Oddjob Airways.
</p>
<p>Normal Q-Q Plot of Overall, I am satisfied with the price performance ratio
</p>
<p>of Oddjob Airways.
</p>
<p>for status = Blue
</p>
<p>for status = Gold
</p>
<p>for status = Silver
</p>
<p>Observed Value
</p>
<p>2
</p>
<p>1
</p>
<p>0
</p>
<p>0 2 4 6 8
</p>
<p>&ndash;1
</p>
<p>E
x
</p>
<p>p
e
</p>
<p>ct
e
</p>
<p>d
 N
</p>
<p>o
rm
</p>
<p>a
l
</p>
<p>&ndash;2
</p>
<p>&ndash;3
</p>
<p>Observed Value
</p>
<p>3
</p>
<p>2
</p>
<p>1
</p>
<p>0
</p>
<p>0 2 4 6 8
</p>
<p>&ndash;1
</p>
<p>E
x
</p>
<p>p
e
</p>
<p>ct
e
</p>
<p>d
 N
</p>
<p>o
rm
</p>
<p>a
l
</p>
<p>&ndash;2
</p>
<p>&ndash;3
</p>
<p>Observed Value
</p>
<p>3
</p>
<p>2
</p>
<p>1
</p>
<p>0
</p>
<p>0 2 4 6 8
</p>
<p>&ndash;1
</p>
<p>E
x
</p>
<p>p
e
</p>
<p>ct
e
</p>
<p>d
 N
</p>
<p>o
rm
</p>
<p>a
l
</p>
<p>&ndash;2
</p>
<p>&ndash;3
</p>
<p>Observed Value
</p>
<p>2
</p>
<p>1
</p>
<p>0
</p>
<p>0 2 4 6 8
</p>
<p>&ndash;1
</p>
<p>E
x
</p>
<p>p
e
</p>
<p>ct
e
</p>
<p>d
 N
</p>
<p>o
rm
</p>
<p>a
l
</p>
<p>&ndash;2
</p>
<p>&ndash;3
</p>
<p>Observed Value
</p>
<p>2
</p>
<p>1
</p>
<p>0
</p>
<p>0 2 4 6 8
</p>
<p>&ndash;1
</p>
<p>E
x
</p>
<p>p
e
</p>
<p>ct
e
</p>
<p>d
 N
</p>
<p>o
rm
</p>
<p>a
l
</p>
<p>&ndash;2
</p>
<p>&ndash;3
</p>
<p>. Fig.&nbsp;6.9 Normal Q&ndash;Q plot output
</p>
<p>. Fig.&nbsp;6.10 Independent samples t-test</p>
<p/>
</div>
<div class="page"><p/>
<p>198 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>SPSS will produce . Tables&nbsp;6.7 and 6.8. . Table&nbsp;6.7 shows the sample size (N) which is 280 
females and 785 males. The mean (Mean) scores are also show as 4.500 and 4.2369 respec-
tively and these mean differences, at first sight, appear different between the two groups. 
However, as we learned before, we have to take the variation in the data into account to 
test whether this difference is also present in the population. The standard deviation (Std. 
Deviation) gives some indication but the formal test is shown in . Table&nbsp;6.8. On the left of 
the output, we can see the test results of Levene&rsquo;s test for the equality of population vari-
ances. The low F-value (F) of 0.418 suggests that we cannot reject the null hypothesis that 
the population variances are equal. This is also mirrored in the large p-value of 0.518, 
which lies far above 0.05. Because we obtained evidence that the variances are equal, we 
also find that the independent samples t-test is appropriate. We can thus proceed to inter-
pret the output further.
</p>
<p>. Table 6.7 Group statistics
</p>
<p>Group Statistics
</p>
<p>Gender N Mean Std. Deviation Std. Error Mean
</p>
<p>overall_sat female 280 4.5000 1.64611 .09837
</p>
<p>male 785 4.2369 1.61306 .05757
</p>
<p>6.6.1.5 Interpret the Results
</p>
<p>Looking at the central and right part of the output in . Table&nbsp;6.8, we can see that SPSS 
carries out two tests, one based on the pooled variance estimate (upper row) and the 
other based on separate variance estimates using Welch's correction (lower row). Since 
we assume that the population variances are equal, we should interpret the upper row. 
When comparing the p-value under Sig. (2-tailed) with the significance level, we learn that 
the p-value (0.020) is smaller than the significance level (0.05). Therefore, we can reject 
the independent samples t-test&rsquo;s null hypothesis that there is no difference in satisfaction 
between female and male customers and conclude that that the overall price/performance 
satisfaction differs significantly between female and male travelers.
</p>
<p>6.6.2 Research Question 2
</p>
<p>In the second research question, we examine whether customers&rsquo; membership status (i.e., 
status) relates to their overall price/performance satisfaction (i.e., overall_sat) with Oddjob 
Airways. The status variable defines three groups: Blue, Silver, and Gold. Again, we start 
by formulating a null hypothesis that is again non-directional in nature, expecting that 
</p>
<p>!  If both the normality and equality of the variance assumptions were not met, the 
Mann-Whitney U test should have been performed. This is the non-parametric 
</p>
<p>counterpart of the independent samples t-test. Please see . Table&nbsp;6.5 for details on 
how to carry out this test.
</p>
<p>6</p>
<p/>
</div>
<div class="page"><p/>
<p>6199
6.6 &middot; Example
</p>
<p>.
 T
</p>
<p>ab
le
</p>
<p> 6
.8
</p>
<p> I
n
</p>
<p>d
e
</p>
<p>p
e
</p>
<p>n
d
</p>
<p>e
n
</p>
<p>t 
sa
</p>
<p>m
p
</p>
<p>le
s 
</p>
<p>t-
te
</p>
<p>st
</p>
<p>In
d
</p>
<p>ep
en
</p>
<p>d
en
</p>
<p>t 
Sa
</p>
<p>m
p
</p>
<p>le
s 
</p>
<p>Te
st
</p>
<p>Le
ve
</p>
<p>n
e
</p>
<p>'s
 T
</p>
<p>e
st
</p>
<p> f
o
</p>
<p>r 
</p>
<p> E
q
</p>
<p>u
a
</p>
<p>lit
y 
</p>
<p>o
f V
</p>
<p>a
ri
</p>
<p>a
n
</p>
<p>ce
s
</p>
<p>t-
te
</p>
<p>st
 f
</p>
<p>o
r 
</p>
<p>E
q
</p>
<p>u
a
</p>
<p>lit
y 
</p>
<p>o
f 
</p>
<p>M
e
</p>
<p>a
n
</p>
<p>s
t-
</p>
<p>te
st
</p>
<p> f
o
</p>
<p>r 
E
</p>
<p>q
u
</p>
<p>a
lit
</p>
<p>y 
o
</p>
<p>f 
M
</p>
<p>e
a
</p>
<p>n
s
</p>
<p>F
S
</p>
<p>ig
.
</p>
<p>t
d
</p>
<p>f
</p>
<p>S
ig
</p>
<p>. 
</p>
<p>(2
-t
</p>
<p>a
ile
</p>
<p>d
)
</p>
<p>M
e
</p>
<p>a
n
</p>
<p>  
</p>
<p>D
if
</p>
<p>fe
re
</p>
<p>n
ce
</p>
<p>S
td
</p>
<p>. E
rr
</p>
<p>o
r 
</p>
<p> 
</p>
<p>D
if
</p>
<p>fe
re
</p>
<p>n
ce
</p>
<p>9
5
</p>
<p>&nbsp;%
 C
</p>
<p>o
n
</p>
<p>fi
d
</p>
<p>e
n
</p>
<p>ce
 In
</p>
<p>te
rv
</p>
<p>a
l o
</p>
<p>f 
</p>
<p>th
e
</p>
<p> D
if
</p>
<p>fe
re
</p>
<p>n
ce
</p>
<p>Lo
w
</p>
<p>e
r
</p>
<p>U
p
</p>
<p>p
e
</p>
<p>r
</p>
<p>o
ve
</p>
<p>ra
ll_
</p>
<p>sa
t
</p>
<p>E
q
</p>
<p>u
a
</p>
<p>l v
a
</p>
<p>ri
a
</p>
<p>n
ce
</p>
<p>s 
</p>
<p>a
ss
</p>
<p>u
m
</p>
<p>e
d
</p>
<p>.4
1
</p>
<p>8
.5
</p>
<p>1
8
</p>
<p>2
.3
</p>
<p>3
0
</p>
<p>1
0
</p>
<p>6
3
</p>
<p>.0
2
</p>
<p>0
.2
</p>
<p>6
3
</p>
<p>0
6
</p>
<p>.1
1
</p>
<p>2
8
</p>
<p>9
.0
</p>
<p>4
1
</p>
<p>5
4
</p>
<p>.4
8
</p>
<p>4
5
</p>
<p>7
</p>
<p>E
q
</p>
<p>u
a
</p>
<p>l v
a
</p>
<p>ri
a
</p>
<p>n
ce
</p>
<p>s 
n
</p>
<p>o
t 
</p>
<p>a
ss
</p>
<p>u
m
</p>
<p>e
d
</p>
<p>2
.3
</p>
<p>0
8
</p>
<p>4
8
</p>
<p>2
.6
</p>
<p>9
8
</p>
<p>.0
2
</p>
<p>1
.2
</p>
<p>6
3
</p>
<p>0
6
</p>
<p>.1
1
</p>
<p>3
9
</p>
<p>8
.0
</p>
<p>3
9
</p>
<p>0
9
</p>
<p>.4
8
</p>
<p>7
0
</p>
<p>2</p>
<p/>
</div>
<div class="page"><p/>
<p>200 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>. Fig.&nbsp;6.11 One-way ANOVA dialog box
</p>
<p>the mean of the overall price/performance satisfaction is the same between the status 
groups, while the alternative hypothesis states that at least two status groups differ. Next, 
we decide to use a significance level (α) of 0.05. We have already established that a com-
parison of three or more groups involves a one-way ANOVA and we therefore follow the 
steps as indicated in . Fig.&nbsp;6.4.
</p>
<p>6.6.2.1 Check the Assumptions
</p>
<p>In checking the assumptions, we already know that the sample is a random subset of the 
population and we also know that other respondents&rsquo; responses do not influence those of 
the respondents (i.e., they are independent). Next, we check the normality but as we had 
already tested for normality of overall_sat for the three loyalty groups (Blue, Silver, and 
Gold, see . Table&nbsp;6.6) we know that this variable is not normally distributed. If we thus 
follow . Table&nbsp;6.2., we should either conduct a one-way ANOVA F-test when the variances 
are equal or a Kruskal-Wallis rank test when the variances are not equal.
</p>
<p>To test for the equality of variances, we need to carry out an ANOVA analysis first. To 
do this, go to ► Analyze ► Compare Means ► One-Way ANOVA, which opens a dialog 
box similar to . Fig.&nbsp;6.11. Move the test variable overall_sat into the Dependent List box 
and add the variable status that indicates the three groups (Blue, Silver, and Gold) into the 
Factor box.
</p>
<p>Next, under Post Hoc (. Fig.&nbsp;6.12) we should specify a series of post hoc tests for multi-
ple group comparisons that are all shown in . Fig.&nbsp;6.12. Since we do not yet know the result 
of Levene&rsquo;s test, we choose Ryan/Einot-Gabriel/Welsch Q (R-E-G-W Q) and Games-Howell. 
Since group sizes are fairly unequal, we also select Hochberg&rsquo;s GT2. Next, click on Continue 
to get back to the main menu.
</p>
<p>Go back to the main menu and click on Options. In the dialog box that opens,  
(. Fig.&nbsp;6.13), tick Descriptive and Homogeneity of variance test. Note that if you were to 
have support for normality (which we don&rsquo;t), it is useful to tick Welch as well. Go back to 
the main menu by clicking on Continue and then OK.
The descriptive statistics in . Table&nbsp;6.9 show that the groups clearly differ in size. For 
example, the Blue group comprises 677 customers, whereas the Gold group comprises 
143 customers. The results also indicate that the means of overall_sat differ between the 
</p>
<p>6</p>
<p/>
</div>
<div class="page"><p/>
<p>6201
6.6 &middot; Example
</p>
<p>. Fig.&nbsp;6.12 Post hoc multiple comparisons dialog box
</p>
<p>. Fig.&nbsp;6.13 One-way ANOVA options
</p>
<p>three groups. For example, in the Blue group, the mean is 4.47 compared to 3.99 in the 
Gold group. Before evaluating the ANOVA&rsquo;s results to assess whether these differences are 
significant however, we have to take a closer look at the results of Levene&rsquo;s test as shown in 
. Table&nbsp;6.10. The Levene&rsquo;s test statistic clearly suggests that the population variances are 
equal, as the test&rsquo;s p-value (0.404) is well above 0.05. Thus, following from . Table&nbsp;6.2, we 
should use the F-test to decide whether at least one group mean differs from the others.</p>
<p/>
</div>
<div class="page"><p/>
<p>202 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>. Table 6.10 Test of homogeneity of variances
</p>
<p>Test of Homogeneity of Variances
</p>
<p>Levene 
</p>
<p> Statistic df1 df2 Sig.
</p>
<p>Overall, I am 
</p>
<p>satisfied with 
</p>
<p>the price 
</p>
<p>performance 
</p>
<p>ratio of 
</p>
<p>Oddjob 
</p>
<p>Airways.
</p>
<p>Based on Mean .907 2 1062 .404
</p>
<p>Based on 
</p>
<p>Median
</p>
<p>.068 2 1062 .934
</p>
<p>Based on 
</p>
<p>Median and 
</p>
<p>with adjusted df
</p>
<p>.068 2 1017.925 .934
</p>
<p>Based on 
</p>
<p>trimmed mean
</p>
<p>.771 2 1062 .463
</p>
<p>. Table 6.11 ANOVA table
</p>
<p>ANOVA
Overall, I am satisfied with the price performance ratio of Oddjob Airways.
</p>
<p>Sum of Squares df Mean Square F Sig.
</p>
<p>Between Groups 51.755 2 25.878 9.963 .000
</p>
<p>Within Groups 2758.455 1062 2.597
</p>
<p>Total 2810.210 1064
</p>
<p>6.6.2.2 Calculate the Test Statistic
SPSS will calculate the test statistic and provide a table as shown in . Table&nbsp;6.11. The top 
part of the table reports several measures of model significance and fit which we will inter-
pret next to make the test decision.
</p>
<p>. Table 6.9 Descriptive statistics
</p>
<p>Descriptives
Overall, I am satisfied with the price performance ratio of Oddjob Airways.
</p>
<p>N Mean
</p>
<p>Std. 
</p>
<p> Deviation
</p>
<p>Std. 
</p>
<p>Error
</p>
<p>95&nbsp;% Confidence Inter-
</p>
<p>val for Mean
</p>
<p>Mini-
</p>
<p>mum
</p>
<p>Maxi-
</p>
<p>mum
</p>
<p>Lower 
</p>
<p>Bound
</p>
<p>Upper 
</p>
<p>Bound
</p>
<p>Blue 677 4.47 1.641 .063 4.35 4.60 1 7
</p>
<p>Silver 245 4.03 1.560 .100 3.84 4.23 1 7
</p>
<p>Gold 143 3.99 1.556 .130 3.73 4.24 1 7
</p>
<p>Total 1065 4.31 1.625 .050 4.21 4.40 1 76</p>
<p/>
</div>
<div class="page"><p/>
<p>6203
6.6 &middot; Example
</p>
<p>.
 T
</p>
<p>ab
le
</p>
<p> 6
.1
</p>
<p>2
 P
</p>
<p>o
st
</p>
<p> h
o
</p>
<p>c 
te
</p>
<p>st
 r
</p>
<p>e
su
</p>
<p>lt
s 
</p>
<p>(H
o
</p>
<p>ch
b
</p>
<p>e
rg
</p>
<p>&rsquo;s
 G
</p>
<p>T
2
</p>
<p> a
n
</p>
<p>d
 G
</p>
<p>a
m
</p>
<p>e
s 
</p>
<p>H
o
</p>
<p>w
e
</p>
<p>ll) M
u
</p>
<p>lt
ip
</p>
<p>le
 C
</p>
<p>o
m
</p>
<p>p
ar
</p>
<p>is
o
</p>
<p>n
s
</p>
<p>D
e
</p>
<p>p
e
</p>
<p>n
d
</p>
<p>e
n
</p>
<p>t 
V
</p>
<p>a
ri
</p>
<p>a
b
</p>
<p>le
: O
</p>
<p>ve
ra
</p>
<p>ll,
 I 
</p>
<p>a
m
</p>
<p> s
a
</p>
<p>ti
sf
</p>
<p>ie
d
</p>
<p> w
it
</p>
<p>h
 t
</p>
<p>h
e
</p>
<p> p
ri
</p>
<p>ce
 p
</p>
<p>e
rf
</p>
<p>o
rm
</p>
<p>a
n
</p>
<p>ce
 r
</p>
<p>a
ti
</p>
<p>o
 o
</p>
<p>f 
O
</p>
<p>d
d
</p>
<p>jo
b
</p>
<p> A
ir
</p>
<p>w
ay
</p>
<p>s.
</p>
<p>(I
) T
</p>
<p>ra
ve
</p>
<p>le
r 
</p>
<p>S
ta
</p>
<p>tu
s
</p>
<p>(J
) T
</p>
<p>ra
ve
</p>
<p>le
r 
</p>
<p>S
ta
</p>
<p>tu
s
</p>
<p>M
e
</p>
<p>a
n
</p>
<p> D
if
</p>
<p>fe
re
</p>
<p>n
ce
</p>
<p> 
</p>
<p>(I
-J
</p>
<p>)
S
</p>
<p>td
. E
</p>
<p>rr
o
</p>
<p>r
S
</p>
<p>ig
.
</p>
<p>9
5
</p>
<p>&nbsp;%
 C
</p>
<p>o
n
</p>
<p>fi
d
</p>
<p>e
n
</p>
<p>ce
 In
</p>
<p>te
rv
</p>
<p>a
l
</p>
<p>Lo
w
</p>
<p>e
r 
</p>
<p>B
o
</p>
<p>u
n
</p>
<p>d
U
</p>
<p>p
p
</p>
<p>e
r 
</p>
<p>B
o
</p>
<p>u
n
</p>
<p>d
</p>
<p>H
o
</p>
<p>ch
b
</p>
<p>e
rg
</p>
<p>B
lu
</p>
<p>e
S
</p>
<p>ilv
e
</p>
<p>r
.4
</p>
<p>4
0
</p>
<p>*
.1
</p>
<p>2
0
</p>
<p>.0
0
</p>
<p>1
.1
</p>
<p>5
.7
</p>
<p>3
</p>
<p>G
o
</p>
<p>ld
.4
</p>
<p>8
7
</p>
<p>*
.1
</p>
<p>4
8
</p>
<p>.0
0
</p>
<p>3
.1
</p>
<p>3
.8
</p>
<p>4
</p>
<p>S
ilv
</p>
<p>e
r
</p>
<p>B
lu
</p>
<p>e
&minus;
</p>
<p>.4
4
</p>
<p>0
*
</p>
<p>.1
2
</p>
<p>0
.0
</p>
<p>0
1
</p>
<p>&minus;
.7
</p>
<p>3
&minus;
</p>
<p>.1
5
</p>
<p>G
o
</p>
<p>ld
.0
</p>
<p>4
7
</p>
<p>.1
7
</p>
<p>0
.9
</p>
<p>9
0
</p>
<p>&minus;
.3
</p>
<p>6
.4
</p>
<p>5
</p>
<p>G
o
</p>
<p>ld
B
</p>
<p>lu
e
</p>
<p>&minus;
.4
</p>
<p>8
7
</p>
<p>*
.1
</p>
<p>4
8
</p>
<p>.0
0
</p>
<p>3
&ndash;
</p>
<p>.8
4
</p>
<p>&minus;
.1
</p>
<p>3
</p>
<p>S
ilv
</p>
<p>e
r
</p>
<p>&minus;
.0
</p>
<p>4
7
</p>
<p>.1
7
</p>
<p>0
.9
</p>
<p>9
0
</p>
<p>&minus;
.4
</p>
<p>5
.3
</p>
<p>6
</p>
<p>G
a
</p>
<p>m
e
</p>
<p>s-
</p>
<p>H
o
</p>
<p>w
e
</p>
<p>ll
</p>
<p>B
lu
</p>
<p>e
S
</p>
<p>ilv
e
</p>
<p>r
.4
</p>
<p>4
0
</p>
<p>*
.1
</p>
<p>1
8
</p>
<p>.0
0
</p>
<p>1
.1
</p>
<p>6
.7
</p>
<p>2
</p>
<p>G
o
</p>
<p>ld
.4
</p>
<p>8
7
</p>
<p>*
.1
</p>
<p>4
5
</p>
<p>.0
0
</p>
<p>3
.1
</p>
<p>5
.8
</p>
<p>3
</p>
<p>S
ilv
</p>
<p>e
r
</p>
<p>B
lu
</p>
<p>e
&minus;
</p>
<p>.4
4
</p>
<p>0
*
</p>
<p>.1
1
</p>
<p>8
.0
</p>
<p>0
1
</p>
<p>&minus;
.7
</p>
<p>2
&minus;
</p>
<p>.1
6
</p>
<p>G
o
</p>
<p>ld
.0
</p>
<p>4
7
</p>
<p>.1
6
</p>
<p>4
.9
</p>
<p>5
6
</p>
<p>&ndash;
.3
</p>
<p>4
.4
</p>
<p>3
</p>
<p>G
o
</p>
<p>ld
B
</p>
<p>lu
e
</p>
<p>&minus;
.4
</p>
<p>8
7
</p>
<p>*
.1
</p>
<p>4
5
</p>
<p>.0
0
</p>
<p>3
&minus;
</p>
<p>.8
3
</p>
<p>&minus;
.1
</p>
<p>5
</p>
<p>S
ilv
</p>
<p>e
r
</p>
<p>&minus;
.0
</p>
<p>4
7
</p>
<p>.1
6
</p>
<p>4
.9
</p>
<p>5
6
</p>
<p>&minus;
.4
</p>
<p>3
.3
</p>
<p>4
</p>
<p>* 
T
</p>
<p>h
e
</p>
<p> m
e
</p>
<p>a
n
</p>
<p> d
if
</p>
<p>fe
re
</p>
<p>n
ce
</p>
<p> is
 s
</p>
<p>ig
n
</p>
<p>if
ic
</p>
<p>a
n
</p>
<p>t 
a
</p>
<p>t 
th
</p>
<p>e
 0
</p>
<p>.0
5
</p>
<p>&nbsp;le
ve
</p>
<p>l.</p>
<p/>
</div>
<div class="page"><p/>
<p>204 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>6.6.2.3 Make the Test Decision
</p>
<p>Let&rsquo;s now focus on the F-test result with respect to the overall model in . Table&nbsp;6.11. The 
model has an F-value of 9.963, which yields a p-value of 0.00 (less than 0.05), suggesting 
that at least two of the three groups differ significantly with regard to the overall price/per-
formance satisfaction. SPSS also indicates the between-group sum of squares (i.e., SSB), 
which is labelled Between Groups in . Table&nbsp;6.11 and the within-group sum of squares 
(i.e., SSW), which is labelled Within Groups. The total sum of squares (i.e., SST) is the sum 
of this. We will need these figures to calculate the effect size later.
</p>
<p>6.6.2.4 Carry Out Post Hoc Tests
</p>
<p>To evaluate whether all groups are mutually different or only two, we take a look at the 
post hoc test results. The Levene&rsquo;s test showed that the population variances are equal. The 
descriptive statistics in . Table&nbsp;6.9 indicate that the group-specific sample sizes are clearly 
different. Hence, following the procedure in . Fig.&nbsp;6.6, we should focus on the interpreta-
tion of Hochberg&rsquo;s GT2.
</p>
<p>The results in . Table&nbsp;6.12 list a series of comparisons based on Hochberg&rsquo;s GT2 (upper 
part) and the Games-Howell procedure (lower part). In the first row, you can see the com-
parison between the Blue group and Silver group. The difference between the means of 
these two groups is 0.440 units. Following this row across, we see that this difference is sta-
tistically significant (p-value&nbsp;=&nbsp;0.001). On the contrary, further below, we can see that the 
difference between the Silver and Gold groups (0.047) is not significant (p-value&nbsp;=&nbsp;0.990).
</p>
<p>Even though the population variances are assumed to be equal and group-specific 
sample sizes differ, let us take a look at the results of the Ryan/Einot-Gabriel/Welsch Q 
procedure for the sake of completeness. . Table&nbsp;6.13 organizes the means of the three 
groups into homogeneous subsets. Subsets that do not differ at a significance level of 0.05 
are grouped together, and subsets that differ are placed in separate columns. Notice how 
the Blue group shows up in a separate column than the Gold and Silver groups. This indi-
cates that the Blue group is significantly different from the other two in terms of the overall 
price/performance satisfaction. The Gold and Silver groups show up in the same column, 
indicating that they are not significantly different from each other. The lower part of  
. Table&nbsp;6.13 uses the same display to illustrate the results of Hochberg&rsquo;S GT2.
</p>
<p>6.6.2.5 Measure the Strength of the Effects
</p>
<p>Finally, we want to examine the strength of the effect by computing η&sup2; and ω&sup2;. However, 
the One-Way ANOVA analysis in SPSS does not provide these measures.13 Nevertheless 
we can easily compute η&sup2; and ω&sup2; manually using the information from . Table&nbsp;6.10. For 
this we need to look up SSB, SST, SSW, n and k from the output. Note also that MSW&nbsp;=&nbsp;SSW/
(n-k) and that k represents the number of groups to compare while n represents the 
sample size.
</p>
<p>13 Note that when initiating the analysis by going to ► Analyze ► General Linear Model ► Univariate, 
we can request these statistics under Options (Estimates of effect size).
</p>
<p>6</p>
<p/>
</div>
<div class="page"><p/>
<p>6205
6.6 &middot; Example
</p>
<p>η2
51 755
</p>
<p>2810 210
0 0184= = =
</p>
<p>SS
</p>
<p>SS
B
</p>
<p>T
</p>
<p>.
</p>
<p>.
.  
</p>
<p>ω2
1 51 755 3 1 2 560
</p>
<p>2810 210 2 560
0=
</p>
<p>&minus; &minus;( )&sdot;
+
</p>
<p>=
&minus; &minus;( )&sdot;
+
</p>
<p>=
SS k MS
</p>
<p>SS MS
B W
</p>
<p>T W
</p>
<p>. .
</p>
<p>. .
..0166
</p>
<p> 
</p>
<p>The effect size η2 is 0.0184. This means that differences in the travelers&rsquo; status explain 
1.841&nbsp;% of the total variation in the overall price/performance satisfaction. The ω&sup2; dis-
played is 0.0166, which is low.
</p>
<p>6.6.2.6 Interpret the Results
Overall, based on the outputs of the ANOVA in . Table&nbsp;6.11 and the post-hoc output in 
Tables&nbsp;6.12, we conclude that:
1. Gold and Blue members, as well as Silver and Blue members, differ significantly in 
</p>
<p>their mean overall price/performance satisfaction.
2. There is no difference between Gold and Silver members in their mean overall price/
</p>
<p>performance satisfaction.
3. Membership status explains only a minimal share of the customers&rsquo; price/perfor-
</p>
<p>mance satisfaction. Hence, other factors&mdash;presently not included in the model&mdash;
explain the remaining variation in the outcome variable.
</p>
<p>. Table 6.13 Post hoc test results (Ryan/Einot-Gabriel/Welsch Q procedure)
</p>
<p>Overall, I am satisfied with the price performance ratio of Oddjob Airways.
</p>
<p>Traveler Status N
</p>
<p>Subset for alpha&nbsp;=&nbsp;0.05
</p>
<p>1 2
</p>
<p>Ryan-Einot-Gabriel-
</p>
<p>Welsch Range
</p>
<p>Gold 143 3.99
</p>
<p>Silver 245 4.03
</p>
<p>Blue 677 4.47
</p>
<p>Sig. .807 1.000
</p>
<p>Hochberga, b Gold 143 3.99
</p>
<p>Silver 245 4.03
</p>
<p>Blue 677 4.47
</p>
<p>Sig. .985 1.000
</p>
<p>Means for groups in homogeneous subsets are displayed.
a Uses Harmonic Mean Sample Size&nbsp;=&nbsp;239.011.
b The group sizes are unequal. The harmonic mean of the group sizes is used. Type I error levels 
</p>
<p>are not guaranteed.</p>
<p/>
</div>
<div class="page"><p/>
<p>206 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>6.7 Customer Spending Analysis with IWD Market Research 
(Case Study)
</p>
<p>Founded in 1998, IWD Market Research Institute (https://www.iwd-marketresearch.com/index.
</p>
<p>php) is a major German full-service provider, specialized in smartphone-supported face-to-
</p>
<p>face surveys, particularly in the retail sector. One of the company&rsquo;s main fields of expertise are 
</p>
<p>catchment area studies. These studies involve analyzing from which streets or districts potential 
</p>
<p>customers originate, along with their demographics and spending behavior.
</p>
<p>Case Study
</p>
<p>6</p>
<p/>
<div class="annotation"><a href="https://www.iwd-marketresearch.com/index.php">https://www.iwd-marketresearch.com/index.php</a></div>
<div class="annotation"><a href="https://www.iwd-marketresearch.com/index.php">https://www.iwd-marketresearch.com/index.php</a></div>
</div>
<div class="page"><p/>
<p>6207
6.8 &middot; Review Questions
</p>
<p>In 2017, one of UK&rsquo;s major supermarket chains commissioned a study to better understand their 
</p>
<p>customer base. In the course of this project, IWD surveyed the following items among 7199 
</p>
<p>customers who frequented the store during the project period (variable names in parentheses):
</p>
<p> 5 Could you please tell me your current postal code? (postal_code)
 5 How often do you shop in this store? (frequency)
 5 How much have you spent today? (spending)
 5 Do you regularly receive our leaflet at home? (leaflet)
 5 How did you get here today? (journey)
 5 May I ask you for your age? (age)
 5 How many people live in your household (including yourself )? (household)
 5 The customer&rsquo;s gender (gender)
</p>
<p>Use the data provided in IWD.sav (⤓ Web Appendix &rarr; Downloads) to answer the following 
research questions:
</p>
<p>1. Is there a significant difference in spending between male and female customers?
</p>
<p>2. Does the intensity with which customers receive a leaflet variable have a significant effect 
</p>
<p>on their spending? Use an appropriate test to check for significant differences in spending 
</p>
<p>between each of the three categories of the leaflet variable (&ldquo;Yes, regularly (weekly);&rdquo; &ldquo;Yes, 
</p>
<p>irregularly;&rdquo; &ldquo;No&rdquo;).
</p>
<p>3. Does the customers&rsquo; spending depend on how they got to the supermarket (journey)? Are 
</p>
<p>there significant differences between the journey types?
</p>
<p>4. Extend the previous analysis by researching the impact of leaflet and journey on spending. Is 
</p>
<p>there a significant interaction between the leaflet and journey variables?
</p>
<p>5. Based on your analysis results, please provide recommendations for the management team 
</p>
<p>on how to align their future marketing actions.
</p>
<p>6.8 Review Questions
</p>
<p>1. Describe the steps involved in hypothesis testing in your own words.
2. If you take a look at the following video, you will see many situations that could be 
</p>
<p>tested. Please identify these and discuss what tests are needed.
</p>
<p>&copy; igmarx/Getty Images/iStock
</p>
<p>https://www.youtube.com/
</p>
<p>watch?v=CJOfmHmwGO0</p>
<p/>
<div class="annotation"><a href="https://www.youtube.com/watch?v=CJOfmHmwGO0">https://www.youtube.com/watch?v=CJOfmHmwGO0</a></div>
<div class="annotation"><a href="https://www.youtube.com/watch?v=CJOfmHmwGO0">https://www.youtube.com/watch?v=CJOfmHmwGO0</a></div>
</div>
<div class="page"><p/>
<p>208 Chapter 6 &middot; Hypothesis Testing and ANOVA 
</p>
<p>3. Explain the concept of the p-value and explain how it relates to the significance level α.
4. What level of α would you choose for the following types of market research studies? 
</p>
<p>Give reasons for your answers.
(a)  An initial study on preferences for mobile phone colors.
(b) The production quality of Rolex watches.
(c)  A repeat study on differences in preference for either Coca Cola or Pepsi.
</p>
<p>5. Write two hypotheses for each of the example studies in question 4, including the 
null hypothesis and alternative hypothesis.
</p>
<p>6. Describe the difference between independent and paired samples t-tests in your own 
words and provide two examples of each type.
</p>
<p>7. What is the difference between an independent samples t-test and an ANOVA?
8. What are post hoc test and why is their application useful in ANOVA?
</p>
<p>References
</p>
<p>Agresti, A., &amp; Finlay, B. (2014). Statistical methods for the social sciences (4th ed.). London: Pearson.
</p>
<p>Benjamin, D. J., et al. (2018). Redefine statistical significance. Nature Human Behaviour, 2, 6&ndash;10.
</p>
<p>Boneau, C. A. (1960). The effects of violations of assumptions underlying the t test. Psychological Bulletin, 
</p>
<p>57(1), 49&ndash;64.
</p>
<p>Cohen, J. (1992). A power primer. Psychological Bulletin, 112(1), 155&ndash;159.
</p>
<p>Everitt, B. S., &amp; Skrondal, A. (2010). The Cambridge dictionary of statistics (4th ed.). Cambridge: Cambridge 
</p>
<p>University Press.
</p>
<p>Field, A. (2013). Discovering statistics using SPSS (4th ed.). London: Sage.
</p>
<p>Hubbard, R., &amp; Bayarri, M. J. (2003). Confusion over measure of evidence (p&rsquo;s) versus errors (α&rsquo;s) in classical 
</p>
<p>statistical testing. The American Statistician, 57(3), 171&ndash;178.
</p>
<p>Kimmel, H. D. (1957). Three criteria for the use of one-tailed tests. Psychological Bulletin, 54(4), 351&ndash;353.
</p>
<p>Lehmann, E. L. (1993). The Fischer, Neyman-Pearson theories of testing hypotheses: One theory or two? 
</p>
<p>Journal of the American Statistical Association, 88(424), 1242&ndash;1249.
</p>
<p>Lakens, D., et al. (2018). Justify your alpha. Nature Human Behaviour, 2, 168&ndash;171.
</p>
<p>Levene, H. (1960). Robust tests for equality of variances. In I. Olkin (Ed.) Contributions to probability and 
</p>
<p>statistics (pp. 278&ndash;292). Palo Alto, CA: Stanford University Press.
</p>
<p>Liao, T. F. (2002). Statistical group comparison. New York, NJ: Wiley-InterScience.
</p>
<p>Mann, H. B., &amp; Whitney, D. R. (1947). On a test of whether one of two random variables is stochastically 
</p>
<p>larger than the other. The Annals of Mathematical Statistics, 18(1), 50&ndash;60.
</p>
<p>Norman, G. (2010). Likert scales, levels of measurement and the &ldquo;laws&rdquo; of statistics. Advances in Health 
</p>
<p>Sciences Education, 15(5), 625&ndash;632.
</p>
<p>Nuzzo, R. (2014). Scientific method: Statistical errors. Nature, 506(7487), 150&ndash;152.
</p>
<p>Ruxton, G. D., &amp; Neuhaeuser, M. (2010). When should we use one-tailed hypothesis testing? Methods in 
</p>
<p>Ecology and Evolution, 1(2), 114&ndash;117.
</p>
<p>Schuyler, W. H. (2011). Readings statistics and research (6th ed). London: Pearson.
</p>
<p>Shapiro, S. S., &amp; Wilk, M. B. (1965). An analysis of variance test for normality (complete samples). Biometri-
</p>
<p>ka, 52(3/4), 591&ndash;611.
</p>
<p>Van Belle, G. (2008). Statistical rules of thumb (2nd ed.). Hoboken, N.J.: John Wiley &amp; Sons.
</p>
<p>Wasserstein, R. L., &amp; Lazar, N. A. (2016). The ASA&rsquo;s statement on p-values: Context, process, and purpose. 
</p>
<p>The American Statistician, 70(2), 129&ndash;133.
</p>
<p>Welch, B. L. (1951). On the comparison of several mean values: An alternative approach. Biometrika, 
</p>
<p>38(3/4), 330&ndash;336.
</p>
<p>Further Readings
</p>
<p>Kanji, G. K. (2006). 100 statistical tests (3rd ed.). London: Sage.
</p>
<p>Van Belle, G. (2011). Statistical rules of thumb (2nd ed.). Hoboken, N.J.: John Wiley &amp; Sons.
</p>
<p>6</p>
<p/>
</div>
<div class="page"><p/>
<p>209
</p>
<p>Regression Analysis
</p>
<p>7.1 Introduction &ndash; 210
</p>
<p>7.2 Understanding Regression Analysis &ndash; 211
</p>
<p>7.3 Conducting a Regression Analysis &ndash; 214
7.3.1 Check the Regression Analysis Data Requirements &ndash; 214
</p>
<p>7.3.2 Specify and Estimate the Regression Model &ndash; 217
</p>
<p>7.3.3 Test the Regression Analysis Assumptions &ndash; 221
</p>
<p>7.3.4 Interpret the Regression Results &ndash; 227
</p>
<p>7.3.5 Validate the Regression Results &ndash; 232
</p>
<p>7.3.6 Use the Regression Model &ndash; 233
</p>
<p>7.4 Example &ndash; 238
</p>
<p>7.5 Farming with AgriPro (Case Study) &ndash; 252
</p>
<p>7.6 Review Questions &ndash; 254
</p>
<p> References &ndash; 255
</p>
<p>7
</p>
<p>Electronic supplementary material
</p>
<p>The online version of this chapter (https://doi.org/10.1007/978-3-662-56707-4_7) contains 
</p>
<p>additional material that is available to authorized users. You can also download the &ldquo;Springer 
</p>
<p>Nature More Media App&rdquo; from the iOS or Android App Store to stream the videos and scan the 
</p>
<p>image containing the &ldquo;Play button&rdquo;.
</p>
<p>&copy; Springer-Verlag GmbH Germany, part of Springer Nature 2019 
</p>
<p>M. Sarstedt, E. Mooi, A Concise Guide to Market Research, Springer Texts in Business  
</p>
<p>and Economics, https://doi.org/10.1007/978-3-662-56707-4_7</p>
<p/>
<div class="annotation"><a href="https://crossmark.crossref.org/dialog/?doi=10.1007/978-3-662-56707-4_7&amp;amp;domain=pdf&amp;amp;date_stamp=2018-9-17">https://crossmark.crossref.org/dialog/?doi=10.1007/978-3-662-56707-4_7&amp;amp;domain=pdf&amp;amp;date_stamp=2018-9-17</a></div>
</div>
<div class="page"><p/>
<p>210 Chapter 7 &middot; Regression Analysis
</p>
<p>Keywords
Adjusted R2 &bull; Akaike information criterion &bull; Autocorrelation &bull; Bayes information criterion &bull; Binary 
</p>
<p>logistic regression &bull; Bootstrapping &bull; Coefficient of determination &bull; Collinearity &bull; Constant &bull; Control 
</p>
<p>variables &bull; Cross-validation &bull; Dependent variables &bull; Dummy variables &bull; Durbin-Watson test &bull; Error &bull; 
</p>
<p>Error sum of squares &bull; Estimation sample &bull; F-test &bull; Heteroscedasticity &bull; Homoscedasticity &bull; Independent 
</p>
<p>variables &bull; Intercept &bull; Moderation analysis &bull; Multicollinearity &bull; Multinomial logistic regression &bull; Multiple 
</p>
<p>regression &bull; Nested models &bull; Ordinary least squares &bull; Outliers &bull; Ramsey&rsquo;s RESET test &bull; Regression sum 
</p>
<p>of squares &bull; Residual &bull; R2 &bull; Simple regression &bull; Split-sample validation &bull; Standard error &bull; Standardized 
</p>
<p>effects &bull; Tolerance &bull; Unstandardized effects &bull; Validation Sample &bull; Variance inflation factor &bull; Weighted 
</p>
<p>Least Squares
</p>
<p>7.1 Introduction
</p>
<p>Regression analysis is one of the most frequently used analysis techniques in market 
research. It allows market researchers to analyze the relationships between dependent 
variables and independent variables. In marketing applications, the dependent variable is 
the outcome we care about (e.g., sales), while we use the independent variables to achieve 
those outcomes (e.g., pricing or advertising). The key benefits of using regression analy-
sis are it allows us to:
1. Calculate if one independent variable or a set of independent variables has a 
</p>
<p>significant relationship with a dependent variable.
2. Estimate the relative strength of different independent variables&rsquo; effects on a 
</p>
<p>dependent variable.
3. Make predictions.
</p>
<p>Knowing what the effects of independent variables on dependent variables are, helps 
market researchers in many different ways. For example, this knowledge can help guide 
spending if we know promotional activities relate strongly to sales.
</p>
<p>Knowing effects&rsquo; relative strength is useful for marketers, because it may help answer 
questions such as: Do sales depend more on the product price or on product promotions? 
Regression analysis also allows us to compare the effects of variables measured on different 
</p>
<p>Learning Objectives
After reading this chapter you should understand:
</p>
<p> 5 The basic concept of regression analysis.
 5 How regression analysis works.
 5 The requirements and assumptions of regression analysis.
 5 How to specify a regression analysis model.
 5 How to interpret regression analysis results.
 5 How to predict and validate regression analysis results.
 5 How to conduct regression analysis with SPSS.
 5 How to interpret regression analysis output produced by SPSS.
</p>
<p>7</p>
<p/>
</div>
<div class="page"><p/>
<p>7211
7.2 &middot; Understanding Regression Analysis
</p>
<p>scales, such as the effect of price changes (e.g., measured in dollars) and the effect of a spe-
cific number of promotional activities.
</p>
<p>Regression analysis can also help us make predictions. For example, if we have esti-
mated a regression model by using data on the weekly supermarket sales of a brand of milk 
in dollars, the milk price (which changes with the season and supply), as well as an index 
of promotional activities (comprising product placement, advertising, and coupons), the 
results of the regression analysis could answer the question: what would happen to the 
sales if the prices were to increase by 5&nbsp;% and the promotional activities by 10&nbsp;%? Such 
answers help (marketing) managers make sound decisions. Furthermore, by calculating 
various scenarios, such as price increases of 5, 10, and 15&nbsp;%, managers can evaluate mar-
keting plans and create marketing strategies.
</p>
<p>7.2 Understanding Regression Analysis
</p>
<p>In the previous paragraph, we briefly discussed what regression can do and why it is a useful 
market research tool. We now provide a more detailed discussion. Look at . Fig.&nbsp;7.1: It plots 
a dependent (y) variable (the weekly sales of a brand of milk in dollars against an indepen-
dent (x1) variable (an index of promotional activities). Regression analysis is a way of fitting 
a &ldquo;best&rdquo; line through a series of observations. With a &ldquo;best&rdquo; line we mean one that is fitted 
in such a way that it minimizes the sum of the squared differences between the observa-
tions and the line itself. It is important to know that the best line fitted by means of regres-
sion analysis is not necessarily the true line (i.e., the line that represents the population). 
Specifically, if we have data issues, or fail to meet the regression assumptions (discussed 
later), the estimated line may be biased.
</p>
<p>Before we discuss regression analysis further, we should discuss regression notation. 
Regression models are generally written as follows:
</p>
<p>y x e= + +α β1 1  
</p>
<p>What does this mean? The y represents the dependent variable, which is the outcome you 
are trying to explain. In . Fig.&nbsp;7.1, we plot the dependent variable on the vertical axis. The 
α represents the constant (or intercept) of the regression model, and indicates what your 
dependent variable would be if the independent variable were zero. In . Fig.&nbsp;7.1, you can see 
the constant is the value where the fitted straight (sloping) line crosses the y-axis, which is 
at 2463.963. Thus, if the index of promotional activities is zero, we expect the weekly super-
market sales of a specific milk brand to be $2464. It may not always be realistic to assume 
that independent variables are zero (prices are, after all, rarely zero), but the constant 
should always be included to ensure the regression model&rsquo;s best possible fit with the data.
</p>
<p>The independent variable is indicated by x1, while the &szlig;1 (pronounced beta) indicates 
its (regression) coefficient. This coefficient represents the slope of the line, or the slope of 
the diagonal grey line in . Fig.&nbsp;7.1. A positive &szlig;1 coefficient indicates an upward sloping 
regression line, while a negative &szlig;1 coefficient indicates a downward sloping line. In our 
example, the line slopes upward. This makes sense, since sales tend to increase with an 
increase in promotional activities. In our example, we estimate the &szlig;1 as 54.591, meaning </p>
<p/>
</div>
<div class="page"><p/>
<p>212 Chapter 7 &middot; Regression Analysis
</p>
<p>that if we increase the promotional activities by one unit, the weekly supermarket sales of 
a brand of milk will go up by an average of $54.591. This &szlig;1 value has a degree of associ-
ated uncertainty called the standard error. This standard error is assumed to be normally 
distributed. Using a t-test (see 7 Chap.&nbsp;6), we can test if the &szlig;1 is indeed significantly dif-
ferent from zero.
</p>
<p>The last element of the notation, the e, denotes the equation error (also called the 
residual or disturbance term). The error is the distance between each observation and 
the best fitting line. To clarify what a regression error is, examine . Fig.&nbsp;7.1 again. The 
error is the difference between the regression line (which represents our regression pre-
diction) and the actual observation (indicated by each dot). The predictions made by 
the &ldquo;best&rdquo; regression line are indicated by  ŷ  (pronounced y-hat). Thus, the error of 
each observation is:1
</p>
<p>e y y= &minus; ˆ  
</p>
<p>.00
</p>
<p>.00
</p>
<p>5000.00
</p>
<p>10000.00
</p>
<p>15000.00
</p>
<p>20.00 40.00 60.00
</p>
<p>Index of promotional activities
</p>
<p>W
e
</p>
<p>e
k
</p>
<p>ly
 s
</p>
<p>a
le
</p>
<p>s 
in
</p>
<p> U
S
</p>
<p>D
</p>
<p>80.00 100.00 120.00 140.00
</p>
<p>. Fig.&nbsp;7.1 A visual explanation of regression analysis
</p>
<p>1 Strictly speaking, the difference between the predicted and the observed y-values is .̂e
</p>
<p>7</p>
<p/>
</div>
<div class="page"><p/>
<p>7213
7.2 &middot; Understanding Regression Analysis
</p>
<p>In the example above, we have only one independent variable. We call this simple 
regression. If we include multiple independent variables, we call this multiple regression. 
The notation for multiple regression is like that of simple regression. If we were to have 
two independent variables, for example the price (x1), and an index of promotional activ-
ities (x2), our notation would be:
</p>
<p>y x x e= + + +α β β1 1 2 2  
</p>
<p>We need one regression coefficient for each independent variable (i.e., &szlig;1 and &szlig;2). Tech-
nically the &szlig;s indicate how a change in an independent variable influences the dependent 
variable if all other independent variables are held constant.2
</p>
<p>2 This only applies to the standardized βs.
</p>
<p>Now that we have introduced a few regression analysis basics, it is time to discuss how to 
execute a regression analysis. We outline the key steps in . Fig.&nbsp;7.2. We first introduce the 
regression analysis data requirements, which will determine if regression analysis can be 
used. After this first step, we specify and estimate the regression model. Next, we discuss the 
basics, such as which independent variables to select. Thereafter, we discuss the assump-
tions of regression analysis, followed by how to interpret and validate the regression results. 
The last step is to use the regression model to, for example, make predictions.
</p>
<p>The Explained Visually webpage offers an excellent visualization of how regression analysis works.
</p>
<p>&copy; Kurt Kleemann/stock.adobe.com
</p>
<p>http://setosa.io/ev/ordinary-least-squares-regression/</p>
<p/>
<div class="annotation"><a href="http://setosa.io/ev/ordinary-least-squares-regression/">http://setosa.io/ev/ordinary-least-squares-regression/</a></div>
</div>
<div class="page"><p/>
<p>214 Chapter 7 &middot; Regression Analysis
</p>
<p>7.3 Conducting a Regression Analysis
</p>
<p>7.3.1 Check the Regression Analysis Data Requirements
</p>
<p>Various data requirements must be taken into consideration before we undertake a regres-
sion analysis. These include the:
 4 Sample size,
 4 variables need to vary,
 4 scale type of the dependent variable, and
 4 collinearity.
</p>
<p>We discuss each requirement in turn.
</p>
<p>7.3.1.1 Sample Size
</p>
<p>The first data requirement is that we need an &ldquo;acceptable&rdquo; sample size. &ldquo;Acceptable&rdquo; relates 
to a sample size that gives you a good chance of finding significant results if they are pos-
sible (i.e., the analysis achieves a high degree of statistical power; see 7 Chap.&nbsp;6). There are 
two ways to calculate &ldquo;acceptable&rdquo; sample sizes.
 4 The first, formal, approach is a power analysis. As mentioned in 7 Chap.&nbsp;6 (Box&nbsp;6.2), 
</p>
<p>these calculations require you to specify several parameters, such as the expected 
effect size and the maximum type I error you want to allow for. Generally, you should 
set the power to 0.80, which is an acceptable level. A power level of 0.80&nbsp;means there 
is an 80&nbsp;% probability of deciding that an effect will be significant, if it is indeed 
significant. Kelley and Maxwell (2003) discuss sample size requirements in far 
</p>
<p>Check the regression analysis data requirements 
</p>
<p>Specify and estimate the regression model 
</p>
<p>Test the regression analysis assumptions 
</p>
<p>Interpret the regression results 
</p>
<p>Validate the regression results 
</p>
<p>Use the regression model 
</p>
<p>. Fig.&nbsp;7.2 Steps involved in a regression analysis
</p>
<p>7</p>
<p/>
</div>
<div class="page"><p/>
<p>7215
7.3 &middot; Conducting a Regression Analysis
</p>
<p>more detail. G*power&mdash;a free program available at http://www.gpower.hhu.de &mdash;is 
commonly used to calculate sample sizes precisely. SPSS also provides an add-on 
module called &ldquo;Sample Power,&rdquo; which can be used to carry out such analyses.
 4 The second approach is by using rules of thumb. These rules are not specific or 
</p>
<p>precise, but are easy to apply. Green (1991); VanVoorhis and Morgan (2007) suggest 
that if you want to test for individual parameters&rsquo; effect (i.e., whether one coefficient 
is significant or not), you need a sample size of 104&nbsp;+&nbsp;k. Thus, if you have ten 
independent variables, you need 104&nbsp;+&nbsp;10&nbsp;=&nbsp;114 observations. Note that this rule of 
thumb is best applied when you have a small number of independent variables, less 
than 10 and certainly less than 15. VanVoorhis and Morgan (2007) add that having 
at least 30 observations per variable (i.e. 30&nbsp;k) allows for detecting smaller effects (an 
expected R2 of 0.10 or smaller) better.
</p>
<p>7.3.1.2 Variables Need to Vary
</p>
<p>A regression model cannot be estimated if the variables have no variation. If there is no 
variation in the dependent variable (i.e., it is constant), we also do not need regression, as 
we already know what the dependent variable&rsquo;s value is! Likewise, if an independent vari-
able has no variation, it cannot explain any variation in the dependent variable.
</p>
<p>3 This is only a requirement if you are interested in the regression coefficients, which is the dominant 
</p>
<p>use of regression. If you are only interested in prediction, collinearity is not important.
</p>
<p>No variation can lead to epic failures! Consider the admission tests set by the Uni-
</p>
<p>versity of Liberia: Not a single student passed the entry exams. In such situations, a 
</p>
<p>regression analysis will clearly make no difference! https://www.independent.co.uk/
</p>
<p>student/news/epic-fail-all-25000-students-fail-university-entrance-exam-in-libe-
</p>
<p>ria-8785707.html
</p>
<p>7.3.1.3 Scale Type of the Dependent Variable
The third data requirement is that the dependent variable needs to be interval or ratio 
scaled (7 Chap.&nbsp;3 discusses scaling). If the data are not interval or ratio scaled, alternative 
types of regression should be used. You should use binary logistic regression if the depen-
dent variable is binary and only takes two values (zero and one). If the dependent variable 
is a nominal variable with more than two levels, you should use multinomial logistic regres-
sion. This should, for example, be used if you want to explain why people prefer product A 
over B or C. We do not discuss these different methods in this chapter, but they are related 
to regression. For a discussion of regression methods for dependent variables measured 
on a nominal or ordinal scale, see Field (2013).
</p>
<p>7.3.1.4 Collinearity
</p>
<p>The last data requirement is that no or little collinearity should be present.3 Collinearity is 
a data issue that arises if two independent variables are highly correlated. Perfect collin-
earity occurs if we enter two or more independent variables containing exactly the same </p>
<p/>
<div class="annotation"><a href="http://www.gpower.hhu.de">http://www.gpower.hhu.de</a></div>
<div class="annotation"><a href="https://www.independent.co.uk/student/news/epic-fail-all-25000-students-fail-university-entrance-exam-in-liberia-8785707.html">https://www.independent.co.uk/student/news/epic-fail-all-25000-students-fail-university-entrance-exam-in-liberia-8785707.html</a></div>
<div class="annotation"><a href="https://www.independent.co.uk/student/news/epic-fail-all-25000-students-fail-university-entrance-exam-in-liberia-8785707.html">https://www.independent.co.uk/student/news/epic-fail-all-25000-students-fail-university-entrance-exam-in-liberia-8785707.html</a></div>
<div class="annotation"><a href="https://www.independent.co.uk/student/news/epic-fail-all-25000-students-fail-university-entrance-exam-in-liberia-8785707.html">https://www.independent.co.uk/student/news/epic-fail-all-25000-students-fail-university-entrance-exam-in-liberia-8785707.html</a></div>
</div>
<div class="page"><p/>
<p>216 Chapter 7 &middot; Regression Analysis
</p>
<p>information, therefore yielding a correlation of 1 or &minus;1 (i.e., they are perfectly correlated). 
Perfect collinearity may occur if you enter the same independent variable twice, or if one 
variable is a linear combination of another (e.g., one variable is a multiple of another vari-
able, such as sales in units and sales in thousands of units). If this occurs, regression anal-
ysis cannot estimate one of the two coefficients. In practice, however, weaker forms of col-
linearity are common. For example, if we study what drives supermarket sales, variables 
such as price reductions and promotions are often used together. If this occurs very often, 
the variables price and promotion may be collinear, which means there is little uniqueness 
or new information in each of the variables. The problem with having collinearity is that 
it tends to regard significant parameters as insignificant. Substantial collinearity can even 
lead to sign changes in the regression coefficients&rsquo; estimates. When three or more variables 
are strongly related to each other, we call this multicollinearity.
</p>
<p>Fortunately, collinearity is relatively easy to detect by calculating the variance inflation 
factor (VIF).4 The VIF indicates the effect on the standard error of the regression coefficient 
for each independent variable. Specifically, the square root of the VIF indicates you how 
much larger the standard error is, compared to if that variable were uncorrelated with all 
other independent variables in the regression model. Generally, a VIF of 10 or above indi-
cates that (multi) collinearity is a problem (Hair et al. 2019).5 Some research suggests that 
VIFs far above 10&mdash;such as 20 or 40&mdash;can be acceptable if the sample size is large and the 
R2 (discussed later) is high (0.90 or more) (O&rsquo;brien 2007). Conversely, if the sample sizes 
are below 200 and the R2 is low (0.25 or less), collinearity is more problematic (Mason and 
Perreault 1991). Consequently, in such situations, lower VIF values&mdash;such as 5&mdash;should 
be the maximum.
</p>
<p>You can remedy collinearity in several ways but each of these have costs. If perfect 
collinearity occurs, drop one of the perfectly overlapping variables. If weaker forms of 
collinearity occur, you can utilize three approaches to reduce collinearity (O&rsquo;brien 2007):
</p>
<p> 4 The first option is to use principal component or factor analysis on the collinear 
variables (see 7 Chap.&nbsp;8). By using principal component or factor analysis, you create 
a small number of factors that comprise most of the original variables&rsquo; information, 
but are uncorrelated. If you use factors, collinearity no longer an issue.
 4 The second option is to re-specify the regression model by removing highly 
</p>
<p>correlated variables. Which variables should you remove? If you create a correlation 
matrix of all the independent variables entered in the regression model, you 
should first focus on the variables that are most strongly correlated (see 7 Chap.&nbsp;5 
for how to create a correlation matrix). First try removing one of the two most 
strongly correlated variables. The one you should remove depends on your research 
problem&mdash;retain the most relevant variable of the two.
</p>
<p>4 A related measure is the tolerance, which is 1/VIF and calculated as 1/(1&minus;R2).
</p>
<p>5 The VIF is calculated using a completely separate regression analysis. In this regression analysis, the 
</p>
<p>variable for which the VIF is calculated is regarded as a dependent variable and all other indepen-
</p>
<p>dent variables are regarded as independents. The R2 that this model provides is deducted from 1 
</p>
<p>and the reciprocal value of this sum (i.e., 1/(1&minus;R2)) is the VIF. The VIF is therefore an indication of how 
</p>
<p>much the regression model explains one independent variable. If the other variables explain much 
</p>
<p>of the variance (the VIF is larger than 10), collinearity is likely a problem.
</p>
<p>7</p>
<p/>
</div>
<div class="page"><p/>
<p>7217
7.3 &middot; Conducting a Regression Analysis
</p>
<p> 4 The third option is not to do anything. In many cases removing collinear variables 
does not reduce the VIF values significantly. Even if we do, we run the risk of 
mis-specifying the regression model (see Box 7.1 for details). Given the trouble 
researchers go through to collect data and specify a regression model, it is often 
better to accept collinearity in all but the most extreme cases. In this case, however, 
we should be cautious with the interpretation of the regression coefficients because 
their values and significance levels may be biased.
</p>
<p>7.3.2 Specify and Estimate the Regression Model
</p>
<p>We need to select the variables we want to include and decide how to estimate the model 
to conduct a regression analysis. In the following, we will discuss each step in detail.
</p>
<p>7.3.2.1 Model Specification
</p>
<p>The model specification step involves choosing the variables to use. The regression model 
should be simple yet complete. To quote Albert Einstein: &ldquo;Everything should be made 
as simple as possible, but not simpler!&rdquo; How do we achieve this? By focusing on our 
ideas of what relates to the dependent variable of interest, the availability of data, client 
requirements, and prior regression models. For example, typical independent variables 
that explain the sales of a product include the price and promotions. When available, 
in-store advertising, competitors&rsquo; prices, and promotions are usually also included. Market 
researchers may, of course, choose different independent variables for other applications. 
Omitting important variables (see Box 7.1) has substantial implications for the regression 
model, so it is best to be inclusive. A few practical suggestions:
</p>
<p> 4 If you have many variables available in the data that overlap in terms of how 
they are defined&mdash; such as satisfaction with the waiter/waitress and with the 
speed of service&mdash;try to pick the variable that is most distinct or relevant for the 
client. Alternatively, you could conduct a principal component or factor analysis 
(see 7&nbsp;Chap.&nbsp;8) first and use the factors as the regression analysis&rsquo;s independent 
variables.
</p>
<p>Box 7.1 Omitting relevant variables
</p>
<p>Omitting key variables from a regression model can lead to biased results. Imagine that we want 
</p>
<p>to explain weekly sales by only referring to promotions. From the introduction, we know the &szlig; of 
</p>
<p>the regression model only containing promotions is estimated as 54.591. If we add the variable 
</p>
<p>price (arguably a key variable), the estimated &szlig; of promotions drops to 42.266. As can be seen, 
</p>
<p>the difference between the estimated &szlig;s in the two models (i.e., with and without price) is 12.325, 
</p>
<p>suggesting that the &ldquo;true&rdquo; relationship between promotions and sales is weaker than in a model 
</p>
<p>with only one independent variable. This example shows that omitting important independent 
</p>
<p>variables leads to biases in the value of the estimated &szlig;s. That is, if we omit a relevant variable x2 
</p>
<p>from a regression model that only includes x1, we cause a bias in the &szlig;1 estimate. More precisely, 
</p>
<p>the &szlig;1 is likely to be inflated, which means that the estimated value is higher than it should be.
</p>
<p>Thus, the &szlig;1 itself is biased because we omit x2!</p>
<p/>
</div>
<div class="page"><p/>
<p>218 Chapter 7 &middot; Regression Analysis
</p>
<p> 4 If you expect to need a regression model for different circumstances, you should 
make sure that the independent variables are the same, which will allow you 
to compare the models. For example, temperature can drive the sales of some 
supermarket products (e.g., ice cream). In some countries, such as Singapore, the 
temperature is relatively constant, so including this variable is not important. In 
other countries, such as Germany, the temperature can fluctuate far more. If you are 
intent on comparing the ice cream sales in different countries, it is best to include 
variables that may be relevant to all the countries you want to compare (e.g., by 
including temperature, even if it is not very important in Singapore).
 4 Consider the type of advice you want to provide. If you want to make concrete 
</p>
<p>recommendations regarding how to use point-of-sales promotions and free product 
giveaways to boost supermarket sales, both variables need to be included.
 4 Take the sample size rules of thumb into account. If practical issues limit the 
</p>
<p>sample size to below the threshold that the rules of thumb recommend, use as few 
independent variables as possible. Larger sample sizes allow you more freedom to 
add independent variables, although they still need to be relevant.
 4 If you have ordinal variables, you need to construct dummy variables. Dummy 
</p>
<p>variables indicate categories or subgroups using a 0 (absent) or 1 (present) value. 
Dummies can be used to understand if for example ice cream sales differ between 
three countries, France, Germany, and Singapore. We need only two variables to 
indicate the groups since if sales observations do not come from Germany (=0) 
or Singapore (=0), they need to be from France. Thus, we have used France as the 
base category. Sometimes the choice of base category is not so important but if we 
have a base category where a characteristic is absent (e.g., no advertising compared 
to three dummies that indicate three different forms of advertising) it is useful to 
set this as the base category (by omitting a dummy for this category). Note that we 
always construct one dummy fewer than the number of groups and that it is only a 
decision for which category to omit the dummy! We can enter dummy variables to a 
regression model to estimate if there are differences between categories or subgroups 
(such as countries or types of advertising).
</p>
<p>7.3.2.2 Model Estimation
</p>
<p>Model estimation refers to how we estimate a regression model. The most common method 
of estimating regression models is ordinary least squares (OLS). OLS fits a regression line to 
the data that minimizes the sum of the squared distances to it. These distances are squared 
to stop negative distances (i.e., below the regression line) from cancelling out positive dis-
tances (i.e., above the regression line), because squared values are always positive. More-
over, by using the square, we emphasize observations that are far from the regression much 
more, while observations close to the regression line carry very little weight. The rule to use 
squared distances is an effective (but also arbitrary) way of calculating the best fit between 
a set of observations and a regression line (Hill et al. 2011). If we return to . Fig.&nbsp;7.1, we see 
the vertical &ldquo;spikes&rdquo; from each observation to the regression line. OLS estimation is aimed 
at minimizing the squares of these spikes.
</p>
<p>We use the data behind . Fig.&nbsp;7.1&mdash;as shown in . Table 7.1&mdash;to illustrate the method 
with which OLS regressions are calculated. This data has 30 observations, with information 
</p>
<p>7</p>
<p/>
</div>
<div class="page"><p/>
<p>7219
7.3 &middot; Conducting a Regression Analysis
</p>
<p>. Table 7.1 Regression data
</p>
<p>Week Sales Price Promotion
</p>
<p>1 3454 1.10 12.04
</p>
<p>2 3966 1.08 22.04
</p>
<p>3 2952 1.08 22.04
</p>
<p>4 3576 1.08 22.04
</p>
<p>5 3692 1.08 21.42
</p>
<p>6 3226 1.08 22.04
</p>
<p>7 3776 1.09 47.04
</p>
<p>8 14,134 1.05 117.04
</p>
<p>9 5114 1.10 92.04
</p>
<p>10 4022 1.08 62.04
</p>
<p>11 4492 1.12 87.04
</p>
<p>12 10,186 1.02 92.04
</p>
<p>13 7010 1.08 61.42
</p>
<p>14 4162 1.06 72.04
</p>
<p>15 3446 1.13 47.04
</p>
<p>16 3690 1.05 37.04
</p>
<p>17 3742 1.10 12.04
</p>
<p>18 7512 1.08 62.04
</p>
<p>19 9476 1.08 62.04
</p>
<p>20 3178 1.08 22.04
</p>
<p>21 2920 1.12 2.04
</p>
<p>22 8212 1.04 42.04
</p>
<p>23 3272 1.09 17.04
</p>
<p>24 2808 1.11 7.04
</p>
<p>25 2648 1.12 2.04
</p>
<p>26 3786 1.11 7.04
</p>
<p>27 2908 1.12 2.04
</p>
<p>28 3395 1.08 62.04
</p>
<p>29 4106 1.04 82.04
</p>
<p>30 8754 1.02 132.04</p>
<p/>
</div>
<div class="page"><p/>
<p>220 Chapter 7 &middot; Regression Analysis
</p>
<p>on the supermarket&rsquo;s sales of a brand of milk (sales), the price (price), and an index of pro-
motional activities (promotion) for weeks 1&ndash;30. This dataset is small and only used to illus-
trate how OLS estimates are calculated. The data can be downloaded (⤓ Web Appendix &rarr; 
Downloads), but are also included in . Table 7.1.
</p>
<p>To estimate the effect of price and promotion on sales, we need to calculate the &szlig;s, of 
which the estimate is noted as  β̂  (pronounced as beta-hat). The  β̂  indicates the estimated 
association between each independent variable (price and promotion) and the dependent 
variable sales. We can estimate  β̂  as follows:
</p>
<p> ˆ ( )β = &minus;x x x yT T1  
</p>
<p>In this equation, to solve the  β̂ s, we first multiply the transposed matrix indicated as xT. 
This matrix has three elements, a vector of 1s, which are added to estimate the intercept 
and two vectors of the independent variables price and promotion. Together, these form 
a 30&nbsp;&times;&nbsp;3&nbsp;matrix. Next, we multiply this matrix with the untransposed matrix, indicated 
as x, consisting of the same elements (as a 3&nbsp;&times;&nbsp;30&nbsp;matrix). This multiplication results in a 
3&nbsp;&times;&nbsp;3&nbsp;matrix of which we calculate the inverse, indicated by the power of &minus;1 in the equa-
tion. This also results in a 3&nbsp;&times;&nbsp;3&nbsp;matrix (xTx)&minus;1. Next, we calculate xTy, which consists of the 
30&nbsp;&times;&nbsp;3&nbsp;matrix and the vector with the dependent variables&rsquo; observations (a 1&nbsp;&times;&nbsp;30&nbsp;matrix). 
In applied form:
</p>
<p>x=
</p>
<p>
</p>
<p>
</p>
<p>






</p>
<p>
</p>
<p>
</p>
<p>






</p>
<p>1 1 10 12 04
</p>
<p>1 1 08 22 04
</p>
<p>1 1 02 132 04
</p>
<p>. .
</p>
<p>. .
</p>
<p>. .
</p>
<p>  
,
</p>
<p>xT =
</p>
<p>&hellip;
</p>
<p>&hellip;
</p>
<p>&hellip;
</p>
<p>
</p>
<p>
</p>
<p>



</p>
<p>
</p>
<p>
</p>
<p>



</p>
<p>1 1 1
</p>
<p>1 10 1 08 1 02
</p>
<p>12 04 22 04 132 04
</p>
<p>. . .
</p>
<p>. . .
</p>
<p>,
</p>
<p>( )
</p>
<p>. . .
</p>
<p>. . .
</p>
<p>. . .
</p>
<p>x xT &minus; =
</p>
<p>&minus; &minus;
</p>
<p>&minus;
</p>
<p>&minus;
</p>
<p>
</p>
<p>
</p>
<p>



</p>
<p>1
</p>
<p>77 97 70 52 0 04
</p>
<p>70 52 63 86 0 03
</p>
<p>0 04 0 03 0 00
</p>
<p>
</p>
<p>
</p>
<p>



</p>
<p>,6
</p>
<p>x yT =
</p>
<p>
</p>
<p>
</p>
<p>



</p>
<p>
</p>
<p>
</p>
<p>



</p>
<p>147615 00
</p>
<p>158382 64
</p>
<p>8669899 36
</p>
<p>.
</p>
<p>.
</p>
<p>.
</p>
<p>,
</p>
<p>6 This term can be calculated manually, but also by using the function mmult in Microsoft Excel where  
</p>
<p>x xT  is calculated. Once this matrix has been calculated, you can use the minverse function to arrive 
</p>
<p>at  ( )x xT &minus;1 .
</p>
<p>7</p>
<p/>
</div>
<div class="page"><p/>
<p>7221
7.3 &middot; Conducting a Regression Analysis
</p>
<p> Hence,    ( )
</p>
<p>.
</p>
<p>.
</p>
<p>.
</p>
<p>x x x yT T&minus; &sdot; = &minus;
</p>
<p>
</p>
<p>
</p>
<p>



</p>
<p>
</p>
<p>
</p>
<p>



</p>
<p>1
</p>
<p>30304 05
</p>
<p>25209 86
</p>
<p>42 27
</p>
<p>.
</p>
<p>This last matrix indicates the estimated βs  (i.e.,  β̂ ) with 30,304.05 representing the inter-
cept, &minus;25,209.86 representing the effect of a one-unit increase in the price on sales, and 
42.27 the effect of a one-unit increase in promotions on sales.
</p>
<p>As discussed before, each  β̂  also has a standard error. This standard error can be 
expressed in standard deviations and, as seen in the discussion in 7 Chap.&nbsp;5, values outside the 
&plusmn;&nbsp;1.96&nbsp;&middot;&nbsp;t-value from the  β̂  indicate the significance of two-tailed tests. If this range includes 
a value of 0, the  β̂ is said to be insignificant. If it excludes 0, the  β̂  is said to be significant.
</p>
<p>While OLS is an effective estimator, there are alternatives that work better in specific situations. 
</p>
<p>These situations occur if we violate one of the regression assumptions. For example, if the 
</p>
<p>regression errors are heteroscedastic (discussed in 7 Sect.&nbsp;7.3.3.3), we need to account for this 
by, for example, using Weighted Least Squares (WLS). We briefly discuss when WLS should be 
used in this chapter. If the expected mean error of the regression model is not zero, estimators 
</p>
<p>such as two-staged least squares (2SLS) can be used in specific situations. There are many more 
</p>
<p>estimators, but these are beyond the scope of this book. Greene (2011) discusses these and other 
</p>
<p>estimation procedures in detail.
</p>
<p>7.3.3 Test the Regression Analysis Assumptions
</p>
<p>We have already discussed several issues that determine whether running a regression 
analysis is useful. We now discuss regression analysis assumptions. If a regression anal-
ysis fails to meet its assumptions, it can provide invalid results. Four regression analysis 
assumptions are required to provide valid results:
1. The regression model can be expressed linearly,
2. The regression model&rsquo;s expected mean error is zero,
3. The errors&rsquo; variance is constant (homoscedasticity), and
4. The errors are independent (no autocorrelation).
</p>
<p>There is a fifth assumption which is optional. If we meet this assumption, we have informa-
tion on how the regression parameters are distributed, which allows straightforward con-
clusions regarding their significance. If the regression analysis fails to meet this assumption, 
the regression model will still be accurate, but we cannot rely accurately on the standard 
errors (and t-values) to determine the regression parameters&rsquo; significance.
5. The errors need to be approximately normally distributed.
</p>
<p>We next discuss these assumptions and how we can test each of them.</p>
<p/>
</div>
<div class="page"><p/>
<p>222 Chapter 7 &middot; Regression Analysis
</p>
<p>7.3.3.1 First Assumption: Linearity
The first assumption means that we can write the regression model as  y x e= + +α β1 1 .
Thus, non-linear relationships, such as  β1
</p>
<p>2
1x , are not permissible. However, logarith-
</p>
<p>mic expressions, such as log(x1), are possible as the regression model is still specified 
linearly. If you can write a model whose regression parameters (the &szlig;s) are linear, you 
satisfy this assumption.
</p>
<p>A separate issue is whether the relationship between the independent variable x and 
the dependent variable y is linear. You can check the linearity between x and y variables 
by plotting the independent variables against the dependent variable. Using a scatter plot, 
we can then assess whether there is some type of non-linear pattern. . Figure&nbsp;7.3 shows 
such a plot. The straight, sloping line indicates a linear relationship between sales and pro-
motions. For illustration purposes, we have also added a curved upward sloping line. This 
dashed line corresponds to a  x1
</p>
<p>2 transformation. It visually seems that the quadratic line 
fits the data best. If we fail to identify non-linear relationships as such, our regression line 
does not fit the data well, as evidenced in a low model fit (e.g., the R2, which we discuss 
later) and nonsignificant effects. After transforming x1 by squaring it (or using any other 
transformation), you still satisfy the assumption of specifying the regression model lin-
early, despite the non-linear relationship between x and y. We discuss details of transfor-
mations in Box 7.3&nbsp;later in this chapter.
</p>
<p>Ramsey&rsquo;s RESET test is a specific linearity test (Ramsey 1969; Cook and Weisberg 1983). 
This test includes the squared values of the independent variables (i.e.,  x1
</p>
<p>2) and third 
powers (i.e.,  x1
</p>
<p>3 ), and tests if these are significant (Baum 2006).7 While this test can detect 
these specific types of non-linearities, it does not indicate which variable or variables have 
</p>
<p>.00 25.00 50.00 75.00 100.00 125.00
</p>
<p>Index of promotional activities
</p>
<p>W
e
</p>
<p>e
lk
</p>
<p>ly
 s
</p>
<p>a
le
</p>
<p>s 
in
</p>
<p> U
S
</p>
<p>D
</p>
<p>4000.00
</p>
<p>6000.00
</p>
<p>8000.00
</p>
<p>10000.00
</p>
<p>12000.00
</p>
<p>14000.00
</p>
<p>Observed
</p>
<p>Linear
</p>
<p>Quadratic
</p>
<p>. Fig.&nbsp;7.3 Different relationships between promotional activities and weekly sales
</p>
<p>7 The test also includes the predicted values squared and to the power of three.
</p>
<p>7</p>
<p/>
</div>
<div class="page"><p/>
<p>7223
7.3 &middot; Conducting a Regression Analysis
</p>
<p>a non-linear relationship with the dependent variable. Sometimes this test is (falsely) called 
a test for omitted variables, but it actually tests for non-linearities.
</p>
<p>7.3.3.2 Second Assumption: Expected Mean Error Is Zero
</p>
<p>The second assumption is that the expected (not the estimated!) mean error is zero. If we 
do not expect the sum of the errors to be zero, we obtain a biased line. That is, we have a 
line that consistently overestimates or underestimates the true relationship. This assump-
tion is not testable by means of statistics, as OLS always renders a best line with a calculated 
mean error of exactly zero. This assumption is important, because if the error&rsquo;s expected 
value is not zero, there is additional information in the data that has not been used in the 
regression model. For example, omitting important variables, as discussed in Box 7.1, or 
autocorrelation may cause the expected error to no longer be zero (see 7 Sect.&nbsp;7.3.3.4).
</p>
<p>7.3.3.3 Third Assumption: Homoscedasticity
</p>
<p>The third assumption is that the errors&rsquo; variance is constant, a situation we call homosce-
dasticity. Imagine that we want to explain various supermarkets&rsquo; weekly sales in dollars. 
Large stores obviously have a far larger sales spread than small supermarkets. For 
example, if you have average weekly sales of $50,000, you might see a sudden jump to 
$60,000, or a fall to $40,000. However, a very large supermarket could see sales move 
from an average of $5&nbsp;million to $7&nbsp;million. This causes the weekly sales&rsquo; error variance 
of large supermarkets to be much larger than that of small supermarkets. We call this 
non-constant variance heteroscedasticity. If we estimate regression models on data in 
which the variance is not constant, they will still result in correct βs. However, the asso-
ciated standard errors are likely to be too large and may cause some βs to not be signifi-
cant, although they actually are.
</p>
<p>. Figure&nbsp;7.4 provides a visualization of heteroscedasticity. As the dependent variable 
increases, the error variance also increases. A simple scatterplot (see 7 Chap.&nbsp;5) with the 
dependent variable on the y-axis and the error plotted on the x-axis can visualize hetero-
scedasticity. If heteroscedasticity is an issue, the points are typically funnel shaped, dis-
playing more (or less) variance as the independent variable increases (decreases). Note 
that the variance can also first go up and then down (diamond shaped) or down and then 
up (diabolo shaped). These funnel shapes are typical of heteroscedasticity and indicate 
that the error variance changes as a function of the dependent variable. If these plots reveal 
heteroscedasticity as an issue, we can deal with it in two different ways described next.
</p>
<p>First, WLS may be used. Compared to OLS, where each observation has an equal weight 
(see 7 Sect.&nbsp;7.3.2.2), WLS &ldquo;weights&rdquo; the regression line such that observations with a smaller 
variance are given greater weight in determining the regression coefficients. The difficult 
part is to understand which variable drives the heteroscedasticity. Returning to the store 
sales example above, if a variable store size were available, it would address the issue that 
weekly sales&rsquo; error variance of large supermarkets is much larger than that of small super-
markets. This would make it a useful weighting variable. Only use WLS if there is a clear 
indication of heteroscedasticity and if you have a good weighting variable. Before using </p>
<p/>
</div>
<div class="page"><p/>
<p>224 Chapter 7 &middot; Regression Analysis
</p>
<p>WLS, try adding the weight variable to the original regression model to see if heterosce-
dasticity is still a problem. Often heteroscedasticity arises because of omitted variables.
</p>
<p>Second, bootstrapping may be used. If we expect that our regression model suffers from 
heteroscedasticity, bootstrapping is an alternative. Bootstrapping takes different samples 
from the dataset and estimates many regression models (typically 1000) from this dataset. 
For each sample, the regression model is calculated and these different values are weighted 
into bootstrapped  β̂ s and standard errors. These bootstrapped  β̂ s and standard errors 
give an indication of how robust the results are and if the interpretation of the OLS and 
bootstrapped  β̂ s and standard errors are the same, heteroscedasticity, is unlikely to be a 
major concern. Moreover, the bootstrapped  β̂ s and standard errors give an indication 
of the true values of both when heteroscedasticity is controlled for.
</p>
<p>7.3.3.4 Fourth Assumption: No Autocorrelation
</p>
<p>The fourth assumption is that the regression model errors are independent; that is, the 
error terms are uncorrelated for any two observations. Imagine that you want to explain 
the supermarket sales of a brand of milk by using the previous week&rsquo;s sales of that milk. It 
is very likely that if sales increased last week, they will also increase this week. This may be 
due to, for example, the growing economy, an increasing appetite for milk, or other reasons 
that underlie the growth in supermarket sales of milk. This issue is called autocorrelation 
</p>
<p>&minus;4000.00
0
</p>
<p>5000
</p>
<p>10000
</p>
<p>15000
</p>
<p>.00
</p>
<p>Unstandardized Residual
</p>
<p>W
e
</p>
<p>e
k
</p>
<p>ly
 s
</p>
<p>a
le
</p>
<p>s 
in
</p>
<p> U
S
</p>
<p>D
</p>
<p>2000.00 4000.00 6000.00&minus;2000.00
</p>
<p>Large error variance
</p>
<p>Small error variance
</p>
<p>. Fig.&nbsp;7.4 An example of heteroscedasticity
</p>
<p>7</p>
<p/>
</div>
<div class="page"><p/>
<p>7225
7.3 &middot; Conducting a Regression Analysis
</p>
<p>and means that regression errors are correlated positively (or negatively) over time. For 
example, the data in . Table 7.1 are taken from weeks 1 to 30, which means they have a 
time component.
</p>
<p>We can identify the presence of autocorrelation by using the Durbin-Watson (D-W) 
test (Durbin and Watson 1951). The D-W test assesses whether there is autocorrelation 
by testing the null hypothesis of no autocorrelation, which is tested for negative autocor-
relation against a lower and upper bound and for positive autocorrelation against a lower 
and upper bound. If we reject the null hypothesis of no autocorrelation, we find support 
for an alternative hypothesis that there is some degree of positive or negative autocorrela-
tion. Essentially, there are four situations, which we indicate in . Fig.&nbsp;7.5.
1. The errors may be positively related (called positive autocorrelation). This means 
</p>
<p>that if we have observations over time, we observe that positive errors are generally 
followed by positive errors and negative errors by negative errors. For example, 
supermarket sales usually increase over certain time periods (e.g., before Christmas) 
and decrease during other periods (e.g., the summer holidays).
</p>
<p>2. If positive errors are commonly followed by negative errors and negative errors by 
positive errors, we have negative autocorrelation. Negative autocorrelation is less 
common than positive autocorrelation, but also occurs. If we study, for example, 
how much time salespeople spend on shoppers, we may see that if they spend much 
time on one shopper, they spend less time on the next, allowing the salesperson to 
stick to his/her schedule, or to simply go home on time.
</p>
<p>3. If no systematic pattern of errors occurs, we have no autocorrelation. This absence of 
autocorrelation is required to estimate standard (OLS) regression models.
</p>
<p>4. The D-W values may fall between the lower and upper critical value. If this occur, 
the test is inconclusive.
</p>
<p>The situation that occurs depends on the interplay between the D-W test statistic (d) and 
the lower (dL) and upper (d
</p>
<p>U) critical value:
 4 If the test statistic is lower than the lower critical value (d &lt; dL), we have positive 
</p>
<p>autocorrelation.
 4 If the test statistic is higher than 4&nbsp;minus the lower critical value (d&nbsp;&gt;&nbsp;4&minus;dL), we have 
</p>
<p>negative autocorrelation.
 4 If the test statistic falls between the upper critical value and 4&nbsp;minus the upper 
</p>
<p>critical value (dU&nbsp;&lt;&nbsp;d&nbsp;&lt;&nbsp;4&minus;dU), we have no autocorrelation.
</p>
<p>dL=1.352 4-dL=2.648d
U
</p>
<p>=1.489 4-d
U
</p>
<p>=2.511
</p>
<p>Positive
</p>
<p>autocorrelation
</p>
<p>Indecision No
</p>
<p>autocorrelation
</p>
<p>Indecision Negative
</p>
<p>autocorrelation
</p>
<p>. Fig.&nbsp;7.5 Durbin-Watson test values (n&nbsp;=&nbsp;30, k&nbsp;=&nbsp;1)</p>
<p/>
</div>
<div class="page"><p/>
<p>226 Chapter 7 &middot; Regression Analysis
</p>
<p>7.3.3.5 Fifth (Optional) Assumption: Error Distribution
</p>
<p>The fifth, optional, assumption is that the regression model errors are approximately 
normally distributed. If this is not the case, the t-values may be incorrect. However, 
even if the regression model errors are not normally distributed, the regression model 
still provides good estimates of the coefficients. Consequently, we consider this 
assumption an optional one. Potential reasons for regression errors being non-nor-
mally distributed include outliers (discussed in 7 Chap.&nbsp;5) and a non-linear relation-
ship between the dependent and one or more independent variable(s) as discussed 
in 7 Sect.&nbsp;7.3.3.1.
</p>
<p>There are two main ways of checking for normally distributed errors: you can use 
plots or carry out a formal test. Formal tests of normality include the Shapiro-Wilk tests 
(see 7&nbsp;Chap.&nbsp;6), which needs to be run on the saved errors. A formal test may indicate 
non-normality and provide absolute standards. However, formal test results reveal little 
about the source of non-normality. A histogram with a normality plot may can help assess 
why errors are non-normally distributed (see 7 Chap.&nbsp;5 for details). Such plots are easily 
explained and interpreted and may suggest the source of non-normality (if present).
</p>
<p>&copy; echoevg/Getty Images/iStock
</p>
<p>https://www.guide-marketresearch.com/app/download/13488671527/
</p>
<p>SPSS+3rd_Chapter+7_DW+Test.pdf?t=1516713141
</p>
<p> 4 If the test statistic falls between the lower and upper critical value (dL&nbsp;&lt;&nbsp;d&nbsp;&lt;&nbsp;d
U), or 
</p>
<p>it falls between 4&nbsp;minus the upper critical value and 4&nbsp;minus the lower critical value 
(4&minus;dU&nbsp;&lt;&nbsp;d&nbsp;&lt;&nbsp;4&minus;dL), the test does not inform on the presence of autocorrelation and is 
undecided.
</p>
<p>The critical values dL and d
U can be found on the website accompanying this book (⤓ Web 
</p>
<p>Appendix &rarr; Downloads). From this table, you can see that the lower critical value dL of a 
model with one independent variable and 30 observations is 1.352 and the upper critical 
value dU is 1.489. . Figure&nbsp;7.5 shows the resulting intervals. Should the D-W test indicate 
autocorrelation, you should use models that account for this problem, such as panel and 
time series models. We do not discuss these methods in this book, but Hill et al. (2011) is 
a useful source of further information.
</p>
<p>7</p>
<p/>
<div class="annotation"><a href="https://www.guide-market-research.com/app/download/13488671527/SPSS+3rd_Chapter+7_DW+Test.pdf?t=1516713141">https://www.guide-market-research.com/app/download/13488671527/SPSS+3rd_Chapter+7_DW+Test.pdf?t=1516713141</a></div>
<div class="annotation"><a href="https://www.guide-market-research.com/app/download/13488671527/SPSS+3rd_Chapter+7_DW+Test.pdf?t=1516713141">https://www.guide-market-research.com/app/download/13488671527/SPSS+3rd_Chapter+7_DW+Test.pdf?t=1516713141</a></div>
</div>
<div class="page"><p/>
<p>7227
7.3 &middot; Conducting a Regression Analysis
</p>
<p>7.3.4 Interpret the Regression Results
</p>
<p>In the previous sections, we discussed how to specify a basic regression model and how 
to test regression assumptions. We now discuss the regression model fit, followed by the 
interpretation of individual variables&rsquo; effects.
</p>
<p>7.3.4.1 Overall Model Fit
</p>
<p>Assessing the overall model fit starts by interpreting the F-test, which determines whether 
or not the model is significant (i.e., whether any of the independent variables has an effect 
on the dependent variable). The test statistic&rsquo;s F-value is the result of a one-way ANOVA 
(see 7 Chap.&nbsp;6) that tests the null hypothesis that all the regression coefficients equal zero. 
Thus, the following null hypothesis is tested:8
</p>
<p>H  0 1 2 3 0: β β β= = =&hellip;=  
</p>
<p>If the regression coefficients are all equal to zero, then all the independent variables&rsquo; effect 
on the dependent variable is zero. In other words, there is no (zero) relationship between 
the dependent variable and the independent variables. If we do not reject the null hypothe-
sis, we need to change the regression model, or, if this is not possible, report that the regres-
sion model is non-significant. If the p-value of the F-test is below 0.05 (i.e., the model is 
significant), does not, however, imply that all the regression coefficients are significant, or 
even that one of them is significant when considered in isolation. However, if the F-value 
is significant, it is highly likely that at least one or more regression coefficients are signif-
icant. Note that model significance is not an indicator of (close) fit, only of significance.
</p>
<p>If we find that the F-test is significant, we can interpret the model fit by using the R2. 
The R2 (also called the coefficient of determination) indicates the degree to which the 
model, relative to the mean, explains the observed variation in the dependent variable. 
In . Fig.&nbsp;7.6, we illustrate this graphically by means of a scatter plot. The y-axis relates to 
the dependent variable sales (weekly sales in dollars) and the x-axis to the independent 
variable promotion (index of promotional activities). In the scatter plot, we see 30 obser-
vations of sales and price (note that we use a small sample size for illustration purposes). 
The horizontal line (at about $5000 sales per week) refers to the average sales across all 30 
observations. This is also our benchmark. After all, if we were to have no regression line, 
our best estimate of the weekly sales would also be the average. The sum of all the squared 
differences between each observation and the average is the total variation or the total 
sum of the squares (SST). We indicate the total variation in only one observation on the 
right of the scatter plot.
</p>
<p>The straight upward sloping line (starting at the y-axis at about $2500 sales per week 
when there are no promotional activities) is the regression line that OLS estimates. If we 
want to understand what the regression model adds beyond the average (which is the 
benchmark for calculating the R2), we can calculate the difference between the regres-
sion line and the line indicating the average. We call this the regression sum of squares 
(SSR), as it is the variation in the data that the regression analysis explains. The final point 
we need to understand regarding how well a regression line fits the available data, is the 
</p>
<p>8 This hypothesis can also be read as that a model with only an intercept is sufficient.</p>
<p/>
</div>
<div class="page"><p/>
<p>228 Chapter 7 &middot; Regression Analysis
</p>
<p>unexplained sum of the squares. This is the difference between the observations (indi-
cated by the dots) and the regression line. The squared sum of these differences refers to 
the regression error that we discussed previously and which is therefore denoted as the 
error sum of squares (SSE). In more formal terms, we can describe these types of varia-
tion as follows:
</p>
<p>SS SS SST R E= +  
</p>
<p>This is the same as:
</p>
<p>i
</p>
<p>n
</p>
<p>i
</p>
<p>i
</p>
<p>n
</p>
<p>i
</p>
<p>i
</p>
<p>n
</p>
<p>i iy y y y y y
</p>
<p>= = =
&sum; &sum; &sum;&minus;( ) = &minus;( ) + &minus;( )
</p>
<p>1 1 1
</p>
<p>&sup2; &sup2; &sup2;ˆ ˆ  
</p>
<p>Here, n describes the number of observations,  yi  is the value of the independent vari-
able for observation i,  ŷi  is the predicted value of observation i, and  y  is the mean 
value of y. As you may see, this description is like the one-way ANOVA we discussed 
in 7 Chap.&nbsp;6. A useful regression line should explain a substantial amount of variation 
(have a high SSR) relative to the total variation (SST). This degree of fit is indicated by 
the R2 as follows:
</p>
<p>R
SS
</p>
<p>SS
R
</p>
<p>T
</p>
<p>2 =  
</p>
<p>Index of promotional activities
</p>
<p>125.00100.0075.0050.0025.00.00
</p>
<p>W
e
</p>
<p>e
k
</p>
<p>ly
 s
</p>
<p>a
le
</p>
<p>s 
in
</p>
<p> U
S
</p>
<p>D
</p>
<p>14000.00
</p>
<p>12000.00
</p>
<p>10000.00
</p>
<p>8000.00
</p>
<p>6000.00
</p>
<p>4000.00
</p>
<p>2000.00
</p>
<p>.00
</p>
<p>SSE
</p>
<p>SSR
</p>
<p>SST
</p>
<p>Mean
</p>
<p>. Fig.&nbsp;7.6 Explanation of the R2
</p>
<p>7</p>
<p/>
</div>
<div class="page"><p/>
<p>7229
7.3 &middot; Conducting a Regression Analysis
</p>
<p>The R2 always lies between 0 and 1, with a higher R2 indicating a better model fit. When 
interpreting the R2, higher values indicate that the variation in x explains more of the vari-
ation in y. Therefore, relative to the SSR, the SSE is low.
</p>
<p>It is difficult to provide rules of thumb regarding what R2 is appropriate, as this varies 
</p>
<p>from research area to research area and on the model complexity. For example, in 
</p>
<p>longitudinal studies, R2s of 0.90 and higher are common. In cross-sectional designs, 
</p>
<p>values of around 0.30 are common, while values of 0.10 are normal in cross-sectional 
</p>
<p>data in exploratory research. In scholarly research focusing on marketing, R2 values 
</p>
<p>of 0.50, 0.30, and 0.10 can, as a rough rule of thumb, be respectively described as 
</p>
<p>substantial, moderate, and weak. Similarly, the regression model's complexity influences 
</p>
<p>the R2 as the statistic increases with a greater number of independent variables.
</p>
<p>Tip
</p>
<p>If we use the R2 to compare different regression models (but with the same dependent 
variable), we run into problems. If we add irrelevant variables that are slightly correlated 
with the dependent variable, the R2 will increase. Thus, if we only use the R2 as the basis for 
understanding regression model fit, we are driven towards selecting regression models with 
many independent variables. Selecting a model only based on the R2 is generally not a good 
strategy, unless we are interested in making predictions. If we are interested in determin-
ing whether independent variables have a significant relationship with a dependent vari-
able, or when we wish to estimate the relative strength of different independent variables&rsquo; 
effects, we need regression models that do a good job of explaining the data (which have a 
low SSE), but which also have a few independent variables. It is easier to recommend that 
a management should change a few key variables to improve an outcome than to recom-
mend a long list of somewhat related variables. We also do not want too many independent 
variables, because they are likely to complicate the insights. Consequently, it is best to rely 
on simple models when possible. Relevant variables should, of course, always be included. 
To avoid a bias towards complex models, we can use the adjusted R2 to select regression 
models. The adjusted R2 only increases if the addition of another independent variable 
explains a substantial amount of the variance. We calculate the adjusted R2 as follows:
</p>
<p>R Radj
n
</p>
<p>n k
2 21 1
</p>
<p>1
</p>
<p>1
= &minus; &minus; &sdot;
</p>
<p>&minus;
</p>
<p>&minus; &minus;
( )  
</p>
<p>Here, n describes the number of observations and k the number of independent variables 
(not counting the constant α). This adjusted R2 is a relative measure and should be used to 
compare different but nested models with the same dependent variable. Nested means that 
all of a simpler model&rsquo;s terms are included in a more complex model, as well as additional 
variables. You should pick the model with the highest adjusted R2 when comparing regres-
sion models. However, do not blindly use the adjusted R2 as a guide, but also look at each 
individual variable and see if it is relevant (practically) for the problem you are researching. 
</p>
<p>&gt; We cannot interpret the adjusted R2 as the percentage of explained variance as we 
can with the regular R2. The adjusted R2 is only a measure of how much the model 
</p>
<p>explains while controlling for model complexity.</p>
<p/>
</div>
<div class="page"><p/>
<p>230 Chapter 7 &middot; Regression Analysis
</p>
<p>Because the adjusted R2 can only compare nested models, there are additional fit indices 
that can be used to compare models with the same dependent variable, but different inde-
pendent variables (Treiman 2014). The Akaike information criterion (AIC) and the Bayes 
information criterion (BIC) are such measures of model fit. More precisely, AIC and BIC are 
a relative measure indicating the difference in information when a set of candidate models 
with different independent variables is estimated. For example, we can use these criteria 
to compare two models where the first regression model explains the sales by using two 
independent variables (e.g., price and promotions) and the second model adds one more 
independent variable (e.g., price, promotions, and service quality). We can also use the 
AIC and BIC when we explain sales by using two different sets of independent variables.
</p>
<p>Both the AIC and BIC apply a penalty (the BIC a slightly larger one) as the number of 
independent variables increases with the sample size (Treiman 2014).9 Smaller values are 
better and, when comparing models and a rough guide is that when the more complex 
model&rsquo;s AIC (or BIC) is 10&nbsp;lower than that of another model, the former model should 
be given strong preference (Fabozzi et al. 2014). When the difference is less than 2, the 
simpler model is preferred. For values between 2 and 10, the evidence shifts towards the 
more complex model, although a specific cut-off point is hard to recommend. When inter-
preting these statistics, note that the AIC tends to point towards a more complex model 
than the BIC.
</p>
<p>7.3.4.2 Effects of Individual Variables
</p>
<p>Having established that the overall model is significant and that the R2 is satisfactory, we 
need to interpret the effects of the various independent variables used to explain the depen-
dent variable. If a regression coefficient&rsquo;s p-value is below 0.05, we generally say that the 
specific independent variable relates significantly to the dependent variable. To be precise, 
the null and alternative hypotheses tested for an individual parameter (e.g., β1) are:
</p>
<p>H0 1 0: β =  
</p>
<p>H1 1 0: β &ne;  
</p>
<p>If a coefficient is significant (i.e., the p-value is below 0.05), we reject the null hypothe-
sis and support the alternative hypothesis, concluding that the parameter differs signifi-
cantly from zero. For example, if we estimate a regression model on the data shown in 
. Fig.&nbsp;7.1, the (unstandardized) β1 coefficient of promotional activities&rsquo; effect on sales 
is 54.591, with a t-value of 5.354. This t-value results in a p-value less than 0.05, indicat-
ing that the effect is significantly different from zero. If we hypothesize a direction (i.e., 
smaller or larger than zero) instead of significantly different from zero, we should divide 
</p>
<p>9 The AIC is specifically calculated as  AIC =

</p>
<p>

</p>
<p>
</p>
<p>

+
</p>
<p>
</p>
<p>


</p>
<p>
</p>
<p>


</p>
<p>n log
SS
</p>
<p>n
</p>
<p>k
</p>
<p>n
E 2 , where SSE is the error sum of squares, 
</p>
<p>n is the number of observations and k the number of independent variables, while the BIC is calcu-
</p>
<p>lated as  BIC =

</p>
<p>

</p>
<p>
</p>
<p>

+
&sdot; ( )
</p>
<p>


</p>
<p>
</p>
<p>


</p>
<p>n log
SS
</p>
<p>n
</p>
<p>k log n
</p>
<p>n
E . Note that these formulations only hold in case of normally 
</p>
<p>distributed residuals with constant variance (Burnham and Anderson 2013).
</p>
<p>7</p>
<p/>
</div>
<div class="page"><p/>
<p>7231
7.3 &middot; Conducting a Regression Analysis
</p>
<p>the corresponding p-value by two. This is the same as applying the t-test for a directional 
effect, which is explained in 7 Chap.&nbsp;6.
</p>
<p>The next step is to interpret the actual size of the β coefficients, which we can interpret 
in terms of unstandardized effects and standardized effects. The unstandardized β coeffi-
cient indicates the effect that a one-unit increase in the independent variable (on the scale 
used to measure the original independent variable) has on the dependent variable. This 
effect is therefore the partial relationship between a change in a single independent vari-
able and the dependent variable. For example, the unstandardized β1 coefficient of pro-
motional activities&rsquo; effect on sales (54.591) indicates that a one-unit change in (the index 
of) promotional activities increases sales by 54.591 units. Importantly, if we have multiple 
independent variables, a variable&rsquo;s unstandardized coefficient is the effect of that indepen-
dent variable&rsquo;s increase by one unit, but keeping the other independent variables constant.
</p>
<p>While this is a very simple example, we might run a multiple regression in which the 
independent variables are measured on different scales, such as in dollars, units sold, or 
on Likert scales. Consequently, the independent variables&rsquo; effects cannot be directly com-
pared with one another, because their influence also depends on the type of scale used. 
Comparing the unstandardized β coefficients would, in any case, amount to comparing 
apples with oranges!
</p>
<p>Fortunately, the standardized βs allow us to compare the relative effect of differently 
measured independent variables by expressing the effect in terms of standard deviation 
changes from the mean. More precisely, the standardized β coefficient expresses the effect 
that a single standard deviation change in the independent variable has on the dependent 
variable. The standardized βs are used to compare different independent variables&rsquo; effects. 
All we need to do is to find the highest absolute value, which indicates the variable that has 
the strongest effect on the dependent variable. The second highest absolute value indicates 
the second strongest effect, etc. Only consider significant βs in this respect, as insignifi-
cant βs do not (statistically) differ from zero! In practice, the standardized β is important, 
because it allows us to assess the effect of one variable (e.g., promotional activities), rela-
tive to other variables (e.g., prices). While the standardized βs are helpful from a practi-
cal point of view, they only allow for comparing the coefficients within and not between 
models! Even if you just add a single variable to your regression model, the standardized 
βs may change substantially.
</p>
<p>&gt; When interpreting (standardized) β coefficients, you should always keep the effect 
size in mind. If a β coefficient is significant, it merely indicates an effect that differs 
</p>
<p>from zero. This does not necessarily mean that the effect is managerially relevant. 
</p>
<p>For example, we may find a $0.01 sales effect of spending $1&nbsp;more on promotional 
</p>
<p>activities that is statistically significant. Statistically, we could conclude that the 
</p>
<p>effect of a $1 increase in promotional activities increases sales by an average of 
</p>
<p>$0.01 (just one dollar cent). While this effect differs significantly from zero, we 
</p>
<p>would probably not recommend increasing promotional activities in practice (we 
</p>
<p>would lose money on the margin) as the effect size is just too small.10
</p>
<p>10 Cohen&rsquo;s (1994) classical article &ldquo;The Earth is Round (p&nbsp;&lt;&nbsp;.05)&rdquo; offers an interesting discussion on signif-
</p>
<p>icance and effect sizes.</p>
<p/>
</div>
<div class="page"><p/>
<p>232 Chapter 7 &middot; Regression Analysis
</p>
<p>There are also situations in which an effect is not constant for all observations, but depends 
on another variable&rsquo;s values. Researchers can run a moderation analysis, which we discuss 
in Box 7.2, to estimate such effects.
</p>
<p>7.3.5 Validate the Regression Results
</p>
<p>Having checked for the assumptions of the regression analysis and interpreted the results, 
we need to assess the regression model&rsquo;s stability. Stability means that the results are stable 
over time, do not vary across different situations, and are not heavily dependent on the 
model specification. We can check for a regression model&rsquo;s stability in several ways:
1. We can randomly split the dataset into two parts (called split-sample validation) and 
</p>
<p>run the regression model again on each data subset. 70&nbsp;% of the randomly chosen 
data is often used to estimate the regression model (called estimation sample) and 
the remaining 30&nbsp;% is used for comparison purposes (called validation sample). 
We can only split the data if the remaining 30&nbsp;% still meets the sample size rules of 
thumb discussed earlier. If the use of the two samples results in similar effects, we 
can conclude that the model is stable. Note that not all regression models need to be 
</p>
<p>Box 7.2&nbsp;Moderation analysis
</p>
<p>The discussion of individual variables&rsquo; effects assumes that there is only one effect. That is, that 
</p>
<p>only one β parameter represents all observations well. This is often not true. For example, the link 
</p>
<p>between sales and price has been shown to be stronger when promotional activities are higher. 
</p>
<p>In other words, the effect of price (β1) is not constant, but varies with the level of promotional 
</p>
<p>activities.
</p>
<p>Moderation analysis is one way of testing if such heterogeneity is present. A moderator 
</p>
<p>variable, usually denoted by m, is a variable that changes the strength (or even direction) of the 
</p>
<p>relationship between the independent variable (x1) and the dependent variable (y). You only need 
</p>
<p>to create a new variable that is the multiplication of x1 and m (i.e., x1&middot;m). The regression model 
</p>
<p>then takes the following form:
</p>
<p>y x m x m e= + + + &sdot; +α β β β1 1 2 3 1  
</p>
<p>In words, a moderator analysis requires entering the independent variable x1, the moderator 
</p>
<p>variable m, and the product x1&middot;m (commonly referred to as interaction term), which represents 
</p>
<p>the interaction between the independent variable and the moderator. Moderation analysis is 
</p>
<p>therefore also commonly referred to as an analysis of interaction effects. After estimating this 
</p>
<p>regression model, you can interpret the significance and sign of the β3 parameter. A significant 
</p>
<p>effect suggests that
</p>
<p> 5 when the sign of β3 is positive, the effect β1 increases as m increases,
 5 when the sign of β3 is negative, the effect β1 decreases as m increases.
</p>
<p>For further details on moderation analysis, please see David Kenny&rsquo;s discussion on moderation 
</p>
<p>(http://www.davidakenny.net/cm/moderation.htm), or the advanced discussion by Aiken and 
</p>
<p>West (1991). Jeremy Dawson&rsquo;s website (http://www.jeremydawson.co.uk/slopes.htm) offers a 
</p>
<p>tool for visualizing moderation effects. An example of a moderation analysis is found in Mooi and 
</p>
<p>Frambach (2009).
</p>
<p>7</p>
<p/>
<div class="annotation"><a href="http://www.davidakenny.net/cm/moderation.htm">http://www.davidakenny.net/cm/moderation.htm</a></div>
<div class="annotation"><a href="http://www.jeremydawson.co.uk/slopes.htm">http://www.jeremydawson.co.uk/slopes.htm</a></div>
</div>
<div class="page"><p/>
<p>7233
7.3 &middot; Conducting a Regression Analysis
</p>
<p>identical when you try to validate the results. The signs of the individual parameters 
should at least be consistent and significant variables should remain so, except if 
they are marginally significant, in which case changes are expected (e.g., p&nbsp;=&nbsp;0.045 
becomes p&nbsp;=&nbsp;0.051)..11 Finally, note that it is mere convention to use 70 and 30&nbsp;% and 
there is no specific reason for using these percentages.
</p>
<p>2. We can also cross-validate our findings on a new dataset and examine whether 
these findings are similar to the original findings. Again, similarity in the findings 
indicates stability and that our regression model is properly specified. Cross-vali-
dation does, of course, assume that we have a second dataset.
</p>
<p>3. We can add several alternative variables to the model and examine whether the 
original effects change. For example, if we try to explain weekly supermarket sales, 
we could use several additional variables, such as the breadth of the assortment 
or the downtown/non-downtown location in our regression model. If the basic 
findings we obtained earlier continue to hold even when adding these two new 
variables, we conclude that the effects are stable. This analysis does, of course, require 
us to have more variables available than those included in the original regression 
model. If we add variables not because we are interested in them but because we 
want to rule these out as alternative explanations, we call these control variables.
</p>
<p>7.3.6 Use the Regression Model
</p>
<p>When we have found a useful regression model that satisfies regression analysis&rsquo;s assump-
tions, it is time to use it. Prediction is a key use of regression models. Essentially, predic-
tion entails calculating the values of the dependent variables of new observations based on 
assumed values of the independent variables and the previously calculated unstandardized 
β coefficients. Let us illustrate this by returning to our opening example. Imagine that we 
are trying to predict weekly supermarket sales (in dollars) (y) and have estimated a regres-
sion model with two independent variables: price ( x1 ) and an index of promotional activ-
ities ( x2 ). The regression model is as follows:
</p>
<p>y x x e= + + +α β β1 1 2 2  
</p>
<p>If we estimate this model on the previously used dataset, the estimated unstandardized 
coefficients using regression analysis are 30,304.054 for the intercept, &minus;25,209.858 for price, 
and 42.266 for promotions. We can use these coefficients to predict sales in different situ-
ations. Imagine, for example, that we set the price at $1.10 and the promotional activities 
at 50. Our expectation of the weekly sales would then be:
</p>
<p>ŷ &nbsp;=  30,304.054&nbsp;&minus;&nbsp;25,209.858&sdot;$1.10&nbsp;+&nbsp;42.266&sdot;50 promotional activities&nbsp;=&nbsp; 
$4686.5102 sales per week.
</p>
<p>11 It is possible to compare regression coefficients statistically, avoiding the need to the subjectivity of 
</p>
<p>&ldquo;similar.&rdquo; Strictly speaking, the test for comparing coefficients is z-distributed with  z=
&minus;
</p>
<p>+
</p>
<p>b b
</p>
<p>SE SE
</p>
<p>1 2
</p>
<p>1
2
</p>
<p>2
2
</p>
<p> 
</p>
<p>(see Paternoster et al. 1998).</p>
<p/>
</div>
<div class="page"><p/>
<p>234 Chapter 7 &middot; Regression Analysis
</p>
<p>. Table 7.2 Steps involved in carrying out a regression analysis
</p>
<p>Theory Action
</p>
<p>Check the regression analysis data requirements
</p>
<p>Sufficient sample size Run a power analysis using G*power.
</p>
<p>Check if sample size is 104&nbsp;+&nbsp;k, where k indicates the number of 
</p>
<p>independent variables. If the expected effects are weak (the R2 is 
</p>
<p>0.10 or lower), use at least 30 &sdot; k observations per independent 
variable.
</p>
<p>To check the sample size, go to ► Analyze ► Regression 
►&nbsp;Linear ► Statistics and check Descriptives. In the output 
check N under Descriptive Statistics. Alternatively, after running 
a regression analysis, look at the intersection of df and Total in 
the ANOVA table. You need to add 1 to this number to get the 
total sample size.
</p>
<p>Do the dependent and 
</p>
<p>independent variables show 
</p>
<p>variation?
</p>
<p>Calculate the standard deviation of the variables by going 
</p>
<p>to ► Analyze ► Regression ► Linear ► Statistics and check 
Descriptive. In the output check Std. Deviation under 
Descriptive Statistics. At the very least, the standard deviation 
should be greater than 0.
</p>
<p>Is the dependent variable 
</p>
<p>interval or ratio scaled?
See 7 Chap.&nbsp;3 determine the measurement level.
</p>
<p>Is (multi)collinearity present? Check the VIF. Go to ► Analyze ► Regression ► Linear 
►&nbsp;Statistics and check Collinearity diagnostics. In the output, 
under Collinearity Statistics, assess if the VIFs are all below 10 
(although the threshold can be higher, or lower, in some cases; 
</p>
<p>see 7 Sect.&nbsp;7.3.1.4 for details). Note that SPSS also produces an 
additional table labelled Collinearity Diagnostics that is not 
needed.
</p>
<p>We could also build several scenarios to plan for different situations by, for example, 
increasing the price to $1.20 and reducing the promotional activities to 40. By using regres-
sion models like this, one can, for example, automate stocking and logistical planning, or 
develop strategic marketing plans.
</p>
<p>Regression can also help by providing insight into variables&rsquo; specific effects. For 
example, if the effect of promotions is not significant, it may tell managers that the super-
market&rsquo;s sales are insensitive to promotions. Alternatively, if there is some effect, the 
strength and direction of promotional activities&rsquo; effect may help managers understand 
whether they are useful.
</p>
<p>. Table 7.2 summarizes (on the left side) the major theoretical decisions we need to 
make if we want to run a regression model. On the right side, these decisions are then 
translated into SPSS actions.
</p>
<p>7</p>
<p/>
</div>
<div class="page"><p/>
<p>7235
7.3 &middot; Conducting a Regression Analysis
</p>
<p>Theory Action
</p>
<p>Specify and estimate the regression model
</p>
<p>Model specification 1. Pick distinct variables
</p>
<p>2. Try to build a robust model
</p>
<p>3. Consider the variables that are needed to give advice
</p>
<p>4.  Consider whether the number of independent variables is in 
</p>
<p>relation to the sample size
</p>
<p>When using ordinal variables, create dummies first. Do this by 
</p>
<p>going to ► Transform ► Create Dummy Variables. Move the 
ordinal variable to the Create Dummy Variables for box and 
also enter the first part of the name of the dummy under Root 
Names (One per Selected Variable) of the Main Effect Dummy 
Variables box. By default, SPSS chooses to give value labels to 
each category. We can change this to Use values if we have not 
defined value labels. Note that SPSS will automatically create 
</p>
<p>dummies for all categories and we have to specify the base 
</p>
<p>category.
</p>
<p>Estimate the regression 
</p>
<p>model
</p>
<p>► Analyze ► Regression ► Linear. Under Dependent, enter the 
dependent variable and add all the independent variables under 
</p>
<p>Independent(s). Click on OK.
</p>
<p>Test the regression analysis assumptions
</p>
<p>Can the regression model be 
</p>
<p>specified linearly?
</p>
<p>Consider whether you can write the regression model as:  
</p>
<p>y x x e= + + +&hellip;+α β β1 1 2 2
</p>
<p>Is the relationship between 
</p>
<p>the independent and 
</p>
<p>dependent variables linear?
</p>
<p>Plot the dependent variable against the independent variable 
</p>
<p>using a scatterplot matrix to see if the relation (if any) appears to 
</p>
<p>be linear. ► Graphs ► Chart Builder. Then click on Scatter/Dot 
and drag Simple Scatter to the Chart preview window. Drag the 
dependent variable onto the Y-axis and the first independent 
variable to the X-axis. Repeat for the other independent 
variables.
</p>
<p>To conduct Ramsey&rsquo;s RESET test first run the regression model by 
</p>
<p>going to ► Analyze ► Regression ► Linear. Under Dependent, 
enter the dependent variable and add all the independent 
</p>
<p>variables under Block 1 of 1 and click on Save. Then click on 
Unstandardized under Predicted Values, followed by Continue 
and OK. After this go to ► Transform ► Compute Variable. Under 
Target Variable, type PRED_2 and under numeric expression 
enter the unstandardized prediction variable PRE_1 and type 
</p>
<p>**2 after this to compute the squared predicted values. Repeat 
this for predicted values to the power of 3 by entering PRED_3 
</p>
<p>under Target Variable. Under numeric expression enter the 
unstandardized prediction variable PRE_1 and type **3.
Then re-run the regression model by going to ► Analyze 
►&nbsp;Regression ► Linear. Under Dependent, enter the dependent 
variable and add all the independent variables under Block 1 of 
1. Then click on Next and enter PRED_2 and PRED_3 to the box. 
Under Statistics tick R squared change and click on Continue 
and then OK. Check under Model Summary if Sig. F Change is 
significant for model 2.
</p>
<p>. Table&nbsp;7.2 (Continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>236 Chapter 7 &middot; Regression Analysis
</p>
<p>Theory Action
</p>
<p>Is the expected mean error of 
</p>
<p>the regression model zero?
</p>
<p>Choice made on theoretical grounds.
</p>
<p>Is the error variance constant 
</p>
<p>(homoscedasticity)?
</p>
<p>Re-run the regression model by going to ► Analyze 
►&nbsp;Regression ► Linear. Under Dependent, enter the dependent 
variable and add all the independent variables under Block 1 of 1 
and click on Save. Then go to Save and click on Unstandardized 
under Residuals. Then click on Continue and OK.
Plot the dependent variable against the residual by going 
</p>
<p>to ► Graphs ► Chart Builder. Then click on Scatter/Dot and 
drag Simple Scatter to the Chart preview window. Drag the 
dependent variable onto the Y-axis and the saved residual onto 
the X-axis.
Assess if there is a clear in- or decrease in the error variance (i.e. a 
</p>
<p>funnel shape).
</p>
<p>If there is evidence of heteroscedasticity we can use 
</p>
<p>bootstrapping. Re-run the regression model by going to 
</p>
<p>►&nbsp;Analyze ► Regression ► Linear and click on Bootstrap. Then 
click on Perform bootstrapping and make sure that Number of 
samples is set to 1,000. Click on Continue and OK. Note that this 
requires the SPSS bootstrapping add-on. If this is not installed, 
</p>
<p>you will not see this option.
</p>
<p>Check if the interpretation of the regression results is the 
</p>
<p>same for the standard as for the bootstrapped significance 
</p>
<p>(under Sig. (2-tailed)). Under the column Bias, you can see the 
difference with the normal &szlig;s. The bias should be small. That is, 
</p>
<p>bootstrapped parameter estimates should fall in the region of 2 
</p>
<p>&plusmn; standard errors from the coefficients of the model estimated 
</p>
<p>via OLS. Compare the normal and bootstrapped model results to 
</p>
<p>ensure they are similar.
</p>
<p>Are the errors independent 
</p>
<p>(no autocorrelation)?
</p>
<p>First assess if there is a time component to the data (i.e., multiple 
</p>
<p>observations, across time, from one respondent/object). If there 
</p>
<p>is, sort the data according to the time variable and conduct the 
</p>
<p>Durbin&ndash;Watson test. Compare the calculated Durbin&ndash;Watson 
</p>
<p>test statistic with the critical lower and upper values. If positive or 
</p>
<p>negative autocorrelation is present, panel or time-series models 
</p>
<p>need to be used.
</p>
<p>Re-run the regression model by going to ► Analyze 
►&nbsp;Regression ► Linear. Under Dependent, enter the dependent 
variable and add all the independent variables under Block 1 
of 1 and click on Statistics. Then click on Durbin-Watson under 
Residuals, followed by Continue and OK.
The Durbin-Watson test for first-order serial correlation should 
</p>
<p>not be significant. The critical values can be found on the website 
</p>
<p>accompanying this book (⤓ Web Appendix &rarr; Downloads).
</p>
<p>. Table&nbsp;7.2 (Continued)
</p>
<p>7</p>
<p/>
</div>
<div class="page"><p/>
<p>7237
7.3 &middot; Conducting a Regression Analysis
</p>
<p>Theory Action
</p>
<p>Are the errors approximately 
</p>
<p>normally distributed?
</p>
<p>Visual inspection: Re-run the regression model by going to 
</p>
<p>►&nbsp;Analyze ► Regression ► Linear. Under Dependent, enter the 
dependent variable and add all the independent variables under 
</p>
<p>Block 1 of 1 and click on Plots. Then click on Histogram under 
Standardized Residual Plots. Then click on Continue and OK. 
Check whether the length of the bars of the histogram follows to 
</p>
<p>the normal curve.
</p>
<p>Statistical test: Re-run the regression model by going to 
</p>
<p>►&nbsp;Analyze ► Regression ► Linear. Under Dependent, enter the 
dependent variable and add all the independent variables under 
</p>
<p>Block 1 of 1 and click on Save. Then click on Unstandardized 
under Residuals. Then click on Continue and OK.
Calculate the Shapiro&ndash;Wilk test. ► Analyze ► Descriptive 
Statistics ► Explore. Add the unstandardized residual to the 
Dependent list and click on Plots. Tick the Normality plots with 
tests box and click on Continue and OK.
Check if the Shapiro-Wilk test under Sig. reports a p-value greater 
than 0.05.
</p>
<p>Interpret the regression model
</p>
<p>Consider the overall model fit Check the significance of the F-test and the R2 value.
</p>
<p>Consider the effects of the 
</p>
<p>independent variables 
</p>
<p>separately
</p>
<p>Check the (standardized) β. Also check the sign of the β. Consider 
</p>
<p>the significance of each coefficient by checking the p-value und 
</p>
<p>Sig..
</p>
<p>To compare models Calculate the AIC and BIC. This can only be done by setting up 
</p>
<p>the regression model and instead of clicking on OK, click on 
Paste. Add SELECTION to the/STATISTICS subcommand (e.g./
STATISTICS COEFF OUTS R ANOVA COLLIN TOL SELECTION). 
Select the entire code and go to ► Run ► All.
Check the AIC and BIC and ascertain if the simpler model has AIC 
</p>
<p>and BIC values that are at least 2, but preferably 10, lower than 
</p>
<p>that of the more complex model.
</p>
<p>Validate the model
</p>
<p>Are the results robust? Randomly select 30&nbsp;% of cases (assuring minimum sample size 
</p>
<p>requirements apply). To do this, go to ► Data ► Select Cases. 
Then click on Random sample of cases, followed by Sample. 
Type 30 in the box Approximately &hellip; % of all cases and click on 
Continue. Before clicking on OK, make sure to select Filter out 
unselected cases under Output. Now click on OK.
Then go to ► Data ► Select Cases and select All cases. Next, go 
to ► Data ► Split File. In the dialog box that opens, select the 
option Organize output by groups, move the filter_$ variable 
into the Groups Based on box, and click on OK.
Compare the model results to ensure they are similar (i.e., the 
</p>
<p>coefficients of the regression run on the smaller sample are 
</p>
<p>similar to the coefficients of the regression model run on the 
</p>
<p>larger sample in terms of direction and significance.
</p>
<p>. Table&nbsp;7.2 (Continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>238 Chapter 7 &middot; Regression Analysis
</p>
<p>12 Note that this only works, as shown in the lower left of . Fig.&nbsp;7.7, if the &ldquo;Python essentials&rdquo; are 
installed.
</p>
<p>7.4 Example
</p>
<p>Let&rsquo;s go back to the Oddjob Airways case study (as introduced in 7 Chap.&nbsp;5) and run a 
regression analysis on the data. Our aim is to explain commitment, which is the custom-
er&rsquo;s intention to continue the relationship. This variable is the mean of the three items 
com1 (&ldquo;I am very committed to Oddjob Airways&rdquo;), com2 (&ldquo;My relationship with Oddjob 
Airways means a lot to me&rdquo;), and com3 (&ldquo;If Oddjob Airways would not exist any longer, it 
would be a hard loss for me&rdquo;) and has already been included in the dataset (⤓ Web Appen-
dix &rarr; Downloads).
</p>
<p>Our task is to identify which variables relate to commitment to Oddjob Airways. 
Regression analysis can help us determine which variables relate significantly to commit-
ment, while also identifying the relative strength of the different independent variables. 
The Oddjob Airways dataset offers several variables that may explain the commitment 
variable. Based on prior research and discussions with Oddjob Airway&rsquo;s management, the 
following variables have been identified as promising candidates:
</p>
<p> 4 Oddjob Airways gives you a sense of safety (s9),
 4 The condition of Oddjob Airways&rsquo; aircraft is immaculate (s10),
 4 Oddjob Airways also pays attention to its service delivery&rsquo;s details (s19),
 4 Oddjob Airways makes traveling uncomplicated (s21), and
 4 Oddjob Airways offers great value for money (s23).
</p>
<p>As additional variables, we add the following three categories to the model: the respon-
dent&rsquo;s status (status), age (age), and gender (gender).
</p>
<p>z Check the Regression Analysis Data Requirements
To check whether our data meet all requirements, we need to run the regression analy-
sis first. Before we run a regression analysis, however, we need to create dummy variables 
from the status variable. To do this, go to ► Transform ► Create Dummy Variables. Move 
the ordinal variable status into the Create Dummy Variables for box and also enter the first 
part of the name of the dummy as category under Root Names (One per Selected Variable) 
of the Main Effect Dummy Variables box (. Fig.&nbsp;7.7). By default, SPSS chooses to give value 
labels to label each category which is good since value labels have been defined as Blue, 
Silver, and Gold. Then click on OK.12
</p>
<p>Next, we should run the regression analysis. Go to ► Analyze ► Regression ► Linear 
and enter the dependent variable commitment in the Dependent box and s9, s10, s19, 
s21, s23, category_2, category_3, age, and gender in the Independent(s) box as shown in 
.&nbsp;Fig.&nbsp;7.8. This will require a bit of scrolling. Note that if we were to add category_1 as well, 
this variable would be perfectly collinear with category_2 and category_3 since if we know 
an observation is not in the latter two, it must be in the former. SPSS issues no warning 
when it drops a variable.
</p>
<p>Next, we need to tell SPSS that we require several options to conduct the steps as dis-
cussed earlier. First, click on Statistics and check (if it isn&rsquo;t already checked) Estimates, 
</p>
<p>7</p>
<p/>
</div>
<div class="page"><p/>
<p>7239
7.4 &middot; Example
</p>
<p>. Fig.&nbsp;7.7 The create dummy variables dialog box
</p>
<p>Model fit, Descriptives, and Collinearity diagnostics (. Fig.&nbsp;7.9). You should also check 
Durbin-Watson if the data have a time component and are sorted based on this compo-
nent. In these data, there is no time component so this should not be checked. Then click 
on Continue.
</p>
<p>To save the predicted values and the errors we should click on Save. Select the option 
Unstandardized right under Predicted Values and under Residuals (. Fig.&nbsp;7.10). Then click 
on Continue, followed by OK, which will initiate the regression analysis.
</p>
<p>zz Sample Size
After having run the analysis, we should first check if the sample size is sufficient for a 
regression analysis. To do so, we examine the Descriptive Statistics table (. Table 7.3), 
which shows the mean, the standard deviation, and the number of observations (indicated 
by N). Here, we find the value 973. Green&rsquo;s (1991) rule of thumb suggests that we need at 
least 104&nbsp;+&nbsp;k observations, where k is the number of independent variables. Since we have 
nine independent variables, we satisfy this criterion. In fact, even if we apply VanVoorhis 
and Morgan&rsquo;s (2007) more stringent criteria of 30 observations per variable, we still have 
a sufficient sample size. SPSS also displays a correlation matrix. However, as this matrix 
takes up a lot of space, we don&rsquo;t display it here.</p>
<p/>
</div>
<div class="page"><p/>
<p>240 Chapter 7 &middot; Regression Analysis
</p>
<p>zz Variables Need to Vary
To ascertain if our variables display some variation, we examine the Descriptive Statistics 
output from . Table 7.3 again. At the very least, the standard deviation, indicated under 
</p>
<p>. Fig.&nbsp;7.9 The statistics option (regression analysis)
</p>
<p>. Fig.&nbsp;7.8 The regression dialog box
</p>
<p>7</p>
<p/>
</div>
<div class="page"><p/>
<p>7241
7.4 &middot; Example
</p>
<p>. Fig.&nbsp;7.10 The save option (regression analysis)
</p>
<p>. Table 7.3 Descriptive statistics
</p>
<p>Descriptive Statistics
</p>
<p>Mean Std. Deviation N
</p>
<p>commitment 4.2254 1.71537 973
</p>
<p>s9 72.63 20.795 973
</p>
<p>s10 64.65 21.370 973
</p>
<p>s19 57.41 21.489 973
</p>
<p>s21 59.18 22.535 973
</p>
<p>s23 49.37 22.675 973
</p>
<p>category_2 .2343 .42380 973
</p>
<p>category_3 .1377 .34478 973
</p>
<p>age 50.58 11.959 973
</p>
<p>gender 1.74 .440 973</p>
<p/>
</div>
<div class="page"><p/>
<p>242 Chapter 7 &middot; Regression Analysis
</p>
<p>Std. Deviation should be greater than 0. The output also shows each variable&rsquo;s mean. Two 
variables require a bit more to interpret these. The variable status is coded using thee labels, 
Blue, Silver, and Gold, and from the output we can see that .2343 or 23&nbsp;% of all respondents 
fall into category_2 (Silver) category, while .1377 or 14&nbsp;% fall into category_3 (Gold). Hence, 
we can conclude that the reaming 63&nbsp;% fall into the Blue category. Turning to the variable 
gender, which is coded 1 for females and 2 for males, we can conclude that as the mean is 
1.74, 74&nbsp;% of our observations are male.
</p>
<p>zz Scale Type of the Dependent Variable
The scale of the dependent variable is interval or ratio scaled. Specifically, three 7-point 
Likert scales create the mean of three items that form the commitment variable. Most 
researchers would consider this to be interval or ratio scaled, which meets the OLS regres-
sion data assumptions.
</p>
<p>zz Collinearity
To check for collinearity among the independent variables, we need to examine the regres-
sion output (. Table 7.4), which shows the beta coefficients, their significances, and col-
linearity statistics. As we can see, the highest VIF value is 2.069, which is below 10 and 
also below the conservative threshold of 5. Hence, we conclude that collinearity is not at a 
critical level. Note that SPSS will also produce a specific table with collinearity diagnostics 
but this table is not necessary for an essential diagnostic of collinearity.
</p>
<p>. Table 7.4 Regression output
</p>
<p>Coefficientsa
</p>
<p>Model
</p>
<p>Unstandardized 
</p>
<p>Coefficients
</p>
<p>Standardized 
</p>
<p>Coefficients
</p>
<p>t Sig.
</p>
<p>Collinearity  
</p>
<p>Statistics
</p>
<p>B
</p>
<p>Std. 
</p>
<p>Error Beta
</p>
<p>Toler-
</p>
<p>ance VIF
</p>
<p>1 (Constant) 1.199 .300 3.997 .000
</p>
<p>s9 .005 .003 .063 1.722 .085 .521 1.919
</p>
<p>s10 .001 .003 .008 .224 .823 .498 2.009
</p>
<p>s19 .012 .003 .154 4.072 .000 .483 2.069
</p>
<p>s21 .019 .003 .245 6.821 .000 .532 1.880
</p>
<p>s23 .016 .003 .208 6.003 .000 .571 1.752
</p>
<p>category_2 .183 .112 .045 1.641 .101 .902 1.108
</p>
<p>category_3 .428 .138 .086 3.105 .002 .897 1.115
</p>
<p>age .010 .004 .072 2.667 .008 .951 1.051
</p>
<p>gender &minus;.345 .105 &minus;.089 &minus;3.285 .001 .946 1.057
</p>
<p>a Dependent Variable: commitment
</p>
<p>7</p>
<p/>
</div>
<div class="page"><p/>
<p>7243
7.4 &middot; Example
</p>
<p>Having now met all the described requirements for a regression analysis, our next task 
is to interpret the regression analysis results.
</p>
<p>z Specify and Estimate the Regression Model
We know exactly which variables to select for this model: commitment, as the dependent 
variable, and s9, s10, s19, s21, s23, category_2, category_3, age, and gender as the indepen-
dent variables as we had specified earlier. We have already done this so there is no need 
to repeat this.
</p>
<p>z Test the Regression Analysis Assumptions
In the next step, we test the following assumptions relevant to regression analysis: 
 4 Linearity,
 4 expected mean is zero,
 4 homoscedasticity,
 4 no autocorrelation, and
 4 normal error distribution.
</p>
<p>zz First Assumption: Linearity
The first assumption is whether the regression model can be expressed linearly. Since no 
variable transformations occurred, we meet this assumption, because we can write the 
regression model linearly as:
</p>
<p>commitment s s s s s
</p>
<p>category c
</p>
<p>= + + + + + +
</p>
<p>+
</p>
<p>α β β β β β
</p>
<p>β β
</p>
<p>1 2 3 4 5
</p>
<p>6 7
</p>
<p>9 10 19 21 23
</p>
<p>2_ aategory age gender e_ 3 8 9+ + +β β  
</p>
<p>Separately, we also check whether the relationships between the independent and depen-
dent variables are linear. To do this, create scatterplots of the dependent variable against 
all the independent variables. To do this, go to ► Graphs ► Chart Builder. Then click on 
Scatter/Dot and drag Simple Scatter to the Chart preview window. Drag the dependent vari-
able commitment onto the Y-Axis and the first independent variable s9 (&ldquo;Oddjob Airways 
gives you a sense of safety&rdquo;) to the X-Axis and click on OK.
</p>
<p>. Figure&nbsp;7.11 shows the resulting scatterplot. The large number of dots makes it diffi-
cult to see whether the relationship is linear and this is quite typical for large datasets. The 
scatterplot neither suggests nor rejects linearity clearly. Note that because commitment is 
computed as the mean of three variables measured on seven-point scales, we observe dis-
tinct bands. This is because the variable commitment can only take on 21 distinct values.
</p>
<p>Another means to test for nonlinear relationships between the independent and depen-
dent variable is to run Ramsey&rsquo;s RESET test. Unfortunately, the test is not readily available via 
SPSS&rsquo;s graphical user interface but we can manually run the test using a series of commands. 
To conduct Ramsey&rsquo;s RESET we need to square and take the third power of the predictions 
of the regression model we saved earlier. To do this, go to ► Transform ► Compute Variable 
and type PRED_2 under Target Variable. Under Numeric Expression enter the unstandardized 
prediction variable PRE_1 that we requested SPSS to save when running the regression anal-
ysis. Now type **2 after PRE_1 to compute the squared predicted values. After clicking on 
OK, SPSS will add a new variable PRED_2 to the dataset. Repeat this series of commands but 
enter PRED_3 under Target Variable and add **3 after PRE_1 to raise to the power of three.</p>
<p/>
</div>
<div class="page"><p/>
<p>244 Chapter 7 &middot; Regression Analysis
</p>
<p>Then re-run the regression model by going to ► Analyze ► Regression ► Linear 
Regression. Under Dependent enter the dependent variable commitment and add all the 
independent variables (i.e., and s9, s10, s19, s21, s23, category_2, category_3, age, and 
gender) under Block 1 of 1. Then click on Next and enter PRED_2 and PRED_3 to the box. 
Note that this block will now read Block 2 of 2. Under Statistics, tick R squared change and 
click on Continue and then OK.
</p>
<p>SPSS produces a series of outputs of which only the Model Summary is relevant to us. 
Specifically, we need to check whether the R2 differs significantly between model 1 (the 
initial model) and model 2 (the model additionally containing PRED_2 and PRED_3). If 
we read the output in . Table 7.5, we see that the change in R2 is not significant as indicated 
by the p-value of .800 under Sig. F Change. The results thus suggest that the relationships are 
linear. Bear in mind, however, that this test does not consider all forms of non-linearities.
</p>
<p>200
</p>
<p>C
o
</p>
<p>m
m
</p>
<p>it
m
</p>
<p>e
n
</p>
<p>t
</p>
<p>40 60 80 100
</p>
<p>... Oddjob Airways gives you a sense of safety.
</p>
<p>2.00
</p>
<p>3.00
</p>
<p>4.00
</p>
<p>5.00
</p>
<p>6.00
</p>
<p>1.00
</p>
<p>7.00
</p>
<p>. Fig.&nbsp;7.11 Scatterplot to examine linearity
</p>
<p>. Table 7.5 Model summary used for Ramsey&rsquo;s RESET test
</p>
<p>Model Summaryc
</p>
<p>Model R
</p>
<p>R 
</p>
<p>Square
</p>
<p>Ad-
</p>
<p>justed 
</p>
<p>R 
</p>
<p>Square
</p>
<p>Std. 
</p>
<p>Error of 
</p>
<p>the Es-
</p>
<p>timate
</p>
<p>Change Statistics
</p>
<p>R 
</p>
<p>Square 
</p>
<p>Change
</p>
<p>F 
</p>
<p>Change df1 df2
</p>
<p>Sig. F 
</p>
<p>Change
</p>
<p>1 .581a .338 .332 1.40236 .338 54.593 9 963 .000
</p>
<p>2 .582b .338 .331 1.40349 .000 .223 2 961 .800
</p>
<p>a Predictors: (Constant), gender, s21, age, category_3, category_2, s10, s23, s9, s19
b Predictors: (Constant), gender, s21, age, category_3, category_2, s10, s23, s9, s19, PRED_3, PRED_2
c Dependent Variable: commitment
</p>
<p>7</p>
<p/>
</div>
<div class="page"><p/>
<p>7245
7.4 &middot; Example
</p>
<p>In case the visual inspection or Ramsey&rsquo;s RESET test indicate a nonlinear relationship, 
we can run a curve estimation to explore the concrete form of the relationship. In Box 7.3, 
we offer a brief introduction into curve estimation using SPSS.
</p>
<p>Box 7.3 Curve estimation
</p>
<p>SPSS&rsquo;s curve estimation option allows running multiple regression models with a single 
</p>
<p>independent variable, assuming different types of nonlinear relationships. To run this analysis, go 
</p>
<p>to ► Analyze ► Regression ► Curve Estimation. In the dialog box that opens (. Fig.&nbsp;7.12), enter 
commitment into the Dependent(s) box and, for example, s9 under Independent. Under Models 
we can select different types of transformations to map a potential nonlinear relationship. Typical 
</p>
<p>transformations include the Logarithmic, Quadratic, and Exponential. Make sure to also select 
Linear. Now click on OK.
. Figure&nbsp;7.13 shows the resulting output with linear, logarithmic, quadratic, and exponential 
transformations. Considering the great number of data points, it is difficult to spot, which type of 
</p>
<p>transformation would better represent the relationship between commitment and s9. In this case, 
</p>
<p>we should compare the R2 of all significant models as an indicator of what line fits best. To do so, 
</p>
<p>select Display ANOVA table option in . Fig.&nbsp;7.12 and pick the model with a significant F-value, 
which has the highest R2.13
</p>
<p>13 Note that it is better to calculate if the R2 increase is significant (as for Ramsey&rsquo;s RESET test) but this 
</p>
<p>needs to be done manually and falls outside of the scope of this book.
</p>
<p>. Fig.&nbsp;7.12 Curve estimation dialog box</p>
<p/>
</div>
<div class="page"><p/>
<p>246 Chapter 7 &middot; Regression Analysis
</p>
<p>zz Second Assumption: Expected Mean Error Is Zero
Assessing whether the regression model&rsquo;s expected mean error is zero is made on theo-
retical grounds&mdash;there is no empirical test for this. We have a randomly drawn sample 
from the population and the model is similar in specification to other models explaining 
commitment. This makes it reasonable to assume that the regression model&rsquo;s expected 
mean error is zero.
</p>
<p>zz Third Assumption: Homoscedasticity
To consider if the errors are constant (homoscedastic) we need to re-use the errors of the 
regression model we saved earlier. We should then plot the dependent variable against 
the residual by going to ► Graphs ► Chart Builder. Then click on Scatter/Dot and drag 
Simple Scatter to the Chart preview window. Drag the dependent variable commitment 
onto the Y-axis and the unstandardized residuals variable RES_1 onto the X-axis. Click on 
OK. The resulting scatterplot shown in . Fig.&nbsp;7.14 shows no clear increase or decrease in 
error variance (i.e., a funnel shape). Since there is no clear evidence of heteroscedasticity, 
we do not need to use bootstrapping.
</p>
<p>zz Fourth Assumption: No Autocorrelation
If we had data with a time component, we would also perform the Durbin-Watson test 
to check for potential autocorrelation. This requires us to first specify a time component, 
which is absent in the Oddjob Airways dataset.
</p>
<p>200 40 60 80 100
</p>
<p>... Oddjob Airways gives you a sense of safety.
</p>
<p>C
o
</p>
<p>m
m
</p>
<p>it
m
</p>
<p>e
n
</p>
<p>t
</p>
<p>2.00
</p>
<p>3.00
</p>
<p>4.00
</p>
<p>5.00
</p>
<p>6.00
</p>
<p>1.00
</p>
<p>7.00
Observed
Linear
Logarithmic
Quadratic
Exponential
</p>
<p>. Fig.&nbsp;7.13 Examples of linear, logarithmic, quadratic, and exponential relationships
</p>
<p>7</p>
<p/>
</div>
<div class="page"><p/>
<p>7247
7.4 &middot; Example
</p>
<p>&ndash;6.00000 &ndash;4.00000 &ndash;2.00000 2.00000.00000 4.00000
</p>
<p>Unstandardized Residual
</p>
<p>Simple Scatter of Commitment by Unstandardized Residual
</p>
<p>1.00
</p>
<p>2.00
</p>
<p>3.00
</p>
<p>4.00
</p>
<p>5.00
</p>
<p>6.00
</p>
<p>7.00
</p>
<p>C
o
</p>
<p>m
m
</p>
<p>it
m
</p>
<p>e
n
</p>
<p>t
</p>
<p>. Fig.&nbsp;7.14 Scatterplot to assess homoscedasticity
</p>
<p>zz Fifth (Optional) Assumption: Normal Error Distribution
To check whether the errors are normally distributed, we need to re-run the regression 
model by going to ► Analyze ► Regression ► Linear Regression. Under Dependent, 
enter the dependent variable commitment and add all the independent variables (i.e., s9, 
s10, s19, s21, s23, category_2, category_3, age, and gender) under Block 1 of 1 (in case you 
ran Ramsey&rsquo;s RESET test, you should press RESET first). Next, click on Plots. In the dialog 
box that opens, click on Histogram under Standardized Residual Plots, followed by Con-
tinue and OK. SPSS will then produce a plot as shown in . Fig.&nbsp;7.15, which suggest that our 
data are normally distributed as the bars indicating the frequency of the errors generally 
follow the normal curve.
</p>
<p>However, we can check this further by conducting the Shapiro&ndash;Wilk test. Do this by 
going to ► Analyze ► Descriptive Statistics ► Explore. Add the unstandardized residual 
variable RES_1 to the Dependent list box and click on Plots. Tick the Normality plots with 
tests box and click on Continue and OK. Then check if the Shapiro-Wilk test under Sig. 
reports a greater value than 0.05. We see this is the case (.083) and therefore conclude that 
the residual is normally distributed (. Table 7.6).
</p>
<p>z Interpret the Regression Model
We have already conducted a regression analysis previously to test the assumptions, so 
there&rsquo;s no need to run the analysis again. We only need to interpret . Table 7.4 in detail and 
the two tables that precede this regression table and which we haven&rsquo;t interpreted previ-
ously. These are . Tables 7.7 and 7.8.
</p>
<p>We start our interpretation of the regression model by examining the model fit. To do 
so, we first check if the model is significant by interpreting the F-test. The p-value under Sig. </p>
<p/>
</div>
<div class="page"><p/>
<p>248 Chapter 7 &middot; Regression Analysis
</p>
<p>in . Table 7.8 (.000) is clearly lower than 0.05, indicating that the model is significant.14 In 
the next step, we interpret the model&rsquo;s R2, which is given in . Table 7.7. The value of .338 is 
moderate but still satisfactory, considering that customer commitment is a rather abstract 
concept, which is therefore difficult to predict. The adjusted R2 is .332 but this value is only 
useful when comparing models with different predictors.
</p>
<p>. Table 7.6 Tests of normality
</p>
<p>Tests of Normality
</p>
<p>Kolmogorov-Smirnova Shapiro-Wilk
</p>
<p>Statistic df Sig. Statistic df Sig.
</p>
<p>RES_1 .026 973 .113 .997 973 .083
</p>
<p>a Lilliefors Significance Correction
</p>
<p>&minus;4
</p>
<p>0
</p>
<p>20
</p>
<p>F
re
</p>
<p>q
u
</p>
<p>e
n
</p>
<p>cy
</p>
<p>Dependent Variable: Commitment
</p>
<p>Histogram
</p>
<p>40
</p>
<p>60
</p>
<p>80
</p>
<p>100
</p>
<p>&minus;2 0
</p>
<p>Regression Standardized Residual
</p>
<p>2
</p>
<p>Mean = 5.52E&minus;16
</p>
<p>Std. Dev. = 0.995
</p>
<p>N = 973
</p>
<p>. Fig.&nbsp;7.15 Histogram of the errors with a standard normal curve
</p>
<p>14 Note that a p-value is never exactly zero, but has values different from zero in later decimal places.
</p>
<p>7</p>
<p/>
</div>
<div class="page"><p/>
<p>7249
7.4 &middot; Example
</p>
<p>After assessing the overall model fit, it is time to look at the individual coefficients 
shown in . Table 7.4. First, we look at the coefficients&rsquo; p-values (Sig.) to assess whether 
these are significant. We find six significant coefficients (s19, s21, s23, category_3, age, and 
gender), with p-values below 0.05. Note that although the constant is also significant, this is 
not a variable and is usually excluded from further interpretation. The significant variables 
require further interpretation. First look at the sign (plus or minus) of the Unstandardized 
Coefficients Beta column in your interpretation. For example, the more satisfied respon-
dents are with Oddjob Airways service delivery (s19), the higher their commitment. The 
unstandardized B (or β) is .012, which means that when the variable s19 moves up by one 
unit (i.e., respondents rate it as 1&nbsp;higher on average), the dependent variable commitment 
goes up by 0.012 units. The same logic applies to the interpretation of the other significant 
coefficients. The interpretation gender is slightly different as this is a dummy variable with 
only two categories. The negative coefficient of &minus;.347 indicates that moving from the base 
category (female) to the other category (male) will decrease commitment by 0.347 units. 
That is, males show less commitment to Oddjob Airways than females. We find that the 
coefficient of category_3 (Gold) is positive (.010) and significant. Thus, we conclude that 
flyers in the Gold category show significantly higher levels of commitment than those in 
the Blue category (i.e., the reference category).
</p>
<p>Next, we should check the Standardized Coefficients Beta column to assess which of 
the variables have the strongest impact on the dependent variable. This cannot be read 
from the unstandardized βs! Remember that the standardized β allows us to compare 
the relative effect of differently measured independent variables by expressing the effect 
in terms of standard deviation changes from the mean. To interpret the standardized βs, 
we should look at the highest absolute value first, which is .245 for s21 (&ldquo;Oddjob Airways 
</p>
<p>. Table 7.7 Model summary
</p>
<p>Model Summaryb
</p>
<p>Model R R Square
</p>
<p>Adjusted R 
</p>
<p>Square
</p>
<p>Std. Error of the 
</p>
<p>Estimate
</p>
<p>1 .581a .338 .332 1.40236
</p>
<p>a Predictors: (Constant), gender, s21, age, category_3, category_2, s10, s23, s9, s19
b Dependent Variable: commitment
</p>
<p>. Table 7.8 ANOVA table
</p>
<p>ANOVAa
</p>
<p>Model
</p>
<p>Sum of 
</p>
<p>Squares df
</p>
<p>Mean 
</p>
<p>Square F Sig.
</p>
<p>1 Regression 966.269  9 107.363 54.593 .000b
</p>
<p>Residual 1893.845 963 1.967
</p>
<p>Total 2860.114 972
</p>
<p>a Dependent Variable: commitment
b Predictors: (Constant), gender, s21, age, category_3, category_2, s10, s23, s9, s19</p>
<p/>
</div>
<div class="page"><p/>
<p>250 Chapter 7 &middot; Regression Analysis
</p>
<p>makes traveling uncomplicated&rdquo;). This result suggests that to increase their customers&rsquo; 
commitment, Oddjob Airways should focus on making the travelling as uncomplicated as 
possible. The variable s23 (&ldquo;Oddjob Airways offers great value for money&rdquo;) has the second 
strongest impact on customer commitment. Note, that while these standardized β coef-
ficients of age and gender also have a significant bearing on the customers&rsquo; commitment, 
they do not indicate much managerial importance.
</p>
<p>In this example, we estimated one model as determined by prior research and man-
agement input. However, in other instances, we might have alternative models, which we 
wish to compare in terms of their fit. In Box 7.4, we describe how to do this by using the 
relative fit statistic AIC.
</p>
<p>Box 7.4. Model comparison using the AIC and BIC
</p>
<p>AIC and BIC are commonly used metrics to compare models with the same dependent variable 
</p>
<p>but different sets of independent variables. Unfortunately, AIC and BIC cannot be accessed 
</p>
<p>by SPSS&rsquo;s graphical user interface but only via syntax, which is, however, not difficult to do. To 
</p>
<p>show how to request these metrics, simply run the initial regression model as explained earlier. 
</p>
<p>However, in the final step, instead of clicking OK, click on Paste. This brings up the IBM Statistics 
Syntax Editor in which you will see a command that starts with the word REGRESSION. Find 
the line that starts with/STATISTICS and add SELECTION to the end of this line. In our case the 
resulting code should look like this:
</p>
<p>REGRESSION
</p>
<p>/DESCRIPTIVES MEAN STDDEV CORR SIG N
</p>
<p>/MISSING LISTWISE
</p>
<p>/STATISTICS COEFF OUTS R ANOVA COLLIN TOL SELECTION
</p>
<p>/CRITERIA&nbsp;=&nbsp;PIN(.05) POUT(.10)
</p>
<p>/NOORIGIN
</p>
<p>/DEPENDENT commitment
</p>
<p>/METHOD&nbsp;=&nbsp;ENTER s9 s10 s19 s21 s23 category_2 category_3 age gender
</p>
<p>/SAVE PRED RESID.
</p>
<p>Then go to ► Run Statistics ► All, which will produce the output shown in . Table&nbsp;7.9. Under 
Akaike Information Criterion, we find the AIC value, which is 667.999. Similarly, under Schwarz 
Bayesian Criterion, we find the BIC value, which is 716.802. We could now re-run the regression 
model with a different set-up (e.g., omitting s9) and compare the initial model&rsquo;s AIC and BIC values 
</p>
<p>with those of the new model.
</p>
<p>. Table 7.9 Relative measures of fit
</p>
<p>Model Summaryb
</p>
<p>Model R
</p>
<p>R 
</p>
<p>Square
</p>
<p>Adjusted 
</p>
<p>R Square
</p>
<p>Std. Error 
</p>
<p>of the  
</p>
<p>Estimate
</p>
<p>Selection Criteria
</p>
<p>Akaike  
</p>
<p>Information 
</p>
<p>Criterion
</p>
<p>Amemiya 
</p>
<p>Prediction 
</p>
<p>Criterion
</p>
<p>Mallows' 
</p>
<p>Prediction 
</p>
<p>Criterion
</p>
<p>Schwarz 
</p>
<p>Bayesian 
</p>
<p>Criterion
</p>
<p>1 .581a .338 .332 1.40236 667.999 .676 10.000 716.802
</p>
<p>a Predictors: (Constant), gender, s21, age, category_3, category_2, s10, s23, s9, s19
b Dependent Variable: commitment
</p>
<p>7</p>
<p/>
</div>
<div class="page"><p/>
<p>7251
7.4 &middot; Example
</p>
<p>z Validate the Regression Model Using SPSS
Next, we need to validate the model. Let&rsquo;s first split-validate our model by randomly select-
ing 30&nbsp;% of the cases. Note that we need to make sure that the 30&nbsp;% of cases left still meet the 
minimum sample size requirements, else split validation should not be conducted. To do this, 
go to ► Data ► Select Cases, which will open a dialog box like in . Fig.&nbsp;7.16. Then click on 
Random sample of cases, followed by Sample. Type 30 in the box Approximately &hellip; % of all 
cases and click on Continue. Before clicking on OK, make sure to select Filter out unselected 
cases under Output. Now click on OK. SPSS will now produce a new variable filter_$ to the 
dataset, which takes the value 1 if an observation has been selected, and 0 else. When running 
an analysis, SPSS now only considers those observations with a value of 1. However, our aim 
is to compare the regression results from the 30&nbsp;% of the dataset with the other 70&nbsp;% of the 
dataset. Hence, we should go ► Data ► Select Cases and select All cases. Next, we need to tell 
SPSS to run separate regressions for all observations where filter_$&nbsp;=&nbsp;0&nbsp;versus filter_$&nbsp;=&nbsp;1. This 
can easily be done by using the split file command, which we can find under ► Data ► Split 
File. In the dialog box that opens (. &nbsp;Fig.&nbsp;7.17), select the option Organize output by groups, 
move the filter_$ variable into the Groups Based on box, and click on OK.
</p>
<p>. Fig.&nbsp;7.16 The select cases dialog box</p>
<p/>
</div>
<div class="page"><p/>
<p>252 Chapter 7 &middot; Regression Analysis
</p>
<p>We now have two groups of data, which SPSS analyses separately when re-running the 
regression analysis. We do not show the model estimation results since the selection of 
cases is random and therefore will not match the output you obtain! Check if the results 
obtained from the analysis of the estimation sample (i.e., the 70&nbsp;%) and validation sample 
(i.e., the 30&nbsp;%) are similar. It is likely some effects will change but the general pattern should 
not change. This means that the signs of the regression coefficients should be the same in 
the estimation sample and validation sample. Similarly, when sorting the coefficients by 
size, the ordering should be identical across the samples.
</p>
<p>As we have no second dataset available, we cannot re-run the analysis to compare 
results between datasets. We do, however, have access to other variables such as country. 
If we add this variable, we should check again if the models are similar. If they are, we can 
conclude that the results are stable.
</p>
<p>7.5 Farming with AgriPro (Case Study)
</p>
<p>. Fig.&nbsp;7.17 The Split File dialog box
</p>
<p>AgriPro (http://www.
</p>
<p>agriprowheat.com) is a firm 
</p>
<p>based in Colorado, USA, 
</p>
<p>which does research on 
</p>
<p>and produces genetically 
</p>
<p>modified wheat seed. Every 
</p>
<p>year, AgriPro conducts 
</p>
<p>thousands of experiments 
</p>
<p>on different varieties of 
</p>
<p>wheat seeds in different 
</p>
<p>USA locations. In these 
</p>
<p>experiments, the agricultural 
</p>
<p>and economic characteristics, 
</p>
<p>regional adaptation, and 
</p>
<p>yield potential of different 
</p>
<p>varieties of wheat seeds are 
</p>
<p>investigated. In addition, 
</p>
<p>the benefits of the wheat 
</p>
<p>produced, including the 
</p>
<p>milling and baking quality, 
</p>
<p>are examined. If a new variety 
</p>
<p>of wheat seed with superior 
</p>
<p>characteristics is identified, 
</p>
<p>AgriPro produces and 
</p>
<p>Case Study
</p>
<p>7</p>
<p/>
<div class="annotation"><a href="http://www.agriprowheat.com">http://www.agriprowheat.com</a></div>
<div class="annotation"><a href="http://www.agriprowheat.com">http://www.agriprowheat.com</a></div>
</div>
<div class="page"><p/>
<p>7253
7.5 &middot; Farming with AgriPro (Case Study)
</p>
<p>markets it throughout the 
</p>
<p>USA and parts of Canada.
</p>
<p>AgriPro&rsquo;s product is sold 
</p>
<p>to farmers through their 
</p>
<p>distributors, known in the 
</p>
<p>industry as growers. Growers 
</p>
<p>buy wheat seed from AgriPro, 
</p>
<p>grow wheat, harvest the 
</p>
<p>seeds, and sell the seed to 
</p>
<p>local farmers, who plant 
</p>
<p>them in their fields. These 
</p>
<p>growers also provide the 
</p>
<p>farmers, who buy their seeds, 
</p>
<p>with expert local knowledge 
</p>
<p>about management and the 
</p>
<p>environment.
</p>
<p>AgriPro sells its products 
</p>
<p>to these growers in several 
</p>
<p>geographically defined 
</p>
<p>markets. These markets are 
</p>
<p>geographically defined, 
</p>
<p>because the different local 
</p>
<p>conditions (soil, weather, 
</p>
<p>and local plant diseases) 
</p>
<p>force AgriPro to produce 
</p>
<p>different products. One of 
</p>
<p>these markets, the heartland 
</p>
<p>region of the USA, is an 
</p>
<p>important AgriPro market, 
</p>
<p>but the company has been 
</p>
<p>performing below the 
</p>
<p>management expectations 
</p>
<p>in it. The heartland region 
</p>
<p>includes the states of Ohio, 
</p>
<p>Indiana, Missouri, Illinois, and 
</p>
<p>Kentucky.
</p>
<p>To help AgriPro understand 
</p>
<p>more about farmers in 
</p>
<p>the heartland region, it 
</p>
<p>commissioned a marketing 
</p>
<p>research project involving 
</p>
<p>the farmers in these states. 
</p>
<p>AgriPro, together with a 
</p>
<p>marketing research firm, 
</p>
<p>designed a survey, which 
</p>
<p>included questions regarding 
</p>
<p>what farmers planting 
</p>
<p>wheat find important, how 
</p>
<p>they obtain information 
</p>
<p>on growing and planting 
</p>
<p>wheat, what is important for 
</p>
<p>their purchasing decision, 
</p>
<p>and their loyalty to and 
</p>
<p>satisfaction with the top five 
</p>
<p>wheat suppliers (including 
</p>
<p>AgriPro). In addition, 
</p>
<p>questions were asked about 
</p>
<p>how many acres of farmland 
</p>
<p>the respondents farm, how 
</p>
<p>much wheat they planted, 
</p>
<p>how old they were, and their 
</p>
<p>level of education.
</p>
<p>This survey was mailed to 650 
</p>
<p>farmers from a commercial 
</p>
<p>list that includes nearly all 
</p>
<p>farmers in the heartland 
</p>
<p>region. In all, 150 responses 
</p>
<p>were received, resulting in 
</p>
<p>a 23&nbsp;% response rate. The 
</p>
<p>marketing research firm also 
</p>
<p>assisted AgriPro to assign 
</p>
<p>variable names and labels. 
</p>
<p>They did not delete any 
</p>
<p>questions or observations 
</p>
<p>due to nonresponse to items.
</p>
<p>Your task is to analyze the 
</p>
<p>dataset further and, based 
</p>
<p>on the dataset, provide the 
</p>
<p>AgriPro management with 
</p>
<p>advice. This dataset is labeled 
</p>
<p>Agripro.sav and is available 
</p>
<p>in the ⤓ Web Appendix (&rarr; 
7&nbsp;Chap.&nbsp;7 &rarr; Downloads). 
Note that the dataset 
</p>
<p>contains the variable names 
</p>
<p>and labels matching those 
</p>
<p>in the survey. In the Web 
</p>
<p>Appendix (⤓ Web Appendix 
&rarr; Downloads), we also 
include the original survey.15
</p>
<p>&copy; valio84sl/Getty Images/iStock
</p>
<p>https://www.guide-market-research.com/app/download/13488671727/
</p>
<p>SPSS+3rd_Chapter+7_Wheat+farming+survey.pdf?t=1516713162
</p>
<p>15 We would like to thank Dr. D.I. Gilliland and AgriPro for making the data and case study available.</p>
<p/>
<div class="annotation"><a href="https://www.guide-market-research.com/app/download/13488671727/SPSS+3rd_Chapter+7_Wheat+farming+survey.pdf?t=1516713162">https://www.guide-market-research.com/app/download/13488671727/SPSS+3rd_Chapter+7_Wheat+farming+survey.pdf?t=1516713162</a></div>
<div class="annotation"><a href="https://www.guide-market-research.com/app/download/13488671727/SPSS+3rd_Chapter+7_Wheat+farming+survey.pdf?t=1516713162">https://www.guide-market-research.com/app/download/13488671727/SPSS+3rd_Chapter+7_Wheat+farming+survey.pdf?t=1516713162</a></div>
</div>
<div class="page"><p/>
<p>254 Chapter 7 &middot; Regression Analysis
</p>
<p>7.6 Review Questions
</p>
<p>1. Explain what regression analysis is in your own words.
2. Imagine you are asked to use regression analysis to explain the profitability of new 
</p>
<p>supermarket products, such as the introduction of a new type of jam or yoghurt, 
during the first year of their launch. Which independent variables would you use to 
explain these new products&rsquo; profitability?
</p>
<p>To help you with this task, 
</p>
<p>AgriPro has prepared several 
</p>
<p>questions that it would like to 
</p>
<p>see answered:
</p>
<p>1. What do these farmers 
</p>
<p>find important when 
</p>
<p>growing wheat? Please 
</p>
<p>describe the variables 
</p>
<p>import1 (&ldquo;Wheat fulfills my 
</p>
<p>rotational needs&rdquo;), import2 
</p>
<p>(&ldquo;I double crop soybeans&rdquo;), 
</p>
<p>import3 (&ldquo;Planting wheat 
</p>
<p>improves my corn yield&rdquo;), 
</p>
<p>import4 (&ldquo;It helps me 
</p>
<p>break disease and pest 
</p>
<p>cycles&rdquo;), and import5 (&ldquo;It 
</p>
<p>gives me summer cash 
</p>
<p>flow&rdquo;) and interpret.
</p>
<p>2. What drives how much 
</p>
<p>wheat these farmers 
</p>
<p>grow (wheat)? Agripro 
</p>
<p>management is interested 
</p>
<p>in whether import1, 
</p>
<p>import2, import3, import4, 
</p>
<p>and import5 can explain 
</p>
<p>wheat. Please run this 
</p>
<p>regression model and test 
</p>
<p>the assumptions. Can you 
</p>
<p>report on this model to 
</p>
<p>AgriPro&rsquo;s management? 
</p>
<p>Please discuss.
</p>
<p>3. Please calculate the AIC 
</p>
<p>and BIC for the model 
</p>
<p>discussed in question 2. 
</p>
<p>Then add the variables 
</p>
<p>acre and age. Calculate 
</p>
<p>the AIC and BIC again. 
</p>
<p>Which model is better? 
</p>
<p>Should we present the 
</p>
<p>model with or without 
</p>
<p>acre and age to our 
</p>
<p>client?
</p>
<p>4. AgriPro expects that 
</p>
<p>farmers who are more 
</p>
<p>satisfied with their 
</p>
<p>products devote a greater 
</p>
<p>percentage of their total 
</p>
<p>number of acres to wheat 
</p>
<p>(wheat). Please test this 
</p>
<p>assumption by using 
</p>
<p>regression analysis. The 
</p>
<p>client has requested 
</p>
<p>that you control for 
</p>
<p>the number of acres of 
</p>
<p>farmland (acre), the age 
</p>
<p>of the respondent (age), 
</p>
<p>the quality of the seed 
</p>
<p>(var3), and the availability 
</p>
<p>of the seed (var4), and 
</p>
<p>check the assumptions of 
</p>
<p>the regression analysis. 
</p>
<p>Note that a smaller 
</p>
<p>sample size is available 
</p>
<p>for this analysis, which 
</p>
<p>means the sample size 
</p>
<p>requirement cannot be 
</p>
<p>met. Proceed with the 
</p>
<p>analysis nevertheless. Are 
</p>
<p>all the other assumptions 
</p>
<p>satisfied? If not, is there 
</p>
<p>anything we can do 
</p>
<p>about this, or should we 
</p>
<p>ignore the assumptions if 
</p>
<p>they are not satisfied?
</p>
<p>5. Agripro wants you 
</p>
<p>to consider which 
</p>
<p>customers are most loyal 
</p>
<p>to its biggest competitor 
</p>
<p>Pioneer (loyal5). Use the 
</p>
<p>number of acres (acre), 
</p>
<p>number of acres planted 
</p>
<p>with wheat (wheat), and 
</p>
<p>the age of the respondent 
</p>
<p>(age). What findings do 
</p>
<p>we obtain? Does this 
</p>
<p>regression model meet 
</p>
<p>the requirements and 
</p>
<p>assumptions?
</p>
<p>6. As an AgriPro&rsquo;s consultant, 
</p>
<p>and based on this study&rsquo;s 
</p>
<p>empirical findings, what 
</p>
<p>marketing advice do 
</p>
<p>you have for AgriPro&rsquo;s 
</p>
<p>marketing team? Using 
</p>
<p>bullet points, provide four 
</p>
<p>or five carefully thought 
</p>
<p>through suggestions.
</p>
<p>7</p>
<p/>
</div>
<div class="page"><p/>
<p>7255
References
</p>
<p>3. Imagine you have to present the findings of a regression model to a client. The client 
believes that the regression model is a &ldquo;black box&rdquo; and that anything can be made 
significant. What would your reaction be?
</p>
<p>4. I do not care about the assumptions&mdash;just give me the results! Please evaluate this 
statement in the context of regression analysis. Do you agree?
</p>
<p>5. Are all regression assumptions equally important? Please discuss.
6. Using standardized βs, we can compare effects between different variables. Can we 
</p>
<p>compare apples and oranges after all? Please discuss.
7. Try adding or deleting variables from the regression model in the Oddjob Airways 
</p>
<p>example and use the adjusted R2, as well as AIC statistic, to assess if these models are 
better.
</p>
<p>References
</p>
<p>Aiken, L. S., &amp; West, S. G. (1991). Multiple regression: testing and interpreting interactions. Thousand Oaks, 
</p>
<p>CA: Sage.
</p>
<p>Baum, C. F. (2006). An introduction to modern econometrics using Stata. College Station, TX: Stata Press.
</p>
<p>Burnham, K. P., &amp; Anderson, D. R. (2013). Model Selection and multimodel inference: A practical informa-
</p>
<p>tion-theoretic approach (2nd ed.). New York, NJ: Springer.
</p>
<p>Cohen, J. (1994). The earth is round (p &lt; .05). The American Psychologist, 49(912), 997&ndash;1003.
</p>
<p>Cook, R. D., &amp; Weisberg, S. (1983). Diagnostics for heteroscedasticity in regression. Biometrika, 70(1), 
</p>
<p>1&ndash;10.
</p>
<p>Durbin, J., &amp; Watson, G. S. (1951). Testing for serial correlation in least squares regression, II. Biometrika, 
</p>
<p>38(1&ndash;2), 159&ndash;179.
</p>
<p>Fabozzi, F. J., Focardi, S. M., Rachev, S. T., &amp; Arshanapalli, B. G. (2014). The basics of financial econometrics: 
</p>
<p>tools, concepts, and asset management applications. Hoboken, NJ: John Wiley &amp; Sons.
</p>
<p>Field, A. (2013). Discovering statistics using SPSS (4th ed.). London: Sage.
</p>
<p>Green, S. B. (1991). How many subjects does it take to do a regression analysis? Multivariate Behavioral 
</p>
<p>Research, 26(3), 499&ndash;510.
</p>
<p>Greene, W. H. (2011). Econometric analysis (7th ed.). Upper Saddle River, NJ: Prentice Hall.
</p>
<p>Hair Jr., J. F., Black, W. C., Babin, B. J., &amp; Anderson, R. E. (2019). Multivariate data analysis (8th ed.). Boston, 
</p>
<p>MA: Cengage.
</p>
<p>Hill, C., Griffiths, W., &amp; Lim, G. C. (2011). Principles of econometrics (4th ed.). Hoboken, NJ: John Wiley &amp; 
</p>
<p>Sons.
</p>
<p>Kelley, K., &amp; Maxwell, S. E. (2003). Sample size for multiple regression: Obtaining regression coefficients 
</p>
<p>that are accurate, not simply significant. Psychological Methods, 8(3), 305&ndash;321.
</p>
<p>Mason, C. H., &amp; Perreault Jr., W. D. (1991), Collinearity, power, and interpretation of multiple regression 
</p>
<p>analysis. Journal of Marketing Research, 28(3), 268&ndash;280.
</p>
<p>Mooi, E. A., &amp; Frambach, R. T. (2009). A stakeholder perspective on buyer&ndash;supplier conflict. Journal of Mar-
</p>
<p>keting Channels, 16(4), 291&ndash;307.
</p>
<p>O&rsquo;brien, R. M. (2007). A caution regarding rules of thumb for variance inflation factors. Quality &amp; Quantity, 
</p>
<p>41(5), 673&ndash;690.
</p>
<p>Paternoster, R., Brame, R., Mazerolle, P., &amp; Piquero, A. (1998). Using the correct statistical test for the equal-
</p>
<p>ity of regression coefficients. Criminology, 36(4), 859&ndash;866.
</p>
<p>Ramsey, J. B. (1969). Test for specification errors in classical linear least-squares regression analysis. Jour-
</p>
<p>nal of the Royal Statistical Society, Series B, 31(2), 350&ndash;371.
</p>
<p>Treiman, D. J. (2014). Quantitative data analysis: Doing social research to test ideas. Hoboken, NJ: John 
</p>
<p>Wiley &amp; Sons.
</p>
<p>VanVoorhis, C. R. W., &amp; Morgan, B. L. (2007). Understanding power and rules of thumb for determining 
</p>
<p>sample sizes. Tutorials in Quantitative Methods for Psychology, 3(2), 43&ndash;50.</p>
<p/>
</div>
<div class="page"><p/>
<p>256 Chapter 7 &middot; Regression Analysis
</p>
<p>Further Reading
</p>
<p>Echambadi, R., &amp; Hess, J. D. (2007). Mean-centering does not alleviate collinearity problems in moderated 
</p>
<p>multiple regression models. Marketing Science, 26(3), 438&ndash;445.
</p>
<p>Iacobucci, D. (2008). Mediation analysis: Quantitative applications in the social sciences. Thousand Oaks, CA: 
</p>
<p>Sage.
</p>
<p>Shmueli, G. (2010). To explain or to predict? Statistical Science, 25(3), 289&ndash;310.
</p>
<p>Spiller, S. A., Fitzsimons, G. J., Lynch Jr., J. G., &amp; McClelland, G. H. (2013). Spotlights, floodlights, and the 
</p>
<p>magic number zero: Simple effects tests in moderated regression. Journal of Marketing Research, 
</p>
<p>50(2), 277&ndash;288.
</p>
<p>Zhao, X., Lynch, J. G., &amp; Chen, Q. (2010). Reconsidering Baron and Kenny: Myths and truths about media-
</p>
<p>tion analysis. Journal of Consumer Research, 37(2), 197&ndash;206.
</p>
<p>7</p>
<p/>
</div>
<div class="page"><p/>
<p>257
</p>
<p>Principal Component and 
Factor Analysis
</p>
<p>8.1 Introduction &ndash; 259
</p>
<p>8.2 Understanding Principal Component and Factor 
Analysis &ndash; 261
</p>
<p>8.2.1 Why Use Principal Component and Factor Analysis? &ndash; 261
</p>
<p>8.2.2 Analysis Steps &ndash; 262
</p>
<p>8.3 Principal Component Analysis &ndash; 263
8.3.1 Check Requirements and Conduct Preliminary  
</p>
<p>Analyses &ndash; 263
</p>
<p>8.3.2 Extract the Factors &ndash; 266
</p>
<p>8.3.3 Determine the Number of Factors &ndash; 271
</p>
<p>8.3.4 Interpret the Factor Solution &ndash; 272
</p>
<p>8.3.5 Evaluate the Goodness-of-Fit of the Factor Solution &ndash; 275
</p>
<p>8.3.6 Compute the Factor Scores &ndash; 275
</p>
<p>8.4 Confirmatory Factor Analysis and Reliability  
Analysis &ndash; 276
</p>
<p>8.5 Structural Equation Modeling &ndash; 280
</p>
<p>8.6 Example &ndash; 282
8.6.1 Principal Component Analysis &ndash; 282
</p>
<p>8.6.2 Reliability Analysis &ndash; 293
</p>
<p>8
</p>
<p>&copy; Springer-Verlag GmbH Germany, part of Springer Nature 2019 
</p>
<p>M. Sarstedt, E. Mooi, A Concise Guide to Market Research, Springer Texts in Business  
</p>
<p>and Economics, https://doi.org/10.1007/978-3-662-56707-4_8
</p>
<p>Electronic supplementary material
</p>
<p>The online version of this chapter (https://doi.org/10.1007/978-3-662-56707-4_8) contains 
</p>
<p>additional material that is available to authorized users. You can also download the &ldquo;Springer 
</p>
<p>Nature More Media App&rdquo; from the iOS or Android App Store to stream the videos and scan the 
</p>
<p>image containing the &ldquo;Play button&rdquo;.</p>
<p/>
<div class="annotation"><a href="https://crossmark.crossref.org/dialog/?doi=10.1007/978-3-662-56707-4_8&amp;amp;domain=pdf&amp;amp;date_stamp=2018-9-17">https://crossmark.crossref.org/dialog/?doi=10.1007/978-3-662-56707-4_8&amp;amp;domain=pdf&amp;amp;date_stamp=2018-9-17</a></div>
</div>
<div class="page"><p/>
<p>8.7 Customer Satisfaction at Haver &amp; Boecker  
(Case Study) &ndash; 296
</p>
<p>8.8 Review Questions &ndash; 297
</p>
<p> References &ndash; 298</p>
<p/>
</div>
<div class="page"><p/>
<p>8259
8.1 &middot; Introduction
</p>
<p>Keywords
Anti-image &bull; Bartlett method &bull; Bartlett&rsquo;s test of sphericity &bull; Communality &bull; Components &bull; Confirmatory 
</p>
<p>factor analysis&nbsp; &bull;&nbsp; Correlation residuals &bull; Covariance-based structural equation modeling &bull; Cronbach&rsquo;s 
</p>
<p>Alpha&nbsp; &bull;&nbsp; Direct oblimin rotation&nbsp; &bull;&nbsp; Eigenvalue &bull; Eigenvectors &bull; Exploratory factor analysis &bull; Factor analy-
</p>
<p>sis&nbsp;&bull;&nbsp;Factor loading&nbsp;&bull;&nbsp;Factor rotation &bull; Factor scores &bull; Factor weights &bull; Factors &bull; Internal consistency reliabil-
</p>
<p>ity&nbsp;&bull; Kaiser criterion&nbsp;&bull;&nbsp;Kaiser&ndash;Meyer&ndash;Olkin criterion &bull; Latent root criterion &bull; Measure of sampling adequa-
</p>
<p>cy&nbsp;&bull;&nbsp;Oblique rotation&nbsp;&bull;&nbsp;Orthogonal rotation &bull; Parallel analysis &bull; Partial least squares structural equation mod-
</p>
<p>eling &bull; Path diagram&nbsp;&bull;&nbsp;Principal axis factoring &bull; Principal component analysis &bull; Principal components&nbsp;&bull;&nbsp;Prin-
</p>
<p>cipal factor analysis &bull; Promax rotation &bull; Quartimax rotation&nbsp;&bull;&nbsp;Regression method &bull; Reliability analysis&nbsp;&bull;&nbsp;Scree 
</p>
<p>plot&nbsp;&bull;&nbsp;Split-half reliability &bull; Structural equation modeling&nbsp;&bull;&nbsp;Test-retest reliability&nbsp;&bull;&nbsp;Varimax rotation
</p>
<p>8.1 Introduction
</p>
<p>Principal component analysis (PCA) and factor analysis (also called principal factor analysis 
or principal axis factoring) are two methods for identifying structure within a set of vari-
ables. Many analyses involve large numbers of variables that are difficult to interpret. Using 
PCA or factor analysis helps find interrelationships between variables (usually called items) 
to identify a smaller number of unifying variables called factors. Consider the example of a 
soccer club whose management wants to measure the satisfaction of the fans. The manage-
ment could, for instance, measure fan satisfaction by asking how satisfied the fans are with 
the (1) assortment of merchandise, (2) quality of merchandise, and (3) prices of merchan-
dise. It is likely that these three items together measure satisfaction with the merchandise. 
Through the application of PCA or factor analysis, we can determine whether a single factor 
represents the three satisfaction items well. Practically, PCA and factor analysis are applied 
to understand much larger sets of variables, tens or even hundreds, when just reading the 
variables&rsquo; descriptions does not determine an obvious or immediate number of factors.
</p>
<p>PCA and factor analysis both explain patterns of correlations within a set of observed 
variables. That is, they identify sets of highly correlated variables and infer an underlying 
factor structure. While PCA and factor analysis are very similar in the way they arrive at a 
solution, they differ fundamentally in their assumptions of the variables&rsquo; nature and their 
treatment in the analysis. Due to these differences, the methods follow different research 
objectives, which dictate their areas of application. While the PCA&rsquo;s objective is to reproduce 
</p>
<p>Learning Objectives
After reading this chapter, you should understand:
</p>
<p> 5 The basics of principal component and factor analysis.
 5 The principles of exploratory and confirmatory factor analysis.
 5 Key terms, such as communality, eigenvalues, factor loadings, and factor scores.
 5 What factor rotation is.
 5 How to determine whether data are suitable for carrying out an exploratory factor 
analysis.
</p>
<p> 5 How to interpret SPSS principal component analysis output.
 5 The principles of reliability analysis and its execution in SPSS.
 5 The concept of structural equation modeling.</p>
<p/>
</div>
<div class="page"><p/>
<p>260 Chapter 8 &middot; Principal Component and Factor Analysis
</p>
<p>a data structure, as well as possible only using a few factors, factor analysis aims to explain 
the variables&rsquo; correlations using factors (e.g., Hair et al. 2010; Matsunaga 2010; Mulaik 
2009).1 We will discuss these differences and their implications in this chapter.
</p>
<p>Both PCA and factor analysis can be used for exploratory or confirmatory purposes. 
What are exploratory and confirmatory factor analyses? Comparing the left and right panels 
of . &nbsp;Fig&nbsp;8.1 shows us the difference. Exploratory factor analysis, often simply referred to as 
EFA, does not rely on previous ideas on the factor structure we may find. That is, there may 
be relationships (indicated by the arrows) between each factor (indicated by ovals) and each 
item. While some of these relationships may be weak (indicated by the dotted arrows), others 
are more pronounced, suggesting that these items represent an underlying factor well. The 
left panel of  .&nbsp;Fig. 8.1 illustrates this point. Thus, an exploratory factor analysis reveals the 
number of factors and the items belonging to a specific factor. In a confirmatory factor anal-
ysis, usually simply referred to as CFA, there may only be relationships between a factor and 
specific items. In the right panel of  . Fig. 8.1, the first three items relate to factor 1, whereas 
the last two items relate to factor 2. Different from the exploratory factor analysis, in a con-
firmatory factor analysis, we have clear expectations of the factor structure (e.g., because 
researchers have proposed a scale that we want to adapt for our study) and we want to test 
for the expected structure.
</p>
<p>In this chapter, we primarily deal with exploratory factor analysis, as it conveys the 
principles that underlie all factor analytic procedures and because the two techniques are 
(almost) identical from a statistical point of view. Nevertheless, we will also discuss an 
important aspect of confirmatory factor analysis, namely reliability analysis, which tests 
the consistency of a measurement scale (see 7 Chap.&nbsp;3). We will also briefly introduce a 
specific confirmatory factor analysis approach called structural equation modeling (often 
simply referred to as SEM). Structural equation modeling differs statistically and practi-
cally from PCA and factor analysis. It is not only used to evaluate how well observed vari-
ables relate to factors but also to analyze hypothesized relationships between factors that 
the researcher specifies prior to the analysis based on theory and logic.
</p>
<p>1 Other methods for carrying out factor analyses include, for example, unweighted least squares, gen-
</p>
<p>eralized least squares, or maximum likelihood but these are statistically complex.
</p>
<p>Satisfaction with the
condition of the
</p>
<p>stadium (x1)
</p>
<p>Satisfaction with the
outer appearance of the
</p>
<p>stadium (x2) 
</p>
<p>Satisfaction with the
interior design of the
</p>
<p>stadium (x3) 
</p>
<p>Satisfaction with
</p>
<p>the stadium
</p>
<p>(factor 1) 
</p>
<p>Assortment of 
</p>
<p>merchandise (x4) 
</p>
<p>Quality of 
</p>
<p>merchandise (x5) 
</p>
<p>Satisfaction with
</p>
<p>the merchandise
</p>
<p>(factor 2) 
</p>
<p>Satisfaction with the
condition of the
</p>
<p>stadium (x1)
</p>
<p>Satisfaction with the
outer appearance of the
</p>
<p>stadium (x2)
</p>
<p>Satisfaction with the
interior design of the
</p>
<p>stadium (x3)
</p>
<p>Satisfaction with
</p>
<p>the stadium
</p>
<p>(factor 1) 
</p>
<p>Assortment of 
</p>
<p>merchandise (x4)
</p>
<p>Quality of 
</p>
<p>merchandise (x5)
</p>
<p>Satisfaction with
</p>
<p>the merchandise
</p>
<p>(factor 2) 
</p>
<p>. Fig. 8.1 Exploratory factor analysis (left) and confirmatory factor analysis (right)
</p>
<p>8</p>
<p/>
</div>
<div class="page"><p/>
<p>8261
8.2 &middot; Understanding Principal Component and Factor Analysis
</p>
<p>8.2 Understanding Principal Component and Factor Analysis
</p>
<p>8.2.1 Why Use Principal Component and Factor Analysis?
</p>
<p>Researchers often face the problem of large questionnaires comprising many items. For 
example, in a survey of a major German soccer club, the management was particularly inter-
ested in identifying and evaluating performance features that relate to soccer fans&rsquo; satisfaction 
(Sarstedt et al. 2014). Examples of relevant features include the stadium, the team composi-
tion and their success, the trainer, and the management. The club therefore commissioned a 
questionnaire comprising 99 previously identified items by means of literature databases and 
focus groups of fans. All the items were measured on scales ranging from 1 (&ldquo;very dissatisfied&rdquo;) 
to 7 (&ldquo;very satisfied&rdquo;). . Table 8.1 shows an overview of some items considered in the study.
</p>
<p>. Table 8.1 Items in the soccer fan satisfaction study
</p>
<p>Satisfaction with &hellip;
</p>
<p>Condition of the stadium Public appearances of the players
</p>
<p>Interior design of the stadium Number of stars in the team
</p>
<p>Outer appearance of the stadium Interaction of players with fans
</p>
<p>Signposting outside the stadium Volume of the loudspeakers in the stadium
</p>
<p>Signposting inside the stadium Choice of music in the stadium
</p>
<p>Roofing inside the stadium Entertainment program in the stadium
</p>
<p>Comfort of the seats Stadium speaker
</p>
<p>Video score boards in the stadium Newsmagazine of the stadium
</p>
<p>Condition of the restrooms Price of annual season ticket
</p>
<p>Tidiness within the stadium Entry fees
</p>
<p>Size of the stadium Offers of reduced tickets
</p>
<p>View onto the playing field Design of the home jersey
</p>
<p>Number of restrooms Design of the away jersey
</p>
<p>Sponsors&rsquo; advertisements in the stadium Assortment of merchandise
</p>
<p>Location of the stadium Quality of merchandise
</p>
<p>Name of the stadium Prices of merchandise
</p>
<p>Determination and commitment of the players Pre-sale of tickets
</p>
<p>Current success regarding matches Online-shop
</p>
<p>Identification of the players with the club Opening times of the fan-shops
</p>
<p>Quality of the team composition Accessibility of the fan-shops
</p>
<p>Presence of a player with whom fans can identify Behavior of the sales persons in the fan shops</p>
<p/>
</div>
<div class="page"><p/>
<p>262 Chapter 8 &middot; Principal Component and Factor Analysis
</p>
<p>As you can imagine, tackling such a large set of items is problematic, because it pro-
vides quite complex data. Given the task of identifying and evaluating performance fea-
tures that relate to soccer fans&rsquo; satisfaction (measured by &ldquo;Overall, how satisfied are you 
with your soccer club&rdquo;), we cannot simply compare the items on a pairwise basis. It is far 
more reasonable to consider the factor structure first. For example, satisfaction with the 
condition of the stadium (x1), outer appearance of the stadium (x2), and interior design 
of the stadium (x3) cover similar aspects that relate to the respondents&rsquo; satisfaction with 
the stadium. If a soccer fan is generally very satisfied with the stadium, he/she will most 
likely answer all three items positively. Conversely, if a respondent is generally dissatis-
fied with the stadium, he/she is most likely to be rather dissatisfied with all the perfor-
mance aspects of the stadium, such as the outer appearance and interior design. Conse-
quently, these three items are likely to be highly correlated&mdash;they cover related aspects 
of the respondents&rsquo; overall satisfaction with the stadium. More precisely, these items can 
be interpreted as manifestations of the factor capturing the &ldquo;joint meaning&rdquo; of the items 
related to it. The arrows pointing from the factor to the items in . Fig. 8.1 indicate this point. 
In our example, the &ldquo;joint meaning&rdquo; of the three items could be described as satisfaction 
with the stadium, since the items represent somewhat different, yet related, aspects of the 
stadium. Likewise, there is a second factor that relates to the two items x4 and x5, which, 
like the first factor, shares a common meaning, namely satisfaction with the merchandise.
</p>
<p>PCA and factor analysis are two statistical procedures that draw on item correlations 
in order to find a small number of factors. Having conducted the analysis, we can make 
use of few (uncorrelated) factors instead of many variables, thus significantly reducing the 
analysis&rsquo;s complexity. For example, if we find six factors, we only need to consider six cor-
relations between the factors and overall satisfaction, which means that the recommen-
dations will rely on six factors.
</p>
<p>8.2.2 Analysis Steps
</p>
<p>Like any multivariate analysis method, PCA and factor analysis are subject to certain 
requirements, which need to be met for the analysis to be meaningful. A crucial require-
ment is that the variables need to exhibit a certain degree of correlation. In our example in 
. Fig. 8.1, this is probably the case, as we expect increased correlations between x1, x2, and 
x3, on the one hand, and between x4 and x5 on the other. Other items, such as x1 and x4, are 
probably somewhat correlated, but to a lesser degree than the group of items x1, x2, and x3 
and the pair x4 and x5. Several methods allow for testing whether the item correlations are 
sufficiently high.
</p>
<p>Both PCA and factor analysis strive to reduce the overall item set to a smaller set of 
factors. More precisely, PCA extracts factors such that they account for variables&rsquo; vari-
ance, whereas factor analysis attempts to explain the correlations between the variables. 
Whichever approach you apply, using only a few factors instead of many items reduces its 
precision, because the factors cannot represent all the information included in the items. 
Consequently, there is a trade-off between simplicity and accuracy. In order to make the 
analysis as simple as possible, we want to extract only a few factors. At the same time, we 
do not want to lose too much information by having too few factors. This trade-off has to 
be addressed in any PCA and factor analysis when deciding how many factors to extract 
from the data.
</p>
<p>8</p>
<p/>
</div>
<div class="page"><p/>
<p>8263
8.3 &middot; Principal Component Analysis
</p>
<p>Once the number of factors to retain from the data has been identified, we can proceed 
with the interpretation of the factor solution. This step requires us to produce a label for each 
factor that best characterizes the joint meaning of all the variables associated with it. This step 
is often challenging, but there are ways of facilitating the interpretation of the factor solution. 
Finally, we have to assess how well the factors reproduce the data. This is done by examining 
the solution&rsquo;s goodness-of-fit, which completes the standard analysis. However, if we wish to 
continue using the results in further analyses, we need to calculate the factor scores. Factor 
scores are linear combinations of the items and can be used as variables in follow-up analyses.
</p>
<p>. Figure 8.2 illustrates the steps involved in the analysis; we will discuss these in more 
detail in the following sections. In doing so, our theoretical descriptions and illustrations 
will focus on the PCA, as this method is easier to grasp. However, most of our descriptions 
also apply to factor analysis.
</p>
<p>8.3 Principal Component Analysis
</p>
<p>8.3.1 Check Requirements and Conduct Preliminary Analyses
</p>
<p>Before carrying out a PCA, we have to consider several requirements, which we can test 
by answering the following questions:
</p>
<p> 4 Are the measurement scales appropriate?
 4 Is the sample size sufficiently large?
 4 Are the observations independent?
 4 Are the variables sufficiently correlated?
</p>
<p>Check requirements and conduct preliminary analyses 
</p>
<p>Extract the factors 
</p>
<p>Determine the number of factors 
</p>
<p>Interpret the factor solution 
</p>
<p>Evaluate the goodness-of-fit of the factor solution 
</p>
<p>Compute the factor scores (optional) 
</p>
<p>. Fig. 8.2 Steps involved in a PCA</p>
<p/>
</div>
<div class="page"><p/>
<p>264 Chapter 8 &middot; Principal Component and Factor Analysis
</p>
<p>z Are the measurement scales appropriate?
For a PCA, it is best to have data measured on an interval or ratio scale. In practical appli-
cations, items measured on an ordinal scale level have become common. Ordinal scales 
can be used if:
</p>
<p> 4 the scale points are equidistant, which means that the difference in the wording 
between scale steps is the same (see 7 Chap.&nbsp;3), and
 4 there are five or more response categories.
</p>
<p>z Is the sample size sufficiently large?
Another point of concern is the sample size. As a rule of thumb, the number of (valid) 
observations should be at least ten times the number of items used for analysis. This only 
provides a rough indication of the necessary sample size. Fortunately, researchers have 
conducted studies to determine minimum sample size requirements, which depend on 
other aspects of the study. MacCallum et al. (1999) suggest the following:
 4 When all communalities (we will discuss this term in 7 Sect.&nbsp;8.3.2.4) are above 0.60, 
</p>
<p>small sample sizes of below 100 are adequate.
 4 With communalities around 0.50, sample sizes between 100 and 200 are sufficient.
 4 When communalities are consistently low, with many or all under 0.50, a sample size 
</p>
<p>between 100 and 200 is adequate if the number of factors is small and each of these is 
measured with six or more items.
 4 When communalities are consistently low and the factors numbers are high or are 
</p>
<p>measured with only few items (i.e., 3 or less), 300 observations are recommended.
</p>
<p>z Are the observations independent?
We have to ensure that the observations are independent. This means that the observations 
need to be completely unrelated (see 7 Chap.&nbsp;3). If we use dependent observations, we would 
introduce &ldquo;artificial&rdquo; correlations, which are not due to an underlying factor structure, 
but simply to the same respondents having answered the same questions multiple times.
</p>
<p>z Are the variables sufficiently correlated?
As indicated before, PCA is based on correlations between items. Consequently, conduct-
ing a PCA only makes sense if the items correlate sufficiently. The problem is deciding what 
&ldquo;sufficient&rdquo; actually means.
</p>
<p>An obvious step is to examine the correlation matrix (7 Chap.&nbsp;5). Naturally, we want 
the correlations between different items to be as high as possible, but they will not always 
be. In our previous example, we expect high correlations between x1, x2, and x3, on the 
one hand, and x4 and x5 on the other. Conversely, we might expect lower correlations 
between, for example, x1 and x4 and between x3 and x5. Thus, not all of the correlation 
matrix&rsquo;s elements need to have high values. The PCA depends on the relative size of the 
correlations. Therefore, if single correlations are very low, this is not necessarily problem-
atic! Only when all the correlations are around zero, PCA is no longer useful. In addition, 
the statistical significance of each correlation coefficient helps decide whether it differs 
significantly from zero.
</p>
<p>There are additional measures to determine whether the items correlate sufficiently. 
One is the anti-image. The anti-image describes the portion of an item&rsquo;s variance that is 
independent of another item in the analysis. Obviously, we want all items to be highly 
correlated, so that the anti-images of an item set are as small as possible. Initially, we do 
</p>
<p>8</p>
<p/>
</div>
<div class="page"><p/>
<p>8265
8.3 &middot; Principal Component Analysis
</p>
<p>not interpret the anti-image values directly, but use a measure based on the anti-image 
concept: The Kaiser&ndash;Meyer&ndash;Olkin (KMO) criterion. The KMO criterion, also called the 
measure of sampling adequacy (MSA), indicates whether the other variables in the dataset 
can explain the correlations between variables. Kaiser (1974), who introduced the sta-
tistic, recommends a set of nicely labeled threshold values for KMO and MSA, which 
.&nbsp;Table&nbsp;8.2 presents.
</p>
<p>The Bartlett&rsquo;s test of sphericity can be used to test the null hypothesis that the correla-
tion matrix is a diagonal matrix (i.e., all non-diagonal elements are zero) in the population. 
Since we need high correlations for PCA, we want to reject the null hypothesis. A large test 
statistic value and corresponding a small p-value will favor the rejection of the hypoth-
esis. In practical applications, it is virtually impossible not to reject this null hypothesis, 
as typically there are some correlations, particularly in larger sets of items. In addition, 
PCA is typically used with large samples, a situation, which favors the rejection of the null 
hypothesis. Thus, Bartlett&rsquo;s test is of rather limited value for assessing whether the vari-
ables are sufficiently correlated.
</p>
<p>To summarize, the correlation matrix with the associated significance levels provides a 
first insight into the correlation structures. However, the final decision of whether the data 
are appropriate for PCA should be primarily based on the KMO statistic. If this measure 
indicates sufficiently correlated variables, we can continue the analysis of the results. If 
not, we should try to identify items that correlate only weakly with the remaining items 
and remove them. In Box 8.1, we discuss how to do this.
</p>
<p>. Table 8.2 Threshold values for KMO and MSA
</p>
<p>KMO/MSA value Adequacy of the correlations
</p>
<p>Below 0.50 Unacceptable
</p>
<p>0.50&ndash;0.59 Miserable
</p>
<p>0.60&ndash;0.69 Mediocre
</p>
<p>0.70&ndash;0.79 Middling
</p>
<p>0.80&ndash;0.89 Meritorious
</p>
<p>0.90 and higher Marvelous
</p>
<p>Box 8.1 Identifying problematic items
</p>
<p>Examining the correlation matrix and the significance levels of correlations allows identifying 
</p>
<p>items that correlate only weakly with the remaining items. An even better approach is examining 
</p>
<p>the variable-specific MSA values, which are interpreted like the overall KMO statistic (see  
</p>
<p>. Table 8.2). In fact, the KMO statistic is simply the overall mean of all variable-specific MSA 
values. Consequently, all the MSA values should also lie above the threshold level of 0.50. If 
</p>
<p>this is not the case, consider removing this item from the analysis. An item&rsquo;s communality (see 
7 Sect.&nbsp;8.3.2.4) can also serve as a useful indicator of how well the factors extracted represent 
an item. However, communalities are mostly considered when evaluating the solution&rsquo;s 
</p>
<p>goodness-of-fit.</p>
<p/>
</div>
<div class="page"><p/>
<p>266 Chapter 8 &middot; Principal Component and Factor Analysis
</p>
<p>8.3.2 Extract the Factors
</p>
<p>8.3.2.1 Principal Component Analysis vs. Factor Analysis
Factor analysis assumes that each variable&rsquo;s variance can be divided into common vari-
ance (i.e., variance shared with all the other variables in the analysis) and unique variance  
(. Fig. 8.3), the latter of which can be further broken down into specific variance (i.e., 
variance associated with only one specific variable) and error variance (i.e., variance 
due to measurement error). The method, however, can only reproduce common vari-
ance. Thereby factor analysis explicitly recognizes the presence of error. Conversely, PCA 
assumes that all variance is common variance, which factor extraction can fully explain 
(e.g., Preacher and MacCallum 2003). These differences entail different interpretations of 
the analysis&rsquo;s outcomes. PCA asks:
</p>
<p>&raquo; Which umbrella term can we use to summarize a set of variables that loads highly on a 
specific factor?
</p>
<p>Conversely, factor analysis asks:
</p>
<p>&raquo; What is the common reason for the strong correlations between a set of variables?
From a theoretical perspective, the assumption that there is a unique variance for which the 
factors cannot fully account, is generally more realistic, but simultaneously more restric-
tive. Although theoretically sound, this restriction can sometimes lead to complications 
in the analysis, which have contributed to the widespread use of PCA, especially in market 
research practice.
</p>
<p>Researchers usually suggest using PCA when data reduction is the primary concern; 
that is, when the focus is to extract a minimum number of factors that account for a 
maximum proportion of the variables&rsquo; total variance. In contrast, if the primary concern 
is to identify latent dimensions represented in the variables, factor analysis should be 
applied. However, prior research has shown that both approaches arrive at essentially the 
same result when
</p>
<p>Common variance /
</p>
<p>communality
</p>
<p>Common variance /
</p>
<p>communality
</p>
<p>Unique 
</p>
<p>variance 
</p>
<p>Principal component analysis Factor analysis 
</p>
<p>Variance extracted 
</p>
<p>Variance excluded 
</p>
<p>. Fig. 8.3 Principal component analysis vs. factor analysis
</p>
<p>8</p>
<p/>
</div>
<div class="page"><p/>
<p>8267
8.3 &middot; Principal Component Analysis
</p>
<p> 4 more than 30&nbsp;variables are used, or
 4 most of the variables&rsquo; communalities exceed 0.60.
</p>
<p>With 20 or fewer variables and communalities below 0.40&mdash;which are clearly undesirable 
in empirical research&mdash;the differences are probably pronounced (Stevens 2009).
</p>
<p>Apart from these conceptual differences in the variables&rsquo; nature, PCA and factor 
 analysis differ in the aim of their analysis. Whereas the goal of factor analysis is to explain 
the correlations between the variables, PCA focuses on explaining the variables&rsquo; variances. 
That is, the PCA&rsquo;s objective is to determine the linear combinations of the variables that 
retain as much information from the original variables as possible. Strictly speaking, PCA 
does not extract factors, but components, which are labeled as such in SPSS.
</p>
<p>Despite these differences, which have very little relevance in many common research 
settings in practice, PCA and factor analysis have many points in common. For example, 
the methods follow very similar ways to arrive at a solution and their interpretations of 
statistical measures, such as KMO, eigenvalues, or factor loadings, are (almost) identical. 
In fact, SPSS blends these two procedures when running a PCA as the program initially 
applies a factor analysis but rescales the estimates such that they conform to a PCA. That 
way, the analysis assumes that the entire variance is common but produces (rotated) load-
ings (we will discuss factor rotation in 7 Sect.&nbsp;8.3.4.1), which facilitate the interpretation 
of the factors.
</p>
<p>Despite the small differences of PCA and factor analysis in most research settings, 
researchers have strong feelings about the choice of PCA or factor analysis. Cliff (1987, p. 
349) summarizes this issue well, by noting that proponents of factor analysis &ldquo;insist that 
components analysis is at best a common factor analysis with some error added and at 
worst an unrecognizable hodgepodge of things from which nothing can be determined.&rdquo; 
For further discussions on this topic, see also Velicer and Jackson (1990) and Widaman 
(1993).2
</p>
<p>8.3.2.2 How Does Factor Extraction Work?
</p>
<p>When extracting factors, PCA&rsquo;s objective is to reproduce a data structure with only a 
few factors. PCA does this by generating a new set of factors as linear composites of the 
original variables, which reproduces the original variables&rsquo; variance as best as possi-
ble. These linear composites are called principal components, but, for simplicity&rsquo;s sake, 
we refer to them as factors. More precisely, PCA computes eigenvectors. These eigen-
vectors include so called factor weights, which extract the maximum possible variance 
of all the variables, with successive factoring continuing until a significant share of the 
variance is explained.
</p>
<p>Operationally, the first factor is extracted in such a way that it maximizes the vari-
ance accounted for in the variables. We can visualize this easily by examining the vector 
space illustrated in . Fig. 8.4. In this example, we have five variables (x1&minus;x5) represented 
</p>
<p>2 Related discussions have been raised in structural equation modeling, where researchers have 
</p>
<p>heatedly discussed the strengths and limitations of factor-based and component-based approaches 
</p>
<p>(e.g.&nbsp;Sarstedt et al. 2016a; Hair et al. 2017b).</p>
<p/>
</div>
<div class="page"><p/>
<p>268 Chapter 8 &middot; Principal Component and Factor Analysis
</p>
<p>by five vectors starting at the zero point, with each vector&rsquo;s length standardized to one. 
To maximize the variance accounted for, the first factor F1 is fitted into this vector space 
in such a way that the sum of all the angles between this factor and the five variables in 
the vector space is minimized. We do this to interpret the angle between two vectors 
as correlations. For example, if the factor&rsquo;s vector and a variable&rsquo;s vector are congruent, 
the angle between these two is zero, indicating that the factor and the variable correlate 
perfectly. On the other hand, if the factor and the variable are uncorrelated, the angle 
between these two is 90&deg;. This correlation between a (unit-scaled) factor and a vari-
able is called the factor loading. Note that factor weights and factor loadings essentially 
express the same thing&mdash;the relationships between variables and factors&mdash;but they are 
based on different scales.
</p>
<p>After extracting F1, a second factor (F2) is extracted, which maximizes the remain-
ing variance accounted for. The second factor is fitted at a 90&deg; angle into the vector space 
(.&nbsp;Fig.&nbsp;8.4) and is therefore uncorrelated with the first factor.4 If we extract a third factor, 
it will explain the maximum amount of variance for which factors 1 and 2&nbsp;have hitherto 
not accounted. This factor will also be fitted at a 90&deg; angle to the first two factors, making it 
independent from the first two factors (we don&rsquo;t illustrate this third factor in . Fig. 8.4, as 
this is a three-dimensional space). The fact that the factors are uncorrelated is an import-
ant feature, as we can use them to replace many highly correlated variables in follow-up 
analyses. For example, using uncorrelated factors as independent variables in a regression 
analysis helps solve potential collinearity issues (7 Chap.&nbsp;7).
</p>
<p>F1
</p>
<p>F2
</p>
<p>x1
x2
</p>
<p>x3
</p>
<p>x4
x5
</p>
<p>90&deg;
</p>
<p>. Fig. 8.4 Factor extraction3
</p>
<p>4 Note that this changes when oblique rotation is used. We will discuss factor rotation later in this 
</p>
<p>chapter.
</p>
<p>3 Note that . Fig. 8.3 describes a special case, as the five variables are scaled down into a two-dimen-
sional space. In this set-up, it would be possible for the two factors to explain all five items. However, 
</p>
<p>in real-life, the five items span a five-dimensional vector space.
</p>
<p>8</p>
<p/>
</div>
<div class="page"><p/>
<p>8269
8.3 &middot; Principal Component Analysis
</p>
<p>An important PCA feature is that it works with standardized variables (see 7 Chap.&nbsp;5 for 
an explanation of what standardized variables are). Standardizing variables has import-
ant implications for our analysis in two respects. First, we can assess each factor&rsquo;s eigen-
value, which indicates how much a specific factor extracts all of the variables&rsquo; variance  
(see 7 Sect.&nbsp;8.3.2.3). Second, the standardization of variables allows for assessing each 
variable&rsquo;s communality, which describes how much the factors extracted capture or repro-
duce each variable&rsquo;s variance (see 7 Sect.&nbsp;8.3.2.4).
</p>
<p>8.3.2.3 What Are Eigenvalues?
</p>
<p>To understand the concept of eigenvalues, think of the soccer fan satisfaction study 
(.&nbsp;Fig.&nbsp;8.1). In this example, there are five variables. As all the variables are standardized 
prior to the analysis, each has a variance of 1. In a simplified way, we could say that the 
overall information (i.e., variance) that we want to reproduce through factor extraction is 
5 units. Let&rsquo;s assume that we extract the two factors presented above.
</p>
<p>The first factor&rsquo;s eigenvalue indicates how much of the total variance the factor accounts 
for. Each variable has a variance of 1, which means the number of variables is the total vari-
ance (i.e., 5&nbsp;variables&nbsp;=&nbsp;5 units of variance). If a factor has an eigenvalue of, let&rsquo;s say 2.10, it 
covers the information of 2.10&nbsp;variables or, put differently, accounts for 2.10/5.00&nbsp;=&nbsp;42&nbsp;% 
of the overall variance (. Fig. 8.5).
</p>
<p>Extracting a second factor will allow us to explain another part of the remaining vari-
ance (i.e., 5.00&nbsp;&minus;&nbsp;2.10&nbsp;=&nbsp;2.90 units, . Fig. 8.5). However, the eigenvalue of the second 
factor will always be smaller than that of the first factor. Assume that the second factor 
has an eigenvalue of 1.30 units. The second factor then accounts for 1.30/5.00&nbsp;=&nbsp;26&nbsp;% of 
the overall variance. Together, these two factors explain (2.10&nbsp;+&nbsp;1.30)/5.00&nbsp;=&nbsp;68&nbsp;% of the 
</p>
<p>The Explained Visually webpage offers an excellent illustration of two- and three-dimensional 
</p>
<p>factor extraction.
</p>
<p>&copy; intheskies/stock.adobe.com
</p>
<p>http://setosa.io/ev/principal-component-analysis/</p>
<p/>
<div class="annotation"><a href="http://setosa.io/ev/principal-component-analysis/">http://setosa.io/ev/principal-component-analysis/</a></div>
</div>
<div class="page"><p/>
<p>270 Chapter 8 &middot; Principal Component and Factor Analysis
</p>
<p>overall variance. Every additional factor extracted increases the variance accounted for 
until we have extracted as many factors as there are variables. In this case, the factors 
account for 100&nbsp;% of the overall variance, which means that the factors reproduce the 
complete variance.
</p>
<p>0.30 
</p>
<p>2.10 
</p>
<p>1.30 
</p>
<p>0.80 
</p>
<p>0.50 
</p>
<p>2.10 
</p>
<p>1.30 
</p>
<p>5.00 
</p>
<p>Total variance Total variance 
</p>
<p>reproduced by 
</p>
<p>five factors 
</p>
<p>Variance 
</p>
<p>reproduced by 
</p>
<p>two factors 
</p>
<p>%
 o
</p>
<p>f 
v
</p>
<p>a
ri
</p>
<p>a
n
</p>
<p>ce
 
</p>
<p>100% 100% 
</p>
<p>68% 
</p>
<p>. Fig. 8.5 Total variance explained by variables and factors
</p>
<p>For readers interested in the statistical principles, the Explained Visually webpage illustrates the 
</p>
<p>concepts of eigenvalues and eigenvectors.
</p>
<p>&copy; Alexander Vasilyev/stock.adobe.com
</p>
<p>http://setosa.io/ev/eigenvectors-and-eigenvalues/
</p>
<p>8</p>
<p/>
<div class="annotation"><a href="http://setosa.io/ev/eigenvectors-and-eigenvalues/">http://setosa.io/ev/eigenvectors-and-eigenvalues/</a></div>
</div>
<div class="page"><p/>
<p>8271
8.3 &middot; Principal Component Analysis
</p>
<p>Following the PCA approach, we assume that factor extraction can reproduce each vari-
able&rsquo;s entire variance. In other words, we assume that each variable&rsquo;s variance is common; 
that is, the variance is shared with other variables. This differs in factor analysis, in which 
each variable can also have a unique variance.
</p>
<p>8.3.2.4 What Is Communality?
</p>
<p>Whereas the eigenvalue tells us how much variance each factor accounts for, the commu-
nality indicates how much variance of each variable factor extraction can reproduce. There 
is no commonly agreed threshold for a variable&rsquo;s communality, as this depends strongly 
on the complexity of the analysis at hand. However, generally, the extracted factors should 
account for at least 50&nbsp;% of a variable&rsquo;s variance. Thus, the communalities should be above 
0.50. Every additional factor extracted will increase the explained variance, and if we 
extract as many factors as there are variables (in our example five), each variable&rsquo;s commu-
nality would be 1.00. The factors extracted would then fully explain each variable; that is, 
the first factor will explain a certain amount of each variable&rsquo;s variance, the second factor 
another part, and so on.
</p>
<p>However, since our overall objective is to reduce the number of variables through factor 
extraction, we should extract only a few factors that account for a high degree of overall 
variance. This raises the question of how to decide on the number of factors to extract from 
the data, which we discuss in the following section.
</p>
<p>8.3.3 Determine the Number of Factors
</p>
<p>Determining the number of factors to extract from the data is a crucial and challenging 
step in any PCA. Several approaches offer guidance in this respect, but most researchers 
do not pick just one method, but use multiple ones. If different methods suggest the same 
number of factors, this leads to greater confidence in the results.
</p>
<p>8.3.3.1 The Kaiser Criterion
</p>
<p>An intuitive way to decide on the number of factors is to extract all the factors with an 
eigenvalue greater than 1. The reason for this is that each factor with an eigenvalue greater 
than 1 accounts for more variance than a single variable (remember, we are looking at stan-
dardized variables, which is why each variable&rsquo;s variance is exactly 1). As the objective of 
PCA is to reduce the overall number of variables, each factor should of course account 
for more variance than a single variable can. If this occurs, then this factor is useful for 
reducing the set of variables. Extracting all the factors with an eigenvalue greater than 1 
is frequently called the Kaiser criterion or latent root criterion and is commonly used to 
determine the number of factors. However, the Kaiser criterion is well known for over-
specifying the number of factors; that is, the criterion suggests more factors than it should 
(e.g., Russell 2002; Zwick and Velicer 1986).
</p>
<p>8.3.3.2 The Scree Plot
</p>
<p>Another popular way to decide on the number of factors to extract is to plot each factor&rsquo;s 
eigenvalue (y-axis) against the factor with which it is associated (x-axis). This results 
in a scree plot, which typically has a distinct break in it, thereby showing the &ldquo;correct&rdquo; </p>
<p/>
</div>
<div class="page"><p/>
<p>272 Chapter 8 &middot; Principal Component and Factor Analysis
</p>
<p>number of factors (Cattell 1966). This distinct break is called the &ldquo;elbow.&rdquo; Researchers 
typically recommend retaining all factors above this break, as they contribute most to 
the explanation of the variance in the dataset. Thus, we select one factor less than indi-
cated by the elbow.
</p>
<p>8.3.3.3 Parallel Analysis
</p>
<p>A large body of review papers and simulation studies has produced a prescriptive con-
sensus that Horn&rsquo;s (1965) parallel analysis is the best method for deciding how many 
factors to extract (e.g., Dinno 2009; Hayton et al. 2004; Henson and Roberts 2006; 
Matsunga 2010; Zwick and Velicer 1986). The rationale underlying parallel analysis is 
that factors from real data with a valid underlying factor structure should have larger 
eigenvalues than those derived from randomly generated data (actually pseudorandom 
deviates) with the same sample size and number of variables. Parallel analysis involves 
several steps. First, a large number of datasets are randomly generated that have the 
same number of observations and variables as the original dataset. Parallel PCAs are 
then run on each of the datasets (hence, parallel analysis), resulting in many slightly 
different sets of randomly generated eigenvalues. We then compare the randomly gen-
erated eigenvalues with those from the original analysis. Only factors whose original 
eigenvalues are larger than the 95th percentile of the eigenvalues should be retained 
(Longman et al. 1989).
</p>
<p>8.3.3.4 Expectations
</p>
<p>When, for example, replicating a previous market research study, we might have a priori 
information on the number of factors we want to find. For example, if a previous study 
suggests that a certain item set comprises five factors, we should extract the same number 
of factors, even if statistical criteria, such as the scree plot, suggest a different number. 
Similarly, theory might suggest that a certain number of factors should be extracted from 
the data.
</p>
<p>Strictly speaking, these are confirmatory approaches to PCA, which blur the distinc-
tion between these two factor analysis types. Ultimately however, we should not only rely 
on the data, but keep in mind that the research results should be interpretable and action-
able for market research practice. Once we have decided on the number of factors to retain 
from the data, we can start interpreting the factor solution.
</p>
<p>&gt; Whatever combination of approaches we use to determine the number of factors, 
the factors extracted should account for at least 50&nbsp;% of the total variance 
</p>
<p>explained (75&nbsp;% or more is recommended). 
</p>
<p>8.3.4 Interpret the Factor Solution
</p>
<p>8.3.4.1 Rotate the Factors
</p>
<p>To interpret the solution, we have to determine which variables relate to each of the factors 
extracted. We do this by examining the factor loadings, which represent the correlations 
between the factors and the variables and can take values ranging from &minus;1 to +1. A high 
</p>
<p>8</p>
<p/>
</div>
<div class="page"><p/>
<p>8273
8.3 &middot; Principal Component Analysis
</p>
<p>factor loading indicates that a certain factor represents a variable well. Subsequently, we 
look for high absolute values, because the correlation between a variable and a factor 
can also be negative. Using the highest absolute factor loadings, we &ldquo;assign&rdquo; each vari-
able to a certain factor and then produce a label for each factor that best characterizes 
the joint meaning of all the variables associated with it. This labeling is subjective, but 
a key PCA step. An example of a label is the respondents&rsquo; satisfaction with the stadium, 
which  represents the items referring to its condition, outer appearance, and interior design 
(.&nbsp;Fig.&nbsp;8.1).
</p>
<p>We can make use of factor rotation to facilitate the factors&rsquo; interpretation. We do not 
have to rotate the factor solution, but it will facilitate interpreting the findings, partic-
ularly if we have a reasonably large number of items (say six or more). To understand 
what factor rotation is all about, once again consider the factor structure described in 
. Fig. 8.4. Here, we see that both factors relate to the variables in the set. However, the 
first factor appears to generally correlate more strongly with the variables, whereas the 
second factor only correlates weakly with the variables (to clarify, we look for small 
angles between the factors and variables). This implies that we &ldquo;assign&rdquo; all variables 
to the first factor without taking the second into consideration. This does not appear 
to be very meaningful, as we want both factors to represent certain facets of the vari-
able set. Factor rotation can resolve this problem. By rotating the factor axes, we can 
create a situation in which a set of variables loads highly on only one specific factor, 
whereas another set loads highly on another. . Figure 8.6 illustrates the factor rota-
tion graphically.
</p>
<p>On the left side of the figure, we see that both factors are orthogonally rotated 49&deg;, 
meaning that a 90&deg; angle is maintained between the factors during the rotation procedure. 
Consequently, the factors remain uncorrelated, which is in line with the PCA&rsquo;s initial objec-
tive. By rotating the first factor from F1 to F1&prime;, it is now strongly related to variables x1, x2, 
and x3, but weakly related to x4 and x5. Conversely, by rotating the second factor from F2 
to F2&prime;, it is now strongly related to x4 and x5, but weakly related to the remaining variables. 
The assignment of the variables is now much clearer, which facilitates the interpretation 
of the factors significantly.
</p>
<p>Various orthogonal rotation methods exist, all of which differ with regard to their treat-
ment of the loading structure. The varimax rotation is the best-known and this procedure 
</p>
<p>F1
</p>
<p>F1
</p>
<p>F2
</p>
<p>F2
</p>
<p>x1
x2
</p>
<p>x3
</p>
<p>x4
x5
</p>
<p>F
</p>
<p>45&ordm;49&ordm;
</p>
<p>49&ordm;
66&ordm;
</p>
<p>1
</p>
<p>F1
</p>
<p>F2
</p>
<p>F2
x1
</p>
<p>x2
</p>
<p>x3
</p>
<p>x4
</p>
<p>x5
</p>
<p>. Fig. 8.6 Orthogonal and oblique factor rotation</p>
<p/>
</div>
<div class="page"><p/>
<p>274 Chapter 8 &middot; Principal Component and Factor Analysis
</p>
<p>aims at maximizing the dispersion of loadings within factors, which means a few vari-
ables will have high loadings, while the remaining variables&rsquo; loadings will be considerably 
smaller (Kaiser 1958)
</p>
<p>Alternatively, we can choose between several oblique rotation techniques. In oblique 
rotation, the 90&deg; angle between the factors is not maintained during rotation, and the 
resulting factors are therefore correlated. . Figure 8.6 (right side) illustrates an example 
of an oblique factor rotation. Promax rotation is a commonly used oblique rotation tech-
nique. The promax rotation allows for setting an exponent (referred to as kappa) that 
needs to be greater than 1. Higher values make the loadings even more extreme (i.e., 
high loadings are amplified and weak loadings are reduced even further), which is at 
the cost of stronger correlations between the factors and less total variance explained 
(Hamilton 2013). A kappa value of 3&nbsp;works well for most applications. Direct oblimin 
rotation is a popular alternative oblique rotation type, which allows specifying the 
maximum degree of obliqueness. This degree is the delta, which determines the level 
of the correlation allowed between the factors. A delta of zero (the default) ensures 
that the factors are&mdash;if at all&mdash;only moderately correlated, which is acceptable for most 
analyses. Oblique rotation is used when factors are possibly related. It is, for example, 
very likely that the respondents&rsquo; satisfaction with the stadium is related to their satis-
faction with other aspects of the soccer club, such as the number of stars in the team or 
the quality of the merchandise. However, relinquishing the initial objective of extract-
ing uncorrelated factors can diminish the factors&rsquo; interpretability. We therefore recom-
mend using the varimax rotation to enhance the interpretability of the results. Only if 
the results are difficult to interpret, an oblique rotation should be applied. Among the 
oblique rotation methods, researchers generally recommend the promax (Gorsuch 
1983) or oblimin (Kim and Mueller 1978) methods but differences between the rota-
tion types are typically marginal (Brown 2009).
</p>
<p>8.3.4.2 Assign the Variables to the Factors
</p>
<p>After rotating the factors, we need to interpret them and give each factor a name, which 
has some descriptive value. Interpreting factors involves assigning each variable to a 
specific factor based on the highest absolute (!) loading. For example, if a variable has 
a 0.60&nbsp;loading with the first factor and a 0.20&nbsp;loading with the second, we would assign 
this variable to the first factor. Loadings may nevertheless be very similar (e.g., 0.50 for 
the first factor and 0.55 for the second one), making the assignment ambiguous. In such 
a situation, we could assign the variable to another factor, even though it does not have 
the highest loading on this specific factor. While this step can help increase the results&rsquo; 
face validity (see 7 Chap.&nbsp;3), we should make sure that the variable&rsquo;s factor loading with 
the designated factor is above an acceptable level. If very few factors have been extracted, 
the loading should be at least 0.50, but with a high number of factors, lower loadings 
of above 0.30 are acceptable. Alternatively, some simply ignore a certain variable if it 
does not fit with the factor structure. In such a situation, we should re-run the analy-
sis without variables that do not load highly on a specific factor. In the end, the results 
should be interpretable and actionable, but keep in mind that this technique is, first and 
foremost, exploratory!
</p>
<p>8</p>
<p/>
</div>
<div class="page"><p/>
<p>8275
8.3 &middot; Principal Component Analysis
</p>
<p>8.3.5 Evaluate the Goodness-of-Fit of the Factor Solution
</p>
<p>8.3.5.1  Check the Congruence of the Initial and Reproduced 
Correlations
</p>
<p>While PCA focuses on explaining the variables&rsquo; variances, checking how well the method 
approximates the correlation matrix allows for assessing the quality of the solution (i.e., 
the goodness-of-fit) (Graffelman 2013). More precisely, to assess the solution&rsquo;s goodness-
of-fit, we can make use of the differences between the correlations in the data and those 
that the factors imply. These differences are also called correlation residuals and should 
be as small as possible.
</p>
<p>In practice, we check the proportion of correlation residuals with an absolute value 
higher than 0.05. Even though there is no strict rule of thumb regarding the maximum 
proportion, a proportion of more than 50&nbsp;% should raise concern. However, high residuals 
usually go hand in hand with an unsatisfactory KMO measure; consequently, this problem 
already surfaces when testing the assumptions.
</p>
<p>8.3.5.2  Check How Much of Each Variable&rsquo;s Variance Is Reproduced 
by Means of Factor Extraction
</p>
<p>Another way to check the solution&rsquo;s goodness-of-fit is by evaluating how much of each 
variable&rsquo;s variance the factors reproduce (i.e., the communality). If several communal-
ities exhibit low values, we should consider removing these variables. Considering the 
variable-specific MSA measures could help us make this decision (see Box 8.1). If there 
are more variables in the dataset, communalities usually become smaller; however, if the 
factor solution accounts for less than 50&nbsp;% of a variable&rsquo;s variance (i.e., the variable&rsquo;s com-
munality is less than 0.50), it is worthwhile reconsidering the set-up.
</p>
<p>8.3.6 Compute the Factor Scores
</p>
<p>After the rotation and interpretation of the factors, we can compute the factor scores, 
another element of the analysis. Factor scores are linear combinations of the items and can 
be used as separate variables in subsequent analyses. For example, instead of using many 
highly correlated independent variables in a regression analysis, we can use few uncor-
related factors to overcome collinearity problems.
</p>
<p>The simplest ways to compute factor scores for each observation is to sum all the scores 
of the items assigned to a factor. While easy to compute, this approach neglects the poten-
tial differences in each item&rsquo;s contribution to each factor (Sarstedt et al. 2016).
</p>
<p>Drawing on the item weights produced by the PCA is a more elaborate way of com-
puting factor scores (Hershberger 2005). These weights indicate each item&rsquo;s relative con-
tribution to forming the factor; we simply multiply the standardized variables&rsquo; values 
with the weights to get the factor scores. Factor scores computed on the basis of item 
weights have a zero mean. This means that if a respondent has a value greater than zero 
for a certain factor, he/she scores above the average in terms of the characteristic that this 
factor describes. Conversely, if a factor score is below zero, then this respondent exhibits 
the characteristic below average.</p>
<p/>
</div>
<div class="page"><p/>
<p>276 Chapter 8 &middot; Principal Component and Factor Analysis
</p>
<p>Different from the PCA, a factor analysis does not produce determinate factor scores. 
In other words, the factor is indeterminate, which means that part of it remains an arbi-
trary quantity, capable of taking on an infinite range of values (e.g., Grice 2001; Steiger 
1979). Thus, we have to rely on other approaches to compute factor scores. The use of these 
approaches is, however, not restricted to factor analysis but extends to PCA, because of the 
specific way SPSS (and other programs) have implemented the method. The most promi-
nent of these approaches is the regression method. This method takes into account (1) the 
correlation between the factors and variables (via the variable loadings), (2) the correla-
tion between the variables, and (3) the correlation between the factors if oblique rotation 
has been used (DiStefano et al. 2009). The regression method z-standardizes each factor to 
zero mean and unit standard deviation.5 We can therefore interpret an observation&rsquo;s score 
in relation to the mean and in terms of the units of standard deviation from this mean. For 
example, an observation&rsquo;s factor score of 0.79 implies that this observation is 0.79 standard 
deviations above the average with regard to the corresponding factor.
</p>
<p>Another popular approach is the Bartlett method, which is similar to the regression 
method. In SPSS, the method produces factor scores with zero mean and standard devia-
tions larger than one. Owing to the way they are estimated, the factor scores that the Bartlett 
method produces are considered more accurate (Hershberger 2005). However, in practical 
applications, both methods produce very similar results. Because of the z-standardization 
of the scores, which facilitates the comparison of scores across factors, we recommend 
using the regression method.
</p>
<p>In . Table 8.3 we summarize the main steps that need to be taken when conducting a 
PCA or factor analysis in SPSS.
</p>
<p>8.4 Confirmatory Factor Analysis and Reliability Analysis
</p>
<p>Many researchers and practitioners acknowledge the prominent role that exploratory 
factor analysis plays in exploring data structures. Data can be analyzed without precon-
ceived ideas of the number of factors or how these relate to the variables under consider-
ation. Whereas this approach is, as its name implies, exploratory in nature, the confirma-
tory factor analysis allows for testing hypothesized structures underlying a set of variables.
</p>
<p>In a confirmatory factor analysis, the researcher needs to first specify the constructs 
and their associations with variables, which should be based on previous measurements 
or theory. Instead of allowing the procedure to determine the number of factors, as is 
done in an exploratory factor analysis, a confirmatory factor analysis tells us how well 
the actual data fit the pre-specified structure. Returning to our introductory example, we 
could, for example, assume that the construct satisfaction with the stadium can be mea-
sured by the three items x1 (condition of the stadium), x2 (appearance of the stadium), 
and x3 (interior design of the stadium). Likewise, we could hypothesize that satisfaction 
with the merchandise can be adequately measured using the items x4 and x5. In a confir-
matory factor analysis, we set up a theoretical model linking the items with the respective 
</p>
<p>5 Note that this is only the case in PCA. When using factor analysis, the standard deviations are differ-
</p>
<p>ent from one (DiStefano et al. 2009).
</p>
<p>8</p>
<p/>
</div>
<div class="page"><p/>
<p>8277
8.4 &middot; Confirmatory Factor Analysis and Reliability Analysis
</p>
<p>. Table 8.3 Steps involved in carrying out a PCA or factor analysis in SPSS
</p>
<p>Theory Action
</p>
<p>Check assumptions and carry out preliminary analyses
</p>
<p>Select variables that should be 
</p>
<p>reduced to a set of underlying 
</p>
<p>factors (PCA) or should be used to 
</p>
<p>identify underlying dimensions 
</p>
<p>(factor analysis)
</p>
<p>► Analyze ► Dimension Reduction ► Factor. Enter the 
variables in the Variables box.
</p>
<p>Are the variables interval or ratio 
</p>
<p>scaled?
</p>
<p>Determine the measurement level of your variables  
</p>
<p>(see 7 Chap.&nbsp;3). If ordinal variables are used, make sure that 
the scale steps are equidistant.
</p>
<p>Is the sample size sufficiently 
</p>
<p>large?
</p>
<p>Check MacCallum et al.&rsquo;s (1999) guidelines for minimum 
</p>
<p>sample size requirements, dependent on the variables&rsquo; 
</p>
<p>communality. For example, if all the communalities are 
</p>
<p>above 0.60, small sample sizes of below 100 are adequate. 
</p>
<p>With communalities around 0.50, sample sizes between 100 
</p>
<p>and 200 are sufficient. Ensure that your dataset meets these 
</p>
<p>thresholds after handling missing values.
</p>
<p>Are the observations 
</p>
<p>independent?
</p>
<p>Determine whether the observations are dependent or 
</p>
<p>independent (see 7 Chap.&nbsp;3).
</p>
<p>Are the variables sufficiently 
</p>
<p>correlated?
</p>
<p>► Analyze ► Dimension Reduction ► Factor ► Descriptives. 
Tick Coefficients, Significance levels, KMO and Bartlett&rsquo;s 
test of sphericity, and Anti-image.
Check whether the KMO &ge; 0.50. Also consider the following 
</p>
<p>measures:
</p>
<p>&ndash;  Are the correlation coefficients different from zero and 
</p>
<p>significant (indicated in the lower part of the correlation 
</p>
<p>matrix under Sig. (1-tailed)?)
&ndash; Is the p-value of the Bartlett&rsquo;s test (indicated by Sig.) &le; 0.05?
To identify items that are too lowly correlated, check the 
</p>
<p>variable-specific MSA values (indicated in the Anti-Image 
Correlation table). Are the MSA values &ge; 0.50?
</p>
<p>Extract the factors
</p>
<p>Choose the method of factor 
</p>
<p>analysis
</p>
<p>If the goal is to reduce the number of variables to a set of 
</p>
<p>underlying factors (i.e., principal component analysis):
</p>
<p>► Analyze ► Dimension Reduction ► Factor ► Extraction 
► Principal components.
If the goal is to identify underlying dimensions (i.e., factor 
</p>
<p>analysis):
</p>
<p>► Analyze ► Dimension Reduction ► Factor ► Extraction 
►Principal axis factoring</p>
<p/>
</div>
<div class="page"><p/>
<p>278 Chapter 8 &middot; Principal Component and Factor Analysis
</p>
<p>Theory Action
</p>
<p>Determine the number of factors
</p>
<p>Determine the number of factors Kaiser criterion: Extract all factor with an eigenvalue greater 
</p>
<p>than 1 (default).
</p>
<p>Create a scree plot and select the number left of the 
</p>
<p>distinctive break (elbow).
</p>
<p>► Analyze ► Dimension Reduction ► Factor ► Extraction 
► Scree plot
Run parallel analysis: Download the syntax file Parallel 
</p>
<p>analysis.sps from the book&rsquo;s website (⤓Web Appendix 
&rarr; Downloads) and open it in SPSS. Specify the number 
of observations under compute Ncases (line 10) and 
the number of variables under compute NVars (line 11). 
Go to ►&nbsp;Run ► All. Extract those factors whose original 
eigenvalues are greater than those indicated under Prcntyle.
Pre-specify the number of factors based on a priori 
</p>
<p>information: ► Analyze ► Data Reduction ► Factor 
►&nbsp;Extraction ► Fixed number of factors: Factors to extract
Check the Cumulative % column in the Total Variance 
Explained column.
</p>
<p>Interpret the factor solution
</p>
<p>Rotate the factors Use the varimax procedure or, if necessary, the promax 
</p>
<p>procedure with kappa set to 3: ► Analyze ► Dimension 
Reduction ► Factor ► Rotation.
</p>
<p>Assign variables to factors and 
</p>
<p>interpret the factors
</p>
<p>Use the rotated solution to assign each variable to a certain 
</p>
<p>factor based on the highest absolute loading. To facilitate 
</p>
<p>interpretation, you may also assign a variable to a different 
</p>
<p>factor but check that the loading lies at an acceptable level 
</p>
<p>(0.50 if only few factors are extracted, 0.30 if many factors are 
</p>
<p>extracted).
</p>
<p>Find an umbrella term for clusters of items assigned to each 
</p>
<p>factor.
</p>
<p>Compute factor scores Save factor scores as new variables using the regression 
</p>
<p>method: ► Analyze ► Dimension Reduction ► Factor 
►&nbsp;Scores ► Save as variables: Regression.
</p>
<p>Evaluate the goodness-of-fit of the factor solution
</p>
<p>Check the congruence of 
</p>
<p>the initial and reproduced 
</p>
<p>correlations
</p>
<p>Create a reproduced correlation matrix: ► Analyze 
► Dimension Reduction ► Factor ► Descriptives 
►&nbsp;Reproduced. Is the proportion of residuals greater than 
0.05&nbsp;&le;&nbsp;50&nbsp;%?
</p>
<p>Check how much of each 
</p>
<p>variable&rsquo;s variance is reproduced 
</p>
<p>by means of factor extraction
</p>
<p>Examine the communalities from the reproduced correlation 
</p>
<p>matrix. Check if reproduced communalities (on the diagonal) 
</p>
<p>are&nbsp;&ge;&nbsp;0.50.
</p>
<p>. Table&nbsp;8.3 (Continued)
</p>
<p>8</p>
<p/>
</div>
<div class="page"><p/>
<p>8279
8.4 &middot; Confirmatory Factor Analysis and Reliability Analysis
</p>
<p>construct (note that in confirmatory factor analysis, researchers generally use the term 
construct rather than factor). This process is also called operationalization (see 7 Chap.&nbsp;3) 
and usually involves drawing a visual representation (called a path diagram) indicating 
the expected relationships.
</p>
<p>. Figure 8.7 shows a path diagram&mdash;you will notice the similarity to the diagram in  
. Fig. 8.1. Ovals represent the constructs (e.g., Y1, satisfaction with the stadium) and boxes 
represent the items (x1 to x5). Other elements include the relationships between the con-
structs and respective items (the loadings l1 to l5), the error terms (e1 to e5) that capture the 
extent to which a construct does not explain a specific item, and the correlations between 
the constructs of interest (r12).
</p>
<p>Having defined the individual constructs and developed the path diagram, we can 
estimate the model. The relationships between the constructs and items (the loadings l1 
to l5) and the item correlations (not shown in . Fig. 8.7) are of particular interest, as they 
indicate whether the construct has been reliably and validly measured.
</p>
<p>Reliability analysis is an important element of a confirmatory factor analysis and essen-
tial when working with measurement scales. The preferred way to evaluate reliability is by 
taking two independent measurements (using the same subjects) and comparing these 
using correlations. This is also called test-retest reliability (see 7 Chap.&nbsp;3). However, prac-
ticalities often prevent researchers from surveying their subjects a second time.
</p>
<p>An alternative is to estimate the split-half reliability. In the split-half reliability, scale 
items are divided into halves and the scores of the halves are correlated to obtain an esti-
mate of reliability. Since all items should be consistent regarding what they indicate about 
the construct, the halves can be considered approximations of alternative forms of the 
</p>
<p>Satisfaction with the 
condition of the stadium (x1) 
</p>
<p>Satisfaction with the outer 
appearance of the stadium (x2) 
</p>
<p>Satisfaction with the interior 
design of the stadium (x3) 
</p>
<p>Satisfaction with  
the stadium (Y1) 
</p>
<p>Assortment of 
merchandise (x4) 
</p>
<p>Quality of 
merchandise (x5)  
</p>
<p>Satisfaction with  
the merchandise (Y2) 
</p>
<p>l1 
</p>
<p>l2 
</p>
<p>l3 
</p>
<p>l4 
</p>
<p>l5 
</p>
<p>e1 
</p>
<p>e2 
</p>
<p>e3 
</p>
<p>e4 
</p>
<p>e5 
</p>
<p>r12 
</p>
<p>. Fig. 8.7 Path diagram (confirmatory factor analysis)</p>
<p/>
</div>
<div class="page"><p/>
<p>280 Chapter 8 &middot; Principal Component and Factor Analysis
</p>
<p>Box 8.2 Things to consider when calculating Cronbach&rsquo;s Alpha
</p>
<p>When calculating Cronbach&rsquo;s Alpha, ensure that all items are formulated in the same direction 
</p>
<p>(positively or negatively worded). For example, in psychological measurement, it is common 
</p>
<p>to use both negatively and positively worded items in a questionnaire. These need to be 
</p>
<p>reversed prior to the reliability analysis. In SPSS, this can be achieved using the Recode option 
discussed in 7 Chap.&nbsp;5. Furthermore, we have to be aware of there being multiple factors in our 
item set. Some multi-item scales comprise subsets of items that measure different facets of a 
</p>
<p>multidimensional construct. For example, soccer fan satisfaction is a multidimensional construct 
</p>
<p>that includes aspects such as satisfaction with the stadium, the merchandise (as described 
</p>
<p>above), the team, and the coach. Each of these factors is measured using different sets of items, 
</p>
<p>whose consistency has to be evaluated separately. Calculating one Cronbach&rsquo;s Alpha over 99 
</p>
<p>items would certainly be inappropriate. Cronbach&rsquo;s Alpha is always calculated over the items 
</p>
<p>belonging to one construct and not all items in the dataset!
</p>
<p>same scale. Consequently, instead of looking at the scale&rsquo;s test-retest reliability, research-
ers consider the scale&rsquo;s equivalence, thus showing the extent to which two measures of the 
same general trait agree. We call this type of reliability the internal consistency reliability.
</p>
<p>In the example of satisfaction with the stadium, we compute this scale&rsquo;s split-half reli-
ability manually by, for example, splitting up the scale into x1 on the one side and x2 and 
x3 on the other. We then compute the sum of x2 and x3 (or calculate the items&rsquo; average) 
to form a total score and correlate this score with x1. A high correlation indicates that the 
two subsets of items measure related aspects of the same underlying construct and, thus, 
suggests a high degree of internal consistency. However, with many items, there are many 
different ways to split the variables into two groups.
</p>
<p>Cronbach (1951) proposed calculating the average of all possible split-half coefficients 
resulting from different ways of splitting the scale items. The Cronbach&rsquo;s Alpha coefficient 
has become by far the most popular measure of internal consistency. In the example above, 
this would comprise calculating the average of the correlations between (1) x1 and x2&nbsp;+&nbsp;x3, 
(2) x2 and x1&nbsp;+&nbsp;x3, as well as (3) x3 and x1&nbsp;+&nbsp;x2. The Cronbach&rsquo;s Alpha coefficient gener-
ally varies from 0 to 1, whereas a generally agreed lower limit for the coefficient is 0.70. 
However, in exploratory studies, a value of 0.60 is acceptable, while values of 0.80 or higher 
are regarded as satisfactory in the more advanced stages of research (Hair et al. 2011). In 
Box 8.2, we provide more advice on the use of Cronbach&rsquo;s Alpha. We will illustrate a reli-
ability analysis using the standard SPSS module in the example at the end of this chapter.
</p>
<p>8.5 Structural Equation Modeling
</p>
<p>Whereas a confirmatory factor analysis involves testing if and how items relate to specific 
constructs, structural equation modeling involves the estimation of relations between these 
constructs. It has become one of the most important methods in social sciences, includ-
ing marketing research.
</p>
<p>There are broadly two approaches to structural equation modeling: Covariance-based 
structural equation modeling (e.g., J&ouml;reskog 1971) and partial least squares structural equa-
tion modeling (e.g., Wold 1982), simply referred to as CB-SEM and PLS-SEM. Both estima-
tion methods are based on the idea of an underlying model that allows the researcher to 
test relationships between multiple items and constructs.
</p>
<p>8</p>
<p/>
</div>
<div class="page"><p/>
<p>8281
8.5 &middot; Structural Equation Modeling
</p>
<p>. Figure 8.8 shows an example path diagram with four constructs (represented by circles 
or ovals) and their respective items (represented by boxes).6 A path model incorporates 
two types of constructs: (1) exogenous constructs (here, satisfaction with the stadium (Y1) 
and satisfaction with the merchandise (Y2)) that do not depend on other constructs, and 
(2) endogenous constructs (here, overall satisfaction (Y3) and loyalty (Y4)) that depend on 
one or more exogenous (or other endogenous) constructs. The relations between the con-
structs (indicated with p) are called path coefficients, while the relations between the con-
structs and their respective items (indicated with l) are the item loadings. One can distin-
guish between the structural model that incorporates the relations between the constructs 
and the (exogenous and endogenous) measurement models that represent the relationships 
between the constructs and their related items. Items that measure constructs are labeled x.
</p>
<p>In the model in . Fig. 8.8, we assume that the two exogenous constructs satisfaction with 
the stadium and satisfaction with the merchandise relate to the endogenous construct overall 
satisfaction and that overall satisfaction relates to loyalty. Depending on the research question, 
we could of course incorporate additional exogenous and endogenous constructs. Using 
empirical data, we could then test this model and, thus, evaluate the relationships between 
all the constructs and between each construct and its items. We could, for example, assess 
which of the two constructs, Y1 or Y2, relates more strongly to Y3. The result helps us when 
developing marketing plans to increase overall satisfaction and, ultimately, loyalty.
</p>
<p>The evaluation of a path model analysis requires several steps that include the assess-
ment of both measurement models and the structural model. Diamantopoulos and Siguaw 
(2000) and Hair et al. (2019) provide thorough descriptions of the covariance-based struc-
tural equation modeling approach and its application. Hair et al. (2017a, 2018) provide a 
step-by-step introduction on how to set up and test path models using partial least squares 
structural equation modeling.
</p>
<p>6 Note that we omitted the error terms for clarity.
</p>
<p>x1 
</p>
<p>x2 
</p>
<p>x3 
</p>
<p>x4 
</p>
<p>x5 
</p>
<p>Satisfaction with  
the stadium (Y1) 
</p>
<p>Satisfaction with  
the merchandise (Y2) 
</p>
<p>x6 
</p>
<p>x7 
</p>
<p>x8 
</p>
<p>Overall satisfaction 
(Y3) 
</p>
<p>l1 
</p>
<p>l2 
</p>
<p>l3 
</p>
<p>l5 
</p>
<p>l4 
</p>
<p>l6 
</p>
<p>l7 
</p>
<p>l8 
</p>
<p>p11 
</p>
<p>p21 
</p>
<p>Structural  model 
</p>
<p>Measurement models of the exogenous constructs  Measurement models of the endogenous constructs  
</p>
<p>Loyalty (Y4)
</p>
<p>x9 
</p>
<p>x10 
</p>
<p>l9 
</p>
<p>l10 
</p>
<p>p34 
</p>
<p>. Fig. 8.8 Path diagram (structural equation modeling)</p>
<p/>
</div>
<div class="page"><p/>
<p>282 Chapter 8 &middot; Principal Component and Factor Analysis
</p>
<p>8.6 Example
</p>
<p>In this example, we take a closer look at some of the items from the Oddjob Airways dataset 
(⤓ Web Appendix &rarr; Downloads). This dataset contains eight items that relate to the cus-
tomers&rsquo; experience when flying with Oddjob Airways. For each of the following items, the 
respondents had to rate their degree of agreement from 1 (&ldquo;completely disagree&rdquo;) to 100 
(&ldquo;completely agree&rdquo;). The variable names are included below:
</p>
<p> 4 with Oddjob Airways you will arrive on time (s1),
 4 the entire journey with Oddjob Airways will occur as booked (s2),
 4 in case something does not work out as planned, Oddjob Airways will find a good 
</p>
<p>solution (s3),
 4 the flight schedules of Oddjob Airways are reliable (s4),
 4 Oddjob Airways provides you with a very pleasant travel experience (s5),
 4 Oddjob Airways&rsquo;s on board facilities are of high quality (s6),
 4 Oddjob Airways&rsquo;s cabin seats are comfortable (s7), and
 4 Oddjob Airways offers a comfortable on-board experience (s8).
</p>
<p>Our aim is to reduce the complexity of this item set by extracting several factors. Hence, 
we use these items to run a PCA.
</p>
<p>8.6.1 Principal Component Analysis
</p>
<p>8.6.1.1 Check Requirements and Conduct Preliminary Analyses
Before initiating the analysis, we need to check the assumptions of PCA and carry out 
preliminary analyses. We find that all eight variables are interval scaled from 1 (&ldquo;very 
unsatisfied&rdquo;) to 100 (&ldquo;very satisfied&rdquo;), therefore meeting the requirements in terms of the 
measurement scale.
</p>
<p>Determining whether the variables are sufficiently correlated is part of the PCA. To 
initiate the analysis, go to ► Analyze ► Dimension Reduction ► Factor. In the dialog box 
that opens (. Fig. 8.9), enter all eight variables into the Variables box.
</p>
<p>Next, click on Descriptives (. Fig. 8.10) and check the boxes next to Coefficients, Sig-
nificance levels, Anti-image, and KMO and Bartlett&rsquo;s test of sphericity. Also make sure to 
select Reproduced, which requests the reproduced correlation matrix that we will use 
for assessing the goodness-of-fit of the factor solution. Finally, select Initial solution and 
Univariate descriptives in the upper part of the dialog box to display useful summary 
statistics of your data. All other options are of minor importance, so skip these and click 
Continue.
</p>
<p>Now click on Extraction (. Fig. 8.11) and choose Principal components in the Method 
drop-down menu. Under Extract, you can determine the rule for factor extraction. The 
default option in SPSS is the Kaiser criterion as indicated by the option Eigenvalues greater 
than 1. In case you have prior information regarding the number of factors to extract, select 
Fixed number of factors and specify the corresponding number next to Factors to extract. 
Finally, under Display, make sure to select Unrotated factor solution and Scree plot. Click 
on Continue.
</p>
<p>8</p>
<p/>
</div>
<div class="page"><p/>
<p>8283
8.6 &middot; Example
</p>
<p>Under Rotation, you can choose between several orthogonal and oblique rotation 
methods. Select the Varimax procedure and click on Continue. Finally, under Options, you 
can decide how missing values should be handled and specify the display format of the 
coefficients in the component matrix. Select Exclude cases listwise to eliminate observations 
that have missing values in any of the variables used in any of the analyses. Avoid replacing 
missing values with the mean as this will diminish the variation in the data, especially if 
there are many missing values in your dataset. You should always check the option Sorted 
by size under Coefficient Display Format, as this greatly increases the clarity of the display 
of results. If you wish, you can suppress low loadings of say less than 0.20 by selecting the 
option Suppress small coefficients. Particularly when analyzing many items, this option 
makes the output much easier to interpret. After having specified all the options, you can 
initiate the analysis by clicking on Continue, followed by OK.
</p>
<p>. Fig. 8.9 Factor analysis dialog box
</p>
<p>. Fig. 8.10 Descriptives option 
(factor analysis)</p>
<p/>
</div>
<div class="page"><p/>
<p>284 Chapter 8 &middot; Principal Component and Factor Analysis
</p>
<p>The descriptive statistics in . Table 8.4 reveal that there are several observations with 
missing values in the dataset. However, with 921 valid observations, the sample size 
requirements are clearly met, even if the analysis produces very low communality values.
</p>
<p>The correlation matrix in the upper part of . Table 8.5 indicates that there are several 
pairs of highly correlated variables. The values in the diagonal are all 1.000, which is logical, 
as this is the correlation between a variable and itself! The off-diagonal cells correspond 
to the pairwise correlations. For example, the pairwise correlation between s1 and s2 is 
.754. The corresponding value in the lower part of . Table 8.5 shows that all correlations 
are significant (.000). As an absolute minimum standard, we need at least one correlation 
in the off-diagonal cells to be significant and we clearly meet this minimum.The correla-
tion matrix in . Table 8.5 also shows that there are several pairs of highly correlated vari-
ables. For example, not only s1 is highly correlated with s2 (correlation&nbsp;=&nbsp;.754), but also s3 
is highly correlated with s1 (correlation&nbsp;=&nbsp;.622), just like s4 (correlation&nbsp;=&nbsp;.733). As these 
variables&rsquo; correlations with the remaining correlations is much lower, it is likely that these 
four variables form one factor. As you can see from the correlation matrix, we can already 
identify a likely factor structure.
</p>
<p>The results in . Table 8.6 indicate a KMO value of .907, which is &ldquo;marvelous&rdquo;  
(. Table 8.2). Correspondingly, all MSA values shown on the diagonal in the lower part of 
the Anti-image Matrices output (. Table 8.7) are high. For example, s1 has an MSA value 
of .914. Not surprisingly the Bartlett&rsquo;s test shown in . Table 8.6 is significant (Sig.&nbsp;=&nbsp;.000), 
which means that we can reject the null hypothesis of uncorrelated variables. Summariz-
ing these results, we conclude that the data are appropriate for PCA. Hence, we can con-
tinue with the interpretation of the PCA.
</p>
<p>. Fig. 8.11 Extraction option (factor analysis)8</p>
<p/>
</div>
<div class="page"><p/>
<p>8285
8.6 &middot; Example
</p>
<p>. Table 8.4 Descriptive statistics
</p>
<p>Descriptive Statistics
</p>
<p>Mean Std. Deviation Analysis N
</p>
<p>s1 60.36 26.300 921
</p>
<p>s2 59.34 25.963 921
</p>
<p>s3 55.83 25.150 921
</p>
<p>s4 56.89 27.808 921
</p>
<p>s5 56.48 22.269 921
</p>
<p>s6 56.10 22.070 921
</p>
<p>s7 51.60 24.568 921
</p>
<p>s8 57.08 21.286 921
</p>
<p>. Table 8.5 Correlation matrix
</p>
<p>Correlation Matrix
</p>
<p>s1 s2 s3 s4 s5 s6 s7 s8
</p>
<p>Correlation s1 1.000 .754 .622 .733 .525 .500 .455 .542
</p>
<p>s2 .754 1.000 .697 .771 .536 .493 .453 .535
</p>
<p>s3 .622 .697 1.000 .648 .550 .492 .452 .553
</p>
<p>s4 .733 .771 .648 1.000 .484 .436 .367 .487
</p>
<p>s5 .525 .536 .550 .484 1.000 .818 .788 .811
</p>
<p>s6 .500 .493 .492 .436 .818 1.000 .832 .842
</p>
<p>s7 .455 .453 .452 .367 .788 .832 1.000 .780
</p>
<p>s8 .542 .535 .553 .487 .811 .842 .780 1.000
</p>
<p>Sig. 
</p>
<p>(1-tailed)
</p>
<p>s1 .000 .000 .000 .000 .000 .000 .000
</p>
<p>s2 .000 .000 .000 .000 .000 .000 .000
</p>
<p>s3 .000 .000 .000 .000 .000 .000 .000
</p>
<p>s4 .000 .000 .000 .000 .000 .000 .000
</p>
<p>s5 .000 .000 .000 .000 .000 .000 .000
</p>
<p>s6 .000 .000 .000 .000 .000 .000 .000
</p>
<p>s7 .000 .000 .000 .000 .000 .000 .000
</p>
<p>s8 .000 .000 .000 .000 .000 .000 .000</p>
<p/>
</div>
<div class="page"><p/>
<p>286 Chapter 8 &middot; Principal Component and Factor Analysis
</p>
<p>. Table 8.6 KMO and Bartlett&rsquo;s test statistics
</p>
<p>KMO and Bartlett's Test
</p>
<p>Kaiser-Meyer-Olkin Measure of Sampling Adequacy. .907
</p>
<p>Bartlett's Test of Sphericity Approx. Chi-Square 6421.354
</p>
<p>df 28
</p>
<p>Sig. .000
</p>
<p>8.6.1.2 Extract the Factors and Determine the Number of Factors
. Table 8.8 lists the eigenvalues associated with each factor before extraction, after 
extraction, and after rotation. In the columns labeled Initial Eigenvalues, we see the results 
before extraction. SPSS lists all eight factors (we know that there are potentially as many 
factors as there are variables) in this column. Most of these factors are only of minor 
importance. This is reflected in each factor&rsquo;s eigenvalue, which is displayed in the table&rsquo;s 
second column. Here, we see that the first factor has an eigenvalue of 5.249. As there are 
eight variables in our dataset, this factor accounts for 5.249/8.00&nbsp;=&nbsp;65.611&nbsp;% of the overall 
variance, as indicated in the third column. It is quite remarkable that by using only one 
factor instead of eight variables, we can account for over 65&nbsp;% of the overall variance! The 
second factor has an eigenvalue of 1.328 and, thus, still covers more variance than a single 
variable. In contrast, factors 3&ndash;8 only marginally account for the total variance explained, 
as their eigenvalues are considerably smaller than 1.
</p>
<p>The second set of columns, labeled Extraction Sums of Squared Loadings, contains the 
factor solutions after extraction. Since we chose the Kaiser criterion as default option, SPSS 
extracts all factors with an eigenvalue greater than 1. As a consequence, SPSS extracts two 
factors, which jointly account for 82.215&nbsp;% of the overall variance. The final part of the 
table, labeled Rotation Sums of Squared Loadings, displays the factors after rotation. The 
rotation typically changes the factors&rsquo; eigenvalues, but not the total variance explained. For 
example, before rotation, the second factor accounted for 16.604&nbsp;% of the overall variance 
but after rotation, it accounts for 39.582&nbsp;%.
</p>
<p>Looking at the scree plot in . Fig. 8.12, we find an &ldquo;elbow&rdquo; in the line at three factors. 
As the number of factors that the scree plot suggests is one factor less than the elbow indi-
cates, we conclude that two factors are appropriate. This finding therefore supports the 
conclusion as the Kaiser criterion.
</p>
<p>While the Kaiser criterion and the scree plot are helpful for determining the number 
of factors to extract, parallel analysis is a more robust criterion. Parallel analysis can only 
be run using SPSS syntax. To do so, go to the book&rsquo;s ⤓ Web Appendix (&rarr; Downloads) and 
download the syntax file Parallel analysis.sps (O&rsquo;Connor 2000). Next, go to ► File ► Open 
►Syntax, locate the syntax file on your hard drive and open it. SPSS will now show the 
syntax editor as in . Fig. 8.13.
</p>
<p>Under compute Ncases in line 10, you need to specify the number of observations, 
which is 921 in our case study. Similarly, under compute NVars (line 11), specify the number 
</p>
<p>8</p>
<p/>
</div>
<div class="page"><p/>
<p>8287
8.6 &middot; Example
</p>
<p>.
 T
</p>
<p>ab
le
</p>
<p> 8
.7
</p>
<p> A
n
</p>
<p>ti
-i
</p>
<p>m
a
</p>
<p>g
e
</p>
<p> m
a
</p>
<p>tr
ic
</p>
<p>e
s
</p>
<p>A
n
</p>
<p>ti
-i
</p>
<p>m
ag
</p>
<p>e 
M
</p>
<p>at
ri
</p>
<p>ce
s
</p>
<p>s1
s2
</p>
<p>s3
s4
</p>
<p>s5
s6
</p>
<p>s7
s8
</p>
<p>A
n
</p>
<p>ti
-i
</p>
<p>m
a
</p>
<p>g
e
</p>
<p> C
o
</p>
<p>va
ri
</p>
<p>a
n
</p>
<p>ce
s1
</p>
<p>.3
5
</p>
<p>4
&minus;
</p>
<p>.1
0
</p>
<p>7
&minus;
</p>
<p>.0
2
</p>
<p>9
&minus;
</p>
<p>.1
1
</p>
<p>2
&minus;
</p>
<p>8
.9
</p>
<p>4
6
</p>
<p>E
&minus;
</p>
<p>5
&minus;
</p>
<p>.0
0
</p>
<p>7
&minus;
</p>
<p>.0
1
</p>
<p>1
&minus;
</p>
<p>.0
1
</p>
<p>9
</p>
<p>s2
&minus;
</p>
<p>.1
0
</p>
<p>7
.2
</p>
<p>8
9
</p>
<p>&minus;
.1
</p>
<p>0
2
</p>
<p>&minus;
.1
</p>
<p>2
2
</p>
<p>&minus;
.0
</p>
<p>0
9
</p>
<p>&minus;
.0
</p>
<p>0
1
</p>
<p>&minus;
.0
</p>
<p>1
3
</p>
<p>.0
0
</p>
<p>2
</p>
<p>s3
&minus;
</p>
<p>.0
2
</p>
<p>9
&minus;
</p>
<p>.1
0
</p>
<p>2
.4
</p>
<p>4
0
</p>
<p>&minus;
.0
</p>
<p>6
6
</p>
<p>&minus;
.0
</p>
<p>3
6
</p>
<p>.0
1
</p>
<p>0
.0
</p>
<p>0
4
</p>
<p>&minus;
.0
</p>
<p>3
6
</p>
<p>s4
&minus;
</p>
<p>.1
1
</p>
<p>2
&minus;
</p>
<p>.1
2
</p>
<p>2
&minus;
</p>
<p>.0
6
</p>
<p>6
.3
</p>
<p>3
4
</p>
<p>&minus;
.0
</p>
<p>1
6
</p>
<p>&minus;
.0
</p>
<p>0
4
</p>
<p>.0
3
</p>
<p>7
&minus;
</p>
<p>.0
1
</p>
<p>1
</p>
<p>s5
&minus;
</p>
<p>8
.9
</p>
<p>4
6
</p>
<p>E
&minus;
</p>
<p>5
&minus;
</p>
<p>.0
0
</p>
<p>9
&minus;
</p>
<p>.0
3
</p>
<p>6
&minus;
</p>
<p>.0
1
</p>
<p>6
.2
</p>
<p>4
7
</p>
<p>&minus;
.0
</p>
<p>5
7
</p>
<p>&minus;
.0
</p>
<p>6
8
</p>
<p>&minus;
.0
</p>
<p>6
3
</p>
<p>s6
&minus;
</p>
<p>.0
0
</p>
<p>7
&minus;
</p>
<p>.0
0
</p>
<p>1
.0
</p>
<p>1
0
</p>
<p>&minus;
.0
</p>
<p>0
4
</p>
<p>&minus;
.0
</p>
<p>5
7
</p>
<p>.1
9
</p>
<p>7
&minus;
</p>
<p>.0
9
</p>
<p>3
&minus;
</p>
<p>.0
8
</p>
<p>5
</p>
<p>s7
&minus;
</p>
<p>.0
1
</p>
<p>1
&minus;
</p>
<p>.0
1
</p>
<p>3
.0
</p>
<p>0
4
</p>
<p>.0
3
</p>
<p>7
&minus;
</p>
<p>.0
6
</p>
<p>8
&minus;
</p>
<p>.0
9
</p>
<p>3
.2
</p>
<p>6
2
</p>
<p>&minus;
.0
</p>
<p>4
0
</p>
<p>s8
&minus;
</p>
<p>.0
1
</p>
<p>9
.0
</p>
<p>0
2
</p>
<p>&minus;
.0
</p>
<p>3
6
</p>
<p>&minus;
.0
</p>
<p>1
1
</p>
<p>&minus;
.0
</p>
<p>6
3
</p>
<p>&minus;
.0
</p>
<p>8
5
</p>
<p>&minus;
.0
</p>
<p>4
0
</p>
<p>.2
2
</p>
<p>6
</p>
<p>A
n
</p>
<p>ti
-i
</p>
<p>m
a
</p>
<p>g
e
</p>
<p> C
o
</p>
<p>rr
e
</p>
<p>la
ti
</p>
<p>o
n
</p>
<p>s1
.9
</p>
<p>1
7
</p>
<p>a
&minus;
</p>
<p>.3
3
</p>
<p>4
&minus;
</p>
<p>.0
7
</p>
<p>2
&minus;
</p>
<p>.3
2
</p>
<p>5
.0
</p>
<p>0
0
</p>
<p>&minus;
.0
</p>
<p>2
5
</p>
<p>&minus;
.0
</p>
<p>3
5
</p>
<p>&minus;
.0
</p>
<p>6
8
</p>
<p>s2
&minus;
</p>
<p>.3
3
</p>
<p>4
.8
</p>
<p>8
4
</p>
<p>a
&minus;
</p>
<p>.2
8
</p>
<p>5
&minus;
</p>
<p>.3
9
</p>
<p>3
&minus;
</p>
<p>.0
3
</p>
<p>4
&minus;
</p>
<p>.0
0
</p>
<p>3
&minus;
</p>
<p>.0
4
</p>
<p>9
.0
</p>
<p>0
6
</p>
<p>s3
&minus;
</p>
<p>.0
7
</p>
<p>2
&minus;
</p>
<p>.2
8
</p>
<p>5
.9
</p>
<p>4
3
</p>
<p>a
&minus;
</p>
<p>.1
7
</p>
<p>1
&minus;
</p>
<p>.1
1
</p>
<p>1
.0
</p>
<p>3
4
</p>
<p>.0
1
</p>
<p>1
&minus;
</p>
<p>.1
1
</p>
<p>5
</p>
<p>s4
&minus;
</p>
<p>.3
2
</p>
<p>5
&minus;
</p>
<p>.3
9
</p>
<p>3
&minus;
</p>
<p>.1
7
</p>
<p>1
.8
</p>
<p>8
3
</p>
<p>a
&minus;
</p>
<p>.0
5
</p>
<p>7
&minus;
</p>
<p>.0
1
</p>
<p>4
.1
</p>
<p>2
5
</p>
<p>&minus;
.0
</p>
<p>3
9
</p>
<p>s5
.0
</p>
<p>0
0
</p>
<p>&minus;
.0
</p>
<p>3
4
</p>
<p>&minus;
.1
</p>
<p>1
1
</p>
<p>&minus;
.0
</p>
<p>5
7
</p>
<p>.9
3
</p>
<p>1
a
</p>
<p>&minus;
.2
</p>
<p>5
9
</p>
<p>&minus;
.2
</p>
<p>6
9
</p>
<p>&minus;
.2
</p>
<p>6
5
</p>
<p>s6
&minus;
</p>
<p>.0
2
</p>
<p>5
&minus;
</p>
<p>.0
0
</p>
<p>3
.0
</p>
<p>3
4
</p>
<p>&minus;
.0
</p>
<p>1
4
</p>
<p>&minus;
.2
</p>
<p>5
9
</p>
<p>.8
8
</p>
<p>3
a
</p>
<p>&minus;
.4
</p>
<p>0
8
</p>
<p>&minus;
.4
</p>
<p>0
0
</p>
<p>s7
&minus;
</p>
<p>.0
3
</p>
<p>5
&minus;
</p>
<p>.0
4
</p>
<p>9
.0
</p>
<p>1
1
</p>
<p>.1
2
</p>
<p>5
&minus;
</p>
<p>.2
6
</p>
<p>9
&minus;
</p>
<p>.4
0
</p>
<p>8
.9
</p>
<p>0
4
</p>
<p>a
&minus;
</p>
<p>.1
6
</p>
<p>4
</p>
<p>s8
&minus;
</p>
<p>.0
6
</p>
<p>8
.0
</p>
<p>0
6
</p>
<p>&minus;
.1
</p>
<p>1
5
</p>
<p>&minus;
.0
</p>
<p>3
9
</p>
<p>&minus;
.2
</p>
<p>6
5
</p>
<p>&minus;
.4
</p>
<p>0
0
</p>
<p>&minus;
.1
</p>
<p>6
4
</p>
<p>.9
1
</p>
<p>8
a
</p>
<p>a
 M
</p>
<p>e
a
</p>
<p>su
re
</p>
<p>s 
o
</p>
<p>f 
S
</p>
<p>a
m
</p>
<p>p
lin
</p>
<p>g
 A
</p>
<p>d
e
</p>
<p>q
u
</p>
<p>a
cy
</p>
<p>(M
S
</p>
<p>A
)</p>
<p/>
</div>
<div class="page"><p/>
<p>288 Chapter 8 &middot; Principal Component and Factor Analysis
</p>
<p>.
 T
</p>
<p>ab
le
</p>
<p> 8
.8
</p>
<p> F
a
</p>
<p>ct
o
</p>
<p>r 
e
</p>
<p>xt
ra
</p>
<p>ct
io
</p>
<p>n
</p>
<p>To
ta
</p>
<p>l V
ar
</p>
<p>ia
n
</p>
<p>ce
 E
</p>
<p>xp
la
</p>
<p>in
ed
</p>
<p>C
o
</p>
<p>m
p
</p>
<p>o
n
</p>
<p>e
n
</p>
<p>t
</p>
<p>In
it
</p>
<p>ia
l E
</p>
<p>ig
e
</p>
<p>n
va
</p>
<p>lu
e
</p>
<p>s
E
</p>
<p>xt
ra
</p>
<p>ct
io
</p>
<p>n
 S
</p>
<p>u
m
</p>
<p>s 
o
</p>
<p>f 
S
</p>
<p>q
u
</p>
<p>a
re
</p>
<p>d
 L
</p>
<p>o
a
</p>
<p>d
in
</p>
<p>g
s
</p>
<p>R
o
</p>
<p>ta
ti
</p>
<p>o
n
</p>
<p> S
u
</p>
<p>m
s 
</p>
<p>o
f 
</p>
<p>S
q
</p>
<p>u
a
</p>
<p>re
d
</p>
<p> L
o
</p>
<p>a
d
</p>
<p>in
g
</p>
<p>s
</p>
<p>To
ta
</p>
<p>l
%
</p>
<p> o
f V
</p>
<p>a
ri
</p>
<p>a
n
</p>
<p>ce
C
</p>
<p>u
m
</p>
<p>u
la
</p>
<p>ti
ve
</p>
<p> %
To
</p>
<p>ta
l
</p>
<p>%
 o
</p>
<p>f V
a
</p>
<p>ri
a
</p>
<p>n
ce
</p>
<p>C
u
</p>
<p>m
u
</p>
<p>la
ti
</p>
<p>ve
 %
</p>
<p>To
ta
</p>
<p>l
%
</p>
<p> o
f V
</p>
<p>a
ri
</p>
<p>a
n
</p>
<p>ce
C
</p>
<p>u
m
</p>
<p>u
la
</p>
<p>ti
ve
</p>
<p> %
</p>
<p>1
5
</p>
<p>.2
4
</p>
<p>9
6
</p>
<p>5
.6
</p>
<p>1
1
</p>
<p>6
5
</p>
<p>.6
1
</p>
<p>1
5
</p>
<p>.2
4
</p>
<p>9
6
</p>
<p>5
.6
</p>
<p>1
1
</p>
<p>6
5
</p>
<p>.6
1
</p>
<p>1
3
</p>
<p>.4
1
</p>
<p>1
4
</p>
<p>2
.6
</p>
<p>3
3
</p>
<p>4
2
</p>
<p>.6
3
</p>
<p>3
</p>
<p>2
1
</p>
<p>.3
2
</p>
<p>8
1
</p>
<p>6
.6
</p>
<p>0
4
</p>
<p>8
2
</p>
<p>.2
1
</p>
<p>5
1
</p>
<p>.3
2
</p>
<p>8
1
</p>
<p>6
.6
</p>
<p>0
4
</p>
<p>8
2
</p>
<p>.2
1
</p>
<p>5
3
</p>
<p>.1
6
</p>
<p>7
3
</p>
<p>9
.5
</p>
<p>8
2
</p>
<p>8
2
</p>
<p>.2
1
</p>
<p>5
</p>
<p>3
.3
</p>
<p>9
7
</p>
<p>4
.9
</p>
<p>6
6
</p>
<p>8
7
</p>
<p>.1
8
</p>
<p>1
</p>
<p>4
.2
</p>
<p>6
3
</p>
<p>3
.2
</p>
<p>9
0
</p>
<p>9
0
</p>
<p>.4
7
</p>
<p>1
</p>
<p>5
.2
</p>
<p>3
1
</p>
<p>2
.8
</p>
<p>9
0
</p>
<p>9
3
</p>
<p>.3
6
</p>
<p>1
</p>
<p>6
.1
</p>
<p>9
6
</p>
<p>2
.4
</p>
<p>5
4
</p>
<p>9
5
</p>
<p>.8
1
</p>
<p>5
</p>
<p>7
.1
</p>
<p>9
3
</p>
<p>2
.4
</p>
<p>0
9
</p>
<p>9
8
</p>
<p>.2
2
</p>
<p>4
</p>
<p>8
.1
</p>
<p>4
2
</p>
<p>1
.7
</p>
<p>7
6
</p>
<p>1
0
</p>
<p>0
.0
</p>
<p>0
0
</p>
<p>E
xt
</p>
<p>ra
ct
</p>
<p>io
n
</p>
<p> M
e
</p>
<p>th
o
</p>
<p>d
: P
</p>
<p>ri
n
</p>
<p>ci
p
</p>
<p>a
l C
</p>
<p>o
m
</p>
<p>p
o
</p>
<p>n
e
</p>
<p>n
t 
</p>
<p>A
n
</p>
<p>a
ly
</p>
<p>si
s.
</p>
<p>8</p>
<p/>
</div>
<div class="page"><p/>
<p>8289
8.6 &middot; Example
</p>
<p>. Fig. 8.13 Syntax editor
</p>
<p>Component Number
</p>
<p>E
ig
</p>
<p>e
n
</p>
<p>v
a
</p>
<p>lu
e
</p>
<p>0
</p>
<p>4
</p>
<p>2
</p>
<p>1
</p>
<p>3
</p>
<p>1 2 3 4 5 6 7 8
</p>
<p>Scree Plot
</p>
<p>Elbow
</p>
<p>. Fig. 8.12 Scree plot</p>
<p/>
</div>
<div class="page"><p/>
<p>290 Chapter 8 &middot; Principal Component and Factor Analysis
</p>
<p>. Fig. 8.14 Parallel analysis output
</p>
<p>of variables used in the analysis, which is 8. Next, initiate the analysis by going to ► Run  
► All and SPSS will show an output similar to . Fig. 8.14.
</p>
<p>The column labeled Prcntyle shows the 95th percentile for each factor&rsquo;s eigenvalue 
resulting from the randomly generated data. Note that because of this random process, 
your numbers are going to look different. However, deviations typically occur at the third 
decimal place. We can now compare the original eigenvalues from . Table 8.8 with the ran-
domly generated eigenvalues from . Fig. 8.14. We learn that the first two factors produce 
eigenvalues larger than the randomly generated eigenvalues. Whereas the first original 
Eigenvalue is clearly higher (5.249; . Table 8.7) than the randomly generated one (1.185; 
. Fig. 8.14), the difference is much less pronounced for the second factor (1.328 vs. 1.122). 
The third factor&rsquo;s original eigenvalue (.397) is clearly lower than its randomly generated 
counterpart (1.076). Hence, based on the parallel analysis results, we would also opt for 
a two-factor solution.
</p>
<p>8.6.1.3 Interpret the Factor Solution
</p>
<p>We continue with the interpretation of the factors. To do so, take a look at the Rotated Com-
ponent Matrix (. Table 8.9), which shows the item loadings after rotation. To interpret the 
factors, we first &ldquo;assign&rdquo; each variable to a certain factor based on its maximum absolute 
factor loading. That is, if the highest absolute loading is negative, higher values of a par-
ticular variable relate negatively to the assigned factor. After that, we should find a label 
for each factor that best describes the set of variables associated with that factor. Looking 
at . Table 8.9, we see that s1&ndash;s4 load highly on the second factor, whereas s5&ndash;s8 load on 
the first factor. For example, s1 has a .829 loading on the second factor, while its loading is 
much weaker on the first factor (.299). If you compare these results with the regular Com-
ponent Matrix, you will see that prior to rotation, all items load highly on the first factor 
and much weaker on the second.
</p>
<p>Having identified which variables load highly on which factor in the rotated solution, 
we now need to identify labels for each factor. Looking at the variable labels, we learn 
</p>
<p>8</p>
<p/>
</div>
<div class="page"><p/>
<p>8291
8.6 &middot; Example
</p>
<p>that the first set of variables (s1&ndash;s4) relate to reliability aspects of the journey and related 
processes, such as the booking. We could therefore label this factor (i.e., factor 2) reli-
ability. The second set of variables (s5&ndash;s8) relate to different aspects of the onboard facil-
ities and the travel experience. Hence, we could label this factor (i.e., factor 1) onboard 
experience. The labeling of factors is subjective and you could provide different labels.
</p>
<p>8.6.1.4 Evaluate the Goodness-of-Fit of the Factor Solution
</p>
<p>The last step involves assessing the analysis&rsquo;s goodness-of-fit. To do so, we first look at the 
residuals (i.e., the differences between observed and reproduced correlations) in the repro-
duced correlation matrix (. Table 8.10). Examining the lower part of the table, we see that 
there are several residuals with absolute values larger than 0.05. However, we do not have 
to count every single value in the matrix (this could be quite exhausting if there are over 
100&nbsp;variables in the dataset!). Instead, SPSS counts the proportion of residuals with high 
residuals, which is reported in the first part of the table. As we can see in point b beneath 
the table, 28.0&nbsp;% of the residuals have absolute values greater than 0.05. As the percentage 
of increased residuals is well below 50&nbsp;%, we can presume a good model fit.
</p>
<p>This result is supported by the variables&rsquo; communalities and the total variance explained. 
All communalities in . Table 8.11 are very high, indicating that the factors reproduce the 
variables&rsquo; variance well. For example, with a value of .763, s1 has a communality value clearly 
above the 0.50 threshold, suggesting that the two factors account for 76.3&nbsp;% of this variable&rsquo;s 
variation. Finally, the two factors explain over 80&nbsp;% of each variable&rsquo;s variance (.&nbsp;Table 8.8). 
Jointly these results provide support for the solution&rsquo;s goodness-of-fit.
</p>
<p>&gt; In case the analysis indicates a poor goodness-of-fit, you should reconsider the 
set-up by eliminating items that have low communalities and MSA values.
</p>
<p>. Table 8.9 Rotated component matrix
</p>
<p>Rotated Component Matrixa
</p>
<p>Component
</p>
<p>1 2
</p>
<p>s6 .903 .272
</p>
<p>s7 .902 .208
</p>
<p>s8 .856 .352
</p>
<p>s5 .852 .347
</p>
<p>s4 .198 .885
</p>
<p>s2 .282 .871
</p>
<p>s1 .299 .829
</p>
<p>s3 .340 .759
</p>
<p>Extraction Method: Principal Component Analysis.
</p>
<p>Rotation Method: Varimax with Kaiser Normalization.
a Rotation converged in 3 iterations.</p>
<p/>
</div>
<div class="page"><p/>
<p>292 Chapter 8 &middot; Principal Component and Factor Analysis
</p>
<p>.
 T
</p>
<p>ab
le
</p>
<p> 8
.1
</p>
<p>0
 R
</p>
<p>e
p
</p>
<p>ro
d
</p>
<p>u
ce
</p>
<p>d
 c
</p>
<p>o
rr
</p>
<p>e
la
</p>
<p>ti
o
</p>
<p>n
s 
</p>
<p>a
n
</p>
<p>d
 r
</p>
<p>e
si
</p>
<p>d
u
</p>
<p>a
l m
</p>
<p>at
ri
</p>
<p>ce
s
</p>
<p>R
ep
</p>
<p>ro
d
</p>
<p>u
ce
</p>
<p>d
 C
</p>
<p>o
rr
</p>
<p>el
at
</p>
<p>io
n
</p>
<p>s
</p>
<p>s1
s2
</p>
<p>s3
s4
</p>
<p>s5
s6
</p>
<p>s7
s8
</p>
<p>R
e
</p>
<p>p
ro
</p>
<p>d
u
</p>
<p>ce
d
</p>
<p> C
o
</p>
<p>rr
e
</p>
<p>la
ti
</p>
<p>o
n
</p>
<p>s1
.7
</p>
<p>7
7
</p>
<p>a
.8
</p>
<p>0
6
</p>
<p>.7
3
</p>
<p>1
.7
</p>
<p>9
3
</p>
<p>.5
4
</p>
<p>2
.4
</p>
<p>9
5
</p>
<p>.4
4
</p>
<p>2
.5
</p>
<p>4
8
</p>
<p>s2
.8
</p>
<p>0
6
</p>
<p>.8
3
</p>
<p>8
a
</p>
<p>.7
5
</p>
<p>7
.8
</p>
<p>2
7
</p>
<p>.5
4
</p>
<p>2
.4
</p>
<p>9
1
</p>
<p>.4
3
</p>
<p>5
.5
</p>
<p>4
8
</p>
<p>s3
.7
</p>
<p>3
1
</p>
<p>.7
5
</p>
<p>7
.6
</p>
<p>9
1
</p>
<p>a
.7
</p>
<p>3
9
</p>
<p>.5
5
</p>
<p>3
.5
</p>
<p>1
3
</p>
<p>.4
6
</p>
<p>4
.5
</p>
<p>5
8
</p>
<p>s4
.7
</p>
<p>9
3
</p>
<p>.8
2
</p>
<p>7
.7
</p>
<p>3
9
</p>
<p>.8
2
</p>
<p>2
a
</p>
<p>.4
7
</p>
<p>6
.4
</p>
<p>2
0
</p>
<p>.3
6
</p>
<p>3
.4
</p>
<p>8
2
</p>
<p>s5
.5
</p>
<p>4
2
</p>
<p>.5
4
</p>
<p>2
.5
</p>
<p>5
3
</p>
<p>.4
7
</p>
<p>6
.8
</p>
<p>4
7
</p>
<p>a
.8
</p>
<p>6
4
</p>
<p>.8
4
</p>
<p>0
.8
</p>
<p>5
2
</p>
<p>s6
.4
</p>
<p>9
5
</p>
<p>.4
9
</p>
<p>1
.5
</p>
<p>1
3
</p>
<p>.4
2
</p>
<p>0
.8
</p>
<p>6
4
</p>
<p>.8
9
</p>
<p>0
a
</p>
<p>.8
7
</p>
<p>1
.8
</p>
<p>6
9
</p>
<p>s7
.4
</p>
<p>4
2
</p>
<p>.4
3
</p>
<p>5
.4
</p>
<p>6
4
</p>
<p>.3
6
</p>
<p>3
.8
</p>
<p>4
0
</p>
<p>.8
7
</p>
<p>1
.8
</p>
<p>5
6
</p>
<p>a
.8
</p>
<p>4
5
</p>
<p>s8
.5
</p>
<p>4
8
</p>
<p>.5
4
</p>
<p>8
.5
</p>
<p>5
8
</p>
<p>.4
8
</p>
<p>2
.8
</p>
<p>5
2
</p>
<p>.8
6
</p>
<p>9
.8
</p>
<p>4
5
</p>
<p>.8
5
</p>
<p>6
a
</p>
<p>R
e
</p>
<p>si
d
</p>
<p>u
a
</p>
<p>lb
s1
</p>
<p>&minus;
.0
</p>
<p>5
3
</p>
<p>&minus;
.1
</p>
<p>0
9
</p>
<p>&minus;
.0
</p>
<p>6
0
</p>
<p>&minus;
.0
</p>
<p>1
7
</p>
<p>.0
0
</p>
<p>5
.0
</p>
<p>1
4
</p>
<p>&minus;
.0
</p>
<p>0
6
</p>
<p>s2
&minus;
</p>
<p>.0
5
</p>
<p>3
&minus;
</p>
<p>.0
6
</p>
<p>0
&minus;
</p>
<p>.0
5
</p>
<p>6
&minus;
</p>
<p>.0
0
</p>
<p>6
.0
</p>
<p>0
2
</p>
<p>.0
1
</p>
<p>8
&minus;
</p>
<p>.0
1
</p>
<p>3
</p>
<p>s3
&minus;
</p>
<p>.1
0
</p>
<p>9
&minus;
</p>
<p>.0
6
</p>
<p>0
&minus;
</p>
<p>.0
9
</p>
<p>1
&minus;
</p>
<p>.0
0
</p>
<p>3
&minus;
</p>
<p>.0
2
</p>
<p>2
&minus;
</p>
<p>.0
1
</p>
<p>2
&minus;
</p>
<p>.0
0
</p>
<p>6
</p>
<p>s4
&minus;
</p>
<p>.0
6
</p>
<p>0
&minus;
</p>
<p>.0
5
</p>
<p>6
&minus;
</p>
<p>.0
9
</p>
<p>1
.0
</p>
<p>0
8
</p>
<p>.0
1
</p>
<p>6
.0
</p>
<p>0
4
</p>
<p>.0
0
</p>
<p>5
</p>
<p>s5
&minus;
</p>
<p>.0
1
</p>
<p>7
&minus;
</p>
<p>.0
0
</p>
<p>6
&minus;
</p>
<p>.0
0
</p>
<p>3
.0
</p>
<p>0
8
</p>
<p>&minus;
.0
</p>
<p>4
6
</p>
<p>&minus;
.0
</p>
<p>5
3
</p>
<p>&minus;
.0
</p>
<p>4
0
</p>
<p>s6
.0
</p>
<p>0
5
</p>
<p>.0
0
</p>
<p>2
&minus;
</p>
<p>.0
2
</p>
<p>2
.0
</p>
<p>1
6
</p>
<p>&minus;
.0
</p>
<p>4
6
</p>
<p>&minus;
.0
</p>
<p>3
9
</p>
<p>&minus;
.0
</p>
<p>2
6
</p>
<p>s7
.0
</p>
<p>1
4
</p>
<p>.0
1
</p>
<p>8
&minus;
</p>
<p>.0
1
</p>
<p>2
.0
</p>
<p>0
4
</p>
<p>&minus;
.0
</p>
<p>5
3
</p>
<p>&minus;
.0
</p>
<p>3
9
</p>
<p>&minus;
.0
</p>
<p>6
5
</p>
<p>s8
&minus;
</p>
<p>.0
0
</p>
<p>6
&minus;
</p>
<p>.0
1
</p>
<p>3
&minus;
</p>
<p>.0
0
</p>
<p>6
.0
</p>
<p>0
5
</p>
<p>&minus;
.0
</p>
<p>4
0
</p>
<p>&minus;
.0
</p>
<p>2
6
</p>
<p>&minus;
.0
</p>
<p>6
5
</p>
<p>E
xt
</p>
<p>ra
ct
</p>
<p>io
n
</p>
<p> M
e
</p>
<p>th
o
</p>
<p>d
: P
</p>
<p>ri
n
</p>
<p>ci
p
</p>
<p>a
l C
</p>
<p>o
m
</p>
<p>p
o
</p>
<p>n
e
</p>
<p>n
t 
</p>
<p>A
n
</p>
<p>a
ly
</p>
<p>si
s.
</p>
<p>a
 R
</p>
<p>e
p
</p>
<p>ro
d
</p>
<p>u
ce
</p>
<p>d
 c
</p>
<p>o
m
</p>
<p>m
u
</p>
<p>n
a
</p>
<p>lit
ie
</p>
<p>s
b
</p>
<p> R
e
</p>
<p>si
d
</p>
<p>u
a
</p>
<p>ls
 a
</p>
<p>re
 c
</p>
<p>o
m
</p>
<p>p
u
</p>
<p>te
d
</p>
<p> b
e
</p>
<p>tw
e
</p>
<p>e
n
</p>
<p> o
b
</p>
<p>se
rv
</p>
<p>e
d
</p>
<p> a
n
</p>
<p>d
 r
</p>
<p>e
p
</p>
<p>ro
d
</p>
<p>u
ce
</p>
<p>d
 c
</p>
<p>o
rr
</p>
<p>e
la
</p>
<p>ti
o
</p>
<p>n
s.
</p>
<p> T
h
</p>
<p>e
re
</p>
<p> a
re
</p>
<p> 8
 (
</p>
<p>2
8
</p>
<p>.0
&nbsp;%
</p>
<p>) 
n
</p>
<p>o
n
</p>
<p>re
d
</p>
<p>u
n
</p>
<p>d
a
</p>
<p>n
t 
</p>
<p>re
si
</p>
<p>d
u
</p>
<p>a
ls
</p>
<p> w
it
</p>
<p>h
 a
</p>
<p>b
so
</p>
<p>lu
te
</p>
<p> v
a
</p>
<p>lu
e
</p>
<p>s 
g
</p>
<p>re
at
</p>
<p>e
r 
</p>
<p>th
a
</p>
<p>n
 0
</p>
<p>.0
5
</p>
<p>.
</p>
<p>8</p>
<p/>
</div>
<div class="page"><p/>
<p>8293
8.6 &middot; Example
</p>
<p>8.6.1.5 Compute the Factor Scores
If you wish to use factor scores in subsequent analyses, you can rerun the analysis by going 
to ► Analyze ► Dimension Reduction ► Factor and selecting the Scores option. Since we 
recommend using the regression method, choose Save as variables and Regression. When 
clicking on Continue and OK, SPSS creates two new variables labeled FAC1_1 and FAC2_1, 
which include the scores of the two factors (. Fig. 8.15). These are z-standardized, meaning 
that the newly generated variables have mean values of 0 and standard deviations of 1. This 
entails the factor scores are estimated in units of standard deviations from their means. 
For example, the first observation is about 1.911 standard deviations below average on the 
onboard experience factor (i.e., factor 1) and about 0.914 standard deviations above the reli-
ability factor (i.e., factor 2). In contrast, the second observation is clearly above average in 
terms of onboard experience (1.684) and reliability (1.297). Using these variables as input 
we could, for example, evaluate whether male and female customers differ significantly 
with regard to their satisfaction with the airline&rsquo;s reliability, and the onboard experience.
</p>
<p>. Table 8.11 Communalities
</p>
<p>Communalities
</p>
<p>Initial Extraction
</p>
<p>s1 1.000 .777
</p>
<p>s2 1.000 .838
</p>
<p>s3 1.000 .691
</p>
<p>s4 1.000 .822
</p>
<p>s5 1.000 .847
</p>
<p>s6 1.000 .890
</p>
<p>s7 1.000 .856
</p>
<p>s8 1.000 .856
</p>
<p>Extraction Method: Principal Component Analysis.
</p>
<p>!  SPSS can only calculate factor scores if it has information on all the variables 
included in the analysis. If SPSS does not have all the information, it only shows a &ldquo;.&rdquo; 
</p>
<p>(dot) in the data view window, indicating a system-missing value.
</p>
<p>8.6.2 Reliability Analysis
</p>
<p>To illustrate its usage, let&rsquo;s carry out a reliability analysis of the first factor onboard experi-
ence by calculating Cronbach&rsquo;s Alpha as a function of variables s5 to s8. To run the reliabil-
ity analysis, click on ► Analyze ► Scale ► Reliability Analysis. Next, enter variables s5, 
s6, s7, and s8 into the Items box (again, you may have to right-click on the items and select 
Display Variable Names to show the names instead of the variable labels) and type in the </p>
<p/>
</div>
<div class="page"><p/>
<p>294 Chapter 8 &middot; Principal Component and Factor Analysis
</p>
<p>. Fig. 8.15 SPSS data view window
</p>
<p>scale&rsquo;s name (e.g., satisfaction with the onboard experience). Make sure that Alpha is selected 
in the Model drop-down list (. Fig. 8.16).
</p>
<p>Next, click on Statistics and choose Scale if item deleted (. Fig 8.17). You can also 
request several descriptive statistics for each item (including correlations) and the entire 
scale. However, for the sake of simplicity, we will work with the default settings. Click on 
Continue, followed by OK.
</p>
<p>The results in . Table 8.12 show that the scale exhibits a high degree of internal consis-
tency reliability. With a value of .944, the Cronbach&rsquo;s Alpha coefficient lies well above the 
commonly suggested threshold of .70. This result is not surprising, since we are simply 
testing a scale previously established using item correlations. Keep in mind that we should 
</p>
<p>. Fig. 8.16 Reliability analysis dialog box
</p>
<p>8</p>
<p/>
</div>
<div class="page"><p/>
<p>8295
8.6 &middot; Example
</p>
<p>. Table 8.13 Item-total statistics
</p>
<p>Item-Total Statistics
</p>
<p>Scale Mean if Item 
</p>
<p>Deleted
</p>
<p>Scale Variance if 
</p>
<p>Item Deleted
</p>
<p>Corrected Item- 
</p>
<p>Total Correlation
</p>
<p>Cronbach's Alpha 
</p>
<p>if Item Deleted
</p>
<p>s5 165.53 4084.951 .861 .928
</p>
<p>s6 165.91 4045.200 .896 .917
</p>
<p>s7 170.42 3859.797 .852 .933
</p>
<p>s8 164.96 4215.151 .861 .929
</p>
<p>. Table 8.12 Reliability statistics
</p>
<p>Reliability Statistics
</p>
<p>Cronbach's Alpha No of Items
</p>
<p>.944 4
</p>
<p>. Fig. 8.17 Statistics option 
(reliability analysis)
</p>
<p>carry out a reliability analysis to test a scale using a different sample&mdash;this example is only 
for illustration purposes! The rightmost column of . Table 8.13 indicates what the Cron-
bach&rsquo;s Alpha would be if we deleted the item indicated in that row. When we compare 
each of the values with the overall Cronbach&rsquo;s Alpha value, we can see that any change in 
the scale&rsquo;s set-up would reduce the Cronbach&rsquo;s Alpha value. For example, by removing s5 
from the scale, the Cronbach&rsquo;s Alpha of the new scale comprising only s6, s7, and s8 would 
be reduced to .928. In the column labeled Corrected Item-Total Correlation of . Table 8.13, 
SPSS indicates the correlation between the item and the scale that is composed of other 
items. This information is useful for determining whether reverse-coded items were also 
identified as such. Reverse-coded items should have a minus sign.</p>
<p/>
</div>
<div class="page"><p/>
<p>296 Chapter 8 &middot; Principal Component and Factor Analysis
</p>
<p>8.7 Customer Satisfaction at Haver &amp; Boecker (Case Study)
</p>
<p>Case Study
</p>
<p>&copy; Haver &amp; Boecker OHG
</p>
<p>Haver &amp; Boecker (http://
</p>
<p>www.haverboecker.com) is 
</p>
<p>one of the world&rsquo;s leading 
</p>
<p>and most renowned 
</p>
<p>machine producers in the 
</p>
<p>fields of mineral processing, 
</p>
<p>as well as the storing, 
</p>
<p>conveying, packing, and 
</p>
<p>loading of bulk material. 
</p>
<p>The family-owned group 
</p>
<p>operates through its global 
</p>
<p>network of facilities, with 
</p>
<p>manufacturing units, among 
</p>
<p>others, in Germany, the UK, 
</p>
<p>Belgium, US, Canada, Brazil, 
</p>
<p>China, and India.
</p>
<p>The company&rsquo;s relationships 
</p>
<p>with its customers are 
</p>
<p>usually long-term oriented 
</p>
<p>and complex. Since the 
</p>
<p>company&rsquo;s philosophy 
</p>
<p>is to help customers and 
</p>
<p>business partners solve their 
</p>
<p>challenges or problems, 
</p>
<p>they often customize their 
</p>
<p>products and services to 
</p>
<p>meet the buyers&rsquo; needs. 
</p>
<p>Therefore, the customer 
</p>
<p>is not a passive buyer, but 
</p>
<p>an active partner. Given 
</p>
<p>this background, the 
</p>
<p>customers&rsquo; satisfaction 
</p>
<p>plays an important role in 
</p>
<p>establishing, developing, 
</p>
<p>and maintaining successful 
</p>
<p>customer relationships.
</p>
<p>Early on, the company&rsquo;s 
</p>
<p>management realized the 
</p>
<p>importance of customer 
</p>
<p>satisfaction and decided 
</p>
<p>to commission a market 
</p>
<p>research project in order to 
</p>
<p>identify marketing activities 
</p>
<p>that can positively contribute 
</p>
<p>to the business&rsquo;s overall 
</p>
<p>success. Based on a thorough 
</p>
<p>literature review, as well 
</p>
<p>as interviews with experts, 
</p>
<p>the company developed a 
</p>
<p>short survey to explore their 
</p>
<p>customers&rsquo; satisfaction with 
</p>
<p>specific performance features 
</p>
<p>and their overall satisfaction. 
</p>
<p>All the items were measured 
</p>
<p>on seven-point scales, with 
</p>
<p>higher scores denoting 
</p>
<p>higher levels of satisfaction. 
</p>
<p>&copy; Haver &amp; Boecker OHG
</p>
<p>8</p>
<p/>
<div class="annotation"><a href="http://www.haverboecker.com">http://www.haverboecker.com</a></div>
<div class="annotation"><a href="http://www.haverboecker.com">http://www.haverboecker.com</a></div>
</div>
<div class="page"><p/>
<p>8297
8.8 &middot; Review Questions
</p>
<p>8.8 Review Questions
</p>
<p>1. What is factor analysis? Try to explain what factor analysis is in your own words.
2. What is the difference between exploratory factor analysis and confirmatory factor 
</p>
<p>analysis?
3. What is the difference between PCA and factor analysis?
4. Describe the terms communality, eigenvalue, and factor loading. How do these 
</p>
<p>concepts relate to one another?
5. Describe the Kaiser criterion, the scree plot, and parallel analysis to determine 
</p>
<p>the number of factors. What are there similarities and differences between these 
methods?
</p>
<p>A standardized survey was 
</p>
<p>mailed to customers in 
</p>
<p>12 countries worldwide, 
</p>
<p>which resulted in 281 fully 
</p>
<p>completed questionnaires. 
</p>
<p>The following items (names 
</p>
<p>in parentheses) were listed in 
</p>
<p>the survey:
</p>
<p> 4 Reliability of the machines 
and systems. (s1)
</p>
<p> 4 Life-time of the machines 
and systems. (s2)
</p>
<p> 4 Functionality and 
user-friendliness 
</p>
<p>operation of the machines 
</p>
<p>and systems. (s3)
</p>
<p> 4 Appearance of the 
machines and systems. (s4)
</p>
<p> 4 Accuracy of the machines 
and systems. (s5)
</p>
<p> 4 Timely availability of the 
after-sales service. (s6)
</p>
<p> 4 Local availability of the 
after-sales service. (s7)
</p>
<p> 4 Fast processing of 
complaints. (s8)
</p>
<p> 4 Composition of 
quotations. (s9)
</p>
<p> 4 Transparency of 
quotations. (s10)
</p>
<p> 4 Fixed product prize 
for the machines and 
</p>
<p>systems. (s11)
</p>
<p> 4 Cost/performance ratio 
of the machines and 
</p>
<p>systems. (s12)
</p>
<p> 4 Overall, how satisfied are 
you with the supplier? 
</p>
<p>(overall)
</p>
<p>Your task is to analyze the 
</p>
<p>dataset to provide the 
</p>
<p>management of Haver 
</p>
<p>&amp; Boecker with advice 
</p>
<p>for effective customer 
</p>
<p>satisfaction management. The 
</p>
<p>dataset is labeled Haver and 
</p>
<p>Boecker.sav (⤓ Web Appendix 
&rarr; Downloads).
1. Using regression analysis, 
</p>
<p>locate those variables 
</p>
<p>that best explain the 
</p>
<p>customers&rsquo; overall 
</p>
<p>satisfaction (overall). 
</p>
<p>Evaluate the model fit 
</p>
<p>and assess the impact 
</p>
<p>of each variable on the 
</p>
<p>dependent variable. 
</p>
<p>Remember to consider 
</p>
<p>collinearity diagnostics.
</p>
<p>2. Determine the factors 
</p>
<p>that characterize the 
</p>
<p>respondents using factor 
</p>
<p>analysis. Use items s1&ndash;s12 
</p>
<p>for this. Run a PCA with 
</p>
<p>varimax rotation to help 
</p>
<p>interpretation. Consider 
</p>
<p>the following aspects:
</p>
<p>(a) Are all assumptions 
</p>
<p>for carrying out a 
</p>
<p>PCA met? Are the 
</p>
<p>data are sufficiently 
</p>
<p>correlated?
</p>
<p>(b) How many factors 
</p>
<p>would you extract? 
</p>
<p>Base your decision on 
</p>
<p>the Kaiser criterion, 
</p>
<p>the scree plot, and 
</p>
<p>parallel analysis. Do 
</p>
<p>these three methods 
</p>
<p>suggest the same 
</p>
<p>number of factors?
</p>
<p>(c) Find suitable labels for 
</p>
<p>the extracted factors.
</p>
<p>(d) Evaluate the 
</p>
<p>factor solution&rsquo;s 
</p>
<p>goodness-of-fit.
</p>
<p>3. Use the factor scores and 
</p>
<p>regress the customers&rsquo; 
</p>
<p>overall satisfaction 
</p>
<p>(overall) on these. 
</p>
<p>Evaluate the strength of 
</p>
<p>the model and compare it 
</p>
<p>with the initial regression. 
</p>
<p>What should Haver &amp; 
</p>
<p>Boecker&rsquo;s management 
</p>
<p>do to increase their 
</p>
<p>customers&rsquo; satisfaction?
</p>
<p>4. Calculate the Cronbach&rsquo;s 
</p>
<p>Alpha over items s1&ndash;s5 
</p>
<p>and interpret the results.
</p>
<p>For further information on 
</p>
<p>the dataset and the study, 
</p>
<p>see Festge and Schwaiger 
</p>
<p>(2007), as well as Sarstedt 
</p>
<p>et&nbsp;al. (2009).</p>
<p/>
</div>
<div class="page"><p/>
<p>298 Chapter 8 &middot; Principal Component and Factor Analysis
</p>
<p>6. What is the purpose of a varimax rotation? Does a rotation alter eigenvalues or 
factor loadings?
</p>
<p>7. Re-run the Oddjob Airways case study by carrying out a factor analysis and compare 
the results to the PCA analysis described in 7 Sect.&nbsp;8.6. Are there any differences?
</p>
<p>8. What is reliability analysis and why is it important?
9. Explain the basic principle of structural equation modeling.
</p>
<p>References
</p>
<p>Brown, J. D. (2009). Choosing the right type of rotation in PCA and EFA. JALT Testing &amp; Evaluation SIG News-
</p>
<p>letter, 13(3), 20&ndash;25.
</p>
<p>Cattell, R. B. (1966). The scree test for the number of factors. Multivariate Behavioral Research, 1(2),  
</p>
<p>245&ndash;276.
</p>
<p>Cliff, N. (1987). Analyzing multivariate data. New York, NJ: Harcourt Brace Jovanovich.
</p>
<p>Cronbach, L. J. (1951). Coefficient alpha and the internal structure of tests. Psychometrika, 16(3), 297&ndash;334.
</p>
<p>Diamantopoulos, A., &amp; Siguaw, J. A. (2000). Introducing LISREL: A guide for the uninitiated. London: Sage.
</p>
<p>Dinno, A. (2009). Exploring the sensitivity of Horn&rsquo;s parallel analysis to the distributional form of random 
</p>
<p>data. Multivariate Behavioral Research, 44(3), 362&ndash;388.
</p>
<p>DiStefano, C., Zhu, M., &amp; M&icirc;ndriă, D. (2009). Understanding and using factor scores: Considerations fort he 
</p>
<p>applied researcher. Practical Assessment, Research &amp; Evaluation, 14(20), 1&ndash;11.
</p>
<p>Festge, F., &amp; Schwaiger, M. (2007). The drivers of customer satisfaction with industrial goods: An interna-
</p>
<p>tional study. Advances in International Marketing, 18, 179&ndash;207.
</p>
<p>Gorsuch, R. L. (1983). Factor analysis (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum Associates.
</p>
<p>Graffelman, J. (2013). Linear-angle correlation plots: New graphs for revealing correlation structure. Jour-
</p>
<p>nal of Computational and Graphical Statistics, 22(1), 92&ndash;106.
</p>
<p>Grice, J. W. (2001). Computing and evaluating factor scores. Psychological Methods, 6(4), 430&ndash;450.
</p>
<p>Hair, J. F., Black, W. C., Babin, B. J., &amp; Anderson, R. E. (2019). Multivariate data analysis. A global perspective 
</p>
<p>(8th ed.). Boston. MA: Cengage.
</p>
<p>Hair, J. F., Ringle, C. M., &amp; Sarstedt, M. (2011). PLS-SEM: Indeed a silver bullet. Journal of Marketing Theory 
</p>
<p>and Practice, 19(2), 139&ndash;151.
</p>
<p>Hair, J. F., Hult, G. T. M., Ringle, C. M., &amp; Sarstedt, M. (2017a). A primer on partial least squares structural equa-
</p>
<p>tion modeling (PLS-SEM) (2nd ed.). Thousand Oaks, CA: Sage.
</p>
<p>Hair, J. F., Hult, G. T. M., Ringle, C. M., Sarstedt, M., &amp; Thiele, K. O. (2017b). Mirror, mirror on the wall. A com-
</p>
<p>parative evaluation of composite-based structural equation modeling methods. Journal of the Acad-
</p>
<p>emy of Marketing Science, 45(5), 616&ndash;632.
</p>
<p>Hair, J. F., Sarstedt, M., Ringle, C. M., &amp; Gudergan, S. P. (2018). Advanced issues in partial least squares struc-
</p>
<p>tural equation modeling (PLS-SEM). Thousand Oaks, CA: Sage.
</p>
<p>Hamilton, L. C. (2013), Statistics with Stata: Version 12: Cengage Learning.
</p>
<p>Hayton, J. C., Allen, D. G., &amp; Scarpello, V. (2004). Factor retention decisions in exploratory factor analysis:  
</p>
<p>A tutorial on parallel analysis. Organizational Research Methods, 7(2), 191&ndash;205.
</p>
<p>Henson, R. K., &amp; Roberts, J. K. (2006). Use of exploratory factor analysis in published research: Common 
</p>
<p>errors and some comment on improved practice. Educational and Psychological Measurement, 66(3), 
</p>
<p>393&ndash;416.
</p>
<p>Hershberger, S. L. (2005). Factor scores. In: B. S. Everitt &amp; D. C. Howell (Eds.), Encyclopedia of statistics in 
</p>
<p>behavioral science (pp. 636&ndash;644). New York, NJ: John Wiley.
</p>
<p>Horn, J. L. (1965). A rationale and test for the number of factors in factor analysis. Psychometrika, 30(2), 
</p>
<p>179&ndash;185.
</p>
<p>J&ouml;reskog, K. G. (1971). Simultaneous factor analysis in several populations. Psychometrika, 36(4), 409&ndash;426.
</p>
<p>Kaiser, H. F. (1958). The varimax criterion for factor analytic rotation in factor analysis. Educational and Psy-
</p>
<p>chological Measurement, 23(3), 770&ndash;773.
</p>
<p>Kaiser, H. F. (1974). An index of factorial simplicity. Psychometrika, 39(1), 31&ndash;36.
</p>
<p>8</p>
<p/>
</div>
<div class="page"><p/>
<p>8299
References
</p>
<p>Kim, J. O., &amp; Mueller, C. W. (1978). Introduction to factor analysis: What it is and how to do it. Thousand Oaks, 
</p>
<p>CA: Sage.
</p>
<p>Longman, R. S., Cota, A. A., Holden, R. R., &amp; Fekken, G. C. (1989). A regression equation for the parallel anal-
</p>
<p>ysis criterion in principal components analysis: Mean and 95th percentile Eigenvalues. Multivariate 
</p>
<p>Behavioral Research, 24(1), 59&ndash;69.
</p>
<p>MacCallum, R. C., Widaman, K. F., Zhang, S., &amp; Hong, S. (1999). Sample size in factor analysis. Psychological 
</p>
<p>Methods, 4(1), 84&ndash;99.
</p>
<p>Matsunga, M. (2010). How to factor-analyze your data right: Do&rsquo;s and don&rsquo;ts and how to&rsquo;s. International 
</p>
<p>Journal of Psychological Research, 3(1), 97&ndash;110.
</p>
<p>Mulaik, S. A. (2009). Foundations of factor analysis (2nd ed.). London: Chapman &amp; Hall.
</p>
<p>O'Connor, B. P. (2000). SPSS and SAS programs for determining the number of components using parallel 
</p>
<p>analysis and Velicer's MAP test. Behavior Research Methods, Instruments, &amp; Computers, 32(3), 396&ndash;402.
</p>
<p>Preacher, K. J., &amp; MacCallum, R. C. (2003). Repairing Tom Swift&rsquo;s electric factor analysis machine. Under-
</p>
<p>standing Statistics, 2(1), 13&ndash;43.
</p>
<p>Russell, D. W. (2002). In search of underlying dimensions: The use (and abuse) of factor analysis in Person-
</p>
<p>ality and Social Psychology Bulletin. Personality and Social Psychology Bulletin, 28(12), 1629&ndash;1646.
</p>
<p>Sarstedt, M., Schwaiger, M., &amp; Ringle, C. M. (2009). Do we fully understand the critical success factors of 
</p>
<p>customer satisfaction with industrial goods? Extending Festge and Schwaiger&rsquo;s model to account for 
</p>
<p>unobserved heterogeneity. Journal of Business Market Management, 3(3), 185&ndash;206.
</p>
<p>Sarstedt, M., Ringle, C. M., Raithel, S., &amp; Gudergan, S. (2014). In pursuit of understanding what drives fan 
</p>
<p>satisfaction. Journal of Leisure Research, 46(4), 419&ndash;447.
</p>
<p>Sarstedt, M., Hair, J. F., Ringle, C. M., Thiele, K. O., &amp; Gudergan, S. P. (2016). Estimation issues with PLS and 
</p>
<p>CBSEM: Where the bias lies!. Journal of Business Research, 69(10), 3998&ndash;4010.
</p>
<p>Steiger, J. H. (1979). Factor indeterminacy in the 1930's and the 1970's some interesting parallels. Psycho-
</p>
<p>metrika, 44(2), 157&ndash;167.
</p>
<p>Stevens, J. P. (2009). Applied multivariate statistics for the social sciences (5th ed.). Hillsdale: Erlbaum.
</p>
<p>Velicer, W. F., &amp; Jackson, D. N. (1990). Component analysis versus common factor analysis: Some issues in 
</p>
<p>selecting an appropriate procedure. Multivariate Behavioral Research, 25(1), 1&ndash;28.
</p>
<p>Widaman, K. F. (1993). Common factor analysis versus principal component analysis: Differential bias in 
</p>
<p>representing model parameters?. Multivariate Behavioral Research, 28(3), 263&ndash;311.
</p>
<p>Wold, H. O. A. (1982). Soft modeling: The basic design and some extensions. In: K. G. J&ouml;reskog &amp; H. O. A. 
</p>
<p>Wold (Eds.), Systems under indirect observations: Part II (pp. 1&ndash;54). Amsterdam: North-Holland.
</p>
<p>Zwick, W. R., &amp; Velicer, W. F. (1986). Comparison of five rules for determining the number of components 
</p>
<p>to retain. Psychological Bulletin, 99(3), 432&ndash;442.
</p>
<p>Further Reading
</p>
<p>Nunnally, J. C., &amp; Bernstein, I. H. (1993). Psychometric theory (3rd ed.). New York: McGraw-Hill.
</p>
<p>Stewart, D. W. (1981). The application and misapplication of factor analysis in marketing research. Journal 
</p>
<p>of Marketing Research, 18(1), 51&ndash;62.</p>
<p/>
</div>
<div class="page"><p/>
<p>301
</p>
<p>Cluster Analysis
</p>
<p>9.1 Introduction &ndash; 302
</p>
<p>9.2 Understanding Cluster Analysis &ndash; 302
</p>
<p>9.3 Conducting a Cluster Analysis &ndash; 305
9.3.1 Select the Clustering Variables &ndash; 305
9.3.2 Select the Clustering Procedure &ndash; 309
9.3.3 Select a Measure of Similarity or Dissimilarity &ndash; 322
9.3.4 Decide on the Number of Clusters &ndash; 328
9.3.5 Validate and Interpret the Clustering Solution &ndash; 331
</p>
<p>9.4 Example &ndash; 336
9.4.1 Hierarchical Cluster Analysis &ndash; 336
9.4.2 Two-Step Clustering &ndash; 349
</p>
<p>9.5 Oh, James! (Case Study) &ndash; 352
</p>
<p>9.6 Review Questions &ndash; 353
</p>
<p> References &ndash; 353
</p>
<p>9
</p>
<p>Electronic supplementary material
</p>
<p>The online version of this chapter (https://doi.org/10.1007/978-3-662-56707-4_9) contains 
</p>
<p>additional material that is available to authorized users. You can also download the &ldquo;Springer 
</p>
<p>Nature More Media App&rdquo; from the iOS or Android App Store to stream the videos and scan the 
</p>
<p>image containing the &ldquo;Play button&rdquo;.
</p>
<p>&copy; Springer-Verlag GmbH Germany, part of Springer Nature 2019 
</p>
<p>M. Sarstedt, E. Mooi, A Concise Guide to Market Research, Springer Texts in Business  
</p>
<p>and Economics, https://doi.org/10.1007/978-3-662-56707-4_9</p>
<p/>
<div class="annotation"><a href="https://crossmark.crossref.org/dialog/?doi=10.1007/978-3-662-56707-4_9&amp;amp;domain=pdf&amp;amp;date_stamp=2018-9-17">https://crossmark.crossref.org/dialog/?doi=10.1007/978-3-662-56707-4_9&amp;amp;domain=pdf&amp;amp;date_stamp=2018-9-17</a></div>
</div>
<div class="page"><p/>
<p>302 Chapter 9 &middot; Cluster Analysis
</p>
<p>Keywords
Agglomerative clustering &bull; Average linkage &bull; Centroid linkage &bull; Chaining effect &bull; Chebychev dis-
</p>
<p>tance&nbsp;&bull;&nbsp;City-block distance &bull; Clusters &bull; Clustering variables &bull; Complete linkage &bull; Dendrogram &bull; Distance 
</p>
<p>matrix &bull; Divisive clustering &bull; Euclidean distance &bull; Factor-cluster segmentation &bull; Hierarchical clustering 
</p>
<p>methods&nbsp;&bull; k-means &bull; k-means++ &bull; k-medians &bull; k-medoids &bull; Label switching &bull; Linkage algorithm &bull; Local 
</p>
<p>optimum &bull; Manhattan metric &bull; Market segmentation &bull; Matching coefficients &bull; Non-hierarchical clus-
</p>
<p>tering methods&nbsp;&bull; Partitioning methods &bull; Profiling &bull; Russel and Rao coefficient &bull; Silhouette measure of 
</p>
<p>cohesion and separation &bull; Simple matching coefficient &bull; Single linkage&nbsp;&bull; Straight line distance &bull; Two-
</p>
<p>step clustering &bull; Variance ratio criterion &bull; Ward&rsquo;s linkage
</p>
<p>9.1 Introduction
</p>
<p>Market segmentation is one of the most fundamental marketing activities. To successfully 
match products and services to customer needs, companies have to divide markets into 
groups (segments) of consumers, customers, and clients with similar needs and wants. Firms 
can then target each of these segments by positioning themselves in a unique segment (e.g., 
Ferrari in the high-end sports car market). Market segmentation &ldquo;is essential for marketing 
success: the most successful firms segment their markets carefully&rdquo; (Lilien and Rangaswamy 
2004, p. 61) and &ldquo;tools such as segmentation [ &hellip; ] have the largest impact on marketing 
decisions&rdquo; (Roberts et al. 2014, p. 127). While market researchers often form market seg-
ments based on practical grounds, industry practice and wisdom, cluster analysis uses data 
to form segments, making segmentation less dependent on subjectivity.
</p>
<p>9.2 Understanding Cluster Analysis
</p>
<p>Cluster analysis is a method for segmentation and identifies homogenous groups of objects 
(or cases, observations) called clusters. These objects can be individual customers, groups 
of customers, companies, or entire countries. Objects in a certain cluster should be as 
similar as possible to each other, but as distinct as possible from objects in other clusters.
</p>
<p>Let&rsquo;s try to gain a basic understanding of cluster analysis by looking at a simple example. 
Imagine that you are interested in segmenting customers A to G in order to better target 
them through, for example, pricing strategies.
</p>
<p>The first step is to decide on the characteristics that you will use to segment your 
customers A to G. In other words, you have to decide which clustering variables will 
</p>
<p>Learning Objectives
After reading this chapter you should understand:
</p>
<p> 5 The basic concepts of cluster analysis.
 5 How basic cluster algorithms work.
 5 How to compute simple clustering results manually.
 5 The different types of clustering procedures.
 5 The SPSS clustering outputs.
</p>
<p>9</p>
<p/>
</div>
<div class="page"><p/>
<p>9303
9.2 &middot; Understanding Cluster Analysis
</p>
<p>be included in the analysis. For example, you may want to segment a market based on  
customers&rsquo; price consciousness (x) and brand loyalty (y). These two variables can be  
measured on a scale from 0 to 100&nbsp;with higher values denoting a higher degree of price  
consciousness and brand loyalty. . Table&nbsp;9.1 and the scatter plot in . Fig.&nbsp;9.1 show the 
values of seven customers (referred to as objects).
</p>
<p>The aim of cluster analysis is to identify groups of objects (here, customers) that are 
very similar regarding their price consciousness and brand loyalty, and assign them to clus-
ters. After having decided on the clustering variables (here, price consciousness and brand 
loyalty), we need to decide on the clustering procedure to form our groups of objects. This 
step is crucial for the analysis, as different procedures require different decisions prior to 
</p>
<p>G 
</p>
<p>D 
</p>
<p>F 
</p>
<p>E 
</p>
<p>C 
</p>
<p>B A 
</p>
<p>Price consciousness (x) 
</p>
<p>B
ra
</p>
<p>n
d
</p>
<p> lo
y
</p>
<p>a
lt
</p>
<p>y
 (
</p>
<p>y
) 
</p>
<p>. Fig.&nbsp;9.1 Scatter plot
</p>
<p>. Table 9.1 Data
</p>
<p>Customer A B C D E F G
</p>
<p>x 33 82 66 30 79 50 10
</p>
<p>y 95 94 80 67 60 33 17</p>
<p/>
</div>
<div class="page"><p/>
<p>304 Chapter 9 &middot; Cluster Analysis
</p>
<p>analysis. There are many different approaches and little guidance on which one to use. We 
will discuss the most popular approaches in market research, including:
</p>
<p> 4 hierarchical methods,
 4 partitioning methods (especially k-means), and
 4 two-step clustering.
</p>
<p>While the basic aim of these procedures is the same, namely grouping similar objects 
into clusters, they take different routes, which we will discuss in this chapter. An import-
ant consideration before starting the grouping is to determine how similarity should be 
measured. Most methods calculate measures of (dis)similarity by estimating the distance 
between pairs of objects. Objects with smaller distances between one another are consid-
ered more similar, whereas objects with larger distances are considered more dissimilar. 
The decision on how many clusters should be derived from the data is a fundamental issue 
in the application of cluster analysis. This question is explored in the next step of the anal-
ysis. In most instances, we do not know the exact number of clusters and then we face a 
trade-off. On the one hand, we want as few clusters as possible to make the clusters easy to 
understand and actionable. On the other hand, having many clusters allows us to identify 
subtle differences between objects.
</p>
<p>Megabus is a hugely successful bus line in the US. They completely rethought the nature of their 
</p>
<p>customers and concentrated on three specific segments of the market: College kids, women 
</p>
<p>travelling in groups, and active seniors. To meet these customer segments&rsquo; needs, Megabus 
</p>
<p>reimagined the entire driving experience by developing double-decker buses with glass roofs 
</p>
<p>and big windows, and equipped with fast WiFi. Megabus&rsquo;s success of segmenting and targeting 
</p>
<p>efforts has led to practitioners talk about the &ldquo;Megabus Effect&rdquo;&mdash;how one company has shaped 
</p>
<p>an entire industry.
</p>
<p>&copy; Stagecoach Group plc.
</p>
<p>https://www.youtube.com/watch?v=mnrblwymSEo
</p>
<p>In the final step, we need to interpret the clustering solution by defining and labeling 
the obtained clusters. We can do this by comparing the mean values of the clustering vari-
ables across the different clusters, or by identifying explanatory variables to profile the 
</p>
<p>9</p>
<p/>
<div class="annotation"><a href="https://www.youtube.com/watch?v=mnrblwymSEo">https://www.youtube.com/watch?v=mnrblwymSEo</a></div>
</div>
<div class="page"><p/>
<p>9305
9.3 &middot; Conducting a Cluster Analysis
</p>
<p>clusters. Ultimately, managers should be able to identify customers in each cluster on the 
basis of easily measurable variables. This final step also requires us to assess the clustering 
solution&rsquo;s stability and validity. . Figure&nbsp;9.2 illustrates the steps associated with a cluster 
analysis; we will discuss these steps in more detail in the following sections.
</p>
<p>9.3 Conducting a Cluster Analysis
</p>
<p>9.3.1 Select the Clustering Variables
</p>
<p>At the beginning of the clustering process, we have to select appropriate variables for clus-
tering. Even though this choice is critical, it is rarely treated as such. Instead, a mixture of 
intuition and data availability guide most analyses in marketing practice. However, faulty 
assumptions may lead to improper market segmentation and, consequently, to deficient 
marketing strategies. Thus, great care should be taken when selecting the clustering vari-
ables! There are several types of clustering variables, as shown in . Fig.&nbsp;9.3. Sociodemo-
graphic variables define clusters based on people&rsquo;s demographic (e.g., age, ethnicity, and 
gender), geographic (e.g., residence in terms of country, state, and city), and socioeconomic 
(e.g., education, income, and social class) characteristics. Psychometric variables capture 
unobservable character traits such as people&rsquo;s personalities or lifestyles. Finally, behav-
ioral clustering variables typically consider different facets of consumer behavior, such as 
the way people purchase, use, and dispose of products. Other behavioral clustering vari-
ables capture specific benefits which different groups of consumers look for in a product.
</p>
<p>The types of variables used for cluster analysis provide different solutions and, thereby, 
influence targeting strategies. Over the last decades, attention has shifted from more tradi-
tional sociodemographic clustering variables towards behavioral and psychometric vari-
ables. The latter generally provide better guidance for decisions on marketing instruments&rsquo; 
</p>
<p>Select the clustering variables 
</p>
<p>Select the clustering procedure 
</p>
<p>Select a measure of similarity or dissimilarity 
</p>
<p>Decide on the number of clusters 
</p>
<p>Validate and interpret the clustering solution 
</p>
<p>. Fig.&nbsp;9.2 Steps involved in a cluster analysis</p>
<p/>
</div>
<div class="page"><p/>
<p>306 Chapter 9 &middot; Cluster Analysis
</p>
<p>effective specification. Generally, clusters based on psychometric variables are more 
homogenous and these consumers respond more consistently to marketing actions (e.g., 
Wedel and Kamakura 2000). However, consumers in these clusters are frequently hard 
to identify as such variables are not easily measured. Conversely, clusters determined by 
sociodemographic variables are easy to identify but are also more heterogeneous, which 
complicates targeting efforts. Consequently, researchers frequently combine different vari-
ables such as lifestyle characteristics and demographic variables, benefiting from each 
one&rsquo;s strengths.
</p>
<p>In some cases, the choice of clustering variables is apparent because of the task at hand. 
For example, a managerial problem regarding corporate communications will have a fairly 
well defined set of clustering variables, including contenders such as awareness, attitudes, 
perceptions, and media habits. However, this is not always the case and researchers have 
to choose from a set of candidate variables. But how do we make this decision? To facili-
tate the choice of clustering variables, we should consider the following guiding questions:
 4 Do the variables differentiate sufficiently between the clusters?
 4 Is the relation between the sample size and the number of clustering variables 
</p>
<p>reasonable?
 4 Are the clustering variables highly correlated?
 4 Are the data underlying the clustering variables of high quality?
</p>
<p>Sociodemographic Psychometric Behavioral  
</p>
<p>Demographic 
</p>
<p>Geographic 
</p>
<p>Personality 
</p>
<p>Lifestyle 
Choice of retail 
</p>
<p>outlets 
</p>
<p>Socioeconomic 
</p>
<p>Perceptions and 
intentions 
</p>
<p>Product and 
service use 
</p>
<p>Purchase 
behavior 
</p>
<p>Benefits 
</p>
<p>. Fig.&nbsp;9.3 Types of clustering variables
</p>
<p>9</p>
<p/>
</div>
<div class="page"><p/>
<p>9307
9.3 &middot; Conducting a Cluster Analysis
</p>
<p>z Do the variables differentiate sufficiently between the clusters?
It is important to select those clustering variables that provide a clear-cut differentiation 
between the objects.1 More precisely, criterion validity is of special interest; that is, the 
extent to which the &ldquo;independent&rdquo; clustering variables are associated with one or more 
criterion variables not included in the analysis. Such criterion variables generally relate 
to an aspect of behavior, such as purchase intention or willingness-to-pay. Given this 
relationship, there should be significant differences between the criterion variable(s) 
across the clusters (e.g., consumers in one cluster exhibit a significantly higher willing-
ness-to-pay than those in other clusters). These associations may or may not be causal, 
but it is essential that the clustering variables distinguish significantly between the vari-
able(s) of interest.
</p>
<p>z Is the relation between the sample size and the number of clustering variables 
reasonable?
</p>
<p>When choosing clustering variables, the sample size is important. From a statistical per-
spective, every additional variable requires an over-proportional increase in observations 
to ensure valid results. Unfortunately, there is no generally accepted guideline regarding 
minimum sample sizes or the relationship between the objects and the number of clus-
tering variables used. Recent rules-of-thumb are as follows:
 4 In the simplest case where clusters are of equal size, Qiu and Joe (2009) recommend 
</p>
<p>a sample size at least ten times the number of clustering variables multiplied by the 
number of clusters.
 4 Dolnicar et al. (2014) recommend using a sample size of 70 times the number of 
</p>
<p>clustering variables.
 4 Dolnicar et al. (2016) find that increasing the sample size from 10 to 30 times the 
</p>
<p>number of clustering variables substantially improves the clustering solution. This 
improvement levels off subsequently, but is still noticeable up to a sample size of 
approximately 100 times the number of clustering variables.&nbsp;
</p>
<p>These rules-of-thumb are approximate as the required sample size depends on many 
factors, such as survey data characteristics (e.g., nonresponse, sampling error, response 
styles), relative cluster sizes, and the degree to which the clusters overlap (Dolnicar et&nbsp;al. 
2016). Qiu and Joe (2009) suggest a minimum sample size of 10 times the number of 
clustering variables. Keep in mind that no matter how many variables are used and no 
matter how small the sample size, cluster analysis will almost always provide a result. At 
the same time, increasing the sample size has decreasing marginal returns on the quality 
of results. In addition, we need to be able to find clusters that are managerially relevant 
as the cluster sizes need to be substantial to ensure that the targeted marketing programs 
are profitable.
</p>
<p>z Are the clustering variables highly correlated?
If there is strong correlation between the variables, they are not sufficiently unique to identify 
distinct market segments. If highly correlated variables&mdash;0.90 and over&mdash;are used for cluster 
</p>
<p>1 Tonks (2009) provides a discussion of segment design and the choice of clustering variables in  
</p>
<p>consumer markets.</p>
<p/>
</div>
<div class="page"><p/>
<p>308 Chapter 9 &middot; Cluster Analysis
</p>
<p>2 See Arabie and Hubert (1994), Sheppard (1996), and Dolnicar and Gr&uuml;n (2009).
</p>
<p>Box 9.1 Issues with factor-cluster segmentation
Dolnicar and Gr&uuml;n (Dolnicar and Gr&uuml;n 2009) identify several problems of the factor-cluster 
</p>
<p>segmentation approach (see 7 Chap.&nbsp;8 for a discussion of principal component and factor 
analysis and related terminology):
</p>
<p>1. The data are pre-processed and the clusters are identified on the basis of transformed values, 
</p>
<p>not on the original information, which leads to different results.
</p>
<p>2. In factor analysis, the factor solution does not explain all the variance; information is thus 
</p>
<p>discarded before the clusters have been identified or constructed.
</p>
<p>3. Eliminating variables with low loadings on all the extracted factors means that, potentially, 
</p>
<p>the most important pieces of information for the identification of niche clusters are 
</p>
<p>discarded, making it impossible to ever identify such groups.
</p>
<p>4. The interpretations of clusters based on the original variables become questionable, given 
</p>
<p>that these clusters were constructed by using factor scores.
</p>
<p>Several studies have shown that the factor-cluster segmentation reduces the success of finding 
</p>
<p>useable clusters significantly.2&nbsp;Consequently, you should reduce the number of items in the 
</p>
<p>questionnaire&rsquo;s pre-testing phase, retaining a reasonable number of relevant, non-overlapping 
</p>
<p>questions that you believe differentiate the clusters well. However, if you have doubts about the 
</p>
<p>data structure, factor-clustering segmentation may still be a better option than discarding items.
</p>
<p>analysis, the specific aspects that these variables cover will be overrepresented in the clustering 
solution. For example, if we were to add another variable called brand preference to our anal-
ysis, it would almost cover the same aspect as brand loyalty. The concept of being attached to 
a brand would therefore be overrepresented in the analysis, because the clustering procedure 
does not conceptually differentiate between the clustering variables. Researchers frequently 
handle such correlation problems by applying cluster analysis to the observations&rsquo; factor 
scores, derived from a principal component or factor analysis. However, this factor-cluster 
segmentation approach is subject to several limitations, which we discuss in Box 9.1.
</p>
<p>z Are the data underlying the clustering variables of high quality?
Ultimately, the choice of clustering variables always depends on contextual influences, 
such as the data availability or the resources to acquire additional data. Market researchers 
often overlook that the choice of clustering variables is closely connected to data quality. 
Only those variables that ensure that high quality data can be used should be included in 
the analysis (Dolnicar and Lazarevski 2009). Following our discussions in 7 Chaps. 3&ndash;5, 
data are of high quality if the questions &hellip;
</p>
<p> 4 &hellip; have a strong theoretical basis,
 4 &hellip; are not contaminated by respondent fatigue or response styles, and
 4 &hellip; reflect the current market situation (i.e., they are recent).
</p>
<p>The requirements of other functions in the organization often play a major role in the 
choice of clustering variables. Consequently, we have to be aware that the choice of clus-
tering variables should lead to segments acceptable to the different functions in the 
organization.
</p>
<p>9</p>
<p/>
</div>
<div class="page"><p/>
<p>9309
9.3 &middot; Conducting a Cluster Analysis
</p>
<p>9.3.2 Select the Clustering Procedure
</p>
<p>By choosing a specific clustering procedure, we determine how clusters should be 
formed. This forming of clusters always involves optimizing some kind of criterion, 
such as minimizing the within-cluster variance (i.e., the clustering variables&rsquo; overall 
variance of the objects in a specific cluster), or maximizing the distance between the 
clusters. The procedure could also address the question of how to determine the (dis)
similarity between objects in a newly formed cluster and the remaining objects in the 
dataset.
</p>
<p>There are many different clustering procedures and also many ways of classifying these 
(e.g., overlapping versus non-overlapping, unimodal versus multimodal, exhaustive versus 
non-exhaustive). Wedel and Kamakura (2000), Dolnicar (2003), and Kaufman and Rous-
seeuw (2005) offer reviews of clustering techniques. A practical distinction is the differ-
entiation between hierarchical and partitioning methods (especially k-means), which we 
will discuss in the next sections.
</p>
<p>9.3.2.1 Hierarchical Clustering Methods
z Understanding Hierarchical Clustering Methods
Hierarchical clustering methods are characterized by the tree-like structure established in 
the course of the analysis. Most hierarchical methods fall into a category called agglomer-
ative clustering. In this category, clusters are consecutively formed from objects. Agglom-
erative clustering starts with each object representing an individual cluster. The objects are 
then sequentially merged to form clusters of multiple objects, starting with the two most 
similar objects. Similarity is typically defined in terms of the distance between objects. 
That is, objects with smaller distances between one another are considered more similar, 
whereas objects with larger distances are considered more dissimilar. After the merger 
of the first two most similar (i.e., closest) objects, the agglomerative clustering proce-
dure continues by merging another pair of objects or adding another object to an already 
existing cluster. This procedure continues until all the objects have been merged into 
one big cluster. As such, agglomerative clustering establishes a hierarchy of objects from 
the bottom (where each object represents a distinct cluster) to the top (where all objects 
form one big cluster). The left-hand side of . Fig.&nbsp;9.4 shows how agglomerative clustering 
merges objects (represented by circles) step-by-step with other objects or clusters (rep-
resented by ovals).
</p>
<p>Hierarchical clustering can also be interpreted as a top-down process, where all 
objects are initially merged into a single cluster, which the algorithm then gradually 
splits up into smaller clusters. This approach to hierarchical clustering is called divisive 
clustering. The right-hand side of .&nbsp;Fig.&nbsp;9.4 illustrates the divisive clustering concept. As 
we can see, in both agglomerative and divisive clustering, a cluster on a higher level of 
the hierarchy always encompasses all clusters from a lower level. This means that if an 
object is assigned to a certain cluster, there is no possibility of reassigning this object 
to another cluster (hence, the name hierarchical clustering). This is an important dis-
tinction between hierarchical and partitioning methods, such as k-means, which we 
will explore later in this chapter.</p>
<p/>
</div>
<div class="page"><p/>
<p>310 Chapter 9 &middot; Cluster Analysis
</p>
<p>Divisive procedures are rarely used in market research and not implemented in statis-
tical software programs such as SPSS as they are computationally very intensive for all but 
small datasets.3 We therefore focus on (agglomerative) hierarchical clustering.
</p>
<p>z Linkage algorithms
When using agglomerative hierarchical clustering, you need to specify a linkage algorithm. 
Linkage algorithms define the distance from a newly formed cluster to a certain object, or to 
other clusters in the solution. The most popular linkage algorithms include the following:
</p>
<p> 4 Single linkage (nearest neighbor in SPSS): The distance between two clusters 
corresponds to the shortest distance between any two members in the two clusters.
 4 Complete linkage (furthest neighbor in SPSS): The oppositional approach to single 
</p>
<p>linkage assumes that the distance between two clusters is based on the longest 
distance between any two members in the two clusters.
 4 Average linkage (between-groups linkage in SPSS): The distance between two clusters 
</p>
<p>is defined as the average distance between all pairs of the two clusters&rsquo; members.
 4 Centroid linkage: In this approach, the geometric center (centroid) of each cluster is 
</p>
<p>computed first. This is done by computing the clustering variables&rsquo; average values of 
all the objects in a certain cluster. The distance between the two clusters equals the 
distance between the two centroids.
</p>
<p>3 Whereas agglomerative methods have the large task of checking N&middot;(N&ndash;1)/2 possible first combina-
</p>
<p>tions of observations (note that N represents the number of observations in the dataset), divisive 
</p>
<p>methods have the almost impossible task of checking 2(N-1)&ndash;1&nbsp;combinations.
</p>
<p>D
iv
</p>
<p>isiv
e
</p>
<p> clu
ste
</p>
<p>rin
g
</p>
<p>A
g
</p>
<p>g
lo
</p>
<p>m
e
</p>
<p>ra
ti
</p>
<p>v
e
</p>
<p> c
lu
</p>
<p>st
e
</p>
<p>ri
n
</p>
<p>g
</p>
<p>S
te
</p>
<p>p
 1
</p>
<p> 
S
</p>
<p>te
p
</p>
<p> 2
 
</p>
<p>S
te
</p>
<p>p
 3
</p>
<p> 
S
</p>
<p>te
p
</p>
<p> 4
 
</p>
<p>S
te
</p>
<p>p
 5
</p>
<p> 
</p>
<p>S
te
</p>
<p>p
 5
</p>
<p> 
S
</p>
<p>te
p
</p>
<p> 4
 
</p>
<p>S
te
</p>
<p>p
 3
</p>
<p> 
S
</p>
<p>te
p
</p>
<p> 2
 
</p>
<p>S
te
</p>
<p>p
 1
</p>
<p> 
</p>
<p>. Fig.&nbsp;9.4 Agglomerative and divisive clustering9</p>
<p/>
</div>
<div class="page"><p/>
<p>9311
9.3 &middot; Conducting a Cluster Analysis
</p>
<p> 4 Ward&rsquo;s linkage: This approach differs from the previous ones in that it does not 
combine the two closest or most similar objects successively. Instead, Ward&rsquo;s linkage 
combines those objects whose merger increases the overall within-cluster variance 
(i.e., the homogeneity of clusters) to the smallest possible degree. The approach is 
generally used in combination with (squared) Euclidean distances, but can be used 
in combination with any other (dis)similarity measure.
</p>
<p>. Figs. 9.5, 9.6, 9.7, 9.8 and 9.9 illustrate these linkage algorithms for two clusters, which 
are represented by white circles surrounding a set of objects.
</p>
<p>Each of these linkage algorithms can yield different results when used on the same 
dataset, as each has specific properties:
</p>
<p> 4 The single linkage algorithm is based on minimum distances; it tends to form one 
large cluster with the other clusters containing only one or a few objects each. We 
can make use of this chaining effect to detect outliers, as these will be merged with 
the remaining objects&mdash;usually at very large distances&mdash;in the last steps of the 
analysis. Single linkage is considered the most versatile algorithm.
 4 The complete linkage method is strongly affected by outliers, as it is based on 
</p>
<p>maximum distances. Clusters produced by this method are likely to be compact and 
tightly clustered.
</p>
<p>Price consciousness (x) 
</p>
<p>B
ra
</p>
<p>n
d
</p>
<p> lo
y
</p>
<p>a
lt
</p>
<p>y
 (
</p>
<p>y
) 
</p>
<p>0 
</p>
<p>20 
</p>
<p>40 
</p>
<p>60 
</p>
<p>80 
</p>
<p>100 
</p>
<p>0 20 40 60 80 100 
</p>
<p>. Fig.&nbsp;9.5 Single linkage</p>
<p/>
</div>
<div class="page"><p/>
<p>312 Chapter 9 &middot; Cluster Analysis
</p>
<p> 4 The average linkage and centroid linkage algorithms tend to produce clusters with 
low within-cluster variance and with similar sizes. The average linkage is affected by 
outliers, but less than the complete linkage method.
 4 Ward&rsquo;s linkage yields clusters of similar size with a similar degree of tightness. 
</p>
<p>Prior research has shown that the approach generally performs very well. However, 
outliers and highly correlated variables have a strong impact on the results.
</p>
<p>To better understand how the linkage algorithms work, let&rsquo;s manually examine some calcu-
lation steps using single linkage as an example. Let's start&nbsp;by looking at the distance matrix 
in . Table&nbsp;9.2, which&nbsp;shows&nbsp;the distances between objects A-G from our initial example. 
In this distance matrix, the non-diagonal elements express the distances between pairs 
of objects based on the Euclidean distance&mdash;we will discuss this distance measure in the 
following section. The diagonal elements of the matrix represent the distance from each 
object to itself, which is, of course, 0. In our example, the distance matrix is an 8&nbsp;&times;&nbsp;8 table 
with the lines and rows representing the objects under consideration (see . Table&nbsp;9.1). 
As the distance between objects B and C (in this case, 21.260 units; printed in bold in 
. Table&nbsp;9.2) is the same as between C and B, the distance matrix is symmetrical. 
</p>
<p>Price consciousness (x) 
</p>
<p>B
ra
</p>
<p>n
d
</p>
<p> lo
y
</p>
<p>a
lt
</p>
<p>y
 (
</p>
<p>y
) 
</p>
<p>0 
</p>
<p>20 
</p>
<p>40 
</p>
<p>60 
</p>
<p>80 
</p>
<p>100 
</p>
<p>0 20 40 60 80 100 
</p>
<p>. Fig.&nbsp;9.6 Complete linkage
</p>
<p>9</p>
<p/>
</div>
<div class="page"><p/>
<p>9313
9.3 &middot; Conducting a Cluster Analysis
</p>
<p>Price consciousness (x) 
</p>
<p>B
ra
</p>
<p>n
d
</p>
<p> lo
y
</p>
<p>a
lt
</p>
<p>y
 (
</p>
<p>y
) 
</p>
<p>0 
</p>
<p>20 
</p>
<p>40 
</p>
<p>60 
</p>
<p>80 
</p>
<p>100 
</p>
<p>0 20 40 60 80 100
</p>
<p>. Fig.&nbsp;9.7 Average linkage
</p>
<p>Furthermore, since the distance between an object and itself is 0, you only need to look at 
either the lower or upper non-diagonal elements.
</p>
<p>In the very first step, the two objects exhibiting the smallest distance in the matrix are 
merged. Since the smallest distance occurs between B and C (d(B,C)&nbsp;=&nbsp;21.260), we merge 
these two objects in the first step of the analysis.
</p>
<p>&gt; Agglomerative clustering procedures always merge those objects with the smallest 
distance, regardless of the linkage algorithm used (e.g., single or complete linkage).
</p>
<p>In the next step, we form a new distance matrix by considering the single linkage deci-
sion rule as discussed above. Using this linkage algorithm, we need to compute the dis-
tance from the newly formed cluster [B,C] (clusters are indicated by squared brackets) 
to all the other objects. For example, with regard to the distance from the cluster [B,C] to 
object A, we need to check whether A is closer to object B or to object C. That is, we look 
for the minimum value in d(A,B) and d(A,C) from . Table&nbsp;9.2. As d(A,C)&nbsp;=&nbsp;36.249 is 
smaller than d(A,B)&nbsp;=&nbsp;49.010, the distance from A to the newly formed cluster is equal to 
d(A,C); that is, 36.249. We also compute the distances from cluster [B,C] to all the other </p>
<p/>
</div>
<div class="page"><p/>
<p>314 Chapter 9 &middot; Cluster Analysis
</p>
<p>objects (i.e., D, E, F, G). For example, the distance between [B,C] and D is the minimum 
of d(B,D)&nbsp;=&nbsp;58.592 and d(C,D)&nbsp;=&nbsp;38.275 (. Table&nbsp;9.2). Finally, there are several distances, 
such as d(D,E) and d(E,F), which are not affected by the merger of B and C. These dis-
tances are simply copied into the new distance matrix. This yields the new distance matrix 
shown in . Table&nbsp;9.3.
</p>
<p>Continuing the clustering procedure, we simply repeat the last step by merging the 
objects in the new distance matrix that exhibit the smallest distance and calculate the 
distance from this new cluster to all the other objects. In our case, the smallest distance 
(23.854, printed in bold in . Table&nbsp;9.3) occurs between the newly formed cluster [B, C] 
and object E. The result of this step is described in . Table&nbsp;9.4.
</p>
<p>Try to calculate the remaining steps yourself and compare your solution with the dis-
tance matrices in the following . Tables 9.5, 9.6 and 9.7.
</p>
<p>By following the single linkage procedure, the last steps involve the merger of cluster 
[A,B,C,D,E,F] and object G at a distance of 43.081. Do you get the same results? As you 
can see, conducting a basic cluster analysis manually is not that hard at all&mdash;not if there 
are only a few objects.
</p>
<p>Price consciousness (x) 
</p>
<p>B
ra
</p>
<p>n
d
</p>
<p> lo
y
</p>
<p>a
lt
</p>
<p>y
 (
</p>
<p>y
) 
</p>
<p>0 
</p>
<p>20 
</p>
<p>40 
</p>
<p>60 
</p>
<p>80 
</p>
<p>100 
</p>
<p>0 20 40 60 80 100 
</p>
<p>. Fig.&nbsp;9.8 Centroid linkage
</p>
<p>9</p>
<p/>
</div>
<div class="page"><p/>
<p>9315
9.3 &middot; Conducting a Cluster Analysis
</p>
<p>Price consciousness (x) 
</p>
<p>B
ra
</p>
<p>n
d
</p>
<p> lo
y
</p>
<p>a
lt
</p>
<p>y
 (
</p>
<p>y
) 
</p>
<p>0 
</p>
<p>20 
</p>
<p>40 
</p>
<p>60 
</p>
<p>80 
</p>
<p>100 
</p>
<p>0 20 40 60 80 100 
</p>
<p>. Fig.&nbsp;9.9 Ward&rsquo;s linkage
</p>
<p>. Table 9.2 Euclidean distance matrix
</p>
<p>Objects A B C D E F G
</p>
<p>A 0
</p>
<p>B 49.010 0
</p>
<p>C 36.249 21.260 0
</p>
<p>D 28.160 58.592 38.275 0
</p>
<p>E 57.801 34.132 23.854 40.497 0
</p>
<p>F 64.288 68.884 49.649 39.446 39.623 0
</p>
<p>G 81.320 105.418 84.291 53.852 81.302 43.081 0
</p>
<p>Note: Smallest distance is printed in bold.</p>
<p/>
</div>
<div class="page"><p/>
<p>. Table 9.3 Distance matrix after first clustering step (single linkage)
</p>
<p>Objects A B, C D E F G
</p>
<p>A 0
</p>
<p>B, C 36.249 0
</p>
<p>D 28.160 38.275 0
</p>
<p>E 57.801 23.854 40.497 0
</p>
<p>F 64.288 49.649 39.446 39.623 0
</p>
<p>G 81.320 84.291 53.852 81.302 43.081 0
</p>
<p>Note: Smallest distance is printed in bold.
</p>
<p>. Table 9.4 Distance matrix after second clustering step (single linkage)
</p>
<p>Objects A B, C, E D F G
</p>
<p>A 0
</p>
<p>B, C, E 36.249 0
</p>
<p>D 28.160 38.275 0
</p>
<p>F 64.288 39.623 39.446 0
</p>
<p>G 81.320 81.302 53.852 43.081 0
</p>
<p>Note: Smallest distance is printed in bold.
</p>
<p>. Table 9.5 Distance matrix after third clustering step (single linkage)
</p>
<p>Objects A, D B, C, E F G
</p>
<p>A, D 0
</p>
<p>B, C, E 36.249 0
</p>
<p>F 39.446 39.623 0
</p>
<p>G 53.852 81.302 43.081 0
</p>
<p>Note: Smallest distance is printed in bold.
</p>
<p>. Table 9.6 Distance matrix after fourth clustering step (single linkage)
</p>
<p>Objects A, B, C, D, E F G
</p>
<p>A, B, C, D, E 0
</p>
<p>F 39.446 0
</p>
<p>G 53.852 43.081 0
</p>
<p>Note: Smallest distance is printed in bold.
</p>
<p>9</p>
<p/>
</div>
<div class="page"><p/>
<p>9317
9.3 &middot; Conducting a Cluster Analysis
</p>
<p>9.3.2.2 Partitioning Methods: k-means
Partitioning clustering methods are another important group of procedures. As with hier-
archical clustering, there is a wide array of different algorithms; of these, k-means is the 
most popular for market research.
</p>
<p>z Understanding k-means Clustering
</p>
<p>The k-means method follows an entirely different concept than the hierarchical methods 
discussed above. The initialization of the analysis is one crucial difference. Unlike with 
hierarchical clustering, we need to specify the number of clusters to extract from the 
data prior to the analysis. Using this information as input, k-means starts by randomly 
assigning all objects to the clusters. In the next step, k-means successively reassigns 
the objects to other clusters with the aim of minimizing the within-cluster variation. 
This within-cluster variation is equal to the squared distance of each observation to 
the center of the associated cluster (i.e., the centroid). If the reallocation of an object 
to another cluster decreases the within-cluster variation, this object is reassigned to 
that cluster.
</p>
<p>Since cluster affiliations can change in the course of the clustering process (i.e., an 
object can move to another cluster in the course of the analysis), k-means does not build 
a hierarchy as hierarchical clustering does (. Fig.&nbsp;9.4). Therefore, k-means belongs to the 
group of non-hierarchical clustering methods.
</p>
<p>For a better understanding of the approach, let&rsquo;s take a look at how it works in practice. 
.&nbsp;Figs. 9.10, 9.11, 9.12 and 9.13 illustrate the four steps of the k-means clustering process&mdash;
research has produced several variants of the original algorithm, which we briefly discuss 
in Box 9.2.
</p>
<p>. Table 9.7 Distance matrix after fifth clustering step (single linkage)
</p>
<p>Objects A, B, C, D, E, F G
</p>
<p>A, B, C, D, E, F 0
</p>
<p>G 43.081 0
</p>
<p>Box 9.2&nbsp;Variants of the original k-means method
k-medians is a popular variant of k-means, which essentially follows the same logic and 
procedure. However, instead of using the cluster mean as a reference point for the calculation 
</p>
<p>of the within cluster variance, k-medians minimizes the absolute deviations from the cluster 
</p>
<p>medians, which equals the city-block distance. Thus, k-medians does not optimize the squared 
</p>
<p>deviations from the mean as in k-means, but absolute distances. Thereby k-median avoids the 
</p>
<p>possible effect of extreme values on the cluster solution. Other variants use other cluster centers 
</p>
<p>(e.g., k-medoids; Kaufman and Rousseeuw 2005; Park and Jun 2009), or optimize the initialization 
process (e.g., k-means++; Arthur and Vassilvitskii 2007). However, neither of these variants is 
menu-accessible in SPSS.</p>
<p/>
</div>
<div class="page"><p/>
<p>318 Chapter 9 &middot; Cluster Analysis
</p>
<p>D 
</p>
<p>F 
</p>
<p>E 
</p>
<p>C 
</p>
<p>B 
A 
</p>
<p>Price consciousness (x) 
</p>
<p>B
ra
</p>
<p>n
d
</p>
<p> lo
y
</p>
<p>a
lt
</p>
<p>y
 (
</p>
<p>y
) 
</p>
<p>0 
</p>
<p>20 
</p>
<p>40 
</p>
<p>60 
</p>
<p>80 
</p>
<p>100 
</p>
<p>0 20 40 60 80 100
</p>
<p>CC1 
</p>
<p>CC2 
</p>
<p>G 
</p>
<p>. Fig.&nbsp;9.10 k-means procedure (step 1: placing random cluster centers)
</p>
<p> 4 Step 1: The researcher needs to specify the number of clusters that k-means should 
retain from the data. Using this number as the input, the algorithm selects a center 
for each cluster. In our example, two cluster centers are randomly initiated, which 
CC1 (first cluster) and CC2 (second cluster) represent in . Fig.&nbsp;9.10.
 4 Step 2: Euclidean distances are computed from the cluster centers to every object. 
</p>
<p>Each object is then assigned to the cluster center with the shortest distance to it. 
In our example (. Fig.&nbsp;9.11), objects A, B, and C are assigned to the first cluster, 
whereas objects D, E, F, and G are assigned to the second. We now have our initial 
partitioning of the objects into two clusters.
 4 Step 3: Based on the initial partition in step 2, each cluster&rsquo;s geometric center 
(i.e., its centroid) is computed. This is done by computing the mean values of 
the objects contained in the cluster (e.g., A, B, C in the first cluster) in terms of 
each of the variables (price consciousness and brand loyalty). As we can see in 
.&nbsp;Fig.&nbsp;9.12, both clusters&rsquo; centers now shift to new positions (CC1&rsquo; in the first and 
CC2&rsquo; in the second cluster; the inverted comma indicates that the cluster center 
has changed).
</p>
<p>9</p>
<p/>
</div>
<div class="page"><p/>
<p>9319
9.3 &middot; Conducting a Cluster Analysis
</p>
<p>D 
</p>
<p>F 
</p>
<p>E 
</p>
<p>C 
</p>
<p>B 
A 
</p>
<p>Price consciousnes (x)
</p>
<p>B
ra
</p>
<p>n
d
</p>
<p> lo
y
</p>
<p>a
lt
</p>
<p>y
 (
</p>
<p>y
)
</p>
<p>0 
</p>
<p>20 
</p>
<p>40 
</p>
<p>60 
</p>
<p>80 
</p>
<p>100 
</p>
<p>0 20 40 60 80 100
</p>
<p>CC1 
</p>
<p>CC2 
</p>
<p>G 
</p>
<p>. Fig.&nbsp;9.11 k-means procedure (step 2: assigning objects to the closest cluster center)
</p>
<p>Naftali Harris&rsquo;s website offers a nice visualization of k-means clustering:
</p>
<p>https://www.naftaliharris.com/blog/visualizing-k-means-clustering/
</p>
<p>Tip
</p>
<p> 4 Step 4: The distances are computed from each object to the newly located cluster 
centers and the objects are again assigned to a certain cluster on the basis of their 
minimum distance to other cluster centers (CC1&rsquo; and CC2&rsquo;). Since the cluster 
centers&rsquo; position changed with respect to the initial situation, this could lead to 
a different cluster solution. This is also true of our example, because object E is 
now&mdash;unlike in the initial partition&mdash;closer to the first cluster center (CC1&rsquo;) than 
to the second (CC2&rsquo;). Consequently, this object is now assigned to the first cluster 
(.&nbsp;Fig.&nbsp;9.13).
</p>
<p>The k-means procedure is now repeated until a predetermined number of iterations are 
reached, or convergence is achieved (i.e., there is no change in the cluster affiliations).</p>
<p/>
<div class="annotation"><a href="https://www.naftaliharris.com/blog/visualizing-k-means-clustering/">https://www.naftaliharris.com/blog/visualizing-k-means-clustering/</a></div>
</div>
<div class="page"><p/>
<p>320 Chapter 9 &middot; Cluster Analysis
</p>
<p>D 
</p>
<p>F 
</p>
<p>E 
</p>
<p>C 
</p>
<p>B 
A 
</p>
<p>Price consciousness (x) 
</p>
<p>B
ra
</p>
<p>n
d
</p>
<p> lo
y
</p>
<p>a
lt
</p>
<p>y
 (
</p>
<p>y
) 
</p>
<p>0 
</p>
<p>20 
</p>
<p>40 
</p>
<p>60 
</p>
<p>80 
</p>
<p>100 
</p>
<p>0 20 40 60 80 100
</p>
<p>CC1 
</p>
<p>CC2 
</p>
<p>CC2  
</p>
<p>CC1  
</p>
<p>G 
</p>
<p>. Fig.&nbsp;9.12 k-means procedure (step 3: re-computing cluster centers)
</p>
<p>Three aspects are worth noting in terms of using k-means:
 4 k-means is implicitly based on pairwise Euclidean distances, because the sum of 
</p>
<p>the squared distances from the centroid is equal to the sum of the pairwise squared 
Euclidean distances divided by the number of objects. Hence, SPSS does not allow 
for selecting a distance measure&mdash;as in hierarchical clustering&mdash;but uses Euclidean 
distances. Therefore, the method should only be used with metric and, in case of 
equidistant scales, ordinal variables.
 4 Results produced by k-means depend on the starting partition. That is, k-means 
</p>
<p>produce different results, depending on the starting partition chosen by the 
researcher or initiated by the software. In SPSS, the initialization depends on the 
ordering of the objects. As a result, k-means may converge in a local optimum, which 
means that the solution is only optimal compared to similar solutions, but not 
globally. Therefore, you should run k-means multiple with objects sorted in different 
random orders to verify the stability of a given solution.
 4 k-means is less computationally demanding than hierarchical clustering techniques. 
</p>
<p>The method is therefore generally preferred for sample sizes above 500, and particu-
larly for big data applications.
 4 Running k-means requires specifying the number of clusters to retain prior to 
</p>
<p>running the analysis. We discuss this issue in the next section.
</p>
<p>9</p>
<p/>
</div>
<div class="page"><p/>
<p>9321
9.3 &middot; Conducting a Cluster Analysis
</p>
<p>G 
</p>
<p>D 
</p>
<p>F 
</p>
<p>E 
</p>
<p>C 
</p>
<p>B 
A 
</p>
<p>0 
</p>
<p>20 
</p>
<p>B
ra
</p>
<p>n
d
</p>
<p> lo
y
</p>
<p>a
lt
</p>
<p>y
 (
</p>
<p>y
)
</p>
<p>40 
</p>
<p>60 
</p>
<p>80 
</p>
<p>100 
</p>
<p>0 20 40 
</p>
<p>Price consciousness (x)
</p>
<p>60 80 100 
</p>
<p>CC2 &lsquo;
</p>
<p>CC1 &lsquo;
</p>
<p>. Fig.&nbsp;9.13 k-means procedure (step 4: reassigning objects to the closest cluster center)
</p>
<p>9.3.2.3 Two-Step Cluster Analysis
Chiu et al.&rsquo;s (2001) two-step cluster analysis is an alternative to k-means for very large data-
sets. As its name implies, the method follows a two-stage approach.
</p>
<p>In the first stage, the method merges all objects into sub-clusters. To do so, the method 
successively screens all objects to decide whether an object is merged with an existing 
cluster or establishes a new sub-cluster. Thereby two-step clustering establishes a cluster 
feature tree with roots and leaves (. Fig.&nbsp;9.14). Each of potentially eight roots consists of a 
maximum number of eight leaves. Each leave has a maximum number of eight sub-clus-
ters. Hence, two-step clustering allows for a maximum number of 8&nbsp;&middot;&nbsp;8&nbsp;&middot;&nbsp;8&nbsp;=&nbsp;512 sub-clus-
ters. Sub-clusters in one leave are similar to each other, as defined by the distance measure, 
whereas sub-clusters in different leaves are distinct. By establishing a cluster feature tree, 
two-step cluster analysis reduces computing time, which is an issue for very large datasets. 
In the second stage, two-step cluster analysis uses a modified hierarchical agglomerative 
clustering procedure to merge the sub-clusters.
</p>
<p>One crucial advantage of the two-step cluster analysis is that it can handle categorical 
and continuous variables simultaneously. Hierarchical clustering and k-means are clearly 
limited in this regard as these methods require continuous variables (k-means) or vari-
ables measured on either a categorical, ordinal, or continuous scale (hierarchical cluster-
ing). Furthermore, two-step clustering allows for automatically selecting the number of </p>
<p/>
</div>
<div class="page"><p/>
<p>322 Chapter 9 &middot; Cluster Analysis
</p>
<p>clusters based on statistical criteria. The procedure also indicates each variable&rsquo;s importance 
for the construction of a specific cluster. Finally, two-step cluster analysis also offers an 
overall goodness-of-fit measure called silhouette measure of cohesion and sepearation. 
It is essentially based on the average distances between the objects and can vary between 
&minus;1 and +1. A value of less than 0.20 indicates a poor solution quality, a value between 0.20 
and 0.50 a fair solution, whereas values higher than 0.50 indicate a good solution. These 
desirable features make the somewhat less popular two-step clustering a good alternative 
to the traditional methods.
</p>
<p>9.3.3 Select a Measure of Similarity or Dissimilarity
</p>
<p>In the previous section, we discussed different linkage algorithms used in agglomerative 
hierarchical clustering, the k-means procedure as well as two-step clutering. All these 
clustering procedures rely on measures that express the (dis)similarity between pairs of 
objects. In the following section, we introduce different measures for metric, ordinal, 
nominal, and binary variables.
</p>
<p>9.3.3.1 Metric and Ordinal Variables
z Distance Measures
</p>
<p>A straightforward way to assess two objects&rsquo; proximity is by drawing a straight line 
between them. For example, on examining the scatter plot in . Fig.&nbsp;9.1, we can easily 
see that the length of the line connecting observations B and C is much shorter than the 
line connecting B and G. This type of distance is called Euclidean distance or straight 
line distance; it is the most commonly used type for analyzing metric variables and, if 
the scales are equidistant (7Chap. 3), ordinal variables. Researchers also often use the 
squared Euclidean distance.
</p>
<p>In order to use a clustering procedure, we need to express these distances mathemati-
cally. Using the data from Table 9.1, we can compute the Euclidean distance between cus-
tomer B and customer C (generally referred to as d(B,C)) by using variables x and y with 
the following formula:
</p>
<p>Root
</p>
<p>(all objects)
</p>
<p>Root 1 Root 8
</p>
<p>Leaf 1 Leaf 8 Leaf 57 Leaf 64
</p>
<p>Sub-clusters
</p>
<p>1 &ndash; 8
Sub-clusters
</p>
<p>57 &ndash; 64
</p>
<p>Sub-clusters
</p>
<p>449 &ndash; 456
Sub-clusters
</p>
<p>505 &ndash; 512
</p>
<p>. Fig.&nbsp;9.14 Cluster feature tree
</p>
<p>9</p>
<p/>
</div>
<div class="page"><p/>
<p>9323
9.3 &middot; Conducting a Cluster Analysis
</p>
<p>d B C x x y yEuclidean B C B C( , ) ( ) ( )= &minus; + &minus;
2 2
</p>
<p> 
</p>
<p>As can be seen, the Euclidean distance is the square root of the sum of the squared differ-
ences in the variables&rsquo; values. Using the data from . Table&nbsp;9.1, we obtain the following:
</p>
<p>d B CEuclidean , .( )= &minus;( ) + &minus;( ) = &asymp;82 66 94 80 452 21 260
2 2
</p>
<p> 
</p>
<p>This distance corresponds to the length of the line that connects objects B and C. In this 
case, we only used two variables, but we can easily add more under the root sign in the 
formula. However, each additional variable will add a dimension (e.g., with six clustering 
variables, we have to deal with six dimensions), making it difficult to represent the solu-
tion graphically. Similarly, we can compute the distance between customer B and G, which 
yields the following:
</p>
<p>d B GEuclidean , , .( )= &minus;( ) + &minus;( ) = &asymp;82 10 94 17 11113 105 418
2 2
</p>
<p> 
</p>
<p>We should also compute the distance between all other pairs of objects and summarize 
them in a distance matrix. . Table&nbsp;9.2 shows the Euclidean distance matrix for objects A-G.
</p>
<p>There are also alternative distance measures: The city-block distance uses the sum of the 
variables&rsquo; absolute differences. This distance measure is referred to as the Manhattan metric 
as it is akin to the walking distance between two points in a city like New York&rsquo;s Manhat-
tan district, where the distance equals the number of blocks in the directions North-South 
and East-West. Using the city-block distance to compute the distance between customers 
B and C (or C and B) yields the following:
</p>
<p>d B C x x y yCity block B C B C&minus; = &minus; + &minus; = &minus; + &minus; =( , ) 82 66 94 80 30  
</p>
<p>The resulting distance matrix is shown in . Table&nbsp;9.8.
</p>
<p>. Table 9.8 City-block distance matrix
</p>
<p>Objects A B C D E F G
</p>
<p>A 0
</p>
<p>B 50 0
</p>
<p>C 48 30 0
</p>
<p>D 31 79 49 0
</p>
<p>E 81 37 33 56 0
</p>
<p>F 79 93 63 54 56 0
</p>
<p>G 101 149 119 70 112 56 0</p>
<p/>
</div>
<div class="page"><p/>
<p>324 Chapter 9 &middot; Cluster Analysis
</p>
<p>G 
</p>
<p>B 
</p>
<p>Price consciousness (x) 
</p>
<p>B
ra
</p>
<p>n
d
</p>
<p> lo
y
</p>
<p>a
lt
</p>
<p>y
 (
</p>
<p>y
) 
</p>
<p>0 
</p>
<p>20 
</p>
<p>40 
</p>
<p>60 
</p>
<p>80 
</p>
<p>100 
</p>
<p>0 20 40 60 80 100 
</p>
<p>Euclidean distance 
</p>
<p>Chebychev distance 
</p>
<p>City-block  
</p>
<p>distance 
</p>
<p>. Fig.&nbsp;9.15 Distance measures
</p>
<p>z Association Measures
The (dis)similarity between objects can also be expressed using association measures (e.g., 
correlations). For example, suppose a respondent rated price consciousness 2 and brand 
loyalty 3, a second respondent indicated 5 and 6, whereas a third rated these variables 3 
and 3. Euclidean and city-block distances would indicate that the first respondent is more 
</p>
<p>Lastly, when working with metric (or ordinal) data, researchers frequently use the Che-
bychev distance, which is the maximum of the absolute difference in the clustering vari-
ables&rsquo; values. For customers B and C, this is calculated as:
</p>
<p>d B C max x x y y maxChebychev B C B C, , ,( )= &minus; &minus;( )= &minus; &minus;( )=82 66 94 80 16
</p>
<p>. Figure&nbsp;9.15 illustrates the interrelation between these three distance measures regarding 
two objects (here: B and G) from our example.
</p>
<p>Different distance measures typically lead to different cluster solutions. Thus, it is 
</p>
<p>advisable to use several measures, check for the stability of results, and compare them 
</p>
<p>with theoretical or known patterns.
</p>
<p>Tip
</p>
<p>9</p>
<p/>
</div>
<div class="page"><p/>
<p>9325
9.3 &middot; Conducting a Cluster Analysis
</p>
<p>similar to the third than to the second. Nevertheless, one could convincingly argue that 
the first respondent&rsquo;s ratings are more similar to the second&rsquo;s, as both rate brand loyalty 
higher than price consciousness. This can be accounted for by computing the correlation 
between two vectors of values as a measure of similarity (i.e., high correlation coefficients 
indicate a high degree of similarity). Consequently, similarity is no longer defined as the 
difference between the answer categories, but as the similarity of the answering profiles.
</p>
<p>Whether you use one of the distance measures or correlations depends on whether 
</p>
<p>you think the relative magnitude of the variables within an object (which favors 
</p>
<p>correlation) matters more than the relative magnitude of each variable across the 
</p>
<p>objects (which favors distance). Some researchers recommended using correlations 
</p>
<p>when applying clustering procedures that are particularly susceptible to outliers, such 
</p>
<p>as complete linkage, average linkage, or centroid linkage. Furthermore, correlations 
</p>
<p>implicitly standardize the data, as differences in the scale categories do not have a 
</p>
<p>strong bearing on the interpretation of the response patterns. Nevertheless, distance 
</p>
<p>measures are most commonly used for their intuitive interpretation. Distance 
</p>
<p>measures best represent the concept of proximity, which is fundamental to cluster 
</p>
<p>analysis. Correlations, although having widespread application in other techniques, 
</p>
<p>represent patterns rather than proximity.
</p>
<p>Tip
</p>
<p>z Standardizing the Data
In many analysis tasks, the variables under consideration are measured in different units 
with hugely different variance. This would be the case if we extended our set of cluster-
ing variables by adding another metric variable representing the customers&rsquo; gross annual 
income. Since the absolute variation of the income variable would be much higher than 
the variation of the remaining two variables (remember, x and y are measured on a scale 
from 0 to 100), this would significantly change our analysis results. We can resolve this 
problem by standardizing the data prior to the analysis (7 Chap.&nbsp;5).
</p>
<p>Different standardization methods are available, such as z-standardization, which res-
cales each variable to a mean of 0 and a standard deviation of 1 (see 7 Chap.&nbsp;5). In cluster 
analysis, however, range standardization (e.g., to a range of 0 to 1) typically works better 
(Milligan and Cooper 1988).
</p>
<p>9.3.3.2 Binary and Nominal Variables
</p>
<p>Whereas the distance measures presented thus far can be used for variables measured on 
a metric and, in general, on an ordinal scale, applying them to binary and nominal vari-
ables is problematic. When nominal variables are involved, you should instead select a 
similarity measure expressing the degree to which the variables&rsquo; values share the same 
category. These matching coefficients can take different forms, but rely on the same allo-
cation scheme as shown in . Table&nbsp;9.9. In this crosstab, cell a is the number of character-
istics present in both objects A and B, whereas cell d describes the number of character-
istics absent in both objects. Cells b and c describe the number of characteristics present 
in one, but not the other, object.</p>
<p/>
</div>
<div class="page"><p/>
<p>326 Chapter 9 &middot; Cluster Analysis
</p>
<p>The allocation scheme in . Table&nbsp;9.9 applies to binary variables (i.e., nominal variables 
with two categories). For nominal variables with more than two categories, you need to 
convert the categorical variable into a set of binary variables in order to use matching coef-
ficients. For example, a variable with three categories needs to be transformed into three 
binary variables, one for each category (see the following example).
</p>
<p>Based on the allocation scheme in . Table&nbsp;9.9, we can compute different matching coef-
ficients, such as the simple matching (SM) coefficient:
</p>
<p>SM
a d
</p>
<p>a b c d
=
</p>
<p>+
</p>
<p>+ + +  
</p>
<p>This coefficient takes both the joint presence and the joint absence of a characteristic (as 
indicated by cells a and d in . Table&nbsp;9.9) into account. This feature makes the simple match-
ing coefficient particularly useful for symmetric variables where the joint presence and 
absence of a characteristic carry an equal degree of information. For example, the binary 
variable gender has the possible states &ldquo;male&rdquo; and &ldquo;female.&rdquo; Both are equally valuable and 
carry the same weight when the simple matching coefficient is computed. However, when 
the outcomes of a binary variable are not equally important (i.e., the variable is asymmet-
ric), the simple matching coefficient proves problematic. An example of an asymmetric 
variable is the presence, or absence, of a relatively rare attribute, such as customer com-
plaints. While you say that two customers who complained have something in common, 
you cannot say that customers who did not complain have something in common. The 
most important outcome is usually coded as 1 (present) and the other is coded as 0 (absent). 
The agreement of two 1s (i.e., a positive match) is more significant than the agreement of 
two 0s (i.e., a negative match). Similarly, the simple matching coefficient proves problem-
atic when used on nominal variables with many categories. In this case, objects may appear 
very similar, because they have many negative matches rather than positive matches.
</p>
<p>Given this issue, researchers have proposed several other matching coefficients, such as 
the Jaccard coefficient (JC) and the Russell and Rao coefficient, which (partially) omit the d cell 
from the calculation. Like the simple matching coefficient, these coefficients range from 0 
to 1&nbsp;with higher values indicating a greater degree of similarity.4 They are defined as follows:
</p>
<p>4 There are many other matching coefficients, with exotic names such as Yule&rsquo;s Q, Kulczynski, or Ochiai, 
</p>
<p>which are also menu-accessible in SPSS. As most applications of cluster analysis rely on metric or 
</p>
<p>ordinal data, we will not discuss these. See Wedel and Kamakura (2000) for more information on 
</p>
<p>alternative matching coefficients.
</p>
<p>. Table 9.9 Allocation scheme for matching coefficients
</p>
<p>Second object
</p>
<p>Presence of a charac-
</p>
<p>teristics (1)
</p>
<p>Absence of a charac-
</p>
<p>teristic (0)
</p>
<p>First object Presence of a characteristic (1) a b
</p>
<p>Absence of a characteristic (0) c d
</p>
<p>9</p>
<p/>
</div>
<div class="page"><p/>
<p>9327
9.3 &middot; Conducting a Cluster Analysis
</p>
<p>JC
a
</p>
<p>a b c
</p>
<p>RR
a
</p>
<p>a b c d
</p>
<p>=
+ +
</p>
<p>=
+ + +
</p>
<p> 
</p>
<p>To provide an example that compares the three coefficients, consider the following three 
variables:
 4 gender: male, female
 4 customer: yes, no
 4 country of residence: GER, UK, USA
</p>
<p>We first transform the measurement data into binary data by recoding the original three 
variables into seven binary variables (i.e., two for gender and customer; three for country 
of residence). . Table&nbsp;9.10 shows a binary data matrix for three objects A, B, and C. Object 
A is a male customer from Germany; object B is a male non-customer from the United 
States; object C is a female non-customer, also from the United States. 
</p>
<p>Using the allocation scheme from . Table&nbsp;9.9 to compare objects A and B yields the 
following results for the cells: a&nbsp;=&nbsp;1, b&nbsp;=&nbsp;2, c&nbsp;=&nbsp;2, and d&nbsp;=&nbsp;2. This means that the two objects 
have only one shared characteristic (a&nbsp;=&nbsp;1), but two characteristics, which are absent from 
both objects (d&nbsp;=&nbsp;2). Using this information, we can now compute the three coefficients 
described earlier:
</p>
<p>SM A B( , ) . ,=
+
</p>
<p>+ + +
=
</p>
<p>1 2
</p>
<p>1 2 2 2
0 571
</p>
<p> 
</p>
<p>  
JC A B( , ) .=
</p>
<p>+ +
=
</p>
<p>1
</p>
<p>1 2 2
0 2
</p>
<p>, and
</p>
<p>RR A B( , ) .=
+ + +
</p>
<p>=
1
</p>
<p>1 2 2 2
0 143
</p>
<p> 
</p>
<p>As we can see, the simple matching coefficient suggests that objects A and B are reason-
ably similar. Conversely, the Jaccard coefficient, and particularly the Russel Rao coeffi-
cient, suggests that they are not.
</p>
<p>. Table 9.10 Recoded measurement data
</p>
<p>Object Gender
(binary)
</p>
<p>Customer
</p>
<p>(binary)
Country of residence
</p>
<p>(binary)
</p>
<p>Male Female Yes No GER UK USA
</p>
<p>A 1 0 1 0 1 0 0
</p>
<p>B 1 0 0 1 0 0 1
</p>
<p>C 0 1 0 1 0 0 1</p>
<p/>
</div>
<div class="page"><p/>
<p>328 Chapter 9 &middot; Cluster Analysis
</p>
<p>Try computing the distances between the other object pairs. Your computation 
should yield the following: SM(A,C)&nbsp;=&nbsp;0.143, SM(B,C)&nbsp;=&nbsp;0.714, JC(A,C)&nbsp;=&nbsp;0, JC(B,C)&nbsp;=&nbsp;0.5, 
RR(A,C)&nbsp;=&nbsp;0, and RR(B,C)&nbsp;=&nbsp;0.286.
</p>
<p>9.3.3.3 Mixed Variables
</p>
<p>Most datasets contain variables that are measured on multiple scales. For example, a market 
research questionnaire may require the respondent&rsquo;s gender, income category, and age. 
We therefore have to consider variables measured on a nominal, ordinal, and metric scale. 
How can we simultaneously incorporate these variables into an analysis?
</p>
<p>Often research use the distance measures discussed in the context of metric (and 
ordinal) data. Even though this approach may slightly change the results compared to 
using matching coefficients, it should not be rejected. Cluster analysis is mostly an explor-
atory technique whose results only provide guidance for making decisions but are no sub-
stitute for decision-making.
</p>
<p>An alternative is to dichotomize all the variables and apply the matching coeffi-
cients discussed above. For metric variables, this involves specifying categories (e.g., low, 
medium, and high age) and converting these into sets of binary variables. In most cases, 
the specification of categories is somewhat arbitrary. Furthermore, this procedure leads 
to a severe loss in precision, as we disregard more detailed information on each object. 
For example, we lose precise information on each respondent&rsquo;s age when scaling this vari-
able down into age categories. Given such issues, you should avoid combining metric and 
nominal variables in a single cluster analysis.
</p>
<p>Another way to handle variables measured on different scale levels is to use the two-
step cluster analysis (see 7 Sect.&nbsp;9.3.2.3). This method uses a distance measure that draws 
on probability distributions. Specifically, this distance defines the distance between two 
objects in terms of the decrease of the likelihood value when merging them.
</p>
<p>9.3.4 Decide on the Number of Clusters
</p>
<p>An important question we haven&rsquo;t yet addressed is how to decide on the number of clus-
ters. A misspecified number of clusters results in under- or oversegmentation, which easily 
leads to inaccurate management decisions on, for example, customer targeting, product 
positioning, or determining the optimal marketing mix (Becker et al. 2015).
</p>
<p>We can select the number of clusters pragmatically, choosing a grouping that &ldquo;works&rdquo; 
for our analysis, but sometimes we want to select the &ldquo;best&rdquo; solution that the data suggest. 
However, different clustering methods require different approaches to decide on the 
number of clusters. Hence, we discuss hierarchical and portioning methods separately.
</p>
<p>9.3.4.1 Hierarchical Methods
</p>
<p>To guide the decision of how many clusters to extract from the data, we can draw on the 
distances at which the objects were combined. More precisely, we can seek a solution in 
which an additional combination of clusters or objects would occur at a greatly increased 
distance. This raises the issue of what a great distance is.
</p>
<p>We can seek an answer by plotting the distance level at which the mergers of objects 
and clusters occur by using a dendrogram. . Figure&nbsp;9.16 shows the dendrogram for our 
example as produced by SPSS. We read the dendrogram from the left to the right. The 
</p>
<p>9</p>
<p/>
</div>
<div class="page"><p/>
<p>9329
9.3 &middot; Conducting a Cluster Analysis
</p>
<p>horizontal lines indicate the distances at which the objects were merged. Note that in 
SPSS, these distances do not correspond to the actual merging distances as computed in 
Tables 9.2, 9.3, 9.4, 9.5 and 9.7. Instead, SPSS rescales the distances to a range of 0&ndash;25 (i.e., 
the last merging step to a one-cluster solution takes place at a rescaled distance of 25). The 
rescaling on the x-axis facilitates the decision on how many clusters to extract from the 
data. Specifically, to decide on the number of clusters, we cut the dendrogram vertically 
in the area where no merger has occurred for a long distance. In our example, this is done 
when moving from a four-cluster solution, which occurs at a rescaled distance of 8, to a 
three-cluster solution, which occurs at a distance of 18. This result suggests a four-cluster 
solution [A,D], [B,C,E], [F], and [G], but this conclusion is not clear-cut. In fact, the den-
drogram often does not provide a clear indication, because it is generally difficult to iden-
tify where the cut should be made. This is particularly true of large sample sizes when the 
dendrogram becomes unwieldy.
</p>
<p>As an alternative to the dendrogram, we can also contrast the distances against the 
number of clusters to produce a scree plot, similar to the one used to decide on the number 
of factors in factor analysis (7 Chap.&nbsp;8). Specifically, we can plot the number of clusters on 
the x-axis (starting with the one-cluster solution at the very left) against the distance at 
which objects or clusters are merged on the y-axis. Using this plot, we then search for the 
distinctive break (elbow), which indicates the number of clusters to retain. Note that&mdash;
unlike in factor analysis&mdash;we do not pick the solution with one cluster less than indicated 
by the elbow. Furthermore, the distances typically sharply increase when switching from 
a two-cluster solution to a one-cluster solution. However, this break should not be viewed 
as a reliable indicator for the decision regarding the number of segments.
</p>
<p>Dendrogram using Single Linkage
Rescaled Distance Cluster Combine
</p>
<p>2
</p>
<p>0 5 10 15 20 25
</p>
<p>B
</p>
<p>C
</p>
<p>E
</p>
<p>AY
</p>
<p>D
</p>
<p>F
</p>
<p>G
</p>
<p>3
</p>
<p>5
</p>
<p>1
</p>
<p>4
</p>
<p>6
</p>
<p>7
</p>
<p>. Fig.&nbsp;9.16 Dendrogram</p>
<p/>
</div>
<div class="page"><p/>
<p>330 Chapter 9 &middot; Cluster Analysis
</p>
<p>Research has produced several other criteria for determining the number of clusters 
in a dataset. One of the most prominent criteria is Calinski and Harabasz&rsquo;s (1974) variance 
ratio criterion (VRC). For a solution with n objects and k clusters, the VRC is defined as:
</p>
<p>VRC SS K SS n Kk B W= &minus; &minus;( / ( )) / ( / ( )),1  
</p>
<p>where SSB is the sum of the squares between the clusters and SSW is the sum of the squares 
within the clusters. The criterion should seem familiar, as it is equivalent to the F-value of a 
one-way ANOVA (7 Chap.&nbsp;6). To determine the appropriate number of clusters, you should 
choose the number that maximizes the VRC. However, as the VRC usually decreases with 
a greater number of clusters, you should compute the difference in the VRC values ωk of 
each cluster solution, using the following formula:
</p>
<p>ωk k k k kVRC VRC VRC VRC= &minus; &minus; &minus;+ &minus;( ) ( ).1 1  
</p>
<p>The number of clusters k that minimizes the value in ωk indicates the best cluster solution. 
Prior research has shown that the VRC reliably identifies the correct number of clusters 
across a broad range of constellations (Miligan and Cooper 1985). However, owing to the 
term VRC k&minus;1, which is not defined for a one-cluster solution, the minimum number of 
clusters that can be selected is three, which is a disadvantage when using the ωk statistic.
</p>
<p>To compute the VRC, we need to run a series of ANOVAs using the clustering vari-
ables as dependent variables and the cluster affiliation as the factor variable. The VRC for 
a certain number of clusters k results from summing all the F-value across the different 
ANOVAs. Note that the computation of the VRC values is more straightforward when 
running k-means clustering as SPSS allows running ANOVAs on the clustering variables 
as part of this clustering procedure.
</p>
<p>&gt; Overall, the above criteria can often only provide rough guidance regarding 
the number of clusters that should be selected&ndash;you should also take practical 
</p>
<p>considerations into account. Occasionally, you might have a priori knowledge, 
</p>
<p>or a theory on which you can base your choice. However, first and foremost, you 
</p>
<p>should ensure that your results are interpretable and meaningful. Not only must 
</p>
<p>the number of clusters be small enough to ensure manageability, but each segment 
</p>
<p>should also be large enough to warrant strategic attention.
</p>
<p>9.3.4.2 Partitioning Methods
When running partitioning methods, such as k-means, you have to pre-specify the number 
of clusters to retain from the data. There are varying ways of guiding this decision:
 4 Compute the VRC (see discussion in the context of hierarchical clustering) for an 
</p>
<p>alternating number of clusters and select the solution that maximizes the VRC or 
minimizes ωk. For example, compute the VRC for a three- to five-cluster solution 
and select the number of clusters that minimizes ωk.
 4 Run a hierarchical procedure to determine the number of clusters by using the 
</p>
<p>dendrogram and run k-means afterwards.5 This approach also enables you to find 
</p>
<p>5 See Punji and Stewart (1983) for additional information on this sequential approach.
</p>
<p>9</p>
<p/>
</div>
<div class="page"><p/>
<p>9331
9.3 &middot; Conducting a Cluster Analysis
</p>
<p>starting values for the initial cluster centers to handle a second problem, which 
relates to the procedure&rsquo;s sensitivity to the initial classification (we will follow this 
approach in the example application).
 4 Rely on prior information, such as earlier research findings.
</p>
<p>9.3.4.3 Two-step Clustering
One crucial advantage of two-step clustering is that the method allows for automatically 
selecting the number of clusters based on statistical criteria. In doing so, two-step cluster-
ing follows a two-stage approach (Bacher et al. 2004).
</p>
<p>In the first stage, the method determines a maximum number of clusters based on 
Akaike&rsquo;s Information Criterion (AIC; Akaike 1973) or the Bayes Information Criterion (BIC; 
Schwarz 1978), depending on the researcher&rsquo;s specification. These criteria add different 
terms to the log likelihood value resulting from the analysis, which penalize the complex-
ity of the solution as expressed by the number of clusters&mdash;solutions with a more clusters 
entail a stronger penalty term. In SPSS, the maximum number of clusters is determined 
by the ratio between AIC (or BIC) for a solution with k clusters and a one-cluster solu-
tion. The solution for which this ratio is smaller than a certain threshold assumed by the 
program is the maximum number of clusters.
</p>
<p>In the second stage, two-step clustering computes the ratio of distances between dif-
ferent cluster solutions using the AIC (or BIC) values as input. The resulting ratio deter-
mines the final number of clusters to extract.
</p>
<p>9.3.5 Validate and Interpret the Clustering Solution
</p>
<p>Before interpreting the cluster solution, we need to assess the stability of the results. Sta-
bility means that the cluster membership of individuals does not change, or only changes 
a little when different clustering methods are used to cluster the objects. Thus, when dif-
ferent methods produce similar results, we claim stability.
</p>
<p>The aim of any cluster analysis is to differentiate well between the objects. The identified 
clusters should therefore differ substantially from each other and the members of different 
clusters should respond differently to different marketing-mix elements and programs.
</p>
<p>Lastly, we need to profile the cluster solution by using observable variables. Profiling 
ensures that we can easily assign new objects to clusters based on observable traits. For 
example, we could identify clusters based on loyalty to a product, but in order to use these 
different clusters, their membership should be identifiable according to tangible variables, 
such as income, location, or family size, in order to be actionable.
</p>
<p>The key to successful segmentation is to critically revisit the results of different cluster analysis 
</p>
<p>set-ups (e.g., by using different algorithms on the same data) in terms of managerial relevance. 
</p>
<p>The following criteria help identify a clustering solution (Kotler and Keller 2015; Tonks 2009).
</p>
<p> 5 Substantial: The clusters are large and sufficiently profitable to serve.
 5 Reliable: Only clusters that are stable over time can provide the necessary basis for a 
</p>
<p>successful marketing strategy. If clusters change their composition quickly, or their members&rsquo; 
</p>
<p>behavior, targeting strategies are not likely to succeed. Therefore, a certain degree of stability </p>
<p/>
</div>
<div class="page"><p/>
<p>332 Chapter 9 &middot; Cluster Analysis
</p>
<p>9.3.5.1 Stability
</p>
<p>Stability is evaluated by using different clustering procedures on the same data and con-
sidering the differences that occur. For example, you may first run a hierarchical cluster-
ing procedure, followed by k-means clustering to check whether the cluster affiliations of 
the objects change. Alternatively, running a hierarchical clustering procedure, you can use 
different distance measures and evaluate their effect on the stability of the results. However, 
note that it is common for results to change even when your solution is adequate. As a rule 
of thumb, if more than 20&nbsp;% of the cluster affiliations change from one technique to the 
other, you should reconsider the analysis and use, for example, a different set of cluster-
ing variables, or reconsider the number of clusters. Note, however, that this percentage is 
likely to increase with the number of clusters used.
</p>
<p>When the data matrix exhibits identical values (referred to as ties), the ordering of the 
objects in the dataset can influence the results of the hierarchical clustering procedure. 
For example, when computing the distance matrix based on the city-block distance for 
the data from . Table&nbsp;9.1, object pairs (D,E), (E,F), and (F,G) have the same distance of 
56 units. Ties can prove problematic when they occur for the minimum distance in a dis-
tance matrix, as the decision about which objects to merge then becomes ambiguous (i.e., 
should we merge objects D and E, E and F, or F and G if 56&nbsp;was the smallest distance in the 
matrix?). To handle this problem, Van Der Kloot et al. (2005) recommend re-running the 
analysis with a different input order of the data. The downside of this approach is that the 
labels of a cluster may change from one analysis to the next. This issue is referred to as label 
switching. For example, in the first analysis, cluster 1&nbsp;may correspond to cluster 2 in the 
second analysis. Ties are, however, more the exception than the rule in practical applica-
tions&mdash;especially when using (squared) Euclidean distances&mdash;and generally don't have a 
pronounced impact on the results. However, if changing the order of the objects also dras-
tically changes the cluster compositions (e.g., in terms of cluster sizes), you should recon-
sider the set-up of the analysis and, for example, re-run it with different clustering variables.
</p>
<p>9.3.5.2 Differentiation of the Data
</p>
<p>To examine whether the final partition differentiates the data well, we need to examine 
the cluster centroids. This step is highly important, as the analysis sheds light on whether 
the clusters are truly distinct. Only if objects across two (or more) clusters exhibit sig-
nificantly different means in the clustering variables (or any other relevant variable) can 
</p>
<p>is necessary to ensure that marketing strategies can be implemented and produce adequate 
</p>
<p>results. Reliability can be evaluated by critically revisiting and replicating the clustering 
</p>
<p>results at a later date.
</p>
<p> 5 Accessible: The clusters can be effectively reached and served.
 5 Actionable: Effective programs can be formulated to attract and serve the clusters.
 5 Parsimonious: To be managerially meaningful, only a small set of substantial clusters should 
</p>
<p>be identified.
</p>
<p> 5 Familiar: To ensure management acceptance, the cluster composition should be easy to 
relate to.
</p>
<p> 5 Relevant: Clusters should be relevant in respect of the company&rsquo;s competencies and 
objectives.
</p>
<p>9</p>
<p/>
</div>
<div class="page"><p/>
<p>9333
9.3 &middot; Conducting a Cluster Analysis
</p>
<p>they be distinguished from each other. This can be easily ascertained by comparing the 
means of the clustering variables across the clusters with independent t-tests or ANOVA 
(see 7 Chap. 6).
</p>
<p>Furthermore, we need to assess the solution&rsquo;s criterion validity (see 7 Chap. 4). We do 
this by focusing on the criterion variables that have a theoretical relationship with the clus-
tering variables, but were not included in the analysis. In market research, criterion vari-
ables are usually managerial outcomes, such as the sales per person, or willingness-to-pay. 
If these criterion variables differ significantly, we can conclude that the clusters are distinct 
groups with criterion validity.
</p>
<p>9.3.5.3 Profiling
</p>
<p>As indicated at the beginning of the chapter, cluster analysis usually builds on unob-
servable clustering variables. This creates an important problem when working with the 
final solution: How can we decide to which cluster a new object should be assigned if its 
unobservable characteristics, such as personality traits, personal values, or lifestyles, are 
unknown? We could survey these attributes and make a decision based on the clustering 
variables. However, this is costly and researchers therefore usually try to identify observ-
able variables (e.g., demographics) that best mirror the partition of the objects. More pre-
cisely, these observable variables should partition the data into similar groups as the clus-
tering variables do. Using these observable variables, it is then easy to assign a new object 
(whose cluster membership is unknown) to a certain cluster. For example, assume that we 
used a set of questions to assess the respondents&rsquo; values and learned that a certain cluster 
contains respondents who appreciate self-fulfillment, enjoyment of life, and a sense of 
accomplishment, whereas this is not the case in another cluster. If we were able to identify 
explanatory variables, such as gender or age, which distinguish these clusters adequately, 
then we could assign a new person to a specific cluster on the basis of these observable 
variables whose value traits may still be unknown.
</p>
<p>9.3.5.4 Interpret the Clustering Solution
</p>
<p>The interpretation of the solution requires characterizing each cluster by using the crite-
rion or other variables (in most cases, demographics). This characterization should focus 
on criterion variables that convey why the cluster solution is relevant. For example, you 
could highlight that customers in one cluster have a lower willingness to pay and are sat-
isfied with lower service levels, whereas customers in another cluster are willing to pay 
more for a superior service. By using this information, we can also try to find a meaningful 
name or label for each cluster; that is, one that adequately reflects the objects in the cluster. 
This is usually a challenging task, especially when unobservable variables are involved.
</p>
<p>While companies develop their own market segments, they frequently use standardized 
</p>
<p>segments, based on established buying trends, habits, and customers&rsquo; needs to position 
</p>
<p>their products in different markets. The PRIZM lifestyle by Nielsen is one of the most popular 
</p>
<p>segmentation databases. It combines demographic, consumer behavior, and geographic data 
</p>
<p>to help marketers identify, understand, and reach their customers and prospective customers. 
</p>
<p>PRIZM defines every US household in terms of more than 60 distinct segments to help 
</p>
<p>marketers discern these consumers&rsquo; likes, dislikes, lifestyles, and purchase behaviors.</p>
<p/>
</div>
<div class="page"><p/>
<p>334 Chapter 9 &middot; Cluster Analysis
</p>
<p>. Table 9.11 Steps involved in carrying out a cluster analysis in SPSS
</p>
<p>Theory Action
</p>
<p>Research problem
</p>
<p>Identification of homogenous groups of objects in a population
</p>
<p>Select clustering 
</p>
<p>variables to form 
</p>
<p>segments
</p>
<p>Select relevant variables that potentially exhibit high degrees of criterion 
</p>
<p>validity with regard to a specific managerial objective.
</p>
<p>Requirements
</p>
<p>Sufficient sample 
</p>
<p>size
</p>
<p>Make sure that the relationship between the objects and the clustering vari-
</p>
<p>ables is reasonable. Ten times the number of clustering variables is the bare 
</p>
<p>minimum, but 30 to 70 times is recommended. Ensure that the sample size is 
</p>
<p>large enough to guarantee substantial segments.
</p>
<p>Low levels of 
</p>
<p>collinearity 
</p>
<p>among the 
</p>
<p>variables
</p>
<p>► Analyze ► Correlate ► Bivariate
</p>
<p>In case of highly correlated variables (correlation coefficients &gt; 0.90), delete 
</p>
<p>one variable of the offending pair.
</p>
<p>Specification
</p>
<p>Choose the 
</p>
<p>clustering 
</p>
<p>procedure
</p>
<p>If there is a limited number of objects in your dataset or you do not know the 
</p>
<p>number of clusters:
</p>
<p>► Analyze ► Classify ► Hierarchical Cluster
</p>
<p>If there are many observations (&gt; 500) in your dataset and you have a priori 
</p>
<p>knowledge regarding the number of clusters:
</p>
<p>► Analyze ► Classify ► K-Means Cluster
</p>
<p>If there are many observations in your dataset and the clustering variables 
</p>
<p>are measured on different scale levels:
</p>
<p>► Analyze ► Classify ► Two-Step Cluster
</p>
<p>Choose clustering 
</p>
<p>algorithm
</p>
<p>(only hierarchical 
</p>
<p>clustering)
</p>
<p>► Analyze ► Classify ► Hierarchical Cluster ► Method ► Cluster Method
</p>
<p>Use Ward&rsquo;s method if equally sized clusters are expected and no outliers are 
</p>
<p>present. Preferably use single linkage, also to detect outliers.
</p>
<p>. Table&nbsp;9.11 summarizes the steps involved in a hierarchical, k-means, and two-step clus-
tering using SPSS.
</p>
<p>An example is the segment labeled &ldquo;Connected Bohemians,&rdquo; which Nielsen characterizes as 
</p>
<p>a &ldquo;collection of mobile urbanites, Connected Bohemians represent the nation's most liberal 
</p>
<p>lifestyles. Its residents are a progressive mix of tech savvy, young singles, couples, and families 
</p>
<p>ranging from students to professionals. In their funky row houses and apartments, Bohemian 
</p>
<p>Mixers are the early adopters who are quick to check out the latest movie, nightclub, laptop, and 
</p>
<p>microbrew.&rdquo; Members of this segment are between 25 and 44&nbsp;years old, have a midscale income, 
</p>
<p>own a hybrid vehicle, eat at Starbucks, and go skiing/snowboarding. (www.MyBestSegments.com).
</p>
<p>9</p>
<p/>
<div class="annotation"><a href="http://www.MyBestSegments.com">http://www.MyBestSegments.com</a></div>
</div>
<div class="page"><p/>
<p>9335
9.3 &middot; Conducting a Cluster Analysis
</p>
<p>Theory Action
</p>
<p>Select a measure 
</p>
<p>of (dis)similarity
</p>
<p>Hierarchical methods:
</p>
<p>► Analyze ► Classify ► Hierarchical Cluster ► Method ► Measure
</p>
<p>Depending on the scale level, select the measure;
</p>
<p>convert variables with multiple categories into a set of binary variables and 
</p>
<p>use matching coefficients; standardize variables if necessary (on a range of 
</p>
<p>0 to 1).
</p>
<p>k-means clustering:
</p>
<p>Uses Euclidean distances per default.
</p>
<p>Two-step clustering:
</p>
<p>► Analyze ► Classify ► Two-Step Cluster ► Distance Measure
</p>
<p>Use Euclidean distances when all variables are continuous; for mixed vari-
</p>
<p>ables, you have to use the log-likelihood.
</p>
<p>Deciding on 
</p>
<p>the number of 
</p>
<p>clusters
</p>
<p>Hierarchical clustering:
</p>
<p>Examine the dendrogram:
</p>
<p>► Analyze ► Classify ► Hierarchical Cluster ► Plots ►Dendrogram
</p>
<p>Draw a scree plot: Double-click on the Agglomeration Schedule in the 
output window, highlight all coefficients in the column and right-click the 
</p>
<p>mouse button. In the menu that opens up, select Create Graph ► Line
</p>
<p>Compute the VRC using an ANOVA:
</p>
<p>► Analyze ► Compare Means ► One-Way ANOVA
</p>
<p>Move the cluster membership variable in the Factor box and the clustering 
variables in the Dependent List box;
</p>
<p>Compute VRC for each segment solution and compare values.
</p>
<p>Include practical considerations in your decision.
</p>
<p>k-means:
</p>
<p>Run a hierarchical cluster analysis and decide on the number of segments 
</p>
<p>based on a dendrogram or scree plot; use this information to run k-means 
</p>
<p>with k clusters.
</p>
<p>Compute the VRC using an ANOVA:
</p>
<p>► Analyze ► Classify ► K-Means Cluster ► Options ►ANOVA table;
</p>
<p>Compute VRC for each segment solution and compare values.
</p>
<p>Include practical considerations in your decision.
</p>
<p>Two-step clustering:
</p>
<p>Specify the maximum number of clusters:
</p>
<p>► Analyze ► Classify ► Two-Step Cluster ►Number of Clusters
</p>
<p>Run separate analyses using the AIC and BIC as clustering criteria:
</p>
<p>► Analyze ► Classify ► Two-Step Cluster ► Clustering Criterion
</p>
<p>Examine the model summary output.
</p>
<p>Include practical considerations in your decision.
</p>
<p>. Table 9.11 (Continued)</p>
<p/>
</div>
<div class="page"><p/>
<p>336 Chapter 9 &middot; Cluster Analysis
</p>
<p>Theory Action
</p>
<p>Validating and interpreting the cluster solution
</p>
<p>Stability Re-run the analysis using different clustering procedures, algorithms or dis-
</p>
<p>tance measures.
</p>
<p>Change the order of objects in the dataset.
</p>
<p>Differentiation of 
</p>
<p>the data
</p>
<p>Compare the cluster centroids across the different clusters for significant 
</p>
<p>differences.
</p>
<p>If possible, assess the solution&rsquo;s criterion validity.
</p>
<p>Profiling Identify observable variables (e.g., demographics) that best mirror the parti-
</p>
<p>tion of the objects based on the clustering variables.
</p>
<p>Interpreting 
</p>
<p>of the cluster 
</p>
<p>solution
</p>
<p>Identify names or labels for each cluster and characterize each cluster using 
</p>
<p>observable variables.
</p>
<p>. Table 9.11 (Continued)
</p>
<p>9.4 Example
</p>
<p>Let&rsquo;s go back to the Oddjob Airways case study and run a cluster analysis on the data. Our 
aim is to identify a manageable number of segments that differentiates the customer base 
well. To do so, we first select a set of clustering variables, taking the sample size and poten-
tial collinearity issues into account. Next, we apply hierarchical clustering based on the 
squared Euclidean distances, using the Ward&rsquo;s linkage algorithm. This analysis will help 
us determine a suitable number of segments and a starting partition, which we will then 
use as the input for k-means clustering.
</p>
<p>9.4.1 Hierarchical Cluster Analysis
</p>
<p>9.4.1.1 Select the Clustering Variables
</p>
<p>The Oddjob Airways dataset (&darr; Web Appendix &rarr; Downloads) offers several variables for 
segmenting its customer base. Our analysis draws on the following set of variables, which 
we consider promising for identifying distinct segments based on customers&rsquo; expectations 
regarding the airline&rsquo;s service quality (variable names in parentheses):
</p>
<p> 4 With Oddjob Airways you will arrive on time (e1),
 4 Oddjob Airways provides you with a very pleasant travel experience (e5),
 4 Oddjob Airways gives you a sense of safety (e9),
 4 Oddjob Airways makes traveling uncomplicated (e21), and
 4 Oddjob Airways provides you with interesting on-board entertainment, service, and 
</p>
<p>information sources (e22).
</p>
<p>With five clustering variables, our analysis meets even the most conservative rule-of-thumb 
regarding minimum sample size requirements. Specifically, according to Dolnicar et al. 
</p>
<p>9</p>
<p/>
</div>
<div class="page"><p/>
<p>9337
9.4 &middot; Example
</p>
<p>. Fig.&nbsp;9.17 Bivariate correlations dialog box
</p>
<p>(2016), the cluster analysis should draw on 100 times the number of clustering variables to 
optimize cluster recovery. As our sample size of 1065 is clearly higher than 5&nbsp;&middot;&nbsp;100&nbsp;=&nbsp;500, we 
can proceed with the analysis. Note, however, that the actual sample size used in the analy-
sis may be substantially lower when using casewise deletion. This also applies to our analy-
sis, which draws on 969 objects (i.e., after casewise deletion) as we can see in . Table&nbsp;9.16.
</p>
<p>To begin with, we examine the variable correlations by clicking on ► Analyze ► Cor-
relate ► Bivariate. Next, enter the variables e1, e5, e9, e21, and e22 into the Variables box 
(. Fig.&nbsp;9.17). Click on OK and SPSS will display the results (. Table&nbsp;9.12).
</p>
<p>The results show that collinearity is not at a critical level. The variables e1 and e21 show 
the highest correlation of 0.613, which is clearly lower than the 0.90 threshold. We can 
therefore proceed with the analysis, using all five clustering variables.
</p>
<p>9.4.1.2 Select the Clustering Procedure and a Measure of Similarity 
or Dissimilarity
</p>
<p>To initiate hierarchical clustering, go to ► Analyze ► Classify ► Hierarchical Cluster, 
which opens a dialog box similar to . Fig.&nbsp;9.18.
</p>
<p>Move the variables e1, e5, e9, e21, and e22 into the Variable(s) box. The Statistics option 
gives us the opportunity to request the distance matrix (labeled proximity matrix in this 
case) and the agglomeration schedule, which provides information on the objects being 
combined at each stage of the clustering process. Furthermore, we can specify the number 
or range of clusters to retain from the data. As we do not yet know how many clusters to 
retain, just check the box Agglomeration schedule and continue.
</p>
<p>Under Plots, check the box Dendrogram to graphically display the distances at which 
objects and clusters are joined. SPSS also offers the option to display an Icicle diagram 
(All&nbsp;clusters), which is yet another graph for displaying clustering solutions. Its name stems </p>
<p/>
</div>
<div class="page"><p/>
<p>338 Chapter 9 &middot; Cluster Analysis
</p>
<p>. Table 9.12 Bivariate correlations output
</p>
<p>Correlations
</p>
<p>e1 e5 e9 e21 e22
</p>
<p>e1 Pearson 
</p>
<p> Correlation
</p>
<p>1 .515** .533** .613** .370**
</p>
<p>Sig. 
</p>
<p>(2-tailed)
</p>
<p>.000 .000 .000 .000
</p>
<p>N 1038 1026 1023 1018 997
</p>
<p>e5 Pearson 
</p>
<p> Correlation
</p>
<p>.515** 1 .525** .574** .530**
</p>
<p>Sig. 
</p>
<p>(2-tailed)
</p>
<p>.000 .000 .000 .000
</p>
<p>N 1026 1041 1023 1017 998
</p>
<p>e9 Pearson 
</p>
<p> Correlation
</p>
<p>.533** .525** 1 .522** .417**
</p>
<p>Sig. 
</p>
<p>(2-tailed)
</p>
<p>.000 .000 .000 .000
</p>
<p>N 1023 1023 1036 1016 996
</p>
<p>e21 Pearson 
</p>
<p> Correlation
</p>
<p>.613** .574** .522** 1 .425**
</p>
<p>Sig. 
</p>
<p>(2-tailed)
</p>
<p>.000 .000 .000 .000
</p>
<p>N 1018 1017 1016 1028 989
</p>
<p>e22 Pearson 
</p>
<p>Correlation
</p>
<p>.370** .530** .417** .425** 1
</p>
<p>Sig. 
</p>
<p>(2-tailed)
</p>
<p>.000 .000 .000 .000
</p>
<p>N 997 998 996 989 1012
</p>
<p>** Correlation is significant at the 0.01&nbsp;level (2-tailed).
</p>
<p>from the analogy to rows of icicles hanging from the eaves of a house. The diagram is read 
from the bottom to the top; the columns correspond to the objects being clustered, and 
the rows represent the number of clusters. Given the great number of objects, we do not 
request the icicle diagram in our example.
</p>
<p>The option Method allows us to specify the cluster method, the distance measure, and 
the type of standardization of values. Because of its versatility and general performance, 
we choose the Ward&rsquo;s method and Squared Euclidean distance as distance measure. Even 
though all the variables used in our analysis are measured on a scale from 0 to 100, we 
standardize the data to account for differences in the variables&rsquo; variances. To do so, go to 
the Transform Values drop-down menu and select Range 0 to 1.
</p>
<p>9</p>
<p/>
</div>
<div class="page"><p/>
<p>9339
9.4 &middot; Example
</p>
<p>. Fig.&nbsp;9.18 Hierarchical cluster analysis dialog box
</p>
<p>Finally, the Save option enables us to save cluster memberships for a single solution or 
a range of solutions. Saved variables can then be used in subsequent analyses to explore 
differences between groups. As a start, we will skip this option, so continue and click on 
OK in the main menu.
</p>
<p>9.4.1.3 Decide on the Number of Clusters
</p>
<p>First, we take a closer look at the agglomeration schedule (. Table&nbsp;9.13), which displays 
the objects or clusters combined at each stage (columns Cluster 1 and Cluster 2) and the 
distances at which this merger takes place (column Coefficients). Given the great number 
of objects, we limit the display of the agglomeration schedule to the merger stages 200 
to 210. The table shows that in stage 200, objects 133 and 684 are merged at a distance of 
0.046. From here onward, the resulting cluster is labeled as indicated by the first object 
involved in this merger, which is object 133. The last column on the very right tells you in 
which stage of the algorithm this cluster will appear next. In this case, this happens in in 
stage 350, where this object is merged with object 409&nbsp;at a distance of 0.359 (not shown).
</p>
<p>Next, we use the agglomeration schedule to determine the number of segments to 
retain from the data. To do so, we generate a scree plot by plotting the distances (Coeffi-
cients column in . Table&nbsp;9.13) against the number of clusters. The distinct break (elbow) 
indicates the solution regarding where an additional combination of two objects or clus-
ters would occur at a greatly increased distance. Thus, the number of clusters prior to this 
merger is the most probable solution. SPSS does not automatically provide this plot. To 
generate a scree plot we have to double-click the Agglomeration Schedule in the output 
window. Next, highlight all coefficients in the column and right-click the mouse button. 
In the menu that opens up, select Create Graph ► Line (. Fig.&nbsp;9.19). SPSS will add a line 
chart to the output, which represents the scree plot.
</p>
<p>The scree plot in . Fig.&nbsp;9.20 shows that there is no clear elbow indicating a suitable 
number of clusters to retain. This result is quite common for datasets with several hundred 
objects.</p>
<p/>
</div>
<div class="page"><p/>
<p>340 Chapter 9 &middot; Cluster Analysis
</p>
<p>. Fig.&nbsp;9.19 Generating a scree plot
</p>
<p>. Table 9.13 Agglomeration schedule (partial screenshot)
</p>
<p>Agglomeration Schedule
</p>
<p>Stage
</p>
<p>Cluster Combined
</p>
<p>Coefficients
</p>
<p>Stage Cluster First Appears
</p>
<p>Next StageCluster 1 Cluster 2 Cluster 1 Cluster 2
</p>
<p>&hellip; &hellip; &hellip; &hellip; &hellip; &hellip; &hellip;
</p>
<p>200 133 684 .046 0 119 350
</p>
<p>201 330 478 .047 91 0 429
</p>
<p>202 723 881 .048 0 0 391
</p>
<p>203 536 835 .049 0 0 319
</p>
<p>204 250 712 .050 0 0 257
</p>
<p>205 624 631 .051 0 0 363
</p>
<p>206 370 505 .052 0 0 427
</p>
<p>207 67 112 .053 0 0 370
</p>
<p>208 444 853 .054 0 83 362
</p>
<p>209 48 767 .055 0 0 325
</p>
<p>210 563 572 .057 0 112 385
</p>
<p>&hellip; &hellip; &hellip; &hellip; &hellip; &hellip; &hellip;
</p>
<p>9</p>
<p/>
</div>
<div class="page"><p/>
<p>9341
9.4 &middot; Example
</p>
<p>1
</p>
<p>0
</p>
<p>50
</p>
<p>100
</p>
<p>150
</p>
<p>V
a
</p>
<p>lu
e
</p>
<p>s
</p>
<p>Stage
</p>
<p>Agglomeration Schedule
</p>
<p>Coefficients
</p>
<p>200
</p>
<p>250
</p>
<p>51 101 151 201 251 301 351 401 451 501 551 601 651 701 751 801 851 901 951
</p>
<p>. Fig.&nbsp;9.20 Scree plot
</p>
<p>Next, we should take a look at the dendrogram. We don&rsquo;t display the dendrogram 
here because of the size of the dataset. Reading the dendrogram from left to right, we 
find that the vast majority of objects are merged at very small distances. The dendrogram 
also shows that the step from a three-cluster solution to a two-cluster solution occurs at a 
greatly increased distance. Hence, we assume a three-cluster solution and continue with 
the analysis.
</p>
<p>9.4.1.4 Validate and Interpret the Clustering Solution
</p>
<p>To get a first impression of the size and nature of the three clusters, let&rsquo;s re-run the hierar-
chical cluster analysis, but this time, we pre-specify the number of segments. To do so, go 
back to ► Analyze ► Classify ► Hierarchical Cluster and select the Save option. In the 
dialog box that opens, select Single solution and enter 3 next to Number of clusters. Click 
on Continue followed by OK. When running the analysis, SPSS generates the same output 
but also adds one additional variable to your dataset (CLU3_1), which reflect each object&rsquo;s 
cluster membership. SPSS automatically places CLU in front, followed by a 3 to identify 
the total number of clusters. The variable's values (1, 2, and 3) identify each object&rsquo;s cluster 
membership.
</p>
<p>To learn about the size of the clusters, go to ► Analyze ► Descriptive Statistics ► Fre-
quencies and enter CLU3_1 into the Variable(s) box. When clicking on OK, SPSS will open 
an output similar to . Table&nbsp;9.14.</p>
<p/>
</div>
<div class="page"><p/>
<p>342 Chapter 9 &middot; Cluster Analysis
</p>
<p>The output in . Table&nbsp;9.14 shows that the cluster analysis assigned 969 objects to the 
three segments; 96 objects were not assigned to any segment due to missing values. The 
first cluster is the largest among the three clusters with 516 objects, which translates into 
a relative cluster size of 53.3&nbsp;%. Clusters 2 and 3 are smaller and similar in size with 238 
and 215 objects, respectively.
</p>
<p>Next, we would like to compute the centroids of our clustering variables. To do so, 
split up the dataset using the Split File command (► Data ► Split File) (see 7 Chap. 5). 
Choose CLU3_1 as the grouping variable and select the option Compare groups. Next, go to 
►&nbsp;Analyze ► Descriptive Statistics ► Descriptives (see 7 Chap. 5) and request the mean, 
minimum, and maximum, as well as the standard deviations for the clustering variables 
e1, e5, e9, e21, and e22. . Table&nbsp;9.15 shows the resulting output. The first column in the 
table indicates the cluster number with the first element (labeled with a dot) representing 
the group of missing values. However, we focus our analysis of the results on the first three 
groups and particularly the clustering variables&rsquo; mean values.
</p>
<p>Comparing the variable means across the three clusters, we find that respondents 
in the first cluster have extremely high expectations regarding all five performance fea-
tures, as evidenced in average values of around 90 and higher. Respondents in the second 
cluster strongly emphasize punctuality (e1), while comfort (e5) and, particularly, enter-
tainment aspects (e22) are less important. Finally, respondents in the third cluster do 
not express high expectations in general, except in terms of security (e9). Based on these 
results, we could label the first cluster &ldquo;the demanding traveler,&rdquo; the second cluster &ldquo;on-
time is enough,&rdquo; and the third cluster &ldquo;no thrills.&rdquo; We could further check whether these 
differences in means are significant by using a one-way ANOVA as described in 7 Chap. 6.
</p>
<p>In a further step, we can try to profile the clusters using sociodemographic variables. 
Specifically, we use crosstabs (see 7 Chap. 5) to contrast our clustering with the vari-
able flight_purpose, which indicates whether the respondents primarily fly for business 
purposes (flight_purpose&nbsp;=&nbsp;1) or private purposes (flight_purpose&nbsp;=&nbsp;2). Before doing so, 
we need to turn off the Split File command by going to ► Data ► Split File and click-
ing on Analyze all cases, do not create groups, followed by OK. Next, click on ► Analyze 
►&nbsp;Descriptive Statistics ► Crosstabs. In the dialog box that opens, enter CLU3_1 into the 
</p>
<p>. Table 9.14 Frequencies
</p>
<p>CLU3_1
</p>
<p>Frequency Percent Valid Percent
</p>
<p>Cumulative  
</p>
<p>Percent
</p>
<p>Valid 1 516 48.5 53.3 53.3
</p>
<p>2 238 22.3 24.6 77.8
</p>
<p>3 215 20.2 22.2 100.0
</p>
<p>Total 969 91.0 100.0
</p>
<p>Missing System 96 9.0
</p>
<p>Total 1065 100.0
</p>
<p>9</p>
<p/>
</div>
<div class="page"><p/>
<p>9343
9.4 &middot; Example
</p>
<p>. Table 9.15 Descriptive statistics
</p>
<p>Descriptive Statistics
</p>
<p>CLU3_1 N Minimum Maximum Mean Std. Deviation
</p>
<p>. e1 69 2 100 79.09 23.522
</p>
<p>e5 72 1 100 70.65 26.768
</p>
<p>e9 67 43 100 81.99 18.709
</p>
<p>e21 59 1 100 71.47 27.555
</p>
<p>e22 43 2 100 61.35 23.931
</p>
<p>Valid N (listwise) 0
</p>
<p>1 e1 516 69 100 95.13 7.202
</p>
<p>e5 516 25 100 86.98 14.519
</p>
<p>e9 516 28 100 94.38 10.035
</p>
<p>e21 516 50 100 89.89 11.507
</p>
<p>e22 516 50 100 87.61 12.195
</p>
<p>Valid N (listwise) 516
</p>
<p>2 e1 238 53 100 92.58 9.165
</p>
<p>e5 238 5 100 76.65 20.048
</p>
<p>e9 238 19 100 89.77 15.189
</p>
<p>e21 238 1 100 83.37 17.343
</p>
<p>e22 238 1 75 47.16 15.865
</p>
<p>Valid N (listwise) 238
</p>
<p>3 e1 215 1 100 59.42 21.327
</p>
<p>e5 215 1 100 58.28 19.658
</p>
<p>e9 215 1 100 71.63 20.414
</p>
<p>e21 215 1 100 56.73 19.303
</p>
<p>e22 215 2 100 58.03 20.175
</p>
<p>Valid N (listwise) 215
</p>
<p>Row(s) box and flight_purpose into the Column(s) box. Also click on Statistics and select 
Chi-square and Contingency coefficient and click on Continue followed by OK. The results 
in . Table&nbsp;9.16 show that the first cluster primarily consists of leisure travelers, whereas the 
majority of respondents in the second and third cluster are business travelers. With a p-
value of 0.003, the χ
</p>
<p>2
-test statistic indicates a significant relationship between these two 
</p>
<p>variables. However, the strength of the variables&rsquo; association is rather small, as indicated 
by the Contingency Coefficient of 0.108.</p>
<p/>
</div>
<div class="page"><p/>
<p>344 Chapter 9 &middot; Cluster Analysis
</p>
<p>The Oddjob Airways dataset offers various other variables such as age, gender, or status, 
which could be used to further profile the cluster solution. However, instead of testing these 
variables&rsquo; efficacy step-by-step, we proceed and assess the solution&rsquo;s stability by running 
an alternative clustering procedure on the data. Specifically, we apply k-means clustering, 
using the cluster centers produced by the Ward&rsquo;s linkage analysis as input for the starting 
partition, instead of letting k-means choose the centers.
</p>
<p>To do so, we need to do some data management in SPSS, as the cluster centers have 
to be supplied in a specific format. Specifically, we need to aggregate the data first (briefly 
introduced in 7 Chap.&nbsp;5). By going to ► Data ► Aggregate, SPSS opens a dialog box 
similar to .&nbsp;Fig.&nbsp;9.21. Proceed by entering CLU3_1 into the Break Variable(s) box as well 
as e1, e5, e9, e21, and e22 into the Aggregated Variables box. When using the default set-
tings, SPSS computes the variables&rsquo; mean values along the lines of the break variable, which 
correspond to the cluster centers that we need for the k-means clustering. SPSS indicates 
this circumstance by the postifix _mean, added to each aggregate variable&rsquo;s name. For k-
means to process the cluster centers, we need to delete the postfix _mean using the Name 
</p>
<p>. Table 9.16 Crosstab
</p>
<p>CLU3_1 * flight_purpose Crosstabulation
</p>
<p>Count
</p>
<p>flight_purpose
</p>
<p>Total1 2
</p>
<p>CLU3_1 1 232 284 516
</p>
<p>2 137 101 238
</p>
<p>3 114 101 215
</p>
<p>Total 483 486 969
</p>
<p>Chi-Square Tests
</p>
<p>Value df Asymptotic Significance (2-sided)
</p>
<p>Pearson Chi-Square 11.463a 2 .003
</p>
<p>Likelihood Ratio 11.493 2 .003
</p>
<p>Linear-by-Linear Association 6.432 1 .011
</p>
<p>N of Valid Cases 969
</p>
<p>a 0 cells (0.0%) have expected count less than 5. The minimum expected count is 107.17.
</p>
<p>Symmetric Measures
</p>
<p>Value Approximate Significance
</p>
<p>Nominal by Nominal Contingency Coefficient .108 .003
</p>
<p>N of Valid Cases 969
</p>
<p>9</p>
<p/>
</div>
<div class="page"><p/>
<p>9345
9.4 &middot; Example
</p>
<p>. Fig.&nbsp;9.21 Aggregate data dialog box
</p>
<p>&amp; Label. Finally, we do not want to add the aggregated variables to the active dataset, but 
rather need to create a new dataset comprising only the aggregated variables. Hence, select 
Create a new dataset containing only the aggregated variables and specify a dataset label 
such as aggregate (.&nbsp;Fig.&nbsp;9.21). When clicking on OK, SPSS creates and opens a new dataset 
labeled aggregate.
</p>
<p>The new dataset is almost in the right format&mdash;but we still need to change the break 
variable&rsquo;s name from CLU3_1 to cluster_. SPSS will issue a warning but this can be safely 
ignored. Furthermore, we need to delete the first object, which includes the cluster centers 
of the missing values. The final dataset should have the form shown in . Fig.&nbsp;9.22.
</p>
<p>Everything is now set for the k-means cluster analysis. To run the analysis, select the 
original dataset Oddjob.sav and go to ► Analyze ► Classify ► K-Means Cluster. In the 
dialog box that opens (. Fig.&nbsp;9.23), first move the five clustering variables into the Variables 
box. To use the cluster centers from our previous analysis, check the box Read initial and 
click on Open dataset. You can now choose the dataset labeled aggregate. In the Number of 
Clusters box, specify 3, which corresponds to the result of the hierarchical cluster analysis. </p>
<p/>
</div>
<div class="page"><p/>
<p>346 Chapter 9 &middot; Cluster Analysis
</p>
<p>. Fig.&nbsp;9.23 k-means cluster analysis dialog box
</p>
<p>Next, click on Save and check the box Cluster Membership in order to create a new vari-
able indicating each object&rsquo;s cluster membership as produced by k-means clustering. 
Under Options, you can request several statistics and specify how missing values should 
be treated. Ensure to request the Initial cluster centers as well as the ANOVA table. Now 
start the analysis.
</p>
<p>The k-means procedure generates . Tables&nbsp;9.17 and 9.18, which show the initial and 
final cluster centers. As we can see, there is a high degree of agreement between the initial 
cluster centers produced by the Ward&rsquo;s linkage and the final cluster centers produced by 
k-means clustering. While some cluster centers changed (also indicated in the Iteration 
History output, not shown here), the clusters&rsquo; nature, as expressed by the cluster labels &ldquo;the 
demanding traveler,&rdquo; &ldquo;on-time is enough,&rdquo; and &ldquo;no thrills,&rdquo; remains intact.
</p>
<p>To further check for the solution&rsquo;s stability, we next explore the overlap in the two 
cluster solutions, by contrasting the objects&rsquo; cluster affiliations using crosstabs. To do so, 
go to ► Analyze ► Descriptive Statistics ► Crosstabs and select CLU3_1 under Row(s) 
</p>
<p>. Fig.&nbsp;9.22 Aggregated data file
</p>
<p>9</p>
<p/>
</div>
<div class="page"><p/>
<p>9347
9.4 &middot; Example
</p>
<p>. Table 9.17 Initial cluster centers
</p>
<p>Initial Cluster Centers
</p>
<p>Cluster
</p>
<p>1 2 3
</p>
<p>e1 95 93 59
</p>
<p>e5 87 77 58
</p>
<p>e9 94 90 72
</p>
<p>e21 90 83 57
</p>
<p>e22 88 47 58
</p>
<p>Input from FILE Subcommand
</p>
<p>. Table 9.18 Final cluster centers
</p>
<p>Final Cluster Centers
</p>
<p>Cluster
</p>
<p>1 2 3
</p>
<p>e1 95 90 59
</p>
<p>e5 92 74 55
</p>
<p>e9 96 90 67
</p>
<p>e21 92 81 54
</p>
<p>e22 91 55 54
</p>
<p>. Table 9.19 Comparison of clustering results
</p>
<p>CLU3_1 * QCL_1&nbsp;Crosstabulation
</p>
<p>Count
</p>
<p>QCL_1
</p>
<p>Total1 2 3
</p>
<p>CLU3_1 1 410 100 6 516
</p>
<p>2 14 213 11 238
</p>
<p>3 10 36 169 215
</p>
<p>Total 434 349 186 969
</p>
<p>and QCL_1 under Column(s). The latter variable represents the objects&rsquo; cluster affiliations 
as produced by the k-means clustering. After clicking on OK, SPSS will produce an output 
similar to . Table&nbsp;9.19.</p>
<p/>
</div>
<div class="page"><p/>
<p>348 Chapter 9 &middot; Cluster Analysis
</p>
<p>The results show that there is a strong degree of overlap between the two cluster anal-
yses. For example, 410 objects that fall into the first cluster in the Ward&rsquo;s linkage analysis 
also fall into this cluster in the k-means clustering. At the same time, however, 100 objects 
now appear in the second k-means cluster. This divergence is considerably lower in the 
second and third cluster. Overall, the two analyses have an overlap of (410&nbsp;+&nbsp;213&nbsp;+&nbsp;169)/
969&nbsp;=&nbsp;81.73&nbsp;%, which is very satisfactory as less than 20&nbsp;% of all objects appear in a differ-
ent cluster when using k-means.
</p>
<p>In contrast to hierarchical clustering, the k-means outputs provide us with an ANOVA 
of the cluster centers (. Table&nbsp;9.20). Since all the values in the final column Sig. are below 
0.05, we can conclude that all the clustering variables&rsquo; means differ significantly across at 
least two of the three segments.
</p>
<p>Since we used the prior analysis results from hierarchical clustering as an input for the 
k-means procedure, the problem of selecting the correct number of segments is not prob-
lematic in this example. Complementing our prior analyses, we now compute the VRC for 
different numbers of clusters based on the k-means results. Specifically, we want use the 
VRC values to compute the ωk statistics for a three-, four-, and five-cluster solution. Since 
determining a suitable number clusters using the ωk statistic involves comparing the VRC 
values of solutions with one segment less than k and with one cluster more than k, we need 
to run k-means for a two- to six-cluster solution. To do so, go back to ► Analyze ► Clas-
sify ► K-Means Cluster. As we seek to run k-means with different numbers of clusters, we 
cannot use the initial cluster centers from the Ward&rsquo;s linkage clustering. Hence, uncheck 
the box next to Read initial. Next, set the Number of Clusters to 2, run the analysis, and save 
the F-values for variables e1, e5, e9, e21, and e22 from the ANOVA table, which correspond 
to the VRC values. Repeat these steps for a three-, four-, five- and six-cluster solution, each 
time saving the F-values. . Table&nbsp;9.21 summarizes the F-values from the ANOVA tables.
</p>
<p>To compute the ωk statistic, we enter the F-values&mdash;which again, correspond to the 
VRC values&mdash;from . Table&nbsp;9.21 into the following formula:
</p>
<p>ωk k k k kVRC VRC VRC VRC= &minus; &minus; &minus;+( ) ( ).1 1-  
</p>
<p>. Table 9.20 ANOVA output
</p>
<p>ANOVA
</p>
<p>Cluster Error
</p>
<p>F Sig.Mean Square df Mean Square df
</p>
<p>e1 91964.042 2 170.733 966 538.643 .000
</p>
<p>e5 94966.114 2 230.012 966 412.875 .000
</p>
<p>e9 58156.159 2 164.349 966 353.857 .000
</p>
<p>e21 96081.135 2 202.743 966 473.905 .000
</p>
<p>e22 158600.747 2 227.709 966 696.508 .000
</p>
<p>The F tests should be used only for descriptive purposes because the clusters have been chosen 
</p>
<p>to maximize the differences among cases in different clusters. The observed significance levels 
</p>
<p>are not corrected for this and thus cannot be interpreted as tests of the hypothesis that the 
</p>
<p>cluster means are equal.
</p>
<p>9</p>
<p/>
</div>
<div class="page"><p/>
<p>9349
9.4 &middot; Example
</p>
<p>For example, for a three-cluster solution, we compute
</p>
<p>ω3 2 158 417 2 460 116 2 460 116 3 048 191 286 376= &minus;( )&minus; &minus;( )=, . , . , . , . .  
</p>
<p>Similarly, we can compute ωk for four and five clusters resulting in ω4=&nbsp;72.794 and 
ω5=&nbsp;10.674, respectively. Comparing the values, we find that the minimum ωk results for 
a five-cluster solution. However, looking into the cluster sizes of a five-cluster solution, 
shows that one cluster contains only 15 objects, which calls the relevance of this cluster 
into question. Similarly, when using a four-cluster solution, one cluster contains only 60 
objects. Hence, it appears more reasonable to retain the three-cluster solution.
</p>
<p>This analysis concludes our cluster analysis. However, we could further explore the 
solution&rsquo;s stability by running other linkage algorithms, such as centroid or complete 
linkage, on the data. Relatedly, we could use different (dis)similarity measures and assess 
their impact on the results. So go ahead and explore these options yourself!
</p>
<p>9.4.2 Two-Step Clustering
</p>
<p>In the  last step of the analysis, we run two-step clustering on the data. As two-step cluster-
ing allows handling segmentation variables measured on different scale levels, we extend 
the prior set and now also consider gender as an additional (categorical) segmentation 
variable. To initiate the analysis, go to ► Analyze ► Classify ► Two-Step Cluster. A new 
dialog box opens, similar to that shown in . Fig.&nbsp;9.24. First, move gender into the Categor-
ical Variables box and e1, e5, e9, e21, and e22 into the Continuous Variables box.
</p>
<p>Under Distance Measure we can choose between two options. While Log-likelihood can 
be used for categorical and continuous variables, the Euclidean distance requires variables 
measured on a continuous scale. Since our analysis contains both categorical and contin-
uous variables, we have to use the Log-likelihood distance measure.
</p>
<p>Under Number of Clusters, we can specify a fixed number or a maximum number of 
clusters to retain from the data. One of two-step clustering&rsquo;s major advantages is that it 
allows the automatic selection of the number of clusters on the grounds of information 
</p>
<p>. Table 9.21 F-values for different numbers of clusters
</p>
<p>F-values
</p>
<p>Number of clusters k
</p>
<p>2 3 4 5 6
</p>
<p>e1 448.182 555.639 425.992 391.870 474.269
</p>
<p>e5 830.757 458.807 306.988 272.402 290.935
</p>
<p>e9 456.818 373.290 264.142 237.495 186.223
</p>
<p>e21 734.041 490.399 453.413 479.337 312.860
</p>
<p>e22 578.393 581.981 707.882 548.408 446.994
</p>
<p>Total 3,048.191 2,460.116 2,158.417 1,929.512 1,711.281</p>
<p/>
</div>
<div class="page"><p/>
<p>350 Chapter 9 &middot; Cluster Analysis
</p>
<p>. Fig.&nbsp;9.24 Two-step cluster analysis dialog box
</p>
<p>criteria. In line with our previous analyses, we specify a maximum number of 5&nbsp;clusters. 
Under Clustering Criterion, select Schwarz&rsquo;s Bayesian Criterion (BIC) but to test the stabil-
ity of the solution, we will re-run the analysis using Akaike&rsquo;s Information Criterion (AIC).
</p>
<p>Under Options, we can select options related to outlier treatment, memory allocation, 
and variable standardization. Variables that are already standardized have to be assigned 
as such, but since this is not the case in our analysis, we can simply proceed.
</p>
<p>Finally, under Output, we can specify additional variables for describing the resulting 
clusters. Select Create cluster membership variable and click on Continue followed by OK.
</p>
<p>SPSS produces a very simple output, as shown in . Fig.&nbsp;9.25. The upper part of the 
output describes the algorithm applied, the number of variables used (labeled input fea-
tures) and the final number of clusters retained from the data. In our case, the number of 
clusters is chosen according to BIC, which indicates a three-segment solution (the same 
holds when using AIC instead of BIC).
</p>
<p>The lower part of the output (. Fig.&nbsp;9.25) indicates the quality of the cluster solution. 
The silhouette measure of cohesion and separation reaches a value of less than 0.50, indi-
cating a fair cluster quality. We proceed with the analysis by double-clicking on the output. 
This will open up the model viewer (. Fig.&nbsp;9.26), an evaluation tool that graphically pres-
ents the structure of the revealed clusters.
</p>
<p>The model viewer provides us with two windows: The main view, which initially 
shows a model summary (left-hand side), and an auxiliary view, which initially features 
</p>
<p>9</p>
<p/>
</div>
<div class="page"><p/>
<p>9351
9.4 &middot; Example
</p>
<p>Model Summary
</p>
<p>Algorithm
</p>
<p>Inputs
</p>
<p>TwoStep
</p>
<p>6
</p>
<p>3
</p>
<p>&ndash;1.0 &ndash;0.5 0.0 0.5 1.0
</p>
<p>Poor Fair Good
</p>
<p>Clusters
</p>
<p>Cluster Quality
</p>
<p>Silhouette measure of cohesion and separation
</p>
<p>. Fig.&nbsp;9.25 Two-step cluster analysis output
</p>
<p>. Fig.&nbsp;9.26 Additional options in the model viewer
</p>
<p>the cluster sizes (right-hand side). At the bottom of each window (next to View), you 
can request different information on each of the clusters. To further analyze the clus-
ters, select Clusters in the main view and Predictor Importance in the auxiliary view 
(.&nbsp;Fig.&nbsp;9.26).</p>
<p/>
</div>
<div class="page"><p/>
<p>352 Chapter 9 &middot; Cluster Analysis
</p>
<p>On the left of . Fig&nbsp;9.26, we can now see a description of the three clusters, including 
their (relative) sizes. We find that the first cluster contains 40.2&nbsp;% of the objects, the second 
cluster 33.5&nbsp;% of the objects, and the third cluster contains 26.2&nbsp;% of the objects. Further 
below, the output shows the distribution of the gender variable in each cluster. Moving 
the mouse over the boxes showing the clustering variable labels, SPSS shows their mean 
values as well as their relative importance in terms of predicting each object&rsquo;s member-
ship per cluster. Darker shades (i.e., higher values in feature importance) denote the vari-
able&rsquo;s greater importance for the clustering solution. Comparing the results, we learn that 
gender is by far the most important variable for each of the clusters, followed by e5 (&ldquo;Oddjob 
Airways provides you with a very pleasant travel experience&rdquo;), e21 (&ldquo;Oddjob Airways 
makes traveling uncomplicated&rdquo;), e9 (&ldquo;Oddjob Airways gives you a sense of safety&rdquo;), e22 
(&ldquo;Oddjob Airways provides you with interesting on-board entertainment, service, and 
information sources&rdquo;), and e1 (&ldquo;with Oddjob Airways you will arrive on time&rdquo;).6&nbsp;Click-
ing on one of the boxes will show a graph with the frequency distribution of each cluster.
</p>
<p>The auxiliary view on the right-hand side shows an overview of the variables&rsquo; overall 
importance for predicting the clustering solution (i.e., across all clusters). The model viewer 
provides us with additional options for visualizing the results or comparing clustering solu-
tions. It is worthwhile to simply play around with the different self-explanatory options. 
So go ahead and explore the model viewer&rsquo;s features yourself!
</p>
<p>9.5 Oh, James! (Case Study)
</p>
<p>The James Bond movie series is one of the success stories of filmmaking. The movies are the 
</p>
<p>longest continually running and the third-highest-grossing film series to date, which started in 
</p>
<p>1962&nbsp;with Dr. No, starring Sean Connery as James Bond. As of 2018, there have been 24&nbsp;movies 
</p>
<p>with six actors having played James Bond. Interested in the factors that contributed to this 
</p>
<p>running success, you decide to investigate the different James Bond movies&rsquo; characteristics. 
</p>
<p>Specifically, you want to find out whether the movies can be grouped into clusters, which 
</p>
<p>differ in their box-office revenues. To do so, you draw on Internet Movie Database (www.imdb.
</p>
<p>com) and collect data on all 24&nbsp;movies based on the following variables (variable names in 
</p>
<p>parentheses):
</p>
<p> 5 Title. (title)
 5 Actor playing James Bond. (actor)
 5 Year of publication. (year)
 5 Budget in USD, adjusted for inflation. (budget)
 5 Box-office revenues in the USA, adjusted for inflation. (gross_usa)
 5 Box-office revenues worldwide, adjusted for inflation. (gross_worldwide)
 5 Runtime in minutes. (runtime)
 5 Native country of the villain actor. (villain_country)
 5 Native country of the bondgirl. (bondgirl_country)
</p>
<p>Case Study
</p>
<p>6 The strong emphasis of gender in determining the solution supports prior research, which found 
</p>
<p>that two-step clustering puts greater emphasis on categorical variables in the results computation 
</p>
<p>(Bacher et al. 2004).
</p>
<p>9</p>
<p/>
<div class="annotation"><a href="http://www.imdb.com">http://www.imdb.com</a></div>
<div class="annotation"><a href="http://www.imdb.com">http://www.imdb.com</a></div>
</div>
<div class="page"><p/>
<p>9353
References
</p>
<p>9.6 Review Questions
</p>
<p>1. In your own words, explain the objective and basic concept of cluster analysis.
2. What are the differences between hierarchical and partitioning methods? When do 
</p>
<p>we use hierarchical or partitioning methods?
3. Repeat the manual calculations of the hierarchical clustering procedure from 
</p>
<p>the beginning of the chapter, but use complete linkage as the clustering method. 
Compare the results with those of the single linkage method.
</p>
<p>4. Explain the different options to decide on the number of clusters to extract from the 
data. Should you rather on statistical measures or rather on practical reasoning?
</p>
<p>5. Run the two-step clustering analysis on the Oddjob Airways data again (Oddjob.
sav, &darr; Web Appendix &rarr; Downloads) but with a prespecified number of four and five 
clusters. Compare your results with the original three-cluster solution.
</p>
<p>6. Which clustering variables could be used to segment:
 4 The market for smartphones?
 4 The market for chocolate?
 4 The market for car insurances?
</p>
<p>References
</p>
<p>Akaike, H. (1973). Information theory and an extension of the maximum likelihood principle. In B. N. 
</p>
<p>Petrov &amp; F. Cs&aacute;ki (Eds.), Selected papers of Hirotugu Akaike (pp. 199&ndash;213). New York: Springer.
</p>
<p>Arabie, P., &amp; Hubert, L. (1994). Cluster analysis in marketing research. In R. P. Bagozzi (Ed.), Advanced meth-
</p>
<p>ods in marketing research (pp. 160&ndash;189). Cambridge: Basil Blackwell &amp; Mott, Ltd.
</p>
<p>Arthur, D., &amp; Vassilvitskii, S. (2007). k-means++: The advantages of careful seeding. Proceedings of the 18th 
</p>
<p>annual ACM-SIAM symposium on discrete algorithms. Society for Industrial and Applied Mathematics 
</p>
<p>Philadelphia, PA, USA, pp. 1027&ndash;1035.
</p>
<p>Bacher, J., Wenzig, K., &amp; Vogler, M. (2004). SPSS TwoStep Cluster &ndash; A first evaluation. Arbeits- und Diskus-
</p>
<p>sionspapiere/Universit&auml;t Erlangen-N&uuml;rnberg, Sozialwissenschaftliches Institut, Lehrstuhl f&uuml;r Soziolo-
</p>
<p>gie, 2004-2. http://www.ssoar.info/ssoar/handle/document/32715.
</p>
<p>Becker, J.-M., Ringle, C. M., Sarstedt, M., &amp; V&ouml;lckner, F. (2015). How collinearity affects mixture regression 
</p>
<p>results. Marketing Letters, 26(4), 643&ndash;659.
</p>
<p>Caliński, T., &amp; Harabasz, J. (1974). A dendrite method for cluster analysis. Communications in Statistics&mdash;
</p>
<p>Theory and Methods, 3(1), 1&ndash;27.
</p>
<p> 5 Haircolor of the bondgirl. (bondgirl_hair)
</p>
<p>Use the dataset James Bond.sav (&darr; Web Appendix &rarr; Downloads) to run a cluster analysis&mdash;
despite potential objections regarding the sample size. Answer the following questions:
</p>
<p>1. Which clustering variables would you choose in light of the study objective, their levels of 
</p>
<p>measurement, and correlations?
</p>
<p>2. Given the levels of measurement, which clustering method would you prefer? Carry out a 
</p>
<p>cluster analysis using this procedure.
</p>
<p>3. Interpret and profile the obtained clusters by examining cluster centroids. Compare the 
</p>
<p>differences across clusters on the box-office revenue variables.
</p>
<p>4. Use a different clustering method to test the stability of your results.</p>
<p/>
<div class="annotation"><a href="http://www.ssoar.info/ssoar/handle/document/32715">http://www.ssoar.info/ssoar/handle/document/32715</a></div>
</div>
<div class="page"><p/>
<p>354 Chapter 9 &middot; Cluster Analysis
</p>
<p>Chiu, T., Fang, D., Chen, J., Wang, Y., &amp; Jeris, C. (2001). A robust and scalable clustering algorithm for mixed 
</p>
<p>type attributes in large database environment. Proceedings of the 7th ACM SIGKDD international con-
</p>
<p>ference in knowledge discovery and data mining. Association for Computing Machinery, San Francisco, 
</p>
<p>CA, USA, pp. 263&ndash;268
</p>
<p>Dolnicar, S. (2003). Using cluster analysis for market segmentation&mdash;typical misconceptions, established 
</p>
<p>methodological weaknesses and some recommendations for improvement. Australasian Journal of 
</p>
<p>Market Research, 11(2), 5&ndash;12.
</p>
<p>Dolnicar, S., &amp; Gr&uuml;n, B. (2009). Challenging &ldquo;factor-cluster segmentation&rdquo;. Journal of Travel Research, 47(1), 
</p>
<p>63&ndash;71.
</p>
<p>Dolnicar, S., &amp; Lazarevski, K. (2009). Methodological reasons for the theory/practice divide in market seg-
</p>
<p>mentation. Journal of Marketing Management, 25(3&ndash;4), 357&ndash;373.
</p>
<p>Dolnicar, S., Gr&uuml;n, B., Leisch, F., &amp; Schmidt, F. (2014). Required sample sizes for data-driven market seg-
</p>
<p>mentation analyses in tourism. Journal of Travel Research, 53(3), 296&ndash;306.
</p>
<p>Dolnicar, S., Gr&uuml;n, B., &amp; Leisch, F. (2016). Increasing sample size compensates for data problems in seg-
</p>
<p>mentation studies. Journal of Business Research, 69(2), 992&ndash;999.
</p>
<p>Kaufman, L., &amp; Rousseeuw, P. J. (2005). Finding groups in data. An introduction to cluster analysis. Hoboken, 
</p>
<p>NY: Wiley.
</p>
<p>Kotler, P., &amp; Keller, K. L. (2015). Marketing management (15th ed.). Upper Saddle River, NJ: Prentice Hall.
</p>
<p>Lilien, G. L., &amp; Rangaswamy, A. (2004). Marketing engineering. Computer-assisted marketing analysis and 
</p>
<p>planning (2nd ed.). Bloomington: Trafford Publishing.
</p>
<p>Milligan, G. W., &amp; Cooper, M. (1988). A study of variable standardization. Journal of Classification, 5(2), 
</p>
<p>181&ndash;204.
</p>
<p>Park, H.-S., &amp; Jun, C.-H. (2009). A simple and fast algorithm for K-medoids clustering. Expert Systems with 
</p>
<p>Applications, 36(2), 3336&ndash;3341.
</p>
<p>Punj, G., &amp; Stewart, D. W. (1983). Cluster analysis in marketing research: Review and suggestions for appli-
</p>
<p>cation. Journal of Marketing Research, 20(2), 134&ndash;148.
</p>
<p>Qiu, W., &amp; Joe, H. (2009). clusterGeneration: Random cluster generation (with specified degree of separa-
</p>
<p>tion). R package version 1.2.7. https://cran.r-project.org/web/packages/clusterGeneration/cluster-
</p>
<p>Generation.pdf. Accessed 04 May 2018.
</p>
<p>Roberts, J. H., Kayande, U. K., &amp; Stemersch, S. (2014). From academic research to marketing practice: 
</p>
<p>Exploring the marketing science value chain. International Journal of Research in Marketing, 31(2), 
</p>
<p>127&ndash;140.
</p>
<p>Schwarz, G. (1978). Estimating the dimension of a model. The Annals of Statistics, 6(2), 461&ndash;464.
</p>
<p>Sheppard, A. (1996). The sequence of factor analysis and cluster analysis: Differences in segmentation 
</p>
<p>and dimensionality through the use of raw and factor scores. Tourism Analysis, 1, 49&ndash;57.
</p>
<p>Tonks, D. G. (2009). Validity and the design of market segments. Journal of Marketing Management, 
</p>
<p>25(3/4), 341&ndash;356.
</p>
<p>Wedel, M., &amp; Kamakura, W. A. (2000). Market segmentation: Conceptual and methodological foundations 
</p>
<p>(2nd ed.). Boston, NJ: Kluwer Academic.
</p>
<p>Van Der Kloot, W. A., Spaans, A. M. J., &amp; Heinser, W. J. (2005). Instability of hierarchical cluster analysis due 
</p>
<p>to input order of the data: The PermuCLUSTER solution. Psychological Methods, 10(4), 468&ndash;476.
</p>
<p>Further Reading
</p>
<p>Bottomley, P., &amp; Nairn, A. (2004). Blinded by science: The managerial consequences of inadequately vali-
</p>
<p>dated cluster analysis solutions. International Journal of Market Research, 46(2), 171&ndash;187.
</p>
<p>Dolnicar, S., Gr&uuml;n, B., &amp; Leisch, F. (2016). Increasing sample size compensates for data problems in seg-
</p>
<p>mentation studies. Journal of Business Research, 69(2), 992&ndash;999.
</p>
<p>Dolnicar, S., &amp; Leisch, F. (2017). Using segment level stability to select target segments in data-driven mar-
</p>
<p>ket segmentation studies. Marketing Letters, 28(3), 423&ndash;436.
</p>
<p>Ernst, D., &amp; Dolnicar, S. (2017). How to avoid random market segmentation solutions. Journal of Travel 
</p>
<p>Research, &nbsp;57(1), 69&ndash;82.
</p>
<p>Punj, G., &amp; Stewart, D. W. (1983). Cluster analysis in marketing research: Review and suggestions for appli-
</p>
<p>cation. Journal of Marketing Research, 20(2), 134&ndash;148.
</p>
<p>Romesburg, C. (2004). Cluster analysis for researchers. Morrisville: Lulu Press.
</p>
<p>Wedel, M., &amp; Kamakura, W. A. (2000). Market segmentation: Conceptual and methodological foundations 
</p>
<p>(2nd ed.). Boston: Kluwer Academic.
</p>
<p>9</p>
<p/>
<div class="annotation"><a href="https://cran.r-project.org/web/packages/clusterGeneration/clusterGeneration.pdf">https://cran.r-project.org/web/packages/clusterGeneration/clusterGeneration.pdf</a></div>
<div class="annotation"><a href="https://cran.r-project.org/web/packages/clusterGeneration/clusterGeneration.pdf">https://cran.r-project.org/web/packages/clusterGeneration/clusterGeneration.pdf</a></div>
</div>
<div class="page"><p/>
<p>355
</p>
<p>Communicating the Results
</p>
<p>10.1 Introduction &ndash; 356
</p>
<p>10.2 Identify the Audience &ndash; 356
</p>
<p>10.3 Guidelines for Written Reports &ndash; 357
</p>
<p>10.4 Structure of the Written Report &ndash; 358
10.4.1 Title Page &ndash; 359
</p>
<p>10.4.2 Executive Summary &ndash; 359
</p>
<p>10.4.3 Table of Contents &ndash; 360
</p>
<p>10.4.4 Introduction &ndash; 360
</p>
<p>10.4.5 Methodology &ndash; 360
</p>
<p>10.4.6 Results &ndash; 361
</p>
<p>10.4.7 Conclusion and Recommendations &ndash; 370
</p>
<p>10.4.8 Limitations &ndash; 370
</p>
<p>10.4.9 Appendix &ndash; 371
</p>
<p>10.5 Guidelines for Oral Presentations &ndash; 371
</p>
<p>10.6 Visual Aids in Oral Presentations &ndash; 371
</p>
<p>10.7 Structure of the Oral Presentation &ndash; 372
</p>
<p>10.8 Follow-Up &ndash; 373
</p>
<p>10.9 Ethics in Research Reports &ndash; 374
</p>
<p>10.10 Review Questions &ndash; 375
</p>
<p> References &ndash; 375
</p>
<p>10
</p>
<p>&copy; Springer-Verlag GmbH Germany, part of Springer Nature 2019 
</p>
<p>M. Sarstedt, E. Mooi, A Concise Guide to Market Research, Springer Texts in Business  
</p>
<p>and Economics, https://doi.org/10.1007/978-3-662-56707-4_10
</p>
<p>Electronic supplementary material
</p>
<p>The online version of this chapter (https://doi.org/10.1007/978-3-662-56707-4_10) contains 
</p>
<p>additional material that is available to authorized users. You can also download the &ldquo;Springer 
</p>
<p>Nature More Media App&rdquo; from the iOS or Android App Store to stream the videos and scan the 
</p>
<p>image containing the &ldquo;Play button&rdquo;.</p>
<p/>
<div class="annotation"><a href="https://crossmark.crossref.org/dialog/?doi=10.1007/978-3-662-56707-4_10&amp;amp;domain=pdf&amp;amp;date_stamp=2018-9-17">https://crossmark.crossref.org/dialog/?doi=10.1007/978-3-662-56707-4_10&amp;amp;domain=pdf&amp;amp;date_stamp=2018-9-17</a></div>
</div>
<div class="page"><p/>
<p>356 Chapter 10 &middot; Communicating the Results
</p>
<p>Keywords
Ethics &bull; KISS principle &bull; Minto principle &bull; Pyramid structure for presentations &bull; Self-contained figure &bull; 
</p>
<p>Self-contained table &bull; Visual aids
</p>
<p>10.1 Introduction
</p>
<p>Communicating results is key to any market research project. This includes giving clear 
answers to the investigated research questions and recommending a course of action, 
where appropriate. The importance of communicating marketing research results should 
not be underestimated. Even if the research has been carefully conducted, the recipi-
ents will find it difficult to understand the implications of the results and to appreciate 
the study&rsquo;s quality if you spend too little time and energy on communicating these. Clear 
communication may also set the stage for follow-up research. If you communicate the 
findings effectively, the clients, who may know little about market research and may even 
be unfamiliar with the specific market research project, will understand them. Hence, the 
communication must be relevant for the addressed audience and provide a clear picture 
of the project.
</p>
<p>Market researchers usually present their findings in the form of an oral presentation 
and written report. This report is the written evidence of the research effort and includes 
the details. Identifying the addressed audience is critical for both these points, as this deter-
mines how you can best communicate the findings. In this chapter, we discuss guidelines 
on how to effectively communicate research findings orally and in writing. We first discuss 
written reports before listing the basics of oral presentations. We also provide hints on 
how to acquire research follow-up. At the end of the chapter, we briefly review the ethical 
issues related to market research.
</p>
<p>10.2 Identify the Audience
</p>
<p>When providing reports (and presentations), you should keep the audience&rsquo;s character-
istics and needs in mind and should tailor the report to their objectives. Imagine you are 
dealing with the marketing department of a company planning to launch a new product 
and needing to learn more about the potential customers&rsquo; buying behavior. The knowledge 
</p>
<p>Learning Objectives
After reading this chapter, you should understand:
</p>
<p> 5 Why communicating the results is a crucial element of every market research study.
 5 The elements that should be included in a written research report and how to 
structure these elements.
</p>
<p> 5 How to communicate the findings in an oral presentation.
 5 The ethical issues concerning communicating the report findings to the client.
</p>
<p>10</p>
<p/>
</div>
<div class="page"><p/>
<p>10357
10.3 &middot; Guidelines for Written Reports
</p>
<p>and level of interest in the study might differ greatly within the department. While the 
managers, who commissioned the study, are generally familiar with its objective and 
design, others, who might be unaware of the background (e.g., the marketing direc-
tor or the sales staff), must be informed about the research to allow them to understand 
the research findings. When preparing the report, you should consider the following 
questions:
 4 Who will read the report?
 4 Why will they read the report?
 4 Which parts of the report are of specific interest to them?
 4 What do they already know about the study?
 4 What information will be new to them?
 4 What is the most important point for them to know after they have read the report?
 4 What can be done with the research findings?
</p>
<p>These questions help you determine the level of detail that should be included in your 
report. Furthermore, they reveal information that requires specific focus during the 
project. Remember, a successful report meets its audience&rsquo;s needs! However, not every-
thing that you consider appropriate for your audience is appropriate. Nothing is worse than 
suggesting an idea that the audience finds unpalatable (e.g., saying that a specific senior 
management behavior or attitude is a major obstacle to success), or proposing a course 
of action that has been attempted before. Informal talks with the client are therefore vital 
before you present the results&mdash;never present findings formally without discussing them 
with the client first!
</p>
<p>Further, you need to ask clients about their expectations and the recommendations they 
think will be made early in the project. Why would clients spend $100,000 if you merely 
give them the answers they expect to get? Such discussions may help exceed clients&rsquo; expec-
tations in a way that is useful to them.
</p>
<p>10.3 Guidelines for Written Reports
</p>
<p>You should always keep the people addressed in the report in mind. Decision makers are 
generally unfamiliar with statistical details but would like to know how the findings can 
help them make decisions. You should therefore avoid research jargon and state the key 
insights clearly without omitting important facts. There are several major rules to consider 
when writing a report (Armstrong 2010; Churchill and Iacobucci 2015):
1. The report must be complete; that is, it must contain all information that the reader 
</p>
<p>needs in order to understand the research. Technical or ambiguous terms, as well 
as abbreviations and symbols, should be clearly defined and illustrated. Although 
you know what terms like heteroscedasticity or eigenvalue mean, the report reader 
probably won&rsquo;t! In addition, the report must provide enough detail to enable 
the reader to verify and replicate the findings if necessary. Bear in mind that the 
staff turnover in many organizations is high and that reports should therefore be 
stand-alone to allow those with little knowledge of the background to read and 
understand them.</p>
<p/>
</div>
<div class="page"><p/>
<p>358 Chapter 10 &middot; Communicating the Results
</p>
<p>2. The report must be accurate. The readers will base their assessment of the entire 
research project&rsquo;s quality on the presented report. Consequently, the report must 
be well written. For example, grammar and spelling must be correct, no slang 
should be used, tables must be labeled correctly, and page numbers should be 
included. If there are small errors, the reader may believe they are due to your lack 
of care and generalize about your analysis! Therefore, proofread (using a profes-
sional proofreader) to eliminate obvious errors. Lastly, objectivity is an important 
attribute of any report. This means that any subjective conclusions should be 
clearly stated as such.
</p>
<p>3. The report must be clear and language simple and concise:
 4 Use short sentences.
 4 Use simple and unambiguous words.
 4 Use concrete examples to illustrate aspects of the research (e.g., unexpected 
findings). These can also be helpful if the audience has strong beliefs that are not 
consistent with your recommendation. Such recommendations are otherwise 
almost certainly not implemented as the client does not believe them.
 4 Use the active voice to make the report easy to read and to help understanding.
 4 Avoid negative words.
 4 Use business language.
 4 Avoid exclamation marks and do not use caps unnecessarily. Avoid the use of 
bold or italics for more than just a few words.
</p>
<p>4. Follow the KISS principle: Keep it short and simple! This principle requires the report 
to be concise. And since it needs to be action-driven, the reader must immediately 
understand its purpose and the results, so start off with these. You should present 
the results clearly and simply. Important details can be shown in the appendix 
or appendices of the report, which should also not be overloaded with irrelevant 
material. In addition, keep in mind that each section&rsquo;s first sentences are the most 
important ones: They should summarize the main idea you want to convey in this 
section.
</p>
<p>5. The report must be structured logically. This applies to the general structure of the 
report (see . Table 10.1) and to the line of argumentation in each section. Make sure 
you avoid style elements that may distract the reader:
</p>
<p> 4 Avoid cross-references. Having to search elsewhere for important results is 
disruptive. For example, do not put important tables in the appendix.
 4 Use footnotes instead of endnotes and as few as possible.
 4 The structure should not be too detailed. As a rule of thumb, you should avoid 
using more than four levels.
 4 A new level must include at least two sections. For example, if there is a 
7&nbsp;Sect.&nbsp;3.1.1, there must also be a Sect.&nbsp;3.1.2.
</p>
<p>10.4 Structure of the Written Report
</p>
<p>When preparing a written report, a clear structure helps readers to quickly and easily find 
those elements that interest them. Although all reports differ, we include a suggested struc-
ture for a research report in . Table 10.1.
</p>
<p>10</p>
<p/>
</div>
<div class="page"><p/>
<p>10359
10.4 &middot; Structure of the Written Report
</p>
<p>10.4.1 Title Page
</p>
<p>The title page should state the title of the report, the name of the client who commissioned 
the report, the organization or researcher submitting it, and the date of release. The heading 
should clearly state the nature and scope of the report. It may simply describe the research 
(e.g., &ldquo;Survey of Mobile Phone Usage&rdquo;) or may outline the objectives of the study in the 
form of an action title (e.g., &ldquo;How to Increase the Adoption of Wearable Technologies&rdquo;).
</p>
<p>10.4.2 Executive Summary
</p>
<p>The executive summary should appear first and is essential, because it is often the only 
section that executives read. This summary helps set the expectations of those who read 
more. Hence, this section must be short to allow busy executives to read it and should give 
them the essence (findings and recommendations) of the research. As a rule of thumb, 
the executive summary should not exceed 150&nbsp;words. It should contain key findings and 
recommendations, and help the reader understand the full study. The executive summary 
also requires more structure. A common way of giving structure is to tell a story. Begin 
with a description of the problem, thereafter introducing the issues that make this diffi-
cult or complicated and describing how these give rise to a number of questions. Finally, 
lead the reader through your line of reasoning to the answer:
</p>
<p>. Table 10.1 Suggested structure for a written research report
</p>
<p>Title Page
</p>
<p>Executive Summary
</p>
<p>Table of Contents
</p>
<p>1. Introduction
</p>
<p>1.1 Problem definition
</p>
<p>1.2 Research objectives
</p>
<p>1.3 Research questions and/or hypothesesa
</p>
<p>2. Methodology
</p>
<p>2.1 Population, sampling method, and sample description
</p>
<p>2.2 Quantitative and qualitative methods used for data analysis
</p>
<p>3. Results
</p>
<p>4. Conclusions and Recommendations
</p>
<p>5. Limitations
</p>
<p>6. Appendix
</p>
<p>a In practice, the word hypotheses may be replaced by research question(s) or proposition(s)</p>
<p/>
</div>
<div class="page"><p/>
<p>360 Chapter 10 &middot; Communicating the Results
</p>
<p> 4 Situation: Background information.
 4 Difficulty or complication: A short window of opportunity; a change from the 
</p>
<p>previously stable situation; lack of performance due to unknown causes (i.&nbsp;e., the 
reason for your research study).
 4 Question: The scope and goal of your research study.
 4 Answer: Your findings and conclusions (and if the client requires this, also your 
</p>
<p>recommendations).
</p>
<p>10.4.3 Table of Contents
</p>
<p>The table of contents helps the reader locate specific aspects of the report. The table of con-
tents should correspond to the main report headings. It should also include lists of tables 
and figures with page references.
</p>
<p>10.4.4 Introduction
</p>
<p>This section should explain the project context to the reader. Questions to be answered 
include:
 4 Why was the study undertaken?
 4 What were the objectives and which key questions are answered?
 4 Is the study related to other studies and, if so, which findings did they produce?
 4 How is the report structured?
</p>
<p>Besides introducing the background and purpose of the research, the introduction should 
briefly explain how the objectives and key questions are addressed. You should briefly 
mention the hypotheses or propositions tested during the research and how the research 
was approached (e.g. cluster analysis). You should ensure that critical terms are defined. 
For example, aviation terms such as CASM (cost per available seat mile) require explana-
tion. As a rule, the following three questions on the research should be answered in the 
introduction, but should be neither too detailed nor too technical:
 4 What was done?
 4 How was it done?
 4 Why was it done?
</p>
<p>Keep in mind that the introduction should set the stage for the body of the report and the 
presentation of the results, but no more than this. You should only provide a detailed descrip-
tion of how you collected and analyzed the data in the next section of the report. Lastly, you 
should provide a brief summary of how the report is organized at the end of the introduction.
</p>
<p>10.4.5 Methodology
</p>
<p>In this section, you should describe the research procedure and the different (statisti-
cal) methods used to analyze the data. These must be presented precisely and coherently, 
allowing the reader to understand the analyses&rsquo; process and basic principles. Always keep 
</p>
<p>10</p>
<p/>
</div>
<div class="page"><p/>
<p>10361
10.4 &middot; Structure of the Written Report
</p>
<p>your audience in mind! If the audience is familiar with research methodology, you can 
describe the procedures in detail and skip the basics. If the client has little knowledge of 
research methodology, you should introduce the methods briefly. If you have an audi-
ence of whom some have a little and others more knowledge, you might want to move the 
basics to an appendix.
</p>
<p>If not already stated in the previous section, you should define whether the study is 
exploratory, descriptive, or causal by nature and whether the results are based on primary 
or secondary data. If primary data are used, their source should be specified (e.g., obser-
vation or questionnaire). If a questionnaire was used, you should state whether it was 
administered by means of face-to-face interviews, telephone interviews, or through web 
or mail surveys. Also explain why you chose this specific method.
</p>
<p>The reader should also know the demographic or other relevant characteristics of the 
targeted survey population. This includes the geographical area, age group, and gender. 
While it is usually sufficient to describe the population in a few sentences, the sampling 
method needs more explanation: How was the sample selected? Which sampling frames 
were chosen (e.g., random, systematic, stratified)? In addition, information on the sample 
size, response rate, and sample characteristics are essential, as this indicates the results&rsquo; 
reliability and validity.
</p>
<p>You should include a copy of the actual instruments used, such as the questionnaire 
or the interview guide, the data collection protocol, and the detailed statistical analyses of 
the results, in the appendix, or present them separately. Although these are important to 
fully understand the characteristics of the research project, including them in the main 
text would make reading the report more difficult.
</p>
<p>10.4.6 Results
</p>
<p>In this section, you need to present the findings and describe how they relate to a possi-
ble solution to the research problem and how they influence the recommendations. There 
are several ways of presenting the results logically. You could, for instance, use the differ-
ent research objectives as a guideline to structure this section and then analyze them one 
by one.
</p>
<p>Another way is to first summarize the overall findings and then analyze them in rele-
vant subgroups, such as the type of customer or geographical regions. Alternatively, you 
can classify the findings according to the data type or the research method if several were 
used. For example, you could first present the conclusions of the secondary data collection 
and then those derived from an analysis of the questionnaire.
</p>
<p>Use tables and graphs when presenting statistical data, as they make the report and 
the data more interesting. Tables and graphs also structure information, thus facilitating 
understanding. Graphs often allow the researcher to visually present complex data, which 
might not be possible when only using tables. However, as the following sections will 
show, graphs can also be misleading, as they may be adjusted to favor a specific viewpoint.
</p>
<p>Results are often presented in Excel or Word format. Fortunately, SPSS has built-in 
capabilities to export its results to Excel or Word. To do so, simply right click on a table 
or figure in the SPSS Statistics Viewer and select Export. SPSS then gives you the option 
to export in several formats of which Excel 2007 and higher (*.xlsx), Word/RTF (*.doc), and 
None (graphics only) are the most useful.</p>
<p/>
</div>
<div class="page"><p/>
<p>362 Chapter 10 &middot; Communicating the Results
</p>
<p>10.4.6.1 Window Dressing with Graphs
While graphs have the advantage that they can present complex information in a way that 
is easily understandable, they can be used to mislead the reader. Experience with gener-
ating and interpreting graphs will help you spot this. In this section, we show examples of 
how graphs can mislead. By shortening the x-axis in . Fig.&nbsp;10.1 (i.&nbsp;e., removing the years 
2007&ndash;2011), it suggests a growth in the units sold (. Fig.&nbsp;10.2).
</p>
<p>Likewise, we can modify the scale range (. Fig.&nbsp;10.2 vs. . Fig.&nbsp;10.3). Specifically, reduc-
ing the y-axis to a range from 68 to 100 units with 4-unit increments, suggests faster 
growth (. Fig.&nbsp;10.3). Another example is the &ldquo;floating&rdquo; y-axis (. Fig.&nbsp;10.1 vs. . Fig.&nbsp;10.4), 
which increases the scale range along the y-axis from 0 to 210&nbsp;with 30-unit increments, 
thus making the drop in the number of units sold over the period 2009 to 2012&nbsp;less visu-
ally pronounced.
</p>
<p>Data are often presented by means of three-dimensional figures, such as in . Fig.&nbsp;10.5. 
While these can be visually appealing, they are also subject to window-dressing. In this 
example, the lengths of all the edges were doubled to correspond to the 100&nbsp;% increase in 
turnover. However, the resulting area is not twice but four times as large as the original 
image, thus presenting a false picture of the increase. These are just some common exam-
ples; Huff &rsquo;s (1993) classic text offers more on this topic.
</p>
<p>The following TED-Ed talk offers insights on how to spot misleading graphs.
</p>
<p>&copy; Enis Aksoy/Getty Images/iStock
</p>
<p>https://ed.ted.com/lessons/how-to-spot-a-misleading-graph-lea-
</p>
<p>gaslowitz
</p>
<p>10</p>
<p/>
<div class="annotation"><a href="https://ed.ted.com/lessons/how-to-spot-a-misleading-graph-lea-gaslowitz">https://ed.ted.com/lessons/how-to-spot-a-misleading-graph-lea-gaslowitz</a></div>
<div class="annotation"><a href="https://ed.ted.com/lessons/how-to-spot-a-misleading-graph-lea-gaslowitz">https://ed.ted.com/lessons/how-to-spot-a-misleading-graph-lea-gaslowitz</a></div>
</div>
<div class="page"><p/>
<p>10363
10.4 &middot; Structure of the Written Report
</p>
<p>2007
</p>
<p>60
</p>
<p>70
</p>
<p>80
</p>
<p>90
</p>
<p>100
</p>
<p>110
</p>
<p>120
</p>
<p>130
</p>
<p>140
</p>
<p>150
</p>
<p>160
</p>
<p>170
</p>
<p>2008 2009 2010 2011 2012 2013 2014 2015 2016 2017
</p>
<p>Year
</p>
<p>U
n
</p>
<p>it
s
</p>
<p> s
o
</p>
<p>ld
</p>
<p>. Fig.&nbsp;10.1 What year does the curve start? (I)
</p>
<p>Tables are generally less susceptible to manipulation, as they contain data in numbers. 
As a rule of thumb, each table or graph in the report should be numbered sequentially and 
have a meaningful title so that it can be understood without reading the text. This is called 
a self-contained table or self-contained figure. Some rules of thumb:
 4 Put data to be compared in columns, not rows.
 4 Round data off to whole percentages, thousands or millions for sales, and two or 
</p>
<p>three digits for academic purposes.
 4 Highlight data to reinforce conclusions (e.g., making the key numbers bold).
 4 Clearly state the units of measurement.
</p>
<p>10.4.6.2 Presenting Statistical Data
</p>
<p>In this section, we describe various ideas that you can use to convey statistical results 
in a reader-friendly manner. In the results section, it is common to start presenting the 
descriptive statistics first. This comprises text that is visually supported by graphs, to offer 
information and context to those readers with the required background. Graphs offer two </p>
<p/>
</div>
<div class="page"><p/>
<p>364 Chapter 10 &middot; Communicating the Results
</p>
<p>major advantages: first, they organize and simplify complex and dense information, which 
is especially useful with large data samples (Tufte 2001); second, graphs can summarize 
dense information efficiently. There are, of course, many kinds of graphs and each type has 
its advantages and disadvantages. The sample size and the nature of your data may con-
strain the choice of graphs. Sometimes your client may even have specific requirements. 
Here are some tips to help you with the presentation of your data:
</p>
<p>z Summarize your results efficiently
Graphs, like bar charts and especially dot charts, offer a useful way of summarizing descrip-
tive data most efficiently; that is, by using less space. Bar charts are generally useful where 
the objective is to depict how the outcome variable varies across two or more grouping 
variables. . Figure.&nbsp;10.6 uses the Oddjob.sav dataset to illustrate this point by plotting the 
average net promoter score over the respondents&rsquo; gender and status. Note that, in a com-
plete presentation, it is important to include a title and subtitle, to label the y-axis and the 
x-axis, and to list the source of the data below the figure.
</p>
<p>z Combine several plots
SPSS offers many more graphs many of which we discussed in 7 Chap.&nbsp;5. While this 
chapter will not review the graphs offered in SPSS, it is worth mentioning that the Chart 
</p>
<p>2012
</p>
<p>60
</p>
<p>70
</p>
<p>80
</p>
<p>90
</p>
<p>100
</p>
<p>110
</p>
<p>120
</p>
<p>2013 2014 2015 2016 2017
</p>
<p>Year
</p>
<p>U
n
</p>
<p>it
s
</p>
<p> s
o
</p>
<p>ld
</p>
<p>. Fig.&nbsp;10.2 What year does the curve start? (II)
</p>
<p>10</p>
<p/>
</div>
<div class="page"><p/>
<p>10365
10.4 &middot; Structure of the Written Report
</p>
<p>Builder allows combining coefficients from different analyses in a single plot. .&nbsp;Figure.&nbsp;10.7 
offers an example and depicts the mean net promoter score (bar charts) and the custom-
ers&rsquo; expectation regarding value for money (line chart) along the seven different points 
of the overall satisfaction scale. The inclusion of 95&nbsp;% confidence intervals in the graph&mdash;
indicated by the vertical lines at the end of each bar&mdash;show significant differences in 
the customers&rsquo; recommendation intention along the different satisfaction levels. This is 
because the vertical lines of bars do not overlap for most of the pairs. This matter could be 
unclear if the confidence intervals are not included and may lead to misinterpretation by 
knowledgeable readers, who assume that such differences are statistically not significant.
</p>
<p>z Make concise and clear (regression) tables
Research projects often require running several analyses on the same set of data by using 
slightly different settings in the data analysis technique. For example, researchers gener-
ally run a regression analysis on multiple models, which differ with regard to the number 
of independent variables or the type of dependent variable. When multiple models are 
estimated, these are usually presented in adjacent columns to make comparisons easier. 
In regression tables, each column represents the results of one regression analysis. The 
rows indicate each independent variable&rsquo;s influence on the dependent variable by means 
</p>
<p>2012
</p>
<p>60
</p>
<p>68
</p>
<p>64
</p>
<p>72
</p>
<p>76
</p>
<p>80
</p>
<p>84
</p>
<p>88
</p>
<p>92
</p>
<p>96
</p>
<p>100
</p>
<p>104
</p>
<p>2013 2014 2015 2016 2017
</p>
<p>Year
</p>
<p>U
n
</p>
<p>it
s
</p>
<p> s
o
</p>
<p>ld
</p>
<p>. Fig.&nbsp;10.3 Shortening the y-axis</p>
<p/>
</div>
<div class="page"><p/>
<p>366 Chapter 10 &middot; Communicating the Results
</p>
<p>2007
</p>
<p>0
</p>
<p>30
</p>
<p>60
</p>
<p>90
</p>
<p>120
</p>
<p>150
</p>
<p>180
</p>
<p>210
</p>
<p>2008 2009 2010 2011
</p>
<p>Year
</p>
<p>U
n
</p>
<p>it
s
</p>
<p> s
o
</p>
<p>ld
</p>
<p>2012 2013 2014 2015 2016 2017
</p>
<p>. Fig.&nbsp;10.4 The &ldquo;floating&rdquo; y-axis
</p>
<p>Competitor 
</p>
<p>10 Million  
</p>
<p>Our company 
</p>
<p>20 Million  
</p>
<p>Turnover 2017 
</p>
<p>. Fig.&nbsp;10.5 Doubling the edge length quadruples the area
</p>
<p>10</p>
<p/>
</div>
<div class="page"><p/>
<p>10367
10.4 &middot; Structure of the Written Report
</p>
<p>Blue
</p>
<p>0
</p>
<p>2
</p>
<p>4
</p>
<p>6
</p>
<p>8
</p>
<p>10
</p>
<p>Silver
</p>
<p>Traveler Status
</p>
<p>H
o
</p>
<p>w
 li
</p>
<p>k
e
</p>
<p>ly
 is
</p>
<p> it
 t
</p>
<p>h
a
</p>
<p>t 
y
</p>
<p>o
u
</p>
<p> w
o
</p>
<p>u
ld
</p>
<p> r
e
</p>
<p>co
m
</p>
<p>m
e
</p>
<p>n
d
</p>
<p> o
u
</p>
<p>r
</p>
<p>co
m
</p>
<p>p
a
</p>
<p>n
y
</p>
<p> t
o
</p>
<p> a
 f
</p>
<p>ri
e
</p>
<p>n
d
</p>
<p> o
r 
</p>
<p>co
L
</p>
<p>le
a
</p>
<p>g
u
</p>
<p>e
?
</p>
<p>Gold
</p>
<p>Gender
</p>
<p>female
</p>
<p>male
</p>
<p>. Fig.&nbsp;10.6 Bar chart presentation
</p>
<p>of the (standardized or unstandardized) regression coefficient estimates. To create a clear 
table, include the:
1. Model Title: The first step in any table is to label each model that you are presenting. 
</p>
<p>The label should be self-explanatory (e.g., &ldquo;Regression results of commitment to 
Oddjob Airways on different predictors&rdquo;). For academic purposes, a model number 
(e.g., Model 1, Model 2, etc.) or a title that best represents the model (e.g., Baseline 
model; Extended model, etc.) is sometimes used. This is particularly useful when 
writing up the results as you can then refer to and compare the estimates of the 
different models in the text. The choice of model name depends on the audience and 
the formatting guidelines.
</p>
<p>2. Independent variables: In a (regression) table, the rows refer to the independent 
variables in the model. Give the variables a straightforward name to make it easier 
for the reader to understand. Make sure that these variable names are identical to 
those used in other tables and graphs (if any).</p>
<p/>
</div>
<div class="page"><p/>
<p>368 Chapter 10 &middot; Communicating the Results
</p>
<p>3. Coefficient estimates: Depending on your audience, the (regression) table needs 
to specify whether standardized or unstandardized coefficient estimates are being 
presented. This can be included as a subtitle and explained above the table.
</p>
<p>4. Significance level: Putting asterisks (*) behind the estimated regression coefficients 
is a common way of presenting the coefficients&rsquo; significance levels. Usually, one 
asterisk indicates a significance level of 0.10, two asterisks a significance level of 
0.05, and three asterisks a significance level of 0.01. Depending on the audience, 
researchers sometimes present only effects with a significance level of 0.05. 
Whatever strategy you choose, make sure you add a note below your table indicating 
the level of significance that the asterisks represent.
</p>
<p>5. Standard error or t values: In addition to the significance levels, you need to present 
the corresponding t value or standard error of the coefficient estimate, which 
is usually placed in brackets below the coefficient estimates. Both presentation 
methods are accepted and the choice depends on your audience and the formatting 
criteria.
</p>
<p>6. Sample size and degrees of freedom: For a complete presentation, you should 
also include the sample size and the models&rsquo; degrees of freedom after the model 
estimation. These statistics are respectively indicated as N and df in . Table 10.2. 
</p>
<p>Fully
disagree
</p>
<p>2
0
</p>
<p>2
</p>
<p>4
</p>
<p>6
</p>
<p>8
</p>
<p>10
</p>
<p>12
</p>
<p>3 4 5 6
0
</p>
<p>20
</p>
<p>40
</p>
<p>60
</p>
<p>80
</p>
<p>100
</p>
<p>Fullyagree
</p>
<p>Error Bars: 95% CI
</p>
<p>Overall, I am satisfied with the price performance ratio of
Oddjob Airways
</p>
<p>H
o
</p>
<p>w
 li
</p>
<p>k
e
</p>
<p>ly
 is
</p>
<p>  i
t 
</p>
<p>th
a
</p>
<p>t 
yo
</p>
<p>u
 w
</p>
<p>o
u
</p>
<p>ld
 r
</p>
<p>e
co
</p>
<p>m
m
</p>
<p>e
n
</p>
<p>d
 o
</p>
<p>u
r
</p>
<p>co
m
</p>
<p>p
a
</p>
<p>n
y
</p>
<p> t
o
</p>
<p> a
 f
</p>
<p>ri
e
</p>
<p>n
d
</p>
<p> o
r 
</p>
<p>co
ll
</p>
<p>e
a
</p>
<p>g
u
</p>
<p>e
?
</p>
<p>... O
d
</p>
<p>d
jo
</p>
<p>b
 A
</p>
<p>irw
a
</p>
<p>y
s o
</p>
<p>ff
e
</p>
<p>rs g
re
</p>
<p>a
t v
</p>
<p>a
lu
</p>
<p>e
 fo
</p>
<p>r m
o
</p>
<p>n
e
</p>
<p>y.
</p>
<p>. Fig.&nbsp;10.7 Combination of different estimations and charts
</p>
<p>10</p>
<p/>
</div>
<div class="page"><p/>
<p>10369
10.4 &middot; Structure of the Written Report
</p>
<p>Reporting these statistics can reveal differences in the sample sizes of the different 
estimated models, which can be due to missing values in specific independent 
variables. If this happens, a comparison of the different models may make little 
sense, given that the models are based on different sample sizes with different 
characteristics. It is therefore important to understand what causes the large sample 
size differences between the models before taking any further action or drawing 
conclusions.
</p>
<p>7. Model fit: Finally, depending on the type of estimated model, statistics indicating 
the model significance, such as the R2, and the relative model fit, such as the AIC or 
BIC statistics, should be part of the table. In . Table 10.2 we have included the R2, the 
Adjusted R2, and the BIC to indicate the model fit.
</p>
<p>. Table 10.2 Regression results of commitment to Oddjob Airlines on different predictors
</p>
<p>Model 1 Model 2 Model 3
</p>
<p>Number of flights &minus;0.011***
</p>
<p>(0.003)
</p>
<p>&minus;0.009***
</p>
<p>(0.003)
</p>
<p>&minus;0.008***
</p>
<p>(0.003)
</p>
<p>Age 0.023***
</p>
<p>(0.004)
</p>
<p>0.023***
</p>
<p>(0.004)
</p>
<p>Gender &minus;0.308**
</p>
<p>(0.119)
</p>
<p>Constant 4.308***
</p>
<p>(0.063)
</p>
<p>3.124***
</p>
<p>(0.229)
</p>
<p>3.669***
</p>
<p>(0.306)
</p>
<p>R2 0.016 0.041 0.047
</p>
<p>Adjusted R2 0.015 0.039 0.044
</p>
<p>BIC 1174.958 1154.163 1154.450
</p>
<p>N 1065 1065 1065
</p>
<p>df 1063 1062 1061
</p>
<p>Notes: Dependent variable: commitment; unstandardized coefficients; standard errors in 
</p>
<p>brackets; * p&nbsp;&lt;&nbsp;0.05, ** p&nbsp;&lt;&nbsp;0.01, *** p&nbsp;&lt;&nbsp;0.001
</p>
<p>. Table 10.2 shows an example of a regression table, which comprises three models that 
add several variables, at a time, containing some of the key elements of the table that we 
mentioned earlier. These are: the model title, indicated as Model 1, Model 2 and Model 3. 
Next, the independent variables, with the corresponding coefficients, standard errors (in 
brackets), and significance levels are listed in the first column. For example, in Model 1, 
</p>
<p>! Typing the output tables for such multiple analyses by hand is time-consuming and 
often leads to errors.</p>
<p/>
</div>
<div class="page"><p/>
<p>370 Chapter 10 &middot; Communicating the Results
</p>
<p>the first row presents the unstandardized coefficient for nfligts (&minus;0.011), together with 
the pertaining standard errors (e.g., (0.003)), and significance level (***). Next, the table 
shows the R2, the Adjusted R2, and BIC values along with the sample size (N). The caption 
at the bottom of the table indicates the dependent variable, the display of standard errors, 
the type of coefficients (i.&nbsp;e., unstandardized), and a description of the significance levels.
</p>
<p>10.4.7 Conclusion and Recommendations
</p>
<p>Having presented the findings, the next step is to summarize the most relevant points and 
interpret them in the light of the research objectives. You should write the conclusions in 
such a way that they present information that is relevant for managerial decision-making. 
Keep in mind that, for the client, the quality of the marketing research depends heavily on 
how well decision makers can use the information! The research must provide the client 
with clear benefits, which could lead to further research assignments.
</p>
<p>Researchers are increasingly asked to go beyond stating facts and to provide recom-
mendations or to advise. Whereas conclusions based solely on the research should be 
unbiased and impersonal, specific recommendations are based on a personal and (at least 
partially) subjective opinion on how the results can be most favorably used in the cli-
ent&rsquo;s interest. You should therefore make sure that recommendations are recognizable as 
such. During the negotiations prior to the start of a project, the client needs to determine 
the extent to which the research report should include recommendations. This will also 
depend on the researcher&rsquo;s expertise in the area. Researchers may provide logical recom-
mendations based on the findings, but these might be unrealistic or impossible for the 
client to implement due to issues such as insufficient budgets, predetermined methods, 
or specific policies, regulations, and politics. Make sure that you or another member of 
your research team is familiar with the overall context, including the regulatory and legal 
issues, to avoid such issues. Furthermore, before making recommendations, review them 
with the client to determine whether these are acceptable and actionable (see Box 10.1 for 
an example).
</p>
<p>Box 10.1 Bad recommendations
</p>
<p>A candy company wishes to know how it can increase its sales and has commissioned a research 
</p>
<p>organization to gain insights into its different customer segments. The researchers found 
</p>
<p>that teenagers are the most important target for the given brand and suggest that vending 
</p>
<p>machines in schools would increase the company&rsquo;s revenue. Although this might boost sales, the 
</p>
<p>recommendation does not help the company if vending machines are not allowed in schools. 
</p>
<p>And even if they were allowed, they might lead to negative media reports.
</p>
<p>10.4.8 Limitations
</p>
<p>Finally, you should explain the extent to which the findings can be generalized. All 
research studies have limitations due to time, budget, and other constraints. Further-
more, errors might have occurred during the data collection. Not mentioning potential 
</p>
<p>10</p>
<p/>
</div>
<div class="page"><p/>
<p>10371
10.6 &middot; Visual Aids in Oral Presentations
</p>
<p>weaknesses (e.g.,&nbsp;the use of a convenience sample, or a small sample size) for what-
ever reason reduces the research&rsquo;s credibility. Not disclosing important facts also vio-
lates common codes of industry conduct, such as those drafted by ESOMAR. Taking all 
these factors into regard, the research results should always be discussed objectively and 
in a balanced way. You should neither overly belittle the importance and validity of the 
research, nor try to conceal sources of errors and, hence, potentially mislead managers. 
Finally, some modesty is in order as, in hindsight, many reports have been proved inac-
curate or even wrong. Few, for example, predicted the global financial crisis, the Trump 
presidency, or Brexit.
</p>
<p>10.4.9 Appendix
</p>
<p>All material not directly required for an understanding of the project, but still related to 
the study, should be included in the appendix or appendices. This includes questionnaires, 
interview guides, detailed data analyses, and other types of data or material.
</p>
<p>10.5 Guidelines for Oral Presentations
</p>
<p>Most clients want an oral presentation to accompany the written report. One could deliver 
such a presentation in the form of an interim report during the research, or at the end to 
explain the findings to the management and other staff. Members of the client staff often 
present the research findings to the management and do not ask the market research 
company to do so. Satisfaction with the delivered report may increase if a member of the 
client staff, such as an internal market researcher or business analyst, delivers the presen-
tation, because the client feels they know and accept the content.
</p>
<p>If asked to deliver an oral presentation, you should keep the principles of a written 
report in mind. It is especially important to identify and understand your audience, 
and to prepare the presentation thoroughly. A professional and interesting presenta-
tion might increase interest in the written report! Furthermore, since the oral presenta-
tion allows for interaction, interesting points can be highlighted and discussed in more 
detail. However, if you are not well prepared for the presentation, nor understand your 
audience&rsquo;s expectations, needs, and wants, you could face an unpleasant situation. You 
should always keep the following golden rule in mind: Never deliver a presentation you 
wouldn&rsquo;t want to sit through!
</p>
<p>10.6 Visual Aids in Oral Presentations
</p>
<p>It is useful to provide the audience with a written summary or a handout so that they do 
not have to take notes, but can focus on the presentation. If focus group interviews were 
conducted, for example, you could show excerpts from the recordings to provide con-
crete examples in support of a finding. The saying &ldquo;a picture says more than a thousand 
words&rdquo; is also true of the oral presentation. Visual aids, such as overhead transparencies, 
flip charts, or computer slide shows (e.g., PowerPoint or Prezi at www.prezi.com) not only </p>
<p/>
<div class="annotation"><a href="http://www.prezi.com">http://www.prezi.com</a></div>
</div>
<div class="page"><p/>
<p>372 Chapter 10 &middot; Communicating the Results
</p>
<p>help emphasize important points, but also facilitate the communication of difficult ideas. 
In the following, we summarize some suggestions (Armstrong 2010).
</p>
<p>z Use of visual aids
 4 Use a simple master slide and avoid fancy animations.
 4 Use a sufficiently large font size (as a rule of thumb, 16pt. or higher and never less 
</p>
<p>than 12pt.) so that everyone attending the presentation can read the slides.
 4 Use high contrasts for text. Use black and white. Do not write on illustrations or 
</p>
<p>wallpapers.
 4 Use contrasting colors to emphasize specific points, but not too many.
 4 Use simple graphs, diagrams or short sentences rather than tables.
</p>
<p>z Arranging visual aids
 4 Do not have too much information on one slide (generally, one key issue per slide). 
</p>
<p>Never put a block of text on a page.
 4 Organize the material so that the different modes reinforce one another. For 
</p>
<p>example, you do not want people running ahead of you, so either explain each point 
as you discuss it on a slide, or use many simple slides.
 4 Use a small number of slides compared to the time available for the presentation. 
</p>
<p>The focus should be on the presenter and not on the slides. Having more slides 
than minutes available is not a good idea. Good presenters often use between 3 and 
5&nbsp;minutes to discuss a slide.
 4 Prepare (color) handouts for all members of the audience.
 4 If you intend to use media elements in your presentation, make sure that the 
</p>
<p>equipment supports them (e.g., that the sound equipment is working, or that your 
video formats are supported).
</p>
<p>10.7 Structure of the Oral Presentation
</p>
<p>Be aware that an oral presentation cannot cover the same amount of information as a 
written report. You must be selective and structure the presentation content clearly and 
logically. There are two ways of creating a presentation:
1. A common way of starting your presentation is by structuring the introduction in 
</p>
<p>the classic narrative pattern of story-telling (situation &rarr; difficulty or complication 
&rarr; question &rarr; answer) introduced earlier in the context of written reports. Limit 
the introduction to what the audience can accept. Nothing could be worse than 
triggering resistance of what you are presenting right from the start of your oral 
presentation. Next, move on to the main part of your presentation. Based on a brief 
description of your major findings, capture the audience&rsquo;s attention by presenting 
answers to the logical questions that arise from the project, such as: &ldquo;How were these 
results achieved?&rdquo; or &ldquo;How did we reach this conclusion?&rdquo;
</p>
<p>2. An alternative is to follow the Minto principle, according to which presentations 
have a pyramid structure, starting with the conclusion. This raises question in the 
audience&rsquo;s mind that has to be subsequently answered. . Figure 10.8 illustrates this 
concept by using the example of a mobile phone study, which found that a novel 
smartphone should be introduced in white.
</p>
<p>10</p>
<p/>
</div>
<div class="page"><p/>
<p>10373
10.8 &middot; Follow-Up
</p>
<p>You begin by introducing the result of the study (i.&nbsp;e., the smartphone should be intro-
duced in white) and then work your way down. Begin by explaining that a comprehensive 
market analysis was carried out, after which you discuss the elements of the analysis (i.&nbsp;e., 
focus group interviews, lead user interviews, and a customer survey). Finally, present the 
results of each element of the analysis (e.g., that lead users perceived black as too conser-
vative, silver as too cheap, while white was perceived as modern). Once at the bottom of 
the pyramid, it is time to pause and to provide a summary, before moving from the first 
key line, which you have just presented, to the next key line, and so on. This process forces 
you to only provide the information relevant to the question under consideration. Moving 
from top to bottom and then bottom to top, helps you answer the questions: &ldquo;Why so?&rdquo; 
and &ldquo;So what?,&rdquo; while being both exhaustive and mutually exclusive regarding the results 
and the concepts you have presented. Ensure you never provide findings that do not lead 
to specific conclusions and do not offer conclusions not based on findings. Ultimately, this 
pyramid approach helps the audience grasp the line of reasoning better. This technique 
is also frequently called the Minto principle or Minto pyramid after its creator Barbara 
Minto (2009).
</p>
<p>10.8 Follow-Up
</p>
<p>Having delivered the written report and oral presentation, two tasks remain: First, you may 
need to help the client implement the findings. This includes answering questions that may 
arise from the written report and oral presentation, helping select a product, advertising 
agency, marketing actions, etc., or incorporate information from the report into the firm&rsquo;s 
</p>
<p>New smartphone
</p>
<p>should be white 
 
</p>
<p>Competitor 
</p>
<p>analysis 
</p>
<p>Market  
</p>
<p>analysis 
</p>
<p>Customer 
</p>
<p>survey 
</p>
<p>Lead user 
</p>
<p>interviews 
</p>
<p>Focus group 
</p>
<p>interviews 
</p>
<p>Black: Too 
</p>
<p>conservative 
</p>
<p>Silver: Looks  
</p>
<p>cheap 
</p>
<p>White: Very 
</p>
<p>modern 
</p>
<p>What has been done? 
</p>
<p>How was it done? 
</p>
<p>What was the result? 
</p>
<p>Mutually exclusive &amp; collectively exhaustive 
</p>
<p>S
o
</p>
<p> w
h
</p>
<p>a
t?
</p>
<p> W
h
</p>
<p>y
 so
</p>
<p>? 
</p>
<p>. Fig.&nbsp;10.8 Pyramid structure for presentations</p>
<p/>
</div>
<div class="page"><p/>
<p>374 Chapter 10 &middot; Communicating the Results
</p>
<p>marketing information system or decision support system (see 7 Chap.&nbsp;3). This provides an 
opportunity to discuss other research projects. For example, you might agree on repeating 
the study after one year to see whether the marketing actions were effective. Second, you 
need to evaluate the market research project internally and with the client. Only (critical) 
feedback can disclose potential problems that may have occurred and, thus, provide the 
necessary grounds for improving your work. Using uniform questionnaires for the evalu-
ation of different projects helps comparing the feedback from different projects conducted 
simultaneously or at different points in time. However, some market research companies 
do not want to be involved in implementation.
</p>
<p>10.9 Ethics in Research Reports
</p>
<p>Ethics is an important topic in marketing research, because research interacts with 
human beings at several stages (e.g., during data collection and the communication of 
the findings). There are two &ldquo;problematic&rdquo; relations that can ultimately lead to ethical 
dilemmas. First, ethical issues arise when the researcher&rsquo;s interests conflict with those 
of the participants. For instance, the researcher&rsquo;s interest is to gather as much infor-
mation as possible from the respondents, but they often require their answers to be 
treated confidentially and to remain anonymous. Second, in addition to researchers&rsquo; 
legal and professional responsibilities towards their respondents, they also have report-
ing responsibilities. For example, the European Society for Opinion and Marketing 
Research (ESOMAR) and the International Chamber of Commerce have established a 
code, which sets minimum standards of ethical, which rests on three fundamental prin-
ciples (ESOMAR 2016, p.&nbsp;7):
1. When collecting personal data from data subjects for the purpose of research, 
</p>
<p>researchers must be transparent about the information they plan to collect, the purpose 
for which it will be collected, with whom it might be shared and in what form.
</p>
<p>2. Researchers must ensure that personal data used in research is thoroughly protected 
from unauthorised access and not disclosed without the consent of the data subject.
</p>
<p>3. Researchers must always behave ethically and not do anything that might harm a data 
subject or damage the reputation of market, opinion and social research.
</p>
<p>In practice, researchers face an ethical dilemma. They are paid by the client and may feel 
forced to deliver &ldquo;good&rdquo; results. In this sense, they might be tempted to interpret results 
in a way that fits the client&rsquo;s perspective or the client&rsquo;s presumed interests. For instance, 
researchers might ignore data because they would reveal an inconvenient truth (e.g., the 
client&rsquo;s brand has low awareness, or customers do not like the product design).
</p>
<p>Remember that researchers should never mislead the audience! For instance, it would 
be ethically questionable to modify the scales of a graph so that the results look more 
impressive, as shown in . Figs.&nbsp;10.1, 10.2, 10.3 and 10.4. Furthermore, researchers have a 
duty to treat information and research results confidentially, to store data securely, and to 
use data only for the research purpose agreed upon. Above all, you should keep in mind 
that marketing research is based on trust. Thus, when writing the report, you should respect 
the profession&rsquo;s ethical standards in order to maintain this trust.
</p>
<p>10</p>
<p/>
</div>
<div class="page"><p/>
<p>10375
References
</p>
<p>10.10 Review Questions
</p>
<p>1. What are the basic elements of any written research report?
2. Revisit the case study on Oddjob Airways in 7 Chap.&nbsp;7 and prepare an outline for a 
</p>
<p>written research report.
3. Consider the following situations. Do you think they confront the market researcher 
</p>
<p>with ethical issues?
(a) The client asks the researcher for a list of respondents to allow him/her to target 
</p>
<p>selling activities at them.
(b) The client asks the researcher not to disclose part of the research to his 
</p>
<p>organization.
(c) The client asks the researcher to present other recommendations.
(d) The client asks the researcher to re-consider the analysis, because the findings 
</p>
<p>seem implausible to him/her.
(e) The client wishes to know the name of a particular customer who was very 
</p>
<p>negative about the quality of service provided.
</p>
<p>References
</p>
<p>Armstrong, J. S. (2010). Persuasive advertising: Evidence-based principles. New York, NJ: Palgrave Macmillan.
</p>
<p>Churchill Jr., G. A., &amp; Iacobucci, D. (2015). Marketing research: Methodological foundations (11th ed.). 
</p>
<p>Mason, OH: South-Western College Publishers.
</p>
<p>Huff, D. (1993). How to lie with statistics. New York: W. W. Norton &amp; Company.
</p>
<p>ICC/ESOMAR (2016) international code on market, opinion and social research, and data analytics. http://
</p>
<p>www.esomar.org/uploads/public/knowledge-and-standards/codes-and-guidelines/ICCESOMAR_
</p>
<p>Code_English_.pdf. Accessed 04 May 2018.
</p>
<p>Minto, B. (2009). The pyramid principle: Logic in writing and thinking (3rd ed.). Harlow: Pearson.
</p>
<p>Tufte, E. R. (2001). The visual display of quantitative information (2nd ed.). Cheshire, CT: Graphics Press.
</p>
<p>Further Reading
</p>
<p>Durate, N. (2008). Slideology. The art and science of crafting great presentations. Sebastopol: O&rsquo;Reilly Media.
</p>
<p>Reynolds, G. (2011). Presentation zen: Simple ideas on presentation design and delivery (2nd ed.). San Fran-
</p>
<p>cisco, CA: New Riders Press.</p>
<p/>
<div class="annotation"><a href="http://www.esomar.org/uploads/public/knowledge-and-standards/codes-and-guidelines/ICCESOMAR_Code_English_.pdf">http://www.esomar.org/uploads/public/knowledge-and-standards/codes-and-guidelines/ICCESOMAR_Code_English_.pdf</a></div>
<div class="annotation"><a href="http://www.esomar.org/uploads/public/knowledge-and-standards/codes-and-guidelines/ICCESOMAR_Code_English_.pdf">http://www.esomar.org/uploads/public/knowledge-and-standards/codes-and-guidelines/ICCESOMAR_Code_English_.pdf</a></div>
<div class="annotation"><a href="http://www.esomar.org/uploads/public/knowledge-and-standards/codes-and-guidelines/ICCESOMAR_Code_English_.pdf">http://www.esomar.org/uploads/public/knowledge-and-standards/codes-and-guidelines/ICCESOMAR_Code_English_.pdf</a></div>
</div>
<div class="page"><p/>
<p>377
</p>
<p> 
 
</p>
<p>  
</p>
<p>Supplementary  
Information
</p>
<p>Glossary &ndash; 378
</p>
<p>Index &ndash; 392
</p>
<p>&copy; Springer-Verlag GmbH Germany, part of Springer Nature 2019 
</p>
<p>M. Sarstedt, E. Mooi, A Concise Guide to Market Research, Springer Texts in Business  
</p>
<p>and Economics, https://doi.org/10.1007/978-3-662-56707-4</p>
<p/>
<div class="annotation"><a href="http://">http://</a></div>
</div>
<div class="page"><p/>
<p>378 
</p>
<p>α error: occurs when erroneously rejecting a true 
null hypothesis. Also referred to as type I error.
</p>
<p>α-inflation: results when multiple tests are con-
ducted simultaneously on the same data. The 
</p>
<p>result is that you are more likely to claim a signif-
</p>
<p>icant result when this is not so (i.e., an increase or 
</p>
<p>inflation in the type I error).
</p>
<p>Acquiescence: describes the tendency of respon-
dents from different cultures to agree with state-
</p>
<p>ments (e.g., as formulated in a Likert scale item) 
</p>
<p>regardless of their content.
</p>
<p>Adjusted R2: is a measure of goodness-of-fit that 
takes the number of independent variables and 
</p>
<p>the sample size into account. The statistic is useful 
</p>
<p>for comparing regression models with different 
</p>
<p>numbers of independent variables, sample sizes, 
</p>
<p>or both.
</p>
<p>Agglomerative clustering: is a type of hierar-
chical clustering method in which clusters are 
</p>
<p>consecutively formed from objects. It starts with 
</p>
<p>each object representing an individual cluster. 
</p>
<p>The objects are then sequentially merged to form 
</p>
<p>clusters of multiple objects, starting with the two 
</p>
<p>most similar.
</p>
<p>Aggregation: is a type of scale transformation 
in which variables measured at a lower level are 
</p>
<p>taken to a higher level.
</p>
<p>Akaike Information Criterion (AIC): is a relative 
measure of goodness-of-fit, which can be used to 
</p>
<p>compare regression models with different inde-
</p>
<p>pendent variables and/or number of observations. 
</p>
<p>Compared to an alternative model setup, smaller 
</p>
<p>AIC values indicate a better fit. The criterion is also 
</p>
<p>used in the two-step cluster analysis to determine 
</p>
<p>on the number of clusters.
</p>
<p>Alternative hypothesis: is the hypothesis against 
which the null hypothesis is tested.
</p>
<p>American Marketing Association (AMA): is the 
world&rsquo;s leading association for marketing profes-
</p>
<p>sionals.
</p>
<p>Analysis of Variance (ANOVA): is a multivariate 
data analysis technique that allows testing wheth-
</p>
<p>er the means of (typically) three or more groups 
</p>
<p>differ significantly on one (one-way ANOVA) or 
</p>
<p>two (two-way ANOVA) metric dependent vari-
</p>
<p>able(s). There are numerous extensions to more 
</p>
<p>dependent variables and to differently scaled 
</p>
<p>independent variables.
</p>
<p>Anti-image: is a measure used in principal com-
ponent and factor analysis to determine whether 
</p>
<p>the items correlate sufficiently. The anti-image 
</p>
<p>describes the portion of an item&rsquo;s variance that is 
</p>
<p>independent of another item in the analysis.
</p>
<p>Armstrong and Overton procedure: is used 
to assess the degree of non-response bias. This 
</p>
<p>procedure calls for comparing the first 50&nbsp;% 
</p>
<p> respondents with the last 50&nbsp;% with regard to key 
</p>
<p>demographic variables. The concept behind this 
</p>
<p>procedure is that later respondents more closely 
</p>
<p>match the characteristics of non-respondents.
</p>
<p>Autocorrelation: occurs when the residuals from 
a regression analysis are correlated.
</p>
<p>Average linkage: is a linkage algorithm in hier-
archical clustering methods in which the distance 
</p>
<p>between two clusters is defined as the average 
</p>
<p>distance between all pairs of objects in the two 
</p>
<p>clusters.
</p>
<p>β error: occurs when erroneously accepting a 
false null hypothesis. Also referred to as type II error.
</p>
<p>Back-translation: is a translation method used in 
survey research in which a survey is being trans-
</p>
<p>lated and then back-translated into the original 
</p>
<p>language by another person.
</p>
<p>Balanced scale: describes a scale with an equal 
number of positive and negative scale categories.
</p>
<p>Bar chart: is a graphical representation of a single 
categorical variable indicating each category&rsquo;s 
</p>
<p>frequency of occurrence. Bar charts are primarily 
</p>
<p>useful for describing nominal and ordinal variables.
</p>
<p>Bartlett method: is a procedure to generate 
factor scores in principal component analysis. The 
</p>
<p>resulting factor scores have a zero mean and a 
</p>
<p>standard deviation larger than one.
</p>
<p>Bartlett&rsquo;s test of sphericity: is used in the con-
text of principal component analysis and factor 
</p>
<p>analysis to assess whether the variables are suffi-
</p>
<p>ciently correlated.
</p>
<p>Glossary</p>
<p/>
</div>
<div class="page"><p/>
<p>Glossary
</p>
<p>379
</p>
<p>Centroid linkage: is a linkage algorithm in hier-
archical clustering methods in which the distance 
</p>
<p>between two clusters is defined as the distance 
</p>
<p>between their geometric centers (centroids).
</p>
<p>Chaining effect: is a solution pattern typically 
observed when using a single linkage algorithm in 
</p>
<p>cluster analysis.
</p>
<p>Chebychev distance: is a distance measure used 
in cluster analysis that uses the maximum of the 
</p>
<p>absolute difference in the clustering variables&rsquo; 
</p>
<p>values.
</p>
<p>City-block distance: is a distance measure 
used in cluster analysis that uses the sum of the 
</p>
<p>variables&rsquo; absolute differences. Also referred to as 
</p>
<p>Manhattan metric.
</p>
<p>Closed-ended questions: is a type of question 
format in which respondents have a certain 
</p>
<p> number of response categories from which to 
</p>
<p>choose.
</p>
<p>Cluster analysis: is a class of methods that 
groups a set of objects with the goal of obtaining 
</p>
<p>high similarity within the formed groups and high 
</p>
<p>dissimilarity between groups.
</p>
<p>Clustering variables: are variables used in cluster 
analysis.
</p>
<p>Clusters: are groups of objects with similar char-
acteristics.
</p>
<p>Codebook: contains essential details of a data file, 
such as variable names and summary statistics.
</p>
<p>Coefficient of determination (R2): is a measure 
used in regression analysis to express the depen-
</p>
<p>dent variable&rsquo;s amount of variance that the inde-
</p>
<p>pendent variables explain.
</p>
<p>Collinearity: arises when two variables are highly 
correlated.
</p>
<p>Communality: describes the amount of a vari-
able&rsquo;s variance that the extracted factors in a prin-
</p>
<p>cipal component and factor analysis reproduce.
</p>
<p>Complete linkage: is a linkage algorithm in hier-
archical clustering methods in which the distance 
</p>
<p>between two clusters corresponds to the longest 
</p>
<p>distance between any two members in the two 
</p>
<p>clusters.
</p>
<p>Bayes Information Criterion (BIC): is a relative 
measure of goodness-of-fit, which can be used to 
</p>
<p>compare regression models with different inde-
</p>
<p>pendent variables and/or number of observations. 
</p>
<p>Compared to an alternative model setup, smaller 
</p>
<p>BIC values indicate a better fit. The criterion is also 
</p>
<p>used in the two-step cluster analysis to determine 
</p>
<p>on the number of clusters.
</p>
<p>Big data: refers to very large datasets, generally 
a mix of quantitative and qualitative data in very 
</p>
<p>large volumes.
</p>
<p>Binary logistic regression: is a type of regression 
method used when the dependent variable is 
</p>
<p>binary and only takes two values.
</p>
<p>Bivariate statistics: describes statistics that 
express the empirical relationship between 
</p>
<p>two variables. Covariance and correlation are 
</p>
<p>key  measures that indicate (linear) associations 
</p>
<p> between two variables.
</p>
<p>Bonferroni correction: is a post hoc test typically 
used in an ANOVA that maintains the familywise 
</p>
<p>error rate by calculating a new pairwise alpha that 
</p>
<p>divides the statistical significance level α by the 
</p>
<p>number of comparisons made. See also familywise 
</p>
<p>error rate and α-inflation.
</p>
<p>Bootstrapping: is a resampling technique that 
draws a large number of subsamples from the 
</p>
<p>original data (with replacement) and estimates 
</p>
<p>parameters for each subsample. It is used to deter-
</p>
<p>mine standard errors of coefficients to assess their 
</p>
<p>statistical significance without relying on distribu-
</p>
<p>tional assumptions.
</p>
<p>Box plot: shows the distribution of a (typically 
continuous) variable. It consists of elements 
</p>
<p> expressing the dispersion of the data. Also referred 
</p>
<p>to as box-and-whisker plot.
</p>
<p>Case: is an object such as a customer, a company, 
or a country in statistical analysis. Also referred to 
</p>
<p>as observation.
</p>
<p>Causal research: is used to understand the rela-
tionships between two or more variables. Causal 
</p>
<p>research explains how variables relate.
</p>
<p>Census: is a procedure of systematically acquiring 
and recording information about all the members 
</p>
<p>of a given population.</p>
<p/>
</div>
<div class="page"><p/>
<p>380 Glossary
</p>
<p>Components: are extracted in the course of a 
principal component analysis. They are also com-
</p>
<p>monly referred to as factors.
</p>
<p>Confidence interval: provides the lower and 
upper limit of values within which a population 
</p>
<p>parameter will fall with a certain probability 
</p>
<p>(e.g.,&nbsp;95&nbsp;%).
</p>
<p>Confirmatory factor analysis: is a special form of 
factor analysis used to test whether the measures 
</p>
<p>of a construct are consistent with a researcher's 
</p>
<p>understanding of that construct.
</p>
<p>Constant: is a characteristic of an object whose 
value does not change.
</p>
<p>Constant sum scale: is a type of scale that 
requires respondents to allocate a certain total 
</p>
<p>number of points (typically 100) to a number of 
</p>
<p>alternatives.
</p>
<p>Construct: measures a concept that is abstract, 
complex, and cannot be directly observed. Also 
</p>
<p>referred to as latent variable.
</p>
<p>Construct scores: are composite scores that 
calculate a value for each construct of each obser-
</p>
<p>vation. Construct scores are often computed by 
</p>
<p>taking the mean of all the items associated with 
</p>
<p>the construct.
</p>
<p>Construct validity: is the degree of correspon-
dence between a measure at the conceptual level 
</p>
<p>and its empirical manifestation. Researchers often 
</p>
<p>use this as an umbrella term for content, criterion, 
</p>
<p>discriminant, face, and nomological validity.
</p>
<p>Content validity: refers to the extent to which a 
measure represents all facets of a given construct.
</p>
<p>Control variables: are included into (typically 
regression) analyses in order to rule these out as 
</p>
<p>alternative explanations.
</p>
<p>Correlation: is a measure of how strongly two 
variables relate to each other. Correlation is a 
</p>
<p>scaled version of the covariance.
</p>
<p>Correlation residuals: are the differences be-
tween the original item correlations and the repro-
</p>
<p>duced item correlations in a principal component 
</p>
<p>and factor analysis.
</p>
<p>Covariance: is a measure of how strongly two 
variables relate to each other.
</p>
<p>Covariance-based structural equation model-
ing (CB-SEM): is an approach to structural equa-
tion modeling used to test relationships between 
</p>
<p>multiple items and constructs.
</p>
<p>Criterion validity: measures how well one mea-
sure predicts the outcome of another measure 
</p>
<p>when both are measured at the same time.
</p>
<p>Cronbach&rsquo;s Alpha: is a measure of internal con-
sistency reliability. Cronbach&rsquo;s Alpha generally 
</p>
<p>varies between 0 and 1&nbsp;with greater values indi-
</p>
<p>cating higher degrees of reliability.
</p>
<p>Crosstabs: are tables in a matrix format that show 
the frequency distribution of nominal or ordinal 
</p>
<p>variables.
</p>
<p>Cross validation: entails comparing the results 
of an analysis with those obtained when using a 
</p>
<p>new dataset.
</p>
<p>Customer relationship management (CRM):  
refers to a system of databases and software used 
</p>
<p>to track and predict customer behavior.
</p>
<p>Data entry errors: is a mistake in transcribing 
data during data entry. Erroneous values that fall 
</p>
<p>outside a variable&rsquo;s standard range can easily be 
</p>
<p>identified by means of descriptive statistics (mini-
</p>
<p>mum, maximum, and range).
</p>
<p>Degrees of freedom (df): represents the amount 
of information available to estimate a test statistic. 
</p>
<p>Generally, an estimate&rsquo;s degrees of freedom are 
</p>
<p>equal to the amount of independent information 
</p>
<p>used (i.e., the number of observations) minus the 
</p>
<p>number of parameters estimated.
</p>
<p>Dendrogram: visualizes the results of a cluster anal-
ysis. Horizontal lines in a dendrogram indicate the 
</p>
<p>distances at which the objects have been merged.
</p>
<p>Dependence of observations: is the degree to 
which observations are related.
</p>
<p>Dependent variables: are the concepts a re-
searcher wants to understand, explain, or predict.
</p>
<p>Descriptive research: is used to detail certain 
phenomena, characteristics, or functions. Descrip-
</p>
<p>tive research often builds on previous exploratory 
</p>
<p>research.
</p>
<p>Directional hypothesis: looks for an increase or 
a decrease in a parameter (such as a population </p>
<p/>
</div>
<div class="page"><p/>
<p>Glossary
</p>
<p>381
</p>
<p>mean) relative to a specific standard. Directional 
</p>
<p>hypothesis can either be right-tailed or left-tailed.
</p>
<p>Direct oblimin rotation: is a popular oblique 
type of rotation, which allows specifying the maxi-
</p>
<p>mum degree of obliqueness.
</p>
<p>Discriminant validity: ensures that a measure 
is empirically unique and represents phenomena 
</p>
<p>of interest that other measures in a model do not 
</p>
<p>capture.
</p>
<p>Distance matrix: expresses the distances 
 between pairs of objects.
</p>
<p>Divisive clustering: is a type of hierarchical 
clustering method in which all objects are initially 
</p>
<p>merged into a single cluster, which the algorithm 
</p>
<p>then gradually splits up.
</p>
<p>Double-barreled questions: are survey ques-
tions to which respondents can agree with one 
</p>
<p>part but not with the other. Also refers to survey 
</p>
<p>questions that cannot be answered without 
</p>
<p> accepting an assumption.
</p>
<p>Dummy variables: are binary variables that indi-
cate whether a certain trait is present or not.
</p>
<p>Durbin-Watson test: is a test for autocorrelation 
used in regression analysis.
</p>
<p>Effect size: is a statistical measure to determine 
the strength of the effect (e.g., in an ANOVA).
</p>
<p>Eigenvalue: indicates the amount of variance 
reproduced by a specific component or factor.
</p>
<p>Eigenvectors: are the results of a principal com-
ponent analysis and include the factor weights.
</p>
<p>Equidistance: is indicated when the (psycholog-
ical) distances between a scale&rsquo;s categories are 
</p>
<p>identical.
</p>
<p>Equidistant scale: see Equidistance.
</p>
<p>Error: is the difference between the regression 
line (which represents the regression prediction) 
</p>
<p>and the actual observation.
</p>
<p>Error sum of squares: quantifies the difference 
between the observations and the regression line.
</p>
<p>ESOMAR: is the world organization for market, 
consumer, and societal research.
</p>
<p>Estimation sample: is the sample used to run a 
statistical analysis.
</p>
<p>Eta-squared (η2): is a statistic used in an ANOVA 
to describe the ratio of the between-group varia-
</p>
<p>tion to the total variation, thereby indicating the 
</p>
<p>variance accounted for by the factor variable(s). 
</p>
<p>η2 is identical to the R2, the coefficient of determi-
</p>
<p>nation in regression analysis. It can take on values 
</p>
<p>between 0 and 1&nbsp;whereas a high value implies that 
</p>
<p>the factor exerts a strong influence on the depen-
</p>
<p>dent variable.
</p>
<p>Ethics: are a system of morals and principles, which 
defines a research organization&rsquo;s obligations, for 
</p>
<p>example, with regard to the findings they release 
</p>
<p>being an accurate portrayal of the survey data.
</p>
<p>Ethnography: is a type of qualitative research in 
which the researcher interacts with consumers 
</p>
<p>over a period to observe and question them.
</p>
<p>Euclidean distance: is a distance measure com-
monly used in cluster analysis. It is the square 
</p>
<p>root of the sum of the squared differences in the 
</p>
<p>variables&rsquo; values. Also referred to as straight line 
</p>
<p>distance.
</p>
<p>Experimental design: describes which treatment 
variables to administer and how these relate to 
</p>
<p>dependent variables. Prominent experimental 
</p>
<p>designs include the one-shot case study, the 
</p>
<p> before-after design, the before-after design with a 
</p>
<p>control group, and the Solomon four-group design.
</p>
<p>Experiments: are study designs commonly used in 
causal research in which a researcher controls for a 
</p>
<p>potential cause and observes corresponding chang-
</p>
<p>es in hypothesized effects via treatment variables.
</p>
<p>Explained variation: is the degree of variation 
that a factor variable in an ANOVA explains. It is 
</p>
<p>similar to the Coefficient of Determination used 
</p>
<p>for regression analysis.
</p>
<p>Exploratory factor analysis: is a type of factor 
analysis that derives factors from a set of cor-
</p>
<p>related indicator variables without the researcher 
</p>
<p>having to prespecify a factor structure.
</p>
<p>Exploratory research: is conducted when the 
researcher has little or no information about a par-
</p>
<p>ticular problem or opportunity. It is used to refine 
</p>
<p>research questions, discover new relationships, 
</p>
<p>patterns, themes, and ideas or to inform measure-
</p>
<p>ment development.</p>
<p/>
</div>
<div class="page"><p/>
<p>382 Glossary
</p>
<p>External secondary data: are compiled outside 
a company for a variety of purposes. Sources of 
</p>
<p>secondary data include, for example, govern-
</p>
<p>ments, trade associations, market research firms, 
</p>
<p>consulting firms, (literature) databases, and social 
</p>
<p>networks.
</p>
<p>External validity: is the extent to which the study 
results can be generalized to real-world settings.
</p>
<p>Extreme response styles: occur when respon-
dents systematically select the endpoints of a 
</p>
<p>response scale.
</p>
<p>Face-to-face interview: See Personal interview
</p>
<p>Face validity: is the extent to which a test is 
subjectively viewed as covering the concept it 
</p>
<p>purports to measure.
</p>
<p>Factor analysis: is a statistical procedure that 
uses the correlation patterns among a set of 
</p>
<p> indicator variables to derive factors that repre-
</p>
<p>sent most of the original variables&rsquo; variance. Also 
</p>
<p> referred to as Principal axis factoring.
</p>
<p>Factor-cluster segmentation: is the process of 
running a cluster analysis on factor scores derived 
</p>
<p>from a principal component or factor analysis to 
</p>
<p>handle collinear variables.
</p>
<p>Factor level: the values of a factor variable that 
differentiates the groups in an ANOVA.
</p>
<p>Factor loading: is the correlation between a 
(unit-scaled) factor and a variable.
</p>
<p>Factor rotation: is a technique used to facilitate 
the interpretation of solutions in principal compo-
</p>
<p>nent and factor analysis.
</p>
<p>Factor scores: are composite scores that calcu-
late a value for each factor of each observation.
</p>
<p>Factor variable: is a categorical variable used to 
define the groups (e.g., three types of promotion 
</p>
<p>campaigns) in an ANOVA.
</p>
<p>Factor weights: express the relationships be-
tween variables and factors.
</p>
<p>Factors: are (1) independent variables in an 
 ANOVA, and (2) the resulting variables of a 
</p>
<p>principal component and factor analysis that 
</p>
<p>summarize the information from a set of indicator 
</p>
<p>variables.
</p>
<p>Familywise error rate: is the probability of mak-
ing one or more false discoveries or type I errors 
</p>
<p>when performing multiple hypotheses tests. See 
</p>
<p>also α-inflation.
</p>
<p>Field experiments: are experiments in which the 
manipulation of a treatment variable occurs in a 
</p>
<p>natural setting, thereby emphasizing the external 
</p>
<p>validity, but potentially compromising internal 
</p>
<p>validity.
</p>
<p>Field service firms: are companies that focus on 
conducting surveys, determining samples, sample 
</p>
<p>sizes, and collecting data. Some of these firms 
</p>
<p>also translate surveys, or provide addresses and 
</p>
<p>contact details.
</p>
<p>Focus groups: is a method of data collection in 
which six to ten participants discuss a defined 
</p>
<p>topic under the leadership of a moderator.
</p>
<p>Forced-choice scale: is an answer scale that 
omits a neutral category, thereby forcing the 
</p>
<p>respondents to make a positive or negative 
</p>
<p> assessment.
</p>
<p>Formative construct: is a type of measurement 
in which the indicators form the construct.
</p>
<p>Free-choice scale: is an answer scale that in-
cludes a neutral choice category. Respondents are 
</p>
<p>therefore not forced to make a positive or nega-
</p>
<p>tive assessment.
</p>
<p>Frequency table: is a table that displays the 
absolute, relative, and cumulative frequencies of 
</p>
<p>one or more variables.
</p>
<p>F-test: a test statistic used in an ANOVA and 
regression analysis to test the overall model&rsquo;s 
</p>
<p>significance.
</p>
<p>F-test of sample variance: see Levene&rsquo;s test.
</p>
<p>Full service providers: are large market research 
companies, such as The Nielsen Company, Kan-
</p>
<p>tar, or GfK, that offer syndicated and customized 
</p>
<p>services.
</p>
<p>Grand mean: is the overall average across all 
levels of a factor variable or other variables that 
</p>
<p>split the dataset into groups.
</p>
<p>Heteroskedasticity: refers to a situation in 
regression analysis in which the variance of the 
</p>
<p>residuals is not constant.</p>
<p/>
</div>
<div class="page"><p/>
<p>Glossary
</p>
<p>383
</p>
<p>Hierarchical clustering methods: develop a 
tree-like structure of objects in the course of the 
</p>
<p>clustering process, which can be top-down (di-
</p>
<p>visive clustering) or bottom-up (agglomerative 
</p>
<p>clustering).
</p>
<p>Histogram: is a graph that shows how frequently 
categories derived from a continuous variable 
</p>
<p>occur.
</p>
<p>Homoscedasticity: refers to a situation in regres-
sion analysis in which the variance of the residuals 
</p>
<p>is constant.
</p>
<p>Hypotheses: are claims made about effects or 
relationships in a population.
</p>
<p>Inconsistent answers: are a respondent&rsquo;s contra-
dictory answer patterns.
</p>
<p>Independent samples: occur if observations are 
sampled only once.
</p>
<p>Independent samples t-test: a test using the 
t-statistic that establishes whether two means 
</p>
<p>collected from independent samples differ sig-
</p>
<p>nificantly.
</p>
<p>Independent variables: are variables that 
 explain or predict a dependent variable.
</p>
<p>In-depth interview: is a qualitative conversation 
with participants on a specific topic. This interview 
</p>
<p>type is typically used in exploratory research as it 
</p>
<p>allows one-to-one probing to foster interaction 
</p>
<p>between the interviewer and the respondent.
</p>
<p>Index: consists of a set of variables that defines 
the meaning of the resulting composite.
</p>
<p>Index construction: is the procedure of combin-
ing several items to form an index.
</p>
<p>Interaction effect: refers to how the effect of one 
variable on another variable is influenced by a 
</p>
<p>third variable.
</p>
<p>Interaction term: is an auxiliary variable entered 
into the regression model to account for the inter-
</p>
<p>action of the moderator variable and an indepen-
</p>
<p>dent variable.
</p>
<p>Intercept: is the expected mean value of the 
dependent variable in a regression analysis, when 
</p>
<p>the independent variables are zero. Also referred 
</p>
<p>to as a constant.
</p>
<p>Internal consistency reliability: is a form of 
reliability used to judge the consistency of results 
</p>
<p>across items in the same test. It determines wheth-
</p>
<p>er the items measuring a construct are highly cor-
</p>
<p>related. The most prominent measure of internal 
</p>
<p>consistency reliability is Cronbach&rsquo;s Alpha.
</p>
<p>Internal secondary data: are data that compa-
nies compile for various reporting and analysis 
</p>
<p>purposes.
</p>
<p>Internal validity: is the extent to which causal 
claims can be made in respect of the study results.
</p>
<p>Interquartile range: is the difference between 
the third and first quartile.
</p>
<p>Inter-rater reliability: is the degree of agreement 
between raters expressed by the amount of con-
</p>
<p>sensus in their judgment.
</p>
<p>Interviewer fraud: is an issue in data collection 
resulting from interviewers making up data or 
</p>
<p>even falsifying entire surveys.
</p>
<p>Item non-response: occurs when people do not 
provide answers to certain questions, for exam-
</p>
<p>ple, because they refuse to answer, or forgot to 
</p>
<p>answer.
</p>
<p>Items: represent measurable characteristics in 
conceptual models and statistical analysis. Also 
</p>
<p>referred to as indicators.
</p>
<p>Kaiser criterion: is a statistic used in principal 
component and factor analysis to determine 
</p>
<p>the number of factors to extract from the data. 
</p>
<p>According to this criterion, researchers should 
</p>
<p>extract all factors with an eigenvalue greater than 
</p>
<p>one. Also referred to as latent root criterion.
</p>
<p>Kaiser&ndash;Meyer&ndash;Olkin criterion: is an index 
used to assess the adequacy of the data for a 
</p>
<p>principal component and factor analysis. High 
</p>
<p>values  indicate that the data are sufficiently cor-
</p>
<p>related. Also referred to as measure of sampling 
</p>
<p>adequacy (MSA).
</p>
<p>KISS principle: the abbreviation of &ldquo;Keep it short 
and simple!&rdquo; and implies that any research report 
</p>
<p>should be as concise as possible.
</p>
<p>Kruskal-Wallis rank test: is the non-parametric 
equivalent of the ANOVA. The null hypothesis of 
</p>
<p>the test is that the distribution of the test variable 
</p>
<p>across all groups is identical.</p>
<p/>
</div>
<div class="page"><p/>
<p>384 Glossary
</p>
<p>k-means: is a group of clustering methods that 
starts with an initial partitioning of all the objects 
</p>
<p>into a prespecified number of clusters and then 
</p>
<p>gradually re-allocates objects in order to minimize 
</p>
<p>the overall within-cluster variation.
</p>
<p>k-means++: is a variant of the k-means method 
that uses an improved initialization process.
</p>
<p>k-medians: is a popular variant of k-means that 
aims at minimizing the absolute deviations from 
</p>
<p>the cluster medians.
</p>
<p>k-medoids: is a variant of k-means that uses oth-
er cluster centers rather than the mean or median.
</p>
<p>Lab experiments: are performed in controlled 
environments (usually in a company or academic 
</p>
<p>lab) to isolate the effects of one or more treatment 
</p>
<p>variables on an outcome.
</p>
<p>Label switching: a situation in which the labels 
of clusters change from one analysis to the other.
</p>
<p>Laddering: is an interviewing technique where 
the interviewer pushes a seemingly simple re-
</p>
<p>sponse to a question in order to find subconscious 
</p>
<p>motives. It is typically used in the means-end 
</p>
<p>approach.
</p>
<p>Latent concepts: represent broad ideas or 
thoughts about certain phenomena that research-
</p>
<p>ers have established and want to measure in their 
</p>
<p>research.
</p>
<p>Latent root criterion: See Kaiser criterion.
</p>
<p>Latent variable: measures a concept that is ab-
stract, complex, and cannot be directly observed 
</p>
<p>by (multiple) items. Also referred to as construct.
</p>
<p>Left-tailed hypothesis: is a directional hypoth-
esis expressed in a direction (lower) relative to a 
</p>
<p>standard.
</p>
<p>Levene&rsquo;s test: tests the equality of the variances 
between two or more groups of data. Also referred 
</p>
<p>to as F-test of sample variance.
</p>
<p>Likert scale: is a type of answering scale in which 
respondents have to indicate their degree of 
</p>
<p>agreement to a statement. The degree of agree-
</p>
<p>ment is usually set by the scale endpoints, which 
</p>
<p>range from strongly disagree to strongly agree.
</p>
<p>Limited service providers: are market research 
companies that specialize in one or more services.
</p>
<p>Line chart: is a type of chart in which measure-
ment points are ordered (typically according to 
</p>
<p>their x-axis value) and joined with straight-line 
</p>
<p>segments.
</p>
<p>Linkage algorithm: defines the distance from 
a newly formed cluster to a certain object, or to 
</p>
<p>other clusters in the solution.
</p>
<p>Listwise deletion: entails deleting cases with one 
or more missing value(s) in any of the variables 
</p>
<p>used in an analysis.
</p>
<p>Little&rsquo;s MCAR test: is a test to analyze the pat-
terns of missing data by comparing the observed 
</p>
<p>data with the pattern expected if the data were 
</p>
<p>missing completely at random.
</p>
<p>Local optimum: is an optimal solution when 
compared with similar solutions, but not a global 
</p>
<p>optimum.
</p>
<p>Log transformation: is a type of scale transfor-
mation commonly used to handle skewed data.
</p>
<p>Mail surveys: are paper-based surveys sent to 
respondents via regular mail.
</p>
<p>Manhattan metric: See City-block distance.
</p>
<p>Manipulation checks: a type of analysis in exper-
iments to check whether the experimental treat-
</p>
<p>ment was effective.
</p>
<p>Mann-Whitney U test: is the non-parametric 
equivalent of the independent samples t-test used 
</p>
<p>to assess whether two sample means are equal 
</p>
<p>or not.
</p>
<p>Marginal mean: represents the mean value of 
one category in respect of each of the other types 
</p>
<p>of categories.
</p>
<p>Market segmentation: is the segmenting of 
markets into groups (segments) of objects (e.g., 
</p>
<p>consumers) with similar characteristics (e.g., needs 
</p>
<p>and wants).
</p>
<p>Market segments: are groups of objects with 
similar characteristics.
</p>
<p>Matching coefficients: are similarity measures 
that express the degree to which the clustering 
</p>
<p>variables&rsquo; values fall into the same category.
</p>
<p>Mean: is the most common method of defining a 
typical value of a list of numbers. It is equal to the </p>
<p/>
</div>
<div class="page"><p/>
<p>Glossary
</p>
<p>385
</p>
<p>sum of a variable&rsquo;s values divided by the number 
</p>
<p>of observations. Also referred to as arithmetic 
</p>
<p>mean or simply average.
</p>
<p>Means-end approach: a method used to identify 
the ends consumers aim to satisfy and the means 
</p>
<p>(consumption) they use to do so.
</p>
<p>Measurement scaling: refers to (1) the level at 
which a variable is measured (nominal, ordinal, 
</p>
<p>interval or ratio scale), and (2) the general act of 
</p>
<p>using a set of variables to measure a construct.
</p>
<p>Measure of sampling adequacy (MSA): See 
Kaiser&ndash;Meyer&ndash;Olkin criterion
</p>
<p>Measures of centrality: are statistical indices of a 
typical or average value of a list of numbers. There 
</p>
<p>are two main types of measures of centrality, the 
</p>
<p>median and the mean.
</p>
<p>Measures of dispersion: provide researchers with 
information about the variability of the data (i.e., 
</p>
<p>how far the values are spread out). There are four 
</p>
<p>main types of measures of dispersion: the range, in-
</p>
<p>terquartile range, variance, and standard deviation.
</p>
<p>Median: is a value that separates the lowest 50&nbsp;% 
of values from the highest 50&nbsp;% of values.
</p>
<p>Middle response styles: a systematic way of 
responding to survey items that describes respon-
</p>
<p>dents&rsquo; tendency to choose the mid points of a 
</p>
<p>response scale.
</p>
<p>Minto principle: a guideline for presentations 
that starts with the conclusion, raising questions 
</p>
<p>in the audience&rsquo;s mind about the way this con-
</p>
<p>clusion was reached. The presenter subsequently 
</p>
<p>explains the steps involved in the analysis.
</p>
<p>Missing at random (MAR): is a missing values 
pattern in which the probability that data points 
</p>
<p>are missing varies from respondent to respondent.
</p>
<p>Missing completely at random (MCAR): is a 
missing values pattern in which the probability 
</p>
<p>that data points are missing is unrelated to any 
</p>
<p>other measured variable and to the variable with 
</p>
<p>the missing values.
</p>
<p>Missing data: occur when entire observations are 
missing (survey non-response), or respondents have 
</p>
<p>not answered all the items (item non-response).
</p>
<p>Mixed mode: is the act of combining different 
ways of administering surveys.
</p>
<p>Moderation analysis: involves assessing whether 
the effect of an independent variable on a depen-
</p>
<p>dent variable depends on the values of a third 
</p>
<p>variable, referred to as a moderator variable.
</p>
<p>(Multi)collinearity: is a data issue that arises in 
regression analysis when two or more indepen-
</p>
<p>dent variables are highly correlated.
</p>
<p>Multi-item construct: is a measurement of an 
abstract concept that uses several items.
</p>
<p>Multinomial logistic regression: is a type of 
 regression analysis used when the dependent 
</p>
<p>variable is nominal and takes more than two 
</p>
<p>values.
</p>
<p>Multiple imputation: is a simulation-based sta-
tistical technique that replaces missing observa-
</p>
<p>tions with a set of possible values (as opposed to a 
</p>
<p>single value), representing the uncertainty about 
</p>
<p>the missing data&rsquo;s true value.
</p>
<p>Multiple regression: is a type of regression anal-
ysis that includes multiple independent variables.
</p>
<p>Mystery shopping: is a type of observational 
study in which a trained researcher visits a store or 
</p>
<p>restaurant and consumes their products/services.
</p>
<p>Nested models: are simpler versions of a com-
plex model.
</p>
<p>Net Promoter Score (NPS): is a measure of cus-
tomer loyalty that uses the single question: &ldquo;How 
</p>
<p>likely are you to recommend our company/product/
</p>
<p>service to a friend or colleague?&rdquo;
</p>
<p>Noise: is a synonym for unexplained variation 
that cannot be explained. Also referred to as ran-
</p>
<p>dom noise.
</p>
<p>Nomological validity: is the degree to which 
a construct behaves as it should in a system of 
</p>
<p>related constructs.
</p>
<p>Non-directional hypothesis: tests for any dif-
ference in the parameter, whether positive or 
</p>
<p>negative.
</p>
<p>Non-hierarchical clustering methods: see Parti-
tioning methods.
</p>
<p>Nonparametric tests: are statistical tests for 
hypothesis testing that do not assume a specific 
</p>
<p>distribution of the data (typically a normal distri-
</p>
<p>bution).</p>
<p/>
</div>
<div class="page"><p/>
<p>386 Glossary
</p>
<p>Non-probability sampling: is a sampling tech-
nique that does not give every individual in the 
</p>
<p>population an equal chance of being included in 
</p>
<p>the sample. The resulting sample is typically not 
</p>
<p>representative of the population.
</p>
<p>Non-random missing: is a missing values pat-
tern in which the probability that data points are 
</p>
<p>missing depends on the variable and on other 
</p>
<p>unobserved factors.
</p>
<p>Null and alternative hypothesis: the null hy-
pothesis (indicated as H0) is a statement expecting 
</p>
<p>no difference or no effect. The alternative hypoth-
</p>
<p>esis (indicated as H1) is the hypothesis against 
</p>
<p>which the null hypothesis is tested.
</p>
<p>Oblique rotation: is a technique used to facilitate 
the interpretation of the factor solution in which 
</p>
<p>the independence of a factor to all other factors is 
</p>
<p>not maintained.
</p>
<p>Observation: is an object, such as a customer, a 
company, or a country, in statistical analysis. Also 
</p>
<p>referred to as case.
</p>
<p>Observational studies: are procedures for gath-
ering data in which the researcher observes peo-
</p>
<p>ple&rsquo;s behavior in a certain context. Observational 
</p>
<p>studies are normally used to understand what 
</p>
<p>people are doing rather than why they are doing it.
</p>
<p>Omega-squared (ω&sup2;): is a statistic used in an 
ANOVA to describe the ratio of the between-group 
</p>
<p>variation to the total variation, thereby indicat-
</p>
<p>ing the variance accounted for by the data. It is 
</p>
<p>commonly used for sample sizes of 50 or less and 
</p>
<p>corresponds to the Adjusted R2 of regression anal-
</p>
<p>ysis. Omega-squared is also used to indicate effect 
</p>
<p>sizes of individual variables in regression analysis.
</p>
<p>One-sample t-test: is a parametric test used to 
compare one mean with a given value.
</p>
<p>One-tailed tests: are a class of statistical tests 
frequently used when the hypothesis is expressed 
</p>
<p>directionally (i.e., &lt; or &gt;). The region of rejection is 
</p>
<p>on one side of the sampling distribution.
</p>
<p>One-way ANOVA: is a type of ANOVA that in-
volves a single metric dependent variable and one 
</p>
<p>factor variable with three (or more) levels.
</p>
<p>Open-ended questions: are a type of question 
format that provides little or no structure for re-
</p>
<p>spondents&rsquo; answers. Generally, the researcher asks a 
</p>
<p>question and the respondent writes down his or her 
</p>
<p>answer in a box. Also referred to as verbatim items.
</p>
<p>Operationalization: is the process of defining a 
set of variables to measure a construct. The pro-
</p>
<p>cess defines latent concepts and allows them to 
</p>
<p>be measured empirically.
</p>
<p>Ordinary least squares (OLS): is the estimation 
approach commonly used in regression analysis 
</p>
<p>and involves minimizing the squared deviations 
</p>
<p>from the observations to the regression line 
</p>
<p>(i.e.,&nbsp;the residuals).
</p>
<p>Orthogonal rotation: is a technique used to 
facilitate the interpretation of a factor solution 
</p>
<p>in which a factor&rsquo;s independence is maintained 
</p>
<p>from all other factors. The correlation between the 
</p>
<p>factors is determined as zero.
</p>
<p>Outliers: are observations that differ substantially 
from other observations in respect of one or more 
</p>
<p>characteristics.
</p>
<p>Paired samples: are samples that include multi-
ple observations from the same object (e.g., firm 
</p>
<p>or individual).
</p>
<p>Paired samples t-test: is a statistical procedure 
used to determine whether there is a significant 
</p>
<p>mean difference between observations measured 
</p>
<p>at two points in time.
</p>
<p>Parallel analysis: is a statistic used in principal 
component and factor analysis to determine 
</p>
<p>the number of factors to extract from the data. 
</p>
<p> According to this criterion, researchers should ex-
</p>
<p>tract all factors whose eigenvalues are larger than 
</p>
<p>those derived from randomly generated data with 
</p>
<p>the same sample size and number of variables.
</p>
<p>Parametric test: are statistical tests that assume a 
specific data distribution (typically normal).
</p>
<p>Partial least squares structural equation mod-
eling (PLS-SEM): is a method to estimate struc-
tural equation models. The goal is to maximize 
</p>
<p>the explained variance of the dependent latent 
</p>
<p>variables.
</p>
<p>Partitioning methods: is a group of clustering 
procedures that does not establish a tree-like 
</p>
<p>structure of objects and clusters, but exchanges 
</p>
<p>objects between clusters to optimize a certain 
</p>
<p>goal criterion. The most popular type of partition-
</p>
<p>ing method is k-means.</p>
<p/>
</div>
<div class="page"><p/>
<p>Glossary
</p>
<p>387
</p>
<p>Path diagram: is a visual representation of ex-
pected relationships tested in a structural equa-
</p>
<p>tion modeling analysis.
</p>
<p>Personal interviews: is an interview technique 
that involves face-to-face contact between the 
</p>
<p>interviewer and the respondent. Also referred to 
</p>
<p>as face-to-face interviews.
</p>
<p>Pie chart: displays the relative frequencies of a 
variable&rsquo;s values.
</p>
<p>Population: is a group of objects (e.g., consum-
ers, companies, or products) that a researcher 
</p>
<p>wants to assess.
</p>
<p>Post hoc tests: are a group of tests used for 
paired comparisons in an ANOVA. Post hoc tests 
</p>
<p>maintain the familywise error rate (i.e., they pre-
</p>
<p>vent excessive type I error).
</p>
<p>Power analysis: is a procedure used to estimate 
the power of a statistical test.
</p>
<p>Power of a (statistical) test: represents the prob-
ability of rejecting a null hypothesis when it is in 
</p>
<p>fact false. In other words, the power of a statistical 
</p>
<p>test is the probability of rendering an effect sig-
</p>
<p>nificant when it is indeed significant. The power is 
</p>
<p>defined by 1&minus;β, where β is the probability of a type 
</p>
<p>II error.
</p>
<p>Practical significance: refers to whether differ-
ences or effects are large enough to influence 
</p>
<p>decision-making processes.
</p>
<p>Predictive validity: is the extent to which an 
instrument predicts the outcome of another vari-
</p>
<p>able, measured at a later point in time.
</p>
<p>Primary data: are data gathered for a specific 
research project.
</p>
<p>Principal axis factoring: See Factor analysis.
</p>
<p>Principal component analysis: is a statistical 
procedure that uses correlation patterns among 
</p>
<p>a set of indicator variables to derive factors 
</p>
<p>that represent most of the original variables&rsquo; 
</p>
<p>variance. Different from factor analysis, the 
</p>
<p>procedure uses all the variance in the variables 
</p>
<p>as input.
</p>
<p>Principal components: are linear composites 
of original variables that reproduce the original 
</p>
<p>variables&rsquo; variance as well as possible.
</p>
<p>Principal factor analysis: See Factor analysis.
</p>
<p>Probability sampling: is a sampling technique 
that gives every individual in the population an 
</p>
<p>equal chance, different from zero, of being includ-
</p>
<p>ed in the sample.
</p>
<p>Profiling: is a step in market segmentation that 
identifies observable variables (e.g., demograph-
</p>
<p>ics) that characterize the segments.
</p>
<p>Projective technique: is a special type of testing 
procedure, usually used as part of in-depth inter-
</p>
<p>views. This technique provides the participants 
</p>
<p>with a stimulus (e.g., pictures, words) and then 
</p>
<p>gauges their responses (e.g., through sentence 
</p>
<p>completion).
</p>
<p>Promax rotation: is a popular oblique rotation 
method used in principal component and factor 
</p>
<p>analysis.
</p>
<p>p-value: is the probability of erroneously reject-
ing a true null hypothesis in a given statistical test.
</p>
<p>Pyramid structure for presentations: See Minto 
principle.
</p>
<p>Qualitative data: are audio, pictorial, or textual 
information that researchers use to answer re-
</p>
<p>search questions.
</p>
<p>Qualitative research: is primarily used to gain 
an understanding of why certain things happen. It 
</p>
<p>can be used in an exploratory context by defining 
</p>
<p>problems in more detail, or by developing hypoth-
</p>
<p>eses to be tested in subsequent research.
</p>
<p>Quantile plot: is a graphical method for compar-
ing two (typically normal) distributions by plotting 
</p>
<p>their quantiles against each other.
</p>
<p>Quantitative data: are data to which numbers 
are assigned to represent specific characteristics.
</p>
<p>Quartimax rotation: is a variant of the oblimin 
rotation.
</p>
<p>R2: See Coefficient of determination.
</p>
<p>Ramsey&rsquo;s RESET test: is a test for linearity used in 
regression analysis.
</p>
<p>Random noise: is a synonym for unexplained 
variation that cannot be explained in an analysis 
</p>
<p>such as in a regression or ANOVA.</p>
<p/>
</div>
<div class="page"><p/>
<p>388 Glossary
</p>
<p>Range: is the difference between the highest and 
the lowest value in a variable measured, at least, 
</p>
<p>on an ordinal scale.
</p>
<p>Range standardization: is a type of scale trans-
formation in which the values of a scale are stan-
</p>
<p>dardized to a specific range that the researcher 
</p>
<p>has set.
</p>
<p>Rank order scale: is an ordinal scale that asks 
respondents to rank a set of objects or character-
</p>
<p>istics in terms of, for example, importance, prefer-
</p>
<p>ence, or similarity.
</p>
<p>Reflective constructs: is a type of measurement 
in which the indicators are considered manifesta-
</p>
<p>tions of the underlying construct.
</p>
<p>Regression method: is a procedure to generate 
factor scores in principal component analysis. The 
</p>
<p>resulting factor scores have a zero mean and unit 
</p>
<p>standard deviation.
</p>
<p>Regression sum of squares: quantifies the dif-
ference between the regression line and the line 
</p>
<p>indicating the average. It represents the variation 
</p>
<p>in the data that the regression analysis explains.
</p>
<p>Reliability: is the degree to which a measure is 
free from random error.
</p>
<p>Reliability analysis: is an element of a confirma-
tory factor analysis and essential when working 
</p>
<p>with measurement scales. See Reliability.
</p>
<p>Research design: describes the general ap-
proach to answering a research question related 
</p>
<p>to a marketing opportunity or problem. There 
</p>
<p>are three broad types of research design: explor-
</p>
<p>atory research, descriptive research, and causal 
</p>
<p>research.
</p>
<p>Residual: is the unexplained variance in a regres-
sion model. Also referred to as disturbance term.
</p>
<p>Reverse-scaled items: are items whose state-
ment (if a Likert scale is used), or word pair (if a 
</p>
<p>semantic differential scale is used) is reversed 
</p>
<p>when compared to the other items in the set.
</p>
<p>Right-tailed hypothesis: is a directional hypoth-
esis expressed in a direction (higher) relative to a 
</p>
<p>standard.
</p>
<p>Russell and Rao coefficient: is a similarity coeffi-
cient used in cluster analysis.
</p>
<p>Sample size: is the number of observations 
drawn from a population.
</p>
<p>Sampling: is the process through which objects 
are selected from a population.
</p>
<p>Sampling error: occurs when the sample and pop-
ulation structure differ on relevant characteristics.
</p>
<p>Scale development: is the process of defining a 
set of variables to measure a construct and which 
</p>
<p>follows an iterative process with several steps and 
</p>
<p>feedback loops. Also referred to as operationaliza-
</p>
<p>tion, or, in the case of an index, index construction.
</p>
<p>Scale transformation: is the act of changing 
a variable&rsquo;s values to ensure comparability with 
</p>
<p>other variables, or to make the data suitable for 
</p>
<p>analysis.
</p>
<p>Scanner data: are collected at the checkout of 
a supermarket where details about each product 
</p>
<p>sold are entered into a database.
</p>
<p>Scatter plot: is a graph that represents the rela-
tionship between two variables, thus portraying 
</p>
<p>the joint values of each observation in a two-di-
</p>
<p>mensional graph
</p>
<p>Scree plot: is a graph used in principal compo-
nent and factor analysis that plots the number 
</p>
<p>of factors against the eigenvalues, sometimes 
</p>
<p>resulting in a distinct break (elbow) that indicates 
</p>
<p>the number of factors to extract. Following the 
</p>
<p>same principle, the scree plot is also used in hi-
</p>
<p>erarchical cluster analysis to plot the number of 
</p>
<p>clusters against the distances at which objects 
</p>
<p>were merged.
</p>
<p>Secondary data: are data that have already been 
gathered, often for a different research purpose 
</p>
<p>and some time ago. Secondary data comprise 
</p>
<p>internal secondary data, external secondary data, 
</p>
<p>or a mix of both.
</p>
<p>Segment specialists: are companies that con-
centrate on specific market segments, such as a 
</p>
<p>particular industry or type of customer.
</p>
<p>Self-contained figure: is a graph in a market 
research report that should be numbered sequen-
</p>
<p>tially and have a meaningful title so that it can be 
</p>
<p>understood without reading the text.
</p>
<p>Self-contained table: is a table in a market 
research report that should be numbered sequen-</p>
<p/>
</div>
<div class="page"><p/>
<p>Glossary
</p>
<p>389
</p>
<p>tially and have a meaningful title so that it can be 
</p>
<p>understood without reading the text.
</p>
<p>Semantic differential scales: is a type of answer-
ing scale that comprises opposing pairs of words, 
</p>
<p>normally adjectives (e.g., young/old, masculine/
</p>
<p>feminine) constituting the endpoints of the scale. 
</p>
<p>Respondents then indicate how well one of the 
</p>
<p>word in each pair describes how he or she feels 
</p>
<p>about the object to be rated (e.g., a company or 
</p>
<p>brand).
</p>
<p>Sentence completion: is a type of projective 
technique that provides respondents with begin-
</p>
<p>nings of sentences that they have to complete in 
</p>
<p>ways that are meaningful to them.
</p>
<p>Shapiro-Wilk test: is a test for normality (i.e., 
whether the data are normally distributed).
</p>
<p>Significance level: is the probability that an 
effect is incorrectly assumed when there is in fact 
</p>
<p>none. The researcher sets the significance level 
</p>
<p>prior to the analysis.
</p>
<p>Silhouette measure of cohesion and separation:  
is an overall goodness-of-fit measure in two-step 
</p>
<p>clustering.
</p>
<p>Simple matching coefficient: is a similarity 
coefficient used in cluster analysis.
</p>
<p>Simple regression: is the simplest type of regres-
sion analysis with one dependent and one inde-
</p>
<p>pendent variable.
</p>
<p>Single-item constructs: is a measurement of a 
concept that uses only one item.
</p>
<p>Single linkage: is a linkage algorithm in hierar-
chical clustering methods in which the distance 
</p>
<p>between two clusters corresponds to the shortest 
</p>
<p>distance between any two members in the two 
</p>
<p>clusters.
</p>
<p>Skewed data: occur if a variable is asymmetrically 
distributed. A positive skew (also called right-
</p>
<p>skewed) occurs when many observations are 
</p>
<p>concentrated on the left side of the distribution, 
</p>
<p>producing a long right tail (the opposite is called 
</p>
<p>negative skew or left-skewed).
</p>
<p>Social desirability bias: occurs when respon-
dents provide socially desirable answers (e.g., by 
</p>
<p>reporting higher or lower incomes than are actual-
</p>
<p>ly true), or take a position that they believe society 
</p>
<p>favors (e.g., not smoking or drinking).
</p>
<p>Social media analytics: are methods for ana-
lyzing social networking data and comprise text 
</p>
<p>mining, social network analysis, and trend analysis.
</p>
<p>Social networking data: reflect how people 
would like others to perceive them and, thus, 
</p>
<p>indicate consumers&rsquo; intentions. Product or compa-
</p>
<p>ny-related social networking data are of specific 
</p>
<p>interest to market researchers.
</p>
<p>Specialized service firms: are market research 
companies that focus on particular products, 
</p>
<p>markets, or market research techniques.
</p>
<p>Split-half reliability: is a type of reliability assess-
ment in which scale items are divided into halves 
</p>
<p>and the scores of the halves are correlated.
</p>
<p>Split-sample validation: involves splitting the 
dataset into two samples, running the analysis on 
</p>
<p>both samples, and comparing the results.
</p>
<p>SPSS: Computer package specializing in quanti-
tative data analysis.
</p>
<p>Standard deviation: describes the sample distri-
bution values&rsquo; variability from the mean. It is the 
</p>
<p>square root of the variance.
</p>
<p>Standard error: is the sampling distribution of 
a statistic&rsquo;s standard deviation, mostly from the 
</p>
<p>mean.
</p>
<p>Standardized effects: express the relative ef-
fects of differently measured independent vari-
</p>
<p>ables in a regression analysis by expressing them 
</p>
<p>in terms of standard deviation changes from the 
</p>
<p>mean.
</p>
<p>Standardizing variables: have been rescaled 
(typically to a zero mean and unit standard devia-
</p>
<p>tion) to facilitate comparisons between differently 
</p>
<p>scaled variables.
</p>
<p>Statistical significance: occurs when an effect 
is so large that it is unlikely to have occurred by 
</p>
<p>chance. Statistical significance depends on sev-
</p>
<p>eral factors, including the size of the effect, the 
</p>
<p>variation in the sample data, and the number of 
</p>
<p>observations.
</p>
<p>Straight line distance: See Euclidean distance.</p>
<p/>
</div>
<div class="page"><p/>
<p>390 Glossary
</p>
<p>Straight-lining: occurs when a respondent marks 
the same response in almost all the items.
</p>
<p>Structural equation modeling: is a multivariate 
data analysis technique used to measure rela-
</p>
<p>tionships between constructs, as well as between 
</p>
<p>constructs and their associated indicators.
</p>
<p>Survey non-response: occurs when entire re-
sponses are missing. Survey non-response rates 
</p>
<p>are usually 75&nbsp;%&ndash;95&nbsp;%.
</p>
<p>Surveys: are often used for gathering primary 
data. Designing surveys involves a six-step pro-
</p>
<p>cess: 1. Determine the survey goal; 2. determine 
</p>
<p>the type of questionnaire required and the admin-
</p>
<p>istration method; 3. decide on the questions and 
</p>
<p>4. the scale; 5. design the questionnaire; and 6. 
</p>
<p>pretest and administer the questionnaire.
</p>
<p>Suspicious response patterns: are issues in 
response styles in respect of straight-lining and 
</p>
<p>inconsistent answers that a researcher needs to 
</p>
<p>address in the analysis.
</p>
<p>Syndicated data: are data sold to multiple cli-
ents, allowing them to compare key measures 
</p>
<p>with those of the rest of the market.
</p>
<p>Telephone interviews: allow researchers to 
collect data quickly and facilitate open-ended 
</p>
<p>responses, although not as well as personal inter-
</p>
<p>views.
</p>
<p>Test markets: are a type of field experiment that 
evaluates a new product or promotional cam-
</p>
<p>paign under real market conditions.
</p>
<p>Test-retest reliability: is a type of reliability 
assessment in which the researcher obtains re-
</p>
<p>peated measurement of the same respondent or 
</p>
<p>group of respondents, using the same instrument 
</p>
<p>and under similar conditions. Also referred to as 
</p>
<p>stability of the measurement.
</p>
<p>Test statistic: is calculated from the sample data 
to assess the strength of the evidence in support 
</p>
<p>of the null hypothesis.
</p>
<p>Tolerance: is a measure to detect collinearity 
defined as 1/VIF, where VIF is the variance inflation 
</p>
<p>factor.
</p>
<p>Total sum of squares: quantifies the difference 
between the observations and the line indicating 
</p>
<p>the average.
</p>
<p>Transforming data: is an optional step in work-
flow of data, involving variable respecification and 
</p>
<p>scale transformation.
</p>
<p>Treatments: are elements in an experiment that 
are used to manipulate the participants by sub-
</p>
<p>jecting them to different situations. A simple form 
</p>
<p>of treatment could be an advertisement with and 
</p>
<p>without humor.
</p>
<p>t-test: is the most popular type of parametric test 
for comparing a mean with a given standard and 
</p>
<p>for comparing the means of independent samples 
</p>
<p>(independent samples t-test), or the means of 
</p>
<p>paired samples (paired samples t-test).
</p>
<p>Tukey&rsquo;s honestly significant difference test: is 
a popular post hoc test used in an ANOVA that 
</p>
<p>controls for type I errors, but is limited in terms 
</p>
<p>of statistical power. Often simply referred to as 
</p>
<p>Tukey&rsquo;s method.
</p>
<p>Two-sample t-test: is the most popular type of 
parametric test for comparing the means of inde-
</p>
<p>pendent or paired samples.
</p>
<p>Two-tailed tests: are a class of statistical tests 
frequently used when the hypothesis is not ex-
</p>
<p>pressed directionally (i.e., &ne;). The region of rejec-
</p>
<p>tion is on two sides of the sampling distribution.
</p>
<p>Two-way ANOVA: is a type of ANOVA that in-
volves a single metric dependent variable and two 
</p>
<p>factor variables with three (or more) levels.
</p>
<p>Type I error: occurs when erroneously rejecting a 
true null hypothesis. Also referred to as α error.
</p>
<p>Type II error: occurs when erroneously accept-
ing a false null hypothesis. Also referred to as β 
</p>
<p>error.
</p>
<p>Unbalanced scale: describes a scale with an 
unequal number of positive and negative scale 
</p>
<p>categories.
</p>
<p>Unexplained variation: is the degree of variation 
that a factor variable in an ANOVA cannot explain. 
</p>
<p>It can occur if extraneous factors, not accounted 
</p>
<p>for in the analysis, cause variation instead of the 
</p>
<p>factor variable.
</p>
<p>Unit of analysis: is the level at which a variable 
is measured. Typical measurement levels include 
</p>
<p>that of the respondents, customers, stores, com-
</p>
<p>panies, or countries.</p>
<p/>
</div>
<div class="page"><p/>
<p>Glossary
</p>
<p>391
</p>
<p>Univariate statistics: are statistics that describe 
the centrality and dispersion of a single variable.
</p>
<p>Unstandardized effects: express the absolute 
effects that a one-unit increase in the indepen-
</p>
<p>dent variables have on the dependent variable in 
</p>
<p>a regression analysis.
</p>
<p>Validation sample: is a random subsample of the 
original dataset used for validation testing.
</p>
<p>Validity: is the degree to which a researcher mea-
sures what (s)he wants to measure. It is the degree 
</p>
<p>to which a measure is free from systematic error.
</p>
<p>Variable: represents a measurable characteristic 
whose value can change.
</p>
<p>Variable respecification: involves transforming data 
to create new variables, or to modify existing ones.
</p>
<p>Variance: a measure of dispersion computed by 
the sum of the squared differences of each value 
</p>
<p>and a variable&rsquo;s mean, divided by the sample size 
</p>
<p>minus 1.
</p>
<p>Variance inflation factor (VIF): quantifies the 
degree of collinearity between the independent 
</p>
<p>variables in a regression analysis.
</p>
<p>Variance ratio criterion: is a statistic used in 
cluster analysis to determine the number of 
</p>
<p>clusters. The criterion compares the within- and 
</p>
<p>between-cluster variation of different numbers of 
</p>
<p>clusters.
</p>
<p>Varimax rotation: is the most popular orthogo-
nal rotation method used in principal component 
</p>
<p>and factor analysis.
</p>
<p>Verbatim items: See Open-ended questions.
</p>
<p>Visual aids: include overhead transparencies, 
flip charts, or slides (e.g., PowerPoint or Prezi) that 
</p>
<p>help emphasize important points and facilitate 
</p>
<p>the communication of difficult ideas in a presenta-
</p>
<p>tion of market research results.
</p>
<p>Visual analogue scale: is a type of answering 
scale in which respondents use levers that allow 
</p>
<p>scaling on a continuum. This scale does not pro-
</p>
<p>vide response categories.
</p>
<p>Ward&rsquo;s linkage: is a linkage algorithm in hierar-
chical clustering methods that combines those 
</p>
<p>objects whose merger increases the overall 
</p>
<p>within-cluster variance by the smallest possible 
</p>
<p>degree.
</p>
<p>Web surveys: are less expensive to administer 
and can be fast in terms of data collection, because 
</p>
<p>they can be set up very quickly. Also referred to as 
</p>
<p>computer-assisted web interviews (CAWI).
</p>
<p>Weighted average linkage: is a variant of the 
average linkage algorithm used in cluster analysis 
</p>
<p>that weights the distances according to the num-
</p>
<p>ber of objects in the cluster.
</p>
<p>Weighted Least Squares: is a variant of a stan-
dard regression analysis, which is used to account 
</p>
<p>for violated regression assumptions such as het-
</p>
<p>eroskedastic regression errors. It &ldquo;weights&rdquo; the re-
</p>
<p>gression line such that observations with a smaller 
</p>
<p>variance are given greater weight in determining 
</p>
<p>the regression coefficients.
</p>
<p>Welch correction: is a statistical test used in an 
ANOVA to assess the significance of the overall 
</p>
<p>model when the group variances differ significant-
</p>
<p>ly and the groups differ in size.
</p>
<p>Wilcoxon matched-pairs signed-rank test: is 
the non-parametric equivalent of the paired sam-
</p>
<p>ples t-test.
</p>
<p>Wilcoxon signed-rank test: is the non-paramet-
ric equivalent of the independent samples t-test.
</p>
<p>Workflow: is a strategy to keep track of the en-
tering, cleaning, describing, and transforming of 
</p>
<p>data.
</p>
<p>z-standardization: is a type of scale transforma-
tion in which the values of a scale are standardized 
</p>
<p>to a zero mean and unit standard deviation.
</p>
<p>z-test: is any statistical test for which the distribu-
tion of the test statistic under the null hypothesis 
</p>
<p>can be approximated by a normal distribution.</p>
<p/>
</div>
<div class="page"><p/>
<p>392 
</p>
<p>Index
</p>
<p>α error 158
</p>
<p>α-inflation 177
</p>
<p>β error 158
</p>
<p>χ2-test 105, 114, 116
</p>
<p>3-D scatter plot 113
</p>
<p>5&nbsp;% trimmed mean 111
</p>
<p>A
Acquiescence 68, 98
</p>
<p>Adaptive questioning 64
</p>
<p>Adjusted R2 186, 229
</p>
<p>Agglomeration schedule 337
</p>
<p>Agglomerative clustering 309
</p>
<p>Aggregating data 31
</p>
<p>Aggregation 119
</p>
<p>Akaike&rsquo;s Information Criterion 
</p>
<p>(AIC) 331
</p>
<p>Alternative hypothesis 156
</p>
<p>American Customer Satisfaction 
</p>
<p>Index (ACSI) 56
</p>
<p>American Marketing Association 
</p>
<p>(AMA) 3
</p>
<p>Analysis of Variance (ANOVA) 163
</p>
<p>Anti-image 264
</p>
<p>Arithmetic mean 111
</p>
<p>Armstrong and Overton 
</p>
<p>procedure 39
</p>
<p>Association measures (cluster 
</p>
<p>analysis) 324
</p>
<p>Autocorrelation 224
</p>
<p>Average 111
</p>
<p>Average linkage 310
</p>
<p>B
Back-translation 68
</p>
<p>Balanced scale 74
</p>
<p>Bar chart 108
</p>
<p>Bartlett method (factor scores) 276
</p>
<p>Bartlett&rsquo;s test of sphericity 265
</p>
<p>Bayes Information Criterion 
</p>
<p>(BIC) 331
</p>
<p>Before measurement effect 85
</p>
<p>Before-after design 84
</p>
<p>Before-after design with a control 
</p>
<p>group 84
</p>
<p>Best-worst scaling 70
</p>
<p>Between-group mean squares 183
</p>
<p>Between-group Variation 180
</p>
<p>Between-groups linkage 310
</p>
<p>Big data 54, 320
</p>
<p>Binary logistic regression 215
</p>
<p>Bivariate descriptives 106
</p>
<p>Bivariate graphs 112
</p>
<p>Bivariate statistics 114
</p>
<p>Bivariate tables 112
</p>
<p>Bonferroni correction 184
</p>
<p>Bootstrapping 224
</p>
<p>Box plot 109
</p>
<p>Box-and-whisker plot 109
</p>
<p>Bubble plot 113
</p>
<p>C
Case 27
</p>
<p>Causal research 18, 81
</p>
<p>Causality 18
</p>
<p>Census 39
</p>
<p>Centroid linkage 310
</p>
<p>Chaining effect 311
</p>
<p>Chart Builder (SPSS) 129
</p>
<p>Chart Editor (SPSS) 140
</p>
<p>Chebychev distance 324
</p>
<p>City-block distance 323
</p>
<p>Closed-ended questions 67
</p>
<p>Cluster analysis 302
</p>
<p>Cluster feature tree 321
</p>
<p>Cluster sampling 41
</p>
<p>Clustering variables 302
</p>
<p>Clusters 302
</p>
<p>Codebook 120
</p>
<p>Coefficient of determination See 
</p>
<p>R2
</p>
<p>Collinearity 215, 268
</p>
<p>Communality 271
</p>
<p>Company records (data source) 50
</p>
<p>Complete linkage 310
</p>
<p>Components 267
</p>
<p>Composite measure 28
</p>
<p>Compute Variable (SPSS) 129, 132
</p>
<p>Computer-assisted personal 
</p>
<p>interviews (CAPI) 62
</p>
<p>Computer-assisted self-interviews 
</p>
<p>(CASI) 63
</p>
<p>Computer-assisted telephone 
</p>
<p>interviews (CATI) 63
</p>
<p>Computer-assisted web interviews 
</p>
<p>(CAWI) 63
</p>
<p>Confidence interval 172
</p>
<p>Confirmatory factor analysis 260, 
</p>
<p>276
</p>
<p>Constant 27
</p>
<p>Constant (regression  
</p>
<p>analysis) 211
</p>
<p>Constant sum scale 70
</p>
<p>Construct score 118
</p>
<p>Construct validity 37, 57
</p>
<p>Constructs 118
</p>
<p>Consulting firms (data source) 52
</p>
<p>Content validity 37
</p>
<p>Contingency coefficient 116
</p>
<p>Contingency tables 113
</p>
<p>Control variables 233
</p>
<p>Convenience sampling 42
</p>
<p>Conversion rate 53
</p>
<p>Correlation 115
</p>
<p>Correlation residuals 275
</p>
<p>Covariance 114
</p>
<p>Covariance-based structural 
</p>
<p>equation modeling (CB-
</p>
<p>SEM) 280
</p>
<p>Cramer&rsquo;s V 116
</p>
<p>Criterion validity 37, 307, 333
</p>
<p>Cronbach&rsquo;s Alpha 280
</p>
<p>Cross-validation 233
</p>
<p>Crosstabs 113
</p>
<p>Culture-specific response  
</p>
<p>styles 98
</p>
<p>Customer Relationship 
</p>
<p>Management (CRM) 50
</p>
<p>D
Data entry errors 99
</p>
<p>Degrees of freedom 168
</p>
<p>Dendrogram 328
</p>
<p>Dependent variables (regression 
</p>
<p>analysis) 210
</p>
<p>Descriptive research 17, 106
</p>
<p>Direct oblimin rotation 274
</p>
<p>Directional hypothesis 157
</p>
<p>Discriminant validity 37
</p>
<p>Disturbance term 212
</p>
<p>Divisive clustering 309
</p>
<p>Don&rsquo;t know option 73
</p>
<p>Double-barreled questions 67
</p>
<p>Dummies 118
</p>
<p>Dummy variables 118, 218
</p>
<p>Durbin-Watson test 225</p>
<p/>
</div>
<div class="page"><p/>
<p>393 A&ndash;L
Index
</p>
<p>E
Effect size 185
</p>
<p>Eigenvalues 269
</p>
<p>Eigenvectors 267
</p>
<p>Elbow (scree plot) 329
</p>
<p>Enterprise Resource Planning (ERP) 
</p>
<p>systems 50
</p>
<p>Equidistance 34
</p>
<p>Equidistant scale 74
</p>
<p>Error (regression analysis) 212
</p>
<p>Error sum of squares 228
</p>
<p>ESOMAR 3
</p>
<p>Estimation sample 232
</p>
<p>Eta squared 185
</p>
<p>Ethics 374
</p>
<p>Ethnography 16, 59
</p>
<p>Euclidean distance 322
</p>
<p>Existing research studies (data 
</p>
<p>source) 51
</p>
<p>Experimental design 83
</p>
<p>Experimental research 81
</p>
<p>Experiments 82
</p>
<p>Expert validity 37
</p>
<p>Explained variation 180
</p>
<p>Exploratory factor analysis 260
</p>
<p>Exploratory research 14
</p>
<p>External secondary data 51
</p>
<p>External validity 83
</p>
<p>Extraneous variables 83
</p>
<p>Extreme response styles 98
</p>
<p>Extreme values (box plot) 110
</p>
<p>Eyetracking 59
</p>
<p>F
F-test 183, 227
</p>
<p>F-test of sample variance 163
</p>
<p>Face validity 37
</p>
<p>Face-to-face interviews 62
</p>
<p>Factor analysis 259
</p>
<p>Factor extraction 267
</p>
<p>Factor levels 178
</p>
<p>Factor loadings 268, 272
</p>
<p>Factor rotation 273
</p>
<p>Factor scores 275
</p>
<p>Factor variable 177
</p>
<p>Factor weights 267
</p>
<p>Factor-cluster segmentation 308
</p>
<p>Factors 259
</p>
<p>False negative 158
</p>
<p>False positive 158
</p>
<p>Familywise error rate 177, 184
</p>
<p>Field experiments 20, 83
</p>
<p>Field service firms 7
</p>
<p>Focus groups 15, 80
</p>
<p>Forced-choice scale 71
</p>
<p>Formative constructs 28
</p>
<p>Free-choice scale 72
</p>
<p>Frequency table 110
</p>
<p>Full factorial design 83
</p>
<p>Full service providers 6
</p>
<p>Funnel approach (questionnaire 
</p>
<p>design) 74
</p>
<p>Furthest neighbor 310
</p>
<p>Fused market research 32
</p>
<p>G
Games-Howell procedure 185
</p>
<p>GfK Spex Retail 52
</p>
<p>Global representativeness 
</p>
<p>(sampling) 39
</p>
<p>Governments (data source) 51
</p>
<p>Grand mean 155
</p>
<p>Graphboard Template Chooser 
</p>
<p>(SPSS) 129
</p>
<p>H
Heteroskedasticity 223
</p>
<p>Hierarchical clustering 
</p>
<p>methods 309
</p>
<p>Histogram 108
</p>
<p>Hochberg&rsquo;s GT2 185
</p>
<p>Homoscedasticity 223
</p>
<p>Hybrid market research 32
</p>
<p>Hypotheses 17
</p>
<p>I
Icicle diagram 337
</p>
<p>In-depth interviews 15, 78
</p>
<p>Inconsistent answers 99
</p>
<p>Independent observations 32
</p>
<p>Independent samples 154
</p>
<p>Independent samples t-tests 163, 
</p>
<p>173
</p>
<p>Independent variables (regression 
</p>
<p>analysis) 33, 210
</p>
<p>Index 27, 118
</p>
<p>Index construction 28
</p>
<p>Indicators 27
</p>
<p>Inter-rater reliability 38
</p>
<p>Interaction effect 232
</p>
<p>Interaction term 232
</p>
<p>Intercept 211
</p>
<p>Internal consistency reliability 38, 
</p>
<p>280
</p>
<p>Internal secondary data 50
</p>
<p>Internal validity 83
</p>
<p>Internet data 53
</p>
<p>Interquartile range 109, 111
</p>
<p>Interval scale 34
</p>
<p>Interviewer bias 62, 64
</p>
<p>Interviewer fraud 97
</p>
<p>Item content 66
</p>
<p>Item non-response 102
</p>
<p>Item wording 67
</p>
<p>Items 27, 261
</p>
<p>J
Jaccard coefficient (JC) 326
</p>
<p>Judgmental sampling 42
</p>
<p>K
k-means 317
</p>
<p>k-means++ 317
</p>
<p>k-medians 317
</p>
<p>k-medoids 317
</p>
<p>Kaiser criterion 271
</p>
<p>Kaiser&ndash;Meyer&ndash;Olkin (KMO) 
</p>
<p>criterion 265
</p>
<p>Kendall&rsquo;s tau 116
</p>
<p>KISS principle 358
</p>
<p>Kruskal-Wallis rank test 164
</p>
<p>Kulczynski (cluster analysis) 326
</p>
<p>L
Lab experiments 20, 83
</p>
<p>Label switching 332
</p>
<p>Laddering 79
</p>
<p>Latent concepts 27
</p>
<p>Latent root criterion 271
</p>
<p>Latent variable 27
</p>
<p>Left-skewed data 119
</p>
<p>Left-tailed hypothesis 157
</p>
<p>Levels of measurement 33
</p>
<p>Levene&rsquo;s test 163, 174
</p>
<p>Likert scale 69
</p>
<p>Limited service providers 7
</p>
<p>Line chart 113
</p>
<p>Linkage algorithms 310
</p>
<p>Listwise deletion 106
</p>
<p>Literature databases (data 
</p>
<p>source) 52
</p>
<p>Little&rsquo;s MCAR test 104
</p>
<p>Local optimum 320
</p>
<p>Log transformation 119</p>
<p/>
</div>
<div class="page"><p/>
<p>394 Index
</p>
<p>M
Mail surveys 65
</p>
<p>Mall intercepts 42
</p>
<p>Manhattan metric 323
</p>
<p>Manipulation checks 82
</p>
<p>Mann-Whitney U test 164
</p>
<p>Marginal mean 155
</p>
<p>Market research firms (data 
</p>
<p>source) 52
</p>
<p>Market segmentation 17, 302
</p>
<p>Marketing opportunities 13
</p>
<p>Marketing symptoms 13
</p>
<p>Matching coefficients 325
</p>
<p>MaxDiff scale 70
</p>
<p>Mean 111
</p>
<p>Means-end approach 79
</p>
<p>Measure of sampling adequacy 
</p>
<p>(MSA) 265
</p>
<p>Measurement error 35
</p>
<p>Measurement scaling 33
</p>
<p>Measures of central tendency 110
</p>
<p>Measures of centrality 110
</p>
<p>Measures of dispersion 111
</p>
<p>Median 109&ndash;110
</p>
<p>Middle response styles 98
</p>
<p>Minto principle 372
</p>
<p>Misresponse rates 68
</p>
<p>Missing completely at random 
</p>
<p>(MCAR) 103
</p>
<p>Missing data 101
</p>
<p>Missing not at random 
</p>
<p>(MNAR) 103
</p>
<p>Missing at random (MAR) 103
</p>
<p>Mixed methodology 32
</p>
<p>Mixed mode 65
</p>
<p>Mobile phone surveys 63
</p>
<p>Moderation analysis 232
</p>
<p>Multi-item constructs 29
</p>
<p>Multi-item scale 27
</p>
<p>Multicollinearity 216
</p>
<p>Multinomial logistic 
</p>
<p>regression 215
</p>
<p>Multiple imputation 106
</p>
<p>Multiple regression 213
</p>
<p>Mystery shopping 59
</p>
<p>N
Nearest neighbor (cluster 
</p>
<p>analysis) 310
</p>
<p>Negative skew 119
</p>
<p>Nested models 229
</p>
<p>Net Promoter Score (NPS) 29
</p>
<p>Noise 35
</p>
<p>Nominal scale 33
</p>
<p>Nomological validity 38, 57
</p>
<p>Non-directional hypothesis 157
</p>
<p>Non-hierarchical clustering 
</p>
<p>methods 317
</p>
<p>Non-probability sampling 42
</p>
<p>Nonparametric tests 154
</p>
<p>O
oblique rotation 274
</p>
<p>Observation 27
</p>
<p>Observational studies 16, 58
</p>
<p>Ochiai (cluster analysis) 326
</p>
<p>OLS See Ordinary least squares
</p>
<p>Omega squared 186
</p>
<p>One-sample t-test 163, 166
</p>
<p>One-shot case study 83
</p>
<p>One-tailed test 165
</p>
<p>One-way ANOVA 178
</p>
<p>Open-ended questions 67
</p>
<p>Operationalization 28
</p>
<p>Ordinal scale 33
</p>
<p>Ordinary least squares (OLS) 218
</p>
<p>orthogonal rotation 273
</p>
<p>Outliers 99, 110, 226, 311
</p>
<p>P
p-value 170
</p>
<p>Page requests 53
</p>
<p>Paired samples t-test 154, 175
</p>
<p>Parallel analysis 272
</p>
<p>Parametric tests 154
</p>
<p>Partial least squares structural 
</p>
<p>equation modeling (PLS-
</p>
<p>SEM) 280
</p>
<p>Partitioning clustering 
</p>
<p>methods 317
</p>
<p>Path diagram 279
</p>
<p>Pearson&rsquo;s correlation 
</p>
<p>coefficient 115
</p>
<p>Personal interviews 62
</p>
<p>Phi 116
</p>
<p>Pie chart 110
</p>
<p>Population 38
</p>
<p>Positive skew 119
</p>
<p>Post hoc tests 184
</p>
<p>Power of a statistical test 159
</p>
<p>Power analysis 159
</p>
<p>Practical significance 159
</p>
<p>Practice effects 38
</p>
<p>Predictive validity 37
</p>
<p>Pretest 76
</p>
<p>Primary data 58
</p>
<p>Principal axis factoring 259
</p>
<p>Principal component analysis 
</p>
<p>(PCA) 259
</p>
<p>Principal components 267
</p>
<p>Principal factor analysis 259
</p>
<p>PRIZM 333
</p>
<p>Probability sampling 41
</p>
<p>Profiling (cluster analysis) 331
</p>
<p>Projective techniques 15, 79
</p>
<p>Promax rotation 274
</p>
<p>Pyramid structure 372
</p>
<p>Q
Q-Q plot 162
</p>
<p>Qualitative data 30
</p>
<p>Qualitative research 32, 77
</p>
<p>Quantile plot 162, 194
</p>
<p>Quantitative data 30
</p>
<p>Quantitative research 32
</p>
<p>Quartiles 111
</p>
<p>Questionnaire design 74
</p>
<p>Question order 74
</p>
<p>Quota sampling 42
</p>
<p>R
R2 186, 227
</p>
<p>Ramsey&rsquo;s RESET test 222
</p>
<p>Random error 35
</p>
<p>Random noise 181
</p>
<p>Randomization (experiments) 84
</p>
<p>Range 111
</p>
<p>Range standardization 119, 325
</p>
<p>Rank order scales 69
</p>
<p>Ratio scale 34
</p>
<p>Recode (SPSS) 133
</p>
<p>Recoding 117
</p>
<p>Reflective constructs 28
</p>
<p>Regression method (factor 
</p>
<p>scores) 276
</p>
<p>Regression sum of squares 227
</p>
<p>Reliability 36
</p>
<p>Reliability analysis 260, 279
</p>
<p>Representative sample 39
</p>
<p>Research design 13
</p>
<p>Research problem 13
</p>
<p>Residual 212
</p>
<p>Respondent bias 62
</p>
<p>Response categories (design) 72
</p>
<p>Response categories (labeling) 73
</p>
<p>Response categories (number) 71
</p>
<p>Response rates 76
</p>
<p>Reverse-scaled items 68, 98
</p>
<p>Right-skewed data 119</p>
<p/>
</div>
<div class="page"><p/>
<p>395 M&ndash;W
Index
</p>
<p>Right-tailed hypothesis 157
</p>
<p>Russell and Rao coefficient 326
</p>
<p>Ryan/Einot-Gabriel/Welsch Q 
</p>
<p>(REGWQ) 185
</p>
<p>S
Sales reports (data source) 51
</p>
<p>Sample size 43
</p>
<p>Sampling 39
</p>
<p>Sampling error 41, 154
</p>
<p>Sampling frame 41
</p>
<p>Scale development 28
</p>
<p>Scale properties 71
</p>
<p>Scale transformation 118
</p>
<p>Scale types 69
</p>
<p>Scanner data 17
</p>
<p>Scatter plot 101, 113
</p>
<p>Scree plot 271, 329
</p>
<p>Screeners 74
</p>
<p>Screening questions 74
</p>
<p>Search engines 55
</p>
<p>Secondary data 49
</p>
<p>Segment specialists 7
</p>
<p>Select cases (SPSS) 132
</p>
<p>Self-contained figure 363
</p>
<p>Self-contained table 363
</p>
<p>Self-selection (experiments) 85
</p>
<p>Semantic differential scales 69
</p>
<p>Sentence completion 79
</p>
<p>Sessions 53
</p>
<p>Shapiro-Wilk test 162
</p>
<p>Shelf tests 22
</p>
<p>Significance level 154
</p>
<p>Silhouette measure of cohesion 
</p>
<p>and separation 350
</p>
<p>Simple matching (SM) 
</p>
<p>coefficient 326
</p>
<p>Simple random sampling 41
</p>
<p>Simple regression 213
</p>
<p>Single linkage 310
</p>
<p>Single-item constructs 29
</p>
<p>Skewed data 119
</p>
<p>Snowball sampling 42
</p>
<p>Social desirability bias 66
</p>
<p>Social media analytics 53
</p>
<p>Social network analysis 53
</p>
<p>Social networking data 53
</p>
<p>Solomon four-group design 85
</p>
<p>Spearman&rsquo;s correlation 
</p>
<p>coefficient 116
</p>
<p>Specialized service firms 8
</p>
<p>Specific representativeness 
</p>
<p>(sampling) 39
</p>
<p>Split File (SPSS) 129&ndash;130
</p>
<p>split-half reliability 279
</p>
<p>Split-sample validation 232
</p>
<p>SPSS 123
</p>
<p>SPSS Statistics Data Editor 125
</p>
<p>SPSS Statistics Viewer 127
</p>
<p>SPSS syntax 128
</p>
<p>Spurious correlation 19
</p>
<p>Squared Euclidean distance 322
</p>
<p>Stability of the measurement 38
</p>
<p>Standard deviation 112
</p>
<p>Standard error (regression 
</p>
<p>analysis) 167, 212
</p>
<p>Standardized effects 231
</p>
<p>Standardizing variables 119
</p>
<p>Statistical significance 153
</p>
<p>Straight line distance 322
</p>
<p>Straight-lining 98
</p>
<p>Strata (sampling) 41
</p>
<p>Stratified sampling 41
</p>
<p>Structural equation modeling 260, 
</p>
<p>280
</p>
<p>Survey format 76
</p>
<p>Survey layout 76
</p>
<p>Survey non-response 101
</p>
<p>Surveys 61
</p>
<p>Suspicious response patterns 98
</p>
<p>Syndicated data 6, 52
</p>
<p>System-missing values (SPSS) 126
</p>
<p>Systematic error 35
</p>
<p>Systematic sampling 41
</p>
<p>T
t-test 163
</p>
<p>Telephone interviews 63
</p>
<p>Test markets 21, 60
</p>
<p>Test statistic 154, 166
</p>
<p>test-retest reliability 279
</p>
<p>Test-retest reliability 38
</p>
<p>Testing effect 85
</p>
<p>Text mining 53
</p>
<p>Ties 332
</p>
<p>Tolerance 216
</p>
<p>Total sum of the squares 227
</p>
<p>Tracking cookie 53
</p>
<p>Trade associations (data source) 51
</p>
<p>Transforming data 116
</p>
<p>Treatments 82
</p>
<p>Trend analysis 53
</p>
<p>Tukey&rsquo;s honestly significant 
</p>
<p>difference test 184
</p>
<p>Two-samples t-test (t-test ) 163
</p>
<p>Two-step cluster analysis 321
</p>
<p>Two-tailed test 165
</p>
<p>Two-way ANOVA 178
</p>
<p>Type I error 158
</p>
<p>Type II error 158
</p>
<p>Types of research problems 13
</p>
<p>U
Unbalanced scale 74
</p>
<p>Unexplained variation 181
</p>
<p>Unit of analysis 31
</p>
<p>unit non-response 101
</p>
<p>Univariate descriptives 106
</p>
<p>Univariate graphs 108
</p>
<p>Univariate statistics 110
</p>
<p>Univariate tables 108
</p>
<p>Unstandardized effects 231
</p>
<p>User-defined missing values 
</p>
<p>(SPSS) 126
</p>
<p>V
Vague quantifiers 67
</p>
<p>Validity 36
</p>
<p>Value Labels (SPSS) 129
</p>
<p>Variable 27
</p>
<p>Variable coding 96
</p>
<p>Variable names 96
</p>
<p>Variable respecification 117
</p>
<p>Variance 112
</p>
<p>Variance inflation factor (VIF) 216
</p>
<p>Variance ratio criterion (VRC) 330
</p>
<p>varimax rotation 273
</p>
<p>Verbatim items 67
</p>
<p>VIF See variance inflation factor
</p>
<p>Visual aids 371
</p>
<p>Visual analogue scale 71
</p>
<p>W
Ward&rsquo;s linkage 311
</p>
<p>Web surveys 63
</p>
<p>Weighted Least Squares 221
</p>
<p>Welch&rsquo;s correction 163
</p>
<p>Whisker (box plot) 109
</p>
<p>Wilcoxon matched-pairs signed-
</p>
<p>rank test 164
</p>
<p>Wilcoxon&ndash;Mann&ndash;Whitney test 164
</p>
<p>Wilcoxon rank-sum test 164
</p>
<p>Wilcoxon signed-rank test 164
</p>
<p>Within-group mean squares 183
</p>
<p>Within-group variation 181
</p>
<p>Workflow of data 93</p>
<p/>
</div>
<div class="page"><p/>
<p>396 Index
</p>
<p>Y
Yule&rsquo;s Q (cluster analysis) 326
</p>
<p>Z
z-scores 119
</p>
<p>z-standardization 119, 325
</p>
<p>z-test 168</p>
<p/>
</div>
<ul>	<li>Acknowledgments</li>
	<li> 1 Introduction to Market Research</li>
	<li> 2 The Market Research Process</li>
	<li> 3 Data</li>
	<li> 4 Getting Data</li>
	<li> 6 Hypothesis Testing and ANOVA</li>
	<li> 7 Regression Analysis</li>
	<li> 8 Principal Component and Factor Analysis</li>
	<li> 9 Cluster Analysis</li>
	<li>10 Communicating the Results</li>
	<li> Supplementary Information</li>
<ul>	<li> Glossary</li>
	<li> Index</li>
</ul>
</ul>
</body></html>