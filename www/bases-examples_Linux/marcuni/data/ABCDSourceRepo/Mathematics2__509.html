<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title></title>
</head>
<body><div class="page"><p/>
<p>Springer Undergraduate Mathematics Series
</p>
<p>Thomas&nbsp;Witelski
Mark&nbsp;Bowen
</p>
<p>Methods of 
Mathematical 
Modelling
Continuous Systems and Differential 
Equations</p>
<p/>
</div>
<div class="page"><p/>
<p>Springer Undergraduate Mathematics Series
</p>
<p>Advisory Board
</p>
<p>M.A.J. Chaplain, University of Dundee, Dundee, Scotland, UK
</p>
<p>K. Erdmann, University of Oxford, Oxford, England, UK
</p>
<p>A. MacIntyre, Queen Mary, University of London, London, England, UK
</p>
<p>E. S&uuml;li, University of Oxford, Oxford, England, UK
</p>
<p>M.R. Tehranchi, University of Cambridge, Cambridge, England, UK
</p>
<p>J.F. Toland, University of Cambridge, Cambridge, England, UK</p>
<p/>
</div>
<div class="page"><p/>
<p>More information about this series at http://www.springer.com/series/3423</p>
<p/>
<div class="annotation"><a href="http://www.springer.com/series/3423">http://www.springer.com/series/3423</a></div>
</div>
<div class="page"><p/>
<p>Thomas Witelski &bull; Mark Bowen
</p>
<p>Methods of Mathematical
Modelling
</p>
<p>Continuous Systems and Differential
Equations
</p>
<p>123</p>
<p/>
</div>
<div class="page"><p/>
<p>Thomas Witelski
Department of Mathematics
Duke University
Durham, NC
USA
</p>
<p>Mark Bowen
International Center for Science and
Engineering Programs
</p>
<p>Waseda University
Tokyo
Japan
</p>
<p>ISSN 1615-2085 ISSN 2197-4144 (electronic)
Springer Undergraduate Mathematics Series
ISBN 978-3-319-23041-2 ISBN 978-3-319-23042-9 (eBook)
DOI 10.1007/978-3-319-23042-9
</p>
<p>Library of Congress Control Number: 2015948859
</p>
<p>Mathematics Subject Classification: 34-01, 35-01, 34Exx, 34B40, 35Qxx, 49-01, 92-XX
</p>
<p>Springer Cham Heidelberg New York Dordrecht London
&copy; Springer International Publishing Switzerland 2015
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part
of the material is concerned, specifically the rights of translation, reprinting, reuse of illustrations,
recitation, broadcasting, reproduction on microfilms or in any other physical way, and transmission
or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar
</p>
<p>methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this
publication does not imply, even in the absence of a specific statement, that such names are exempt from
the relevant protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this
book are believed to be true and accurate at the date of publication. Neither the publisher nor the
</p>
<p>authors or the editors give a warranty, express or implied, with respect to the material contained herein or
for any errors or omissions that may have been made.
</p>
<p>Printed on acid-free paper
</p>
<p>Springer International Publishing AG Switzerland is part of Springer Science+Business Media
</p>
<p>(www.springer.com)</p>
<p/>
</div>
<div class="page"><p/>
<p>For Yuka and Emma,
</p>
<p>For Mom and Hae-Young, and
</p>
<p>For students seeking mathematical tools
</p>
<p>to model new challenges&hellip;</p>
<p/>
</div>
<div class="page"><p/>
<p>Preface
</p>
<p>What is Mathematical Modelling?
</p>
<p>In order to explain the purpose of modelling, it is helpful to start by asking: what is
</p>
<p>a mathematical model? One answer was given by Rutherford Aris [4]:
</p>
<p>A model is a set of mathematical equations that &hellip; provide an adequate description of a
</p>
<p>physical system.
</p>
<p>Dissecting the words in his description, &ldquo;a physical system&rdquo; can be broadly inter-
</p>
<p>preted as any real-world problem&mdash;natural or man-made, discrete or continuous and
</p>
<p>can be deterministic, chaotic, or random in behaviour. The context of the system
</p>
<p>could be physical, chemical, biological, social, economic or any other setting that
</p>
<p>provides observed data or phenomena that we would like to quantify. Being &ldquo;ad-
</p>
<p>equate&rdquo; sometimes suggests having a minimal level of quality, but in the context of
</p>
<p>modelling it describes equations that are good enough to provide sufficiently
</p>
<p>accurate predictions of the properties of interest in the system without being too
</p>
<p>difficult to evaluate.
</p>
<p>Trying to include every possible real-world effect could make for a complete
</p>
<p>description but one whose mathematical form would likely be intractable to solve.
</p>
<p>Likewise, over-simplified systems may become mathematically trivial and will not
</p>
<p>provide accurate descriptions of the original problem. In this spirit, Albert Einstein
</p>
<p>supposedly said, &ldquo;Everything should be made as simple as possible, but not sim-
</p>
<p>pler&rdquo; [107], though ironically this is actually an approximation of his precise
</p>
<p>statement [34].
</p>
<p>Many scientists have expressed views about the importance of modelling and the
</p>
<p>limitations of models. Some other notable examples are:
</p>
<p>&bull; In the opening of his foundational paper on developmental biology, Alan Turing
</p>
<p>wrote &ldquo;This [mathematical] model will be a simplification and an idealisation,
</p>
<p>and consequently a falsification. It is to be hoped that the features retained for
</p>
<p>discussion are those of greatest importance &hellip;&rdquo; [100]
</p>
<p>&bull; George Box wrote &ldquo;&hellip;all models are wrong, but some are useful.&rdquo; [17]
</p>
<p>vii</p>
<p/>
</div>
<div class="page"><p/>
<p>&bull; Mark Kac wrote &ldquo;Models are, for the most part, caricatures of reality, but if
</p>
<p>they are good, they portray some features of the real world.&rdquo; [55]
</p>
<p>Useful models strike a balance between such extremes and provide valuable
</p>
<p>insight into phenomena through mathematical analysis. Every proposed model for a
</p>
<p>problem should include a description of how results will be obtained&mdash;a solution
</p>
<p>strategy. This suggests an operational definition:
</p>
<p>model: a useful, practical description of a real-world problem, capable of providing sys-
</p>
<p>tematic mathematical predictions of selected properties
</p>
<p>Models allow researchers to assess balances and trade-offs in terms of levels of
</p>
<p>calculational details versus limitations on predictive capabilities.
</p>
<p>Concerns about models being &ldquo;wrong&rdquo; or &ldquo;false&rdquo; or &ldquo;incomplete&rdquo; are actually
</p>
<p>criticisms of the levels of physics, chemistry or other scientific details being
</p>
<p>included or omitted from the mathematical formulation. Once a well-defined
</p>
<p>mathematical problem is set up, its mathematical study can be an important step in
</p>
<p>understanding the original problem. This is particularly true if the model predicts
</p>
<p>the observed behaviours (a positive result). However, even when the model does
</p>
<p>not work as expected (a negative result), it can lead to a better understanding of
</p>
<p>which (included or omitted) effects have significant influence on the system&rsquo;s
</p>
<p>behaviour and how to further improve the accuracy of the model.
</p>
<p>While being mindful of the possible weaknesses, the positive aspects of models
</p>
<p>should be praised,
</p>
<p>Models are expressions of the hope that aspects of complicated systems can be described by
</p>
<p>simpler underlying mathematical forms.
</p>
<p>Exact solutions can be found for only a very small number of types of problems;
</p>
<p>seeking to extend systems beyond those special cases often makes the exact
</p>
<p>solutions unusable. Modelling can provide more viable and robust approaches, even
</p>
<p>though they may start from counterintuitive ideas, &ldquo;&hellip; simple, approximate solu-
</p>
<p>tions are more useful than complex exact solutions&rdquo; [15].
</p>
<p>Mathematical models also allow for the exploration of conjectures and hypo-
</p>
<p>thetical situations that cannot normally be de-coupled or for parameter ranges that
</p>
<p>might not be easily accessible experimentally or computationally. Modelling lets us
</p>
<p>qualitatively and quantitatively dissect problems in order to evaluate the importance
</p>
<p>of their various parts, which can lead to the original motivating problem becoming a
</p>
<p>building block for the understanding of more complex systems. Good models
</p>
<p>provide the flexibility to be systematically developed allowing more accurate
</p>
<p>answers to be obtained by solving extensions of the model&rsquo;s mathematical equa-
</p>
<p>tions. In summary, our description of the process is
</p>
<p>modelling: a systematic mathematical approach to formulation, simplification and
</p>
<p>understanding of behaviours and trends in problems.
</p>
<p>viii Preface</p>
<p/>
</div>
<div class="page"><p/>
<p>Levels of Models
</p>
<p>Mathematical models can take many different forms spanning a wide range of types
</p>
<p>and complexity,
</p>
<p>At the upper end of complexity are models that are equivalent to the full
</p>
<p>first-principles scientific description of all of the details involved in the entire
</p>
<p>problem. Such systems may consist of dozens or even hundreds of equations
</p>
<p>describing different parts of the problem; computationally intensive numerical
</p>
<p>simulations are often necessary to investigate the full system.
</p>
<p>At the other end of the spectrum are improvised or phenomenological &ldquo;toy&rdquo;
</p>
<p>problems1 that may have some conceptual resemblance to the original system but
</p>
<p>have no obvious direct derivation from that problem. These might be only a few
</p>
<p>equations or just some geometric relations. They are the mathematical modelling
</p>
<p>equivalents of an &ldquo;artistic impression&rdquo; motivated or inspired by the original prob-
</p>
<p>lem. Their value is that they may provide a simple &ldquo;proof of concept&rdquo; prototype for
</p>
<p>how to describe a key element of the complete system.
</p>
<p>Both extremes have drawbacks: intractable calculations in one extreme, and
</p>
<p>imprecise qualitative results at the other. Mathematical models exist in-between and
</p>
<p>try to bridge the gap by offering a process for using identifiable assumptions to
</p>
<p>reduce the full system down to a simpler form, where analysis, calculations and
</p>
<p>insights are more achievable, but without losing the accuracy of the results and the
</p>
<p>connection to the original problem.
</p>
<p>Classes of Real World Problems
</p>
<p>The kinds of questions being considered play an important role in how the model
</p>
<p>for the problem should be constructed. There are three broad types of questions:
</p>
<p>(i) Evaluation questions [also called Forward problems]: Given all needed
</p>
<p>information about the system, can we quantitatively predict its other properties
</p>
<p>and how the system will function? Examples: What is the maximum attainable
</p>
<p>speed of this car? How quickly will this disease spread through the population
</p>
<p>of this city?
</p>
<p>(ii) Detection questions [Inverse problems] [8]: If some information about a
</p>
<p>&ldquo;black box&rdquo; system is not directly available, can you &ldquo;reverse engineer&rdquo; those
</p>
<p>missing parameters? Examples: How can we use data from CAT scans to
</p>
<p>&ldquo;Toy&rdquo; problems &le; Math Models &le; Complete systems
</p>
<p>1Sometimes also described as ad hoc or heuristic models.
</p>
<p>Preface ix</p>
<p/>
</div>
<div class="page"><p/>
<p>estimate the location of a tumour? Can we determine the damping of an
</p>
<p>oscillator from the decay of its time series data?
</p>
<p>(iii) Design questions [Control and optimisation problems]: Can we create a
</p>
<p>solution that best meets a proposed goal? Examples: What shape paper air-
</p>
<p>plane flies the furthest? How should a pill be coated to release its drug at a
</p>
<p>constant rate over an entire day?
</p>
<p>There are many routes available to attack such questions that are typically treated in
</p>
<p>different areas of study. This book will introduce methods for addressing some
</p>
<p>problems of the forms (i) and (iii) in the context of continuous systems and dif-
</p>
<p>ferential equations.
</p>
<p>Stages of the Modelling Process
</p>
<p>The modelling process can sometimes start from a creative and inspired toy
</p>
<p>problem and then seeks to validate the model&rsquo;s connection to the original problem.
</p>
<p>However, this approach requires having a lot of previous experience with and
</p>
<p>background knowledge on the scientific area and/or relevant mathematical tech-
</p>
<p>niques in order to generate the new model. In this book, we follow the more
</p>
<p>systematic approach of starting with some version of the complete scientific
</p>
<p>problem statement and then using mathematical techniques to obtain reduced
</p>
<p>models that can be simplified to a manageable level of computational difficulty.
</p>
<p>The modelling process has two stages, consisting of setting up the problem and
</p>
<p>then solving it:
</p>
<p>&bull; In the formulation phase, the problem is described using basic principles or
</p>
<p>governing laws and assumed relations taken from some branches of knowledge,
</p>
<p>such as physics, biology, chemistry, economics, geometry, probability or others.
</p>
<p>Then all side-conditions that are needed to completely define the problem must
</p>
<p>be identified: geometric constraints, initial conditions, material properties,
</p>
<p>boundary conditions and design parameter values. Finally, the properties of
</p>
<p>interest, how they are to be measured, relevant variables, coordinate systems and
</p>
<p>a system of units must all be decided on.
</p>
<p>&bull; Then2, in the solution phase, mathematical modelling provides approaches to
</p>
<p>reformulating the original problem into a more convenient structure from which
</p>
<p>it can be reduced into solvable parts that can ultimately be re-assembled to
</p>
<p>address the main questions of interest for the problem.
</p>
<p>In some cases, the reformulated problem may seem to only differ from the original
</p>
<p>system at a notational level, but these changes can be essential for separating out
</p>
<p>different effects in the system. At the simplest level, &ldquo;problem reduction&rdquo; consists of
</p>
<p>2Assuming that the problem cannot be easily solved analytically or computed numerically, and
</p>
<p>hence does not need modelling.
</p>
<p>x Preface</p>
<p/>
</div>
<div class="page"><p/>
<p>obtaining so-called asymptotic approximations of the solution, but for more chal-
</p>
<p>lenging problems, this will also involve approaches for transforming the problem
</p>
<p>into different forms that are more tractable for analysis or computation.
</p>
<p>The techniques described here are broadly applicable to many branches of
</p>
<p>engineering and applied science: biology, chemistry, physics, the geosciences and
</p>
<p>mechanical engineering, to name a few. To keep examples compact and accessible,
</p>
<p>we present concise reviews of background from different fields when needed
</p>
<p>(including population biology and chemical reactions in Chap. 1, fluid dynamics in
</p>
<p>Chap. 2 and classical mechanics in Chap. 3), but we seek to maintain focus on the
</p>
<p>modelling techniques and the properties of solutions that can be obtained. We direct
</p>
<p>interested readers to books that present more detailed case studies of problems
</p>
<p>needing more extensive background in specific application areas [8, 27, 37, 38, 51,
</p>
<p>69, 96].
</p>
<p>The structure of this book follows the description of the modelling process
</p>
<p>described above:
</p>
<p>&bull; Part I: Formulation of models
</p>
<p>This part consists of four chapters that present fundamental approaches and
</p>
<p>exact methods for formulating different classes of problems:
</p>
<p>1. Rate equations: simple models for properties evolving in time
</p>
<p>2. Transport equations: models involving structural changes
</p>
<p>3. Variational principles: models based on optimisation of properties
</p>
<p>4. Dimensional analysis: determination of the number of essential system
</p>
<p>parameters
</p>
<p>&bull; Part II: Solution techniques
</p>
<p>This part presents methods for obtaining approximate solutions to some of the
</p>
<p>classes of problems introduced in Part I.
</p>
<p>5. Similarity solutions: determining important special solutions of PDEs using
</p>
<p>scaling analysis
</p>
<p>6. Perturbation methods: exploiting limiting parameters to obtain expansions
</p>
<p>of solutions
</p>
<p>7. Boundary layers: constructing solutions having non-uniform spatial
</p>
<p>structure
</p>
<p>8. Long-wave asymptotics: reduction of problems on slender domains
</p>
<p>9. Weakly-nonlinear oscillators: predicting cumulative changes over large
</p>
<p>numbers of oscillations
</p>
<p>10. Fast/slow dynamical systems: separating effects acting over different
</p>
<p>timescales
</p>
<p>11. Reduced models: obtaining essential properties from simplified versions of
</p>
<p>partial differential equation problems
</p>
<p>&bull; Part III: Case studies: some applications illustrating uses of techniques from
</p>
<p>Parts I and II.
</p>
<p>Preface xi</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1">http://dx.doi.org/10.1007/978-3-319-23042-9_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2">http://dx.doi.org/10.1007/978-3-319-23042-9_2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3">http://dx.doi.org/10.1007/978-3-319-23042-9_3</a></div>
</div>
<div class="page"><p/>
<p>While this book cannot be an exhaustive introduction to all types of mathematical
</p>
<p>models, we seek to develop intuition from the ground-up on formulating equations
</p>
<p>and methods of solving models expressible in terms of differential equations.
</p>
<p>The book is written in a concise and self-contained form that should be
</p>
<p>well-suited for an advanced undergraduate or beginning graduate course or inde-
</p>
<p>pendent study. Students should have a background in calculus and basic differential
</p>
<p>equations. Each chapter provides references to sources that can provide more detail
</p>
<p>on topics that readers wish to pursue in greater depth. We note that the examples
</p>
<p>and exercises are an important part of the book and will introduce readers to many
</p>
<p>classic models that have become important milestones in applied mathematics for
</p>
<p>illustrating important or universal solution structures. Some of these highlights
</p>
<p>include:
</p>
<p>&bull; The Burgers equation (Chaps. 2, 4, 5)
</p>
<p>&bull; The shallow water equations (Chaps. 2, 4, 6)
</p>
<p>&bull; The porous medium equation (Chaps. 5, 8, 11)
</p>
<p>&bull; The Korteweg de Vries (KdV) equation (Chaps. 8, 9)
</p>
<p>&bull; The Fredholm alternative theorem (Chap. 9)
</p>
<p>&bull; The van der Pol equation (Chaps. 9, 10)
</p>
<p>&bull; The Michaelis&ndash;Menten reaction rate model (Chap. 10)
</p>
<p>&bull; The Turing instability mechanism (Chap. 11)
</p>
<p>&bull; Taylor dispersion (Chap. 11)
</p>
<p>Solutions are provided to many exercises. Readers are encouraged to work through
</p>
<p>the exercises in order to gain a deeper understanding of the techniques presented.
</p>
<p>Durham, NC, USA Thomas Witelski
</p>
<p>Tokyo, Japan Mark Bowen
</p>
<p>June 2015
</p>
<p>xii Preface</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2">http://dx.doi.org/10.1007/978-3-319-23042-9_2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4">http://dx.doi.org/10.1007/978-3-319-23042-9_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5">http://dx.doi.org/10.1007/978-3-319-23042-9_5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2">http://dx.doi.org/10.1007/978-3-319-23042-9_2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4">http://dx.doi.org/10.1007/978-3-319-23042-9_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6">http://dx.doi.org/10.1007/978-3-319-23042-9_6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5">http://dx.doi.org/10.1007/978-3-319-23042-9_5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_8">http://dx.doi.org/10.1007/978-3-319-23042-9_8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_11">http://dx.doi.org/10.1007/978-3-319-23042-9_11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_8">http://dx.doi.org/10.1007/978-3-319-23042-9_8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9">http://dx.doi.org/10.1007/978-3-319-23042-9_9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9">http://dx.doi.org/10.1007/978-3-319-23042-9_9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9">http://dx.doi.org/10.1007/978-3-319-23042-9_9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_10">http://dx.doi.org/10.1007/978-3-319-23042-9_10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_10">http://dx.doi.org/10.1007/978-3-319-23042-9_10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_11">http://dx.doi.org/10.1007/978-3-319-23042-9_11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_11">http://dx.doi.org/10.1007/978-3-319-23042-9_11</a></div>
</div>
<div class="page"><p/>
<p>Acknowledgments
</p>
<p>This book follows in the tradition set by the classic text by Lin and Segel [63] that
</p>
<p>first collected and systematically applied the foundational approaches in modelling.
</p>
<p>More recent books by Tayler [96], Fowler [37], Haberman [45], Logan [64],
</p>
<p>Holmes [49] and Howison [51] have made the art of modelling and the tools of
</p>
<p>applied mathematics more accessible.
</p>
<p>This book shares many elements in common with those books but seeks to
</p>
<p>highlight different connections between topics and to use elementary approaches to
</p>
<p>make modelling more applicable to students coming from a diverse range of fields
</p>
<p>seeking to incorporate mathematical modelling in their scientific studies.
</p>
<p>The authors thank the many colleagues and students who gave feedback on early
</p>
<p>versions of the materials in this book. Thomas Witelski also thanks the OCCAM
</p>
<p>and OCIAM centres in the Mathematical Institute of the University of Oxford for a
</p>
<p>visiting fellowship.
</p>
<p>Durham, NC, USA Thomas Witelski
</p>
<p>Tokyo, Japan Mark Bowen
</p>
<p>June 2015
</p>
<p>xiii</p>
<p/>
</div>
<div class="page"><p/>
<p>Contents
</p>
<p>Part I Formulation of Models
</p>
<p>1 Rate Equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
</p>
<p>1.1 The Motion of Particles . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
</p>
<p>1.2 Chemical Reaction Kinetics . . . . . . . . . . . . . . . . . . . . . . . . . 5
</p>
<p>1.3 Ecological and Biological Models . . . . . . . . . . . . . . . . . . . . . 8
</p>
<p>1.4 One-Dimensional Phase-Line Dynamics. . . . . . . . . . . . . . . . . 10
</p>
<p>1.5 Two-Dimensional Phase Plane Analysis. . . . . . . . . . . . . . . . . 12
</p>
<p>1.5.1 Nullclines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
</p>
<p>1.6 Further Directions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
</p>
<p>1.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
</p>
<p>2 Transport Equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
</p>
<p>2.1 The Reynolds Transport Theorem . . . . . . . . . . . . . . . . . . . . . 24
</p>
<p>2.2 Deriving Conservation Laws . . . . . . . . . . . . . . . . . . . . . . . . 26
</p>
<p>2.3 The Linear Advection Equation . . . . . . . . . . . . . . . . . . . . . . 28
</p>
<p>2.4 Systems of Linear Advection Equations . . . . . . . . . . . . . . . . . 30
</p>
<p>2.5 The Method of Characteristics . . . . . . . . . . . . . . . . . . . . . . . 32
</p>
<p>2.6 Shocks in Quasilinear Equations . . . . . . . . . . . . . . . . . . . . . . 34
</p>
<p>2.7 Further Directions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
</p>
<p>2.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
</p>
<p>3 Variational Principles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
</p>
<p>3.1 Review and Generalisation from Calculus . . . . . . . . . . . . . . . 47
</p>
<p>3.1.1 Functionals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
</p>
<p>3.2 General Approach and Basic Examples . . . . . . . . . . . . . . . . . 50
</p>
<p>3.2.1 The Simple Shortest Curve Problem . . . . . . . . . . . . . 51
</p>
<p>3.2.2 The Classic Euler&ndash;Lagrange Problem . . . . . . . . . . . . 55
</p>
<p>3.3 The Variational Formation of Classical Mechanics . . . . . . . . . 56
</p>
<p>3.3.1 Motion with Multiple Degrees of Freedom. . . . . . . . . 58
</p>
<p>xv</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1">http://dx.doi.org/10.1007/978-3-319-23042-9_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1">http://dx.doi.org/10.1007/978-3-319-23042-9_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec1">http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec1">http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec2">http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec2">http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec3">http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec3">http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec4">http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec4">http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec5">http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec5">http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec6">http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec6">http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec7">http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec7">http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec8">http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec8">http://dx.doi.org/10.1007/978-3-319-23042-9_1#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2">http://dx.doi.org/10.1007/978-3-319-23042-9_2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2">http://dx.doi.org/10.1007/978-3-319-23042-9_2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec1">http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec1">http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec2">http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec2">http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec3">http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec3">http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec4">http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec4">http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec5">http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec5">http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec6">http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec6">http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec7">http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec7">http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec8">http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec8">http://dx.doi.org/10.1007/978-3-319-23042-9_2#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3">http://dx.doi.org/10.1007/978-3-319-23042-9_3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3">http://dx.doi.org/10.1007/978-3-319-23042-9_3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec1">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec1">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec2">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec2">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec3">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec3">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec4">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec4">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec5">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec5">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec6">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec6">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec7">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec7">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec7</a></div>
</div>
<div class="page"><p/>
<p>3.4 The Influence of Boundary Conditions . . . . . . . . . . . . . . . . . 59
</p>
<p>3.4.1 Problems with a Free Boundary . . . . . . . . . . . . . . . . 59
</p>
<p>3.4.2 Problems with a Variable Endpoint . . . . . . . . . . . . . . 60
</p>
<p>3.5 Optimisation with Constraints. . . . . . . . . . . . . . . . . . . . . . . . 63
</p>
<p>3.5.1 Review of Lagrange Multipliers . . . . . . . . . . . . . . . . 63
</p>
<p>3.6 Integral Constraints: Isoperimetric Problems . . . . . . . . . . . . . . 65
</p>
<p>3.7 Geometric Constraints: Holonomic Problems . . . . . . . . . . . . . 67
</p>
<p>3.8 Differential Equation Constraints: Optimal Control . . . . . . . . . 69
</p>
<p>3.9 Further Directions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
</p>
<p>3.10 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74
</p>
<p>4 Dimensional Scaling Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . 85
</p>
<p>4.1 Dimensional Quantities . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85
</p>
<p>4.1.1 The SI System of Base Units . . . . . . . . . . . . . . . . . . 86
</p>
<p>4.2 Dimensional Homogeneity . . . . . . . . . . . . . . . . . . . . . . . . . . 87
</p>
<p>4.3 The Process of Nondimensionalisation. . . . . . . . . . . . . . . . . . 88
</p>
<p>4.3.1 Projectile Motion . . . . . . . . . . . . . . . . . . . . . . . . . . 88
</p>
<p>4.3.2 Terminal Velocity of a Falling Sphere in a Fluid . . . . 91
</p>
<p>4.3.3 The Burgers Equation . . . . . . . . . . . . . . . . . . . . . . . 95
</p>
<p>4.4 Further Applications of Dimensional Analysis . . . . . . . . . . . . 98
</p>
<p>4.4.1 Projectile Motion (Revisited) . . . . . . . . . . . . . . . . . . 98
</p>
<p>4.4.2 Closed Curves in the Plane . . . . . . . . . . . . . . . . . . . 100
</p>
<p>4.5 The Buckingham Pi Theorem . . . . . . . . . . . . . . . . . . . . . . . . 101
</p>
<p>4.5.1 Mathematical Consequences . . . . . . . . . . . . . . . . . . . 102
</p>
<p>4.5.2 Application to the Quadratic Equation . . . . . . . . . . . . 103
</p>
<p>4.6 Further Directions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
</p>
<p>4.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
</p>
<p>Part II Solution Techniques
</p>
<p>5 Self-Similar Scaling Solutions of Differential Equations . . . . . . . . 113
</p>
<p>5.1 Finding Scaling-Invariant Symmetries . . . . . . . . . . . . . . . . . . 114
</p>
<p>5.2 Determining the Form of the Similarity Solution. . . . . . . . . . . 115
</p>
<p>5.3 Solving for the Similarity Function . . . . . . . . . . . . . . . . . . . . 117
</p>
<p>5.4 Further Comments on Self-Similar Solutions . . . . . . . . . . . . . 118
</p>
<p>5.5 Similarity Solutions of the Heat Equation . . . . . . . . . . . . . . . 118
</p>
<p>5.5.1 Source-Type Similarity Solutions . . . . . . . . . . . . . . . 119
</p>
<p>5.5.2 The Boltzmann Similarity Solution . . . . . . . . . . . . . . 120
</p>
<p>5.6 A Nonlinear Diffusion Equation . . . . . . . . . . . . . . . . . . . . . . 121
</p>
<p>5.7 Further Directions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
</p>
<p>5.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
</p>
<p>xvi Contents</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec8">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec8">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec9">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec9">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec10">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec10">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec11">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec11">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec12">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec12">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec13">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec13">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec14">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec14">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec15">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec15">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec16">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec16</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec16">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec16</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec17">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec17</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec17">http://dx.doi.org/10.1007/978-3-319-23042-9_3#Sec17</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4">http://dx.doi.org/10.1007/978-3-319-23042-9_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4">http://dx.doi.org/10.1007/978-3-319-23042-9_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec1">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec1">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec2">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec2">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec3">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec3">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec4">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec4">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec5">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec5">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec6">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec6">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec7">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec7">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec8">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec8">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec9">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec9">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec10">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec10">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec11">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec11">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec12">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec12">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec13">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec13">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec14">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec14">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec15">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec15">http://dx.doi.org/10.1007/978-3-319-23042-9_4#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5">http://dx.doi.org/10.1007/978-3-319-23042-9_5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5">http://dx.doi.org/10.1007/978-3-319-23042-9_5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec1">http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec1">http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec2">http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec2">http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec3">http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec3">http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec4">http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec4">http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec5">http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec5">http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec6">http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec6">http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec7">http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec7">http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec8">http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec8">http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec9">http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec9">http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec10">http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec10">http://dx.doi.org/10.1007/978-3-319-23042-9_5#Sec10</a></div>
</div>
<div class="page"><p/>
<p>6 Perturbation Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127
</p>
<p>6.1 Asymptotic Analysis: Concepts and Notation . . . . . . . . . . . . . 127
</p>
<p>6.2 Asymptotic Expansions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129
</p>
<p>6.2.1 Divergence of Asymptotic Expansions. . . . . . . . . . . . 130
</p>
<p>6.3 The Calculation of Asymptotic Expansions . . . . . . . . . . . . . . 132
</p>
<p>6.3.1 The Expansion Method . . . . . . . . . . . . . . . . . . . . . . 133
</p>
<p>6.3.2 The Iteration Method. . . . . . . . . . . . . . . . . . . . . . . . 134
</p>
<p>6.3.3 Further Examples . . . . . . . . . . . . . . . . . . . . . . . . . . 136
</p>
<p>6.4 A Regular Expansion for a Solution of an ODE Problem. . . . . 138
</p>
<p>6.5 Singular Perturbation Problems. . . . . . . . . . . . . . . . . . . . . . . 139
</p>
<p>6.5.1 Rescaling to Obtain Singular Solutions . . . . . . . . . . . 141
</p>
<p>6.6 Further Directions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142
</p>
<p>6.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
</p>
<p>7 Boundary Layer Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147
</p>
<p>7.1 Observing Boundary Layer Structure in Solutions . . . . . . . . . . 148
</p>
<p>7.2 Asymptotics of the Outer and Inner Solutions. . . . . . . . . . . . . 150
</p>
<p>7.3 Constructing Boundary Layer Solutions . . . . . . . . . . . . . . . . . 153
</p>
<p>7.3.1 The Outer Solution . . . . . . . . . . . . . . . . . . . . . . . . . 154
</p>
<p>7.3.2 The Distinguished Limits . . . . . . . . . . . . . . . . . . . . . 155
</p>
<p>7.3.3 The Inner Solution . . . . . . . . . . . . . . . . . . . . . . . . . 156
</p>
<p>7.3.4 Asymptotic Matching . . . . . . . . . . . . . . . . . . . . . . . 157
</p>
<p>7.3.5 The Composite Solution . . . . . . . . . . . . . . . . . . . . . 157
</p>
<p>7.4 Further Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158
</p>
<p>7.5 Further Directions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162
</p>
<p>7.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163
</p>
<p>8 Long-Wave Asymptotics for PDE Problems . . . . . . . . . . . . . . . . . 167
</p>
<p>8.1 The Classic Separation of Variables Solution . . . . . . . . . . . . . 167
</p>
<p>8.2 The Dirichlet Problem on a Slender Rectangle . . . . . . . . . . . . 170
</p>
<p>8.3 The Insulated Wire . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174
</p>
<p>8.4 The Nonuniform Insulated Wire . . . . . . . . . . . . . . . . . . . . . . 177
</p>
<p>8.5 Further Directions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179
</p>
<p>8.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180
</p>
<p>9 Weakly-Nonlinear Oscillators . . . . . . . . . . . . . . . . . . . . . . . . . . . 185
</p>
<p>9.1 Review of Solutions of the Linear Problem . . . . . . . . . . . . . . 186
</p>
<p>9.2 The Failure of Direct Regular Expansions . . . . . . . . . . . . . . . 187
</p>
<p>9.3 Poincare&ndash;Lindstedt Expansions . . . . . . . . . . . . . . . . . . . . . . . 189
</p>
<p>9.4 The Method of Multiple Time-Scales . . . . . . . . . . . . . . . . . . 191
</p>
<p>9.5 Further Directions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194
</p>
<p>9.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195
</p>
<p>Contents xvii</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6">http://dx.doi.org/10.1007/978-3-319-23042-9_6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6">http://dx.doi.org/10.1007/978-3-319-23042-9_6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec1">http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec1">http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec2">http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec2">http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec3">http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec3">http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec4">http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec4">http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec5">http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec5">http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec6">http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec6">http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec7">http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec7">http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec8">http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec8">http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec9">http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec9">http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec10">http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec10">http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec11">http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec11">http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec12">http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec12">http://dx.doi.org/10.1007/978-3-319-23042-9_6#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7">http://dx.doi.org/10.1007/978-3-319-23042-9_7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7">http://dx.doi.org/10.1007/978-3-319-23042-9_7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec1">http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec1">http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec2">http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec2">http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec3">http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec3">http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec4">http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec4">http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec5">http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec5">http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec6">http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec6">http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec7">http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec7">http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec8">http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec8">http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec9">http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec9">http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec10">http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec10">http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec11">http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec11">http://dx.doi.org/10.1007/978-3-319-23042-9_7#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_8">http://dx.doi.org/10.1007/978-3-319-23042-9_8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_8">http://dx.doi.org/10.1007/978-3-319-23042-9_8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_8#Sec1">http://dx.doi.org/10.1007/978-3-319-23042-9_8#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_8#Sec1">http://dx.doi.org/10.1007/978-3-319-23042-9_8#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_8#Sec2">http://dx.doi.org/10.1007/978-3-319-23042-9_8#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_8#Sec2">http://dx.doi.org/10.1007/978-3-319-23042-9_8#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_8#Sec3">http://dx.doi.org/10.1007/978-3-319-23042-9_8#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_8#Sec3">http://dx.doi.org/10.1007/978-3-319-23042-9_8#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_8#Sec4">http://dx.doi.org/10.1007/978-3-319-23042-9_8#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_8#Sec4">http://dx.doi.org/10.1007/978-3-319-23042-9_8#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_8#Sec5">http://dx.doi.org/10.1007/978-3-319-23042-9_8#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_8#Sec5">http://dx.doi.org/10.1007/978-3-319-23042-9_8#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_8#Sec6">http://dx.doi.org/10.1007/978-3-319-23042-9_8#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_8#Sec6">http://dx.doi.org/10.1007/978-3-319-23042-9_8#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9">http://dx.doi.org/10.1007/978-3-319-23042-9_9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9">http://dx.doi.org/10.1007/978-3-319-23042-9_9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9#Sec1">http://dx.doi.org/10.1007/978-3-319-23042-9_9#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9#Sec1">http://dx.doi.org/10.1007/978-3-319-23042-9_9#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9#Sec2">http://dx.doi.org/10.1007/978-3-319-23042-9_9#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9#Sec2">http://dx.doi.org/10.1007/978-3-319-23042-9_9#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9#Sec3">http://dx.doi.org/10.1007/978-3-319-23042-9_9#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9#Sec3">http://dx.doi.org/10.1007/978-3-319-23042-9_9#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9#Sec4">http://dx.doi.org/10.1007/978-3-319-23042-9_9#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9#Sec4">http://dx.doi.org/10.1007/978-3-319-23042-9_9#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9#Sec5">http://dx.doi.org/10.1007/978-3-319-23042-9_9#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9#Sec5">http://dx.doi.org/10.1007/978-3-319-23042-9_9#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9#Sec6">http://dx.doi.org/10.1007/978-3-319-23042-9_9#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9#Sec6">http://dx.doi.org/10.1007/978-3-319-23042-9_9#Sec6</a></div>
</div>
<div class="page"><p/>
<p>10 Fast/slow Dynamical Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . 201
</p>
<p>10.1 Strongly-Nonlinear Oscillators: The van der Pol Equation . . . . 202
</p>
<p>10.2 Complex Chemical Reactions: The Michaelis-Menten
</p>
<p>Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206
</p>
<p>10.3 Further Directions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210
</p>
<p>10.4 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210
</p>
<p>11 Reduced Models for PDE Problems . . . . . . . . . . . . . . . . . . . . . . . 215
</p>
<p>11.1 The Method of Moments . . . . . . . . . . . . . . . . . . . . . . . . . . . 215
</p>
<p>11.2 Turing Instability and Pattern Formation . . . . . . . . . . . . . . . . 219
</p>
<p>11.3 Taylor Dispersion and Enhanced Diffusion. . . . . . . . . . . . . . . 223
</p>
<p>11.4 Further Directions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228
</p>
<p>11.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228
</p>
<p>Part III Case Studies
</p>
<p>12 Modelling in Applied Fluid Dynamics . . . . . . . . . . . . . . . . . . . . . 235
</p>
<p>12.1 Lubrication Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 235
</p>
<p>12.2 Dynamics of an Air Bearing Slider . . . . . . . . . . . . . . . . . . . . 240
</p>
<p>12.3 Rivulets in a Wedge Geometry . . . . . . . . . . . . . . . . . . . . . . . 244
</p>
<p>12.3.1 Imbibition in a Vertical Wedge. . . . . . . . . . . . . . . . . 246
</p>
<p>12.3.2 Draining in a Vertical Wedge . . . . . . . . . . . . . . . . . . 248
</p>
<p>Epilogue . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 251
</p>
<p>Appendix A: Trigonometric Identities and Fourier Series . . . . . . . . . . 253
</p>
<p>Solutions to Selected Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255
</p>
<p>References. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299
</p>
<p>Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 303
</p>
<p>xviii Contents</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_10">http://dx.doi.org/10.1007/978-3-319-23042-9_10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_10">http://dx.doi.org/10.1007/978-3-319-23042-9_10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_10#Sec1">http://dx.doi.org/10.1007/978-3-319-23042-9_10#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_10#Sec1">http://dx.doi.org/10.1007/978-3-319-23042-9_10#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_10#Sec2">http://dx.doi.org/10.1007/978-3-319-23042-9_10#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_10#Sec2">http://dx.doi.org/10.1007/978-3-319-23042-9_10#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_10#Sec2">http://dx.doi.org/10.1007/978-3-319-23042-9_10#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_10#Sec3">http://dx.doi.org/10.1007/978-3-319-23042-9_10#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_10#Sec3">http://dx.doi.org/10.1007/978-3-319-23042-9_10#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_10#Sec4">http://dx.doi.org/10.1007/978-3-319-23042-9_10#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_10#Sec4">http://dx.doi.org/10.1007/978-3-319-23042-9_10#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_11">http://dx.doi.org/10.1007/978-3-319-23042-9_11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_11">http://dx.doi.org/10.1007/978-3-319-23042-9_11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_11#Sec1">http://dx.doi.org/10.1007/978-3-319-23042-9_11#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_11#Sec1">http://dx.doi.org/10.1007/978-3-319-23042-9_11#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_11#Sec2">http://dx.doi.org/10.1007/978-3-319-23042-9_11#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_11#Sec2">http://dx.doi.org/10.1007/978-3-319-23042-9_11#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_11#Sec3">http://dx.doi.org/10.1007/978-3-319-23042-9_11#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_11#Sec3">http://dx.doi.org/10.1007/978-3-319-23042-9_11#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_11#Sec4">http://dx.doi.org/10.1007/978-3-319-23042-9_11#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_11#Sec4">http://dx.doi.org/10.1007/978-3-319-23042-9_11#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_11#Sec5">http://dx.doi.org/10.1007/978-3-319-23042-9_11#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_11#Sec5">http://dx.doi.org/10.1007/978-3-319-23042-9_11#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_12">http://dx.doi.org/10.1007/978-3-319-23042-9_12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_12">http://dx.doi.org/10.1007/978-3-319-23042-9_12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_12#Sec1">http://dx.doi.org/10.1007/978-3-319-23042-9_12#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_12#Sec1">http://dx.doi.org/10.1007/978-3-319-23042-9_12#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_12#Sec2">http://dx.doi.org/10.1007/978-3-319-23042-9_12#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_12#Sec2">http://dx.doi.org/10.1007/978-3-319-23042-9_12#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_12#Sec3">http://dx.doi.org/10.1007/978-3-319-23042-9_12#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_12#Sec3">http://dx.doi.org/10.1007/978-3-319-23042-9_12#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_12#Sec4">http://dx.doi.org/10.1007/978-3-319-23042-9_12#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_12#Sec4">http://dx.doi.org/10.1007/978-3-319-23042-9_12#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_12#Sec5">http://dx.doi.org/10.1007/978-3-319-23042-9_12#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_12#Sec5">http://dx.doi.org/10.1007/978-3-319-23042-9_12#Sec5</a></div>
</div>
<div class="page"><p/>
<p>Part I
</p>
<p>Formulation of Models</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 1
</p>
<p>Rate Equations
</p>
<p>Many real-world systems can be described in terms of the evolution of state variables
</p>
<p>for various system properties, starting from given initial configurations. The sim-
</p>
<p>plest models for such problems are given by ordinary differential equations (ODE)
</p>
<p>describing the rates of change of the state variables as functions of time.
</p>
<p>Applications include:
</p>
<p>&bull; Mechanics: motion of masses subjected to forces
&bull; Modern physics: radioactive decay of materials
&bull; Statistical systems: queues, games, multi-stage processes
&bull; Chemistry/Biochemistry: chemical reactions
&bull; Biology: epidemic models for diseases in populations
&bull; Ecology: dynamics of populations of predator and prey species
</p>
<p>While the dynamics in some of these applications may rest on discrete events, like
</p>
<p>the radioactive decay of an atom or the death of an individual in a population, when
</p>
<p>averaged over large populations, reliable mean-rates of activities can occur; this is
</p>
<p>the basis for writing ODE rate equations and other continuous models. ODEs cannot
</p>
<p>describe all of the details of the processes occurring in these systems, but they provide
</p>
<p>a good starting point for investigations, often yielding accurate predictions of various
</p>
<p>phenomena.
</p>
<p>For a system involving n evolving properties, the governing mathematical problem
</p>
<p>is typically written in the form
</p>
<p>dx
</p>
<p>dt
= f(x, t), x(0) = x0. (1.1)
</p>
<p>where the vector of state variables, x(t) = (x1(t), x2(t), . . . , xn(t)) &isin; Rn , describes
n properties of interest in the system, evolving for times t &ge; 0 and starting from a
given initial state x(0) = x0. The rate functions for the rates of change of each xi ,
dxi/dt = fi , have similarly been collected in a vector, f = ( f1, f2, . . . , fn), where
each fi can potentially depend on all of the state variables.
</p>
<p>&copy; Springer International Publishing Switzerland 2015
</p>
<p>T. Witelski and M. Bowen, Methods of Mathematical Modelling,
</p>
<p>Springer Undergraduate Mathematics Series, DOI 10.1007/978-3-319-23042-9_1
</p>
<p>3</p>
<p/>
</div>
<div class="page"><p/>
<p>4 1 Rate Equations
</p>
<p>System (1.1), where the rate functions have an explicit dependence on time, is
</p>
<p>called non-autonomous. In such systems, the solutions depend on the particular
</p>
<p>details of externally imposed time-dependent influences. In this chapter, we will
</p>
<p>focus on autonomous systems,
</p>
<p>dx
</p>
<p>dt
= f(x), x(0) = x0, (1.2)
</p>
<p>where the rates only depend on the current state of the solution. These systems
</p>
<p>describe &ldquo;natural&rdquo; or unforced behaviour innate to the system and are the traditional
</p>
<p>starting points for studying new classes of problems. In later chapters we will return
</p>
<p>to the influence of inhomogeneous forcing with applications such as control theory
</p>
<p>and driven systems.
</p>
<p>Problems that can be stated in the form (1.2) are called dynamical systems, where
</p>
<p>the independent variable t usually represents time, but may also represent other
</p>
<p>properties depending on the context of the system. The most fundamental issues to
</p>
<p>be addressed for a given dynamical system are
</p>
<p>&bull; Dynamics: What is the behaviour of the solution for t &gt; 0 starting from given
initial conditions x0? (i.e. Will the solution be oscillatory, or monotone increasing,
</p>
<p>or exponentially decaying? Do solutions of certain types exist for any x0? Does a
</p>
<p>unique solution exist?....)
</p>
<p>&bull; Stability: Can the system&rsquo;s behaviour be predicted starting from broad sets of initial
conditions? (i.e. Do the solutions starting from other initial conditions follow the
</p>
<p>behaviour of the solution starting from x0?)
</p>
<p>In the simplest cases (in dimensions n = 1 and n = 2), the complete behaviour of
systems can be understood from local properties of the rate functions and geometric
</p>
<p>descriptions of the set of solutions. This can yield a complete characterisation of
</p>
<p>the dynamics without the need to attempt to explicitly construct the solutions. For
</p>
<p>n = 2, this geometric approach is called phase plane analysis and forms the basis
of (general) dynamical systems theory.
</p>
<p>1.1 The Motion of Particles
</p>
<p>A classic example of a dynamical system from mechanics is the system for motion of
</p>
<p>a particle, where the unknowns describing the state of the particle are its position, X,
</p>
<p>and momentum, P. The rate of change of position is the velocity, and from Newton&rsquo;s
</p>
<p>second law [67, 91], the rate of change of momentum is given by the net applied
</p>
<p>force, F, so we can write
dX
</p>
<p>dt
= V,
</p>
<p>dP
</p>
<p>dt
= F, (1.3)
</p>
<p>where P = mV and the applied forces could depend on position and momentum. If
the mass is constant, then these equations can be combined to give the familiar law
</p>
<p>of motion linking mass times acceleration to the net applied force,</p>
<p/>
</div>
<div class="page"><p/>
<p>1.1 The Motion of Particles 5
</p>
<p>m
d2X
</p>
<p>dt2
= F. (1.4)
</p>
<p>Note that every nth order autonomous differential equation can always be re-expressed
</p>
<p>in the form of a system of n (first-order) rate equations. Defining x = (X1, X2, X3, P1,
P2, P3), system (1.3) can be put in form (1.2) as
</p>
<p>dx
</p>
<p>dt
= f(x) with f =
</p>
<p>(
</p>
<p>P/m
</p>
<p>F(X,P)
</p>
<p>)
</p>
<p>&isin; R6. (1.5)
</p>
<p>Newton&rsquo;s laws give a well-defined procedure for constructing the dynamical system
</p>
<p>for a mechanics problem.1 For other fields, different principles provide guidance; we
</p>
<p>will review how to set up rate equations for problems in chemistry and biology.
</p>
<p>1.2 Chemical Reaction Kinetics
</p>
<p>For chemical systems [6], the fundamental principle for translating chemical reac-
</p>
<p>tions into corresponding sets of rate equations is given by the law of mass action.
</p>
<p>In &ldquo;simple&rdquo; (or elementary) reactions, generically of the form
</p>
<p>reactants
k&minus;&rarr; products, (1.6)
</p>
<p>the rate of creation of products depends on the concentrations of available reactants
</p>
<p>and is also characterised by a rate constant k. The rate of consumption of reactants
</p>
<p>also follows from this relation.
</p>
<p>We will denote the concentration of chemical &lsquo;A&rsquo; by A(t) &ge; 0, and the total rate
of production of A will have contributions from its creation and/or consumption due
</p>
<p>to each chemical reaction involving A,
</p>
<p>d A
</p>
<p>dt
= +
</p>
<p>N
&sum;
</p>
<p>n=1
(creation rate)n &minus;
</p>
<p>N
&sum;
</p>
<p>n=1
(consumption rate)n . (1.7)
</p>
<p>The rate equations form a system of first-order equations, one for each chemical
</p>
<p>in the set of reactions, {A, B,C, . . .}, and the rate functions will be polynomials in
terms of products of concentrations of the reactant chemicals.
</p>
<p>We briefly summarise the basic forms of elementary chemical reactions and the
</p>
<p>corresponding rate equations that follow from the law of mass action:
</p>
<p>1In Chap. 3 we will consider a different approach.</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3">http://dx.doi.org/10.1007/978-3-319-23042-9_3</a></div>
</div>
<div class="page"><p/>
<p>6 1 Rate Equations
</p>
<p>(0) Constant supply: compound A is pumped into the system at a constant rate k
</p>
<p>(source)
k&minus;&rarr; A =&rArr;
</p>
<p>d A
</p>
<p>dt
= k. (1.8)
</p>
<p>This is called a zeroth-order reaction since the rate does not depend on the
</p>
<p>concentration of any reactants, k = k &middot; 1 = k A0.
(i) Decay: substance A transforms into waste at rate k (i.e. A decomposes and is
</p>
<p>removed from the system)
</p>
<p>A
k&minus;&rarr; (waste) =&rArr;
</p>
<p>d A
</p>
<p>dt
= &minus;k A. (1.9)
</p>
<p>This is called a first-order reaction since the reaction rate depends linearly on
</p>
<p>the concentration of a single reactant.
</p>
<p>(ii) Transformation: A is consumed with B being produced from A
</p>
<p>A
k&minus;&rarr; B =&rArr;
</p>
<p>d A
</p>
<p>dt
= &minus;k A,
</p>
<p>d B
</p>
<p>dt
= +k A. (1.10)
</p>
<p>This is the simplest reaction &ldquo;system&rdquo;, having two distinct concentrations evolv-
</p>
<p>ing due to a single reaction.
</p>
<p>(iii) Reversible transformation: A transforms into B and vice versa. Such reactions
</p>
<p>should be explicitly expanded into separate forward and reverse reactions.
</p>
<p>A
k1&minus;⇀↽&minus;
k2
</p>
<p>B = { A k1&minus;&rarr; B and A k2&larr;&minus; B }
</p>
<p>=&rArr;
d A
</p>
<p>dt
= &minus;k1 A + k2 B,
</p>
<p>d B
</p>
<p>dt
= k1 A &minus; k2 B. (1.11)
</p>
<p>In this system, the net rate of production of each substance is obtained by
</p>
<p>summing the reaction rate from the reaction producing it minus the rate from
</p>
<p>the reaction consuming it, as in (1.7).
</p>
<p>(iv) Compound formation: A and B combine to form C
</p>
<p>A + B k&minus;&rarr; C =&rArr;
d A
</p>
<p>dt
= &minus;k AB,
</p>
<p>d B
</p>
<p>dt
= &minus;k AB,
</p>
<p>dC
</p>
<p>dt
= k AB. (1.12)
</p>
<p>The production rate of C being proportional to the product of the reactant
</p>
<p>concentrations follows from a probabilistic description of the collision of inde-
</p>
<p>pendent molecules [6]. The probability of forming a molecule of C increases
</p>
<p>when either of the concentrations of A, B increases (and clearly the reaction
</p>
<p>will not proceed if either is absent, A = 0 or B = 0).
However, suppose A and B are the same chemical, then from (1.12)</p>
<p/>
</div>
<div class="page"><p/>
<p>1.2 Chemical Reaction Kinetics 7
</p>
<p>A + A k&minus;&rarr; C = 2A k&minus;&rarr; C =&rArr;
dC
</p>
<p>dt
= +k A2
</p>
<p>(
</p>
<p>but
d A
</p>
<p>dt
�= &minus;k A2 (?)
</p>
<p>)
</p>
<p>(1.13)
</p>
<p>The equation for the rate of consumption of A cannot be correct because it
</p>
<p>implies that A,C have equal but opposite rates of change, while we know
</p>
<p>that formation of each molecule of C should consume two molecules of A.
</p>
<p>This is an issue with &ldquo;double-counting&rdquo; that points to the need for a more
</p>
<p>precise definition of the &ldquo;reaction rate,&rdquo; as will be addressed in the final type of
</p>
<p>elementary reaction.
</p>
<p>(v) Multiple products: n molecules of A and m molecules of B react to produce
</p>
<p>p molecules of C and q molecules of D:
</p>
<p>n A + m B k&minus;&rarr; p C + q D (1.14a)
</p>
<p>The problem associated with (1.13) is resolved by defining the reaction rate to
</p>
<p>be
</p>
<p>Reaction Rate =&minus;rate of consuming one unit of reactant
=+rate of creating one unit of product.
</p>
<p>Then for (1.14a) we get
</p>
<p>Rate =
1
</p>
<p>p
</p>
<p>dC
</p>
<p>dt
=
</p>
<p>1
</p>
<p>q
</p>
<p>d D
</p>
<p>dt
= &minus;
</p>
<p>1
</p>
<p>n
</p>
<p>d A
</p>
<p>dt
= &minus;
</p>
<p>1
</p>
<p>m
</p>
<p>d B
</p>
<p>dt
= k An Bm
</p>
<p>and can write the rate equations as
</p>
<p>reactants:
d A
</p>
<p>dt
= &minus;nk An Bm
</p>
<p>d B
</p>
<p>dt
= &minus;mk An Bm (1.14b)
</p>
<p>products:
dC
</p>
<p>dt
= pk An Bm
</p>
<p>d D
</p>
<p>dt
= qk An Bm (1.14c)
</p>
<p>Consequently, the rate equation for A for the reaction (1.13) is now correctly
</p>
<p>given by
d A
</p>
<p>dt
= &minus;2k A2. (1.15)
</p>
<p>For systems without losses or sources of chemicals, as in the case of (1.10) or
</p>
<p>(1.11), physical expectations based on the conservation of mass suggest that A+B =
constant, which is validated by evaluating d
</p>
<p>dt
(A+B) using the rate equations. This is
</p>
<p>called a conservation law linking the products and reactants. Typically, the value for
</p>
<p>the constant is set by the summed initial concentrations and can be used to express
</p>
<p>one concentration in terms of the other. For example, if A + B = constant, then</p>
<p/>
</div>
<div class="page"><p/>
<p>8 1 Rate Equations
</p>
<p>B(t) = (A0 + B0) &minus; A(t), allowing us to reduce the number of unknowns in the
system. In some cases there may be various combinations of reactants/products that
</p>
<p>can be used to write a conservation law. For example, for (1.14a), one possible form
</p>
<p>of mass balance is given by
</p>
<p>d
</p>
<p>dt
</p>
<p>(
</p>
<p>1
</p>
<p>n
A +
</p>
<p>1
</p>
<p>p
C
</p>
<p>)
</p>
<p>= 0.
</p>
<p>1.3 Ecological and Biological Models
</p>
<p>Rate equations are also widely used for predicting population growth and the spread
</p>
<p>of epidemics (namely, the growth of the population of diseased individuals) [18, 74].
</p>
<p>The simplest model of population growth, called Malthus&rsquo; law, describes a growth
</p>
<p>rate proportional to the current population, and generates exponential growth,
</p>
<p>d A
</p>
<p>dt
= k A =&rArr; A(t) = A0ekt . (1.16)
</p>
<p>In analogy with the description of chemical reactions, using (1.14a) the growth of
</p>
<p>the population would be due to additions by births, with the parent remaining in the
</p>
<p>population,
</p>
<p>A
β&minus;&rarr; A + A =&rArr;
</p>
<p>d A
</p>
<p>dt
= &minus;βA + 2βA = βA. (1.17)
</p>
<p>We note that the rate constant β would incorporate the time needed for the birth
</p>
<p>process (the gestation period) as well as the fraction of the total population who
</p>
<p>choose to become parents. More generally, the net rate of population growth would
</p>
<p>be the difference between the birth rate β and the death (decay) rate δ, k = β &minus; δ.
The weakness of Malthus&rsquo; law with respect to predicting unlimited growth of
</p>
<p>populations lead to an improved model developed by Pierre Verhulst (1804&ndash;1849),
</p>
<p>usually called the logistic equation,
</p>
<p>d A
</p>
<p>dt
= (β &minus; δ)A &minus; γ A2 = (k &minus; γ A)A, (1.18)
</p>
<p>where the coefficient γ scales the influence of competition effects in decreasing
</p>
<p>the birth rate (and/or increasing the death rate) in growing populations. Here, the
</p>
<p>effective growth rate, k̃(A) = k &minus; γA, depends on the population size and changes
the dynamics from growth (k̃ &gt; 0) for small populations to decay (k̃ &lt; 0) for large
</p>
<p>populations. The borderline between these two cases defines a critical population
</p>
<p>size, A&lowast; = k/γ , called the carrying capacity, which allow (1.18) to be written as</p>
<p/>
</div>
<div class="page"><p/>
<p>1.3 Ecological and Biological Models 9
</p>
<p>d A
</p>
<p>dt
= k
</p>
<p>(
</p>
<p>1 &minus;
A
</p>
<p>A&lowast;
</p>
<p>)
</p>
<p>A. (1.19)
</p>
<p>The logistic equation is the simplest model that makes progress in capturing the
</p>
<p>influence of limited external resources (e.g. food) on growth of the population.
</p>
<p>A more detailed way to describe the coupling of populations to their use of re-
</p>
<p>sources is to introduce additional rate equations to also describe the growth/decay
</p>
<p>of the resources. Consider a population of rabbits whose number evolves according
</p>
<p>to the logistic equation (1.18). Let that population of rabbits, A(t), also serve as the
</p>
<p>food supply (prey) for a population of foxes (predators), B(t). Let the foxes have a
</p>
<p>constant death rate and reproduce only when food available, analogous to a chemical
</p>
<p>reaction of the form, A + B &rarr; B + B. The influence of the consumption of prey
by predators is called predation and generates an additional loss term in the logistic
</p>
<p>equation (1.19) for the rabbit population. Along with the rate equation for the fox
</p>
<p>population, this yields a Lotka-Volterra predator-prey system [45, 74],
</p>
<p>d A
</p>
<p>dt
= (β &minus; δ)A &minus; γ A2 &minus; ρAB,
</p>
<p>d B
</p>
<p>dt
= &minus;κB + σ AB. (1.20)
</p>
<p>In the context of the spread of diseases [18], simple models of epidemics divide
</p>
<p>the total population into sub-groups depending on whether individuals are infected
</p>
<p>(I (t)), susceptible to the disease (S(t)) or recovering from the disease (R(t)). The
</p>
<p>transitions between these states can be interpreted as reactions
</p>
<p>I + S &rarr; I + I, I &rarr; R,
</p>
<p>yielding a basic version of what are generally called SI R models
</p>
<p>d S
</p>
<p>dt
= &minus;kSI,
</p>
<p>d I
</p>
<p>dt
= kSI &minus; γI,
</p>
<p>d R
</p>
<p>dt
= γI. (1.21)
</p>
<p>This particular system conserves the total population, N = S + I + R, but other
formulations can allow for growing or declining overall populations. Diseases for
</p>
<p>which immunity is not achievable can be described by reversible transitions between
</p>
<p>susceptible and infected states, analogous to (1.11),
</p>
<p>S
k1&minus;⇀↽&minus;
k2
</p>
<p>I =&rArr;
d S
</p>
<p>dt
= &minus;k1S + k2 I,
</p>
<p>d I
</p>
<p>dt
= k1S &minus; k2 I , (1.22)
</p>
<p>and are generally called SI S models. Many further extensions are possible, including,
</p>
<p>for example, subdividing the infected population into individuals that are in an earlier,
</p>
<p>exposed phase, E(t), versus a later infectious phase, I (t), called SEIR models [19].</p>
<p/>
</div>
<div class="page"><p/>
<p>10 1 Rate Equations
</p>
<p>1.4 One-Dimensional Phase-Line Dynamics
</p>
<p>The simplest applications described above were expressed as initial value problems
</p>
<p>for a single autonomous ODE (e.g. (1.15), (1.19)),
</p>
<p>dx
</p>
<p>dt
= f (x), x(0) = x0. (1.23)
</p>
<p>If the rate function f (x) is linear or a polynomial function of x , then various methods,
</p>
<p>such as separation of variables can be used to determine the exact solution. However,
</p>
<p>we will see that many problems will yield more complicated rate functions where
</p>
<p>the solution cannot be explicitly calculated. For this reason, it is very useful to have
</p>
<p>a general theory that provides an understanding of all solutions of (1.23) without
</p>
<p>having to find explicit solutions. Further, even when a solution can be written out, it
</p>
<p>may be complicated to analyse. In contrast, there is a qualitative approach that can
</p>
<p>be easier to calculate and to interpret.
</p>
<p>The dynamics of the solutions of (1.23) can be described by a one-dimensional2
</p>
<p>&ldquo;phase line&rdquo; in terms of the graph of the function f (x) (see Fig. 1.1 (left)). Assuming
</p>
<p>that f (x) is a nice function3 the behaviour of all solutions, x(t), can be described
</p>
<p>qualitatively in relation to the properties of f (x) at its zeroes. The values x = x&lowast;
where f (x&lowast;) = 0 are called equilibrium points of (1.23). The values x&lowast; define steady
state solutions since where dx/dt = 0, solutions starting at x&lowast; remain there forever.
The behaviour of solutions starting from within a small neighbourhood around x&lowast;
can be analysed by approximating f (x) by its Taylor series about x = x&lowast;,
</p>
<p>f (x) &asymp; f (x&lowast;)+ f &prime;(x&lowast;)(x &minus; x&lowast;)+ 12 f
&prime;&prime;(x&lowast;)(x &minus; x&lowast;)2. (1.24)
</p>
<p>Writing the separation from the equilibrium point as u(t) = x(t)&minus;x&lowast;, (1.24) becomes
</p>
<p>f (x) &asymp; 0 + au + bu2 + cu3 + &middot; &middot; &middot; as u &rarr; 0, (1.25)
</p>
<p>where a = f &prime;(x&lowast;). If a �= 0, then as u &rarr; 0 (corresponding to x &rarr; x&lowast;), (1.23) can
be approximated by the linearised equation,
</p>
<p>du
</p>
<p>dt
= au &rArr; u(t) = Ceat , (1.26)
</p>
<p>and hence yields x(t) &asymp; x&lowast; + Ceat with C �= 0 for any solution not starting exactly
at the equilibrium point. For a &gt; 0 the equilibrium is locally &lsquo;repelling&rsquo; since the
</p>
<p>separation from the equilibrium point increases with time, while conversely for a &lt; 0
</p>
<p>the separation decreases with time and the equilibrium is locally &lsquo;attracting&rsquo;. More
</p>
<p>generally, if any solution starting near an equilibrium point leaves the neighbourhood
</p>
<p>2Here one-dimensional indicates that the dynamics of solutions can be understood in terms of a
</p>
<p>single variable, x .
3With f being bounded and sufficiently smooth.</p>
<p/>
</div>
<div class="page"><p/>
<p>1.4 One-Dimensional Phase-Line Dynamics 11
</p>
<p>y
</p>
<p>x
</p>
<p>(S)(U)(S)
</p>
<p>f(x) &gt; 0 f(x) &lt; 0f(x) &lt; 0 f(x) &gt; 0
</p>
<p>f (x&lowast;3) &lt; 0f (x&lowast;2) &gt; 0f (x&lowast;1) &lt; 0
</p>
<p>Fig. 1.1 (Left) A smooth rate function f (x) with three equilibrium points, (Right) corresponding
</p>
<p>dynamics on the phase line for (1.23) obtained from local properties of f at its equilibrium points
</p>
<p>of x&lowast; as t &rarr; &infin;, then x&lowast; is called asymptotically unstable, while if all solutions
starting within the neighbourhood approach x&lowast; as t &rarr; &infin; then the equilibrium is
called asymptotically stable. The characterisation of the dynamics of the solutions
</p>
<p>near x&lowast; based on the linearised equation (1.26) is commonly called linear stability
analysis.
</p>
<p>In graphical terms, x&lowast; is stable if the slope f &prime;(x&lowast;) is negative (a &lt; 0) and unstable
if the slope is positive (a &gt; 0). If we consider x(t) to be the position of a point moving
</p>
<p>along the x-axis in Fig. 1.1 (the phase line) then this follows from f &rsquo;s role as the
</p>
<p>velocity, or rate of change of position x . If x starts to the right of x&lowast;3 (x0 &gt; x&lowast;3)
where f (x) &lt; 0 then x(t) will decrease (move to the left, dx/dt &lt; 0) back towards
</p>
<p>x&lowast;3. In contrast if x0 &gt; x&lowast;2 where f (x) &gt; 0 then x(t) would increase with time
(dx/dt &gt; 0), moving away from x&lowast;2.
</p>
<p>Linear stability results provide guidance to understanding the global dynamics
</p>
<p>(not limited to small neighbourhoods of the x&lowast;&rsquo;s). Since f changes sign only at its
zeroes (where we have assumed f &prime;(x&lowast;) to be non-zero), solutions starting at x0 within
intervals between zeroes will either be monotone increasing (moving to the right on
</p>
<p>the phase line) or decreasing (moving to the left on the phase line) depending on the
</p>
<p>sign of f . This is consistent with the results of the local stability analysis at each x&lowast;
being controlled by the sign of f &prime;(x&lowast;).
</p>
<p>The case where a = f &prime;(x&lowast;) = 0 is called a degenerate equilibrium point; the
local analysis for u &rarr; 0 is still addressed using the Taylor series (1.25), but now the
first nontrivial term in the expansion is (at least) quadratic and so the rates of growth
</p>
<p>or decay will be algebraic rather than exponential. If f &prime;&prime;(x&lowast;) �= 0, then the ODE
</p>
<p>du
</p>
<p>dt
= bu2 (1.27)
</p>
<p>can be used to show that a degenerate equilibrium point x&lowast; is unstable for any b �= 0.
Similarly, for the case with f &prime;(x&lowast;) = f &prime;&prime;(x&lowast;) = 0, but f &prime;&prime;&prime;(x&lowast;) �= 0 yielding</p>
<p/>
</div>
<div class="page"><p/>
<p>12 1 Rate Equations
</p>
<p>Fig. 1.2 The graph of
</p>
<p>y = f (x) = h(x)&minus; k for
(1.29), giving the dynamics
</p>
<p>for x(t) on different phase
</p>
<p>lines, graphically
</p>
<p>parametrised by y = k
</p>
<p>x
</p>
<p>y
</p>
<p>10-1
</p>
<p>1
</p>
<p>0
</p>
<p>-1
</p>
<p>du
</p>
<p>dt
= cu3, (1.28)
</p>
<p>a third-order degenerate equilibrium point can be shown to be stable if f &prime;&prime;&prime;(x&lowast;) &lt; 0.
The dependence of solutions on parameters in the system will be an important
</p>
<p>aspect of many problems. Consider the ODE
</p>
<p>dx
</p>
<p>dt
= h(x)&minus; k where h(x) = x &minus; x3, (1.29)
</p>
<p>where k is a parameter. Matching to (1.23), we identify the rate function as f (x) =
h(x) &minus; k. Plotting f (x) in Fig. 1.2, we illustrate how the family of problems (1.29)
parametrised by k can be understood from this graph. Observe that for different values
</p>
<p>of the constant k, the horizontal lines y = k form a &ldquo;stacked&rdquo; set of phase lines cutting
through the curve y = h(x) at the equilibrium points, f (x&lowast;) = 0, corresponding
to that value of k. The positions of the equilibrium are functions of k, but more
</p>
<p>significantly, the number and type of the equilibrium points change for different
</p>
<p>ranges of k, such qualitative changes in the structure of sets of solutions are called
</p>
<p>bifurcations. For (1.29), the dynamics for all times is restricted to a single phase line,
</p>
<p>with y = k fixed, in the next section we&rsquo;ll review systems with coupling to a second
rate equation for y(t) yielding general motion in the xy plane. Despite its restricted
</p>
<p>form, we will see that problems like (1.29) occur as pseudo-two-dimensional phase
</p>
<p>plane structures in reductions of more complicated systems in Chap. 10.
</p>
<p>1.5 Two-Dimensional Phase Plane Analysis
</p>
<p>For systems of two coupled autonomous rate equations (called phase plane systems)
</p>
<p>the approach of the previous section can be extended to similarly give a qualitative
</p>
<p>understanding of all solutions from just local properties of the rate functions.</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_10">http://dx.doi.org/10.1007/978-3-319-23042-9_10</a></div>
</div>
<div class="page"><p/>
<p>1.5 Two-Dimensional Phase Plane Analysis 13
</p>
<p>For n = 2 with x(t) = (x(t), y(t)), Eq. (1.2) can be written as
</p>
<p>dx
</p>
<p>dt
= f (x, y),
</p>
<p>dy
</p>
<p>dt
= g(x, y), (1.30a)
</p>
<p>with initial conditions at t = 0,
</p>
<p>x(0) = x0, y(0) = y0. (1.30b)
</p>
<p>Interpreting variable t as time, this problem can be interpreted as describing the
</p>
<p>motion of a point in the xy &ldquo;phase plane&rdquo; starting from position x0 = (x0, y0)
subject to a position-dependent velocity v = ( f, g). The solution of (1.30a, 1.30b)
is a parametric curve (or trajectory) passing through the point x0.
</p>
<p>Using the chain rule to eliminate t from y(x) = y(x(t)), (1.30a) leads to the
associated ODE (also called the slope field equation),
</p>
<p>dy
</p>
<p>dx
=
</p>
<p>g(x, y)
</p>
<p>f (x, y)
. (1.31)
</p>
<p>Solving this first order ODE for y(x) yields a family of implicit solutions called the
</p>
<p>integral curves that trace out the same paths in the plane as the trajectories. The
</p>
<p>implicit solutions give only the shape of the curves while parametric solutions also
</p>
<p>give the direction of motion on the curves with respect to increasing t .
</p>
<p>Analogous to the analysis of the phase line, equilibrium points (x&lowast;, y&lowast;) are defined
by positions where both rate functions vanish,
</p>
<p>f (x&lowast;, y&lowast;) = 0, g(x&lowast;, y&lowast;) = 0. (1.32)
</p>
<p>With the exception of equilibrium points, results on uniqueness of solutions ensure
</p>
<p>that each point x0 has a single solution curve passing through it and that those curves
</p>
<p>cannot cross. Consequently, assuming f and g are smooth, the solutions are smooth
</p>
<p>curves everywhere in the phase plane except at the equilibrium points. Observe
</p>
<p>from (1.31) that at an equilibrium point the slope dy/dx is indeterminate (formally
</p>
<p>dy/dx =&lsquo;0/0&rsquo;) and requires more careful analysis to describe the local structure of
solutions.
</p>
<p>Near an equilibrium point, define u(t) = (x(t)&minus;x&lowast;, y(t)&minus;y&lowast;) satisfying du/dt =
f(u + x&lowast;), and using a multi-variable Taylor series approximation of f for |u| &rarr; 0
yields the linearised system
</p>
<p>du
</p>
<p>dt
= Au, (1.33)
</p>
<p>where the matrix A is the Jacobian (or gradient &nabla;f), evaluated at (x&lowast;, y&lowast;),
</p>
<p>A = J(x&lowast;, y&lowast;) &equiv;
(
</p>
<p>&part;x f (x&lowast;, y&lowast;) &part;y f (x&lowast;, y&lowast;)
&part;x g(x&lowast;, y&lowast;) &part;y g(x&lowast;, y&lowast;)
</p>
<p>)
</p>
<p>. (1.34)</p>
<p/>
</div>
<div class="page"><p/>
<p>14 1 Rate Equations
</p>
<p>Seeking solutions of the form u(t) = veλt then reduces (1.33) to the matrix eigen-
value problem,
</p>
<p>Av = λv.
</p>
<p>At each equilibrium point, linear algebra yields the eigenvalues as the roots of the
</p>
<p>characteristic polynomial obtained from the setting the determinant to zero,
</p>
<p>|A &minus; λI| = 0.
</p>
<p>Subsequently, for each eigenvalue, the eigenvectors can be obtained by row-
</p>
<p>reductions as the nontrivial nullvector of (A &minus; λkI)vk = 0. The general solution
of the linearised system is then given by the linear combination of the eigenmodes,
</p>
<p>x(t) &asymp; x&lowast; + c1v1eλ1t + c2v2eλ2t for |x &minus; x&lowast;| &rarr; 0. (1.35)
</p>
<p>If A does not have a complete set of eigenvectors (a possibility with repeated eigen-
</p>
<p>values) then this form must be modified.
</p>
<p>Extending the discussion of asymptotic stability from Sect. 1.4 in terms of all
</p>
<p>solutions approaching x&lowast; or any diverging from it, the stability of solutions starting
near x&lowast; can be understood in terms of the eigenvalues, see Table 1.1. Problems having
Re(λ) = 0 fall into a degenerate case, called a centre manifold, and must be studied
more carefully, somewhat like (1.27, 1.28).
</p>
<p>While for the phase line case the behaviour of solutions could be inferred directly
</p>
<p>from the slope of the rate function, λ = a = f &prime;(x&lowast;), the geometry for the phase plane
case is more complicated. The stability properties are still set by the derivatives of
</p>
<p>the rate functions at x&lowast; but now the different cases are most conveniently expressed
in terms of the eigenvalues of A, (1.35). The local geometry of the integral curves
</p>
<p>near non-degenerate x&lowast; is then given by the cases outlined in Table 1.2, where the
</p>
<p>Table 1.1 Asymptotic stability of equilibrium point x&lowast; in terms of eigenvalues from the linear
stability analysis
</p>
<p>λ&rsquo;s Stability t &rarr; &infin;
Both Re(λ) &lt; 0 Stable |u(t)| &rarr; 0
Either Re(λ) &gt; 0 Unstable |u(t)| &rarr; &infin;
</p>
<p>Table 1.2 Geometry of trajectories near equilibrium point x&lowast; in terms of the eigenvalues
</p>
<p>λ&rsquo;s Name Geometry Stability
</p>
<p>λ1, λ2 same sign Node Rays Re(λ)
</p>
<p>λ1, λ2 opp. signs Saddle Hyperbolas Unstable
</p>
<p>λ = &plusmn;iβ Centre Circles Neutral
λ = α &plusmn; iβ Spiral Spirals Re(λ)</p>
<p/>
</div>
<div class="page"><p/>
<p>1.5 Two-Dimensional Phase Plane Analysis 15
</p>
<p>eigenvectors set the orientation of the geometry (most notably the directions of the
</p>
<p>stable and unstable axes of a saddle point).
</p>
<p>If f (x, y) and g(x, y) are linear functions, then there will be a single equilibrium
</p>
<p>point and the above analysis describes the form of the entire phase plane. Otherwise,
</p>
<p>this gives a description in a neighbourhood surrounding each x&lowast;. However, using
the results on uniqueness of trajectories (i.e. curves may cross only at equilibrium
</p>
<p>points), trajectories can be smoothly extended and a global structure can be sketched
</p>
<p>by piecing-together the local linearised geometries around each of the equilibrium
</p>
<p>points.
</p>
<p>In addition to systems of rate equations, phase plane analysis can also be applied
</p>
<p>to second-order autonomous ODEs for x(t), such as
</p>
<p>d2x
</p>
<p>dt2
&minus; g
</p>
<p>(
</p>
<p>x,
dx
</p>
<p>dt
</p>
<p>)
</p>
<p>= 0, (1.36)
</p>
<p>which can be written as an equivalent system by defining an intermediate variable
</p>
<p>y(t):
dx
</p>
<p>dt
= y,
</p>
<p>dy
</p>
<p>dt
= g(x, y). (1.37)
</p>
<p>In this system, the relationship x &prime; = y defines the direction of trajectories as follows:
</p>
<p>&bull; x &prime; &gt; 0 : x(t) increasing (&rarr;) for y &gt; 0 (upper half xy plane)
&bull; x &prime; &lt; 0 : x(t) decreasing (&larr;) for y &lt; 0 (lower half xy plane)
</p>
<p>This choice for the intermediate variable is not unique but has a nice physical in-
</p>
<p>terpretation in term of (x, y) = (position, velocity) with the x-axis being states at
rest (zero velocity). An example of a different choice for y(t) will be given in a later
</p>
<p>chapter.
</p>
<p>As an example, consider the pendulum equation for the angular position of a
</p>
<p>suspended mass swinging under the influence of gravity [7],
</p>
<p>d2θ
</p>
<p>dt2
+ sin θ = 0. (1.38)
</p>
<p>Letting x(t) = θ(t) and following (1.37), we arrive at the phase plane system,
</p>
<p>dx
</p>
<p>dt
= y,
</p>
<p>dy
</p>
<p>dt
= &minus; sin x . (1.39)
</p>
<p>Applying (1.32), the equilibrium points are given by y&lowast; = 0 with x&lowast; = nπ for
n = 0,&plusmn;1,&plusmn;2, . . . . From (1.34) the Jacobian matrix at any (x, y) is
</p>
<p>J(x, y) =
(
</p>
<p>0 1
</p>
<p>&minus; cos x 0
</p>
<p>)
</p>
<p>.</p>
<p/>
</div>
<div class="page"><p/>
<p>16 1 Rate Equations
</p>
<p>x
</p>
<p>y
</p>
<p>π0 0&minus;π
</p>
<p>1
</p>
<p>0
</p>
<p>-1
</p>
<p>x
</p>
<p>y
</p>
<p>ππ
</p>
<p>3
</p>
<p>2
</p>
<p>1
</p>
<p>0
</p>
<p>-1
</p>
<p>-2
</p>
<p>-3
</p>
<p>Fig. 1.3 The phase plane for the pendulum (1.39): (Left) Sketch of linearised behaviours in neigh-
</p>
<p>bourhoods of the equilibrium points and (Right) a computed plot of the full phase plane
</p>
<p>Evaluating the Jacobian at the equilibrium point (0, 0) yields
</p>
<p>A = J(0, 0) =
(
</p>
<p>0 1
</p>
<p>&minus;1 0
</p>
<p>)
</p>
<p>=&rArr; λ2 + 1 = 0, λ = &plusmn;i (a centre),
</p>
<p>while the equilibrium point (π, 0) yields
</p>
<p>A = J(π, 0) =
(
</p>
<p>0 1
</p>
<p>1 0
</p>
<p>)
</p>
<p>=&rArr; λ2 &minus; 1 = 0, λ = &plusmn;1 (a saddle point),
</p>
<p>with eigenvectors (1,&minus;1) and (1, 1). These vectors define the asymptotes of the
family of hyperbolas centred at this equilibrium point, called the stable manifold (for
</p>
<p>λ &lt; 0) and unstable manifold (for λ &gt; 0), y = &plusmn;(x &minus; π), see Fig. 1.3 (left). Other
equilibrium points at ([2k + 1]π, 0) also have exactly the same form by the periodic
nature of g(x). Figure 1.3 shows that the full phase plane smoothly extends the local
</p>
<p>behaviours at the equilibria to cover all possible solutions. It is notable that trajectories
</p>
<p>connecting the saddles (called heteroclinic orbits) separate small-amplitude periodic
</p>
<p>oscillations abound θ = 0 (the continuous family of closed curves) from high-speed
&ldquo;spinning&rdquo; solutions, where the angle increases (or decreases) monotonically for all
</p>
<p>time.
</p>
<p>1.5.1 Nullclines
</p>
<p>Nullclines are curves in the xy plane that can provide further understanding of sys-
</p>
<p>tems by dividing the phase plane into regions with different behaviours. The nullclines
</p>
<p>are not solutions of the system, but they do yield valuable insight on the properties
</p>
<p>of solution trajectories that pass through the nullcline curves (or lie on one side or
</p>
<p>the other).</p>
<p/>
</div>
<div class="page"><p/>
<p>1.5 Two-Dimensional Phase Plane Analysis 17
</p>
<p>The x-nullcline is a curve in the phase plane on which dx/dt = 0. On this nullcline
x(t) instantaneously has zero rate of change, hence x is fixed while y(t) changes
</p>
<p>with time, so a trajectory passing through the x-nullcline will have a vertical tangent.
</p>
<p>The x-nullcline is given by the implicitly defined curve f (x, y) = 0. The x-nullcline
also separates solutions that have x(t) increasing from those that have x decreasing
</p>
<p>with time,
</p>
<p>Region where f (x, y) &lt; 0:
dx
</p>
<p>dt
&lt; 0 x(t) decreasing (&larr;)
</p>
<p>Region where f (x, y) &gt; 0:
dx
</p>
<p>dt
&gt; 0 x(t) increasing (&rarr;)
</p>
<p>Analogously, the y-nullcline is a curve on which dy/dt = 0. Here y(t) instanta-
neously has zero rate of change and a trajectory passing through the y-nullcline will
</p>
<p>have a horizontal tangent. The y-nullcline is given by the implicitly defined curve
</p>
<p>g(x, y) = 0. The y-nullcline also separates solutions that have y(t) increasing from
those that have y decreasing with time,
</p>
<p>Region where g(x, y) &lt; 0:
dy
</p>
<p>dt
&lt; 0 y(t) decreasing (&darr;)
</p>
<p>Region where g(x, y) &gt; 0:
dy
</p>
<p>dt
&gt; 0 y(t) increasing (&uarr;)
</p>
<p>Combining the information on horizontal and vertical components of motion from
</p>
<p>the x, y-nullclines respectively, yields very useful local qualitative information on
</p>
<p>the directions of trajectories that can be extended to understand the structure of the
</p>
<p>phase plane. In particular, note that the intersections of the nullclines are equilibrium
</p>
<p>points and the transitions in values of dx/dt and dy/dt can help identify the type of
</p>
<p>equilibrium point without doing the linear stability analysis.
</p>
<p>As an example consider the system
</p>
<p>dx
</p>
<p>dt
= y &minus;
</p>
<p>x2
&radic;
</p>
<p>2
,
</p>
<p>dy
</p>
<p>dt
= x2 + y2 &minus; 4. (1.40)
</p>
<p>The first equation gives the x-nullcline as the parabola y = x2/
&radic;
</p>
<p>2. Above the
</p>
<p>parabola x(t) is increasing with time, while below the parabola x(t) is monotone
</p>
<p>decreasing. On the parabola, trajectories have vertical tangents. The second equation
</p>
<p>in (1.40) gives the y-nullcline as the circle x2 + y2 = 4. Inside the circle y(t) is
decreasing, while outside the circle y(t) is increasing. On the circle, trajectories have
</p>
<p>horizontal tangents.
</p>
<p>The intersection of the nullclines makes the locations of the two equilibrium points
</p>
<p>immediately clear. These points could also be obtained analytically from (1.32) as
</p>
<p>(x&lowast;, y&lowast;) = (&plusmn;
&radic;
</p>
<p>2,
&radic;
</p>
<p>2). Subsequently, the eigenvalues for the linear stability analysis
</p>
<p>at the equilibrium points can be obtained by solving</p>
<p/>
</div>
<div class="page"><p/>
<p>18 1 Rate Equations
</p>
<p>Fig. 1.4 Nullclines for system (1.40): (Left) directional information determined from the x- and
</p>
<p>y-nullclines and its application to local structure near the two equilibrium points, (Right) computed
</p>
<p>trajectories for the system
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>&minus;
&radic;
</p>
<p>2x&lowast; &minus; λ 1
2x&lowast; 2y&lowast; &minus; λ
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>= 0.
</p>
<p>At (x+&lowast; , y&lowast;) we get λ1 &asymp; 3.356 and λ2 &asymp; &minus;2.528 yielding a saddle point. At
(x&minus;&lowast; , y&lowast;) we get an unstable spiral with λ1,2 &asymp; 2.414 &plusmn; 1.630i . The nature of these
equilibria could be inferred from information provided by the nullclines without these
</p>
<p>slightly cumbersome algebraic calculations, see Fig. 1.4. The usefulness of nullclines
</p>
<p>becomes more significant in reducing more complicated systems and constructing
</p>
<p>proofs about properties of families of solutions.
</p>
<p>1.6 Further Directions
</p>
<p>The analysis of the linear stability of equilibrium points can be extended to dynamical
</p>
<p>systems in n-dimensions [70]. However, the phase plane is special because some
</p>
<p>geometric arguments do not extend in a simple way to curves in space Rn for n &ge; 3.
Consequently it is very helpful when higher-order systems can be reduced down to
</p>
<p>phase planes.
</p>
<p>The material in this chapter gives only a very brief review of selected fundamen-
</p>
<p>tal results. For more detailed background on phase planes and further coverage of
</p>
<p>bifurcations and dynamical systems theory, see, for example [43, 45, 54, 70, 94].
</p>
<p>Comprehensive presentations of chemical reaction systems are found in most
</p>
<p>chemistry textbooks, for example [6]. More concise introductions are given in the
</p>
<p>applied mathematics books by Holmes [49] and Keener and Sneyd [57].
</p>
<p>The models described here by systems of ODE are the simplest type of rate equa-
</p>
<p>tions, sometimes also called state-space models, with the rates of evolution dependent
</p>
<p>on the current solution state. In delay differential equations, the current rate depends
</p>
<p>on the solution at an earlier time, dx/dt = f (x(t &minus; 1)) [35]. Discrete-time maps,
also called difference equations are analogous algebraic equations describing evolv-</p>
<p/>
</div>
<div class="page"><p/>
<p>1.6 Further Directions 19
</p>
<p>ing solutions at discrete times, say year-to-year, as in xn+1 = f (xn) [5]. Stochastic
differential equations have randomly varying contributions to the rate functions and
</p>
<p>are sometimes used to represent the variations among the dynamics of individuals
</p>
<p>in a large population, improving on (1.2) which describes a uniform average behav-
</p>
<p>iour [36]. More detailed models of populations, called structured population models
</p>
<p>divide up the population by age or size; if these are treated as continuous variables,
</p>
<p>then the rate equations yield partial differential equations. We will touch on some of
</p>
<p>these topics in later chapters. Haberman&rsquo;s book [45] also provides very accessible
</p>
<p>introductions to several of these types of models.
</p>
<p>1.7 Exercises
</p>
<p>1.1 Consider the problem of tracking the vertical position, z(t), of a rocket whose
</p>
<p>mass changes as it consumes its fuel. If the rocket starts from rest at z(0) = 0 with
initial mass m(0) = m0 and obeys
</p>
<p>d
</p>
<p>dt
</p>
<p>(
</p>
<p>m(t)
dz
</p>
<p>dt
</p>
<p>)
</p>
<p>= &minus;mg + τm,
dm
</p>
<p>dt
= &minus;m,
</p>
<p>solve the ODEs to determine z(t) and determine the condition on τ that is necessary
</p>
<p>for lift-off.
</p>
<p>1.2 Use basic solution methods for first order ODEs to solve the elementary
</p>
<p>reactions (1.8&ndash;1.13) for A(t), B(t),C(t) starting from initial conditions A0, B0,C0
respectively.
</p>
<p>1.3 Write the four rate equations for chemicals C, E, P, S governed by the reac-
</p>
<p>tions4
</p>
<p>S + E
k1&minus;⇀↽&minus;
k2
</p>
<p>C C
k3&minus;&rarr; P + E .
</p>
<p>1.4 Write the rate equations for X (t), Y (t), Z(t) describing the reaction system
</p>
<p>(source)
A&minus;&rarr; X Y
</p>
<p>B&minus;⇀↽&minus;
C
</p>
<p>X Z
D&minus;⇀↽&minus;
E
</p>
<p>Y 3Y
G&minus;&rarr; Z Z H&minus;&rarr; (waste).
</p>
<p>1.5 Consider the dynamics of x(t) satisfying the first order ODE,
</p>
<p>dx
</p>
<p>dt
= x &minus; x3 &minus; k x(0) = x0,
</p>
<p>for different values of the parameter k (see Fig. 1.2).
</p>
<p>4We delay solving more complicated systems of reactions to Chap. 10. Here we only want to set up
</p>
<p>the rate equations.</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_10">http://dx.doi.org/10.1007/978-3-319-23042-9_10</a></div>
</div>
<div class="page"><p/>
<p>20 1 Rate Equations
</p>
<p>(a) For k = 0, obtain the exact solutions starting from x0 = 1/2 and x0 = &minus;2. Show
that these solutions match the linearised results from (1.26) at the equilibrium
</p>
<p>points x&lowast; = {&minus;1, 0, 1} for the long-time behaviour (t &rarr; &infin;), and the &ldquo;pre-
history&rdquo; of the solution (t &rarr; &minus;&infin;). Show that for all initial conditions with
x0 �= 0, one of two final states are approached as t &rarr; &infin;.
</p>
<p>(b) Determine the two values of k for which the ODE has only two distinct equilib-
</p>
<p>rium points. Sometimes called critical values or bifurcation points, such parame-
</p>
<p>ter values determine special cases, where different analysis is needed to describe
</p>
<p>the system; in this case, this will involve second-order degenerate equilibrium
</p>
<p>points. Determine the coefficient b occurring in the equation for the local be-
</p>
<p>haviour of solutions near the degenerate equilibrium points, du/dt = bu2 with
u(t) = x(t)&minus; x&lowast;.
Show that for this problem, these bifurcation values separate ranges of k where
</p>
<p>there are global attractors (unique final states approached by all initial conditions
</p>
<p>for t &rarr; &infin;) from cases where two stable equilibrium states co-exist (called bi-
stability).
</p>
<p>1.6 Consider the equations for local behaviour at second- and third-order degenerate
</p>
<p>equilibrium points, (1.27) and (1.28).
</p>
<p>(a) Use separation of variables to solve the ODE analytically and subsequently
</p>
<p>describe the stability of the equilibrium point at u = 0 for both choices of the
sign of b.
</p>
<p>(b) Using only the sign of the velocity on the phase line consider solutions starting
</p>
<p>from initial conditions with u0 ≷ 0 to obtain the stability of the equilibrium
</p>
<p>point without the need for the ODE solutions.
</p>
<p>(c) Repeat (a, b) for the dependence of (1.28) on c.
</p>
<p>1.7 Consider the second order ODE for x(t),
</p>
<p>d2x
</p>
<p>dt2
= x &minus; 1
</p>
<p>2
x2.
</p>
<p>(a) Let y = dx/dt and write the ODE as a phase plane system. Determine the linear
stability properties of the two equilibrium points.
</p>
<p>(b) Show that the solutions satisfy the equation
</p>
<p>1
2
(x &prime;)2 &minus; 1
</p>
<p>2
x2 + 1
</p>
<p>6
x3 = H,
</p>
<p>where H is a constant of integration, sometimes called the Hamiltonian.
</p>
<p>(c) For a range of values, 0 &lt; x &lt; M , this problem has a continuous set of periodic
</p>
<p>solutions. Show that the maximum and minimum values of x(t) of each periodic
</p>
<p>solution satisfy a polynomial equation involving H . Define the amplitude of the
</p>
<p>oscillations as A = xmax&minus; xmin. Show that A = 0 corresponds to an equilibrium
point. Show that the largest amplitude solution has xmin = 0; determine its value
for xmax(=M). What is the range of values for H?</p>
<p/>
</div>
<div class="page"><p/>
<p>1.7 Exercises 21
</p>
<p>(d) Use t =
&int;
</p>
<p>dt =
&int;
</p>
<p>dx
dx/dt
</p>
<p>to show that the period of oscillation for these solutions
</p>
<p>is given by
</p>
<p>P = 2
xmax
&int;
</p>
<p>xmin
</p>
<p>dx
&radic;
</p>
<p>x2 &minus; 1
3
</p>
<p>x3 + 2H
.
</p>
<p>(e) Show that the simpler piecewise-linear model
</p>
<p>d2x
</p>
<p>dt2
= f (x) with f (x) =
</p>
<p>{
</p>
<p>x x &lt; 1
</p>
<p>2 &minus; x x &ge; 1
</p>
<p>has the same equilibrium points and the same linear stability properties at the
</p>
<p>equilibria.
</p>
<p>Solve the two linear problems
</p>
<p>d2xA
</p>
<p>dt2
= xA xA(0) = xmin x &prime;A(0) = 0
</p>
<p>d2xB
</p>
<p>dt2
= 2 &minus; xB xB(P/2) = xmax x &prime;B(P/2) = 0
</p>
<p>and construct a periodic solution of the piecewise-linear model by enforcing
</p>
<p>smoothness, x &prime;A = x &prime;B at xA = xB = 1.</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 2
</p>
<p>Transport Equations
</p>
<p>Many systems exhibit evolution over time with properties of interest that vary
</p>
<p>throughout their spatial domains. Examples of such systems arise in population
</p>
<p>dynamics, which describes the distribution of individuals in some population and
</p>
<p>how they interact. &ldquo;Individuals&rdquo; could refer to molecules, electrons, particles, ani-
</p>
<p>mals, people, company stocks, or network messages.
</p>
<p>Oneway to study the overall population is to attempt to track each individual, such
</p>
<p>approaches are sometimes called individual-based models. The tracking process is
</p>
<p>usually very labour intensive and involves collecting a lot of data on the actions of
</p>
<p>all individuals. If this level of detail is not crucial and a more &lsquo;large-scale&rsquo; view is of
</p>
<p>interest, then continuum theory may be a better option.
</p>
<p>Continuum theories yield evolution equations with respect to properties that are
</p>
<p>averaged over small intervals of time and small regions of space. In such cases, we
</p>
<p>implicitly assume a continuum hypothesis which states that appropriately averaged
</p>
<p>behaviours of individuals can be generally predicted from trends in the local popula-
</p>
<p>tion. We consequently formulate continuum models as partial differential equations
</p>
<p>(PDE) governing the evolution of density functions (f (x, t)) describing properties of
</p>
<p>the population at a given position and time. Integrating the density over the entire
</p>
<p>domain can be used to capture the time-dependence of the property on the whole
</p>
<p>population, F (t) =
&int;
</p>
<p>f (x, t) dx.
</p>
<p>Some specific applications of continuum models include:
</p>
<p>&bull; Fluid dynamics: the flow of liquids and gases (density of molecules in space)
&bull; Solid mechanics: the deformation of solids (density of molecules in space)
&bull; Electromagnetics: the flow of electric currents in materials (density of electric
charges in space)
</p>
<p>&bull; Scattering theory: dynamics due to collisions in high energy particle physics (den-
sity of particles having different velocities)
</p>
<p>&copy; Springer International Publishing Switzerland 2015
</p>
<p>T. Witelski and M. Bowen, Methods of Mathematical Modelling,
</p>
<p>Springer Undergraduate Mathematics Series, DOI 10.1007/978-3-319-23042-9_2
</p>
<p>23</p>
<p/>
</div>
<div class="page"><p/>
<p>24 2 Transport Equations
</p>
<p>&bull; Age-structured population dynamics: birth, death, and aging of a population
(distribution of individuals having different ages) [28, 74]
</p>
<p>&bull; Size-structured population dynamics: growth and decay of physical sizes of indi-
viduals in a population (distribution of individuals having different sizes) [8]
</p>
<p>Fluid dynamics and solid mechanics are often grouped together under the heading
</p>
<p>of continuum mechanics. Other population models focus not on change in position,
</p>
<p>but on properties like stock price in financial models, popularity in social networks
</p>
<p>or genetic traits in biological systems.
</p>
<p>In each of these contexts, PDEs can be used to describe the redistribution of the
</p>
<p>property of interest over time. Conveying shifts or &ldquo;motion&rdquo; in the density, whether
</p>
<p>with respect to spatial position or with the independent variable x representing other
</p>
<p>properties (e.g. velocity, age, size), such PDEs are also broadly called transport
</p>
<p>equations. The common structure shared by these models is having a PDE for the
</p>
<p>rate of change of the density involving the spatial gradient of a flux function, which
</p>
<p>characterises transport of the property within the population. Transport equations
</p>
<p>are fundamental for describing problems in many fields extending from theoretical
</p>
<p>physics, chemical engineering, and mathematical biology to probability theory.
</p>
<p>In this chapter we introduce the fundamental approach for formulating transport
</p>
<p>models (conservation laws and the Reynolds transport theorem). We then go on to
</p>
<p>describe the method of characteristics, a methodology for constructing exact solu-
</p>
<p>tions to basic transport models.
</p>
<p>2.1 The Reynolds Transport Theorem
</p>
<p>As a conceptual starting point, we consider how we might describe the dynamics
</p>
<p>of individuals in a large population&mdash;describing their motion (change of absolute
</p>
<p>position as a function of time, X(t)) and deformation (rearrangement or change of
</p>
<p>relative position within groups of surrounding individuals).
</p>
<p>In order to introduce the basic principles, we begin by studying the case of passive
</p>
<p>transport of inert particles carried by an externally imposed flow field, for example,
</p>
<p>particles of dust cloud in the wind or a pollutant carried in a running river. Here
</p>
<p>&ldquo;passive&rdquo; indicates that the presence of the particles does not influence the flow
</p>
<p>driving their motion.
</p>
<p>Each particle can be uniquely identified by its initial position at time t = 0,
</p>
<p>X(t = 0) = A = (A,B,C) ( X(t = 0) = A in 1D ) (2.1a)
</p>
<p>Assume an imposed velocity field, v(x, t), is given that specifies the speed and direc-
</p>
<p>tion that a particle occupying position x would take at time t. Having an explicit
</p>
<p>expression for properties in a fixed coordinate system is called an Eulerian descrip-
</p>
<p>tion. From the definition of velocity as the rate of change of position, the motion of
</p>
<p>a particle is given by</p>
<p/>
</div>
<div class="page"><p/>
<p>2.1 The Reynolds Transport Theorem 25
</p>
<p>dX
</p>
<p>dt
= v(X, t).
</p>
<p>(
dX
</p>
<p>dt
= v(X, t) in 1D
</p>
<p>)
</p>
<p>(2.1b)
</p>
<p>This initial value problem gives the motion of a particle over time, and is sometimes
</p>
<p>called the problem for the particle&rsquo;s pathline.
</p>
<p>An alternative point of view is to recognise that for a particle starting from position
</p>
<p>(2.1a), the Eulerian description of the entire velocity field is not needed. All that is
</p>
<p>essential is the velocity along the particle&rsquo;s pathline. The Lagrangian description
</p>
<p>gives a property following the motion of a given particle as a function of time. The
</p>
<p>Lagrangian velocity for the particle starting from position A is
</p>
<p>V(t;A) = v(X(t;A), t). (2.2)
</p>
<p>The problem for the pathline can then be restated in Lagrangian form as
</p>
<p>dX
</p>
<p>dt
= V(t;A), X(0;A) = A. (2.3)
</p>
<p>We will show that the ability to change between these two equivalent forms will
</p>
<p>enable us to solve transport equations.
</p>
<p>Values of other properties carried by point particles (e.g. density, temperature,
</p>
<p>radioactivity) can similarly be expressed in both Eulerian f (x, t) and Lagrangian
</p>
<p>F(t) forms via
</p>
<p>F(t;A) = f (X(t;A), t). (2.4)
</p>
<p>In describing the evolution of any property f following a particular particle, it is
</p>
<p>necessary to calculate the rate of changeof f for the givenparticle fpart(t) &equiv; F(t;A) =
f (X(t;A), t). Using the chain rule, we can express this &ldquo;Lagrangian time derivative&rdquo;
in terms of Eulerian functions,
</p>
<p>dfpart
</p>
<p>dt
= &part;f
</p>
<p>&part;t
+&nabla;f &middot; dX
</p>
<p>dt
</p>
<p>= &part;f
&part;t
</p>
<p>+ v &middot; &nabla;f &equiv; Df
Dt
</p>
<p>(2.5)
</p>
<p>where we have used (2.1b). The Eulerian form of this derivative is called the con-
</p>
<p>vective (or material) derivative and is denoted
Df
Dt
. We will see that the velocity field
</p>
<p>defining the flow has a special role in transport equations. If v is given, then the
</p>
<p>problem for the evolution of the property of interest is called a kinematics problem
</p>
<p>(as in passive transport). If the evolution of v is coupled to f and must be determined
</p>
<p>as part of the solution, then it is a more challenging dynamics problem.
</p>
<p>The next stage in formulating a continuum model is to determine the rate of
</p>
<p>change of a property evaluated over a &ldquo;material blob&rdquo;&mdash;in other words, we consider
</p>
<p>a specific set of particles, defined as starting from a set of A values (2.1a) occupying
</p>
<p>a region D in space. For example, picture the blob as the fluid in a small droplet. The</p>
<p/>
</div>
<div class="page"><p/>
<p>26 2 Transport Equations
</p>
<p>cumulative value of property f over the material blob is given by
</p>
<p>fblob(t) =
&int;&int;&int;
</p>
<p>D(t)
</p>
<p>f (x, t) dV, (2.6)
</p>
<p>whereD(t) is the region occupied by themoving, deforming blob at time t.Wewould
</p>
<p>like to know how fblob(t) varies with time. In one dimension, a &ldquo;blob&rdquo; is simply a
</p>
<p>time-dependent interval, a(t) &le; x &le; b(t) and (2.6) reduces to
</p>
<p>fblob(t) =
&int; b(t)
</p>
<p>a(t)
</p>
<p>f (x, t) dx. (2.7)
</p>
<p>To find the rate of change, we apply Leibniz&rsquo;s rule to determine the derivative of an
</p>
<p>integral with time-dependent endpoints,
</p>
<p>d
</p>
<p>dt
</p>
<p>(
&int; b(t)
</p>
<p>a(t)
</p>
<p>f (x, t) dx
</p>
<p>)
</p>
<p>=
&int; b
</p>
<p>a
</p>
<p>&part;f
</p>
<p>&part;t
dx + f (b, t)db
</p>
<p>dt
&minus; f (a, t)da
</p>
<p>dt
︸ ︷︷ ︸
</p>
<p>f (x, t)
dx
</p>
<p>dt
</p>
<p>∣
∣
∣
∣
</p>
<p>x=b
</p>
<p>x=a
</p>
<p>=
&int; b
</p>
<p>a
</p>
<p>[
&part;f
</p>
<p>&part;t
+ &part;
</p>
<p>&part;x
</p>
<p>(
</p>
<p>f (x, t)
dx
</p>
<p>dt
</p>
<p>)]
</p>
<p>dx
</p>
<p>=
&int; b
</p>
<p>a
</p>
<p>[
&part;f
</p>
<p>&part;t
+ &part;
</p>
<p>&part;x
(f v)
</p>
<p>]
</p>
<p>dx (2.8)
</p>
<p>where again, we have made use of (the one-dimensional version) of (2.1b). In two
</p>
<p>and three dimensions, making use of the divergence theorem, we can generalise this
</p>
<p>result to give the Reynolds Transport Theorem [1],
</p>
<p>d
</p>
<p>dt
</p>
<p>(&int;&int;&int;
</p>
<p>D(t)
</p>
<p>f dV
</p>
<p>)
</p>
<p>=
&int;&int;&int;
</p>
<p>D(t)
</p>
<p>[
&part;f
</p>
<p>&part;t
+ &nabla; &middot; (f v)
</p>
<p>]
</p>
<p>dV (2.9)
</p>
<p>2.2 Deriving Conservation Laws
</p>
<p>In order to apply the Reynolds transport theorem to obtain a transport model, we
</p>
<p>need the introduction of a conservation principle. This is a statement providing
</p>
<p>information about the rate of change of fblob that applies to all possible material
</p>
<p>blobs.
</p>
<p>For example, requiring conservation of mass&mdash;the principle that total mass can be
</p>
<p>neither created nor destroyed, the mass of every blob must remain constant in time.</p>
<p/>
</div>
<div class="page"><p/>
<p>2.2 Deriving Conservation Laws 27
</p>
<p>Expressing the mass in terms of the material density, f &equiv; ρ, in one-dimension this
gives
</p>
<p>mblob(t) =
&int; b(t)
</p>
<p>a(t)
</p>
<p>ρ(x, t) dx,
dmblob
</p>
<p>dt
= 0 &forall;(a, b). (2.10)
</p>
<p>In order to change from a statement about properties of blobs to a transport PDE, the
</p>
<p>final tool involved is an integral result from analysis, sometimes called the du Bois-
</p>
<p>Reymond lemma [49], which we state in its simplest form on the one-dimensional
</p>
<p>domain 0 &le; x &le; 1 as
</p>
<p>If
</p>
<p>&int; b
</p>
<p>a
</p>
<p>g(x) dx = 0 0 &le; &forall;(a, b) &le; 1, then g(x) &equiv; 0 for 0 &le; x &le; 1 . (2.11)
</p>
<p>In other words, if an integral vanishes for all choices of sub-domains, then the inte-
</p>
<p>grand must vanish on the whole domain.1 This result allows us to convert from an
</p>
<p>integral equation (called a weak form, applying on the domain as a whole) to a dif-
</p>
<p>ferential equation (called a strong form that applies locally, pointwise at each x in
</p>
<p>the whole domain), if the integral is valid for all blobs.
</p>
<p>Applying the Reynolds Transport theorem to (2.10), we reduce the principle of
</p>
<p>conservation of mass to a PDE for the density, yielding the (local) conservation law
</p>
<p>for mass density in one dimension,
</p>
<p>&part;ρ
</p>
<p>&part;t
+ &part;
</p>
<p>&part;x
(ρv) = 0, (2.12)
</p>
<p>also knownas the continuity equation. In three dimensions, the corresponding result is
</p>
<p>d
</p>
<p>dt
</p>
<p>(&int;&int;&int;
</p>
<p>D(t)
</p>
<p>ρ(x, t) dV
</p>
<p>)
</p>
<p>= 0 &forall;D =&rArr; &part;ρ
&part;t
</p>
<p>+&nabla; &middot; (ρv) = 0. (2.13)
</p>
<p>The quantity in the parenthesis is called the flux, q, and corresponds physically to
</p>
<p>the rate of ρ passing through a fixed point per unit time (here q = ρv).
If we are given information on the rate at which the property of interest is created
</p>
<p>or destroyed, say due to a chemical reaction as in dρ/dt = R like (1.8), then the rate
of change of the total amount of the chemical in domain D be can expressed by
</p>
<p>d
</p>
<p>dt
</p>
<p>(&int;&int;&int;
</p>
<p>D
</p>
<p>ρ dV
</p>
<p>)
</p>
<p>=
&int;&int;&int;
</p>
<p>D
</p>
<p>R dV . (2.14)
</p>
<p>This should be true in any subdomain (any material blob). If transport is present then
</p>
<p>D = D(t) and after applying the Reynolds Transport Theorem to the left integral,
we can regroup the resulting integrals together as
</p>
<p>1Assuming the integrand to be a smooth function.</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1">http://dx.doi.org/10.1007/978-3-319-23042-9_1</a></div>
</div>
<div class="page"><p/>
<p>28 2 Transport Equations
</p>
<p>&int;&int;&int;
</p>
<p>D(t)
</p>
<p>[
&part;ρ
</p>
<p>&part;t
+ &nabla; &middot; (ρv)&minus; R
</p>
<p>]
</p>
<p>dV = 0 &forall;D(t). (2.15)
</p>
<p>Then applying the du Bois-Reymond lemma yields the general conservation law
</p>
<p>including reaction terms (sometimes called source or sink terms depending on
</p>
<p>whether the rate of production is positive or negative),
</p>
<p>&part;ρ
</p>
<p>&part;t
+&nabla; &middot; (ρv) = R. (2.16)
</p>
<p>Equation (2.14) can be applied to Newton&rsquo;s second law, stating that the rate of
</p>
<p>change of momentum is equal to the sum of the applied forces
</p>
<p>d
</p>
<p>dt
</p>
<p>(&int;&int;&int;
</p>
<p>D(t)
</p>
<p>ρv dV
</p>
<p>)
</p>
<p>=
&int;&int;&int;
</p>
<p>D(t)
</p>
<p>f dV, (2.17)
</p>
<p>where f gives net forces per unit volume. Applying the Reynolds transport theorem,
</p>
<p>the du Bois Reymond lemma, and expressing the forces in terms of the divergence
</p>
<p>of a stress tensor, f = &nabla; &middot; σ , yields the Cauchy momentum equation,
</p>
<p>&part;(ρv)
</p>
<p>&part;t
+&nabla; &middot; (ρvv) = &nabla; &middot; σ. (2.18)
</p>
<p>Encapsulating the principles of conservation of mass and momentum, equations
</p>
<p>(2.13) and (2.18) are the basis of continuum mechanics [41, 50]. Supplemented by
</p>
<p>appropriate equations for defining the stress in terms of ρ and v, called constitu-
</p>
<p>tive relations or equations of state, these yield the governing equations for solid
</p>
<p>mechanics and the Navier&ndash;Stokes equations for fluid dynamics.
</p>
<p>2.3 The Linear Advection Equation
</p>
<p>In this section we will focus on the most fundamental case of (2.16), where R = 0
(no reactions) and the velocity is a uniform constant vector, v = cî (constant speed),
yielding the one-dimensional advection equation
</p>
<p>&part;ρ
</p>
<p>&part;t
+ c&part;ρ
</p>
<p>&part;x
= 0. (2.19)
</p>
<p>All solutions of the advection equation can be written as constant profile travelling
</p>
<p>waves,
</p>
<p>ρ(x, t) = P(x &minus; ct), (2.20)
</p>
<p>where the terminology &ldquo;travelling wave&rdquo; refers to a solution moving with a fixed
</p>
<p>velocity (speed in one dimension) and with a &ldquo;constant profile&rdquo; meaning that the</p>
<p/>
</div>
<div class="page"><p/>
<p>2.3 The Linear Advection Equation 29
</p>
<p>Fig. 2.1 A travelling wave
</p>
<p>solution (2.20),
</p>
<p>p(x, t) = P(x &minus; ct), of (2.19)
for c &gt; 0 at three successive
</p>
<p>times
</p>
<p>c
</p>
<p>x
</p>
<p>ρ
(x
</p>
<p>,
t)
</p>
<p>840
</p>
<p>1
</p>
<p>0
</p>
<p>-1
</p>
<p>wave shape P(x) given at t = 0 is maintained for all times. If c &gt; 0, the wave profile
propagates to the right (and to the left if c &lt; 0) (see Fig. 2.1).
</p>
<p>While (2.20) is a solution of equation (2.19) for any function P, for the purpose
</p>
<p>of considering the complexities associated with more general transport models (with
</p>
<p>other forms of flux), it is helpful to first understand the action of the equation on
</p>
<p>simple functions. If we can express P(x) as a complex Fourier series (see Appendix
</p>
<p>A), P(x) =
&sum;
</p>
<p>k Ake
ikx, then the travelling wave (2.20) can be written as
</p>
<p>ρ(x, t) =
&infin;
&sum;
</p>
<p>k=&minus;&infin;
Ake
</p>
<p>ik(x&minus;ct) =
&infin;
&sum;
</p>
<p>k=&minus;&infin;
Ake
</p>
<p>i[kx&minus;ωt], (2.21)
</p>
<p>where k is called the wave number (related to the wavelength between successive
</p>
<p>crests of cos(kx) in space, L = 2π /k) and ω is called the angular frequency (related
to the period of oscillation of sin(ωt) in time, T = 2π /ω). For (2.19), the expansion
(2.21) definesω = ck, but the Fourier decomposition is applicable to other equations
as long as a relationship can be found between the frequency and the wavenumber,
</p>
<p>ω = ω(k), called the dispersion relation.
Consider the fifth order linear homogeneous constant-coefficient PDE
</p>
<p>&part;ρ
</p>
<p>&part;t
+ c1
</p>
<p>&part;ρ
</p>
<p>&part;x
+ c3
</p>
<p>&part;3ρ
</p>
<p>&part;x3
+ c5
</p>
<p>&part;5ρ
</p>
<p>&part;x5
= 0. (2.22)
</p>
<p>If we substitute in a Fourier mode ρk(x, t) = Ak exp(i[kx &minus; ωt]) (called a uniform
plane wave) as a trial solution, (2.22) reduces to a relationship between ω and k
</p>
<p>given by
</p>
<p>&minus;iω + c1(ik)+ c3(ik)3 + c5(ik)5 = 0,
</p>
<p>which determines the dispersion relation, ω(k) = c1k &minus; c3k3 + c5k5.
Descriptions of wave properties in terms of the dispersion relation are fundamen-
</p>
<p>tal in many models that arise as generalisations of the advection equation. The phase
</p>
<p>speed, cp(k) &equiv; ω(k)/k, gives the speed ofwaveswithwavenumber k. Equation (2.19)
has constant phase speed (being independent of k), and so is called dispersionless</p>
<p/>
</div>
<div class="page"><p/>
<p>30 2 Transport Equations
</p>
<p>because all of its wave modes travel at the same speed, maintaining the steady profile
</p>
<p>P(x &minus; ct) (2.21). In contrast, for dispersive equations with cp(k) �= constant, the
profile given by the sum ρ(x, t) =
</p>
<p>&sum;
</p>
<p>k Ake
ik[x&minus;cp(k)t] changes with time as the com-
</p>
<p>ponent waves separate (&ldquo;disperse&rdquo;) according to their different speeds. The growth
</p>
<p>or decay of waves is described by dispersion relations having imaginary components:
</p>
<p>wave amplitudes aremaintained ifω(k) is purely real, while ifω(k) has an imaginary
</p>
<p>part then dissipation occurs. In order to observe this effect, consider what happens
</p>
<p>when we substitute the plane wave solution into the diffusion equation ρt = ρxx; the
dispersion relation is found to be ω = &minus;ik2, so that the (real-valued) phase speed
is cp = 0 and the wave will dissipate without propagating: ρk(x, t) = (Ake&minus;k
</p>
<p>2t)eikx
</p>
<p>(these correspond to so-called &lsquo;standing waves&rsquo;).
</p>
<p>We now turn our attention to describing methods for obtaining the solutions to
</p>
<p>various generalisations of the advection equation (2.19).
</p>
<p>2.4 Systems of Linear Advection Equations
</p>
<p>Consider a system of two coupled linear advection equations for properties p(x, t),
</p>
<p>q(x, t) on &minus;&infin; &lt; x &lt; &infin;,
pt + apx + bqx = 0 (2.23a)
qt + cpx + dqx = 0 (2.23b)
</p>
<p>where a, b, c, d are constants, and the initial conditions are given by
</p>
<p>p(x, 0) = f (x) q(x, 0) = g(x). (2.23c)
</p>
<p>The typical approach for determining the solutions of (2.23) is to decouple the system
</p>
<p>into independent advection equations, eachwith a travellingwave solution of the form
</p>
<p>&part;w
</p>
<p>&part;t
+ λ&part;w
</p>
<p>&part;x
= 0 &rArr; w(x, t) = W (x &minus; λt), (2.24)
</p>
<p>where λ is the wave speed for some appropriate travelling wave profile W .
</p>
<p>We start by assuming a solution as a linear combination,
</p>
<p>w(x, t) = Ap(x, t)+ Bq(x, t), (2.25)
</p>
<p>for some constants A,B to be determined. Forming the linear combination of
</p>
<p>A&middot; (2.23a) +B&middot; (2.23b) yields
</p>
<p>(Ap + Bq)t + (aA + cB)px + (bA + dB)qx = 0,</p>
<p/>
</div>
<div class="page"><p/>
<p>2.4 Systems of Linear Advection Equations 31
</p>
<p>while substituting w from (2.25) into (2.24) gives
</p>
<p>(Ap + Bq)t + (λA)px + (λB)qx = 0.
</p>
<p>Comparing coefficients in these equations leads to a matrix eigenvalue problem,
</p>
<p>(
</p>
<p>a c
</p>
<p>b d
</p>
<p>)(
</p>
<p>A
</p>
<p>B
</p>
<p>)
</p>
<p>= λ
(
</p>
<p>A
</p>
<p>B
</p>
<p>)
</p>
<p>. (2.26)
</p>
<p>Solving this system yields the eigenvalues (λ) defining the wave speeds and the
</p>
<p>components of the eigenvectors defining the relationship of w to the solutions p and
</p>
<p>q, (2.25). In order for the eigenvalues to be meaningful as speeds, they must be real
</p>
<p>values. The solutions of the eigenvalue problem, λ1 and A1,B1, and λ2 and A2,B2,
</p>
<p>determine the travelling wave solutions
</p>
<p>w1(x, t) = A1p(x, t)+ B1q(x, t) = W1(x &minus; λ1t),
w2(x, t) = A2p(x, t)+ B2q(x, t) = W2(x &minus; λ2t),
</p>
<p>(2.27)
</p>
<p>where the travelling wave profiles W1(x), W2(x) are otherwise undetermined so far.
</p>
<p>Applying initial conditions (2.23c) to evaluate these equations at time t = 0 explicitly
defines the wave profiles as satisfying
</p>
<p>A1f (x)+ B1g(x) = W1(x),
A2f (x)+ B2g(x) = W2(x).
</p>
<p>(2.28)
</p>
<p>WithWk nowknown in terms of f , g and theAk,Bk coefficients given by the eigenvec-
</p>
<p>tors, the right-hand side of (2.27) is known, yielding a linear system for p(x, t), q(x, t)
</p>
<p>in terms of combinations of of f (x &minus; λk t) and g(x &minus; λk t) (with k = 1, 2).
This approach extends to systems of any number of coupled linear equations,
</p>
<p>&part;p
</p>
<p>&part;t
+ M&part;p
</p>
<p>&part;x
= 0 (2.29)
</p>
<p>where p = (p, q, r, . . .)T &isin; Rn and M is an n &times; n constant coefficient matrix.
Assuming trial solutions of the form w = u &middot;p where u = (A,B,C, . . .)T and noting
the relationship between (2.26) and the coefficients in (2.23), we see that the general
</p>
<p>eigenvalue problem can be stated as
</p>
<p>MT u = λu. (2.30)
</p>
<p>If all the eigenvalues of MT are real and there is a complete set of eigenvectors, then
</p>
<p>(2.29) is called a hyperbolic system and its solutions can be expressed in terms of
</p>
<p>sums of travelling waves (see [65, 80, 81, 106] for more details).</p>
<p/>
</div>
<div class="page"><p/>
<p>32 2 Transport Equations
</p>
<p>2.5 The Method of Characteristics
</p>
<p>Semilinear wave equations take the form
</p>
<p>&part;p
</p>
<p>&part;t
+ c(x, t)&part;p
</p>
<p>&part;x
= r(x, t, p), (2.31a)
</p>
<p>where the speed c depends on both position and time, but not on the solution itself,
</p>
<p>and the reaction rate can depend on all three, but not on derivatives of the solution.
</p>
<p>The terminology &lsquo;semilinear&rsquo; arises because the left-hand side of the equation is
</p>
<p>linear with respect to the dependent variable p, while the right-hand side can be
</p>
<p>nonlinear in p. Problems for this class of equations with initial conditions
</p>
<p>p(x, 0) = f (x), (2.31b)
</p>
<p>can be solved by converting from the original Eulerian PDE form into a Lagrangian
</p>
<p>form that can be solved as a set of coupled ODEs.
</p>
<p>In order to see how (2.31a) defines a property evolving in a flow, let the Lagrangian
</p>
<p>form of the solution for each initial material coordinate A be written as
</p>
<p>P(t;A) = p(X(t;A), t) X(0;A) = A. (2.32)
</p>
<p>Using the chain rule, the rate of change of P is
</p>
<p>dP
</p>
<p>dt
= &part;p
</p>
<p>&part;t
+ &part;p
</p>
<p>&part;x
</p>
<p>dX
</p>
<p>dt
(2.33)
</p>
<p>and this can bematched termby termwith the PDE (2.31a) if theLagrangian variables
</p>
<p>evolve according to the characteristic equations
</p>
<p>dP
</p>
<p>dt
= r(X(t), t,P(t)), dX
</p>
<p>dt
= c(X(t), t). (2.34a)
</p>
<p>The initial conditions (2.31b) take the corresponding form
</p>
<p>P(0;A) = f (A), X(0;A) = A. (2.34b)
</p>
<p>The solution of the X-equation subject to its initial condition therefore defines a
</p>
<p>path in the (x, t) plane known as a characteristic curve (or simply a &lsquo;characteristic&rsquo;),
</p>
<p>and generalises the concept of a pathline. Once X(t) has been determined, it can be
</p>
<p>substituted into the evolution equation for P (2.34a)1 and can then be solved for P(t).
</p>
<p>Thus, the so-called method of characteristics replaces the Eulerian PDE with an
</p>
<p>initial value problem for a pair of ODEs. The Lagrangian solutions (X(t;A),P(t;A))
are parameterised by the initial material coordinate A and can sometimes be inverted
</p>
<p>to give the explicit Eulerian solution p(x, t).</p>
<p/>
</div>
<div class="page"><p/>
<p>2.5 The Method of Characteristics 33
</p>
<p>As an example, consider the transport problem for p(x, t),
</p>
<p>&part;p
</p>
<p>&part;t
+ 2x &part;p
</p>
<p>&part;x
= xp2, p(x, 0) = 2+ sin(x). (2.35)
</p>
<p>Following the above analysis, the corresponding characteristic problem is given by
</p>
<p>dX
</p>
<p>dt
= 2X, X(0) = A, (2.36a)
</p>
<p>dP
</p>
<p>dt
= XP2, P(0) = 2+ sin(A). (2.36b)
</p>
<p>Solving (2.36a) yields X(t;A) = Ae2t , which we can then substitute into the ODE
for P (2.36b) to obtain the general solution
</p>
<p>dP
</p>
<p>dt
= Ae2tP2 &rArr; P(t) = 1
</p>
<p>C &minus; 1
2
</p>
<p>Ae2t
.
</p>
<p>Imposing the initial condition on P at t = 0 (when X = A) then yields that
</p>
<p>P(t;A) =
(
</p>
<p>A
</p>
<p>2
</p>
<p>(
</p>
<p>1&minus; e2t
)
</p>
<p>+ 1
2+ sin(A)
</p>
<p>)&minus;1
,
</p>
<p>(see Fig. 2.2). Inverting Ae2t = X = x gives A = xe&minus;2t . Substituting this into P(t;A)
and applying P = p results in the final form of the solution
</p>
<p>p(x, t) =
(
</p>
<p>x
</p>
<p>2
</p>
<p>(
</p>
<p>e&minus;2t &minus; 1
)
</p>
<p>+ 1
2+ sin(xe&minus;2t)
</p>
<p>)&minus;1
.
</p>
<p>Fig. 2.2 (Left) Characteristic curves in the (x, t) plane for problem (2.35). (Right) Function values
</p>
<p>evolving on a characteristic curve</p>
<p/>
</div>
<div class="page"><p/>
<p>34 2 Transport Equations
</p>
<p>2.6 Shocks in Quasilinear Equations
</p>
<p>Quasilinear equations differ from semilinear equations only in having the speed c
</p>
<p>depend additionally on the solution,
</p>
<p>&part;p
</p>
<p>&part;t
+ c(x, t, p)&part;p
</p>
<p>&part;x
= r(x, t, p). (2.37)
</p>
<p>This makes the characteristic ODEs fully coupled,
</p>
<p>dP
</p>
<p>dt
= r(X, t,P), dX
</p>
<p>dt
= c(X, t,P). (2.38)
</p>
<p>For semilinear equations, the equation (2.34a) for the characteristic curves x =
X(t;A) decouples from P, and standard existence and uniqueness results guarantee
that two curves starting from different initial positions (and having different values
</p>
<p>of P(t)) will never intersect. This is not the case for the coupled equations in (2.38),
</p>
<p>where characteristics can cross and hence predict several different P(t;Aj) values
occurring simultaneously at the same x position.
</p>
<p>As an example, consider the inviscid Burgers equation,
</p>
<p>&part;p
</p>
<p>&part;t
+ p&part;p
</p>
<p>&part;x
= 0, (2.39)
</p>
<p>with initial conditions
</p>
<p>p(x, 0) =
{
</p>
<p>1&minus; |x| |x| &le; 1,
0 otherwise.
</p>
<p>(2.40)
</p>
<p>Equation (2.39) is an important mathematical model that will arise again later in
</p>
<p>other contexts; one aspect of its importance can be observed by noting that if the
</p>
<p>property p is the flow velocity, then (2.39) is the convective derivative of the velocity
</p>
<p>(2.5) (the Lagrangian form of the acceleration), Dv
Dt
</p>
<p>= vt + vvx = 0.
The characteristic equations for this example are
</p>
<p>dX
</p>
<p>dt
= P, X(0;A) = A, (2.41a)
</p>
<p>dP
</p>
<p>dt
= 0, P(0;A) =
</p>
<p>{
</p>
<p>1&minus; |A| |A| &le; 1,
0 else.
</p>
<p>(2.41b)
</p>
<p>We note that for this problem P remains constant along each characteristic, so that
</p>
<p>X = Pt + A and the solution can be expressed as</p>
<p/>
</div>
<div class="page"><p/>
<p>2.6 Shocks in Quasilinear Equations 35
</p>
<p>⎧
</p>
<p>⎪
⎪
⎪
⎨
</p>
<p>⎪
⎪
⎪
⎩
</p>
<p>X = A, P = 0 A &lt; &minus;1,
X = (1+ A)t + A, P = 1+ A &minus; 1 &le; A &le; 0,
X = (1&minus; A)t + A, P = 1&minus; A 0 &le; A &le; 1,
X = A, P = 0 A &gt; 1
</p>
<p>(2.42)
</p>
<p>and restated in an explicit form for t &ge; 0
</p>
<p>p(x, t) =
</p>
<p>⎧
</p>
<p>⎪
⎪
⎪
⎨
</p>
<p>⎪
⎪
⎪
⎩
</p>
<p>0 x &lt; &minus;1,
(1+ x)/(1+ t) &minus;1 &le; x &le; t,
(1&minus; x)/(1&minus; t) t &le; x &le; 1,
0 x &gt; 1.
</p>
<p>(2.43)
</p>
<p>There are several points to note about this representation of the solution&mdash;first, the
</p>
<p>piecewise-defined solutions are not mutually exclusive for t &gt; 1. Consequently
</p>
<p>multiple values are being predicted for p at some locations when t &gt; 1. In relation
</p>
<p>to this, the third subcase becomes undefined at time t = 1, changing from negative
slopes for t &lt; 1 to positive slopes for t &gt; 1. Figure2.3 shows the characteristic curves
</p>
<p>and p(x, t) profiles given by (2.43).Weobserve that the portion of the solution starting
</p>
<p>from x &isin; [&minus;1, 0] spreads out over an increasingly large region as its characteristics
separate from each other (this is sometimes called an expansion fan or rarefaction
</p>
<p>wave).
</p>
<p>In contrast, the portion of the solution starting from x &isin; [0, 1] is being compressed
into a smaller region (up until t = 1) and is referred to as a compressive wave. Its slope
steepens and overturns for t &gt; 1 to yield what could be described as a multi-valued
</p>
<p>&ldquo;breaking wave&rdquo;.
</p>
<p>Mathematically this part of the solution is predicting three values for a physical
</p>
<p>quantity (maybe a density, concentration or temperature, for example) that should
</p>
<p>have a unique value at any point x at a given time t.
</p>
<p> 0
</p>
<p> 1
</p>
<p> 2
</p>
<p>-2 -1  0  1  2
</p>
<p>t
</p>
<p>x x
</p>
<p>2- 1- 0 1 2 3
</p>
<p>1
</p>
<p>0
</p>
<p>Fig. 2.3 (Left) characteristic curves X(t;A) given by (2.42) in the xt plane and a 3D view of the
evolving multi-valued solution p(x, t) (2.43) (Right)</p>
<p/>
</div>
<div class="page"><p/>
<p>36 2 Transport Equations
</p>
<p>xs(t)
</p>
<p>x
210-1
</p>
<p>1
</p>
<p>0
p+(x, t)
</p>
<p>p
&minus;
(x, t)
</p>
<p>x
210-1
</p>
<p>1
</p>
<p>0
</p>
<p>Fig. 2.4 (Left) The multivalued solution (2.43) and insertion of a shock at x = xs(t), (Right)
reduction to a single-valued solution given by (2.46)
</p>
<p>There is a systematic and rigorous approach for correcting this unphysical behav-
</p>
<p>iour and modifying the solution to make it single-valued through the use of shocks.
</p>
<p>Shocks are moving jump discontinuities in the solution that separate one piecewise-
</p>
<p>defined portion of the solution ahead of the shock, p+(x, t), from another part behind
the shock, p&minus;(x, t), eliminating the multi-valued behaviour (see Fig. 2.4). Shock
waves are common in many physical systems, including acoustics (sonic booms),
</p>
<p>fluid flow (hydraulic jumps), and traffic flow (moving traffic jams).
</p>
<p>The construction of shock-corrected solutions builds on the idea that if a shock is
</p>
<p>inserted at one position, x = xs(t), it can appropriately separate the overlapping sets
of characteristic curves to produce a well-defined single-valued solution everywhere
</p>
<p>away from the shock. The constructed solution should satisfy all of the properties
</p>
<p>expected for the conservation law and we use this to derive the equation for the
</p>
<p>motion of the shock position.
</p>
<p>Consider a general quasilinear equation describing the transport of a property
</p>
<p>p(x, t) according to a flux function q = q(p),
</p>
<p>&part;p
</p>
<p>&part;t
+ &part;q(p)
</p>
<p>&part;x
= 0, (2.44)
</p>
<p>which has been derived for smooth solutions via theReynolds transport theorem from
</p>
<p>a conservation law for p. The integrated form of (2.44) on a fixed domain a &le; x &le; b
includes contributions from fluxes at the ends of the domain,
</p>
<p>d
</p>
<p>dt
</p>
<p>(
&int; b
</p>
<p>a
</p>
<p>p dx
</p>
<p>)
</p>
<p>+ q(p)
∣
∣
∣
∣
</p>
<p>x=b
</p>
<p>x=a
= 0. (2.45)
</p>
<p>If a shock were inserted at some position x = xs(t), the piecewise-defined form of
the solution becomes</p>
<p/>
</div>
<div class="page"><p/>
<p>2.6 Shocks in Quasilinear Equations 37
</p>
<p>p(x, t) =
{
</p>
<p>p&minus;(x, t) a &le; x &lt; xs(t),
p+(x, t) xs(t) &lt; x &le; b.
</p>
<p>(2.46)
</p>
<p>Separating (2.45) with respect to dependence on the solution to the left or right of
</p>
<p>the shock then yields
</p>
<p>[
d
</p>
<p>dt
</p>
<p>(&int; xs
</p>
<p>a
</p>
<p>p&minus; dx
</p>
<p>)
</p>
<p>&minus; q(p&minus;(a, t))
]
</p>
<p>+
[
</p>
<p>d
</p>
<p>dt
</p>
<p>(
&int; b
</p>
<p>xs
</p>
<p>p+ dx
</p>
<p>)
</p>
<p>+ q(p+(b, t))
]
</p>
<p>= 0.
</p>
<p>(2.47)
</p>
<p>Applying Leibniz&rsquo;s rule (2.8) then gives
</p>
<p>(&int; xs
</p>
<p>a
</p>
<p>&part;p&minus;
&part;t
</p>
<p>dx + p&minus;(xs, t)
dxs
</p>
<p>dt
</p>
<p>)
</p>
<p>+
(
&int; b
</p>
<p>xs
</p>
<p>&part;p+
&part;t
</p>
<p>dx &minus; p+(xs, t)
dxs
</p>
<p>dt
</p>
<p>)
</p>
<p>+ [q(p+(b, t))&minus; q(p&minus;(a, t))] = 0.
</p>
<p>By adding and subtracting q(p&plusmn;)(xs) and re-grouping terms, we obtain
</p>
<p>(&int; xs
</p>
<p>a
</p>
<p>&part;tp&minus; dx + q(p&minus;(xs, t))&minus; q(p&minus;(a, t))
)
</p>
<p>+
(
&int; b
</p>
<p>xs
</p>
<p>&part;tp+ dx + q(p+(b, t))&minus; q(p+(xs, t))
)
</p>
<p>&minus;q(p&minus;(xs, t))+ q(p+(xs, t))+ [p&minus;(xs, t)&minus; p+(xs, t)]
dxs
</p>
<p>dt
= 0.
</p>
<p>The terms in parentheses on the first two lines vanish based on applying (2.45) to the
</p>
<p>smooth solutions on the sub-intervals a &le; x &lt; xs and xs &lt; x &le; b respectively. The
remaining terms give the so-called Rankine&ndash;Hugoniot shock speed relation
</p>
<p>dxs
</p>
<p>dt
= q(p+(xs, t))&minus; q(p&minus;(xs, t))
</p>
<p>p+(xs, t)&minus; p&minus;(xs, t)
. (2.48)
</p>
<p>For the inviscid Burgers equation (2.39), the flux is q(p) = 1
2
</p>
<p>p2, and for our specific
</p>
<p>example, p&minus;(x, t) = (1 + x)/(1 + t) and p+(x, t) = 0 yielding the shock speed
equation,
</p>
<p>dxs
</p>
<p>dt
= p+(xs, t)&minus; p&minus;(xs, t)
</p>
<p>2
=&rArr; dxs
</p>
<p>dt
= 1+ xs
</p>
<p>2(1+ t) . (2.49)
</p>
<p>Initial conditions for this equation are determined by the time and position where
</p>
<p>characteristics first cross, necessitating the insertion of a shock; in this case,
</p>
<p>xs(1) = 1. Consequently the position of the shock is given by
</p>
<p>xs(t) =
&radic;
</p>
<p>2(1+ t)&minus; 1 for t &ge; 1.</p>
<p/>
</div>
<div class="page"><p/>
<p>38 2 Transport Equations
</p>
<p>Fig. 2.5 Characteristic
</p>
<p>curves in the xt truncated by
</p>
<p>the shock x = xs(t)
corresponding to (2.46)
</p>
<p>Figure2.5 shows the shock in the xt plane in its role in separating families of
</p>
<p>characteristics that would otherwise intersect. Excluding the shock curve, Fig. 2.5
</p>
<p>has a single characteristic curve passing through each (x, t) point and hence describes
</p>
<p>a single-valued solution of the transport problem. This figure differs from Fig. 2.4
</p>
<p>(left) only in the wedge-shaped region bounded by the curves x = 1 and x = t that
form the boundaries of what is sometimes called the shock envelope.
</p>
<p>Returning to Fig. 2.3, we note that our solution p(x, t) began as an equilateral
</p>
<p>triangle on &minus;1 &le; x &le; 1 with height one, and hence area one. As time increases the
profile steepens toward the right while maintaining its base and height, and hence
</p>
<p>area, even as it transitions from being an acute triangle (single-valued solution) to an
</p>
<p>obtuse triangle (multivalued solution) (also see Fig. 2.4 (left)). The consequence of
</p>
<p>introducing the shock is to cut out the portion of (2.43) that overturnswhilemodifying
</p>
<p>the domains on which the other parts of the solution apply for t &ge; 1,
</p>
<p>p(x, t) =
</p>
<p>⎧
</p>
<p>⎪
⎨
</p>
<p>⎪
⎩
</p>
<p>0 x &lt; &minus;1,
(1+ x)/(1+ t) &minus;1 &le; x &le; xs(t),
0 x &gt; xs(t).
</p>
<p>(2.50)
</p>
<p>The resulting solution profiles are right triangles on the base &minus;1 &le; x &le; xs(t)
and p ranging over 0 &le; p &le; max p = p&minus;(xs(t), t) =
</p>
<p>&radic;
2/(1+ t). To satisfy the
</p>
<p>conservation of the integral of p, (2.48) ensures that the shock maintains the area of
</p>
<p>A = 1
2
(base)(height)= 1
</p>
<p>2
(
&radic;
2(1+ t)&minus;1&minus;(&minus;1))(1/
</p>
<p>&radic;
2(1+ t)) = 1. This illustrates
</p>
<p>why the shock selection rule is sometimes called the equal-area rule.2 Later, we will
</p>
<p>see in Chap.5 that solution (2.50) can also be obtained as a similarity solution.
</p>
<p>2See Fig. 2.4&mdash;the placement of the shock not only conserves the area of the newly-formed right
</p>
<p>triangle, but also requires that the areas of the two cut-off multi-valued regions from the obtuse
</p>
<p>triangle to be equal.</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5">http://dx.doi.org/10.1007/978-3-319-23042-9_5</a></div>
</div>
<div class="page"><p/>
<p>2.7 Further Directions 39
</p>
<p>2.7 Further Directions
</p>
<p>The classic text on linear and nonlinear waves is the book by Whitham [106]. There
</p>
<p>are additional more recent books on waves [65, 80] and the method of characteristics
</p>
<p>and its extensions are covered in detail in most books on applied partial differential
</p>
<p>equations and modelling (see [45, 81], for example).
</p>
<p>2.8 Exercises
</p>
<p>2.1 Let x = a(t) and x = b(t) be positions of two points that move according to a
flow dx/dt = v(x, t), then if
</p>
<p>favg(t) =
1
</p>
<p>b(t)&minus; a(t)
</p>
<p>&int; b(t)
</p>
<p>a(t)
</p>
<p>f (x, t) dx,
</p>
<p>calculate lim
b&rarr;a
</p>
<p>dfavg
</p>
<p>dt
. Hint: Let b(t) = a(t)+ εh(t) with ε &rarr; 0.
</p>
<p>2.2 In one dimension, the Euler equations for compressible gas dynamics are
</p>
<p>&part;ρ
</p>
<p>&part;t
+ &part;
</p>
<p>&part;x
(ρv) = 0, ρ
</p>
<p>(
&part;v
</p>
<p>&part;t
+ v &part;v
</p>
<p>&part;x
</p>
<p>)
</p>
<p>= &minus;&part;P
&part;x
</p>
<p>,
</p>
<p>where the gradient of the pressure P(x, t) represents an internal force generated by
</p>
<p>the gas. Note that the left-hand side of the second equation can be written in terms
</p>
<p>of the convective derivative, ρDv/Dt. The first equation is the continuity equation
</p>
<p>for the conservation of mass. Show that the second equation is consistent with the
</p>
<p>conservation of momentum with non-constant density,
</p>
<p>&part;(ρv)
</p>
<p>&part;t
+ &part;(ρv
</p>
<p>2)
</p>
<p>&part;x
= &minus;&part;P
</p>
<p>&part;x
.
</p>
<p>2.3 Consider the solution of a linear wave equation having the dispersion relation
</p>
<p>ω = ω(k),
</p>
<p>ρ(x, t) = cos(kx &minus; ω(k)t)+ cos([k + ε]x &minus; ω(k + ε)t).
</p>
<p>(a) Show that for ε &rarr; 0 this can be re-written in terms of the phase velocity, cp,
and group velocity, cg, as
</p>
<p>ρ(x, t) = 2 cos(k[x &minus; cp(k)t]) cos
(
1
2
ε[x &minus; cg(k)t]
</p>
<p>)
</p>
<p>+ O(ε)
</p>
<p>What is the formula for the group velocity for ε &rarr; 0?</p>
<p/>
</div>
<div class="page"><p/>
<p>40 2 Transport Equations
</p>
<p>(b) Use ρ(x, t) = cos(kx&minus;ωt) to determine the dispersion relation for the equation
</p>
<p>ρt + ρx &minus; ρxxt = 0 (2.51)
</p>
<p>and calculate the group velocity. Also determine the &ldquo;modified dispersion rela-
</p>
<p>tion&rdquo; ω̃(k) from ρ(x, t) = ekx&minus;ω̃t , which will be used in the next exercise.
</p>
<p>2.4 Solitons (or &ldquo;solitary waves&rdquo;) are steady profile travelling waves describing a
</p>
<p>single &ldquo;pulse&rdquo; whose size and speed are connected through nonlinear effects. Con-
</p>
<p>sider the nonlinear wave equation,
</p>
<p>ρt + ρx + 6ρρx &minus; ρxxt = 0,
</p>
<p>called the Benjamin-Bona-Mahony equation.
</p>
<p>(a) By looking for solutions of the PDE in travelling wave form, ρ(x, t) = P(x&minus;ct),
determine the ODE for P(s) with s = x &minus; ct.
</p>
<p>(b) Show that there is a one-parameter family of solutions of the form
</p>
<p>P(s) = Asech2(Bs)
</p>
<p>and determine how A and B are related to the speed c.
</p>
<p>(c) Show that the nonlinear solitary wave surprisingly satisfies the modified disper-
</p>
<p>sion relation from the linearised equation (2.51).
</p>
<p>2.5 Dispersion relations are not limited to being algebraic relations. Consider the
</p>
<p>following fluid dynamicsmodel of water waves, given in terms of a potential function
</p>
<p>φ(x, y, t) (defined on 0 &le; y &le; 1) and a wave profile f (x, t) on the surface of the
water (at y = 0),
</p>
<p>φxx + φyy = 0 on 0 &le; y &le; 1,
φy = 0 at y = 0,
</p>
<p>φt + f = 0 at y = 1,
ft = φy at y = 1.
</p>
<p>Assume the wave is f (x, t) = A cos(kx &minus;ωt). Show that the corresponding potential
must be of the form φ(x, y, t) = B(y) sin(kx&minus;ωt) and obtain the dispersion relation
ω(k).
</p>
<p>2.6 Obtain explicit solutions ρ = ρ(x, t) for t &ge; 0 for the following problems,
(a) The initial value problem for ρ(x, t) on &minus;&infin; &lt; x &lt; &infin;:
</p>
<p>&part;ρ
</p>
<p>&part;t
+ e2t &part;ρ
</p>
<p>&part;x
= ρ + x + t, ρ(x, t = 0) = cos x.</p>
<p/>
</div>
<div class="page"><p/>
<p>2.8 Exercises 41
</p>
<p>(b) The signalling problem3 for ρ(x, t) on x &ge; 0:
</p>
<p>&part;ρ
</p>
<p>&part;t
+ (x + 4)&part;ρ
</p>
<p>&part;x
= &minus;2ρ, ρ(x = 0, t) = cos t, ρ(x, t = 0) = e&minus;x.
</p>
<p>2.7 A one-dimensional compressible fluid blob starts at t = 0 with uniform density
ρ &equiv; 1 on 1 &le; x &le; 2. The blob obeys the conservation of mass equation
</p>
<p>&part;ρ
</p>
<p>&part;t
+ &part;(ρv)
</p>
<p>&part;x
= 0.
</p>
<p>with the (Eulerian) velocity field given as v(x, t) = x2e&minus;3t .
(a) Find the density of the blob for t &ge; 0 as a function of position and time, ρ =
</p>
<p>ρ(x, t).
</p>
<p>(b) Find the positions of the moving left and right edges of the blob, x1(t) &le; x &le;
x2(t).
</p>
<p>(c) Use your results from parts (a, b) to directly evaluate the integral
</p>
<p>&int; x2(t)
</p>
<p>x1(t)
</p>
<p>ρ(x, t) dx
</p>
<p>and show that this is consistent with the Reynolds transport theorem.
</p>
<p>2.8 (The method of characteristics in two dimensions) At time t = 0, a radioactive
substance is released into a steady two-dimensional flow. The initial concentration
</p>
<p>of the substance is given by
</p>
<p>c0(x, y) =
{
</p>
<p>1&minus; (x2 + y2) x2 + y2 &le; 1,
0 else.
</p>
<p>In the absence of flow, the concentration would decay according to the rate equation
</p>
<p>dc/dt = &minus;c. The substance is carried by the two-dimensional Eulerian velocity field
v = (1+ x, y).
(a) The conservation law for the decaying substance on any fluid blob D(t) is
</p>
<p>d
</p>
<p>dt
</p>
<p>(&int;&int;
</p>
<p>D(t)
</p>
<p>c dA
</p>
<p>)
</p>
<p>= &minus;
&int;&int;
</p>
<p>D(t)
</p>
<p>c dA.
</p>
<p>Use the Reynolds transport theorem to derive the PDE for the concentration field
</p>
<p>c(x, y, t).
</p>
<p>(b) Instead of writing &ldquo;A = (x0, y0)&rdquo; as a material coordinate in rectangular coordi-
nates, parametrise the initial data in terms of polar material coordinates (R,
).
</p>
<p>3A wave being specified by a boundary condition from a fixed &ldquo;signal source&rdquo; position.</p>
<p/>
</div>
<div class="page"><p/>
<p>42 2 Transport Equations
</p>
<p>Write the characteristic ODEs (dX/dt, dY/dt, dC/dt) and solve these equations
</p>
<p>with the given initial conditions.
</p>
<p>(c) Obtain the explicit Eulerian solution c(x, y, t).
</p>
<p>(d) The boundary of the region over which the substance has spread remains circular
</p>
<p>for all times; find its radius and the coordinates of its centre as functions of time.
</p>
<p>2.9 Consider the system of wave equations
</p>
<p>pt + 5px &minus; 7qx = 0,
qt + 2px &minus; 4qx = 0.
</p>
<p>(a) Find the eigenvalues and eigenvectors for travelling waves in this system.
</p>
<p>(b) Find the solutions p(x, t) and q(x, t) if the initial conditions at t = 0 are
</p>
<p>p(x, 0) = 5 sin(7x), q(x, 0) = &minus;9 cos(4x).
</p>
<p>2.10 The classic wave equation is
</p>
<p>&part;2φ
</p>
<p>&part;t2
= c2 &part;
</p>
<p>2φ
</p>
<p>&part;x2
. (2.52)
</p>
<p>It can be used to describe small transverse vibrations of a displaced string (like a
</p>
<p>guitar or violin string) starting from initial conditions for the position and velocity
</p>
<p>of each point along the string at t = 0:
</p>
<p>φ(x, 0) = f (x), φt(x, 0) = g(x).
</p>
<p>(a) Show that this problem can be written as a system of first order wave equations:
</p>
<p>pt &minus; c2qx = 0, qt &minus; px = 0,
</p>
<p>where q = φx and p = φt .
(b) Solve the system to obtain p(x, t) and q(x, t) in terms of travelling waves.
</p>
<p>(c) Show that from (b) we can write the solution of the original problem as
</p>
<p>φ(x, t) = A(x &minus; ct)+ B(x + ct).
</p>
<p>(d) Determine the functions A(x) and B(x) in terms of the initial data, functions f (x)
</p>
<p>and g(x). This form of the solution is called the D&rsquo;Alembert solution.</p>
<p/>
</div>
<div class="page"><p/>
<p>2.8 Exercises 43
</p>
<p>2.11 The shallow water equations describe fluid flow in shallow (long, slender)
</p>
<p>layers, such as rivers. In simplest form, they are
</p>
<p>&part;h
</p>
<p>&part;t
+ h &part;v
</p>
<p>&part;x
+ v&part;h
</p>
<p>&part;x
= 0, &part;v
</p>
<p>&part;t
+ v &part;v
</p>
<p>&part;x
+ g&part;h
</p>
<p>&part;x
= 0,
</p>
<p>where v(x, t) is the fluid speed, h(x, t) is the height of the fluid layer, and g is the
</p>
<p>acceleration due to gravity.
</p>
<p>Show that the shallow water equations correspond to the following Lagrangian state-
</p>
<p>ments about conservation ofmass and changeofmomentum for all fluid blobsmoving
</p>
<p>with the flow:
</p>
<p>d
</p>
<p>dt
</p>
<p>(
&int; b(t)
</p>
<p>a(t)
</p>
<p>h dx
</p>
<p>)
</p>
<p>= 0, d
dt
</p>
<p>(
&int; b(t)
</p>
<p>a(t)
</p>
<p>hv dx
</p>
<p>)
</p>
<p>= &minus;G(h)
∣
∣
∣
∣
</p>
<p>x=b
</p>
<p>x=a
</p>
<p>Determine the function G(h).
</p>
<p>2.12 To completely specify the problem for the determination of the position of a
</p>
<p>shock in the Rankine&ndash;Hugoniot equation (2.48), we must provide initial conditions
</p>
<p>on when/where the shock first forms, xs(t&lowast;) = x&lowast;.
Consider the transport equation pt + q(p)x = 0 with initial condition p(x, 0) =
</p>
<p>f (x). Assume that q&prime;(p) &gt; 0 and f (x) has a local maximum (for example, f (x) =
e&minus;x
</p>
<p>2
).
</p>
<p>(a) Consider two characteristic curves, x = X(t;A0) and x = X(t;A1), and assume
that they carry different values of the solution (P0 �= P1). Determine the position,
x0,1, and time, t0,1, where they will intersect.
</p>
<p>(b) Determine the time when the shock first forms, t&lowast; in terms of q, f , by minimising
the (positive) intersection time over all pairs of characteristics. Hint: Consider
</p>
<p>the limit of two characteristics starting very close together.
</p>
<p>2.13 (Shocks in quasilinear equations) Consider the inviscid Burgers equation,
</p>
<p>&part;p
</p>
<p>&part;t
+ p&part;p
</p>
<p>&part;x
= 0,
</p>
<p>starting from the initial conditions
</p>
<p>p(x, t = 0) =
{
</p>
<p>9&minus; x2 |x| &le; 3,
0 |x| &gt; 3.
</p>
<p>(a) Use the method of characteristics to construct the parametric solution.
</p>
<p>(b) Eliminate the parameter from the solution found in part (a) to obtain a multi-
</p>
<p>valued solution in two parts.
</p>
<p>(c) Determine the time t&lowast; and x&lowast;-position where x(t) characteristic curves first inter-
sect (see Exercise 2.12).</p>
<p/>
</div>
<div class="page"><p/>
<p>44 2 Transport Equations
</p>
<p>(d) Use the results from parts (b, c) along with the shock speed equation (2.48) to
</p>
<p>write the ODE initial value problem for the shock position xs(t).
</p>
<p>(e) Write the inviscid Burgers equation as a conservation law, state the conserved
</p>
<p>quantity (with the specific value set by the above initial condition), and integrate
</p>
<p>using the solution from (b) to produce an algebraic equation involving t and xs(t).
</p>
<p>2.14 Consider the (viscous) Burgers equation
</p>
<p>&part;p
</p>
<p>&part;t
+ p&part;p
</p>
<p>&part;x
= ε2 &part;
</p>
<p>2p
</p>
<p>&part;x2
ε &rarr; 0
</p>
<p>subject to boundary conditions
</p>
<p>p(x &rarr; &minus;&infin;) = 2, p(x &rarr; &infin;) = 1.
</p>
<p>Determine the first order ODE satisfied by travelling wave solutions, p(x, t) = P(x&minus;
ct). Solve the ODE and apply the boundary conditions to determine travelling wave
</p>
<p>profile P(s) and the wave speed c. Show that this matches the shock speed that would
</p>
<p>be obtained with ε = 0, for (2.39).
</p>
<p>2.15 (Fully-nonlinear first order PDEs) Themost general first-order PDE involving
</p>
<p>only first derivatives of a solution p(x, t) can be written as
</p>
<p>F(p, px, pt, x, t) = 0,
</p>
<p>where F is a given function. Let s be a parametric variable and parametrise all
</p>
<p>quantities in terms of s as
</p>
<p>x = X(s) t = T(s) p = P(s) px = R(s) pt = Q(s)
</p>
<p>(a) Starting from P(s) = p(X(s),T(s)) take the derivative of P with respect to s and
use the chain rule to express dP/ds in terms of R,Q,X &prime;,T &prime;.
</p>
<p>(b) Take the s-derivative of F = 0 using the chain rule and then use the result from
part (a) to write the equation in the form
</p>
<p>dF
</p>
<p>ds
=
</p>
<p>[
</p>
<p>A
dR
</p>
<p>ds
+ B dX
</p>
<p>ds
</p>
<p>]
</p>
<p>︸ ︷︷ ︸
</p>
<p>=0
</p>
<p>+
[
</p>
<p>C
dQ
</p>
<p>ds
+ D dT
</p>
<p>ds
</p>
<p>]
</p>
<p>︸ ︷︷ ︸
</p>
<p>=0
</p>
<p>= 0.
</p>
<p>Note that selecting X &prime; = A,R&prime; = &minus;B,T &prime; = C,Q&prime; = &minus;D satisfies the overall
equation.
</p>
<p>Obtain a system of five autonomous ODEs for X,T ,P,R,Q in terms of those
</p>
<p>variables and derivatives of F.</p>
<p/>
</div>
<div class="page"><p/>
<p>2.8 Exercises 45
</p>
<p>(c) Determine the characteristic equations for the general Hamilton&ndash;Jacobi PDE,
</p>
<p>pt + H(p, px, x, t) = 0,
</p>
<p>where H is a given function.
</p>
<p>(d) Obtain the parametric solution, X(A, t),P(A, t) for the problem for p(x, t) on
</p>
<p>&minus;&infin; &lt; x &lt; &infin; and t &ge; 0,
</p>
<p>&part;p
</p>
<p>&part;t
+
</p>
<p>(
&part;p
</p>
<p>&part;x
</p>
<p>)4
</p>
<p>= 0, p(x, 0) = e&minus;x2 .</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 3
</p>
<p>Variational Principles
</p>
<p>In many problems, we need to find an optimal solution, one that maximises a benefit
</p>
<p>or minimises a cost for example. Various branches of science include formulations
</p>
<p>based on such principles:
</p>
<p>&bull; Fermat&rsquo;s principle of least time in optics
&bull; Hamilton&rsquo;s principle of least action in mechanics
&bull; &ldquo;paths of least resistance&rdquo; in electrostatics, hydrology, and other areas.
The criteria selecting an &ldquo;optimal&rdquo; solution in a physical system may not always be
</p>
<p>clear (especially in biological problems). However, if we are given a quantity to be
</p>
<p>minimised or maximised, the calculus of variations provides a natural methodology
</p>
<p>for reformulating the question in terms of a differential equation problem.
</p>
<p>In this chapter we focus on problems that require the determination of a function,
</p>
<p>say y&lowast;(x), as the optimal solution to a given system. A classical example known as
the brachistochrone problem (meaning &ldquo;shortest time&rdquo; in Greek) is motivated by the
</p>
<p>question: What shape should a ramp take in order to deliver a mass (moving under
</p>
<p>the influence of gravity) to a specified final position in the least time?; Fig. 3.1 shows
</p>
<p>schematics of some possible trial solutions.
</p>
<p>Our approach will extend elementary methods from calculus for finding local
</p>
<p>optimal points to problems where solution functions, y&lowast;(x), are optimal relative to
all small possible variations of that function.
</p>
<p>3.1 Review and Generalisation from Calculus
</p>
<p>Since our presentation will build on the basic formulations for finding maxima and
</p>
<p>minima from single- and multi-variable calculus, we briefly review that background
</p>
<p>as a means of introducing the terminology that we will employ.
</p>
<p>Consider the problem of finding local extrema of a smooth function y = f (x),
called the objective function. If f has a local maximum at x = x&lowast; with value y&lowast; = f (x&lowast;)
then y&lowast; must be greater or equal to all values of f achieved in a small neighbourhood
</p>
<p>&copy; Springer International Publishing Switzerland 2015
</p>
<p>T. Witelski and M. Bowen, Methods of Mathematical Modelling,
</p>
<p>Springer Undergraduate Mathematics Series, DOI 10.1007/978-3-319-23042-9_3
</p>
<p>47</p>
<p/>
</div>
<div class="page"><p/>
<p>48 3 Variational Principles
</p>
<p>g
</p>
<p>Fig. 3.1 Three trial solutions for the brachistochrone problem for the shape of a ramp to move a
</p>
<p>mass down from (0, 1) to (1, 0) under the influence of gravity as quickly as possible, ỹ = (1 &minus; x)β
for β = 1, 2, 1/2
</p>
<p>around x&lowast;,
f (x&lowast;) &ge; f (x&lowast; + ε) for all |ε| &rarr; 0. (3.1)
</p>
<p>Taking a Taylor series expansion of f at x&lowast; yields
</p>
<p>f (x&lowast; + ε) = f (x&lowast;)+ f &prime;(x&lowast;)ε + 12 f
&prime;&prime;(x&lowast;)ε
</p>
<p>2 + &middot; &middot; &middot; as ε &rarr; 0. (3.2)
</p>
<p>If the slope f &prime;(x&lowast;)were nonzero, then for |ε| &gt; 0 either f (x&lowast; + ε) or f (x&lowast; &minus; ε)would
have a value greater than f (x&lowast;), violating our assumption that f (x&lowast;) is a maximum.
Consequently, we must have f &prime;(x&lowast;) = 0 at a maximum. An analogous argument
applies for local minima of y = f (x), and so local extrema for smooth functions can
only arise at critical points, where
</p>
<p>f &prime;(x&lowast;) = 0.
</p>
<p>Having eliminated the linear term from the Taylor series, the higher order terms in
</p>
<p>(3.2) must also respect the requirement (3.1). This leads to the standard condition on
</p>
<p>the second derivative for a local maximum (f &prime;&prime;(x&lowast;) &lt; 0) (or minimum (f &prime;&prime;(x&lowast;) &gt; 0)).
If f &prime;&prime;(x&lowast;) = 0 at a critical point, then the next nonzero higher order terms need to be
considered in order to determine if the critical point indeed yields a maximum or a
</p>
<p>minimum of f , or is neither (an inflection point).
</p>
<p>Similarly, for a two-variable objective function, having a local maximum of f at
</p>
<p>(x&lowast;, y&lowast;) with value z&lowast; = f (x&lowast;, y&lowast;) implies that all nearby points satisfy
</p>
<p>f (x&lowast;, y&lowast;) &ge; f (x&lowast; + ε1, y&lowast; + ε2) for all |ε1|, |ε2| &rarr; 0.
</p>
<p>The corresponding multi-variable Taylor series for ε1, ε2 &rarr; 0 yields
</p>
<p>f (x&lowast; + ε1, y&lowast; + ε2) = f (x&lowast;, y&lowast;)+ &part;xf (x&lowast;, y&lowast;)ε1 + &part;yf (x&lowast;, y&lowast;)ε2
︸ ︷︷ ︸
</p>
<p>[first derivative terms]
</p>
<p>+ &middot; &middot; &middot; .</p>
<p/>
</div>
<div class="page"><p/>
<p>3.1 Review and Generalisation from Calculus 49
</p>
<p>As in the single variable case, the linear terms must vanish at a local maximum or
</p>
<p>minimum, and since this must hold for all choices of ε1 and ε2, we arrive at the
</p>
<p>generalisation of the previous critical point condition,
</p>
<p>&part;xf&lowast; = 0, &part;yf&lowast; = 0. (3.3)
</p>
<p>Namely, the first partial derivatives of the objective function with respect to all of
</p>
<p>its independent variables must vanish, which can be more compactly expressed in
</p>
<p>terms of the gradient
</p>
<p>&nabla;f&lowast; = 0. (3.4)
</p>
<p>This definition of critical points in terms of the gradient applies to functions of any
</p>
<p>number of independent variables. Being a critical point is a necessary condition
</p>
<p>for a local extrema, but it is not sufficient. Conditions on the second derivatives
</p>
<p>(represented by the Hessian matrix for functions of two or more variables) also
</p>
<p>extend to arbitrary numbers of variables for determining whether a critical point
</p>
<p>yields a maximum, minimum or inflection point of the objective function [24, 68].
</p>
<p>Whether we are seeking a maximum or a minimum, all local extrema are determined
</p>
<p>by the critical point conditions and hence we focus on obtaining critical points of the
</p>
<p>more challenging class of problems that we will consider.
</p>
<p>3.1.1 Functionals
</p>
<p>In general, a functional is a mathematical expression that can be evaluated to give
</p>
<p>a scalar value corresponding to each function to which it is applied. Two simple
</p>
<p>examples are provided by the integrals that correspond to the area under a curve and
</p>
<p>the arclength of a curve,
</p>
<p>A(y) =
&int; 1
</p>
<p>0
</p>
<p>y(x) dx, S(y) =
&int; 1
</p>
<p>0
</p>
<p>&radic;
</p>
<p>1 + y&prime;(x)2 dx,
</p>
<p>for any given function y(x) on 0 &le; x &le; 1.
For the most part, we will only consider functionals that are definite integrals of
</p>
<p>a function and its derivatives,
</p>
<p>J(y) =
&int; b
</p>
<p>a
</p>
<p>L(x, y(x), y&prime;(x), y&prime;&prime;(x), . . .) dx. (3.5)
</p>
<p>Here the integrand function L(x, y, . . .) is called the Lagrangian (named after Joseph
</p>
<p>Lagrange (1736&ndash;1813) who reformulated classical mechanics based on a variational
</p>
<p>principle&mdash;see Sect. 3.3).
</p>
<p>For the above geometric examples of area and arclength, the dependence of the
</p>
<p>functional on the solution is straightforward, while for the brachistochrone problem</p>
<p/>
</div>
<div class="page"><p/>
<p>50 3 Variational Principles
</p>
<p>from Fig. 3.1, the connection is a little less direct. The time of travel to be minimised
</p>
<p>can be expressed as
</p>
<p>T(y) =
&int; T
</p>
<p>0
</p>
<p>dt =
&int;
</p>
<p>ds
</p>
<p>v
=
</p>
<p>&int; 1
</p>
<p>0
</p>
<p>&radic;
</p>
<p>1 + (y&prime;)2
v(y)
</p>
<p>dx, (3.6)
</p>
<p>where we have used the relationship between the speed and distance travelled,
</p>
<p>v = ds/dt, and a further relationship is also needed between the speed and posi-
tion (see Exercise 3.8).
</p>
<p>Now consider the minimisation of an objective functional; by analogy with the
</p>
<p>previous analysis, we see that for J(y) to have a local minimum1 for a particular
</p>
<p>function y&lowast;(x) the functional must satisfy
</p>
<p>J(y&lowast;(x)) &le; J(y&lowast;(x)+ εh(x)),
</p>
<p>for all ε &rarr; 0 and for all admissible &ldquo;perturbation functions&rdquo; h(x) of y&lowast;(x). For the
moment, h(x) is unspecified and serves to describe a neighbourhood of the optimal
</p>
<p>solution y&lowast;(x) within the space of smooth functions. While there are many technical
issues underlying these concepts that are deserving of careful analysis, we defer
</p>
<p>detailed considerations to more advanced texts [71, 99].
</p>
<p>We will describe a straightforward procedure (as an extension of the process of
</p>
<p>finding critical points of an objective function) for determining optimal solutions of
</p>
<p>a functional. In particular, we will have to explain what it means to take a derivative
</p>
<p>of a functional with respect to a function, and we will distinguish these from standard
</p>
<p>derivatives by using the terminology variational derivatives.
</p>
<p>3.2 General Approach and Basic Examples
</p>
<p>Given an objective functional, there is a systematic four-step approach which can be
</p>
<p>used to obtain smooth solutions that correspond to local extrema of the functional:
</p>
<p>(i) Assume the existence of an optimal solution y&lowast;(x) and perform an expansion
of the functional in the neighbourhood of y&lowast;(x) using
</p>
<p>ỹ = y&lowast;(x)+ εh(x) J̃ = J(ỹ), (3.7)
</p>
<p>where the perturbation function h(x) is independent of ε. Formally expanding
</p>
<p>J̃ as ε &rarr; 0 like a Taylor series yields
</p>
<p>J̃ = J(y&lowast; + εh) = J(y&lowast;)+
&ldquo;
</p>
<p>(
</p>
<p>dJ
</p>
<p>dy
</p>
<p>∣
∣
∣
∣
y&lowast;
</p>
<p>)
</p>
<p>(εh)
&rdquo;
+ O(ε2), (3.8)
</p>
<p>1The behaviour at a local maximum of J(y) follows similarly.</p>
<p/>
</div>
<div class="page"><p/>
<p>3.2 General Approach and Basic Examples 51
</p>
<p>where we still have to precisely define the notion of a variational derivative (in
</p>
<p>this case the evaluation of the derivative of an integral with respect to a function).
</p>
<p>The O(ε) term2 in the Taylor series of J will be called the first variation, the
</p>
<p>O(ε2) term the second variation and so on.
</p>
<p>(ii) Apply the critical point condition: the first variation of the functional must be
</p>
<p>zero at the solution y&lowast;(x) for all admissible perturbations h(x),
</p>
<p>&ldquo;
(
</p>
<p>dJ
</p>
<p>dy
</p>
<p>∣
∣
∣
∣
y&lowast;
</p>
<p>)
</p>
<p>(εh)
&rdquo;
= 0 (3.9)
</p>
<p>We will explain the meaning of &lsquo;admissible&rsquo; solutions and perturbations below.
</p>
<p>(iii) Assuming the solution to be smooth, convert the critical point condition on the
</p>
<p>functional into a differential equation for the optimal3 solution y&lowast;(x).
(iv) Solve the differential equation problem.
</p>
<p>The details of this approach will be discussed and expanded out in following exam-
</p>
<p>ples. This framework applies to many more complicated problems. However, an
</p>
<p>important disclaimer is that not every problem can be simplified to a differential
</p>
<p>equation using this framework, those that can be are called variational problems. A
</p>
<p>number of difficulties can arise to make a problem non-variational, such as the func-
</p>
<p>tional not having critical points, or it not being possible to reduce the first variation
</p>
<p>to a differential equation.
</p>
<p>3.2.1 The Simple Shortest Curve Problem
</p>
<p>We begin by considering the simple problem of finding the function y = y(x) that
gives the shortest path from the origin (0, 0) to the given fixed point (1, b), b &isin; R, see
Fig. 3.2. While we know the answer to be the straight line connecting the two points,
</p>
<p>it will be instructive to see how the calculus of variations framework constructs this
</p>
<p>result.
</p>
<p>The shortest path is the one that minimises the total arclength and hence our
</p>
<p>objective functional is
</p>
<p>J(y) =
&int; 1
</p>
<p>0
</p>
<p>&radic;
</p>
<p>1 + (y&prime;)2 dx. (3.10a)
</p>
<p>2The O(εn) order symbol will be defined precisely in Chap. 6, but for the current context we use
</p>
<p>this to refer to the ε &rarr; 0 limit of the remainder of the terms in the series with coefficients εN for
N &ge; n.
3Showing that a solution given by a critical point is a local maximum or minimum involves evaluating
</p>
<p>the second variation at y&lowast;(x).</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6">http://dx.doi.org/10.1007/978-3-319-23042-9_6</a></div>
</div>
<div class="page"><p/>
<p>52 3 Variational Principles
</p>
<p>Fig. 3.2 An admissible trial
</p>
<p>solution ỹ(x) for problem
</p>
<p>(3.10a, 3.10b) and its
</p>
<p>perturbation from the
</p>
<p>optimal solution y&lowast;(x)
</p>
<p>(x)
ỹ(x)
</p>
<p>10
</p>
<p>y
</p>
<p>x
</p>
<p>b
</p>
<p>The statement of the problem identifies boundary conditions that all solutions must
</p>
<p>satisfy,
</p>
<p>y(0) = 0, y(1) = b. (3.10b)
</p>
<p>Analysis of the problem begins by identifying the properties of the family of per-
</p>
<p>turbations h(x) to the optimal solution y&lowast;(x) that define all admissible trial solutions
(3.7), ỹ(x) = y&lowast;(x)+ εh(x). Applying boundary conditions (3.10b) to the admissible
solution ỹ yields that
</p>
<p>ỹ(0) = y&lowast;(0)+ εh(0) = 0, ỹ(1) = y&lowast;(1)+ εh(1) = b.
</p>
<p>Since the boundary conditions on the optimal solution are necessarily the same as
</p>
<p>those on the trial solutions (y&lowast;(0) = 0 and y&lowast;(1) = b), we obtain that the perturbation
functions must satisfy
</p>
<p>h(0) = 0, h(1) = 0. (3.11)
</p>
<p>Next, we substitute (3.7) into (3.10a) giving
</p>
<p>J̃ =
&int; 1
</p>
<p>0
</p>
<p>&radic;
</p>
<p>1 +
(
</p>
<p>y&prime;&lowast; + εh&prime;
)2
</p>
<p>dx =
&int; 1
</p>
<p>0
</p>
<p>&radic;
</p>
<p>1 + (y&prime;&lowast;)2 + 2εh&prime;y&prime;&lowast; + ε2(h&prime;)2 dx.
</p>
<p>For investigating the limit ε &rarr; 0, it is convenient to factor the integrand as
</p>
<p>=
&int; 1
</p>
<p>0
</p>
<p>&radic;
(
</p>
<p>1 + (y&prime;&lowast;)2
)
</p>
<p>(
</p>
<p>1 + 2εh
&prime;y&prime;&lowast;
</p>
<p>1 + (y&prime;&lowast;)2
+ ε
</p>
<p>2(h&prime;)2
</p>
<p>1 + (y&prime;&lowast;)2
)
</p>
<p>dx</p>
<p/>
</div>
<div class="page"><p/>
<p>3.2 General Approach and Basic Examples 53
</p>
<p>and then using the Taylor series expansion
&radic;
</p>
<p>1 + z = 1 + 1
2
</p>
<p>z + O(z2) as z &rarr; 0
applied to the second factor allows us to write
</p>
<p>J̃ =
(&int; 1
</p>
<p>0
</p>
<p>&radic;
</p>
<p>1 + (y&prime;&lowast;)2 dx
)
</p>
<p>+ ε
(
</p>
<p>&int; 1
</p>
<p>0
</p>
<p>h&prime;y&prime;&lowast;
&radic;
</p>
<p>1 + (y&prime;&lowast;)2
dx
</p>
<p>)
</p>
<p>+ O(ε2). (3.12)
</p>
<p>The first term in this expansion gives the expression for the functional at the optimal
</p>
<p>solution, J&lowast; = J(y&lowast;), but since y&lowast; is unknown, in order to evaluate this integral, we
must examine further terms. The O(ε) term provides the first variation (3.8) that will
</p>
<p>determine the critical points.
</p>
<p>It is important to note that the form of the first variation in (3.8) was chosen to
</p>
<p>intentionally suggest that the perturbation function h(x) should appear linearly and
</p>
<p>undifferentiated. We will always seek to put the first variation term into this form.
</p>
<p>For (3.12), getting to this form can be accomplished by performing integration
</p>
<p>by parts to shift the derivative off of the h&prime; factor,
</p>
<p>&int; 1
</p>
<p>0
</p>
<p>h&prime;y&prime;&lowast;
&radic;
</p>
<p>1 + (y&prime;&lowast;)2
dx = y
</p>
<p>&prime;
&lowast;h
</p>
<p>&radic;
</p>
<p>1 + (y&prime;&lowast;)2
</p>
<p>∣
∣
∣
∣
</p>
<p>x=1
</p>
<p>x=0
&minus;
</p>
<p>&int; 1
</p>
<p>0
</p>
<p>d
</p>
<p>dx
</p>
<p>(
</p>
<p>y&prime;&lowast;
&radic;
</p>
<p>1 + (y&prime;&lowast;)2
</p>
<p>)
</p>
<p>h dx;
</p>
<p>integration by parts will be a fundamental calculational tool in most of our problems.
</p>
<p>The boundary conditions on h given by (3.11) eliminate the contributions from the
</p>
<p>boundary terms, and leave the final form of the first variation of the functional as a
</p>
<p>single integral
</p>
<p>δJ
</p>
<p>δy
</p>
<p>∣
∣
∣
∣
y&lowast;
</p>
<p>h = &minus;
&int; 1
</p>
<p>0
</p>
<p>d
</p>
<p>dx
</p>
<p>(
</p>
<p>y&prime;&lowast;
&radic;
</p>
<p>1 + (y&prime;&lowast;)2
</p>
<p>)
</p>
<p>h dx, (3.13)
</p>
<p>where we use the δ-notation to indicate that this is a variational (functional) derivative
</p>
<p>(also sometimes called a Frechet derivative).
</p>
<p>The next step is to enforce the critical point condition (3.9) on (3.13) for all
</p>
<p>admissible perturbations. At this point, we need a basic, but important result from
</p>
<p>analysis called the Fundamental Lemma of the Calculus of Variations which states
</p>
<p>that
</p>
<p>If
</p>
<p>&int; b
</p>
<p>a
</p>
<p>g(x)h(x) dx = 0 &forall;h(x) then g(x) &equiv; 0 on a &le; x &le; b. (3.14)</p>
<p/>
</div>
<div class="page"><p/>
<p>54 3 Variational Principles
</p>
<p>In other words, if the integral of a product of functions is zero for all choices of one
</p>
<p>of the factors, then this is only possible if the other factor is identically zero on the
</p>
<p>whole interval of integration.4,5
</p>
<p>Applying the fundamental lemma to the critical point condition for (3.13),
</p>
<p>&minus;
&int; 1
</p>
<p>0
</p>
<p>d
</p>
<p>dx
</p>
<p>(
</p>
<p>y&prime;&lowast;
&radic;
</p>
<p>1 + (y&prime;&lowast;)2
</p>
<p>)
</p>
<p>h dx = 0, (3.15)
</p>
<p>for all possible h, we obtain the differential equation for y&lowast;(x)
</p>
<p>&minus; d
dx
</p>
<p>(
</p>
<p>y&prime;&lowast;
&radic;
</p>
<p>1 + (y&prime;&lowast;)2
</p>
<p>)
</p>
<p>= 0. (3.16)
</p>
<p>We have consequently replaced an integral condition (the weak form, that applies
</p>
<p>over the whole domain) with an equivalent differential equation (the strong form) that
</p>
<p>applies pointwise on smooth solutions. Together with boundary conditions (3.10b),
</p>
<p>(3.16) provides us with a complete ODE boundary value problem defining the optimal
</p>
<p>solution y&lowast;(x).
In this problem it is straightforward to integrate the ODE once yielding a constant
</p>
<p>of integration C1, then following some algebra,
</p>
<p>y&prime;&lowast;
&radic;
</p>
<p>1 + (y&prime;&lowast;)2
= C1 &rArr; (y&prime;&lowast;)2 =
</p>
<p>C21
</p>
<p>1 &minus; C21
= C2&lowast; &ge; 0, (3.17)
</p>
<p>for some constant C&lowast;. Then using the boundary conditions (3.10b) yields y&lowast;(x) = bx,
confirming that the shortest path is a straight line.
</p>
<p>A second derivative test can be applied to verify that this solution is a local
</p>
<p>minimum of (3.10) (see Exercise 3.2), but here we can use an understanding of the
</p>
<p>structure of the problem to show that it is indeed the solution we seek.6 In many
</p>
<p>cases, problem-specific intuition can be used to distinguish whether critical point
</p>
<p>solutions minimise or maximise the functional.
</p>
<p>A more general version of this problem, allowing for solutions as parametric
</p>
<p>curves in the plane is given in Exercise 3.3.
</p>
<p>4In this simplified statement of this result, we are assuming that g(x) is smooth and hence has no
</p>
<p>discontinuities.
5The du Bois Reymond lemma (2.11) is closely related to this lemma, choosing h(x) = 1 on
arbitrary sub-intervals, and otherwise h = 0.
6For the area and arclength examples, the functionals become unbounded for large amplitude
</p>
<p>solutions and hence there are no local maxima.</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2">http://dx.doi.org/10.1007/978-3-319-23042-9_2</a></div>
</div>
<div class="page"><p/>
<p>3.2 General Approach and Basic Examples 55
</p>
<p>3.2.2 The Classic Euler&ndash;Lagrange Problem
</p>
<p>Consider an objective functional defined in terms of an integral on the interval a &le;
x &le; b with an integrand that is a function of the independent variable x, the solution
y(x) and its first derivative y&prime;(x)
</p>
<p>J(y) =
&int; b
</p>
<p>a
</p>
<p>L(x, y, y&prime;) dx, (3.18a)
</p>
<p>subject to prescribed boundary conditions on y given by
</p>
<p>y(a) = c, y(b) = d. (3.18b)
</p>
<p>Parallelling the previous example, we find that admissible perturbation functions
</p>
<p>must satisfy the homogeneous boundary conditions
</p>
<p>h(a) = 0, h(b) = 0. (3.19)
</p>
<p>The expanded form of J(y&lowast; + εh) is given by
</p>
<p>J̃ =
&int; b
</p>
<p>a
</p>
<p>L(x, y&lowast; + εh, y&prime;&lowast; + εh&prime;) dx
</p>
<p>and by applying the multi-variable Taylor series, this can be written for ε &rarr; 0 as
</p>
<p>J̃ =
&int; b
</p>
<p>a
</p>
<p>[
</p>
<p>L(x, y&lowast;, y
&prime;
&lowast;)+ ε
</p>
<p>(
&part;L
</p>
<p>&part;y
h + &part;L
</p>
<p>&part;y&prime;
h&prime;
</p>
<p>) ∣
∣
∣
∣
y=y&lowast;
</p>
<p>+ O(ε2)
]
</p>
<p>dx
</p>
<p>= J&lowast; + ε
(
</p>
<p>&int; b
</p>
<p>a
</p>
<p>&part;L
</p>
<p>&part;y
h dx +
</p>
<p>&int; b
</p>
<p>a
</p>
<p>&part;L
</p>
<p>&part;y&prime;
h&prime; dx
</p>
<p>)
</p>
<p>+ O(ε2).
</p>
<p>In order to address the h&prime; derivative factor in the third term, we apply integration by
parts to obtain
</p>
<p>&int; b
</p>
<p>a
</p>
<p>&part;L
</p>
<p>&part;y&prime;
h&prime; dx = &part;L
</p>
<p>&part;y&prime;
h
</p>
<p>∣
∣
∣
∣
</p>
<p>x=b
</p>
<p>x=a
&minus;
</p>
<p>&int; b
</p>
<p>a
</p>
<p>d
</p>
<p>dx
</p>
<p>(
&part;L
</p>
<p>&part;y&prime;
</p>
<p>)
</p>
<p>h dx.
</p>
<p>Imposing the boundary conditions (3.19) on the perturbation function, we can then
</p>
<p>re-group the first variation as
</p>
<p>J̃ = J&lowast; + ε
&int; b
</p>
<p>a
</p>
<p>[
&part;L
</p>
<p>&part;y
&minus; d
</p>
<p>dx
</p>
<p>(
&part;L
</p>
<p>&part;y&prime;
</p>
<p>)]
</p>
<p>h dx + O(ε2). (3.20)</p>
<p/>
</div>
<div class="page"><p/>
<p>56 3 Variational Principles
</p>
<p>This was an important and necessary step because in order to apply the fundamental
</p>
<p>lemma (3.14) to the critical point condition, we must have the first variation expressed
</p>
<p>as a single integral having the perturbation h(x) as a factor,
</p>
<p>&int; b
</p>
<p>a
</p>
<p>[
&part;L
</p>
<p>&part;y
&minus; d
</p>
<p>dx
</p>
<p>(
&part;L
</p>
<p>&part;y&prime;
</p>
<p>)]
</p>
<p>h dx = 0.
</p>
<p>Since this holds for all admissible choices of h(x), by (3.14) we obtain the differential
</p>
<p>equation on a &le; x &le; b,
&part;L
</p>
<p>&part;y
&minus; d
</p>
<p>dx
</p>
<p>(
&part;L
</p>
<p>&part;y&prime;
</p>
<p>)
</p>
<p>= 0 (3.21)
</p>
<p>Subject to the boundary conditions (3.18b), (3.21) defines a differential equation
</p>
<p>problem that should have a unique solution for y = y&lowast;(x).
Equation (3.21) is known as the Euler&ndash;Lagrange equation for the functional
</p>
<p>(3.18a). In Sect. 3.3, we will see that this particular form is used extensively in
</p>
<p>problems for mechanical systems.
</p>
<p>A very useful consequence of the general form of L in (3.18a) is that the Euler&ndash;
</p>
<p>Lagrange differential equation for any functional with L = L(x, y, y&prime;) is given by
substituting the specific L into (3.21). For example, the ODE (3.16) for the shortest
</p>
<p>distance problem (3.10a) is produced by (3.21) with L =
&radic;
</p>
<p>1 + (y&prime;)2. Similarly, if
our Lagrangian were L(x, y, y&prime;) = f (x)y + g(x)y&prime; + (y&prime;)2, then
</p>
<p>&part;L
</p>
<p>&part;y
= f (x), &part;L
</p>
<p>&part;y&prime;
= g(x)+ 2y&prime;, d
</p>
<p>dx
</p>
<p>(
&part;L
</p>
<p>&part;y&prime;
</p>
<p>)
</p>
<p>= g&prime;(x)+ 2y&prime;&prime;
</p>
<p>and (3.21) gives the Euler&ndash;Lagrange equation for y&lowast;(x) as
</p>
<p>f (x)&minus; g&prime;(x)&minus; 2d
2y
</p>
<p>dx2
= 0.
</p>
<p>3.3 The Variational Formation of Classical Mechanics
</p>
<p>One of the most wide-spread applications of the calculus of variations is in deriv-
</p>
<p>ing the equations of motion for mechanical systems from the critical points of a
</p>
<p>functional. The theory is based on a restatement of the previous Euler&ndash;Lagrange
</p>
<p>results&mdash;we relabel the variables to describe the motion of a mass:</p>
<p/>
</div>
<div class="page"><p/>
<p>3.3 The Variational Formation of Classical Mechanics 57
</p>
<p>x &rarr; t : independent variable (time)
y(x) &rarr; y(t) : solution (position)
</p>
<p>y&prime;(x) &rarr; y&prime;(t) : derivative (velocity)
L(x, y, y&prime;) &rarr; L(t, y, y&prime;) : still called the Lagrangian
</p>
<p>J =
&int;
</p>
<p>L dx &rarr; I =
&int;
</p>
<p>L dt : functional (action)
</p>
<p>The Euler&ndash;Lagrange equation (3.21) now takes the form
</p>
<p>&part;L
</p>
<p>&part;y
&minus; d
</p>
<p>dt
</p>
<p>(
&part;L
</p>
<p>&part;y&prime;
</p>
<p>)
</p>
<p>= 0, (3.22)
</p>
<p>and the key step in the application to mechanics is in identifying the Lagrangian
</p>
<p>function L as the difference between the kinetic energy T and potential energy V
</p>
<p>L = T &minus; V . (3.23)
</p>
<p>William Hamilton (1805&ndash;1865) used this form of Lagrangian based on the assump-
</p>
<p>tion that mechanical systems should satisfy what come to be called Hamilton&rsquo;s prin-
</p>
<p>ciple of least action, namely that the optimal (actual, observable) solution y&lowast;(t) will
be the one that minimises the action integral, I .
</p>
<p>A very simple example of a mechanical system is the vertical motion of a rigid
</p>
<p>object with mass m subject to gravity g. The kinetic energy of the point mass is
</p>
<p>T = 1
2
</p>
<p>m(y&prime;)2, while the potential energy due to gravity is given by V (y) = mgy.
Substituting this form for L(t, y, y&prime;) (3.23) into the Euler&ndash;Lagrange equation (3.22)
yields
</p>
<p>dV
</p>
<p>dy
&minus; m d(y
</p>
<p>&prime;)
</p>
<p>dt
= 0 &rArr; m d
</p>
<p>2y
</p>
<p>dt2
= &minus;dV
</p>
<p>dy
&rArr; m d
</p>
<p>2y
</p>
<p>dt2
= &minus;mg,
</p>
<p>exactly as would be obtained from Newton&rsquo;s second law, but without the need to
</p>
<p>explicitly work out the forces acting on the system. The difference between the
</p>
<p>Lagrangian and force-based approaches is not significant in this example, but for
</p>
<p>more complicated systems, the Euler&ndash;Lagrange approach can notably simplify the
</p>
<p>process of deriving the equations of motion.
</p>
<p>Thorough treatments of the implications of this formulation are given in books
</p>
<p>on intermediate and advanced mechanics [40, 62, 67]; we limit ourselves here to the
</p>
<p>basic concepts that are most immediately useful for the formulation of models for
</p>
<p>mechanical systems.</p>
<p/>
</div>
<div class="page"><p/>
<p>58 3 Variational Principles
</p>
<p>3.3.1 Motion with Multiple Degrees of Freedom
</p>
<p>One generalisation of the Euler&ndash;Lagrange equation of motion is the derivation of the
</p>
<p>equations of motion for a multi-variable systems. As a specific example, consider
</p>
<p>the motion of a projectile in two dimensions with position x = (x(t), y(t)) subject to
gravity acting in the y-direction. The action can be written in terms of the difference
</p>
<p>of the kinetic and potential energies,
</p>
<p>I =
&int; [
</p>
<p>1
2
</p>
<p>m
(
</p>
<p>(x&prime;)2 + (y&prime;)2
)
</p>
<p>&minus; mgy
]
</p>
<p>dt.
</p>
<p>The principle of least action then requires that I(x, y) is minimised over all possible
</p>
<p>choices of the unknown functions x(t) and y(t). We assume that an optimal solution
</p>
<p>(x&lowast;(t), y&lowast;(t)) exists and express all admissible solutions in terms of independent
perturbations of the unknowns
</p>
<p>x̃(t) = x&lowast;(t)+ εh1(t), ỹ(t) = y&lowast;(t)+ εh2(t).
</p>
<p>Substituting into the action, I(x̃, ỹ) and Taylor expanding in the limit ε &rarr; 0,
</p>
<p>Ĩ = I&lowast; + ε
&int;
</p>
<p>[
</p>
<p>m(x&prime;&lowast;h
&prime;
1 + y&prime;&lowast;h&prime;2)&minus; mgh2
</p>
<p>]
</p>
<p>dt + O(ε2).
</p>
<p>By application of integration by parts and eliminating the boundary terms, we obtain
</p>
<p>the O(ε) term as
</p>
<p>&minus;
&int;
</p>
<p>(mx&prime;&prime;&lowast;)h1 + (my&prime;&prime;&lowast; + mg)h2 dt.
</p>
<p>Satisfying the critical point condition implies that this integral must be equal to zero
</p>
<p>for all choices of h1(t) and h2(t). One class of possibilities is given by h2 &equiv; 0 and
h1(t) arbitrary, this yields the equation mx
</p>
<p>&prime;&prime;
&lowast; = 0. Another choice is h1 &equiv; 0 with h2(t)
</p>
<p>arbitrary, yielding mg + my&prime;&prime;&lowast; = 0; the overall result comes from the intersection of
these cases using the linear independence of the individual perturbations.
</p>
<p>This can be understood as a generalisation of fundamental lemma (3.14) for the
</p>
<p>dot product of vector functions, g(x),h(x) &isin; Rn,
</p>
<p>If
</p>
<p>&int; b
</p>
<p>a
</p>
<p>g(x) &middot; h(x) dx = 0 &forall;h(x) then g(x) &equiv; 0 on a &le; x &le; b. (3.24)
</p>
<p>In other words, if the value of the integral is zero for all choices of component
</p>
<p>perturbation functions in h then each component of g must be identically zero,
</p>
<p>gi(x) &equiv; 0 for i = 1, 2, . . . , n.</p>
<p/>
</div>
<div class="page"><p/>
<p>3.3 The Variational Formation of Classical Mechanics 59
</p>
<p>Hence we can arrive at the (general) result that the critical point condition will yield
</p>
<p>separate Euler&ndash;Lagrange equations with respect to each variable with an independent
</p>
<p>perturbation. In this case
</p>
<p>&forall;h1 : x-Euler&ndash;Lagrange:
&part;L
</p>
<p>&part;x
&minus; d
</p>
<p>dt
</p>
<p>(
&part;L
</p>
<p>&part;x&prime;
</p>
<p>)
</p>
<p>= 0, (3.25a)
</p>
<p>&forall;h2 : y-Euler&ndash;Lagrange:
&part;L
</p>
<p>&part;y
&minus; d
</p>
<p>dt
</p>
<p>(
&part;L
</p>
<p>&part;y&prime;
</p>
<p>)
</p>
<p>= 0. (3.25b)
</p>
<p>Thus systems of differential equations for individual particles moving in two or three
</p>
<p>dimensions (x = (x, y, z)), or sets of particles (x1, x2, . . .), can be obtained from
the Lagrangian for the complete system, L(t, x1, x2, . . . , x
</p>
<p>&prime;
1, x
</p>
<p>&prime;
2, . . .), through the
</p>
<p>application of the Euler&ndash;Lagrange equation to each independent unknown function.
</p>
<p>3.4 The Influence of Boundary Conditions
</p>
<p>In the previous examples, we have seen the important roles played by the boundary
</p>
<p>conditions in:
</p>
<p>(i) specifying boundary conditions for the Euler&ndash;Lagrange problem
</p>
<p>(ii) determining boundary conditions on the perturbation functions
</p>
<p>(iii) eliminating the boundary terms generated by integration by parts in the calcu-
</p>
<p>lation of the first variation
</p>
<p>The last point is perhaps the most important in terms of reducing the problem to
</p>
<p>a differential equation; if it is not possible to eliminate the boundary terms, then
</p>
<p>the fundamental lemma cannot be applied. Choices of boundary conditions that are
</p>
<p>compatible with this requirement are called natural boundary conditions.7
</p>
<p>So far, we have seen how to work with Dirichlet boundary conditions (e.g.
</p>
<p>y(a) = c). We will now consider how other types of boundary conditions affect
problems.
</p>
<p>3.4.1 Problems with a Free Boundary
</p>
<p>Consider a modification of the problem of determining the shortest path we consid-
</p>
<p>ered in Sect. 3.2.1: find the function y(x) passing through the origin that gives the
</p>
<p>shortest path to the vertical line x = 1.
Being a problem in terms of the minimum distance, the functional to be minimised
</p>
<p>is the same as in (3.10a),
</p>
<p>7Given the lack of elementary approaches if the fundamental lemma can not be used, it is tempting
</p>
<p>to call them necessary boundary conditions.</p>
<p/>
</div>
<div class="page"><p/>
<p>60 3 Variational Principles
</p>
<p>J(y) =
&int; 1
</p>
<p>0
</p>
<p>&radic;
</p>
<p>1 + (y&prime;)2 dx,
</p>
<p>but the problem statement now provides only one definite boundary condition,
</p>
<p>y(0) = 0. There is no specific requirement on y at x = 1 and hence this is called a
free boundary. In order to see how to deal with such a situation, we revisit (3.7) to
</p>
<p>consider the form of admissible solutions,
</p>
<p>ỹ(x) = y&lowast;(x)+ εh(x).
</p>
<p>At x = 0, we should have zero perturbation, h(0) = 0 since ỹ(0) = y&lowast;(0) = 0. At
x = 1, ỹ(1) and y&lowast;(1) are arbitrary, and so we have no information about h(1).
</p>
<p>Proceeding as before, we expand J(y&lowast; + εh) for ε &rarr; 0 as
</p>
<p>J̃ = J&lowast; + ε
(
</p>
<p>y&prime;&lowast;h
&radic;
</p>
<p>1 + (y&prime;&lowast;)2
</p>
<p>∣
∣
∣
∣
</p>
<p>x=1
</p>
<p>x=0
&minus;
</p>
<p>&int; 1
</p>
<p>0
</p>
<p>d
</p>
<p>dx
</p>
<p>(
</p>
<p>y&prime;&lowast;
&radic;
</p>
<p>1 + (y&prime;&lowast;)2
</p>
<p>)
</p>
<p>h dx
</p>
<p>)
</p>
<p>+ O(ε2).
</p>
<p>We need the total contribution from the boundary terms to vanish, requiring
</p>
<p>y&prime;&lowast;(1)h(1)
&radic;
</p>
<p>1 + y&prime;&lowast;(1)2
&minus; 0 = 0,
</p>
<p>where the x = 0 boundary term vanishes due to h(0) = 0. Since we do not know
anything about h(1), in order to guarantee that the remaining term vanishes, we
</p>
<p>require that the optimal solution satisfies the natural boundary condition, y&prime;&lowast;(1) = 0.
It is important to note that irrespective of the form taken by the natural boundary
</p>
<p>conditions, they are only involved in eliminating the boundary terms in order to leave
</p>
<p>the integral in a form compatible with the fundamental lemma. Consequently, the
</p>
<p>Euler&ndash;Lagrange equation is again given by (3.21) and (in this case) leads to the same
</p>
<p>ODE as found for the prescribed end-point case (3.16). However, the new boundary
</p>
<p>conditions for the Euler&ndash;Lagrange problem, y&lowast;(0) = 0 and y&prime;&lowast;(1) = 0, now select
a different solution, y&lowast;(x) &equiv; 0 (corresponding to the line from the origin along the
x-axis up to the point of intersection with the line x = 1).
</p>
<p>3.4.2 Problems with a Variable Endpoint
</p>
<p>Another version of the &ldquo;find the shortest path&rdquo; problem is to find y(x) that gives the
</p>
<p>shortest path from the origin to a given curve y = f (x) (see Fig. 3.3).
The boundary condition y&lowast;(0) = 0 holds as before, but now the other end-point
</p>
<p>can be any point on the curve y = f (x). Let us denote this unknown point as x = b
and then the boundary condition is simply
</p>
<p>y(b) = f (b). (3.26a)</p>
<p/>
</div>
<div class="page"><p/>
<p>3.4 The Influence of Boundary Conditions 61
</p>
<p>Fig. 3.3 A trial solution,
</p>
<p>ỹ(x) on 0 &le; x &le; b̃, for the
&ldquo;shortest path to a given
</p>
<p>curve&rdquo; variable endpoint
</p>
<p>problem (3.26)
</p>
<p>ỹ(x)
</p>
<p>b̃0
</p>
<p>y
</p>
<p>x
</p>
<p>y = f(x)
</p>
<p>The objective functional is (as before) the total arclength
</p>
<p>J(y) =
&int; b
</p>
<p>0
</p>
<p>&radic;
</p>
<p>1 + (y&prime;)2 dx. (3.26b)
</p>
<p>We begin the analysis as usual, by adding a perturbation to each unknown, y(x) and
</p>
<p>b. As before, the admissible solutions take the form
</p>
<p>ỹ(x) = y&lowast;(x)+ εh(x),
</p>
<p>while the admissible endpoints can be written as
</p>
<p>b̃ = b&lowast; + εc,
</p>
<p>where c is a perturbation constant. Consequently, we have
</p>
<p>J̃ =
&int; b&lowast;+εc
</p>
<p>0
</p>
<p>&radic;
</p>
<p>1 + (y&prime;&lowast; + εh&prime;)2 dx. (3.27)
</p>
<p>At this point in previous examples, we have Taylor expanded J̃ in the limit ε &rarr; 0. A
new complication present in this problem is that a perturbation appears in the limits
</p>
<p>of integration as well as in the integrand. One effective tool for dealing with this
</p>
<p>issue is Leibniz&rsquo;s rule for the derivative of an integral
</p>
<p>d
</p>
<p>dz
</p>
<p>(
&int; b(z)
</p>
<p>a(z)
</p>
<p>g(x, y(x), z) dx
</p>
<p>)
</p>
<p>=
&int; b
</p>
<p>a
</p>
<p>&part;g
</p>
<p>&part;z
dx +
</p>
<p>[
</p>
<p>g(b, y(b), z)
db
</p>
<p>dz
&minus; g(a, y(a), z)da
</p>
<p>dz
</p>
<p>]
</p>
<p>. (3.28)</p>
<p/>
</div>
<div class="page"><p/>
<p>62 3 Variational Principles
</p>
<p>Applying Leibniz&rsquo;s rule to (3.27) with ε playing the role of z, we obtain the first
</p>
<p>variation in the form
</p>
<p>dJ
</p>
<p>dε
</p>
<p>∣
∣
∣
∣
ε=0
</p>
<p>=
&int; b&lowast;
</p>
<p>0
</p>
<p>y&prime;&lowast;h
&prime;
</p>
<p>&radic;
</p>
<p>1 + (y&prime;&lowast;)2
dx + c
</p>
<p>&radic;
</p>
<p>1 + y&prime;&lowast;(b&lowast;)2.
</p>
<p>After using integration by parts and imposing the critical point condition, this yields
</p>
<p>(
</p>
<p>c
</p>
<p>&radic;
</p>
<p>1 + y&prime;&lowast;(b&lowast;)2 +
y&prime;&lowast;(b&lowast;)h(b&lowast;)
</p>
<p>&radic;
</p>
<p>1 + y&prime;&lowast;(b&lowast;)2
</p>
<p>)
</p>
<p>&minus;
&int; b&lowast;
</p>
<p>0
</p>
<p>d
</p>
<p>dx
</p>
<p>(
</p>
<p>y&prime;&lowast;
&radic;
</p>
<p>1 + (y&prime;&lowast;)2
</p>
<p>)
</p>
<p>h dx = 0.
</p>
<p>If the boundary terms vanish, then applying the fundamental lemma to the integral
</p>
<p>will yield the expected Euler&ndash;Lagrange equation, but it is not yet clear which bound-
</p>
<p>ary conditions on y achieve this since c and h(b&lowast;) are unknown. However, we have not
yet fully utilised (3.26a), namely that ỹ(b̃) = f (b̃). Writing this out more explicitly,
we have
</p>
<p>y&lowast;(b&lowast; + εc)+ εh(b&lowast; + εc) = f (b&lowast; + εc). (3.29)
</p>
<p>Expanding (3.29) in the limit ε &rarr; 0, matching first terms in the respective expansions
of the left- and right-hand sides, we recover y&lowast;(b&lowast;) = f (b&lowast;) for the optimal solution.
Matching O(ε) terms, we find that
</p>
<p>y&prime;&lowast;(b&lowast;)c + h(b&lowast;) = f &prime;(b&lowast;)c
</p>
<p>which can be solved for c
</p>
<p>c = h(b&lowast;)
f &prime;(b&lowast;)&minus; y&prime;&lowast;(b&lowast;)
</p>
<p>.
</p>
<p>Substituting this result into the boundary terms yields
</p>
<p>(
</p>
<p>y&prime;&lowast;(b&lowast;)
&radic;
</p>
<p>1 + y&prime;&lowast;(b&lowast;)2
+
</p>
<p>&radic;
</p>
<p>1 + y&prime;&lowast;(b&lowast;)2
f &prime;(b&lowast;)&minus; y&prime;&lowast;(b&lowast;)
</p>
<p>)
</p>
<p>h(b&lowast;).
</p>
<p>Since no constraints are known on the value of h(b&lowast;), in order to ensure that this term
vanishes for all admissible perturbations, we require that the terms in parentheses
</p>
<p>sum to zero, which (after a little algebra) yields the natural boundary condition
</p>
<p>y&prime;(b&lowast;) = &minus;
1
</p>
<p>f &prime;(b&lowast;)
. (3.30)
</p>
<p>Recalling that the Euler&ndash;Lagrange equation yields straight lines as solutions (3.17),
</p>
<p>this condition selects the minimum distance to the curve via the line that inter-
</p>
<p>sects the curve perpendicularly (recall the negative reciprocal slope relation from
</p>
<p>analytic geometry). While it may seem unusual to have three boundary conditions</p>
<p/>
</div>
<div class="page"><p/>
<p>3.4 The Influence of Boundary Conditions 63
</p>
<p>(on y(0), y(b), y&prime;(b)) for a second order differential equation, it is not overdetermined
since b&lowast; is unknown and has to be determined as part of the solution.
</p>
<p>3.5 Optimisation with Constraints
</p>
<p>While the solutions of many systems are determined from optimising some prop-
</p>
<p>erty of the system, in some cases, the choice of the optimal solution is constrained
</p>
<p>further by some implicit structure in the problem&mdash;such as a finite amount of build-
</p>
<p>ing materials limiting the maximum size of a structure, or finite time limiting how
</p>
<p>thoroughly a task can be performed. These are examples of constrained optimisation
</p>
<p>problems&mdash;the specific constraints are crucial in selecting the relevant solution. In
</p>
<p>simple problems, the constraints can be substituted directly into the objective func-
</p>
<p>tion in order to obtain a reduced problem describing all achievable solutions (see
</p>
<p>Exercise 3.5, for example), but for problems where this cannot be done, the method
</p>
<p>of Lagrange multipliers can be employed instead. This approach will be used to inves-
</p>
<p>tigate several classes of calculus of variations problems in the remaining sections of
</p>
<p>this chapter,
</p>
<p>(i) Isoperimetric problems: optimising a functional subject to a condition on an
</p>
<p>integral of the solution.
</p>
<p>(ii) Holonomic systems: optimising a functional subject to a geometric condition
</p>
<p>applied pointwise on the solution.
</p>
<p>(iii) Optimal control: optimising a functional subject to a differential equation
</p>
<p>applied pointwise on the solution.
</p>
<p>We begin with a brief review of the method of Lagrange multipliers applied to
</p>
<p>problems from multivariable calculus.
</p>
<p>3.5.1 Review of Lagrange Multipliers
</p>
<p>In constrained optimisation problems, feasible solutions lie within a subset of the
</p>
<p>space of all possible solutions. The method of Lagrange multipliers identifies the
</p>
<p>feasible solutions through the same process used in unconstrained optimisation
</p>
<p>problems&mdash;namely obtaining the possible solutions from solving equations deter-
</p>
<p>mined by the critical point condition (cf. (3.4))
</p>
<p>&part;(objective)
</p>
<p>&part;(variables)
= 0.</p>
<p/>
</div>
<div class="page"><p/>
<p>64 3 Variational Principles
</p>
<p>The Lagrange multiplier approach constructs an &ldquo;augmented objective function&rdquo; L
</p>
<p>incorporating the original objective function, call it f (x, y), along with all constraints
</p>
<p>so that the critical points are still described by a gradient condition
</p>
<p>&nabla;L = 0 &hArr; all critical point solutions. (3.31)
</p>
<p>Consider the fundamental problem of maximising a function of two variables subject
</p>
<p>to a single constraint:
</p>
<p>Find (x&lowast;, y&lowast;) yielding max f (x, y) from among the points (x, y) on the curve g(x, y) = 0,
</p>
<p>where g(x, y) = 0 is the implicit equation of a given curve.
Suppose that the parametric equations describing the g = 0 curve are known,
</p>
<p>x = x(t), y = y(t), such that
</p>
<p>g(x(t), y(t)) = 0 &forall;t.
</p>
<p>Differentiating this equation using the chain rule yields
</p>
<p>0 = d
dt
</p>
<p>[
</p>
<p>g(x(t), y(t))
]
</p>
<p>= &nabla;g &middot; dx
dt
</p>
<p>= 0. (3.32)
</p>
<p>If the parameter t is taken to represent time, the geometric interpretation of this
</p>
<p>equation is that the &ldquo;velocity&rdquo; vector dx/dt (which is tangent to the curve x(t)) is
</p>
<p>perpendicular to the level-curve g = 0 since the gradient&nabla;g is orthogonal to contours
of constant function-value.
</p>
<p>Substituting x(t), y(t) into f (x, y) yields a function of a single variable
</p>
<p>F(t) = f (x(t), y(t))
</p>
<p>that is parametrised along the curve g = 0. Finding the critical points of F(t) with
respect to t gives the critical points of f on g,
</p>
<p>dF
</p>
<p>dt
= 0 =&rArr; dF
</p>
<p>dt
= &nabla;f &middot; dx
</p>
<p>dt
= 0. (3.33)
</p>
<p>Hence, the chain rule shows that at a critical point,&nabla;f is also orthogonal to the velocity
vector. In two dimensions, this forces the two gradients to be a scalar multiple of
</p>
<p>each other and then we obtain
</p>
<p>&nabla;f = λ&nabla;g
</p>
<p>where λ (called the Lagrange multiplier) is another unknown that needs to be deter-
</p>
<p>mined. In component form, the resulting set of equations of three variables in the
</p>
<p>three unknowns is
</p>
<p>fx(x&lowast;, y&lowast;) = λgx(x&lowast;, y&lowast;), fy(x&lowast;, y&lowast;) = λgy(x&lowast;, y&lowast;), g(x&lowast;, y&lowast;) = 0.</p>
<p/>
</div>
<div class="page"><p/>
<p>3.5 Optimisation with Constraints 65
</p>
<p>A typical solution strategy for solving the equations is to first solve the &nabla;f = λ&nabla;g
equations to obtain x(λ), y(λ), and then substitute these into g(x(λ), y(λ)) = 0 to
obtain a final equation for the values of λ.
</p>
<p>This approach generalises in a straightforward manner to higher dimensions and
</p>
<p>to multiple constraints (L &equiv; f &minus; λg &minus; μh &minus; &middot; &middot; &middot; ) [24, 68]. We note that had the
parametric equations for x(t), y(t) been available, then solutions could have been
</p>
<p>obtained directly from (3.33). The Lagrange approach does not actually use these
</p>
<p>parametric equations, just the assumption of their existence, to reformulate the prob-
</p>
<p>lem into a convenient form.
</p>
<p>The above discussion motivates the introduction of the augmented (constrained)
</p>
<p>Lagrange objective function satisfying (3.31),
</p>
<p>L (x, y, λ) &equiv; f (x, y)&minus; λg(x, y). (3.34)
</p>
<p>This is just a convenient form that reproduces the set of equations above as the critical
</p>
<p>point equations for L with respect to its three variables,
</p>
<p>&nabla;L = 0 &harr; { Lx = 0, Ly = 0, Lλ = 0 }. (3.35)
</p>
<p>3.6 Integral Constraints: Isoperimetric Problems
</p>
<p>Consider problems where the solution y&lowast;(x) satisfies
</p>
<p>max
y
</p>
<p>(
</p>
<p>J &equiv;
&int; b
</p>
<p>a
</p>
<p>L(x, y, y&prime;) dx
</p>
<p>)
</p>
<p>subject to G &equiv;
&int; b
</p>
<p>a
</p>
<p>g(x, y, y&prime;) dx = 0.
</p>
<p>(3.36)
</p>
<p>These are sometimes called isoperimetric problems with the name referring back to
</p>
<p>a classic geometric problem of maximising the area enclosed by a curve constrained
</p>
<p>to have a fixed perimeter (see Exercise 3.20).
</p>
<p>Maximising J subject to the constraint G = 0 can be expressed in terms of an
augmented Lagrange functional of the form
</p>
<p>I(y, λ) = J &minus; λG, (3.37)
</p>
<p>where λ is a constant. This can also be restated in terms of an augmented Lagrangian
</p>
<p>function
</p>
<p>I =
&int; b
</p>
<p>a
</p>
<p>L dx where L (x, y, y&prime;, λ) = L(x, y, y&prime;)&minus; λg(x, y, y&prime;). (3.38)</p>
<p/>
</div>
<div class="page"><p/>
<p>66 3 Variational Principles
</p>
<p>Once this functional has been identified, we follow the standard variational process
</p>
<p>described in Sect. 3.2, starting with the introduction of perturbations to all of the
</p>
<p>unknowns
</p>
<p>ỹ(x) = y&lowast;(x)+ εh(x), λ̃ = λ&lowast; + εγ.
</p>
<p>Expanding Ĩ as a Taylor series for ε &rarr; 0 and enforcing the critical point condition
on the O(ε) term yields
</p>
<p>&int; b
</p>
<p>a
</p>
<p>[
&part;L
</p>
<p>&part;y
&minus; d
</p>
<p>dx
</p>
<p>(
&part;L
</p>
<p>&part;y&prime;
</p>
<p>)
</p>
<p>&minus; λ&lowast;
{
&part;g
</p>
<p>&part;y
&minus; d
</p>
<p>dx
</p>
<p>(
&part;g
</p>
<p>&part;y&prime;
</p>
<p>)}]
</p>
<p>h dx + γ
&int; b
</p>
<p>a
</p>
<p>g(x, y&lowast;, y
&prime;
&lowast;) dx = 0.
</p>
<p>Requiring this to hold with respect to (i) all possible γ perturbations recovers the
</p>
<p>geometric constraint
&int; b
</p>
<p>a
</p>
<p>g(x, y&lowast;, y
&prime;
&lowast;) dx = 0, (3.39a)
</p>
<p>and (ii) all h(x) perturbations using the fundamental lemma yields the Euler&ndash;
</p>
<p>Lagrange equation
&part;L
</p>
<p>&part;y
&minus; d
</p>
<p>dx
</p>
<p>(
&part;L
</p>
<p>&part;y&prime;
</p>
<p>)
</p>
<p>= 0. (3.39b)
</p>
<p>This again shows that the form of the Euler&ndash;Lagrange equation (3.21) generalises to
</p>
<p>a wide array of problems.
</p>
<p>As an example, consider the problem of finding the function y(x) &gt; 0 on 0 &lt;
</p>
<p>x &lt; 1 satisfying boundary conditions y(0) = 0 and y(1) = 0, with a given arclength,
S =
</p>
<p>&int; 1
0
</p>
<p>&radic;
</p>
<p>1 + (y&prime;)2 dx that maximises the area under the curve, A =
&int; 1
</p>
<p>0 y dx.
</p>
<p>We can write the augmented Lagrangian L = A &minus; λP to maximise the enclosed
area subject to the constraint of a fixed perimeter, P = S + 1 (which includes the
contribution from the lower boundary, y &equiv; 0). Applying (3.39a, 3.39b), we obtain
</p>
<p>1 + λ&lowast;
d
</p>
<p>dx
</p>
<p>(
</p>
<p>y&prime;&lowast;
&radic;
</p>
<p>1 + (y&prime;&lowast;)2
</p>
<p>)
</p>
<p>= 0,
&int; 1
</p>
<p>0
</p>
<p>(&radic;
</p>
<p>1 + (y&prime;&lowast;)2 &minus; S
)
</p>
<p>dx = 0.
</p>
<p>Solving the ODE and imposing the boundary conditions, yields
</p>
<p>y&lowast;(x) =
&radic;
</p>
<p>λ2&lowast; &minus; (x &minus; 12 )2 &minus;
&radic;
</p>
<p>λ2&lowast; &minus; 14 , (3.40)</p>
<p/>
</div>
<div class="page"><p/>
<p>3.6 Integral Constraints: Isoperimetric Problems 67
</p>
<p>Fig. 3.4 The solution y&lowast;(x)
(3.40) maximising the area
</p>
<p>under the curve on 0 &le; x &le; 1
for given arclength S
</p>
<p>S = 1.1
</p>
<p>S = 1.3
</p>
<p>S = 1.5
</p>
<p>x
</p>
<p>y
</p>
<p>10
</p>
<p>0.5
</p>
<p>0.4
</p>
<p>0.3
</p>
<p>0.2
</p>
<p>0.1
</p>
<p>0
</p>
<p>which can be integrated to yield the resulting area and arclength for a given value of
</p>
<p>the Lagrange multiplier λ&lowast;,
</p>
<p>a(λ&lowast;) &equiv;
&int; 1
</p>
<p>0
</p>
<p>y&lowast;(x) dx = λ2&lowast; arcsin
(
</p>
<p>1
</p>
<p>2λ&lowast;
</p>
<p>)
</p>
<p>&minus;
&radic;
</p>
<p>λ2&lowast; &minus; 14 ,
</p>
<p>s(λ&lowast;) &equiv;
&int; 1
</p>
<p>0
</p>
<p>&radic;
</p>
<p>1 + y&prime;&lowast;(x)2 dx = 2λ&lowast; arcsin
(
</p>
<p>1
</p>
<p>2λ&lowast;
</p>
<p>)
</p>
<p>.
</p>
<p>To complete the solution of the constrained problem, the arclength constraint, s(λ&lowast;) =
S, must be applied to determine a value for λ&lowast; in terms of S.
</p>
<p>From (3.40) we see that acceptable (real-valued) solutions must have λ&lowast; &ge; 12 ,
which limits S in the problem statement to be in the range 1 &le; S &le; π/2. Noting
that (3.40) describes arcs of circles going through the fixed endpoints, with centres
</p>
<p>given by ( 1
2
,&minus;
</p>
<p>&radic;
</p>
<p>λ2&lowast; &minus; 14 ), with λ&lowast; being the radius of the circle, see Fig. 3.4. The fact
that (3.40) is not valid for S &gt; π/2 suggests that the assumed form of the solutions
</p>
<p>(in this case, graphs of functions y = y(x)) may be too restrictive and different
representations of the problem could be helpful, see Exercise 3.20.
</p>
<p>3.7 Geometric Constraints: Holonomic Problems
</p>
<p>Consider the problem of finding parametric equations for a curve (x&lowast;(t), y&lowast;(t) on
0 &le; t &le; T ) that minimises the integral
</p>
<p>I =
&int; T
</p>
<p>0
</p>
<p>L(t, x, y, x&prime;, y&prime;) dt, (3.41a)</p>
<p/>
</div>
<div class="page"><p/>
<p>68 3 Variational Principles
</p>
<p>subject to the constraint that for each value of t,
</p>
<p>g(x(t), y(t), t) = 0. (3.41b)
</p>
<p>Problems of this form are called holonomic problems in the context of dynamics of
</p>
<p>mechanical systems. The constraint (3.41b) imposes a condition that the motion in
</p>
<p>the system must satisfy at each instant of time, as typically imposed by structural
</p>
<p>geometric constraints (as in the case of a roller coaster car moving on its track).
</p>
<p>It can be shown that the appropriate generalisation of (3.34) for holonomic prob-
</p>
<p>lems is the augmented Lagrangian
</p>
<p>L (x, y, λ) = L(t, x, y, x&prime;, y&prime;)&minus; λ(t)g(x, y, t) =&rArr; I =
&int; T
</p>
<p>0
</p>
<p>L dt. (3.42)
</p>
<p>Here, a notable difference from (3.38) for isoperimetric problems is that the Lagrange
</p>
<p>multiplier is a function of t, rather than a constant, and cannot be factored out of the
</p>
<p>integral as we did in (3.37). Applying independent perturbations to each unknown,
</p>
<p>x̃(t) = x&lowast;(t)+ εh1(t), ỹ(t) = y&lowast;(t)+ εh2(t), λ̃(t) = λ&lowast;(t)+ εγ (t),
</p>
<p>and expanding I as ε &rarr; 0, we obtain
</p>
<p>δI&lowast; =
&int; T
</p>
<p>0
</p>
<p>{[
&part;L
</p>
<p>&part;x
&minus; d
</p>
<p>dt
</p>
<p>(
&part;L
</p>
<p>&part;x&prime;
</p>
<p>)]
</p>
<p>h1 +
[
&part;L
</p>
<p>&part;y
&minus; d
</p>
<p>dt
</p>
<p>(
&part;L
</p>
<p>&part;y&prime;
</p>
<p>)]
</p>
<p>h2
</p>
<p>&minus;λ&lowast;
(
&part;g
</p>
<p>&part;x
h1 +
</p>
<p>&part;g
</p>
<p>&part;y
h2
</p>
<p>)
</p>
<p>&minus; gγ
}
</p>
<p>dt, (3.43)
</p>
<p>where the terms in the first line give the contributions from the original objective
</p>
<p>function and the terms in the second line represent the influence of the constraint.
</p>
<p>Noting that all perturbations are independently allowable, in enforcing the critical
</p>
<p>point condition, δI&lowast; = 0 (through linear independence, as in (3.24)) we conclude
that the coefficient of each perturbation must vanish
</p>
<p>&forall;h1 : xEuler&ndash;Lagrange:
&part;L
</p>
<p>&part;x
&minus; d
</p>
<p>dt
</p>
<p>(
&part;L
</p>
<p>&part;x&prime;
</p>
<p>)
</p>
<p>= 0,
</p>
<p>&forall;h2 : yEuler&ndash;Lagrange:
&part;L
</p>
<p>&part;y
&minus; d
</p>
<p>dt
</p>
<p>(
&part;L
</p>
<p>&part;y&prime;
</p>
<p>)
</p>
<p>= 0,
</p>
<p>&forall;γ : Geometric constraint: g(x&lowast;(t), y&lowast;(t), t) = 0,
</p>
<p>where we have combined the L, g terms from (3.43) to write the Euler&ndash;Lagrange
</p>
<p>equations in a more compact form using (3.42). In fact, this system can be condensed</p>
<p/>
</div>
<div class="page"><p/>
<p>3.7 Geometric Constraints: Holonomic Problems 69
</p>
<p>further to be expressed as
</p>
<p>u Euler&ndash;Lagrange:
&part;L
</p>
<p>&part;u
&minus; d
</p>
<p>dt
</p>
<p>(
&part;L
</p>
<p>&part;u&prime;
</p>
<p>)
</p>
<p>= 0 u = {x, y, λ},
</p>
<p>where u denotes each unknown function of t in the system. In other contexts, systems
</p>
<p>containing both geometric constraints and differential equations are often also called
</p>
<p>differential algebraic equations (DAE).
</p>
<p>3.8 Differential Equation Constraints: Optimal Control
</p>
<p>For holonomic problems, we considered optimising a functional subject to constraints
</p>
<p>on the possible solution applied pointwise over the entire domain. We now extend
</p>
<p>the analysis to systems where the constraint is given by a differential equation. In
</p>
<p>such cases, we want to minimise
</p>
<p>J =
&int; T
</p>
<p>0
</p>
<p>L(t, x(t), u(t)) dt, (3.44a)
</p>
<p>subject to the constraint that at each t on 0 &le; t &le; T ,
</p>
<p>dx
</p>
<p>dt
= f (t, x(t), u(t)), (3.44b)
</p>
<p>along with given conditions on x(t)
</p>
<p>x(0) = x0 x(T) = x1. (3.44c)
</p>
<p>Problems of this form arise in optimal control theory which seeks to determine a
</p>
<p>control function u(t) that allows the state function x(t) to achieve a desired target
</p>
<p>value (or &ldquo;final state&rdquo;) x1 while also minimising the &ldquo;cost&rdquo; of the overall process in
</p>
<p>imposing the control on the evolution of the state. The cost will be represented by the
</p>
<p>integral (3.44a). The ending time T will also be considered as a degree of freedom
</p>
<p>and used to help reduce the cost and make the target achievable, as some systems
</p>
<p>might be able to run cheaply, if perhaps slowly.
</p>
<p>Equation (3.44b) is called a state equation; it describes how the system evolves
</p>
<p>based on a dynamical model relevant to the problem (e.g. mechanics or chemical
</p>
<p>kinetics). In the absence of external forcing, described here by the control function
</p>
<p>u(t), (u &equiv; 0), then the natural (uncontrolled) dynamics starting from the initial
condition (3.44c)1 are given by the solution of
</p>
<p>dx̂
</p>
<p>dt
= f (x̂, 0, t) x̂(0) = x0. (3.45)</p>
<p/>
</div>
<div class="page"><p/>
<p>70 3 Variational Principles
</p>
<p>Under typical assumptions on the rate function f , this initial value problem has a
</p>
<p>well-defined solution x̂(t). However, this solution might not equal the target value
</p>
<p>x1 at any value of T &ge; 0, or might reach it only after an undesirably long time. Both
of these situations would make the uncontrolled solution x̂ unacceptable, and hence
</p>
<p>we need to consider modifying the evolution of the state from (3.45) by forcing the
</p>
<p>system with some control function u(t) yielding (3.44b).
</p>
<p>Appropriate control functions may allow the state to reach the target, but may also
</p>
<p>involve excessive input of energy, or could still take too long. Hence, the &ldquo;optimality&rdquo;
</p>
<p>in optimal control theory refers to minimising the cost involved in imposing the
</p>
<p>control. Two basic types of cost functionals that can be used, depending on whether
</p>
<p>system speed or minimisation of the energy of the control function is the priority,
</p>
<p>are given respectively by
</p>
<p>Jspeed =
&int; T
</p>
<p>0
</p>
<p>1 dt = T , Jenergy =
&int; T
</p>
<p>0
</p>
<p>u2 dt. (3.46)
</p>
<p>Examples of systems that can be described in this form include the input control of
</p>
<p>chemicals in reaction systems to maintain a steady output, the design of controlled-
</p>
<p>release timed drug delivery, and car power-steering systems. In addition to uses in
</p>
<p>&ldquo;engineered&rdquo; systems, such models can also be applied to describe how biological
</p>
<p>systems adapt to their environments.
</p>
<p>System (3.44) is a classic optimal control theory problem&mdash;its solution involves
</p>
<p>determining the evolution of the state x(t), the control u(t), and the optimal stop-
</p>
<p>ping time T . The imposition of the state equation at each time suggests forming an
</p>
<p>augmented Lagrangian with a time-dependent Lagrange multiplier, as in (3.42),
</p>
<p>L (x, x&prime;, u, λ) = L(t, x, u)&minus; λ(t)
(
</p>
<p>dx
</p>
<p>dt
&minus; f (x, u, t)
</p>
<p>)
</p>
<p>(3.47)
</p>
<p>and corresponding augmented functional
</p>
<p>I =
&int; T
</p>
<p>0
</p>
<p>L (x, x&prime;, u, λ) dt. (3.48)
</p>
<p>Since the stopping time is also an unknown, we will also draw on the analysis carried
</p>
<p>out for the variable endpoint problem in Sect. 3.4.2.
</p>
<p>Applying perturbations to all of the unknowns
</p>
<p>x̃ = x&lowast; + εh(t) ũ = u&lowast; + εv(t) λ̃ = λ&lowast; + εγ (t) T̃ = T&lowast; + εS,
</p>
<p>the cost functional is then
</p>
<p>Ĩ =
&int; T&lowast;+εS
</p>
<p>0
</p>
<p>L (x&lowast; + εh, x&prime;&lowast; + εh&prime;, u&lowast; + εv, λ&lowast; + εγ ) dt. (3.49)</p>
<p/>
</div>
<div class="page"><p/>
<p>3.8 Differential Equation Constraints: Optimal Control 71
</p>
<p>Expanding Ĩ as a Taylor series for ε &rarr; 0 gives
</p>
<p>Ĩ = I&lowast; + ε
dI
</p>
<p>dε
</p>
<p>∣
∣
∣
∣
ε=0
</p>
<p>+ O(ε2),
</p>
<p>where, using Leibniz&rsquo; rule (3.28), we obtain the first variation in the form
</p>
<p>&int; T&lowast;
</p>
<p>0
</p>
<p>[
&part;L
</p>
<p>&part;x
h + &part;L
</p>
<p>&part;x&prime;
h&prime; + &part;L
</p>
<p>&part;u
v + &part;L
</p>
<p>&part;λ
γ
</p>
<p>]
</p>
<p>dt + L&lowast;
∣
∣
∣
∣
t=T&lowast;
</p>
<p>S.
</p>
<p>Applying integration by parts to the h&prime; term, the first variation becomes
</p>
<p>=
&int; T&lowast;
</p>
<p>0
</p>
<p>[{
&part;L
</p>
<p>&part;x
&minus; d
</p>
<p>dt
</p>
<p>(
&part;L
</p>
<p>&part;x&prime;
</p>
<p>)}
</p>
<p>h + &part;L
&part;u
</p>
<p>v + &part;L
&part;λ
</p>
<p>γ
</p>
<p>]
</p>
<p>dt +
(
</p>
<p>L S + &part;L
&part;x&prime;
</p>
<p>h
</p>
<p>) ∣
∣
∣
∣
t=T&lowast;
</p>
<p>,
</p>
<p>(3.50)
</p>
<p>where we have used the initial condition (3.44c)1 to obtain that the perturbation
</p>
<p>satisfies h(0) = 0. Recalling the form of the condition at the variable endpoint
(3.26a), we write the target/final value condition, x̃(T̃) = x1, as
</p>
<p>x&lowast;(T&lowast; + εS)+ εh(T&lowast; + εS) = x1. (3.51)
</p>
<p>Expanding this equation in the limit ε &rarr; 0, we recover x&lowast;(T&lowast;) = x1 by matching
leading terms, and at O(ε) the perturbation function satisfies
</p>
<p>h(T&lowast;) = &minus;x&prime;&lowast;(T&lowast;)S. (3.52)
</p>
<p>Substituting this into the first variation (3.50), the boundary term reduces to
</p>
<p>(
</p>
<p>L &minus; x&prime; &part;L
&part;x&prime;
</p>
<p>) ∣
∣
∣
∣
t=T&lowast;
</p>
<p>S.
</p>
<p>This combination of terms is called the Legendre transform of the Lagrangian with
</p>
<p>respect to the state variable. It will be convenient to define a new function, the
</p>
<p>Hamiltonian,8 from this combination,
</p>
<p>H &equiv; L &minus; x&prime; &part;L
&part;x&prime;
</p>
<p>. (3.53)
</p>
<p>8Note that in a different context, there is another definition of the Hamiltonian having H = &minus;H .
Despite the difference in sign conventions, both are called Hamiltonians, see Exercise 3.7.</p>
<p/>
</div>
<div class="page"><p/>
<p>72 3 Variational Principles
</p>
<p>Since L = L &minus; λ(x&prime; &minus; f ), we find that the Hamiltonian is given by
</p>
<p>H = L + λf , (3.54)
</p>
<p>and hence the boundary term becomesH |t=T&lowast;S. Imposing the critical point condition
δI&lowast; = 0 for all independent perturbations (&forall;h, &forall;v, &forall;γ , &forall;S), we obtain the four
equations:
</p>
<p>&part;L
</p>
<p>&part;x
&minus; d
</p>
<p>dt
</p>
<p>(
&part;L
</p>
<p>&part;x&prime;
</p>
<p>)
</p>
<p>= 0, &part;L
&part;u
</p>
<p>= 0, &part;L
&part;λ
</p>
<p>= 0, H (T&lowast;) = 0. (3.55)
</p>
<p>The last equation provides a natural final condition on the Hamiltonian. Making use
</p>
<p>of the fact that it can be shown that if L does not explicitly (non-autonomously)
</p>
<p>depend on t, then the Hamiltonian is constant (see Exercise 3.7), the condition at T&lowast;
determines that H (t) &equiv; 0 for 0 &le; t &le; T&lowast;.
</p>
<p>The third equation in (3.55) returns the state equation (3.44b). Similarly, the first
</p>
<p>equation yields an ordinary differential equation for the evolution of the Lagrange
</p>
<p>multiplier,
(
&part;L
</p>
<p>&part;x
+ λ&lowast;
</p>
<p>&part;f
</p>
<p>&part;x
</p>
<p>)
</p>
<p>+ dλ&lowast;
dt
</p>
<p>= 0, (3.56)
</p>
<p>which is called the co-state equation, with λ&lowast;(t) (responsible for imposing the state-
equation constraint) being called the co-state in control theory.
</p>
<p>Finally, the perturbation with respect to the control, (3.55)2 gives a geometric
</p>
<p>constraint on the control at each time t on 0 &le; t &le; T&lowast;,
</p>
<p>&part;L
</p>
<p>&part;u
+ λ&lowast;
</p>
<p>&part;f
</p>
<p>&part;u
= 0. (3.57)
</p>
<p>We apply the above derivation to a simple example of an optimal control problem.
</p>
<p>Consider the initial value problem for x(t),
</p>
<p>dx
</p>
<p>dt
= &minus;3x + u x(0) = 2.
</p>
<p>We immediately see that the uncontrolled system would have the exponentially
</p>
<p>decaying solution, x̂(t) = 2e&minus;3t . As an illustrative problem where the influence
of control is crucial, let the final target state for T &gt; 0 be
</p>
<p>x(T) = 5,
</p>
<p>which is unattainable with the uncontrolled solution. Consider minimising a control-
</p>
<p>based cost functional, like Jenergy from (3.46),</p>
<p/>
</div>
<div class="page"><p/>
<p>3.8 Differential Equation Constraints: Optimal Control 73
</p>
<p>min J = 1
2
</p>
<p>&int; T
</p>
<p>0
</p>
<p>u2 dt.
</p>
<p>We can directly identify the Lagrangian function from J as L = 1
2
</p>
<p>u2 and the rate
</p>
<p>function from the state equation as f = &minus;3x + u. Hence the augmented Lagrangian
is
</p>
<p>L = 1
2
</p>
<p>u2 &minus; λ(x&prime; + 3x &minus; u),
</p>
<p>and the Hamiltonian is
</p>
<p>H = 1
2
</p>
<p>u2 + λ(u &minus; 3x).
</p>
<p>From the Euler&ndash;Lagrange equations (3.55), we then find
</p>
<p>&minus;3λ+ dλ
dt
</p>
<p>= 0, u + λ = 0, dx
dt
</p>
<p>+ 3x &minus; u = 0.
</p>
<p>Starting with the algebraic relation, we can eliminate the control in terms of the
</p>
<p>co-state, u = &minus;λ. The co-state equation for λ can then be re-expressed for u as
</p>
<p>du
</p>
<p>dt
= 3u =&rArr; u(t) = Ae3t,
</p>
<p>where A is a constant of integration. With this expression for u(t), the state equation
</p>
<p>becomes
dx
</p>
<p>dt
= &minus;3x + Ae3t &rArr; x(t) = Be&minus;3t + 1
</p>
<p>6
Ae3t,
</p>
<p>where B is a second constant of integration. Substituting x, u and λ into the Hamil-
</p>
<p>tonian yields
</p>
<p>H = 3AB = 0,
</p>
<p>so that either A or B is zero. The choice A = 0 returns the uncontrolled state,
and so we conclude that B = 0 and hence x(t) = 2e3t . Illustrating the dramatic
influence of the control, the optimal controlled solution is exponentially growing,
</p>
<p>whereas the uncontrolled solution is exponentially decaying. The optimal stopping
</p>
<p>time can then be obtained directly from the optimal solution for this simple problem
</p>
<p>as T&lowast; = 13 ln(5/2).
</p>
<p>3.9 Further Directions
</p>
<p>There is an extensive literature on both the theory and the applications of the calcu-
</p>
<p>lus of variations. Some good texts with additional introductory material and other
</p>
<p>advanced topics include [64, 66, 71, 84, 104]. Further texts also provide more rig-
</p>
<p>orous analysis [99]. Presentations of the applications of the calculus of variations in</p>
<p/>
</div>
<div class="page"><p/>
<p>74 3 Variational Principles
</p>
<p>mechanics [40, 62, 67] and other areas of applied physics, including electrostatics
</p>
<p>and quantum mechanics, [104] leading to ODE and PDE problems can also be found
</p>
<p>in many classic engineering and physics textbooks. There are also numerous books
</p>
<p>that present constrained optimisation and optimal control problems as extensions of
</p>
<p>the basic method of the calculus of variations [59, 62, 66, 71, 84, 99].
</p>
<p>While the introductory presentation in this chapter as focused on formulating prob-
</p>
<p>lems leading to ODEs, some of the exercises will show that PDEs can be derived
</p>
<p>similarly from multiple integrals. More challenging problems arise when assump-
</p>
<p>tions on the smoothness of solutions are removed, then optimal solutions may be
</p>
<p>composed of multiple piecewise-smooth sections that must satisfy appropriate con-
</p>
<p>nection conditions at transition points.
</p>
<p>3.10 Exercises
</p>
<p>3.1 Consider the functional for y(x) on 0 &le; x &le; 1,
</p>
<p>J =
&int; 1
</p>
<p>0
</p>
<p>1
2
(y&prime;)2 + k
</p>
<p>x
yy&prime; + x2y dx,
</p>
<p>where k is a constant
</p>
<p>(a) Determine the ODE for y&lowast;(x) by taking the variation of J .
(b) Show that the ODE can be also obtained directly from the Euler&ndash;Lagrange equa-
</p>
<p>tion (3.21).
</p>
<p>(c) For k = 0, determine y&lowast;(x) satisfying the boundary conditions y(0) = 1,
y(1) = 1.
</p>
<p>(d) For k = 2, determine y&lowast;(x) satisfying the boundary conditions y&prime;(0) = 1,
y(1) = 1. Show there is no solution that satisfies y(0) = 1.
</p>
<p>3.2 (The second derivative test) As in single- and multi-variable calculus, whether a
</p>
<p>critical point is a local maximum or minimum can be determined from the next term
</p>
<p>in the local expansion of the objective function. Recall the problem of minimising
</p>
<p>the arclength of the curve y = y(x), (3.10a),
</p>
<p>J =
&int; 1
</p>
<p>0
</p>
<p>&radic;
</p>
<p>1 + (y&prime;)2 dx, y(0) = 0, y(1) = b.
</p>
<p>Setting y(x) = y&lowast;(x)+ εh(x) and expanding J to O(ε) yielded the Euler&ndash;Lagrange
equation.
</p>
<p>(a) Continue the expansion of J to the O(ε2) term to obtain the second variation,
</p>
<p>δ2J .
</p>
<p>(b) Show that for this problem the solution y&lowast;(x) = bx is indeed a local minimiser
by showing that the second variation is positive for all h(x) �&equiv; 0.</p>
<p/>
</div>
<div class="page"><p/>
<p>3.10 Exercises 75
</p>
<p>Fig. 3.5 Exercise 3.3: An
</p>
<p>admissible trial solution in
</p>
<p>the form of a parametric
</p>
<p>curve
</p>
<p>(x̃(t), ỹ(t))
</p>
<p>10
</p>
<p>y
</p>
<p>x
</p>
<p>b
</p>
<p>3.3 Consider finding the shortest path between two points from among all possible
</p>
<p>smooth parametric curves in the xy plane x(t) = (x(t), y(t)) for 0 &le; t &le; T . Let the
curve start at (x, y) = (0, 0) at t = 0 and end at (x, y) = (1, b) at t = T for T fixed
(see Fig. 3.5). The functional for the arclength of the curve is
</p>
<p>J(x, y) =
&int; T
</p>
<p>0
</p>
<p>&radic;
</p>
<p>(x&prime;)2 + (y&prime;)2 dt.
</p>
<p>Show that the Euler&ndash;Lagrange equations for x, y give the parametric equations of the
</p>
<p>straight line found as the solution of (3.10a, 3.10b).
</p>
<p>3.4 For problems where the distance between two points is not given by the Euclid-
</p>
<p>ean distance, geodesics are curves giving the shortest path between two points.
</p>
<p>Consider the problem of determining a geodesic between two points on a surface
</p>
<p>z = F(x, y).
(a) For a parametric curve (x(t), y(t), z(t)) that minimises the arclength,
</p>
<p>J(x, y) =
&int; &radic;
</p>
<p>(x&prime;)2 + (y&prime;)2 + (z&prime;)2 dt,
</p>
<p>observe that the resulting Euler&ndash;Lagrange equations for (x(t), y(t)) are rather
</p>
<p>complicated, even if the surface is the simple paraboloid, z = k(x2 + y2).
(b) Show that even if we restrict the solutions to be functions, with y = y(x),
</p>
<p>the Euler&ndash;Lagrange equation for y(x) on the paraboloid is still a challenging
</p>
<p>nonlinear ODE for k �= 0.
(c) Consider the problem of finding the geodesic from (x, y) = (&minus;1, 0) to (1, 0)
</p>
<p>on the paraboloid. Determine the arclengths of the following trial solutions for
</p>
<p>k &ge; 0 (from geometry or by calculating the integral):</p>
<p/>
</div>
<div class="page"><p/>
<p>76 3 Variational Principles
</p>
<p>(i) the path along the x-axis,
</p>
<p>(ii) the semicircular path connecting the points.
</p>
<p>What can you infer about the geodesic from the limits k &rarr; 0 and k &rarr; &infin; of (i,
ii)?
</p>
<p>3.5 The Euler&ndash;Lagrange equations for constrained motion can be obtained by start-
</p>
<p>ing with the Lagrangian for general unconstrained motion and then substituting-in
</p>
<p>the parametric equations describing the geometric constraint (a curve or surface)
</p>
<p>before taking variations.
</p>
<p>(a) Consider the action integral for two-dimensional motion of a particle subject to
</p>
<p>gravity
</p>
<p>I =
&int;
</p>
<p>1
2
</p>
<p>m
[
</p>
<p>x&prime;(t)2 + y&prime;(t)2
]
</p>
<p>&minus; mgy(t) dt.
</p>
<p>Consider a particle constrained to be on a circle, x2+y2 = ℓ2. Derive the equation
of a pendulum by first plugging the parametric equations x(t) = ℓ sin θ(t),
y(t) = &minus;ℓ cos θ(t) into I and then applying the principle of least action with
respect to θ(t).
</p>
<p>(b) Repeat (a) for the motion of a particle constrained to the curve y = f (x).
(c) Consider the action integral for three-dimensional motion of a particle subject
</p>
<p>to gravity
</p>
<p>I =
&int;
</p>
<p>1
2
</p>
<p>m
[
</p>
<p>x&prime;(t)2 + y&prime;(t)2 + z&prime;(t)2
]
</p>
<p>&minus; mgz(t) dt
</p>
<p>Derive the equations of motion for a particle moving on the surface of a cone,
</p>
<p>x2 + y2 = z2, using the parametric equations x(t) = r(t) cos θ(t), y(t) =
r(t) sin θ(t) and z(t) = r(t).
</p>
<p>3.6 Consider a pendulum whose suspension point is vertically oscillated. Let the
</p>
<p>length of the pendulum be ℓ and its mass m. The acceleration due to gravity, g, is
</p>
<p>acting downward in the &minus;y direction. If the suspension point is oscillating according
to ȳ(t) = &minus;σ sin(ωt), then the position of the pendulum&rsquo;s mass is
</p>
<p>x(t) = ℓ sin θ(t), y(t) = &minus;σ sin(ωt)&minus; ℓ cos θ(t),
</p>
<p>where θ is measured from the &minus;y axis.
Write the Lagrangian for this system in terms of θ, θ &prime; and obtain the Euler&ndash;
</p>
<p>Lagrange equation for this problem, called the parametrically driven pendulum.
</p>
<p>3.7 Define the Hamiltonian, H, in terms of the Lagrangian L(t, y, y&prime;), through the
Legendre transform as
</p>
<p>H &equiv; &minus;L + y&prime; &part;L
&part;y&prime;
</p>
<p>. (3.58)
</p>
<p>(Note the opposite sign convention relative to (3.53).)</p>
<p/>
</div>
<div class="page"><p/>
<p>3.10 Exercises 77
</p>
<p>(a) If L is independent of time (i.e. L = L(y, y&prime;)) show that the Hamiltonian is
constant. (Hint: show that dH/dt = 0)
Further, show that for this case, the second-order Euler&ndash;Lagrange ODE (3.21)
</p>
<p>is equivalent to the first order ODE,
</p>
<p>&minus; L(y, y&prime;)+ y&prime; &part;L
&part;y&prime;
</p>
<p>= C, (3.59)
</p>
<p>where C is a constant (=H); this reduction of the Euler&ndash;Lagrange equation to
a first order equation is called the Beltrami identity, and is a special case of
</p>
<p>Noether&rsquo;s theorem [62].
</p>
<p>(b) If the potential energy V does not depend on y&prime;, determine the most general
form for the kinetic energy T(t, y, y&prime;) so that the Hamiltonian is the total energy,
H = T + V .
</p>
<p>3.8 (The brachistochrone) Recall the problem of finding the curve of least-time
</p>
<p>descent under gravity from (x, y) = (0, 1) &rarr; (1, 0), starting from rest (Fig. 3.1 and
Eq. (3.6)). We now complete the problem as follows:
</p>
<p>(a) Assuming there is no friction, the total mechanical energy, E = 1
2
</p>
<p>mv2 + mgy,
(where v2 = x&prime;(t)2 + y&prime;(t)2) remains constant, set by its initial value. Use this
to determine v(y) and complete the expression of the functional in (3.6).
</p>
<p>(b) Apply (3.21) to obtain the Euler&ndash;Lagrange second order ODE for y&lowast;(x).
(c) Noting that the integrand in (3.6) does not explicitly depend on x, use the Beltrami
</p>
<p>identity (3.59) to obtain a simpler first order ODE for y&lowast;(x). What is the value
of the constant C in this ODE?
</p>
<p>(d) Show that the solution can be expressed in parametric form by the equations of
</p>
<p>a cycloid with k &gt; 0 (see Fig. 3.6),
</p>
<p>x(θ) = k(θ &minus; sin θ), y(θ) = 1 &minus; k(1 &minus; cos θ). (3.60)
</p>
<p>What is the pair of equations that must be solved numerically to determine the
</p>
<p>value of k?
</p>
<p>Fig. 3.6 Exercise 3.8: The
</p>
<p>solution of the
</p>
<p>brachistochrone problem,
</p>
<p>given by the cycloid (3.60)
</p>
<p>g
</p>
<p>1
</p>
<p>1
</p>
<p>0</p>
<p/>
</div>
<div class="page"><p/>
<p>78 3 Variational Principles
</p>
<p>3.9 Consider the functional for y(x) on 1 &le; x &le; 2
</p>
<p>J(y) = 1
2
</p>
<p>&int; 2
</p>
<p>1
</p>
<p>[
</p>
<p>2y2 + x2
(
</p>
<p>dy
</p>
<p>dx
</p>
<p>)2
]
</p>
<p>dx.
</p>
<p>Find the solution y&lowast;(x) that minimises J and satisfies the boundary condition y(2) =
17. What is the natural boundary condition on y&lowast; at x = 1?
</p>
<p>3.10 Obtain the curve y = y&lowast;(x) on 0 &le; x &le; b&lowast; that starts at the origin, ends on the
curve y = 1 + (x &minus; 1)2, and minimises the functional
</p>
<p>J(y) = 1
2
</p>
<p>&int; b
</p>
<p>0
</p>
<p>(y&prime;)2 dx.
</p>
<p>3.11 (Higher-order Euler&ndash;Lagrange equations) Derive the Euler&ndash;Lagrange equa-
</p>
<p>tion for the functional
</p>
<p>J(y) =
&int; b
</p>
<p>a
</p>
<p>L(x, y(x), y&prime;&prime;(x)) dx
</p>
<p>Describe the kinds of natural boundary conditions that are needed.
</p>
<p>3.12 Consider the functional for y(x) on 0 &le; x &le; 1,
</p>
<p>J =
&int; 1
</p>
<p>0
</p>
<p>[
dy
</p>
<p>dx
</p>
<p>d3y
</p>
<p>dx3
&minus; 240xy
</p>
<p>]
</p>
<p>dx
</p>
<p>where y(x) satisfies the boundary conditions
</p>
<p>y&prime;(0) = 0, y&prime;&prime;(1) = 0, y&prime;&prime;&prime;(0) = 0, y(1) = 5.
</p>
<p>(a) Write the expression for the first variation, δJ .
</p>
<p>(b) Show that the critical point condition can be reduced to an ODE boundary value
</p>
<p>problem. Justify how each of the six boundary terms in δJ are eliminated. Solve
</p>
<p>the ODE problem for y&lowast;(x).
</p>
<p>3.13 Consider the functional for y(x) on 0 &le; x &le; 1,
</p>
<p>J =
&int; 1
</p>
<p>0
</p>
<p>[
</p>
<p>(y&prime;)2 + (1 &minus; 2x)
(&int; x
</p>
<p>0
</p>
<p>y2(t) dt
</p>
<p>)]
</p>
<p>dx.
</p>
<p>(a) Write the expression for the first variation, δJ .
</p>
<p>(b) Write the four possible boundary conditions on y(x) (two at each boundary)
</p>
<p>under which, the critical point condition, δJ = 0, can be reduced to an ODE for
y(x).</p>
<p/>
</div>
<div class="page"><p/>
<p>3.10 Exercises 79
</p>
<p>3.14 Consider the functional for y(x) on 0 &le; x &le; 1,
</p>
<p>J(y) =
&int; 1
</p>
<p>0
</p>
<p>[
</p>
<p>y
</p>
<p>(
d2y
</p>
<p>dx2
</p>
<p>)2
</p>
<p>+ y2
]
</p>
<p>dx + y&prime;(0)y&prime;(1)
</p>
<p>with y(x) satisfying the boundary conditions
</p>
<p>y(0) = 2, y(1) = 5.
</p>
<p>Determine the ODE boundary value problem for solutions that minimise or max-
</p>
<p>imise J .
</p>
<p>3.15 Fermat&rsquo;s principle of least time states that a beam of light will take a path
</p>
<p>that minimises its time of travel. The index of refraction, n, of a material gives the
</p>
<p>ratio of the speed of light in vacuum to the slowed speed of light in the material,
</p>
<p>n = c/v &ge; 1.
Consider a layer of glass on 0 &le; x &le; 1 whose index of refraction varies with
</p>
<p>position, n = n(x). Let y(x) describe the path of a beam of light entering the layer at
x = 0 at a 45◦ angle, y&prime;(0) = 1 (see Fig. 3.7 (left)).
(a) Making use of functional (3.6), derive the second-order ODE problem for y(x)
</p>
<p>and show it can be reduced to a first-order equation.
</p>
<p>(b) If n(x) is piecewise constant, n1 for x &lt;
1
2
</p>
<p>and n2 for x &gt;
1
2
</p>
<p>, show that part (a)
</p>
<p>reduces to Snell&rsquo;s law [91] (see Fig. 3.7 (right)).
</p>
<p>(c) What is the form of the Euler&ndash;Lagrange equation if n = n(x, y)?
</p>
<p>3.16 (The beam equation) Hamilton&rsquo;s principle of least action can be applied to
</p>
<p>derive the time-dependent partial differential equation for the transverse deflections
</p>
<p>y = u(x, t) of a flexible solid rod or beam. The problem for a one-dimensional beam
is characterised by the following properties:
</p>
<p>n = n(x)
</p>
<p>θ0
</p>
<p>x
</p>
<p>y
</p>
<p>10
</p>
<p>1
</p>
<p>0
</p>
<p>θ2
θ1
</p>
<p>n2n1
</p>
<p>θ0
</p>
<p>x
</p>
<p>y
</p>
<p>10
</p>
<p>1
</p>
<p>0
</p>
<p>Fig. 3.7 Exercise 3.15: (Left) diffraction of the path of a ray of light due the change of the index
</p>
<p>of refraction with position, n = n(x), (Right) The special case when n is piecewise constant</p>
<p/>
</div>
<div class="page"><p/>
<p>80 3 Variational Principles
</p>
<p>&bull; The length of the beam is ℓ (domain: 0 &le; x &le; ℓ) with constant mass density ρ
(mass per unit length), constant bending stiffness E (like a spring constant) and
</p>
<p>constant moment of inertia I .
</p>
<p>&bull; The overall total kinetic and potential energies of the beam are given by integrals
over the length of the beam of the corresponding energy density functions, e(u),
</p>
<p>E =
&int; ℓ
</p>
<p>0 e(u) dx.
</p>
<p>&bull; The kinetic energy density is 1
2
ρ(&part;tu)
</p>
<p>2.
</p>
<p>&bull; The potential energy density due to bending (i.e. transverse deflection or buckling)
is 1
</p>
<p>2
EI(&part;xxu)
</p>
<p>2.
</p>
<p>Follow these steps to derive the beam equation:
</p>
<p>(a) Write the integrals for the total kinetic T and potential V energies of the beam.
</p>
<p>(b) Write the action integral J(u). (Hint: J is a double integral)
</p>
<p>(c) Apply the principle of least action to derive the beam equation for u(x, t) and
</p>
<p>state the choices of natural boundary conditions for u at x = 0 and x = ℓ. Two
boundary conditions (out of 2 sets of 2 options for natural boundary conditions)
</p>
<p>are needed at each boundary.
</p>
<p>3.17 For a given positive function k(x, y) &gt; 0, consider the integral for the function
</p>
<p>u(x, y) on a finite two-dimensional domain D,
</p>
<p>J(u) =
&int;&int;
</p>
<p>D
</p>
<p>1
2
</p>
<p>k(x, y)
(
</p>
<p>u2x + u2y
)
</p>
<p>dy dx.
</p>
<p>Derive the partial differential equation for the solution u(x, y) and two appropriate
</p>
<p>forms of natural boundary conditions on u(x, y) that produce minima of J(u).
</p>
<p>If k is a constant, show that the PDE reduces to Laplace&rsquo;s equation.
</p>
<p>Hint: Recall the vector version of the derivative product (for the divergence of a
</p>
<p>scalar times a vector), &nabla; &middot; (f g) = (&nabla;f ) &middot; g + f (&nabla; &middot; g), and then make use of the
divergence theorem.
</p>
<p>3.18 How does the problem of minimising the arclength of a non-negative function
</p>
<p>y(x) &ge; 0 on 0 &le; x &le; 1 that encloses a fixed given area A =
&int; 1
</p>
<p>0 y dx relate to the
</p>
<p>isoperimetric example given in Sect. 3.6?
</p>
<p>3.19 Find the solution y(x) on 0 &le; x &le; π that minimises
</p>
<p>J(x) =
&int; π
</p>
<p>0
</p>
<p>1 + (y&prime;)2 dx subject to the constraint
&int; π
</p>
<p>0
</p>
<p>y2 dx = 80
</p>
<p>and boundary conditions y(0) = 0 and y(π) = 1.
(a) Write the augmented Lagrangian L for this problem. Determine the Euler&ndash;
</p>
<p>Lagrange problem and solve for y(x, λ) subject to the boundary conditions,
</p>
<p>where λ is the Lagrange multiplier.</p>
<p/>
</div>
<div class="page"><p/>
<p>3.10 Exercises 81
</p>
<p>(b) Evaluate the integral, I(λ) =
&int;
</p>
<p>y2 dx, as a function of λ. Plot this function and
</p>
<p>estimate the values of λ that yield solutions. If the integral constraint is required
</p>
<p>to equal one instead of 80, what happens to the solutions? What is the minimum
</p>
<p>value of I for which solutions exist?
</p>
<p>3.20 (The classic isoperimetric problem) This problem will lead you through deriv-
</p>
<p>ing that the circle is the closed curve of fixed perimeter P that encloses the maximum
</p>
<p>area:
</p>
<p>Let x(t), y(t) be the parametric equations for a closed curve with 0 &le; t &le; 1 that goes
through the origin:
</p>
<p>x(0) = x(1) = 0, y(0) = y(1) = 0.
</p>
<p>(a) Use Green&rsquo;s theorem to show that the area enclosed by the curve is given by
</p>
<p>1
</p>
<p>2
</p>
<p>&int; 1
</p>
<p>0
</p>
<p>[
</p>
<p>x(t)y&prime;(t)&minus; y(t)x&prime;(t)
]
</p>
<p>dt.
</p>
<p>Show that the augmented objective function
</p>
<p>L (x, y, λ) = 1
2
(xy&prime; &minus; yx&prime;)&minus; λ
</p>
<p>[&radic;
</p>
<p>(x&prime;)2 + (y&prime;)2 &minus; P
]
</p>
<p>,
</p>
<p>with J =
&int; 1
</p>
<p>0 L dt, defines the problem of maximising the area for a closed curve
</p>
<p>with perimeter P.
</p>
<p>(b) Obtain the Euler&ndash;Lagrange equations for x(t) and y(t).
</p>
<p>(c) Integrate each once with respect to t and show that they can be combined to yield
</p>
<p>the equation for a circle with the radius given in terms of |λ|.
(d) Determine λ so that the perimeter constraint is satisfied. Determine the possible
</p>
<p>positions for the centre of the circle.
</p>
<p>3.21 (Sturm-Liouville eigenvalue problems) For given functions p(x) &gt; 0 and q(x),
</p>
<p>show that the functional for y(x)
</p>
<p>I =
&int; 1
</p>
<p>0
</p>
<p>p(x)(y&prime;)2 &minus; q(x)y2 dx
</p>
<p>yields the Euler&ndash;Lagrange equation
</p>
<p>d
</p>
<p>dx
</p>
<p>(
</p>
<p>p(x)
dy
</p>
<p>dx
</p>
<p>)
</p>
<p>+ q(x)y = 0.
</p>
<p>For homogeneous boundary conditions on y(x), the trivial solution y(x) &equiv; 0, is a
critical point for all p, q. Show that seeking nontrivial critical points of I satisfying
</p>
<p>the normalisation condition,
&int; 1
</p>
<p>0
</p>
<p>y2σ(x) dx = 1,</p>
<p/>
</div>
<div class="page"><p/>
<p>82 3 Variational Principles
</p>
<p>for a given weight function σ(x) &gt; 0, yields the Sturm-Liouville equation
</p>
<p>d
</p>
<p>dx
</p>
<p>(
</p>
<p>p(x)
dy
</p>
<p>dx
</p>
<p>)
</p>
<p>+ (q(x)+ λσ(x))y = 0,
</p>
<p>where λ are eigenvalues and y(x) are the corresponding eigenfunctions.
</p>
<p>3.22 (The pendulum revisited) Consider again, the action integral for motion of a
</p>
<p>point mass in two dimensions subject to gravity (recall Exercise 3.5(a)),
</p>
<p>I =
&int;
</p>
<p>1
2
</p>
<p>m
[
</p>
<p>x&prime;(t)2 + y&prime;(t)2
]
</p>
<p>&minus; mgy(t) dt.
</p>
<p>Suppose that the mass is constrained to move on the circle, x2 + y2 = ℓ2. Consider
this as a problem with a holonomic constraint. Write the Euler&ndash;Lagrange equations
</p>
<p>for x(t), y(t). Note that the Lagrange multiplier appearing in these equations can be
</p>
<p>interpreted as a force required to keep the mass on the circle. Show that the equations
</p>
<p>can be reduced to the pendulum equation for θ(t).
</p>
<p>3.23 Consider the problem of finding a locally optimal solution of the functional
</p>
<p>J =
&int; 2
</p>
<p>1
</p>
<p>[
</p>
<p>6y2 + x2
(
</p>
<p>dy
</p>
<p>dx
</p>
<p>)2
</p>
<p>+ x7
]
</p>
<p>dx
</p>
<p>subject to the conditions that
</p>
<p>y(2) = y(1)+ 3,
&int; 2
</p>
<p>1
</p>
<p>24xy dx = 5.
</p>
<p>(a) Write the augmented functional for the constrained optimisation problem.
</p>
<p>(b) Determine the natural boundary condition that allows the critical point condition
</p>
<p>to be reduced to an ODE problem.
</p>
<p>(c) Write the general solution of the ODE (homogeneous and particular terms) and
</p>
<p>the system of equations to determine the three constants in your solution.
</p>
<p>3.24 Find the locally optimum solution of the functional
</p>
<p>J =
&int; 2
</p>
<p>1
</p>
<p>[
3y2
</p>
<p>x5
&minus; (y
</p>
<p>&prime;)2
</p>
<p>x3
</p>
<p>]
</p>
<p>dx
</p>
<p>subject to the conditions that
</p>
<p>y(1) = 4, y(2) = &minus;10,
&int; 2
</p>
<p>1
</p>
<p>y dx = &minus;3.</p>
<p/>
</div>
<div class="page"><p/>
<p>3.10 Exercises 83
</p>
<p>3.25 The Pontryagin Maximum Principle (PMP)9 is a classic result from optimal
</p>
<p>control theory. For the classic optimal control problem (3.44) the PMP states that
</p>
<p>the equations for the optimal solution can be very concisely given in terms of the
</p>
<p>Hamiltonian, H = L + λf ,
</p>
<p>dx
</p>
<p>dt
= &part;H
</p>
<p>&part;λ
,
</p>
<p>dλ
</p>
<p>dt
= &minus;&part;H
</p>
<p>&part;x
,
</p>
<p>&part;H
</p>
<p>&part;u
= 0,
</p>
<p>Subject to H (T&lowast;) = 0. Show that these equations reproduce (3.55) and these equa-
tions are consistent with the Hamiltonian being a constant for all times. (Hint: Apply
</p>
<p>the chain rule to evaluate dH /dt)
</p>
<p>3.26 Determine the solution x(t) and the control function u(t) that satisfy the state
</p>
<p>equation
dx
</p>
<p>dt
= 3x + u 0 &le; t &le; T
</p>
<p>with initial and final conditions
</p>
<p>x(0) = 2, x(T) = 1,
</p>
<p>while minimising the cost functional
</p>
<p>J =
&int; T
</p>
<p>0
</p>
<p>(
</p>
<p>4x2 + 3xu + u2
)
</p>
<p>dt.
</p>
<p>(a) Use the Pontryagin principle from Exercise 3.25 for the case where the final time
</p>
<p>is the optimal stopping time T = T&lowast;.
(b) If instead the final time is specified as T = 1/4, what is the optimal solution?
</p>
<p>What is the value of the Hamiltonian?
</p>
<p>3.27 (The brachistochrone revisited) Recall Exercise 3.5(b), where we determined
</p>
<p>that the equation of motion for the horizontal position x(t) of a particle sliding down
</p>
<p>a ramp y = f (x) under the influence of gravity is
</p>
<p>d
</p>
<p>dt
</p>
<p>(
</p>
<p>[1 + f &prime;(x)2]dx
dt
</p>
<p>)
</p>
<p>= &minus;gf &prime;(x)+ f &prime;(x)f &prime;&prime;(x)
(
</p>
<p>dx
</p>
<p>dt
</p>
<p>)2
</p>
<p>.
</p>
<p>Use this result applied to functions satisfying the boundary conditions f (0) = 1
and f (1) = 0 to show that the brachistochrone problem can be expressed as an
optimal control problem on f subject to minimising travel time T for a particle
</p>
<p>satisfying x(0) = 0 and x(T) = 1. Write a Lagrangian analogous to (3.47) and the
corresponding functional to determine the Euler&ndash;Lagrange problem.
</p>
<p>9Sometimes called the Pontryagin minimum principle, depending on the choice of sign convention
</p>
<p>used for H versus H , recall page 71.</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 4
</p>
<p>Dimensional Scaling Analysis
</p>
<p>&ldquo;Back of the envelope calculations&rdquo; are simple algebraic calculations that can fit
</p>
<p>into a small space but provide substantial guidance on understanding problems. Such
</p>
<p>calculations are often based on dimensional analysis, which identifies the relations
</p>
<p>between system properties that must be present in a problem due to the fundamental
</p>
<p>types of the properties being considered. It is valuable to understand that insight
</p>
<p>on how a system can be expected to behave can be obtained from interpretation of
</p>
<p>appropriate products of the parameters characterising the problem.
</p>
<p>One simple type of dimensional analysis result, sometimes called aFermi estimate,
</p>
<p>provides predictions based on products of dimensional rates, as in the number of
</p>
<p>widgets produced in a year = (number of widgets produced per day) &times; (number
of work-days per week) &times; (average number of weeks per month) &times; (months per
year). This result does not take account of the details of the problem, but gives an
</p>
<p>order of magnitude estimate of the expected number. Dimensional analysis can not
</p>
<p>replace detailed solutions of problems, but it can provide a guide for comparison
</p>
<p>with expectations and identification of important influences in problems.
</p>
<p>In this chapter, our focus will be on the use of dimensional analysis to nondimen-
</p>
<p>sionalise entire problems in order to provide simplified re-statements of the problems
</p>
<p>that identify a reduced (minimal) number of essential parameters that solutions should
</p>
<p>depend on. We will illustrate the use of dimensional analysis through its application
</p>
<p>to a set of examples before discussing the Buckingham Pi theorem, which gives a
</p>
<p>mathematical framework to support the results of the elementary scaling calculations.
</p>
<p>4.1 Dimensional Quantities
</p>
<p>Every physical quantity Q can be expressed as the product of a dimensional unit,
</p>
<p>denoted here by [Q] (describing the physical nature of a single &lsquo;portion&rsquo; or unit of the
quantity), and a magnitude q (the number of portions), i.e. Q = q[Q]. For example,
mass can be measured in dimensional units of kilograms, weight in pounds, volume
</p>
<p>in litres, data in gigabytes, frequency in megahertz, length in meters, time in seconds,
</p>
<p>&copy; Springer International Publishing Switzerland 2015
</p>
<p>T. Witelski and M. Bowen, Methods of Mathematical Modelling,
</p>
<p>Springer Undergraduate Mathematics Series, DOI 10.1007/978-3-319-23042-9_4
</p>
<p>85</p>
<p/>
</div>
<div class="page"><p/>
<p>86 4 Dimensional Scaling Analysis
</p>
<p>temperature in degrees Kelvin, and so on. These choices are not unique: Q = 1 mile
= 1,760 yd = 5,280 ft = 63,360 in = 160,934.4 cm = 1.7011 &times; 10&minus;13 light years;
all of these are equivalent descriptions of the same length with respect to different
</p>
<p>units of measure and different corresponding magnitudes.
</p>
<p>The choice of dimensional units for measurements should be appropriate to the
</p>
<p>problem under consideration. For example, it would be very inconvenient to measure
</p>
<p>interplanetary distances in feet (the magnitudes involved being literally astronomi-
</p>
<p>cally large) or to record the size of a bacterial swarm in kilometers. Having to deal
</p>
<p>with very large (or very small) numbers is not only cumbersome, but the analysis in
</p>
<p>some later chapters will crucially rely on separating small from large quantities and
</p>
<p>a bad choice of measurement scales can obscure this process.
</p>
<p>4.1.1 The SI System of Base Units
</p>
<p>In many everyday physical problems, it is reasonable to employ dimensional units
</p>
<p>of meters for displacement ([Length] = meters), kilograms for mass ([Mass] =
kilograms), and seconds for time ([Time] = seconds). This is a standard set of units1
forming part of what is known as the International System (SI) of Base Units used for
</p>
<p>quantifying distinct physical properties. The seven fundamental (base) dimensional
</p>
<p>units that make up the SI system are [97]
</p>
<p>[Length] = meter, [Time] = second, [Mass] = kilogram, (4.1)
[Temperature] = Kelvin, [Electric current] = ampere,
</p>
<p>[Light intensity] = candela, [Material quantity] = mole.
</p>
<p>These dimensional units are fundamental in the sense that they describe independent
</p>
<p>physical properties that cannot be represented in terms of each other. Dimensional
</p>
<p>units that can be expressed in terms of the fundamental units are known as derived
</p>
<p>units. For example, [speed] = meter/second, [acceleration] = meter/second2, and
[force] = kilogram&middot;meter/second2. The most commonly occurring derived units are
given their own names for convenience, such as [force] = newton, [pressure] =
pascal, and [energy] = joule. For some problems, it can be convenient to express
quantities with respect to different sets of base units, those of easily-measurable
</p>
<p>properties, for example, in terms of the pressure of a gas, [force] = [pressure][area].
Derived dimensional units are products of powers the fundamental units
</p>
<p>[Q] = [Length]α[Time]β[Mass]γ . . . .
</p>
<p>This result also extends to products of quantities, [Q21Q2] = [Q1]2[Q2].
</p>
<p>1Also called the MKS system from Meters, Kilograms, Seconds.</p>
<p/>
</div>
<div class="page"><p/>
<p>4.1 Dimensional Quantities 87
</p>
<p>In what follows, in order to emphasise that it is the nature of a quantity (length,
</p>
<p>mass, time and so on) that we are interested in rather than its representation in a
</p>
<p>particular system of base units, we will simply talk about the quantity&rsquo;s dimensions
</p>
<p>instead of explicitly referring to dimensional units.
</p>
<p>4.2 Dimensional Homogeneity
</p>
<p>The principle of dimensional homogeneity states the intuitive result that all terms
</p>
<p>summed to yield an equation modelling a system must have the same dimensions.
</p>
<p>For example, sums of forces in Newton&rsquo;s second law, or sums of electrical currents
</p>
<p>in Kirichoff&rsquo;s law, or sums and differences of amounts of money in accounting
</p>
<p>calculations. In contrast, it not valid to add a velocity to an acceleration, or a time to
</p>
<p>a mass.
</p>
<p>An immediate consequence is that any complicated (non-monomial) function,
</p>
<p>such as sin, exp, tan, log, and generally any f (X) �= αXβ , must have dependent-
arguments (variables) that are dimensionless. Namely the dimensional units in the
</p>
<p>variables must cancel-out identically. To see why this must be true, consider writing
</p>
<p>the exponential function in terms of its Taylor series expansion
</p>
<p>eX = 1 + X + 1
2
X2 + &middot; &middot; &middot; + 1
</p>
<p>n!X
n + &middot; &middot; &middot; .
</p>
<p>If X was not dimensionless, then each term in the Taylor expansion would have
</p>
<p>different dimensions thereby violating the principle of dimensional homogeneity;
</p>
<p>here all terms must have the same units as the first term in the expansion, [1] which
</p>
<p>is dimensionless. We note that variables representing angles are dimensionless, as in
</p>
<p>the formula for the arclength of circle, S = Rθ, [length] = [length][dimensionless].
As an illustrative example of dimensional homogeneity, consider the motion of a
</p>
<p>vertically launched projectile. If we denote Y as the projectile&rsquo;s height (with initial
</p>
<p>height Y0), T as the time passed, V0 as the initial velocity, and A0 as a constant
</p>
<p>acceleration (typically gravity), the equation of motion for the projectile is simply a
</p>
<p>quadratic form in T
</p>
<p>Y = Y0 + V0T + 12 A0T
2.
</p>
<p>Expressed in terms of its dimensions, we see that each term has the same dimensions,
</p>
<p>namely
</p>
<p>[Length] = [Length] +
[
</p>
<p>Length
</p>
<p>Time
</p>
<p>]
</p>
<p>[Time] +
[
</p>
<p>Length
</p>
<p>Time2
</p>
<p>]
</p>
<p>[Time2].</p>
<p/>
</div>
<div class="page"><p/>
<p>88 4 Dimensional Scaling Analysis
</p>
<p>4.3 The Process of Nondimensionalisation
</p>
<p>The importance of dimensional homogeneity lies in the realisation that as each term
</p>
<p>in an equation must have the same dimensions, we can scale all dependent and
</p>
<p>independent variables by dimensional constants to yield dimensionless equations.
</p>
<p>Effectively, this means that the dimensional units have been factored out of the orig-
</p>
<p>inal problem, leaving a &ldquo;clean&rdquo; mathematical system in terms of only dimensionless
</p>
<p>magnitudes and dimensionless parameters.
</p>
<p>The dimensions of the scaling constants are predetermined by dimensional homo-
</p>
<p>geneity, but we have the freedom to select their magnitudes in order to obtain &lsquo;con-
</p>
<p>venient forms&rsquo; of the nondimensional model that will be better-suited for further
</p>
<p>mathematical analysis.
</p>
<p>In the following examples, we will introduce standard conventions on how to
</p>
<p>select dimensionless parameters as well as highlighting further consequences of
</p>
<p>dimensional analysis.
</p>
<p>4.3.1 Projectile Motion
</p>
<p>Consider a projectile of mass M kilograms that is launched vertically with initial
</p>
<p>speed V0 m/s, from a position Y0 meters above the surface of the Earth. Newton&rsquo;s
</p>
<p>universal law of gravitation coupled with the second law of motion then gives that the
</p>
<p>height of the projectile Y(T) varies with time T according to the ordinary differential
</p>
<p>equation
</p>
<p>M
d2Y
</p>
<p>dT2
= &minus; GMEM
</p>
<p>(RE + Y)2
, Y(0) = Y0, Y&prime;(0) = V0, (4.2)
</p>
<p>where the Earth&rsquo;s properties (mass and radius) are ME = 6 &times; 1024 kg and RE =
6.4 &times; 106 m, and the universal gravitational constant G = 6.7 &times; 10&minus;11 m3/(s2 kg).
We begin by noting that the parameters G and ME only occur as a product and so
</p>
<p>can only appear in the solution in the same form. Consequently, we can regard this
</p>
<p>combination as a single parameter and replace it using g = GME/R2E &asymp; 9.81 m/s2,
this being the familiar value for acceleration due to gravity at the Earth&rsquo;s surface.
</p>
<p>The problem then takes the form
</p>
<p>M
d2Y
</p>
<p>dT2
= &minus;
</p>
<p>gR2EM
</p>
<p>(RE + Y)2
, Y(0) = Y0, Y&prime;(0) = V0. (4.3)
</p>
<p>We now introduce the (as yet arbitrary) length and time scales, L and T,
</p>
<p>Y(T) = Ly(t), T = Tt, (4.4)</p>
<p/>
</div>
<div class="page"><p/>
<p>4.3 The Process of Nondimensionalisation 89
</p>
<p>so that y and t are dimensionless variables. The scaling constants (L and T) for the
</p>
<p>different independent dimensional quantities in a problem (here, length and time)
</p>
<p>are called the characteristic scales.
</p>
<p>Substituting into (4.3) yields the rescaled problem
</p>
<p>L
</p>
<p>T2
d2y
</p>
<p>dt2
= &minus;g 1(
</p>
<p>1 +
(
</p>
<p>L
RE
</p>
<p>)
</p>
<p>y
)2
</p>
<p>, Ly(0) = Y0,
L
</p>
<p>T
y&prime;(0) = V0.
</p>
<p>Dividing through each expression by the dimensional coefficient of the first term on
</p>
<p>the left-hand-side yields the nondimensionalised problem
</p>
<p>d2y
</p>
<p>dt2
= &minus;
</p>
<p>(
gT2
</p>
<p>L
</p>
<p>)
</p>
<p>︸ ︷︷ ︸
</p>
<p>Π1
</p>
<p>1
⎛
</p>
<p>⎜
⎜
⎜
⎝
</p>
<p>1 +
(
</p>
<p>L
</p>
<p>RE
</p>
<p>)
</p>
<p>︸ ︷︷ ︸
</p>
<p>Π2
</p>
<p>y
</p>
<p>⎞
</p>
<p>⎟
⎟
⎟
⎠
</p>
<p>2
, y(0) =
</p>
<p>(
Y0
</p>
<p>L
</p>
<p>)
</p>
<p>︸ ︷︷ ︸
</p>
<p>Π3
</p>
<p>, y&prime;(0) =
(
</p>
<p>V0T
</p>
<p>L
</p>
<p>)
</p>
<p>︸ ︷︷ ︸
</p>
<p>Π4
</p>
<p>,
</p>
<p>(4.5)
</p>
<p>where theΠi are nondimensional constants. It is important to realise that such dimen-
</p>
<p>sionless parameters always represent the ratio of two competing effects. For example,
</p>
<p>Π1 represents the relative importance of gravitational acceleration versus the accel-
</p>
<p>eration of the projectile, Π1 = g/(L/T2). Likewise, Π2 compares the length scale
of interest to the Earth&rsquo;s radius, Π2 = L/RE.
</p>
<p>We have the freedom to choose the length and time scales L and T to scale the
</p>
<p>problem into a desired form; here we describe one such form. Selecting the length
</p>
<p>scale L = Y0 sets Π3 = 1, while choosing a timescale based on acceleration due
to gravity, T = (L/g)1/2, fixes Π1 = 1. Through (4.4), the selection of L and T
gives the respective units of measure that all lengths and times in the problem will
</p>
<p>be calibrated against. Characteristics scales given directly by a single given quantity
</p>
<p>from the original problem (here L = Y0) are sometimes called imposed scales. Scales
obtained from combinations of given quantities (here T in terms of Y0 and g) are
</p>
<p>called derived scales.
</p>
<p>We note that there are, in fact, many possible scaling choices as we could, for
</p>
<p>example, multiply either (or both) of the length or time scales by some function
</p>
<p>f (Y0/RE) and the resulting equation would still be nondimensional. However, it
</p>
<p>turns out that the normalised forms are often the most convenient choices.
</p>
<p>We have employed what we shall refer to as
</p>
<p>The 1st general nondimensional scaling principle:
</p>
<p>Select the characteristic scales so that as many as
</p>
<p>possible of the Π &rsquo;s are normalised.
</p>
<p>(4.6)</p>
<p/>
</div>
<div class="page"><p/>
<p>90 4 Dimensional Scaling Analysis
</p>
<p>For the current example, the nondimensionalised model takes the simplified form
</p>
<p>d2y
</p>
<p>dt2
= &minus; 1
</p>
<p>(1 +Π2y)2
, y(0) = 1, y&prime;(0) = Π4. (4.7a)
</p>
<p>with
</p>
<p>Π2 =
L
</p>
<p>RE
= Y0
</p>
<p>RE
, Π4 =
</p>
<p>V0T
</p>
<p>L
= V0
</p>
<p>(gY0)1/2
. (4.7b)
</p>
<p>The solution of (4.7a) will be a function of the independent variable t and the remain-
</p>
<p>ing nondimensional constants Π2 and Π4, namely
</p>
<p>y = y(t,Π2,Π4),
</p>
<p>or equivalently,
</p>
<p>Y = Y0y(t,Π2,Π4), T = (Y0/g)1/2t,
</p>
<p>in contrast to the solution of the original problem (4.3) which takes the general form
</p>
<p>Y = Y(T,g,RE,Y0,V0).
</p>
<p>We have effectively reduced the complexity of the original problem (involving a
</p>
<p>solution function of five variables) to a solution depending on only three variables.
</p>
<p>As will be discussed further, nondimensionalization allows us to examine different
</p>
<p>limiting forms of problems in a mathematically precise framework. Consider the
</p>
<p>limit Π2 = Y0/RE &rarr; 0 in the model (4.7). At first sight, this limit may appear
to describe increasing the radius of the Earth (RE &rarr; &infin;), or decreasing the initial
height (Y0 &rarr; 0), or both. For the limit RE &rarr; &infin; (with Y0 fixed), we can formally
set Π2 = 0 to reduce (4.7a) to a simpler ODE that can be easily solved,
</p>
<p>d2y
</p>
<p>dt2
= &minus;1 =&rArr; y(t) = 1 +Π4t &minus; 12 t
</p>
<p>2.
</p>
<p>This solution can be interpreted as a first approximation to the motion of a projectile
</p>
<p>that is launched relatively close to the surface of a large-radius planet with the same
</p>
<p>gravity as the Earth. Undoing the nondimensional scaling (4.4) converts this to the
</p>
<p>dimensional form of the classic quadratic polynomial for projectile motion,
</p>
<p>Y = Y0 + V0T &minus; 12 gT
2.
</p>
<p>However if we consider the limit Y0 &rarr; 0 (with RE fixed) then Π4 &rarr; &infin;; this is not
acceptable as a value of for the initial condition on y&prime;(0) and forces us to question
whether we have selected an appropriate choice of characteristic scales.
</p>
<p>In fact, if scalings yield any undefined terms in a non-dimensionalized model,
</p>
<p>then that model in that form will not be solvable. This points to the need to change
</p>
<p>the scalings to put the model into a well-defined form, which we express as</p>
<p/>
</div>
<div class="page"><p/>
<p>4.3 The Process of Nondimensionalisation 91
</p>
<p>The 2nd general nondimensional scaling principle:
</p>
<p>Select characteristic scales so that NO terms in
</p>
<p>the model diverge in the physical limit of interest.
</p>
<p>(4.8)
</p>
<p>The choice of scales is determined once the sub-set of Π &rsquo;s to be normalised is
</p>
<p>made; hence other choices correspond to picking different Π &rsquo;s. For problems with k
</p>
<p>characteristic scales, the scales will be determined from normalising k Π &rsquo;s; this will
</p>
<p>be discussed further in connection with the Buckingham Pi theorem, see Sect. 4.5.
</p>
<p>To examine the Y0 &rarr; 0 limit, consider setting Π1 = 1 and Π4 = 1 in (4.5). The
length and time scales are then L = V20/g and T = V0/g. The revised form of the
nondimensionalised problem is
</p>
<p>d2y
</p>
<p>dt2
= &minus; 1
</p>
<p>(1 + Π̃2y)2
, y(0) = Π̃3, y&prime;(0) = 1. (4.9a)
</p>
<p>Π̃2 =
L
</p>
<p>RE
= V
</p>
<p>2
0
</p>
<p>gRE
, Π̃3 =
</p>
<p>Y0
</p>
<p>L
= Y0g
</p>
<p>V20
. (4.9b)
</p>
<p>This choice of scalings satisfies (4.8) since setting Y0 = 0 sets Π̃3 = 0 but does not
cause any other parameters in the problem to diverge,
</p>
<p>d2y
</p>
<p>dt2
= &minus; 1
</p>
<p>(1 + Π̃2y)2
, y(0) = 0, y&prime;(0) = 1.
</p>
<p>If we further specify that RE &rarr; &infin; then Π̃2 = 0 and the ODE reduces to y&prime;&prime; = &minus;1
yielding the solution
</p>
<p>y(t) = &minus; 1
2
t2 + t =&rArr; Y = V0T &minus; 12 gT
</p>
<p>2.
</p>
<p>For V0 &gt; 0 the time of flight of the projectile is clearly seen to be 2V0/g while the
</p>
<p>maximum height reached is V20/(2g), both of which are directly proportional to the
</p>
<p>scales that we chose.
</p>
<p>4.3.2 Terminal Velocity of a Falling Sphere in a Fluid
</p>
<p>We now consider further aspects of scaling in nondimensionalizing another example
</p>
<p>from physics&mdash;describing the motion of a solid ball with a given initial velocity
</p>
<p>moving vertically downward through a viscous fluid.
</p>
<p>The ball has radius R m and uniform density ρ kg/m3 (so that the mass of the ball
</p>
<p>is given by M = 4
3
πR3ρ). The initial speed of the ball is taken to be V0 m/s. The</p>
<p/>
</div>
<div class="page"><p/>
<p>92 4 Dimensional Scaling Analysis
</p>
<p>fluid has a different density, ρ f and its viscosity is &micro; kg/m s, which gives a measure
</p>
<p>of the frictional resistance to the ball moving through the fluid.
</p>
<p>Noting that the forces acting on the ball are due to its weight, buoyancy and the
</p>
<p>drag of the fluid, we can use Newton&rsquo;s second law to write down a force balance
</p>
<p>M
dV
</p>
<p>dT
= Mg &minus; Fbuoy &minus; Fdrag, V(0) = V0,
</p>
<p>where we have expressed the acceleration as the derivative of the ball&rsquo;s velocity. The
</p>
<p>magnitude of the buoyancy force is given by the weight of the fluid displaced by the
</p>
<p>ball, Fbuoy = 43πR3ρ f g, while the frictional force acting on a sphere is given by
Fdrag = 6π&micro;RV, a classic result derived by Stokes.
</p>
<p>Consequently, the problem can be restated as
</p>
<p>4
</p>
<p>3
πR3ρ
</p>
<p>dV
</p>
<p>dT
= 4
</p>
<p>3
πR3ρg &minus; 4
</p>
<p>3
πR3ρ f g &minus; 6π&micro;RV. (4.10)
</p>
<p>Introducing the nondimensionalization, V(T) = Vv(t) with T = Tt , where V and T
are characteristic scales for speed and time yields the nondimensional model
</p>
<p>dv
</p>
<p>dt
=
</p>
<p>(
(ρ&minus; ρ f )gT
</p>
<p>ρV
</p>
<p>)
</p>
<p>︸ ︷︷ ︸
</p>
<p>Π1
</p>
<p>&minus;
(
</p>
<p>9&micro;T
</p>
<p>2ρR2
</p>
<p>)
</p>
<p>︸ ︷︷ ︸
</p>
<p>Π2
</p>
<p>v, v(0) =
(
</p>
<p>V0
</p>
<p>V
</p>
<p>)
</p>
<p>︸ ︷︷ ︸
</p>
<p>Π3
</p>
<p>. (4.11)
</p>
<p>Setting Π1 = 1 and Π3 = 1 yields the characteristic scales
</p>
<p>V = V0, T =
ρV0
</p>
<p>(ρ&minus; ρ f )g
, (4.12)
</p>
<p>and the nondimensionalized problem reads:
</p>
<p>dv
</p>
<p>dt
= 1 &minus; St v, v(0) = 1, (4.13)
</p>
<p>where the Π2 group has been renamed the Stokes parameter
</p>
<p>St = 9&micro;V0
2(ρ&minus; ρ f )gR2
</p>
<p>. (4.14)
</p>
<p>The &ldquo;Stokes parameter&rdquo; name attached to Π2 is a historical label used for this
</p>
<p>dimensionless parameter, but this classification has important value since it makes
</p>
<p>it easier to search for other results on related problems involving this parameter in
</p>
<p>books, journals, and other sources. Hence dimensionless parameters make it possi-
</p>
<p>ble to universally compare results from different studies (experiments, simulations,
</p>
<p>and theory) and communicate in a common terminology across many branches of</p>
<p/>
</div>
<div class="page"><p/>
<p>4.3 The Process of Nondimensionalisation 93
</p>
<p>Table 4.1 A few commonly used dimensionless parameters
</p>
<p>Name Formula Competing effects Area of study
</p>
<p>Arrhenius E/(RT) Activation/potential energy Thermodynamics
</p>
<p>Damkohler kL/(UC0) Reaction/transport rates Thermodynamics
</p>
<p>Lewis DT /DM Thermal/mass diffusivity Thermodynamics
</p>
<p>Mach V/c Char. speed/sound speed Aerodynamics
</p>
<p>Peclet UL/D Convection/diffusion Thermodynamics
</p>
<p>Reynolds ρUL/&micro; Inertia/viscosity Fluid dynamics
</p>
<p>Stokes (4.14) Drag/gravity Fluid dynamics
</p>
<p>science and engineering. See Table 4.1 for a short list of some of the many other
</p>
<p>named parameters, also see [69].
</p>
<p>The nondimensionalized problem (4.13) has an explicit solution which conse-
</p>
<p>quently depends only on t and the single St parameter:
</p>
<p>v(t,St) = 1
St
</p>
<p>(
</p>
<p>1 &minus; e&minus;t St
)
</p>
<p>+ e&minus;t St. (4.15)
</p>
<p>The solution of the original dimensional problem can then be written in terms of
</p>
<p>(4.15) and (4.12) as
</p>
<p>V(T) = V0v(t/T,St)
</p>
<p>= V0
St
</p>
<p>+ V0
(
</p>
<p>1 &minus; 1
St
</p>
<p>)
</p>
<p>exp
</p>
<p>(
</p>
<p>&minus;St (ρ&minus; ρ f )g
ρV0
</p>
<p>t
</p>
<p>)
</p>
<p>= 2(ρ&minus; ρ f )gR
2
</p>
<p>9&micro;
</p>
<p>(
</p>
<p>1 &minus; e&minus;
9&micro;
</p>
<p>2ρR2
t
)
</p>
<p>+ V0e
&minus; 9&micro;
</p>
<p>2ρR2
t
. (4.16)
</p>
<p>The last expression is what would have been obtained from solving (4.10) directly.
</p>
<p>As should be expected, its functional form is equivalent to (4.15), but (4.16) makes
</p>
<p>it difficult to see that the solution is actually only dependent on a single parameter.
</p>
<p>Having (4.13) in a less cumbersome form than (4.10) facilitates using it to identify
</p>
<p>the steady state as v = 1/St; this represents the &ldquo;terminal&rdquo; free-fall velocity in this
problem (V0/St= 2(ρ&minus; ρ f )gR2/(9&micro;) in dimensional form).
</p>
<p>Here, as in most problems, the dimensionless parameters more efficiently and
</p>
<p>compactly capture the dependence of key properties of the system on its design para-
</p>
<p>meters. In addition, if this model had been compared against experimental data for
</p>
<p>V = V(T,R,V0, ρ f , ρ,&micro;,g) then while the data could involve many experiments
varying the six parameters, Eq. (4.16) shows that all of that data could be captured
</p>
<p>by the two characteristic scales and the Stokes parameter. Dramatic reduction in
</p>
<p>re-organising data to show its underlying fundamental structure is often called col-
</p>
<p>lapsing of data, namely when many data points from different runs are all shown to
</p>
<p>fall on universal curves.</p>
<p/>
</div>
<div class="page"><p/>
<p>94 4 Dimensional Scaling Analysis
</p>
<p>In (4.11), the ODE was normalised by the coefficient of the inertial term, making
</p>
<p>Π1 the ratio of buoyancy to inertial effects and Π2 the ratio of drag to inertial effects
</p>
<p>for given V,T. Setting the V,T characteristic scales to normalise Π1,Π3 = 1 gives
a formula for St in terms of given quantities (4.14) which embodies this ratio,
</p>
<p>St = 9&micro;V0
2(ρ&minus; ρ f )gR2
</p>
<p>= 6π&micro;RV0
4
3
πR3(ρ&minus; ρ f )g
</p>
<p>= drag force
net gravity force
</p>
<p>, (4.17)
</p>
<p>We want to re-iterate the very important point that all dimensionless parameters are
</p>
<p>ratios of competing effects in models. This is a consequence of all Π &rsquo;s being formed
</p>
<p>by dividing equations in the model by scaling coefficients for the influence of one
</p>
<p>term. In general,
</p>
<p>Π = strength of effect 1
strength of effect 2
</p>
<p>. (4.18)
</p>
<p>The limiting cases of such ratios have clear interpretations:
</p>
<p>&bull; Π &rarr; 0: effect 1 is very weak (relative to effect 2).
&bull; Π &rarr; &infin;: effect 1 is very strong (relative to effect 2).
</p>
<p>Between these extremes other special critical values Πc can exist that separate
</p>
<p>different qualitative regimes for the solution&rsquo;s behaviour. The model (4.13) has a
</p>
<p>critical Stokes number of Stc = 1:
&bull; For St &lt; 1 solutions describe balls starting from lower speeds, that will accelerate
</p>
<p>up to the terminal velocity.
</p>
<p>&bull; For St &gt; 1 solutions represent balls starting from speed highers than the terminal
velocity decelerating for all times.
</p>
<p>&bull; For St = 1, the solution starts at and maintains the terminal velocity.
This is a simple example of a critical value of a parameter marking a bifurcation. In
</p>
<p>other systems, critical values can signify a change in the stability of a solution, or act
</p>
<p>as boundaries of parameter regimes in which different numbers of solutions coexist.
</p>
<p>Careful examination of related issues will be given in upcoming chapters (see
</p>
<p>Chaps. 6&ndash;10) using asymptotic analysis and perturbation methods to solve models in
</p>
<p>small parameter limits. For the moment, we note that apart from any physical interpre-
</p>
<p>tations, the limiting cases, Π = 0 and Π = &infin;, have a clear practical difference&mdash;an
infinite coefficient precludes any calculations using the &ldquo;usual methods&rdquo;. In (4.13),
</p>
<p>having St = 0 yields a well-defined solution,2 v(t) = 1+t , while (4.13) with St = &infin;
is a singular limit that can not be sensibly evaluated directly. As already described
</p>
<p>in connection with (4.8), the remedy for this is to rescale the problem.
</p>
<p>2This limiting solution could also be obtained using L&rsquo;Hopital&rsquo;s rule for the St &rarr; 0 limit of (4.15).</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6">http://dx.doi.org/10.1007/978-3-319-23042-9_6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_10">http://dx.doi.org/10.1007/978-3-319-23042-9_10</a></div>
</div>
<div class="page"><p/>
<p>4.3 The Process of Nondimensionalisation 95
</p>
<p>We note that the limit St &rarr; 0 in (4.14) corresponds to several different physical
limiting situations:
</p>
<p>&bull; Low fluid viscosity, &micro; &rarr; 0,
&bull; Low initial ball velocity, V0 &rarr; 0,
&bull; High ball density, ρ &rarr; &infin;,
&bull; Large ball size, R &rarr; &infin;.
For any of these physical regimes, (4.13) gives a well-defined model capable of
</p>
<p>representing the limiting behaviour. Conversely, for the opposite extremes (i.e. high
</p>
<p>viscosity or high speed or low ball mass), (4.13) would have a divergent coefficient
</p>
<p>and should not be used in current form.
</p>
<p>For example, consider the limit of high fluid viscosity that would be problematic
</p>
<p>for (4.13). Setting Π2 = 1 and Π3 = 1 in (4.11) selects the characteristic scales
</p>
<p>V = V0, T =
2ρR2
</p>
<p>9&micro;
, (4.19)
</p>
<p>and the new form of the scaled model:
</p>
<p>dv
</p>
<p>dt
= Π̃1 &minus; v, v(0) = 1, (4.20)
</p>
<p>with Π̃1 = 1/St and yields the limiting solution v(t) = e&minus;t for St = &infin;.
</p>
<p>4.3.3 The Burgers Equation
</p>
<p>To illustrate nondimensionalization for a partial differential equation, we consider a
</p>
<p>problem for the Burgers equation,
</p>
<p>&part;U
</p>
<p>&part;T
+ U&part;U
</p>
<p>&part;X
= D&part;
</p>
<p>2U
</p>
<p>&part;X2
, 0 &le; X &le; E, (4.21a)
</p>
<p>with the boundary and initial conditions,
</p>
<p>U(0,T) = A, &part;XU(E,T) = B, U(X, 0) = C, (4.21b)
</p>
<p>where A&ndash;E are given constants with appropriate dimensional units. In Chap. 2, the
</p>
<p>inviscid Burgers equation (2.39) was introduced, which is a special case of (4.21a)
</p>
<p>with D = 0. Equation (4.21a) occurs in models for problems in fluid dynamics
(where U represents a velocity) and other chemical and physical systems, where
</p>
<p>U represents other physical quantities. Our analysis of the non-dimensionalization
</p>
<p>applies irrespective of the units of U.</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2">http://dx.doi.org/10.1007/978-3-319-23042-9_2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2">http://dx.doi.org/10.1007/978-3-319-23042-9_2</a></div>
</div>
<div class="page"><p/>
<p>96 4 Dimensional Scaling Analysis
</p>
<p>We must choose dimensional scaling constants U, L, and T in
</p>
<p>U(X,T) = Uu(x, t), X = L x, T = Tt, (4.22)
</p>
<p>to yield variables u, x, t that are dimensionless. Using (4.22) in the form U(X,T) =
Uu(X/L,T/T) and employing the chain rule leads to the transformed problem
</p>
<p>(
U
</p>
<p>T
</p>
<p>)
&part;u
</p>
<p>&part;t
+
</p>
<p>(
U2
</p>
<p>L
</p>
<p>)
</p>
<p>u
&part;u
</p>
<p>&part;x
=
</p>
<p>(
DU
</p>
<p>L2
</p>
<p>)
&part;2u
</p>
<p>&part;x2
, 0 &le; L x &le; E,
</p>
<p>Uu(0, t) = A, (U/L)&part;xu(E/L, t) = B, Uu(x, 0) = C.
</p>
<p>Dividing across by one coefficient in each expression, we arrive at the nondimensional
</p>
<p>form
&part;u
</p>
<p>&part;t
+
</p>
<p>(
UT
</p>
<p>L
</p>
<p>)
</p>
<p>︸ ︷︷ ︸
</p>
<p>Π1
</p>
<p>u
&part;u
</p>
<p>&part;x
=
</p>
<p>(
DT
</p>
<p>L2
</p>
<p>)
</p>
<p>︸ ︷︷ ︸
</p>
<p>Π2
</p>
<p>&part;2u
</p>
<p>&part;x2
, 0 &le; x &le;
</p>
<p>(
E
</p>
<p>L
</p>
<p>)
</p>
<p>︸ ︷︷ ︸
</p>
<p>Π3
</p>
<p>, (4.23)
</p>
<p>u(0, t) =
(
</p>
<p>A
</p>
<p>U
</p>
<p>)
</p>
<p>︸ ︷︷ ︸
</p>
<p>Π4
</p>
<p>, &part;xu(E/L, t) =
(
</p>
<p>BL
</p>
<p>U
</p>
<p>)
</p>
<p>︸ ︷︷ ︸
</p>
<p>Π5
</p>
<p>, u(x, 0) =
(
</p>
<p>C
</p>
<p>U
</p>
<p>)
</p>
<p>︸ ︷︷ ︸
</p>
<p>Π6
</p>
<p>.
</p>
<p>In (4.22), we have three scaling constants whose values we can choose to set (an
</p>
<p>arbitrary choice of) three out of the six the Π &rsquo;s in (4.23) to unity, say
</p>
<p>Π3 = 1 =&rArr; L = E, (4.24)
Π4 = 1 =&rArr; U = A,
Π1 = 1 =&rArr; T = L/U = E/A.
</p>
<p>The characteristic length-, solution- and time-scales determined in (4.24) can be
</p>
<p>separated into two types: L,U are imposed scales, while the timescale T is a derived
</p>
<p>scale.
</p>
<p>The final scaled version of the problem is then
</p>
<p>&part;u
</p>
<p>&part;t
+ u &part;u
</p>
<p>&part;x
= Π2
</p>
<p>&part;2u
</p>
<p>&part;x2
, 0 &le; x &le; 1, (4.25a)
</p>
<p>u(0, t) = 1, ux (1, t) = Π5, u(x, 0) = Π6, (4.25b)
</p>
<p>with
</p>
<p>Π2 =
D
</p>
<p>AE
, Π5 =
</p>
<p>BE
</p>
<p>A
, Π6 =
</p>
<p>C
</p>
<p>A
.</p>
<p/>
</div>
<div class="page"><p/>
<p>4.3 The Process of Nondimensionalisation 97
</p>
<p>The solution of this problem will be a function of the independent variables and the
</p>
<p>three remaining Π parameters and gives the solution of the original problem (4.21)
</p>
<p>via (4.22) as
</p>
<p>U = Au(x, t,Π2,Π5,Π6), X = Ex, T = (E/A)t. (4.26)
</p>
<p>This gives the most general explicit understanding of how the solution depends on
</p>
<p>the constants defining the original problem. In contrast, without the use of scaling
</p>
<p>analysis, the best that can be said in general about the solution of the original problem
</p>
<p>(4.21) is that it will have some dependence on each parameter and variable,
</p>
<p>U = U(X,T,A,B,C,D,E).
</p>
<p>The nondimensionalization above proceeded by setting Π1, Π3 and Π4 equal to
</p>
<p>unity. Setting Π1 = 1 yielded T = L/U, which is known as the convective timescale
(the time taken to travel a distance L at velocity U). An alternative choice for a derived
</p>
<p>time-scale results if we set Π2 = 1 instead of Π1 = 1; the characteristic time is then
T = L2/D and is called the diffusive timescale (the time taken for diffusive effects
to propagate throughout the domain). The new form of the scaled problem becomes
</p>
<p>&part;u
</p>
<p>&part;t
+ Π̃1u
</p>
<p>&part;u
</p>
<p>&part;x
= &part;
</p>
<p>2u
</p>
<p>&part;x2
, 0 &le; x &le; 1, (4.27a)
</p>
<p>u(0, t) = 1, ux (1, t) = Π5, u(x, 0) = Π6, (4.27b)
</p>
<p>with
</p>
<p>Π̃1 =
UT
</p>
<p>L
= AE
</p>
<p>D
, Π5 =
</p>
<p>BE
</p>
<p>A
, Π6 =
</p>
<p>C
</p>
<p>A
.
</p>
<p>It is notable that Π̃1 is the inverse ofΠ2 from the first choice of scalings. As explained
</p>
<p>earlier, a dimensionless parameter always represents the ratio of two competing
</p>
<p>effects; in this case convection and diffusion. The relative importance of these effects
</p>
<p>is therefore measured by the ratio
</p>
<p>Pe = convective effects
diffusive effects
</p>
<p>= UL
D
</p>
<p>, (4.28)
</p>
<p>called the Peclet number. We can write Π̃1 = Pe or Π2 = 1/Pe in their respective
models to put the problem in forms comparable to other heat and mass transfer
</p>
<p>problems studied in engineering.
</p>
<p>Whether (4.25), (4.27) or some other choice of scaled problem is appropriate for
</p>
<p>the questions of interest is resolved by the second scaling principle (4.8). We should
</p>
<p>choose the system (4.27) if we consider the limit Pe&rarr; 0 (Π1 &rarr; 0) (convective
effects being less important than diffusive effects) and the system (4.25) for the limit
</p>
<p>Pe&rarr; &infin; (Π2 &rarr; 0) (convective effects being more important than diffusive effects).</p>
<p/>
</div>
<div class="page"><p/>
<p>98 4 Dimensional Scaling Analysis
</p>
<p>4.4 Further Applications of Dimensional Analysis
</p>
<p>4.4.1 Projectile Motion (Revisited)
</p>
<p>Dimensional analysis can sometimes be used to identify the solution structure of
</p>
<p>problems without even writing down model equations. Although this may sound
</p>
<p>simpler than the approach we have outlined above, the absence of equations derived
</p>
<p>from physical laws requires us torely heavily on experience and intuition for guid-
</p>
<p>ance. With that caveat in mind, we now construct the form of the solution to a
</p>
<p>projectile problem without first deriving a model equation.
</p>
<p>Consider a projectile of mass M kg launched at an angle α up from the ground
</p>
<p>with a given speed V m/s. At some later time, the projectile will return to the ground.
</p>
<p>Suppose that we wish to calculate the time of flight of the projectile T (s). Besides
</p>
<p>the given parameters describing the launch of the object (M,V,α), we expect the
</p>
<p>acceleration due to gravity, g m/s2, to also play a key role.
</p>
<p>Consequently, we may expect that
</p>
<p>T = F(M,V,g,α) (4.29)
</p>
<p>for some dimensional function F. With respect to units of time, the only way to
</p>
<p>construct a dimensionless parameter in terms of the given quantities is Π1 = gT/V.
Then, corresponding to (4.29), the dimensionless time must given by a dimensionless
</p>
<p>function f
gT
</p>
<p>V
= f (M,V,g,α). (4.30)
</p>
<p>Of the parameters in f , M,V and g are independent in that we cannot write the
</p>
<p>dimensions of one of these quantities as a combination of the dimensions of the others
</p>
<p>(also note that α is an angle and so already a dimensionless quantity). We cannot
</p>
<p>therefore construct any further nondimensional quantities by combining them. This
</p>
<p>is not consistent with the requirement that f be a nondimensional function and so
</p>
<p>implies that f must be independent of all of these quantities, yielding simply that
</p>
<p>T = V
g
f (α). (4.31)
</p>
<p>We have thus simplified a dimensional function of four quantities down to a nondi-
</p>
<p>mensional function of just one, and, in addition, have shown that T should be inde-
</p>
<p>pendent of the projectile mass M without reference to any model equation.
</p>
<p>Although this analysis does not provide the form of the function f (α), we can
</p>
<p>immediately see that T is linearly dependent on the initial velocity and inversely
</p>
<p>dependent on g; which is precisely what we obtained in Sect. 4.3.1.
</p>
<p>In the above discussion, we ignored the influence of air resistance on the dynamics
</p>
<p>of the projectile. If we include the effects of air resistance so that the projectile</p>
<p/>
</div>
<div class="page"><p/>
<p>4.4 Further Applications of Dimensional Analysis 99
</p>
<p>experiences a retarding force linearly proportional to the velocity with proportionality
</p>
<p>constant K (measured in units of kg/s), Eq. (4.29) would now take the form
</p>
<p>T = F̃(M,V,g,α,K). (4.32)
</p>
<p>In contrast with (4.31), it is now possible to combine M, V, g along with K into a
</p>
<p>dimensionless product. We consequently obtain
</p>
<p>gT
</p>
<p>V
= f̃
</p>
<p>(
</p>
<p>α,
Mg
</p>
<p>KV
</p>
<p>)
</p>
<p>, (4.33)
</p>
<p>namely a dimensionless function of two dimensionless parameters based on inde-
</p>
<p>pendent combinations of the given quantities describing the problem. Note that we
</p>
<p>do not combine the dimensionless parameter α with the other dimensionless prod-
</p>
<p>uct; as α could be the exponent of a non-monomial function, say sin or log, and this
</p>
<p>whole function would remain nondimensional (and undetermined through dimen-
</p>
<p>sional analysis).
</p>
<p>The introduction of the air resistance constant of proportionality K, also provides
</p>
<p>another way to generate a quantity with dimensions of time and this allows us to
</p>
<p>write
KT
</p>
<p>M
= f̂
</p>
<p>(
</p>
<p>α,
Mg
</p>
<p>KV
</p>
<p>)
</p>
<p>. (4.34)
</p>
<p>At first glance, it appears that we have two functional forms for the same expression,
</p>
<p>but in fact (4.33) and (4.34) are equivalent, where we have (multiplying through by
</p>
<p>the nondimensional product)
</p>
<p>Mg
</p>
<p>KV
</p>
<p>KT
</p>
<p>M
= gT
</p>
<p>V
= Mg
</p>
<p>KV
f̂
</p>
<p>(
</p>
<p>α,
Mg
</p>
<p>KV
</p>
<p>)
</p>
<p>= f̃
(
</p>
<p>α,
Mg
</p>
<p>KV
</p>
<p>)
</p>
<p>. (4.35)
</p>
<p>The time of flight T can, in fact, be shown to be given implicitly by
</p>
<p>M
</p>
<p>Kg
</p>
<p>(
</p>
<p>V sinα+ Mg
K
</p>
<p>)
</p>
<p>(1 &minus; e&minus;KT/M)&minus; MT
K
</p>
<p>= 0. (4.36)
</p>
<p>This equation cannot be inverted to give an explicit form for T. But (4.36) can be
</p>
<p>expressed in the form F(Π1,Π2,Π3) = 0, with Π1 = KT/M, which subsequently
leads to (4.34). Thus (4.34) provides us with an understanding of the qualitative
</p>
<p>dependence of T on all quantities in the system and a more detailed quantitative
</p>
<p>solution would involve the numerical solution of (4.36).</p>
<p/>
</div>
<div class="page"><p/>
<p>100 4 Dimensional Scaling Analysis
</p>
<p>4.4.2 Closed Curves in the Plane
</p>
<p>For our final example, we touch on how dimensional analysis connects with the more
</p>
<p>general concept of similarity that we will describe in detail later in Sect. 4.5.1.
</p>
<p>Simple (non-intersecting) closed curves can be associated with two quantities:
</p>
<p>an enclosed area A, and a perimeter P. In terms of dimensions, [A] = L2 and the
perimeter [P] = L, from which we can form one dimensionless parameter Π1 =
P2/A (the dimensionless perimeter to area ratio). For a circle of radius R, this ratio
</p>
<p>reduces to
</p>
<p>Π1 =
(2πR)2
</p>
<p>πR2
= 4π. (4.37)
</p>
<p>Note that this is the only dimensionless parameter for circles and it is independent
</p>
<p>of the radius of the circle.
</p>
<p>For a square with sides of length L, the perimeter to area ratio is
</p>
<p>Π1 =
(4L)2
</p>
<p>L2
= 16. (4.38)
</p>
<p>Consequently, all squares are also similar to each other. Noting that 16 &gt; 4π, we
</p>
<p>observe that for a given perimeter length, circles enclose a greater area than that
</p>
<p>achieved by squares.3
</p>
<p>Triangles with sides of length L,M,N have perimeter P = L + M + N and
Heron&rsquo;s formula gives the area as
</p>
<p>A =
&radic;
</p>
<p>P
</p>
<p>2
</p>
<p>(
P
</p>
<p>2
&minus; L
</p>
<p>)(
P
</p>
<p>2
&minus; M
</p>
<p>)(
P
</p>
<p>2
&minus; N
</p>
<p>)
</p>
<p>. (4.39)
</p>
<p>Consequently, the perimeter to area ratio can be written as
</p>
<p>Π1 =
1
</p>
<p>&radic;
</p>
<p>1
2
</p>
<p>(
1
2
&minus; L
</p>
<p>P
</p>
<p>) (
1
2
&minus; M
</p>
<p>P
</p>
<p>) (
1
2
&minus; N
</p>
<p>P
</p>
<p>)
.
</p>
<p>In this expression, we have several dimensionless ratios of lengths: Π2 = L/P,
Π3 = M/P, and Π4 = N/P. As Π1,Π2 are independent parameters and noting that
Π4 can be written as Π4 = 1 &minus;Π2 &minus;Π3 (using the equation for P), we can write
</p>
<p>Π1 =
1
</p>
<p>&radic;
</p>
<p>1
2
</p>
<p>(
1
2
&minus;Π2
</p>
<p>) (
1
2
&minus;Π3
</p>
<p>) (
</p>
<p>Π2 +Π3 &minus; 12
)
. (4.40)
</p>
<p>3In Chap. 3, we showed that the calculus of variations can be used to prove that, among all smooth
</p>
<p>simple closed curves, the circle uniquely minimises the ratio Π1.</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3">http://dx.doi.org/10.1007/978-3-319-23042-9_3</a></div>
</div>
<div class="page"><p/>
<p>4.5 The Buckingham Pi Theorem 101
</p>
<p>4.5 The Buckingham Pi Theorem
</p>
<p>We conclude this chapter by reviewing the mathematical theory behind dimensional
</p>
<p>analysis, known as the Buckingham Pi theorem. While dimensional analysis can be
</p>
<p>applied directly without this theorem, its results can be used to predict the number
</p>
<p>of dimensionless parameters in a problem and further reduce calculations involved.
</p>
<p>For any system described by n dimensional quantities Q1,Q2, . . . ,Qn involving r
</p>
<p>independent base dimensional units, [U1], [U2], . . . , [Ur ],4 two results are universal:
(i) A set of dimensionless parameters Π j , j = 1, 2, . . . (sometimes also called
</p>
<p>&ldquo;dimensionless groups&rdquo;) can be written as monomial products in terms of powers
</p>
<p>of the Qi &rsquo;s:
</p>
<p>Π = Qα1 Q
β
2 Q
</p>
<p>γ
3 . . . (4.41)
</p>
<p>Since each Π must be dimensionless, they must satisfy:
</p>
<p>[Π ] = [Q1]α[Q2]β[Q3]γ . . . = [U1]0[U2]0 . . . [Ur ]0 (4.42)
</p>
<p>This yields a set of r homogeneous linear equations for the exponentsα,β, γ, . . . ,
</p>
<p>one for each of the [Uk] units, k = 1, 2, . . . , r .
Let r̃ be the number of linearly independent equations in this set, with r̃ &le; r .
Of the n exponents (α,β, γ, . . .), r̃ of them will be determined from the dimen-
</p>
<p>sional relations (4.42) in terms of the remaining n &minus; r̃ exponents, which are
un-determined from this analysis.
</p>
<p>(ii) All relations between the original quantities, Q1,Q2, . . . ,Qn will be repre-
</p>
<p>sented by corresponding relations among the n &minus; r̃ dimensionless parameters,
Π1,Π2, . . . ,Πn&minus;r̃ :
</p>
<p>F(Π1,Π2, . . . ,Πn&minus;r̃ ) = 0. (4.43)
</p>
<p>The structure of the relations is dependent upon the specific form of each
</p>
<p>problem. �
</p>
<p>At its heart, the Π theorem is a consequence of linear algebra applied to the
</p>
<p>dimensional units of the Q&rsquo;s, with the exponents in the Π &rsquo;s being analogous to
</p>
<p>coefficients of a set of linearly independent vectors (whose roles are played by the
</p>
<p>base units Uk). Different presentations and more detail on the Π -theorem can be
</p>
<p>found in [9, 10, 49, 64].
</p>
<p>4The base units, Uk in the Π theorem need not be fundamental units, they can be derived units, just
as long they form a linearly independent set.</p>
<p/>
</div>
<div class="page"><p/>
<p>102 4 Dimensional Scaling Analysis
</p>
<p>4.5.1 Mathematical Consequences
</p>
<p>While the Buckingham Π theorem and the other observations made earlier in this
</p>
<p>chapter are straightforward, they lead to important consequences:
</p>
<p>(i) For problems, where the solution is a function, the Pi theorem predicts that the
</p>
<p>non-dimensional form of the solution will depend on any independent variables
</p>
<p>and the Π groups,
</p>
<p>u = u(x, t,Π1,Π1, . . . ,Πn&minus;r̃ ).
</p>
<p>To write the solution of the original problem in terms of this dimensionless
</p>
<p>solution, characteristic scales are needed for all of the dependent and indepen-
</p>
<p>dent variables. Analogous to (4.42), choices for these scales in terms of the
</p>
<p>given quantities of the problem are obtained by solving for the exponents in
</p>
<p>[Q1]α[Q2]β[Q3]γ . . . = [U j ]1, (4.44)
</p>
<p>namely, the options for characteristic scales are determined by solving the linear
</p>
<p>system with the entry for one dimension set to unity while the other righthand
</p>
<p>side entries are still zero, as in (4.42).
</p>
<p>(ii) If Π1 is a dimensionless parameter for a system, then so is Π̃1 = αΠβ1 for
any numbers α,β, and even more generally, so is Π̂1 = h(Π1) and Π̆1 =
g(Π1,Π2) for any functions g and h. This illustrates the very large degree of
</p>
<p>non-uniqueness in specifying dimensionless parameters. However, this being
</p>
<p>said, once choices are made for the Π &rsquo;s, they allow for systematic analysis of
</p>
<p>comparable systems.
</p>
<p>(iii) Two systems are called similar if they reduce to the same dimensionless prob-
</p>
<p>lem with the same values for all of theΠ &rsquo;s in (4.43). Consequently, two similar
</p>
<p>systems will have the same dimensionless properties and their dimensional
</p>
<p>properties will be proportionally scaled. For example, in the context of trian-
</p>
<p>gles (from Sect. 4.4.2), two triangles are similar if they share the same values
</p>
<p>of Π1,Π2,Π3; this is consistent with the description for similar triangles in
</p>
<p>plane geometry.
</p>
<p>This principle, sometimes called the similitude condition (or &ldquo;dynamic simil-
</p>
<p>itude&rdquo;) is the basis for constructing smaller-scale inexpensive prototypes for
</p>
<p>testing and predicting the properties of full-sized systems.
</p>
<p>(iv) Under broad conditions, when we can assume the implicit function theorem
</p>
<p>applies to (4.43), then the values of some dimensionless parameters (or sys-
</p>
<p>tem properties) can be expressed as functions of the values of the others. For
</p>
<p>example, say F(Π1,Π2,Π3) = 0, then we may able to obtain
</p>
<p>Π3 = f (Π1,Π2).</p>
<p/>
</div>
<div class="page"><p/>
<p>4.5 The Buckingham Pi Theorem 103
</p>
<p>In particular, note that (4.40) is an example of a specific relation of the form
</p>
<p>Π1 = f (Π2,Π3).
The Π -theorem will not determine the solution function f , but it does help
</p>
<p>greatly by telling us how many independent parameters it depends on.
</p>
<p>As described earlier, there are many different possible sets of Π &rsquo;s that can be
</p>
<p>employed to describe each problem. Useful choices depend on which system prop-
</p>
<p>erties are known versus which ones are being sought.
</p>
<p>4.5.2 Application to the Quadratic Equation
</p>
<p>We now apply theΠ theorem in detail to an elementary problem to illustrate a broader
</p>
<p>idea&mdash;while the theorem follows from dimensional analysis, it can be applied to any
</p>
<p>mathematical problem to determine the essential dependence of solutions on the
</p>
<p>given parameters of the system.
</p>
<p>One context in which the quadratic equation,
</p>
<p>AT2 + BT + C = 0, (4.45)
</p>
<p>arises is (as mentioned previously) in the kinematic study of an object moving at
</p>
<p>a constant acceleration, where T would be the time of flight (an unknown, to be
</p>
<p>solved for) and A,B,C are given dimensional constants related to the acceleration,
</p>
<p>initial velocity and initial position respectively. In this context, the dimensions of the
</p>
<p>quantities in (4.45) are
</p>
<p>[T] = T, [C] = L, [B] = L/T, [A] = L/T2.
</p>
<p>Following (4.41), we can denote dimensionless parameters in terms of these quanti-
</p>
<p>ties as
</p>
<p>Π = AαBβCγTδ, (4.46)
</p>
<p>for appropriate values of the exponents. Noting that the only dimensions that appear
</p>
<p>in this problem are L and T, for Π to be dimensionless requires that [Π ] = L0T0,
and so
</p>
<p>(L/T2)
α
(L/T)βLγTδ = L0T0 &rarr; Lα+β+γT&minus;2α&minus;β+δ = L0T0.
</p>
<p>The four unknown exponents α, β, γ and δ must satisfy the two dimension-
</p>
<p>independence equations
</p>
<p>L : α+ β + γ = 0,
T : &minus;2α&minus; β + δ = 0.</p>
<p/>
</div>
<div class="page"><p/>
<p>104 4 Dimensional Scaling Analysis
</p>
<p>Standard theory from linear algebra then gives that each solution will have two free
</p>
<p>parameters that can be set arbitrarily, with two variables being determined in terms
</p>
<p>of the other two variables. This exactly corresponds to the Π theorem&rsquo;s count: 4
</p>
<p>quantities &minus;2 independent dimensions = 2 parameters.
There are many possible choices for selecting the Π &rsquo;s. However, as explained in
</p>
<p>Sect. 4.3.1, there are conventions that lead to specific choices that make the mathe-
</p>
<p>matical formulation more easily interpretable than the original problem.
</p>
<p>For the current example, we seek a dimensionless variable corresponding to T: in
</p>
<p>(4.46), if we pick δ = 1 and for convenience take γ = 0, then we have α = 1,β =
&minus;1, giving, Π1 = A1B&minus;1T1. Since [Π1] = 1 we see that [T] = [B/A], namely that
the ratio of the given quantities B/A determines a characteristic scale.
</p>
<p>Excluding the variable T, the example has 3 given quantities (A,B,C)&mdash;2 dimen-
</p>
<p>sions (L,T) = 1 independent system parameter. Setting δ = 0 in (4.46) and for
convenience picking γ = 1 yields α = 1,β = &minus;2 and Π2 = AC/B2.
</p>
<p>Employing the second result from the Buckingham theorem, the dimensionless
</p>
<p>groups should all be related, F(Π1,Π2) = 0. Applying the implicit function theorem
to F , we can write
</p>
<p>Π1 = f (Π2) =&rArr;
AT
</p>
<p>B
= f (Π2),
</p>
<p>and hence
</p>
<p>T =
(
</p>
<p>B
</p>
<p>A
</p>
<p>)
</p>
<p>f
</p>
<p>(
AC
</p>
<p>B2
</p>
<p>)
</p>
<p>. (4.47)
</p>
<p>We now compare this against the standard result for the solution of the quadratic
</p>
<p>equation (4.45):
</p>
<p>T = &minus;B &plusmn;
&radic;
</p>
<p>B2 &minus; 4AC
2A
</p>
<p>= &minus;B &plusmn;
&radic;
</p>
<p>B2(1 &minus; 4AC/B2)
2A
</p>
<p>(4.48)
</p>
<p>= B
A
</p>
<p>(
</p>
<p>&minus;1
2
&plusmn;
</p>
<p>&radic;
</p>
<p>1 &minus; 4AC
B2
</p>
<p>)
</p>
<p>=
(
</p>
<p>B
</p>
<p>A
</p>
<p>)
</p>
<p>f (Π2).
</p>
<p>Even though the Buckingham theorem cannot predict the details of the function
</p>
<p>f (Π2), (4.47) has indicated the way in which the solution of (4.45) depends on the
</p>
<p>given quantities.
</p>
<p>4.6 Further Directions
</p>
<p>Further use of dimensional analysis for mathematical modelling is well illustrated
</p>
<p>in Chap. 1 of Holmes [49] and at a more advanced level in the books of Barenblatt
</p>
<p>[9, 10] and Sedov [88]. In addition, the book by Szirtes [95] contains an extensive</p>
<p/>
</div>
<div class="page"><p/>
<p>4.6 Further Directions 105
</p>
<p>number of worked examples in dimensional analysis taken from a wide range of
</p>
<p>areas.
</p>
<p>Models for projectile motion have been used as a classic example of dimensional
</p>
<p>analysis in many books on modelling [49, 64] since Lin and Segel [63, 89]. This
</p>
<p>stems from its broad appeal as a fundamental problem in physics as well as the large
</p>
<p>number of basic modelling concepts it connects to. Likewise, the Burgers equation
</p>
<p>is a partial differential equation that plays an important role in many applications in
</p>
<p>applied mathematics beyond its original setting in fluid dynamics [106], and will be
</p>
<p>re-visited in several later chapters.
</p>
<p>Finally, in our introductory discussion, we have barely touched on the relation of
</p>
<p>dimensional analysis to similitude and scale models&mdash;how to construct a model ship,
</p>
<p>for example, with properties that when scaled up will be consistent with those of the
</p>
<p>actual ship. The classic text by Pankhurst [83] has a clear and concise introduction
</p>
<p>to this topic written from an engineering perspective.
</p>
<p>4.7 Exercises
</p>
<p>4.1 (Choosing scalings for different limits) Consider the dimensional problem for
</p>
<p>the motion of a projectile launched from close to the surface of the Earth:
</p>
<p>d2Y
</p>
<p>dT2
= &minus; GME
</p>
<p>(RE + Y)2
, Y(0) = 2 m, Y&prime;(0) = &minus;V0 m/s.
</p>
<p>Assume the Earth to be spherical with a uniform density, ME = 43πR3EρE.
Let Y(T) = Ly(t) and T = Tt . Consider the following cases:
</p>
<p>(i) The fast projectile limit: RE = fixed, V0 &rarr; &infin;, ρE = fixed.
(ii) The dense Earth limit: RE = fixed, V0 = fixed, ρE &rarr; &infin;.
</p>
<p>(iii) The light Earth limit: RE = fixed, V0 = fixed, ρE &rarr; 0.
(iv) The small Earth limit: RE &rarr; 0,V0 = fixed, ME = fixed.
For each case:
</p>
<p>(a) Choose characteristic scalings L,T to normalise as many terms as possible.
</p>
<p>(b) Choose the scalings so that the time it takes for the projectile to fall to should
</p>
<p>be finite for the given limit. Namely, the speed, acceleration, and initial height
</p>
<p>should not diverge, nor should falling (say down to 1 m) take infinitely long in
</p>
<p>time (as in for example if the velocity and acceleration both approach zero) or
</p>
<p>happen nearly instantaneously (if the initial height approaches zero).
</p>
<p>(c) Write the scaled problem and identify all remaining dimensionless parameters.
</p>
<p>(d) Identify the limiting small parameter and for each case, write the problem (called
</p>
<p>the leading order problem) when the parameter is set to zero.</p>
<p/>
</div>
<div class="page"><p/>
<p>106 4 Dimensional Scaling Analysis
</p>
<p>M
</p>
<p>X(T)
</p>
<p>F sin(ΩT)
K
</p>
<p>Ω
</p>
<p>|X
| m
</p>
<p>a
x
</p>
<p>3210
</p>
<p>80
</p>
<p>40
</p>
<p>0
</p>
<p>Ω3
Ω2
Ω1
</p>
<p>T
</p>
<p>X
(T
</p>
<p>)
</p>
<p>20100
</p>
<p>100
</p>
<p>0
</p>
<p>-100
</p>
<p>Fig. 4.1 The elementary problem of a mass on spring with an applied force: (Left) dimensional
</p>
<p>parameters, (Right) solutions X(T) for various parameters and (Inset) the amplitude in relation to
the forcing frequency
</p>
<p>4.2 The governing equation for the linear mass-spring system shown in Fig. 4.1 is
</p>
<p>M
d2X
</p>
<p>dT2
+ KX = F sin(ΩT), X(0) = X0,
</p>
<p>dX
</p>
<p>dT
</p>
<p>∣
∣
∣
∣
T=0
</p>
<p>= V0,
</p>
<p>where X(T) [m] is the position of the mass as a function of time with mass M [kg], and
</p>
<p>spring coefficient K [N/m], magnitude of the applied force, F [N], forcing frequency,
</p>
<p>Ω [s&minus;1], as well as general initial conditions,
Nondimensionalize and select length- and time-scales L, T to normalise the coef-
</p>
<p>ficients of the terms on the left side of the ODE and the initial condition for position.
</p>
<p>Write and solve the scaled problem, and identify the dimensionless parameter for the
</p>
<p>ratio of the forcing frequency to resonant frequency, where the solution&rsquo;s amplitude
</p>
<p>grows without bound, as shown for Ω2 in Fig. 4.1.
</p>
<p>4.3 Consider the initial value problem for a damped driven nonlinear oscillator:
</p>
<p>M
d2X
</p>
<p>dT2
+ BdX
</p>
<p>dT
+ KX3 = F sin(ΩT), X(0) = A, dX
</p>
<p>dT
</p>
<p>∣
∣
∣
∣
T=0
</p>
<p>= C.
</p>
<p>(a) If the units are [M] = kg, [T] = s and [X] = m, state the units for A,B,K,F,Ω .
(b) Consider the limit M &rarr; 0. Let X(T) = Lx(t) and T = Tt where L,T are
</p>
<p>characteristic scale constants. Determine choices for L,T that yield an ODE for
</p>
<p>x with all three terms on the left side of the equation normalised.
</p>
<p>(c) Identify the dimensionless parameters in this scaled problem.
</p>
<p>4.4 Consider the dimensional equation for the damped pendulum
</p>
<p>d2Θ
</p>
<p>dT2
+ BdΘ
</p>
<p>dT
+ g
</p>
<p>L
sinΘ = 0, Θ(0) = Θ0, Θ &prime;(0) = Ω0,</p>
<p/>
</div>
<div class="page"><p/>
<p>4.7 Exercises 107
</p>
<p>where B is the damping coefficient, g gravity, L length, and Θ0,Ω0 initial angle
</p>
<p>and speed. Nondimensionalize in terms of general scalings for the position and time:
</p>
<p>Θ(T ) = Θ̄θ(t), T = Tt . Determine the form of the scaled model and the appropriate
characteristic scales for:
</p>
<p>(i) The weakly damped limit: B &rarr; 0.
(ii) The slow speed limit: Ω0 &rarr; 0.
</p>
<p>(iii) The small amplitude oscillation limit: Θ0 &rarr; 0.
</p>
<p>4.5 Consider dimensional equations describing a system of chemical reactions for
</p>
<p>the concentrations of three chemicals:
</p>
<p>dX
</p>
<p>dT
= A &minus; BY X(0) = X0
</p>
<p>dY
</p>
<p>dT
= CX &minus; DZ Y(0) = Y0 (4.49)
</p>
<p>dZ
</p>
<p>dT
= EY &minus; FY2 + GY3 &minus; HZ Z(0) = Z0
</p>
<p>where A,B,C, . . .H are given dimensional constants. By scaling X,Y,Z,T (i.e.
</p>
<p>X(T) = Xx(t) and similarly for the others) show that these equations can be non-
dimensionalized in the form:
</p>
<p>dx
</p>
<p>dt
= α&minus; y x(0) = &micro;
</p>
<p>β
dy
</p>
<p>dt
= x &minus; z y(0) = σ (4.50)
</p>
<p>γ
dz
</p>
<p>dt
= y &minus; y2 + 1
</p>
<p>3
δy3 &minus; z z(0) = ω
</p>
<p>(a) Determine the characteristic scalings X,Y,Z,T and the dimensionless parame-
</p>
<p>ters in terms of A&ndash;H and X0,Y0,Z0.
</p>
<p>(b) If γ = 0 show that the problem reduces to a system of two ODEs in terms of
x(t) and y(t) only. Find the relation that the initial conditions must satisfy in
</p>
<p>order to avoid a contradiction.
</p>
<p>(c) If β = 0 show that the problem reduces to single first-order ODE for y(t)
alone. Find the relation that the initial conditions must satisfy in order to avoid
</p>
<p>a contradiction.
</p>
<p>4.6 Consider the dimensional problem for U(X,T):
</p>
<p>&part;U
</p>
<p>&part;T
+ AU2 &part;U
</p>
<p>&part;X
+ B&part;
</p>
<p>4U
</p>
<p>&part;X4
= CX2T3 X &ge; 0 T &ge; 0
</p>
<p>U(0,T) = 0, U3(0,T)+ DUXXX(0,T) = E,
</p>
<p>where A,B,C,D,E are given constants.</p>
<p/>
</div>
<div class="page"><p/>
<p>108 4 Dimensional Scaling Analysis
</p>
<p>(a) If X is measured in meters, T is measured in seconds, and U is a density function,
</p>
<p>measured in kg/m3, determine the units for A&ndash;E.
</p>
<p>(b) Determine L,T,U in terms of A&ndash;E in the dimensional scaling U = Uu(x, t)
with X = Lx , T = Tt so that all of coefficients in the PDE are normalised.
Write the complete nondimensionalized problem and identify the dimensionless
</p>
<p>parameters.
</p>
<p>4.7 The shallow water equations are a system of two PDEs describing fluid flow in
</p>
<p>shallow (long, slender) layers, like rivers. In dimensional form, they are
</p>
<p>&part;TH + H&part;XU + U&part;XH = 0,
&part;TU + U&part;XU + g&part;XH = 0,
</p>
<p>where U(X,T) is the fluid speed, H(X,T) is the height of the fluid layer, and g is the
</p>
<p>acceleration due to gravity.
</p>
<p>Nondimensionalize using the average depth of a river H, and average speed U and
</p>
<p>lengthscale L
</p>
<p>H = Hh, U = Uu, X = Lx, T = Tt.
</p>
<p>Select the timescale T to normalise all terms in the h equation and determine the
</p>
<p>only remaining dimensionless parameter, called the Froude number (Fr).
</p>
<p>4.8 One model for the motion of a projectile of mass M launched from the origin
</p>
<p>at an angle α to the horizontal with initial velocity V is given by the solution to the
</p>
<p>vector equation,
</p>
<p>M
d2X
</p>
<p>dT2
= &minus;Mg &minus; KdX
</p>
<p>dT
,
</p>
<p>where X = (X,Y), g = (0,g) and K is a coefficient of air resistance.
(a) Use dimensional homogeneity to determine the units of K.
</p>
<p>(b) In the absence of air resistance (K = 0), show that the solution to this equation
is consistent with (4.31).
</p>
<p>(c) Show that Eq. (4.36) for the time of flight T can be obtained from this equation
</p>
<p>when the air resistance is directional proportional to the projectile&rsquo;s velocity
</p>
<p>(K �= 0).
(d) Repeat the dimensional analysis from the example in the text, assuming that the
</p>
<p>air-resistance is directly proportional to the square of the velocity, (note: you
</p>
<p>will have to redefine the dimensions of K).
</p>
<p>(e) Perform a similar analysis in both cases to derive a nondimensional expression
</p>
<p>for the distance travelled.
</p>
<p>4.9 Returning to the relation between area and perimeter from Sect. 4.4.2, consider
</p>
<p>these questions for different families of shapes:
</p>
<p>(a) Show that for all rectangles (with length L and width W), the perimeter-to-area
</p>
<p>ratio can be expressed in terms of a length-to-width aspect ratio parameter.</p>
<p/>
</div>
<div class="page"><p/>
<p>4.7 Exercises 109
</p>
<p>(b) For ellipses having semi-major and semi-minor axes of L,W, (X/L)2 +
(Y/W)2 = 1, the area is given by A = πLW and a formula by Ramanujan [85]
gives the approximate perimeter as P &asymp; π(3(L+W)&minus;
</p>
<p>&radic;
(3L + W)(L + 3W) ).
</p>
<p>Relate the dimensionless perimeter to area ratio to the aspect ratio. What can be
</p>
<p>said about the relations between a rectangle and its inscribed ellipse?
</p>
<p>(c) Use (4.40) to show that all triangles have Π1 &ge; 12
&radic;
</p>
<p>3.
</p>
<p>4.10 To show that if different choices are made for Π1,Π2 in (4.46), the results
</p>
<p>still yield the form of the quadratic formula (4.48). Determine Π1,Π2, f (Π2) if
</p>
<p>δ = γ = 1 in Π1 and δ = 0, γ = 1 in Π2.
</p>
<p>4.11 Consider the cubic equation,
</p>
<p>AT3 + BT2 + CT + D = 0.
</p>
<p>(a) Assuming the dimensions are [T] = T and [D] = L, use the Buckingham Π
theorem to determine the dimensionless groups for this equation.
</p>
<p>(b) Using (a) write a formula for how the roots T depend on combinations of the
</p>
<p>coefficients.
</p>
<p>(c) If Xk are the three roots of the equation 2X
3 + 3X2 + 4X + 5 = 0, then use (b)
</p>
<p>to determine new coefficients in the following equation
</p>
<p>Y3 + B̃ Y2 + C̃ Y + D̃ = 0
</p>
<p>in terms of the previous A&ndash;D such that the roots are double the roots of the first
</p>
<p>equation, Yk = 2Xk . (Do not determine the values of the roots directly.)
</p>
<p>4.12 The fluid dynamics problem of how water drips from a faucet depends on
</p>
<p>several quantities: the acceleration due to gravity g[m/s2], the density of water
ρ[kg/m3], the viscosity of water &micro;[kg/(ms)], the surface tension of water σ[kg/s2],
the radius of the faucet nozzle R[m], and the speed of the water coming out of the
faucet U[m/s].
(a) Use the Buckingham Π theorem to determine the number of dimensionless
</p>
<p>parameters and write
</p>
<p>Π = gAρB&micro;CσDREUF
</p>
<p>to determine the equations relating the exponents A&ndash;F .
</p>
<p>(b) The choice of dimensionless parameters to describe problems is not unique. This
</p>
<p>problem can be described in terms of the set of Π parameters:
</p>
<p>Re = ρUR
&micro;
</p>
<p>Bo = ρgR
2
</p>
<p>σ
Ca = &micro;U
</p>
<p>σ
</p>
<p>(called the Reynolds, Bond, and Capillary numbers) or in terms of the set</p>
<p/>
</div>
<div class="page"><p/>
<p>110 4 Dimensional Scaling Analysis
</p>
<p>We = ρU
2R
</p>
<p>σ
Oh = &micro;&radic;
</p>
<p>ρRσ
Ga = ρ
</p>
<p>2gR3
</p>
<p>&micro;2
</p>
<p>(the Weber, Ohnesorge, and Galileo numbers).
</p>
<p>(i) State the choices for A&ndash;F for each parameter and show that each of these
</p>
<p>parameters satisfies the equations from (a).
</p>
<p>(ii) Show that the 3 parameters in each set are independent by showing that
</p>
<p>their vectors of dimensional exponents v = (A, B,C, D, E, F) are linearly
independent.</p>
<p/>
</div>
<div class="page"><p/>
<p>Part II
</p>
<p>Solution Techniques</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 5
</p>
<p>Self-Similar Scaling Solutions of Differential
</p>
<p>Equations
</p>
<p>Constructing solutions of ordinary and partial differential equations can be a chal-
</p>
<p>lenging process (even for the linear case). For linear problems, techniques such as
</p>
<p>separation of variables, and Fourier and Laplace transforms can often be used to
</p>
<p>write the general solution of a differential equation that can then be specialised to
</p>
<p>a particular problem through the imposition of additional (initial and/or boundary)
</p>
<p>conditions to generate a unique solution. Such solutions can be cumbersome to obtain
</p>
<p>and may still require substantial further analysis in order to gain a clear insight into
</p>
<p>the nature of the system&rsquo;s resulting behaviour. For nonlinear problems, techniques to
</p>
<p>obtain general solutions exist for only a very limited number of types of equations.
</p>
<p>In this chapter, we will show that the scaling analysis introduced in the context
</p>
<p>of dimensional analysis in Chap.4 can be applied to obtain special solutions of
</p>
<p>both linear and nonlinear partial differential equations. These solutions are called
</p>
<p>similarity solutions (sometimes also called self-similar solutions).
</p>
<p>It will be shown that if the PDE can be scaled in such away as to exactly reproduce
</p>
<p>its original form (as suggested by the term &lsquo;self-similar&rsquo;), then it will possess a
</p>
<p>class of solutions that share this property. A consequence of the property of self-
</p>
<p>similarity is that these solutions can be obtained from a reduced version of the
</p>
<p>original problem. For a PDE with two independent variables, this leads to an ODE
</p>
<p>problem for the similarity solution. Despite their nature as exact solutions to a given
</p>
<p>problem under special conditions, they often provide important understanding of the
</p>
<p>broader behaviour of all solutions of the system.
</p>
<p>The process of constructing a similarity solution to a given problem consists of
</p>
<p>three stages:
</p>
<p>(i) Looking for a scaling &ldquo;symmetry&rdquo; of the problem to see if similarity solutions
</p>
<p>are possible.
</p>
<p>(ii) Determining the forms of the similarity variables and functions from the scale-
</p>
<p>invariant Π groups for the problem.
</p>
<p>&copy; Springer International Publishing Switzerland 2015
</p>
<p>T. Witelski and M. Bowen, Methods of Mathematical Modelling,
</p>
<p>Springer Undergraduate Mathematics Series, DOI 10.1007/978-3-319-23042-9_5
</p>
<p>113</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4">http://dx.doi.org/10.1007/978-3-319-23042-9_4</a></div>
</div>
<div class="page"><p/>
<p>114 5 Self-Similar Scaling Solutions of Differential Equations
</p>
<p>(iii) Solving a reduced problem for the similarity function and then transforming
</p>
<p>back to give the solution of original problem.
</p>
<p>We will illustrate the stages in this process in detail and then go on to apply the
</p>
<p>method to further examples.
</p>
<p>5.1 Finding Scaling-Invariant Symmetries
</p>
<p>Scaling analysis can identify whether a problem, say for u = u(x, t), will admit a
similarity solution by making use of the change of variables
</p>
<p>u(x, t) = Uũ(x̃, t̃ ), x = Lx̃, t = Tt̃, (5.1)
</p>
<p>where U,L,T are un-determined real positive parameters. We call the problem scale
</p>
<p>invariant if relationships exist between the scaling parameters U,L,T in (5.1) that
</p>
<p>make the scaled problem take exactly the same form as the original problem with at
</p>
<p>least one scaling parameter remaining undetermined,
</p>
<p>Problem for u(x, t) &equiv; Problem for ũ(x̃, t̃ ) . (5.2)
</p>
<p>For evolution equations, it expected that the timescale T is the free parameter and
</p>
<p>the other scales can be expressed as U = U(T) and L = L(T).
As an example, consider the inviscid Burgers equation for u(x, t) that was intro-
</p>
<p>duced in Chap.2,
</p>
<p>&part;u
</p>
<p>&part;t
+ u &part;u
</p>
<p>&part;x
= 0, 0 &le; x &lt; &infin;, (5.3a)
</p>
<p>subject to two side conditions,
</p>
<p>u(0, t) = 0,
&int; &infin;
</p>
<p>0
</p>
<p>u(x, t) dx = 4. (5.3b)
</p>
<p>Substituting the change of variables (5.1) into (5.3a, 5.3b) yields,
</p>
<p>&part; ũ
</p>
<p>&part; t̃
+
</p>
<p>(
</p>
<p>UT
</p>
<p>L
</p>
<p>)
</p>
<p>ũ
&part; ũ
</p>
<p>&part; x̃
= 0, 0 &le; x̃ &lt; &infin;, (5.4a)
</p>
<p>ũ(0, t̃ ) = 0, (UL)
&int; &infin;
</p>
<p>0
</p>
<p>ũ(x̃, t̃ ) dx̃ = 4. (5.4b)</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2">http://dx.doi.org/10.1007/978-3-319-23042-9_2</a></div>
</div>
<div class="page"><p/>
<p>5.1 Finding Scaling-Invariant Symmetries 115
</p>
<p>Setting UT/L = 1 and UL = 1 eliminates the scaling constants from (5.4a, 5.4b)
and makes the scaled system identical with (5.3a, 5.3b) and hence the problem is
</p>
<p>scale invariant. From these two relationships, we can express U and L in terms of the
</p>
<p>free parameter T,
</p>
<p>L = T1/2, U = T&minus;1/2. (5.5)
</p>
<p>Consequently, if we have one solution of (5.3a, 5.3b), say u = ũ(x̃, t̃ ), then other
solutions are given by the one-parameter continuous family,
</p>
<p>u(x, t) = T&minus;1/2ũ(T&minus;1/2x,T&minus;1t), (5.6)
</p>
<p>for arbitrary values of T. This transformation is called a scaling symmetry of (5.3)
</p>
<p>[22, 52].
</p>
<p>There is a strong resemblance between the scaling forms (5.1) and (4.22), but there
</p>
<p>is also an important underlying difference. The problems in this chapter will be taken
</p>
<p>to already be in dimensionless form (having been previously nondimensionalized
</p>
<p>using the approachdescribed inChap.4). The scaling parameters in (5.1) are therefore
</p>
<p>dimensionless, corresponding to the magnitudes of solution-, length-, time-, or other
</p>
<p>relevant scales.
</p>
<p>5.2 Determining the Form of the Similarity Solution
</p>
<p>Setting T = 1 in (5.6) returns the original solution and provides no new insight. But,
noting that T is an arbitrary parameter and not part of the original specification of the
</p>
<p>problem suggests that the solution should be independent of T, or more precisely, the
</p>
<p>solution should be invariant with respect to changes in T. We can use this principle
</p>
<p>to yield additional information on the form of the solution.
</p>
<p>In a manner analogous to that used for dimensionless parameters in Chap.4, we
</p>
<p>define a scale-invariant parameter, Π , as a monomial product of powers of the
</p>
<p>variables of the system
</p>
<p>Π = ua xbtc, (5.7)
</p>
<p>which, upon substitution of (5.1), is independent of the undetermined scaling para-
</p>
<p>meter (T). Analogous to the notation we have previously employed for dimensions
</p>
<p>of a quantity, let [Π ] represent the dependence of Π on the scalings U,L,T so that
</p>
<p>[Π ] = UaLbTc = T0, (5.8)
</p>
<p>and in particular for (5.5), this yields
</p>
<p>[Π ] = T&minus;a/2Tb/2Tc = T0.</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4">http://dx.doi.org/10.1007/978-3-319-23042-9_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4">http://dx.doi.org/10.1007/978-3-319-23042-9_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4">http://dx.doi.org/10.1007/978-3-319-23042-9_4</a></div>
</div>
<div class="page"><p/>
<p>116 5 Self-Similar Scaling Solutions of Differential Equations
</p>
<p>We then define a scale invariant independent variable (or &ldquo;similarity variable&rdquo;) and
</p>
<p>the corresponding scale invariant solution (or &ldquo;similarity function&rdquo;) as follows.
</p>
<p>The similarity variable is a scale-invariant productΠ that does not depend on the
</p>
<p>solution u, namely a = 0 in (5.7). Generally it is most convenient to choose a linear
dependence on the independent spatial variable, b = 1, which leads to1
</p>
<p>Π1 = xtc =&rArr; [Π1] = LTc = T0. (5.9)
</p>
<p>For our example, from (5.5), [Π1] = T1/2+c and so we obtain c = &minus;1/2. A common
notation for the similarity variable is the Greek letter η, hence we relabel Π1 as η
</p>
<p>yielding
</p>
<p>η = xt&minus;1/2.
</p>
<p>The similarity function is a scale-invariantΠ that is (most simply) linearly related
</p>
<p>to the solution of the model, namely a = 1 in (5.7). We must make choices for the
exponents b, c in order to represent the solution in the most convenient form; such
</p>
<p>choices are typically guided by the side-conditions present in the problem.
</p>
<p>For convenience in (5.3), we select b = 0 yielding
</p>
<p>Π2 = utc =&rArr; [Π2] = UTc = T0. (5.10)
</p>
<p>This requires that [Π2] = T&minus;1/2+c and hence c = 1/2; we relabel Π2 as f (the
similarity function) which satisfies
</p>
<p>f = t1/2u.
</p>
<p>The main result then follows from the analogous result in the second part of the
</p>
<p>Buckingham Pi theorem (see Sect. 4.5.1)&mdash;that all dimensionless parameters must
</p>
<p>be related to each other. Similarly, this implies that all scale invariant parameters
</p>
<p>must be related, which we state in the form
</p>
<p>F(Π1,Π2) = 0 =&rArr; F(η, f ) = 0.
</p>
<p>Applying the implicit function theorem then gives
</p>
<p>f = f (η) =&rArr; t1/2u = f (xt&minus;1/2).
</p>
<p>and consequently the final form of the similarity solution of the PDE,
</p>
<p>u(x, t) = t&minus;1/2 f (xt&minus;1/2). (5.11)
</p>
<p>1The choice b = 1 leads to a differential equation for the similarity function whose dependence on
η-derivatives will mirror the x-derivatives in the original problem.</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4">http://dx.doi.org/10.1007/978-3-319-23042-9_4</a></div>
</div>
<div class="page"><p/>
<p>5.2 Determining the Form of the Similarity Solution 117
</p>
<p>We note that using this representation of the solution reduces the boundary condition
</p>
<p>at x = 0 for t &gt; 0 to the condition f (0) = 0. If we had instead selected c = 0 in
(5.7), that choice would yieldΠ2 = ux and u(x, t) = x&minus;1g(xt&minus;1/2). The boundary
condition at x = 0 would then be in-determinant (and hence more difficult to work
with).
</p>
<p>5.3 Solving for the Similarity Function
</p>
<p>Once the form of the similarity solution of the PDE has been determined, substituting
</p>
<p>that form into the original problem will yield a reduced problem for the similarity
</p>
<p>function f (η). Substituting (5.11) into (5.3a, 5.3b) gives
</p>
<p>&minus; 1
2
</p>
<p>t&minus;3/2 f (η)&minus; 1
2
</p>
<p>xt&minus;2
d f
</p>
<p>dη
+ t&minus;3/2 f (η)d f
</p>
<p>dη
= 0,
</p>
<p>t&minus;1/2 f (0) = 0,
&int; &infin;
</p>
<p>0
</p>
<p>f (η) dη = 4.
</p>
<p>Noting that the product xt&minus;2 can be rewritten as xt&minus;2 = ηt&minus;3/2, we are able to factor
out all occurrences of the variable t to leave a reduced problem for the similarity
</p>
<p>function,
</p>
<p>f + ηd f
dη
</p>
<p>&minus; 2 f d f
dη
</p>
<p>= 0, f (0) = 0,
&int; &infin;
</p>
<p>0
</p>
<p>f dη = 4. (5.12)
</p>
<p>In this case, we have reduced a PDE to an ODE. The separation between the new
</p>
<p>linearly independent variables t and η is a universal feature of similarity solutions
</p>
<p>stemming from the scale-invariance of the problem. If (5.12) could not be written
</p>
<p>in a form independent of t , then an error must have been introduced in one of the
</p>
<p>previous steps; this is a useful consistency check on the process.
</p>
<p>The ODE for f (η) in (5.12) can then be put in form (η f )&prime; = ( f 2)&prime; and directly
integrated to give
</p>
<p>η f &minus; f 2 = C.
</p>
<p>Evaluating this equation at η = 0 and applying the condition f (0) = 0 then fixes
the value of the constant of integration C = 0 and we are left with two possible
solutions,
</p>
<p>f (η) = 0, or f (η) = η. (5.13)</p>
<p/>
</div>
<div class="page"><p/>
<p>118 5 Self-Similar Scaling Solutions of Differential Equations
</p>
<p>Inserting the nontrivial solution, f (η) = η, into (5.11) we obtain a self-similar
solution of the PDE in the form
</p>
<p>u(x, t) = x/t, (5.14)
</p>
<p>which is known as a rarefaction fan (see Sect. 2.6, Eq. (2.43) for a shifted version
</p>
<p>of this solution obtained via the method of characteristics). Finally, we note that
</p>
<p>satisfying the integral condition in (5.12) necessitates the use of both solutions from
</p>
<p>(5.13) in constructing the solution of (5.3) (compare with Sect. 2.6).
</p>
<p>5.4 Further Comments on Self-Similar Solutions
</p>
<p>It is instructive to contrast the above analysis of problem (5.3a, 5.3b) with the scaling
</p>
<p>and non-dimensionalization performed on problem (4.21a, 4.21b) in Chap.4. The
</p>
<p>PDE (4.21a) is very closely related to (5.3a), and we will show that this equation
</p>
<p>does indeed have similarity solutions of the form (5.11) in Exercise 5.1.
</p>
<p>The scaling of (4.21a, b) yielded fixed constants for all of the scaling parameters
</p>
<p>and hence that problem is not scale invariant. While such fully specified problems set
</p>
<p>specific scales for all variables, appropriately modified versions of such problems
</p>
<p>may have similarity solutions. Such modifications may include omitting initial or
</p>
<p>boundary conditions, changing the domain (say from 0 &le; x &le; L to 0 &le; x &lt; &infin;), or
even omitting some terms from the governing equation. In Chaps. 6 and 7, we will
</p>
<p>see how such changes can be motivated by asymptotic analysis. Solutions of such
</p>
<p>problems may approach the similarity solution in some limit (of a variable or system
</p>
<p>parameter) and are sometimes called asymptotically self-similar solutions.
</p>
<p>5.5 Similarity Solutions of the Heat Equation
</p>
<p>The heat equation (or diffusion equation)
</p>
<p>&part;u
</p>
<p>&part;t
= &part;
</p>
<p>2u
</p>
<p>&part;x2
, (5.15)
</p>
<p>is a classic example in the investigation of symmetries in PDEs because it admits
</p>
<p>several classes of symmetries, each of which corresponds to a different similarity
</p>
<p>solution.
</p>
<p>Applying the scaling (5.1) yields
</p>
<p>&part; ũ
</p>
<p>&part; t̃
=
</p>
<p>(
</p>
<p>T
</p>
<p>L2
</p>
<p>)
</p>
<p>&part;2ũ
</p>
<p>&part; x̃2
.</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2">http://dx.doi.org/10.1007/978-3-319-23042-9_2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2">http://dx.doi.org/10.1007/978-3-319-23042-9_2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4">http://dx.doi.org/10.1007/978-3-319-23042-9_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4">http://dx.doi.org/10.1007/978-3-319-23042-9_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4">http://dx.doi.org/10.1007/978-3-319-23042-9_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4">http://dx.doi.org/10.1007/978-3-319-23042-9_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6">http://dx.doi.org/10.1007/978-3-319-23042-9_6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7">http://dx.doi.org/10.1007/978-3-319-23042-9_7</a></div>
</div>
<div class="page"><p/>
<p>5.5 Similarity Solutions of the Heat Equation 119
</p>
<p>Note that U scales out due to the linearity of the equation, and must be determined by
</p>
<p>side conditions that further specify the problem.Making the PDE scale-invariant fixes
</p>
<p>the relationship between the length- and time-scales for diffusive solutions, L =
&radic;
</p>
<p>T
</p>
<p>(recall the discussion of the diffusive timescale in Sect. 4.3.3). Consequently, we can
</p>
<p>writeΠ1 = η = xt&minus;1/2 as the similarity variable for all typical problems for (5.15).
In the context of the linear diffusion equation, we will now consider how the
</p>
<p>choice of side conditions can affect the overall structure of the similarity solution.
</p>
<p>5.5.1 Source-Type Similarity Solutions
</p>
<p>Consider (5.15) on &minus;&infin; &lt; x &lt; &infin; starting from a non-negative initial condition at
t = 0 that decays rapidly, u(|x | &rarr; &infin;) &rarr; 0. Assuming no flux from infinity, the
solution will maintain its initial mass (assumed finite),
</p>
<p>&int; &infin;
</p>
<p>&minus;&infin;
u(x, t) dx =
</p>
<p>&int; &infin;
</p>
<p>&minus;&infin;
u(x, 0) dx = M.
</p>
<p>This integral constraint will be scale invariant if UL = 1. Consequently, U = T&minus;1/2,
and Π2 = ut1/2, yielding the form of the similarity solution,
</p>
<p>u(x, t) = t&minus;1/2 f (xt&minus;1/2).
</p>
<p>Substituting this form into (5.15) yields the ODE for f (η),
</p>
<p>&minus; 1
2
( f + η f &prime;) = f &prime;&prime;, (5.16)
</p>
<p>which can be re-written as&minus; 1
2
(η f )&prime; = f &prime;&prime; and integrated by separation of variables.
</p>
<p>The non-negative solution of this problem is
</p>
<p>f (η) = M&radic;
4π
</p>
<p>e&minus;η
2/4
</p>
<p>and corresponds to the solution of the heat equation,
</p>
<p>u(x, t) = M&radic;
4π t
</p>
<p>e&minus;x
2/(4t) (5.17)
</p>
<p>which is known as the Cauchy similarity solution or the source-type similarity solu-
</p>
<p>tion, based on its role as the solution of the heat equation starting from a point source
</p>
<p>(with strength M) at the origin at t = 0 (Fig. 5.1). The &lsquo;Cauchy solution&rsquo; label for
(5.17) stems from the fact that it solves the Cauchy problem for the PDE, namely, an
</p>
<p>initial value problem on the whole line &minus;&infin; &lt; x &lt; &infin;.</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4">http://dx.doi.org/10.1007/978-3-319-23042-9_4</a></div>
</div>
<div class="page"><p/>
<p>120 5 Self-Similar Scaling Solutions of Differential Equations
</p>
<p>Fig. 5.1 (Left) The Cauchy similarity solution (5.17), (Right) The Boltzmann similarity solution
</p>
<p>(5.20)
</p>
<p>Note that (5.15) is also invariant under translations in space, x = x̃ +a, and time,
t = t̃ +b; namely ũ = u(x̃, t̃) is also a solution of the heat equation for any choice of
the shifts a and b. A consequence is that (5.17) can be used to describe the long-time
</p>
<p>behaviour for more general initial conditions, with parameters that depend only on
</p>
<p>the mass, centre of mass and variance of the initial data (see Chap.11).
</p>
<p>5.5.2 The Boltzmann Similarity Solution
</p>
<p>Consider (5.15) on the semi-infinite domain 0 &le; x &lt; &infin;with the Dirichlet boundary
conditions
</p>
<p>u(x = 0, t) = 1, u(x &rarr; &infin;) &rarr; 0.
</p>
<p>Having the boundary condition at x = 0 be scale invariant requires U = 1. We
therefore find that Π2 = u and the similarity solution takes the form
</p>
<p>u(x, t) = f (xt&minus;1/2),
</p>
<p>with f (η) satisfying the ODE
</p>
<p>&minus; 1
2
η f &prime; = f &prime;&prime;, (5.18)
</p>
<p>which can be integrated once to yield a Gaussian, and then formally again as the
</p>
<p>integral of the Gaussian,
</p>
<p>f (η) = 1&minus; erf(η/2),
</p>
<p>where the error function is defined as
</p>
<p>erf(z) &equiv; 2&radic;
π
</p>
<p>&int; z
</p>
<p>0
</p>
<p>e&minus;t
2
</p>
<p>dt, (5.19)</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_11">http://dx.doi.org/10.1007/978-3-319-23042-9_11</a></div>
</div>
<div class="page"><p/>
<p>5.5 Similarity Solutions of the Heat Equation 121
</p>
<p>yielding the similarity solution
</p>
<p>u(x, t) = 1&minus; erf
(
</p>
<p>x/
&radic;
4t
</p>
<p>)
</p>
<p>. (5.20)
</p>
<p>5.6 A Nonlinear Diffusion Equation
</p>
<p>Finally, we consider the similarity solution for the Cauchy problem for a nonlinear
</p>
<p>diffusion equation,
&part;u
</p>
<p>&part;t
= &part;
</p>
<p>&part;x
</p>
<p>(
</p>
<p>u3
&part;u
</p>
<p>&part;x
</p>
<p>)
</p>
<p>, (5.21a)
</p>
<p>with
</p>
<p>ux (0, t) = 0,
&int; &infin;
</p>
<p>&minus;&infin;
u dx = M. (5.21b)
</p>
<p>This PDE, often called the porous medium equation, models the spreading of a
</p>
<p>puddle of very viscous fluid (such as honey) on a flat solid surface moving under the
</p>
<p>influence of gravity [1].Here,u(x, t) represents the height of thefluid layer at location
</p>
<p>x and time t ; physically meaningful solutions of this problem will necessarily have
</p>
<p>u(x, t) &ge; 0. The finite-mass similarity solution of this problem will have compact
support. In other words, it will be positive on a finite domain,2 &minus;x&lowast;(t) &lt; x &lt; x&lowast;(t),
with u &equiv; 0 for |x | &ge; x&lowast;(t) where x&lowast;(t) is called the interface or contact line.
</p>
<p>Proceeding as before, making the PDE scale invariant, yields the relation U3 =
L2/T while the integral sets UL = 1. This yields the scalings
</p>
<p>L = T1/5 U = T&minus;1/5,
</p>
<p>and determines the form of the similarity solution as
</p>
<p>u(x, t) = t&minus;1/5 f (xt&minus;1/5).
</p>
<p>Substituting this form back into the original system reduces it to an ODE problem
</p>
<p>for f (η)
</p>
<p>&minus; 1
5
(η f )&prime; = ( f 3 f &prime;)&prime;, f &prime;(0) = 0,
</p>
<p>&int; η&lowast;
</p>
<p>&minus;η&lowast;
f dη = M, (5.22)
</p>
<p>2Without loss of generality, we assume the support to be symmetric relative to the origin.</p>
<p/>
</div>
<div class="page"><p/>
<p>122 5 Self-Similar Scaling Solutions of Differential Equations
</p>
<p>Fig. 5.2 (Left) The u(x, t) lowering/spreading self-similar solution profiles (5.23) at several times,
</p>
<p>(Right) The profiles scaled in terms of t1/5u = f and t&minus;1/5x = η showing the similarity function
</p>
<p>where η&lowast; is a constant to be determined, related to the interface position by x&lowast;(t) =
η&lowast;t1/5. The general solution of the differential equation can be obtained in closed
form and, upon application of the boundary condition at η = 0, reduces to
</p>
<p>f 3 = C2 &minus;
1
</p>
<p>10
η2.
</p>
<p>Finally, for fixed initial mass M , the integral condition combined with continuity
</p>
<p>of the solution (i.e. f (&plusmn;η&lowast;) = 0) determines C2 and η&lowast;, thereby specifying f
completely as
</p>
<p>u(x, t) = 1
t1/5
</p>
<p>(
</p>
<p>C2 &minus;
x2
</p>
<p>10t2/5
</p>
<p>)1/3
</p>
<p>, (5.23)
</p>
<p>see Fig. 5.2.
</p>
<p>5.7 Further Directions
</p>
<p>In the examples, we have seen how a PDE problem can sometimes be reduced to an
</p>
<p>ODEproblem through the determination of a self-similar solution. In other problems,
</p>
<p>scaling invariance may be used to reduce PDEs in terms of several variables to
</p>
<p>PDE depending on fewer variables, or to generate autonomous ODEs from non-
</p>
<p>autonomous ones.
</p>
<p>The books by Barenblatt [9, 10] are an excellent introduction to problems (taken
</p>
<p>from various different fields) that admit similarity solutions. Also see [2, 3, 88]
</p>
<p>for example. Other books provide extensive discussion on constructing similarity
</p>
<p>solutions [22, 52], and the theory of symmetries of PDEs [14, 32].</p>
<p/>
</div>
<div class="page"><p/>
<p>5.8 Exercises 123
</p>
<p>5.8 Exercises
</p>
<p>5.1 Show that the Burgers equation,
</p>
<p>ut + uux = κuxx ,
</p>
<p>with κ &gt; 0 admits the same form of similarity solution (5.11) as problem (5.3) and
</p>
<p>determine the ODE for f (η).
</p>
<p>5.2 Find the similarity solution of the inviscid Burgers equation (5.3a) with the
</p>
<p>integral condition in (5.3b) replaced by
</p>
<p>&int; &infin;
</p>
<p>0
</p>
<p>u2(x, t) dx = 1.
</p>
<p>Show that the same similarity scalings also apply to the generalised Burgers equation
</p>
<p>(
</p>
<p>1
2
</p>
<p>u2
)
</p>
<p>t
+
</p>
<p>(
</p>
<p>1
3
</p>
<p>u3
)
</p>
<p>x
= κuxx .
</p>
<p>Show that if κ = 0, this PDE reduces to (5.3a).
</p>
<p>5.3 Consider the following problem for u(x, t) on 0 &le; x &le; &infin;:
</p>
<p>&part;u
</p>
<p>&part;t
+ u &part;u
</p>
<p>&part;x
= tσu4, u(0, t) = t3, u(x, 0) = 0.
</p>
<p>(a) Determine the value of the constant σ so that this problem has a similarity
</p>
<p>solution.
</p>
<p>(b) Determine the scalesU,L in terms of the timescaleT for the self-similar solution.
</p>
<p>(c) Write u(x, t) for the similarity solution as a product of some power of t and a
</p>
<p>similarity function f (η). State the ODE for f (η).
</p>
<p>5.4 Consider the heat equation for u(x, t) on the half-line, 0 &le; x &lt; &infin;
</p>
<p>&part;u
</p>
<p>&part;t
= &part;
</p>
<p>2u
</p>
<p>&part;x2
</p>
<p>For each of the following sets of side-conditions, determine: (i) the invariant scalings
</p>
<p>U,L in terms of T, (ii) the form of the self-similar solution u(x, t) in terms of f (η),
</p>
<p>and (iii) the ODE and boundary conditions that f (η) should satisfy.
</p>
<p>(a) u(0, t) = t2 and u(x &rarr; &infin;, t) = 0.
(b) ux (0, t) = 2 and u(x &rarr; &infin;, t) = 0.
(c) ux (0, t) = &minus;u2(0, t) and u(x &rarr; &infin;, t) = 0.</p>
<p/>
</div>
<div class="page"><p/>
<p>124 5 Self-Similar Scaling Solutions of Differential Equations
</p>
<p>(d)
&int; &infin;
0 x
</p>
<p>2u dx = 1 and u(x &rarr; &infin;, t) = 0.
(e) ux (0, t) = &minus;u(0, t) and u(x &rarr; &infin;, t) = 0.
</p>
<p>Hint: Show that this problem does not have a solution following (i, ii), but can
</p>
<p>still be obtained from solving an ODE problem.
</p>
<p>5.5 Determine the scale factors and similarity function ODE for the similarity so-
</p>
<p>lution u(x, t) on &minus;&infin; &lt; x &lt; &infin; for
</p>
<p>&part;u
</p>
<p>&part;t
= &part;
</p>
<p>2u
</p>
<p>&part;x2
+ u4, u(|x | &rarr; &infin;) = 0.
</p>
<p>5.6 Consider the problem for u(x, t) on &minus;&infin; &lt; x &lt; &infin;, see Fig. 5.3,
</p>
<p>&part;u
</p>
<p>&part;t
= &minus; &part;
</p>
<p>&part;x
</p>
<p>(
</p>
<p>u3
&part;u
</p>
<p>&part;x
</p>
<p>)
</p>
<p>&minus; &part;
&part;x
</p>
<p>(
</p>
<p>u
&part;3u
</p>
<p>&part;x3
</p>
<p>)
</p>
<p>,
</p>
<p>&int; &infin;
</p>
<p>&minus;&infin;
u dx = 1.
</p>
<p>(a) Apply the scaling (5.1) in order to determine the self-similar solution in the
</p>
<p>form u(x, t) = tα f (η) with η = x/tβ whose amplitude decays, and width
broadens with increasing time as shown in Fig. 5.3 (left). Determine the ODE
</p>
<p>for the similarity function f (η). The corresponding PDE solution is called an
</p>
<p>infinite-time defocusing solution since it spreads indefinitely.
</p>
<p>(b) Under other conditions, solutions may have a critical time tc such that, when
</p>
<p>the critical time is approached the solution will diverge, u(t ր tc) &rarr; &infin;.
Using (5.1) with t = tc + Tt̃ (with t̃ &le; 0), determine the ODE for the similarity
function f̂ (η̂). This is called afinite-time focusingorfinite-time blow-up solution;
</p>
<p>it diverges in amplitude and narrows in width as the critical time is approached.
</p>
<p>Fig. 5.3 Exercise 5.6: (Left) infinite-time spreading solution, (Right) finite-time blow-up solution</p>
<p/>
</div>
<div class="page"><p/>
<p>5.8 Exercises 125
</p>
<p>5.7 The solution u(r, t) of the following problem describes the height of a circular
</p>
<p>drop of fluid spreadingon a dry surface:
</p>
<p>&part;u
</p>
<p>&part;t
= 1
</p>
<p>4r
</p>
<p>&part;
</p>
<p>&part;r
</p>
<p>(
</p>
<p>ru
&part;u
</p>
<p>&part;r
</p>
<p>)
</p>
<p>on 0 &le; r &lt; &infin; with
</p>
<p>&part;u
</p>
<p>&part;r
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>r=0
= 0,
</p>
<p>&int; &infin;
</p>
<p>0
</p>
<p>u(r, t)r dr = 4.
</p>
<p>The solution is positive over a finite range 0 &le; r &le; r&lowast;(t) with u(r&lowast;(t), t) = 0
defining a moving &ldquo;edge&rdquo; with no fluid beyond this position. In other words, take
</p>
<p>the solution beyond the edge r = r&lowast;(t) to be zero.
(a) Show that this problem is scale invariant.
</p>
<p>(b) Determine the ODE for the similarity function f (η).
</p>
<p>(c) Determine the similarity solution u(r, t) = tα f (η) and r&lowast;(t). (Hint: Explain
why
</p>
<p>&int; &infin;
0 ur dr =
</p>
<p>&int; r&lowast;
0 ur dr )
</p>
<p>5.8 Consider the system of two coupled PDEs for h(x, t) and u(x, t),
</p>
<p>&part;h
</p>
<p>&part;t
+ &part;(hu)
</p>
<p>&part;x
= 0, &part;u
</p>
<p>&part;t
+ u &part;u
</p>
<p>&part;x
= &part;
</p>
<p>3h
</p>
<p>&part;x3
+ h2u.
</p>
<p>(a) Let h = Hh̃(x̃, t̃ ), u = Uũ(x̃, t̃ ), x = Lx̃ , and t = Tt̃ . Determine scaling
relations for H,U,L in terms of T to show that these PDEs are scale invariant.
</p>
<p>(b) Let h = tα f (η), u = tβg(η) and η = xtγ . Find α, β, γ for the similarity
solution for this problem and write the ODEs satisfied by f (η) and g(η).
</p>
<p>5.9 Consider the problem
</p>
<p>&part;u
</p>
<p>&part;t
= &part;
</p>
<p>2u
</p>
<p>&part;x2
+ 1, 0 &le; x &le; &infin;,
</p>
<p>with boundary conditions
</p>
<p>u(x = 0, t) = 0, &part;x u(x &rarr; &infin;, t) = 0.
</p>
<p>Find the similarity solution of this problem and then use this to determine a, b in the
</p>
<p>far-field growth of the solution, u(x &rarr; &infin;, t) = atb and c, d in the derivative of the
solution at the boundary, ux (0, t) = ctd .
Hint: Express your solution in terms of the error function (5.19), which satisfies the
</p>
<p>asymptotic approximations
</p>
<p>erf(x) &sim; 1&minus; e
&minus;x2
</p>
<p>x
&radic;
π
</p>
<p>as x &rarr; &infin;, erf(x) &sim; 2x&radic;
π
</p>
<p>as x &rarr; 0.</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 6
</p>
<p>Perturbation Methods
</p>
<p>As we described in Chap. 4, physical problems can always be scaled and restated
</p>
<p>as dimensionless models. The scaling process identifies the relative importance of
</p>
<p>different physical effects in terms of the magnitudes of the dimensionless parameters
</p>
<p>that appear. In the absence of actual parameter values, problem-specific analytical
</p>
<p>and/or numerical methods are typically necessary to make progress towards a general
</p>
<p>solution. However, if any dimensionless parameters are known to be relatively large
</p>
<p>or small, then so-called perturbation methods can often be employed in order to
</p>
<p>generate accurate approximations to the solution.
</p>
<p>Perturbation methods provide a systematic approach to constructing approximate
</p>
<p>solutions to equations such as
</p>
<p>F(x, ε) = 0, G(x, y, ε) = 0,
dx
</p>
<p>dt
= H(x, ε), . . . , (6.1)
</p>
<p>in the limit of a vanishing small perturbation parameter, ε &rarr; 0. This is accomplished
through the introduction of asymptotic expansions, whereby the original problem is
</p>
<p>decomposed into an ordered sequence of simpler sub-problems. The solutions of
</p>
<p>the sub-problems are then recombined to form an approximate solution to the full
</p>
<p>original problem. This may sound very similar to superposition principles that are
</p>
<p>often used to construct solutions of linear ODE and PDE, but a notable difference
</p>
<p>here is that the original equation (algebraic, ODE or PDE) may be nonlinear.
</p>
<p>6.1 Asymptotic Analysis: Concepts and Notation
</p>
<p>Asymptotic analysis provides the mathematical framework that justifies perturbation
</p>
<p>methods. The term asymptotic implies a limit process and hence every asymptotic
</p>
<p>result must be given in terms of a stated parameter approaching a limiting value; for
</p>
<p>example: e&minus;x &rarr; 1 as x &rarr; 0 or e&minus;x &rarr; 0 as x &rarr; +&infin;.
</p>
<p>&copy; Springer International Publishing Switzerland 2015
</p>
<p>T. Witelski and M. Bowen, Methods of Mathematical Modelling,
</p>
<p>Springer Undergraduate Mathematics Series, DOI 10.1007/978-3-319-23042-9_6
</p>
<p>127</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4">http://dx.doi.org/10.1007/978-3-319-23042-9_4</a></div>
</div>
<div class="page"><p/>
<p>128 6 Perturbation Methods
</p>
<p>Two functions f (ε) and g(ε) are said to be asymptotically equivalent in the limit
</p>
<p>ε &rarr; 0, if
lim
ε&rarr;0
</p>
<p>f (ε)
</p>
<p>g(ε)
= 1. (6.2)
</p>
<p>This relationship is often written more compactly as &ldquo; f &sim; g as ε &rarr; 0&rdquo;. It is
important to note that this definition does not simply just mean that f and g have
</p>
<p>the same limiting values; for functions that approach infinity or vanish in the limit,
</p>
<p>equivalence states that they have the same limiting rate of growth or decay. For
</p>
<p>example, in the limit ε &rarr; 0
</p>
<p>1
</p>
<p>ε
+ 1 &sim;
</p>
<p>1
</p>
<p>ε
, tan
</p>
<p>(
π
2
&minus; ε
</p>
<p>)
</p>
<p>&sim;
1
</p>
<p>ε
, sin(ε) &sim; ε,
</p>
<p>1
</p>
<p>1 &minus; εx
&sim; 1 + εx,
</p>
<p>but sin(ε) ≁ ε2 despite each vanishing in the limit. We therefore see that asymptotic
</p>
<p>equivalence does not imply equality of the functions, but it is a necessary condition for
</p>
<p>them to have the same limiting behaviour. As a consequence, asymptotic equivalence
</p>
<p>is not a unique relationship (it effectively defines equivalence classes of functions).
</p>
<p>For example, cos(
&radic;
ε) &sim; (1 &minus; ε/2) &sim; eε &sim; (1 + ε) as ε &rarr; 0.
</p>
<p>A related description of asymptotic behaviour is given by the order relation,
</p>
<p>&ldquo; f = O(g) as ε &rarr; 0&rdquo; (read as &ldquo; f is big-Oh of g&rdquo;) defined by
</p>
<p>lim
ε&rarr;0
</p>
<p>f (ε)
</p>
<p>g(ε)
= A, (6.3)
</p>
<p>where A is finite. The statement f = O(g), identifies the function f (ε) as having
comparable growth or decay as g(ε) as ε &rarr; 0. For example, sin(ε) = O(4ε) as
ε &rarr; 0, and N ! = O(N N+1/2e&minus;N ) as N &rarr; &infin;. The latter result is known as
Stirling&rsquo;s formula [13], a central result for estimating large combinatorial values in
</p>
<p>computing and probability applications. The notation O(1) is often used to describe
</p>
<p>expressions having finite limiting values and separates quantities that are singular
</p>
<p>( f &rarr; &infin; as in f = O(ε&minus;1)) from those that vanish ( f &rarr; 0 as in f = O(ε2)) as
ε &rarr; 0.
</p>
<p>There is also a &ldquo;little oh&rdquo; relation, &ldquo; f = o(g)&rdquo; as ε &rarr; 0 (also written as &ldquo; f ≪ g&rdquo;)
describing f being asymptotically smaller than g if
</p>
<p>lim
ε&rarr;0
</p>
<p>f (ε)
</p>
<p>g(ε)
= 0. (6.4)
</p>
<p>The o(&middot;) notation is used to indicate weak effects due to smaller (&ldquo;higher order&rdquo;)
terms that can be neglected in comparison with other larger terms. Since, for example,
</p>
<p>ε2 = o(ε) we may then write 2ε + 3ε2 &sim; 2ε. The o(&middot;) notation is also often used</p>
<p/>
</div>
<div class="page"><p/>
<p>6.1 Asymptotic Analysis: Concepts and Notation 129
</p>
<p>to state that the difference between two results is smaller than a specified reference
</p>
<p>quantity, as in
</p>
<p>eε &minus;
(
</p>
<p>1 + ε + 1
2
ε2
</p>
<p>)
</p>
<p>= o(ε2) =&rArr; eε = 1 + ε + 1
2
ε2 + o(ε2). (6.5)
</p>
<p>We note that our descriptions of these asymptotic relations in terms of limits of
</p>
<p>ratios are actually convenient simplifications of more rigorous definitions. In partic-
</p>
<p>ular, f = O(g) if | f | &le; A|g| for all sufficiently small ε [13, 72]. The simplifications
are sufficient for most cases, but can fail if the limit is not defined. For example, it is
</p>
<p>true that sin(x) = O(1) as x &rarr; &infin; since | sin(x)| is bounded by one, even though
is does not have a limit. Asymptotic equivalence is more generally defined along the
</p>
<p>lines of (6.5), in terms of the difference between the functions being small, f &sim; g if
f &minus; g = o(g).
</p>
<p>6.2 Asymptotic Expansions
</p>
<p>Having established the order notation, we can now describe the structure of basic
</p>
<p>asymptotic expansions. Consider a function x(t, ε) that can be expanded in terms of
</p>
<p>a &ldquo;separation of variables&rdquo;-type series
</p>
<p>x(t, ε) = δ0(ε)x0(t)+ δ1(ε)x1(t)+ δ2(ε)x2(t)+ &middot; &middot; &middot; , (6.6)
</p>
<p>where it is assumed that all xn = O(1) and the gauge functions {δn(ε)} are asymp-
totically ordered in size as ε &rarr; 0 so that
</p>
<p>δ0(ε) ≫ δ1(ε) ≫ δ2(ε) ≫ &middot; &middot; &middot; . (6.7)
</p>
<p>Equations (6.6) and (6.7) define the basic form of an asymptotic expansion (AE) and,
</p>
<p>in particular, (6.6) separates the dependence on the asymptotic parameter ε in each
</p>
<p>term from the coefficients xn (which may, in general, also be functions of other
</p>
<p>independent variables and parameters in the model). The first term in the expansion
</p>
<p>(6.6) is usually referred to as the leading order term, x &sim; δ0x0.
There are subtle differences in the way one might write the basic content of the first
</p>
<p>few terms of an asymptotic expansion based on our previous discussion of asymptotic
</p>
<p>ordering. Consider
</p>
<p>x &sim; δ0x0 + δ1x1 + δ2x2,
x = δ0x0 + δ1x1 + O(δ2),
x = δ0x0 + δ1x1 + o(δ1).
</p>
<p>(6.8)
</p>
<p>The first expression gives the first three terms explicitly, the second gives two terms
</p>
<p>and an estimate on the asymptotic order of the remainder of the expansion, and the
</p>
<p>third expression does not predict δ2 but just states that the omitted contributions are
</p>
<p>all smaller than the last given O(δ1) term which thus effectively provides only the
</p>
<p>information contained in the two term estimate x &sim; δ0x0 + δ1x1.</p>
<p/>
</div>
<div class="page"><p/>
<p>130 6 Perturbation Methods
</p>
<p>A simple example of an asymptotic expansion is provided by the Taylor series of
</p>
<p>a smooth function x(t) expanded in a neighbourhood of a point t&lowast;
</p>
<p>x(t) = x(t&lowast;)+ εx &prime;(t&lowast;)+ 12!ε
2x &prime;&prime;(t&lowast;)+ 13!ε
</p>
<p>3x &prime;&prime;&prime;(t&lowast;)+ &middot; &middot; &middot; , (6.9)
</p>
<p>where ε = t &minus; t&lowast; (cf. (6.6)); in this case, the small parameter is ε, the separation
between the fixed point t&lowast; and the variable t . We know from calculus that in the limit
ε &rarr; 0, an accurate estimate of the value of x(t) in a neighbourhood of t&lowast; can be
obtained from a limited number of terms in the expansion.
</p>
<p>For some functions, the asymptotic expansion can be handled by symbolic algebra
</p>
<p>programs (such as Maple or Mathematica). In Maple, for example, to calculate
</p>
<p>the first six terms in the expansion of x(t) = etan t for t &rarr; 0 (here t is the small
parameter), the command is simply
</p>
<p>&gt; series(exp(tan(t)),t=0);
</p>
<p>1 + t +
1
</p>
<p>2
t2 +
</p>
<p>1
</p>
<p>2
t3 +
</p>
<p>3
</p>
<p>8
t4 +
</p>
<p>37
</p>
<p>120
t5 + O(t6).
</p>
<p>Maple can also generate asymptotic expansions in other limits, such as for x(t) =
1/(1 + 4t) as t &rarr; &infin;
</p>
<p>&gt; asympt(1/(1+4*t),t);
</p>
<p>1
</p>
<p>4
t&minus;1 &minus;
</p>
<p>1
</p>
<p>16
t&minus;2 +
</p>
<p>1
</p>
<p>64
t&minus;3 &minus;
</p>
<p>1
</p>
<p>256
t&minus;4 +
</p>
<p>1
</p>
<p>1024
t&minus;5 + O
</p>
<p>(
</p>
<p>t&minus;6
)
</p>
<p>,
</p>
<p>where the gauge functions are now inverse powers of t ; this result can also be derived
</p>
<p>as a Taylor series expansion with respect to the variable t = 1/ε in the limit ε &rarr; 0.
We note that asymptotic expansions can take more complex forms than (6.6). For
</p>
<p>example, the function x(t, ε) = exp(sin(ε
&radic;
</p>
<p>t)/ε2), has the asymptotic expansion
</p>
<p>x &sim; e
&radic;
</p>
<p>t/ε
</p>
<p>(
</p>
<p>1 &minus;
1
</p>
<p>6
εt3/2 +
</p>
<p>1
</p>
<p>72
ε2t3 + &middot; &middot; &middot;
</p>
<p>)
</p>
<p>as ε &rarr; 0, (6.10)
</p>
<p>which is clearly not of the form (6.6). Our investigations of solutions to equations
</p>
<p>like (6.1) will be further complicated by the fact that the form of the solution is not
</p>
<p>known beforehand and so we will need to find the gauge functions as well as the
</p>
<p>coefficients.
</p>
<p>6.2.1 Divergence of Asymptotic Expansions
</p>
<p>Example (6.10) indicates that asymptotic expansions exist even in cases where con-
</p>
<p>vergent Taylor series do not. In fact, summed over all terms, asymptotic expansions</p>
<p/>
</div>
<div class="page"><p/>
<p>6.2 Asymptotic Expansions 131
</p>
<p>can diverge, but, as we will shall show, this does not prevent partial sums like (6.8)
</p>
<p>from providing accurate results in the vanishing limit of the perturbation parameter.
</p>
<p>In order to illustrate the above points, we consider an example of a function defined
</p>
<p>in terms of an integral, namely
</p>
<p>I (ε) =
&int; &infin;
</p>
<p>0
</p>
<p>e&minus;t
</p>
<p>1 + εt
dt; (6.11)
</p>
<p>such a definition is rather common and includes Fourier and Laplace integrals, as
</p>
<p>well as Mellin, Hankel and many other integral transformations, and a number
</p>
<p>of special functions, such as the Gamma, Beta, Airy and error functions [11, 13,
</p>
<p>29, 56].
</p>
<p>The Taylor series (6.9) of the integrand in the limit ε &rarr; 0 leads to the asymptotic
expansion
</p>
<p>I (ε) &sim; 1 &minus; ε + 2ε2 &minus; 6ε3 + &middot; &middot; &middot; =
&infin;
&sum;
</p>
<p>n=0
(&minus;1)nn!εn . (6.12)
</p>
<p>The standard ratio test for power series requires (n+1)ε &lt; 1, so we find that the series
has a zero radius of convergence (i.e. it diverges for all |ε| &gt; 0 at sufficiently large
values of n). Furthermore, convergence for ε in an interval around zero, &minus;δ &lt; ε &lt; δ,
should not have been expected since for ε &lt; 0 the singularity at t = &minus;1/ε is not
integrable. Despite these issues, Fig. 6.1 shows that (6.12) truncated at a finite number
</p>
<p>of terms provides a good estimate of the value of the integral as ε &rarr; 0+.
To understand this behaviour, consider (6.11) with ε = 1
</p>
<p>10
; the integral can be
</p>
<p>numerically evaluated to give I (0.1) &asymp; 0.915633. For (6.12), the terms in the ex-
pansion remain asymptotically ordered while (n + 1)ε &lt; 1, namely for n &lt; 10.
Recalling that the first term neglected in the asymptotic expansion gives an estimate
</p>
<p>of the error (cf. (6.8)), we see that truncating the expansion up to and including ten
</p>
<p>terms will give a decreasing magnitude for the error, but going beyond ten will lead
</p>
<p>Fig. 6.1 (Left) The magnitude of term an in (6.12) for ε = 0.1. For n &lt; 10, the terms decay in
size, but thereafter start to grow. (Right) I (ε) from (6.11) compared with the partial sums, ĨN (ε),
</p>
<p>of series (6.12) showing the error growing for ε &ge; 0.1 for above the optimal truncation</p>
<p/>
</div>
<div class="page"><p/>
<p>132 6 Perturbation Methods
</p>
<p>to the error increasing in size (see Fig. 6.1). This is in stark contrast to convergent
</p>
<p>series, where retaining more terms always reduces the error.
</p>
<p>To summarise, asymptotic expansions are always accurate in the limit ε &rarr; 0, but
for finite ε, there will be an optimal truncation n = 0, 1, . . . , N (ε), that minimises
the error. In most cases, however, even just the first few terms from the asymptotic
</p>
<p>expansion can yield an excellent approximation to the true solution, as illustrated
</p>
<p>by Ĩ4(ε) in Fig. 6.1. Complications stemming from attempting to interchange limits
</p>
<p>(ε &rarr; 0 and n &rarr; &infin;) will appear in several situations and often signal subtle changes
of behaviour in the asymptotic expansion.
</p>
<p>6.3 The Calculation of Asymptotic Expansions
</p>
<p>Rather than calculating asymptotic expansions of given functions, we are usually
</p>
<p>more interested in constructing an asymptotic expansion of solutions to problems of
</p>
<p>forms like (6.1).
</p>
<p>We begin by calculating asymptotic expansions of solutions to algebraic equa-
</p>
<p>tions, for which the coefficients {xn}n=0,1,2,... in (6.6) are necessarily constants. It
will be useful to classify solutions (and the corresponding asymptotic expansions)
</p>
<p>in the limit ε &rarr; 0 into the following types:
</p>
<p>&bull; Regular solutions, which have finite limits: limε&rarr;0x = x0 with the leading order
gauge function in (6.6) being δ0 &equiv; 1.
</p>
<p>&bull; Vanishing solutions, which are regular solutions with a zero limit, i.e. limε&rarr;0x = 0
with the leading order gauge function satisfying δ0(ε) ≪ 1.
</p>
<p>&bull; Singular solutions, which have divergent limits: limε&rarr;0|x | = &infin;, corresponding
to a finite x0 with a singular δ0(ε) ≫ 1.
</p>
<p>We now introduce two approaches for constructing solutions in the form of as-
</p>
<p>ymptotic expansions known as the expansion method and the iteration method. We
</p>
<p>will illustrate both methods applied to a simple example for which the solutions can
</p>
<p>be found explicitly.
</p>
<p>Consider the quadratic equation
</p>
<p>x2 &minus; x + 1
4
ε = 0 as ε &rarr; 0, (6.13)
</p>
<p>its exact solutions being
</p>
<p>xA,B =
1 &plusmn;
</p>
<p>&radic;
1 &minus; ε
</p>
<p>2
. (6.14)</p>
<p/>
</div>
<div class="page"><p/>
<p>6.3 The Calculation of Asymptotic Expansions 133
</p>
<p>Employing the generalised binomial expansion for f (z) = (1 + z)r , which can be
derived by application of Taylor series,
</p>
<p>(1 + z)r &sim; 1 + r z + r(r&minus;1)
2
</p>
<p>z2 + r(r&minus;1)(r&minus;2)
3! z
</p>
<p>3 + &middot; &middot; &middot; as z &rarr; 0, (6.15)
</p>
<p>with r = 1
2
, z = &minus;ε, allows us to write the two solutions as
</p>
<p>xA = 1 &minus; 14ε &minus;
1
16
ε2 + &middot; &middot; &middot; = O(1),
</p>
<p>xB = 0 + 14ε +
1
16
ε2 + &middot; &middot; &middot; = O(ε).
</p>
<p>(6.16)
</p>
<p>We note that taking ε ≪ 1 directly in (6.13) gives x2 &minus; x &asymp; 0 yielding approximate
solutions x &asymp; 0, 1. In other words, the balance of the first two terms in (6.13)
is important in locating the roots, with the third term only slightly adjusting their
</p>
<p>values (cf. (6.16)). This is the hallmark of a regular perturbation problem, for which
</p>
<p>the limit ε &rarr; 0 only yields regular (i.e. non-singular) solutions with well-defined
limits for ε &rarr; 0.
</p>
<p>We will begin our analysis with the more concise &lsquo;expansion method&rsquo;, which
</p>
<p>benefits from an a priori assumption on the form for the asymptotic expansion being
</p>
<p>sought.
</p>
<p>6.3.1 The Expansion Method
</p>
<p>In order to solve (6.13) without explicit reference to the exact solutions, we assume
</p>
<p>the solutions are regular and have δn = εn for n = 0, 1, 2, . . . (i.e. the sequence of
gauge functions {δn(ε)} is already known), so that
</p>
<p>x = x0 + εx1 + ε2x2 + &middot; &middot; &middot; . (6.17)
</p>
<p>This is a commonly occurring asymptotic expansion for regular solutions, which can
</p>
<p>be thought of as being a Taylor series expansion of the solution with respect to the
</p>
<p>parameter ε around ε = 0.
Substituting (6.17) into Eq. (6.13) yields
</p>
<p>(x0 + εx1 + ε2x2 + &middot; &middot; &middot; )2 &minus; (x0 + εx1 + ε2x2 + &middot; &middot; &middot; )+
1
</p>
<p>4
ε = 0,
</p>
<p>and ordering terms in powers of ε yields
</p>
<p>(
</p>
<p>x20 &minus; x0
)
</p>
<p>+ ε
(
</p>
<p>2x1x0 &minus; x1 +
1
</p>
<p>4
</p>
<p>)
</p>
<p>+ ε2(x21 + 2x0x2 &minus; x2)+ &middot; &middot; &middot; = 0 + ε0 + ε
20 + &middot; &middot; &middot; .</p>
<p/>
</div>
<div class="page"><p/>
<p>134 6 Perturbation Methods
</p>
<p>Assuming that the coefficients are O(1), requiring both sides of the equation to
</p>
<p>balance leads to the system of equations
</p>
<p>O(ε0) : x20 &minus; x0 = 0 &rArr; x0 = 1 or x0 = 0,
O(ε1) : 2x1x0 &minus; x1 + 14 = 0 &rArr; x1 = &minus;1/4 | x1 = 1/4,
O(ε2) : x21 + 2x0x2 &minus; x2 = 0 &rArr; x2 = &minus;1/16 | x2 = 1/16,
</p>
<p>(6.18)
</p>
<p>and so on for higher orders. Note that only the leading order equation is nonlinear;
</p>
<p>subsequent corrections depend on which of the leading order solutions is considered.
</p>
<p>Comparing the coefficients resulting from (6.18) with (6.16), we observe that we have
</p>
<p>obtained the asymptotic expansions for both solutions of (6.13).
</p>
<p>6.3.2 The Iteration Method
</p>
<p>In contrast to the expansion method, we no longer assume a form for the entire
</p>
<p>asymptotic expansion, but instead only look (initially) at the leading order term
</p>
<p>x &sim; x0δ0(ε), with both x0 and δ0(ε) to be determined. There are two fundamental
assumptions made in relation to the leading order term:
</p>
<p>(i) For every nontrivial solution (i.e. not all xn = 0), the leading order term must
be nontrivial: x0 �= 0 and δ0 �= 0.1
</p>
<p>(ii) The leading order coefficient is finite, x0 = O(1) as ε &rarr; 0 (i.e. we are looking
for regular solutions; we tackle singular solutions later).
</p>
<p>Substituting the leading order term into (6.13) yields
</p>
<p>x20δ
2
0
</p>
<p>︸︷︷︸
</p>
<p>(1)
</p>
<p>&minus; x0δ0
︸︷︷︸
</p>
<p>(2)
</p>
<p>+ 1
4
ε
</p>
<p>︸︷︷︸
</p>
<p>(3)
</p>
<p>= 0. (6.19)
</p>
<p>In order for this equation to hold as ε &rarr; 0, at least two of the terms must balance in
asymptotic scales, with the remaining terms being sub-dominant (i.e. asymptotically
</p>
<p>smaller than the retained terms as ε &rarr; 0). The smaller terms can then be neglected
in determining the leading order solution. The set of dominant terms that balance to
</p>
<p>yield the leading order solutions are called the dominant terms and this argument is
</p>
<p>referred to as the principle of dominant balance.
</p>
<p>Ignoring all O(1) coefficients for the time-being, consider the three possibilities
</p>
<p>for balancing the asymptotic gauges of the potential dominant terms in (6.19):
</p>
<p>(a) Terms (1, 2): δ20 = δ0 &rArr; δ0 = 1
(b) Terms (1, 3): δ20 = ε &rArr; δ0 =
</p>
<p>&radic;
ε
</p>
<p>(c) Terms (2, 3): δ0 = ε &rArr; δ0 = ε
(6.20)
</p>
<p>1Trivial solutions (x &equiv; 0) are exact solutions only if they satisfy the full problem for all ε.</p>
<p/>
</div>
<div class="page"><p/>
<p>6.3 The Calculation of Asymptotic Expansions 135
</p>
<p>In case (a), δ0 = 0 is excluded by the first fundamental assumption (that δ0 should
be non-zero). It is also clear that for this problem, all three terms cannot be of the
</p>
<p>same asymptotic order.
</p>
<p>For each of the proposed balances, we must now attempt to verify the principle
</p>
<p>of dominant balance. Namely, it is essential to confirm that all sub-dominant terms
</p>
<p>which have been omitted from the dominant balance are indeed smaller than the
</p>
<p>dominant terms. When this occurs, the balance is called a distinguished limit.
</p>
<p>For the three possible balances in (6.20) we see that
</p>
<p>(a) Terms (1, 2) : δ20 = δ0 = O(1) ≫ Term (3) : epsilon = O(ε)
(b) Terms (1, 3) : δ20 = ε = O(ε) �≫ Term (2) : δ0 = O(
</p>
<p>&radic;
ε)
</p>
<p>(c) Terms (2, 3) : δ0 = ε = O(ε) ≫ Term (1) : δ20 = O(ε2)
</p>
<p>In case (b), we see that the second term is not sub-dominant to the first and third
</p>
<p>terms, and so is not a valid balance. This leaves cases (a) and (c) as valid dominant
</p>
<p>balances leading to distinguished limits.
</p>
<p>The coefficients in each case can now be obtained:
</p>
<p>(a) δ0 = 1: Eq. (6.19) becomes x20 &minus; x0+
1
4
ε = 0. Thus, as ε &rarr; 0, the leading order
</p>
<p>dominant balance determines the leading order coefficient from
</p>
<p>x20 &minus; x0 = 0 &rArr; x0 = 1,
</p>
<p>where we reject the root x0 = 0 in line with assumption (i) above. We see that
x0 = 1 corresponds to the first term in xA from (6.16).
</p>
<p>(c) δ0 = ε: Eq. (6.19) takes the form εx20 &minus; x0 +
1
4
= 0 (where we have divided
</p>
<p>through by the common factor ε). The rescaled leading order equation yields
</p>
<p>x0 = 1/4, which together with δ0 = ε determines the first term in xB &sim; 14ε
from (6.16).
</p>
<p>Further terms in the expansion of each solution can be obtained by repeating the
</p>
<p>process: determining the distinguished limits for the gauge functions δi (ε) and the
</p>
<p>values for the coefficients xi using
</p>
<p>xA &sim; 1 + δ1Ax1A and xB &sim; 14ε + δ1B x1B,
xA &sim; 1 + δ1Ax1A + δ2Ax2A and xB &sim; 14ε + δ1B x1B + δ2Ax2A,
</p>
<p>and so on, substituting into (6.13) at each step and requiring that the gauge functions
</p>
<p>be asymptotically ordered, i.e. 1 ≫ δ1A ≫ δ2A and ε ≫ δ1B ≫ δ2B . In this manner,
we can obtain the expansions of xA and xB from (6.16).
</p>
<p>Obviously, as more terms are retained in the expansion, the determination of the
</p>
<p>dominant balance requires an increasing amount of work and this can be a substantial
</p>
<p>drawback of the iterative approach. Consequently, the expansion method is often
</p>
<p>favoured in obtaining a rapid result. However, while both roots for this example
</p>
<p>could be obtained using the expansion (6.17), we will encounter many situations for
</p>
<p>which the principle of dominant balance will be particularly useful.</p>
<p/>
</div>
<div class="page"><p/>
<p>136 6 Perturbation Methods
</p>
<p>6.3.3 Further Examples
</p>
<p>Suppose we wish to find the roots of the transcendental equation
</p>
<p>x2 &minus; 2x + ε sin x = 0 as ε &rarr; 0. (6.21)
</p>
<p>This equation does not admit explicit expressions for all roots, but it can be seen that
</p>
<p>x = 0 is a solution for any ε. Setting ε = 0 in (6.21) gives the leading order equation
</p>
<p>x20 &minus; 2x0 = 0 &rArr; x0 = 0 or x0 = 2. (6.22)
</p>
<p>We will focus on the expansion for the nontrivial root, see Fig. 6.2.
</p>
<p>While we may again proceed by hand, we take this opportunity to demonstrate how
</p>
<p>symbolic algebra software can be employed to perform some of the computationally
</p>
<p>intensive calculations. Using Maple, we write
&gt; eps:=epsilon;
</p>
<p>eps := ε
&gt; eq:=xˆ2-2*x+eps*sin(x);
</p>
<p>eq := x2 &minus; 2 x + ε sin (x)
&gt; x:=x0+eps*x1+epsˆ2*x2+epsˆ3*x3;
</p>
<p>x := x0 + ε x1 + ε2x2 + ε3x3
&gt; eqser:=series(eq,eps=0,3);
</p>
<p>eqser := x02 &minus; 2 x0 + (2 x0 x1 &minus; 2 x1 + sin (x0)) ε
</p>
<p>+
(
</p>
<p>2 x0 x2 + x12 &minus; 2 x2 + cos (x0) x1
)
</p>
<p>ε2 + O
(
</p>
<p>ε3
)
</p>
<p>&gt; order0:=coeff(eqser,eps,0);
</p>
<p>order0 := x02 &minus; 2 x0
&gt; order1:=coeff(eqser,eps,1);
</p>
<p>order1 := 2 x0 x1 &minus; 2 x1 + sin (x0)
&gt; order2:=coeff(eqser,eps,2);
</p>
<p>order2 := 2 x0 x2 + x12 &minus; 2 x2 + cos (x0) x1
</p>
<p>Fig. 6.2 Convergence of the
</p>
<p>function
</p>
<p>f (x, ε) = x2 &minus; 2x + ε sin x
for ε = 1
</p>
<p>2
, 1
</p>
<p>4
, 1
</p>
<p>8
to the ε = 0
</p>
<p>limit</p>
<p/>
</div>
<div class="page"><p/>
<p>6.3 The Calculation of Asymptotic Expansions 137
</p>
<p>The series() command performs a Taylor series expansion on the equation. The
</p>
<p>order0 equation is simply our leading order problem (6.22). Separating out the
</p>
<p>coefficient of O(ε1) and substituting the value x0 = 2 into order1 yields the
value for x1 = &minus; 12 sin 2. Continuing on, the order2 equation gives x2 =
</p>
<p>1
4
</p>
<p>sin 2&minus;
1
8
</p>
<p>sin2 2. The expansion up to O(ε3) for the nontrivial root is therefore
</p>
<p>x = 2 &minus;
1
</p>
<p>2
(sin 2)ε +
</p>
<p>(
1
</p>
<p>4
sin 2 &minus;
</p>
<p>1
</p>
<p>8
sin2 2
</p>
<p>)
</p>
<p>ε2 + O(ε3).
</p>
<p>To recap, when the expansion method works, it is a very straightforward approach
</p>
<p>to carry out, either by hand or with the aid of computer software. The limitation of
</p>
<p>the method is that it will fail to construct solutions that are not of the form assumed
</p>
<p>for the asymptotic expansion. The trial solution need not be (6.17) (experience can
</p>
<p>provide good guesses), but the choice of the gauge functions δn must be known before
</p>
<p>this method can be used.
</p>
<p>Our next example introduces a problem for which the expansion method using
</p>
<p>the asymptotic expansion (6.17) fails, and consequently illustrates the strengths of
</p>
<p>the iteration method. Consider the ε &rarr; 0 limit of the equation
</p>
<p>(x &minus; 1)2 &minus; 9ε = 0. (6.23)
</p>
<p>Substituting the expansion (6.17) into Eq. (6.23) leads to the system of equations
</p>
<p>O(ε0) : (x0 &minus; 1)2 = 0 &rArr; x0 = 1 or x0 = 1,
O(ε1) : 2x1(x0 &minus; 1)&minus; 9 = 0 &rArr; &minus;9 = 0 (&times;?)
O(ε2) : x21 + 2(x0 &minus; 1)x2 = 0
...
</p>
<p>Substituting the leading order double root into the O(ε) equation has yielded&minus;9 = 0,
a clear contradiction. This indicates that our choice for the expansion of x was
</p>
<p>incorrect, namely that the solutions of (6.23) are not of the assumed form (6.17). In
</p>
<p>fact, as is trivial to verify, the exact solutions are x = 1 &plusmn; 3
&radic;
ε.
</p>
<p>Applying the iteration method to (6.23) with x &sim; x0δ0(ε) + x1δ1(ε), we would
find directly that the first two gauge functions are given by δ0 = 1 and δ1 =
</p>
<p>&radic;
ε and
</p>
<p>the coefficients are x0 = 1, 1 and x1 = &plusmn;3; looking for higher-order terms would
yield coefficients xi = 0 for i &ge; 2.
</p>
<p>Problems having degenerate (repeated) leading order roots should always be
</p>
<p>treated with caution regarding their expansions. There are also many problems re-
</p>
<p>quiring non-algebraic gauge functions (δ(ε) �= εα); such problems frequently arise
from transcendental equations (see [47, 49]).</p>
<p/>
</div>
<div class="page"><p/>
<p>138 6 Perturbation Methods
</p>
<p>6.4 A Regular Expansion for a Solution of an ODE Problem
</p>
<p>The expansion and iteration methods also extend to solving ODE and PDE problems,
</p>
<p>the only major difference being that at each order we will have to determine a function
</p>
<p>rather than just a constant coefficient.
</p>
<p>We now illustrate the application of the expansion method to find the solution of
</p>
<p>an ordinary differential equation using the projectile problem (4.7a) introduced in
</p>
<p>Chap. 4,
</p>
<p>d2x
</p>
<p>dt2
= &minus;
</p>
<p>1
</p>
<p>(1 + εx)2
, x(0) = 1, x &prime;(0) = α, (6.24)
</p>
<p>in the limit ε &rarr; 0. We begin by substituting the asymptotic expansion x(t) &sim;
x0(t)+ εx1(t)+ ε2x2(t)+ &middot; &middot; &middot; into the ODE and initial conditions. The expansion
for the left-hand side of the ODE is simply
</p>
<p>d2x
</p>
<p>dt2
= x &prime;&prime;0 (t)+ εx &prime;&prime;1 (t)+ ε2x &prime;&prime;2 (t)+ &middot; &middot; &middot;
</p>
<p>and using the binomial expansion (6.15) with r = &minus;2, z = εx , the right-hand side
becomes
</p>
<p>&minus;
1
</p>
<p>(1 + εx)2
= &minus;1 + 2εx &minus; 3ε2x2 + 4ε3x3 + &middot; &middot; &middot; (6.25)
</p>
<p>In fact, this needs to be further expanded using the asymptotic expansion for x(t) to
</p>
<p>yield
</p>
<p>= &minus;1 + 2ε(x0 + εx1 + &middot; &middot; &middot; )&minus; 3ε2(x0 + εx1 + &middot; &middot; &middot; )2 + &middot; &middot; &middot;
= &minus;1 + 2εx0 + ε2(2x1 &minus; 3x20 )+ ε3(2x2 &minus; 6x0x1 + &middot; &middot; &middot; )+ O(ε4).
</p>
<p>The initial conditions provide initial conditions on the coefficient functions xn(t) of
</p>
<p>the asymptotic expansion through a comparison at each order in ε
</p>
<p>x(0) = 1 =&rArr; x0(0)+ εx1(0)+ ε2x2(0)+ &middot; &middot; &middot; = 1 + ε0 + ε20 + &middot; &middot; &middot; ,
</p>
<p>x &prime;(0) = α =&rArr; x &prime;0(0)+ εx &prime;1(0)+ ε2x &prime;2(0)+ &middot; &middot; &middot; = α + ε0 + ε20 + &middot; &middot; &middot; .
</p>
<p>We can now separate the original ODE problem (6.24) into sub-problems for each
</p>
<p>xn(t) at O(ε
n)
</p>
<p>O(ε0) : x &prime;&prime;0 = &minus;1 x0(0) = 1 x &prime;0(0) = α,
O(ε1) : x &prime;&prime;1 = 2x0 x1(0) = 0 x &prime;1(0) = 0,
O(ε2) : x &prime;&prime;2 = 2x1 &minus; 3x20 x2(0) = 0 x &prime;2(0) = 0,
</p>
<p>and so on. The solution to the higher order problems depends on the solutions from
</p>
<p>the lower order ones and so we must solve the sub-problems in sequence. Solving the</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4">http://dx.doi.org/10.1007/978-3-319-23042-9_4</a></div>
</div>
<div class="page"><p/>
<p>6.4 A Regular Expansion for a Solution of an ODE Problem 139
</p>
<p>O(ε0) problem yields the leading order solution, x0(t) = &minus; 12 t
2+αt+1. Substituting
</p>
<p>x0 into the O(ε
1) equation we obtain,
</p>
<p>x &prime;&prime;1 = &minus;t2 + 2αt + 2 =&rArr; x1(t) = &minus; 112 t
4 + α
</p>
<p>3
t3 + t2
</p>
<p>and results at higher orders follow analogously. Reassembling the asymptotic expan-
</p>
<p>sion for the solution gives
</p>
<p>x(t) =
(
</p>
<p>&minus; 1
2
</p>
<p>t2 + αt + 1
)
</p>
<p>+ ε
(
</p>
<p>&minus; 1
12
</p>
<p>t4 + α
3
</p>
<p>t3 + t2
)
</p>
<p>+ O(ε2). (6.26)
</p>
<p>Physically, the flight of the projectile ends when the ground is reached (0 &le; t &le; t&lowast;
for x(t&lowast;) = 0), but mathematically, there is nothing stopping us from considering the
behaviour predicted by (6.26) for longer times. Note that the asymptotic ordering of
</p>
<p>the expansion breaks down with O(x0) = O(εx1) = O(1/ε) when t = O(1/
&radic;
ε)
</p>
<p>and the construction of the solution would also break down at this point, since the
</p>
<p>assumption that |εx1| ≪ |x0| implicit in (6.25) would be violated. This is a common
occurrence for asymptotic expansions and we will also see examples of systems in
</p>
<p>Chaps. 7 and 8 where such difficulties arise. Such a breakdown indicates a transition
</p>
<p>in scaling regimes and the resolution of the problem involves identification of the
</p>
<p>appropriate new scaling. In the next section, we will consider this issue further in the
</p>
<p>context of determining solutions to singular perturbation problems.
</p>
<p>6.5 Singular Perturbation Problems
</p>
<p>Problems having one or more solutions that exhibit singular (divergent) behaviour
</p>
<p>in the limit ε &rarr; 0 are called singular perturbation problems. The singular solutions
are not obtainable from asymptotic expansions appropriate to regular solutions, such
</p>
<p>as (6.17); attempts to use such asymptotic expansions will return only a subset of the
</p>
<p>solutions of the full problem, or at worst, no solutions at all (see Exercise 6.3).
</p>
<p>This behaviour is inherent to all classes of singular perturbation problems:
</p>
<p>&bull; For algebraic equations, a singularly perturbed N th degree polynomial will only
have M regular solutions, with M &lt; N if the leading order equation reduces to an
</p>
<p>M th degree polynomial for x0 due to terms of the form ε
px K (p &gt; 0) vanishing
</p>
<p>for M &lt; K &le; N .
&bull; For differential equations, if the limit ε &rarr; 0 causes the highest order derivative to
</p>
<p>vanish (e.g. ε pd N x/dt N ), the leading order solution of the remaining lower order
</p>
<p>problem will typically not have enough degrees of freedom to satisfy all of the
</p>
<p>initial or boundary conditions imposed on the original problem.</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7">http://dx.doi.org/10.1007/978-3-319-23042-9_7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_8">http://dx.doi.org/10.1007/978-3-319-23042-9_8</a></div>
</div>
<div class="page"><p/>
<p>140 6 Perturbation Methods
</p>
<p>&bull; Likewise, in other classes of singular problems, the ε = 0 leading order problem
may be dramatically reduced from the full problem for ε &gt; 0, for example:
</p>
<p>a singular PDE reducing to an ODE, a singular ODE reducing to an algebraic
</p>
<p>equation, or a system of equations reducing to a single equation.
</p>
<p>The non-regular solutions are not truly lost by such reductions, and can be recovered
</p>
<p>through appropriate rescalings of the original problem. Which solutions are obtained
</p>
<p>depends on the scaling of the problem and the form of the asymptotic expansion
</p>
<p>assumed for the solution.
</p>
<p>As an example, consider the ε &rarr; 0 limit of the (immediately solvable) algebraic
equation
</p>
<p>εx2 &minus; 2x + 1 = 0. (6.27)
</p>
<p>Substituting ε = 0 into (6.27) gives
</p>
<p>&minus; 2x + 1 = 0 &rArr; x = 1
2
. (6.28)
</p>
<p>This leading order equation therefore only yields one of the two roots expected from
</p>
<p>the second-degree equation (6.27). The exact solutions of (6.27) can be written as
</p>
<p>x =
1 &plusmn;
</p>
<p>&radic;
1 &minus; ε
ε
</p>
<p>&sim;
1 &plusmn;
</p>
<p>(
</p>
<p>1 &minus; 1
2
ε &minus; 1
</p>
<p>8
ε2 + O(ε3)
</p>
<p>)
</p>
<p>ε
, (6.29)
</p>
<p>from which we see that
</p>
<p>xA &sim;
2
</p>
<p>ε
&minus;
</p>
<p>1
</p>
<p>2
&minus;
</p>
<p>ε
</p>
<p>8
, xB &sim;
</p>
<p>1
</p>
<p>2
+
</p>
<p>ε
</p>
<p>8
+
</p>
<p>ε2
</p>
<p>16
. (6.30)
</p>
<p>Equation (6.28) produced only the leading order term of the regular solution xB .
</p>
<p>The xA solution diverges as ε &rarr; 0 and cannot be expressed in terms of the regular
expansion (6.17).
</p>
<p>Substituting the leading term from each of these solutions back into (6.27) helps
</p>
<p>identify the cause of the discrepancy
</p>
<p>xA : ε
(
</p>
<p>2
ε
</p>
<p>)2 &minus; 2
(
</p>
<p>2
ε
</p>
<p>)
</p>
<p>+ 1 = 0, xB : ε
(
</p>
<p>1
2
</p>
<p>)2 &minus; 2
(
</p>
<p>1
2
</p>
<p>)
</p>
<p>+ 1 = 0.
</p>
<p>The solutions are determined by different dominant balances in Eq. (6.27). For xA , the
</p>
<p>first two terms balance at O(1/ε) while the third term is sub-dominant at O(1). For
</p>
<p>xB , the second and third terms balance at O(1)with the first term being sub-dominant
</p>
<p>at O(ε) (this being the regular solution that was obtained from (6.28)).</p>
<p/>
</div>
<div class="page"><p/>
<p>6.5 Singular Perturbation Problems 141
</p>
<p>6.5.1 Rescaling to Obtain Singular Solutions
</p>
<p>We now outline a systematic procedure for how the previously introduced methods
</p>
<p>for regular perturbation problems can be extended to handle singular solutions:
</p>
<p>(1) Substitute x = δ0(ε)X into the given problem.
(2) Choose δ0(ε) so as to produce a consistent dominant balance; verify that all
</p>
<p>neglected terms are indeed sub-dominant. Different δ0(ε)&rsquo;s lead to different
</p>
<p>dominant balances, and considering all of the possible choices will yield all of
</p>
<p>the regular and singular solutions.
</p>
<p>(3) Factor out any common ε-scalings to yield a regular perturbation problem in
</p>
<p>X . Then solve this problem using either the iteration or expansion methods to
</p>
<p>generate regular solutions corresponding to this distinguished limit.
</p>
<p>(4) Rescale X by δ0 to obtain x in final form.
</p>
<p>We will illustrate this methodology on the example from the previous section.
</p>
<p>Substituting x = δ0x0 into (6.27) yields
</p>
<p>εδ20 X
2
</p>
<p>︸ ︷︷ ︸
</p>
<p>(1)
</p>
<p>&minus; 2δ0 X
︸ ︷︷ ︸
</p>
<p>(2)
</p>
<p>+ 1
︸︷︷︸
</p>
<p>(3)
</p>
<p>= 0. (6.31)
</p>
<p>We compare the orders of magnitude of the terms (cf. Sect. 6.3.2). There are three
</p>
<p>possible balances:
</p>
<p>(a) Terms (2, 3): δ0 = 1 &rArr; δ0 = 1
(b) Terms (1, 3): εδ20 = 1 &rArr; δ0 = 1/
</p>
<p>&radic;
ε
</p>
<p>(c) Terms (1, 2): εδ20 = δ0 &rArr; δ0 = 1/ε
</p>
<p>In case (a), the omitted first term is sub-dominant, O(ε), and so this is a consistent
</p>
<p>balance; this balance yields the regular solution, xB . In case (b), the dominant balance
</p>
<p>is at O(1), while the omitted second term is O(1/
&radic;
ε) ≫ 1 in the limit ε &rarr; 0 and is
</p>
<p>not sub-dominant. Hence this balance is inconsistent and must be rejected. Finally,
</p>
<p>in case (c) the balancing terms are O(1/ε), while the third term is O(1) ≪ 1/ε,
therefore yielding a second consistent dominant balance; this case yields the singular
</p>
<p>solution.
</p>
<p>In order to investigate the singular solution, we write x = X/ε and substitute into
(6.27) to arrive at the (rescaled) regular problem
</p>
<p>X2 &minus; 2X + ε = 0, (6.32)
</p>
<p>where we have multiplied through by ε. Expanding X (ε) as a regular expansion (here
</p>
<p>X &sim; X0 + εX1 + ε2 X2 will work) and seeking the leading order term yields
</p>
<p>X20 &minus; 2X0 = 0, (6.33)</p>
<p/>
</div>
<div class="page"><p/>
<p>142 6 Perturbation Methods
</p>
<p>which has solutions X0 = 0 and X0 = 2. We ignore the root X0 = 0 because it
is not a nontrivial leading order term.2 The other root yields the singular solution
</p>
<p>xA &sim; 2/ε.
A particular difference between the iteration method described in Sect. 6.3.2 and
</p>
<p>the current methodology is worth noting. Both seek to determine the leading order
</p>
<p>gauge function δ0, and the set of coefficients xn versus Xn will be identical. The
</p>
<p>iteration method seeks to identify one successive term in the asymptotic expansion
</p>
<p>at each iteration. In contrast, the rescaling approach re-casts the entire problem into
</p>
<p>a new (regular perturbation) form for X (ε) = O(1) (as in (6.32)); whether to then
use the expansion method or iteration method to solve for X is left as a separate
</p>
<p>decision. In terms of the asymptotic expansion of the solution, we have
</p>
<p>x &sim; δ0 X (ε)
&sim; δ0
</p>
<p>(
</p>
<p>X0 + δ̃1 X1 + δ̃2 X2 + δ̃3 X3 + &middot; &middot; &middot;
)
</p>
<p>&sim; δ0x0 + δ1x1 + δ2x2 + δ3x3 + &middot; &middot; &middot; , (6.34)
</p>
<p>so that the leading order gauge function δ0 scales through the δ̃ gauge functions in
</p>
<p>the expansion of the rescaled solution.
</p>
<p>Singular problems for ODE and PDE introduce additional complexities and are of
</p>
<p>particular interest as they frequently arise in applications. The following two chapters
</p>
<p>consider these scenarios in detail.
</p>
<p>6.6 Further Directions
</p>
<p>There are many variations of the methods used in this chapter. Reference [47] employs
</p>
<p>an iterative procedure, where the original equation must be written in a form that
</p>
<p>is compatible with the contraction mapping theorem and allows for greater analysis
</p>
<p>of the convergence of the asymptotic expansion. The method described in [49] is
</p>
<p>somewhat more similar to that presented here; there, the gauge functions are assumed
</p>
<p>to be of the form δn = εαn where αn need not be an integer. Finally, we note
that many further approaches for constructing asymptotic expansions for integrals
</p>
<p>and differential equations build directly on the perturbation methods for algebraic
</p>
<p>equations described in this chapter [11, 13, 29, 47, 72, 92].
</p>
<p>2It is a &ldquo;ghost&rdquo; of the xB regular solution, which is O(ε) in terms of X (and violates requirement
</p>
<p>(i) in Sect. 6.3.2).</p>
<p/>
</div>
<div class="page"><p/>
<p>6.7 Exercises 143
</p>
<p>6.7 Exercises
</p>
<p>6.1 Use Taylor series expansions for sin y and ey for y &rarr; 0 and the basic property
exp(
</p>
<p>&sum;
</p>
<p>k ak) =
&prod;
</p>
<p>k e
ak to derive (6.10) for ε &rarr; 0 from x(t, ε) = exp(sin(ε
</p>
<p>&radic;
t)/ε2)
</p>
<p>when t = O(1), but x &sim; 1 +
&radic;
εT + 1
</p>
<p>2
εT when t = ε3T with T = O(1).
</p>
<p>6.2 Consider the limit of ε &rarr; 0 for the equation
</p>
<p>(x &minus; 3)3 = 24εx2.
</p>
<p>Solve by iteration3 to determine x &sim; δ0(ε)x0 + δ1(ε)x1 + δ2(ε)x2.
</p>
<p>6.3 Consider the algebraic equation for ε &rarr; 0
</p>
<p>ε6x3 &minus; 5ε3x2 &minus; 20εx + 60 = 0.
</p>
<p>Show that there are no regular solutions and determine the leading order nontrivial
</p>
<p>term in the expansion of each of the three solutions.
</p>
<p>6.4 Consider the projectile problem for ε &rarr; 0
</p>
<p>d2x
</p>
<p>dt2
= &minus;
</p>
<p>1
</p>
<p>(1 + εx)2
, x(0) = 1, x &prime;(0) = 3ε.
</p>
<p>(a) Let tmax be the time when the projectile reaches its maximum height. How many
</p>
<p>terms in the expansion of x(t) will you need to determine tmax = t0 + εt1 +
O(ε2)?
</p>
<p>(b) Show that while (6.26) with α = 3ε could have been used to determine the
solution in part (a), this could not be used with the initial condition x &prime;(0) = 4/ε.
Assume a singular form x(t) = X (t)/ε &sim; X0(t)/ε+ X1(t) to find this solution.
</p>
<p>6.5 Consider the problem
</p>
<p>dv
</p>
<p>dt
+ εv2 + t = 0, v(0) = 0, ε &rarr; 0.
</p>
<p>(a) Find the first three terms in the expansion of the solution, v(t) &sim; v0(t)+εv1(t)+
ε2v2(t).
</p>
<p>(b) Determine the range of times, 0 &le; t &lt; O(εα), for which the terms in the
expansion retain asymptotic ordering, i.e. v0 ≫ εv1 ≫ ε2v2 ≫ &middot; &middot; &middot; .
</p>
<p>3Use of a computer algebra program (Maple or Mathematica) is recommended for solving
</p>
<p>many of the more algebraically intensive problems.</p>
<p/>
</div>
<div class="page"><p/>
<p>144 6 Perturbation Methods
</p>
<p>6.6 Consider the system of equations
</p>
<p>εx &minus; y = 1
ε2x + y = 4
</p>
<p>in the limit ε &rarr; 0.
Explain why setting ε = 0 does not lead to an acceptable leading order solution.
</p>
<p>Determine the first two terms in the expansions of x(ε), y(ε).
</p>
<p>6.7 Use the iteration method with x &sim; δ0(ε)x0 + δ1(ε)x1 to find the singular real
solution of the equation
</p>
<p>2x2e&minus;5x = 8ε, ε &rarr; 0.
</p>
<p>Note: This equation has three real roots; the two vanishing roots are not of interest
</p>
<p>here (they are x &sim; &plusmn;2ε1/2 + 10ε). The one you should locate has δ0(ε) &rarr; &infin; (i.e.
it is large and positive).
</p>
<p>Hint: Take the logarithm of both sides of the equation before beginning iteration.
</p>
<p>6.8 Re-consider the solutions of Eq. (6.21), but now in the limit of ε &rarr; &infin;: let
ε̃ = 1/ε and find the real-valued solutions of
</p>
<p>sin x + ε̃(x2 &minus; 2x) = 0, ε̃ &rarr; 0.
</p>
<p>Assume x &sim; x0 + ε̃x1 + ε̃2x2. Note that for ε̃ = 0 the leading order problem has
infinitely many solutions, x0 = nπ for any integer n.
(a) Determine x1, x2.
</p>
<p>(b) Plot F(x, ε̃) = sin x + ε̃(x2 &minus; 2x) for ε̃ = 1
100
</p>
<p>. How many zeroes does it have?
</p>
<p>(c) Parts (a, b) show that there is a conflict, as ε &rarr; 0 there is a finite number of
solutions, namely there is a maximum value for n, call it N (ε̃), at each value
</p>
<p>of ε̃. Requiring that the expansion for x remain asymptotically ordered (x0 ≫
εx1 ≫ . . .) suggests one estimate for N , but show that maintaining ordering in
the expansion of the equation, given x0 and x1 from (a), yields the correct N (ε̃).
</p>
<p>6.9 In the 1930s, Carleman showed that in an appropriate asymptotic limit a diffusion
</p>
<p>model could be derived from a system of reactive wave equations. Consider the
</p>
<p>system of PDEs for p(x, t), q(x, t) with ε &gt; 0:
</p>
<p>ε2
&part;p
</p>
<p>&part;t
+ ε
</p>
<p>&part;p
</p>
<p>&part;x
= q &minus; p, ε2
</p>
<p>&part;q
</p>
<p>&part;t
&minus; ε
</p>
<p>&part;q
</p>
<p>&part;x
= p &minus; q.
</p>
<p>(a) If the solutions are uniform in space (i.e. p = p(t), q = q(t)), then p, q satisfy a
reversible transformation reaction P ⇋ Q (see Sect. 1.2). What is the conserved
</p>
<p>quantity for this reaction system? What is the reaction rate?
</p>
<p>(b) If the reactions (the right-hand side terms) are eliminated, find the travelling
</p>
<p>waves for the reduced equations for p(x, t) and q(x, t). What are the speeds of
</p>
<p>these waves?</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1">http://dx.doi.org/10.1007/978-3-319-23042-9_1</a></div>
</div>
<div class="page"><p/>
<p>6.7 Exercises 145
</p>
<p>(c) Define u = p + q and v = (p &minus; q)/ε. Combine the full equations for p and q
to obtain two equations for u and v. In the limit ε &rarr; 0, use regular perturbation
expansions u(x, t) &sim; u0 + εu1 + &middot; &middot; &middot; and v(x, t) &sim; v0 + εv1 + &middot; &middot; &middot; to find the
leading order equations for u and v, and then derive a PDE for u0(x, t) alone.
</p>
<p>6.10 The nondimensional form of the shallow water equations is
</p>
<p>&part;h
</p>
<p>&part;t
+ h
</p>
<p>&part;u
</p>
<p>&part;x
+ u
</p>
<p>&part;h
</p>
<p>&part;x
= 0,
</p>
<p>&part;u
</p>
<p>&part;t
+ u
</p>
<p>&part;u
</p>
<p>&part;x
+
</p>
<p>1
</p>
<p>Fr2
&part;h
</p>
<p>&part;x
= 0,
</p>
<p>where u(x, t) is the fluid speed, h(x, t) is the height of the fluid, and Fr is a dimen-
</p>
<p>sionless parameter. A uniform, steady solution is given by h &equiv; 1 and u &equiv; 1, which
can represent a river having uniform speed and depth.
</p>
<p>Consider waves generated due to some small disturbance on this steady state. Let
</p>
<p>h = 1 + εη(x, t), u = 1 + εν(x, t).
</p>
<p>(a) For ε &rarr; 0, determine the O(ε) linearised wave equations for η, ν.
(b) Apply the approach of Sect. 2.4 to the linearised system to determine the critical
</p>
<p>value of the Froude number at which waves from the disturbance change from
</p>
<p>spreading in both up- and down-stream directions to having all ripples being
</p>
<p>swept downstream (called sub- and super-critical behaviours).</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2">http://dx.doi.org/10.1007/978-3-319-23042-9_2</a></div>
</div>
<div class="page"><p/>
<p>Chapter 7
</p>
<p>Boundary Layer Theory
</p>
<p>We have seen in Chap. 6 that singularly perturbed problems can have co-existing
</p>
<p>regular and singular solutions that scale differently as ε &rarr; 0. In the context of
physical systems described by differential equations, such structures yieldmulti-scale
</p>
<p>phenomena. Everyday life yields countless examples of multi-scale phenomena:
</p>
<p>violent winds in tornadoes surrounded by relatively calm air over large areas, bands
</p>
<p>of wake behind ships moving in otherwise still waters, cracks forming in uniform
</p>
<p>solid materials, spots, stripes and other intricate patterns developing in biological
</p>
<p>systems. In these, and many other contexts, we can separate the behaviour of the
</p>
<p>system into regions of rapid variation of quantities of interest compared to other larger
</p>
<p>scale regions of slow variation. Models that can capture such diverse behaviours will
</p>
<p>allow for multiple distinguished limits, describing balances between different sets of
</p>
<p>dominant effects in different regions. The relatively narrow regions of rapid variations
</p>
<p>are generally called boundary layers.
</p>
<p>Although boundary layers were originally formulated to describe problems in
</p>
<p>fluid mechanics and aerodynamics [76] (where they generally occur on the boundary
</p>
<p>of a solid object passing through a surrounding uniform fluid flow), they also describe
</p>
<p>solutions in broader sets of contexts.
</p>
<p>While attempting to directly find a solution of the full problem on an entire domain
</p>
<p>directly may be very difficult, constructing &ldquo;partial solutions&rdquo; on different regions
</p>
<p>using perturbation expansions can be straightforward. Following the approach in-
</p>
<p>troduced in Sect. 6.5, different dominant balances will re-scale the full model into
</p>
<p>different forms, leading to different regular or singular solutions. Further analysis is
</p>
<p>then needed to assemble the partial solutions into a complete solution of the full prob-
</p>
<p>lem. This is accomplished through asymptotic matching and leads to this solution
</p>
<p>methodology being called the method of matched asymptotic expansions.
</p>
<p>&copy; Springer International Publishing Switzerland 2015
</p>
<p>T. Witelski and M. Bowen, Methods of Mathematical Modelling,
</p>
<p>Springer Undergraduate Mathematics Series, DOI 10.1007/978-3-319-23042-9_7
</p>
<p>147</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6">http://dx.doi.org/10.1007/978-3-319-23042-9_6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6">http://dx.doi.org/10.1007/978-3-319-23042-9_6</a></div>
</div>
<div class="page"><p/>
<p>148 7 Boundary Layer Theory
</p>
<p>7.1 Observing Boundary Layer Structure in Solutions
</p>
<p>In order to illustrate the main principles behind boundary layers and matched asymp-
</p>
<p>totics, we first consider a problem for which we can express the solution exactly and
</p>
<p>examine how it can be separated into pieces stemming from behaviours at different
</p>
<p>scales.
</p>
<p>Consider the linear, constant coefficient ordinary differential equation
</p>
<p>ε
d2y
</p>
<p>dx2
+ 2dy
</p>
<p>dx
+ y = 0 for ε &rarr; 0, (7.1a)
</p>
<p>on the domain 0 &le; x &le; 1, subject to the boundary conditions
</p>
<p>y(0) = 0, y(1) = 1. (7.1b)
</p>
<p>Singular behaviour in the solution should be expected since setting ε = 0 in (7.1a)
reduces the equation to a first order ODE, whose solution can satisfy only one of the
</p>
<p>boundary conditions.
</p>
<p>The exact solution of (7.1) for any ε &gt; 0 is given by
</p>
<p>y(x) =
exp
</p>
<p>(
&minus;1+
</p>
<p>&radic;
1&minus;ε
</p>
<p>ε
x
)
</p>
<p>&minus; exp
(
&minus;1&minus;
</p>
<p>&radic;
1&minus;ε
</p>
<p>ε
x
)
</p>
<p>exp
(
&minus;1+
</p>
<p>&radic;
1&minus;ε
</p>
<p>ε
</p>
<p>)
</p>
<p>&minus; exp
(
&minus;1&minus;
</p>
<p>&radic;
1&minus;ε
</p>
<p>ε
</p>
<p>) (7.2)
</p>
<p>(see Fig. 7.1). If ε is small (0 &lt; ε ≪ 1), we can expand the arguments of the
exponentials to yield
</p>
<p>Fig. 7.1 (Left) solution (7.2) to problem (7.1) for ε = 0.1. (Right) the behaviour of the solution in
the limit ε &rarr; 0</p>
<p/>
</div>
<div class="page"><p/>
<p>7.1 Observing Boundary Layer Structure in Solutions 149
</p>
<p>y(x) =
exp
</p>
<p>(
</p>
<p>&minus;
[
</p>
<p>1
2
+ ε
</p>
<p>8
+ &middot; &middot; &middot;
</p>
<p>]
</p>
<p>x
)
</p>
<p>&minus; exp
(
</p>
<p>&minus;
[
</p>
<p>2
ε
&minus; 1
</p>
<p>2
+ &middot; &middot; &middot;
</p>
<p>]
</p>
<p>x
)
</p>
<p>exp
(
</p>
<p>&minus;
[
</p>
<p>1
2
+ ε
</p>
<p>8
+ &middot; &middot; &middot;
</p>
<p>]
)
</p>
<p>&minus; exp
(
</p>
<p>&minus;
[
</p>
<p>2
ε
&minus; 1
</p>
<p>2
+ &middot; &middot; &middot;
</p>
<p>]
)
</p>
<p>&sim;
exp
</p>
<p>(
</p>
<p>&minus; 1
2
x
)
</p>
<p>&minus; exp
(
</p>
<p>&minus; 2
ε
x
)
</p>
<p>exp
(
</p>
<p>&minus; 1
2
</p>
<p>)
</p>
<p>&minus; exp
(
</p>
<p>&minus; 2
ε
</p>
<p>) , (7.3)
</p>
<p>The size of the domain is independent of ε, and hence one of the spatial scales should
</p>
<p>be x = O(1) as ε &rarr; 0, as represented by the e&minus;x/2 term in (7.3). The other term
there depends on a more rapidly varying spatial scale, x/ε, in which a small (O(ε))
</p>
<p>change in x yields a O(1) change in the solution. The distinctness of these two scales
</p>
<p>makes it possible to construct the solution to (7.1) by seeking its dependence on each
</p>
<p>scale separately.
</p>
<p>Each spatial scale in the problem is associated with a limiting process for the
</p>
<p>solution of (7.1) as ε &rarr; 0. Fixing x = O(1) in the range 0 &lt; x &le; 1 gives
</p>
<p>lim
ε&rarr;0
</p>
<p>y(x) &sim; e
&minus;x/2 &minus; e.s.t.
e&minus;1/2 &minus; e.s.t. &sim; e
</p>
<p>(1&minus;x)/2, (7.4)
</p>
<p>where &ldquo;e.s.t.&rdquo; refers to exponentially small terms, of the form e&minus;α/ε for α &gt; 0, that
are smaller than all algebraic powers of ε (εn ≫ e&minus;α/ε for ε &rarr; 0) and are treated as
negligible in this context. This limiting form of the solution satisfies the boundary
</p>
<p>condition at x = 1, but not the one at x = 0 (7.1b).
Note that we have excluded the case x = 0 from consideration in (7.4) so that
</p>
<p>e&minus;2x/ε is indeed exponentially small. If instead, we consider a small neighbourhood
of the origin, 0 &le; x = O(ε), then we must take the dual limit ε &rarr; 0 and x &rarr; 0
with the ratio X = x/ε held fixed. In terms of the new spatial variable X , the limit
of (7.3) now becomes
</p>
<p>lim
ε&rarr;0
</p>
<p>y &sim; e
&minus;εX/2 &minus; e&minus;2X
e&minus;1/2 &minus; e&minus;2/ε &sim; e
</p>
<p>1/2(1 &minus; e&minus;2X ). (7.5)
</p>
<p>This limiting form satisfies the boundary condition at x = 0 (X = 0). The boundary
condition at x = 1 is not satisfied, but since the right hand boundary position,
corresponding to X = 1/ε, violates the assumption X = O(1) made in taking the
limit, agreement should not have been expected.
</p>
<p>Similar examples are often used in analysis [21] to illustrate functions that have
</p>
<p>non-uniform convergence. In the present context, we see that different limiting prop-
</p>
<p>erties of the solution are captured by different limiting processes. For the majority
</p>
<p>of the domain (here, where x = O(1)), the solution is given by (7.4) and is called
the outer solution. In contrast, in the boundary layer, or inner domain, the solution
</p>
<p>exhibits singular behaviour that cannot be captured by the outer solution. In this
</p>
<p>example, the inner solution in the boundary layer close to x = 0 has a singular
derivative, dy/dx = O(ε&minus;1) &rarr; &infin; as ε &rarr; 0.</p>
<p/>
</div>
<div class="page"><p/>
<p>150 7 Boundary Layer Theory
</p>
<p>It is also worth mentioning that problems featuring a separation of scales can be
</p>
<p>extremely difficult to compute numerically (typically referred to as stiff problems). In
</p>
<p>contrast, solutions of these problems can often be very accurately obtained in terms
</p>
<p>of inner and outer solutions using perturbation methods.
</p>
<p>7.2 Asymptotics of the Outer and Inner Solutions
</p>
<p>We now discuss the construction of solutions to singular perturbation problems by
</p>
<p>calculating perturbation expansions for the outer and inner solutions.
</p>
<p>We shall continue to use problem (7.1a, 7.1b) to illustrate the methodology. We
</p>
<p>begin by attempting to find the outer solution on the outer domain, 0 &lt; x &le; 1, in
which we assume that y(x) and all of its derivatives are bounded, smooth and O(1).
</p>
<p>We assume y(x) can be expanded as a regular perturbation expansion of the form
</p>
<p>y(x) &sim; y0(x)+ εy1(x)+ ε2y2(x)+ &middot; &middot; &middot; as ε &rarr; 0. (7.6)
</p>
<p>Similar to the approach used for (6.24), we substitute this expansion into (7.1a, 7.1b)
</p>
<p>and separate terms in powers of ε &rarr; 0 yielding the system of sub-problems
</p>
<p>O(ε0) : 2y&prime;0 + y0 = 0 y0(1) = 1,
O(ε1) : 2y&prime;1 + y1 = &minus;y&prime;&prime;0 y1(1) = 0,
O(ε2) : 2y&prime;2 + y2 = &minus;y&prime;&prime;1 y2(1) = 0,
</p>
<p>(7.7)
</p>
<p>and so on for higher powers of ε. Note that the boundary condition at x = 0 from
(7.1b) is not included above since x = 0 is not within the outer domain. Solving the
O(1) problem gives the leading order outer solution
</p>
<p>y0(x) = e(1&minus;x)/2, (7.8)
</p>
<p>which reproduces (7.4). Additional terms in the expansion can be constructed by
</p>
<p>working through the higher order sub-problems in (7.7) in sequence.
</p>
<p>We now turn our attention to constructing the solution in the inner region, cor-
</p>
<p>responding to having x = O(ε). Introducing the rescaling x = εX and writing
y(x) = Y (X) transforms (7.1a) to
</p>
<p>d2Y
</p>
<p>dX2
+ 2 dY
</p>
<p>dX
+ εY = 0, (7.9)
</p>
<p>with the boundary condition (7.1b) becoming Y (0) = 0. Seeking the solution in the
form of a regular expansion, Y (X) = Y0(X) + εY1 + ε2Y2(X) + &middot; &middot; &middot; , yields the
leading order O(1) problem
</p>
<p>Y &prime;&prime;0 + 2Y &prime;0 = 0, Y0(0) = 0, (7.10)</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6">http://dx.doi.org/10.1007/978-3-319-23042-9_6</a></div>
</div>
<div class="page"><p/>
<p>7.2 Asymptotics of the Outer and Inner Solutions 151
</p>
<p>with solution
</p>
<p>Y0(X) = A(1 &minus; e&minus;2X ). (7.11)
</p>
<p>Note that one constant, A, remains undetermined in the solution since the ODE in
</p>
<p>(7.10) is second order, but we are only imposing one side condition. The solutions
</p>
<p>of the higher order terms, Yn(X) will similarly add one new undetermined constant
</p>
<p>at each order in the expansion. Since the inner problem did not uniquely define the
</p>
<p>inner solution, we examine its relationship with the outer solution in an attempt to
</p>
<p>fix the unknown constant A.
</p>
<p>It is important to note that the inner and outer domains are not mutually exclusive
</p>
<p>and are valid on regions broader than the strict prescriptions of their spatial scales
</p>
<p>(here x = O(ε) and x = O(1) respectively). In the outer solution x is bounded
away from zero, but can become small, say x = O(&radic;ε) &rarr; 0. Likewise, in the inner
solution x should be small, but X = x/ε can become large, say X = O(1/&radic;ε) &rarr; &infin;.
</p>
<p>In fact, it can be shown that there is an overlap domain,
</p>
<p>overlap domain: ε ≪ x ≪ 1, (7.12)
</p>
<p>between the scales set by the inner and outer domains, where both inner and outer
</p>
<p>solution are valid (see Fig. 7.2), Loosely speaking, there is a range where x is small
</p>
<p>(small enough for the inner solution to apply), but not too small (where the outer
</p>
<p>solution would not apply). Since the original full problem (7.1a, 7.1b) has a unique
</p>
<p>solution; if the inner and outer solutions are both valid in the overlap domain, they
</p>
<p>cannot be two distinct solutions and must in fact be two different asymptotic repre-
</p>
<p>sentations of the same solution. This relation is expressed in terms of limits derived
</p>
<p>from (7.12): (i) x ≪ 1, the outer variable must approach the inner domain, x &rarr; 0
and (ii) ε ≪ x (or after dividing across by ε: 1 ≪ X ), the inner variable must
approach the outer domain, X &rarr; &infin;. The resulting limit requirement
</p>
<p>lim
X&rarr;&infin;
</p>
<p>Y0(X) = lim
x&rarr;0
</p>
<p>y0(x), (7.13)
</p>
<p>is called the leading order asymptotic matching condition [60, 101]. This principle
</p>
<p>can be paraphrased as
</p>
<p>Fig. 7.2 A schematic
</p>
<p>representation of the inner,
</p>
<p>outer and overlap domains
</p>
<p>for problem (7.1a, 7.1b)</p>
<p/>
</div>
<div class="page"><p/>
<p>152 7 Boundary Layer Theory
</p>
<p>&ldquo;The outer limit of the inner solution equals
</p>
<p>the inner limit of the outer solution.&rdquo; (7.14)
</p>
<p>Applying (7.13) to Y0 given by (7.11) and y0 by (7.8) yields
</p>
<p>lim
X&rarr;&infin;
</p>
<p>A(1 &minus; e&minus;2X ) = A = lim
x&rarr;0
</p>
<p>e(1&minus;x)/2 = e1/2, (7.15)
</p>
<p>thereby determining the constant A = e1/2. With this value for A the inner solution
(7.11) reproduces the limit (7.5) found from the exact solution.
</p>
<p>While we have now determined the leading order inner and outer solutions com-
</p>
<p>pletely, only a little more work is needed combine the outer and inner solutions
</p>
<p>to form a composite representation of the leading order solution, denoted here by
</p>
<p>ycomp(x), valid over the entire domain 0 &le; x &le; 1. An appropriate form for ycomp(x)
is given by the expression
</p>
<p>ycomp(x) = y0 + Y0 &minus; (overlap from matching), (7.16)
</p>
<p>where the overlap is simply the contribution found through matching in (7.15). At a
</p>
<p>formal level, on most of the domain, we have y &sim; y0, with the inner solution only
becoming significant in the inner domain. Where Y0 becomes important, we gain
</p>
<p>equal contributions from both the inner and outer solutions, and so to effectively
</p>
<p>prevent &ldquo;double-counting&rdquo;, we must subtract off the overlap.
</p>
<p>Another way of expressing (7.16) is to write
</p>
<p>ycomp = y0 + YBLC, (7.17)
</p>
<p>where the boundary layer correction, YBLC, is the adjustment to the outer solution
</p>
<p>made by the boundary layer to satisfy the boundary condition, with
</p>
<p>YBLC &equiv; Y0 &minus; (overlap from matching), (7.18)
</p>
<p>where we expect YBLC &rarr; 0 as X &rarr; &infin;.
Writing the inner solution (7.11) as Y0 = e1/2 &minus; e(1&minus;4x/ε)/2 and using the overlap
</p>
<p>from (7.15), the leading order boundary layer correction is
</p>
<p>YBLC = e1/2 &minus; e(1&minus;4x/ε)/2 &minus; e1/2 = &minus;e(1&minus;4x/ε)/2, (7.19)
</p>
<p>which does indeed vanish as X &rarr; &infin;. Hence, (7.17) gives the leading order solution
</p>
<p>ycomp = e(1&minus;x)/2 &minus; e(1&minus;4x/ε)/2 =
e&minus;x/2 &minus; e&minus;2x/ε
</p>
<p>e&minus;1/2
, (7.20)</p>
<p/>
</div>
<div class="page"><p/>
<p>7.2 Asymptotics of the Outer and Inner Solutions 153
</p>
<p>on the entire domain 0 &le; x &le; 1. This is comparable to the exact solution (7.2), except
for the absence of the exponentially small e&minus;2/ε term (which cannot be captured in
regular expansions such as (7.6)).
</p>
<p>7.3 Constructing Boundary Layer Solutions
</p>
<p>The presentation in the previous section made use of some prior knowledge of the
</p>
<p>form of the solution to reduce the overall problem to that of determining the ex-
</p>
<p>pansions of the inner and outer solutions. In this section, we describe the further
</p>
<p>steps required to investigate boundary layer problems without any additional given
</p>
<p>information about the form of the solution.
</p>
<p>The full process of constructing a solution involving matched asymptotic expan-
</p>
<p>sions requires examining the two additional questions:
</p>
<p>&bull; What are the scalings for the inner (and outer) solution(s)?
&bull; Where are the boundary layer(s) located?
The answers to these questions ultimately determine the form of the overall solution,
</p>
<p>and control which boundary conditions apply to the inner and outer solutions.
</p>
<p>For many singularly perturbed differential equations, solutions can be constructed
</p>
<p>by a step-by-step process:
</p>
<p>(1) The outer solution: If the problem is in standard form, try a regular expansion,
</p>
<p>y(x) = y0(x)+ εy1(x)+ &middot; &middot; &middot; , for the outer solution. If all of the boundary con-
ditions can be satisfied by this solution, then the problem is complete; otherwise,
</p>
<p>inner regions will be necessary.
</p>
<p>(2) Find the dominant balances: The appropriate forms for all of the regular (outer)
</p>
<p>and singular (inner) solutions of the ODE will be determined by the distinguished
</p>
<p>limits of the problem. In general, both the independent and dependent variables
</p>
<p>may need to be scaled to obtain all of the dominant balances,
</p>
<p>y = εβY (X), X = x &minus; x&lowast;
εα
</p>
<p>&hArr; x = x&lowast; + εαX, (7.21)
</p>
<p>where the powersα, β and the assumed position of the boundary layer, x&lowast; must all
be determined (there may be multiple valid locations for x&lowast;). The outer solution
in step (1) assumes α = 0, β = 0.
</p>
<p>(3) The inner solution: For the singular distinguished limit, write the problem as a
</p>
<p>rescaled regular problem and seek the solution in the form of an appropriate
</p>
<p>regular expansion, Y (X) = Y0(X)+ εY1(x)+ &middot; &middot; &middot; .
(4) Asymptotic matching: Apply asymptotic matching between the inner/outer solu-
</p>
<p>tions (typically via (7.13)) to confirm the consistency of the asymptotic expansion
</p>
<p>and determine any remaining unknown parameters in the solution.
</p>
<p>(5) The composite solution: Writing the outer and inner solutions in terms of the
</p>
<p>original variables and subtracting the overlaps from the matching process to</p>
<p/>
</div>
<div class="page"><p/>
<p>154 7 Boundary Layer Theory
</p>
<p>prevent &ldquo;double-counting&rdquo; will produce the leading order solution on the entire
</p>
<p>domain (7.16). So, in an example with boundary layers at both the left and right
</p>
<p>boundaries, we write
</p>
<p>ycomp(x) &sim; y0(x)+ Y LBLC + Y RBLC. (7.22)
</p>
<p>This description covers broad classes of problems, but as will be seen, in some cases,
</p>
<p>steps (2, 3, 4) may become a bit intertwined. We also note:
</p>
<p>&bull; When boundary layers are necessary, which boundary conditions apply to the
outer solution may not be immediately apparent. Hence a general form for the
</p>
<p>outer solution will be needed initially.
</p>
<p>&bull; The boundary conditions as well as the ODE play a role in determining the dom-
inant balances.
</p>
<p>&bull; The location of the boundary layer and which boundary conditions apply to the
inner solution might not be determined until matching is applied.
</p>
<p>&bull; If the inner/outer solutions are not matchable (either limit does not exist, or equation
(7.13) cannot be satisfied) then the assumed choice of boundary layer position x&lowast;
or dominant balance may be not be right.
</p>
<p>&bull; While the term &ldquo;boundary layer&rdquo; stems from the fact that the inner domain often
occurs at a boundary, in some cases, they can also occur within the domain of a
</p>
<p>problem, in which case they are sometimes called interior layers.
</p>
<p>Consequently, the reader should consider steps (1)&ndash;(5) as &ldquo;guidelines&rdquo; that may need
</p>
<p>to be adjusted depending on the given problem; this is one of the challenging (and
</p>
<p>interesting) points of matched asymptotic expansions.
</p>
<p>We use an example to illustrate the aspects of the above procedure. Consider the
</p>
<p>boundary value problem
</p>
<p>ε
d2y
</p>
<p>dx2
+ dy
</p>
<p>dx
= cos x (7.23a)
</p>
<p>in the limit ε &rarr; 0 on the domain 0 &le; x &le; π , subject to the boundary conditions
</p>
<p>y(0) = 2, y(π) = &minus;1. (7.23b)
</p>
<p>7.3.1 The Outer Solution
</p>
<p>Assuming that y(x) and its derivatives are bounded as ε &rarr; 0, we write the outer
solution as y &sim; y0(x) + εy1(x) + ε2y2(x) &middot; &middot; &middot; . Substituting into (7.23a) gives the
sequence of equations
</p>
<p>O(ε0) : y&prime;0 = cos x,
O(ε1) : y&prime;1 + y&prime;&prime;0 = 0,
O(ε2) : y&prime;2 + y&prime;&prime;1 = 0,</p>
<p/>
</div>
<div class="page"><p/>
<p>7.3 Constructing Boundary Layer Solutions 155
</p>
<p>and so on for higher order equations. The O(1) problem yields y0 = sin x + A and
substituting this into the O(ε) equation gives y1(x) = &minus; cos x + B. We can proceed
in this way to determine as many terms as desired in the expansion of the general
</p>
<p>outer solution
</p>
<p>yout = (sin x + A)+ ε(&minus; cos x + B)+ O(ε2). (7.24)
</p>
<p>At each order, there is only a single constant of integration, A, B, . . . . Imposing
</p>
<p>the condition at x = 0 from (7.23b) selects A = 2, while the condition at x = π
picks A = &minus;1; the outer solution cannot satisfy both at once, and hence a boundary
layer will be required. In summary, at this point, we do not know which boundary
</p>
<p>conditions will apply to the outer and which to the inner solutions.
</p>
<p>7.3.2 The Distinguished Limits
</p>
<p>To determine the relevant scaling of the singular solution, we write y(x) = εβY (X)
and X = (x &minus; x&lowast;)/εα and assume that Y (X) = O(1) for X = O(1). Substituting
into (7.23a) yields
</p>
<p>ε1&minus;2α+βY &prime;&prime;
︸ ︷︷ ︸
</p>
<p>(1)
</p>
<p>+ ε&minus;α+βY &prime;
︸ ︷︷ ︸
</p>
<p>(2)
</p>
<p>= cos(x&lowast; + εαX)
︸ ︷︷ ︸
</p>
<p>(3)
</p>
<p>, (7.25)
</p>
<p>where 0 &le; x&lowast; &le; π . We also note that both boundary conditions (7.23b) take the
form εβY = O(1), and hence any solution local to a boundary must have β = 0. It
remains to determine α from the possible dominant balances:
</p>
<p>(a) Terms (2, 3): ε&minus;α = ε0 &rArr; α = 0,
(b) Terms (1, 3): ε1&minus;2α = ε0 &rArr; α = 1/2,
(c) Terms (1, 2): ε1&minus;2α = ε&minus;α &rArr; α = 1.
</p>
<p>Option (a) is the regular distinguished limit that corresponds to the outer solution.
</p>
<p>Option (b) is not a valid balance since the neglected term (2) is not sub-dominant,
</p>
<p>O(ε&minus;1/2) ≫ O(1). Consequently, the boundary layer must take the form given
by (c) where the neglected term (3) is sub-dominant to the leading balance with
</p>
<p>O(1) ≪ O(ε&minus;1). We note that in some problems, the dominant balances can change
for different assumed positions of the boundary layer, x&lowast; (most notably for non-
autonomous equations), but here term (3) uniformly satisfies | cos(x)| &le; 1 = O(ε0).
Hence our scaled equation for the inner solution is given by
</p>
<p>d2Y
</p>
<p>dX2
+ dY
</p>
<p>dX
= ε cos(x&lowast; + εX), (7.26)
</p>
<p>where x&lowast; has not yet been determined.</p>
<p/>
</div>
<div class="page"><p/>
<p>156 7 Boundary Layer Theory
</p>
<p>7.3.3 The Inner Solution
</p>
<p>Having the inner problem in regular perturbation form, we expand Y (X) as Y &sim;
Y0 + εY1 + ε2Y2 + &middot; &middot; &middot; and substitute into (7.26) to give the system of equations
</p>
<p>O(ε0) : Y &prime;&prime;0 + Y &prime;0 = 0,
O(ε1) : Y &prime;&prime;1 + Y &prime;1 = cos(x&lowast;),
O(ε2) : Y &prime;&prime;2 + Y &prime;2 = &minus; sin(x&lowast;)X, . . . .
</p>
<p>(7.27)
</p>
<p>The O(1) equation yields the leading order inner solution,
</p>
<p>Y0(X) = D + Ce&minus;X , (7.28)
</p>
<p>with the higher order problems producing smaller corrections to this result. The
</p>
<p>constants of integration C, D must be determined by boundary conditions or by
</p>
<p>matching with the outer solution, but this, in turn, depends on the location of x&lowast;.
Consider the forms of the inner domain in terms of X = (x &minus; x&lowast;)/ε for different
</p>
<p>possible values of x&lowast;
</p>
<p>(i) Left boundary (x&lowast; = 0) : x &ge; 0 &rArr; 0 &le; X &lt; o(1/ε)
(ii) Interior : 0 &lt; x&lowast; &lt; π &rArr; &minus;o(1/ε) &lt; X &lt; o(1/ε)
(iii) Right boundary (x&lowast; = π) : x &le; π &rArr; &minus;o(1/ε) &lt; X &le; 0.
</p>
<p>These options correspond to three possible forms of the composite solution (see
</p>
<p>Fig. 7.3): (a) a left boundary layer satisfying y(0) = 2 matching with an outer
solution which has A = 1 in order to satisfy the right boundary condition, (b) a nar-
row interior transition region connecting two outer solutions, with AL = 2 and
AR = &minus;1, and (c) a right boundary layer satisfying y(π) = &minus;1, with an outer
solution satisfying y(0) = 2.
</p>
<p>The location of the boundary layer will be determined by the structure of (7.28)
</p>
<p>and its limiting behaviour. The exponential term e&minus;X in (7.28) diverges if X is allowed
to become large and negative. Such exponentially diverging terms cannot satisfy the
</p>
<p>(a) (b) (c)
</p>
<p>Fig. 7.3 Three hypothetical sketches of the conjectured inner/outer solutions for (7.23a, 7.23b)
</p>
<p>with a boundary layer a at the (Left), b in the (Interior), c at the (Right) edge of the domain</p>
<p/>
</div>
<div class="page"><p/>
<p>7.3 Constructing Boundary Layer Solutions 157
</p>
<p>asymptotic matching condition (7.13) (with X &rarr; &minus;&infin; being the appropriate form
of the &lsquo;outer limit&rsquo; process) and are un-matchable.
</p>
<p>Consequently options (ii) and (iii) are not feasible, and we conclude that the
</p>
<p>boundary layer must be at x&lowast; = 0 with the left boundary condition from (7.23b)
being relevant, namely Y (0) = 2. Applying this condition reduces (7.28) to
</p>
<p>Y0(X) = 2 + C(e&minus;X &minus; 1), (7.29)
</p>
<p>where C remains to be determined.
</p>
<p>7.3.4 Asymptotic Matching
</p>
<p>Having identified the position of the boundary layer as x&lowast; = 0, we have the leading
order inner solution (7.29), valid on 0 &le; x &lt; O(ε), and the outer solution (7.24),
valid on 0 &lt; x &le; π . Since the right boundary lies in the outer domain, that boundary
condition determines A = &minus;1 in (7.24), leaving C from (7.29) as the last remaining
unknown.
</p>
<p>Applying the matching condition (7.13) for Y0(X &rarr; &infin;) and y0(x &rarr; 0) yields
</p>
<p>lim
X&rarr;&infin;
</p>
<p>2 + C(e&minus;X &minus; 1) = 2 &minus; C = lim
x&rarr;0
</p>
<p>sin(x)&minus; 1 = &minus;1 (7.30)
</p>
<p>and hence C = 3.
</p>
<p>7.3.5 The Composite Solution
</p>
<p>The overlap shared in common by the leading order inner and outer solutions above
</p>
<p>is &minus;1. Therefore we can form the boundary layer correction as
</p>
<p>YBLC = Y0 &minus; (&minus;1) = 3e&minus;X .
</p>
<p>Finally, adding this correction to the outer solution yields the leading order composite
</p>
<p>solution on 0 &le; x &le; π (see Fig. 7.4),
</p>
<p>ycomp = &minus;1 + sin(x)+ 3e&minus;x/ε. (7.31)
</p>
<p>This is in agreement with the exact solution (valid for all ε &gt; 0),
</p>
<p>y = &minus;1 + sin(x)&minus; ε[1 + cos(x)]
1 + ε2 +
</p>
<p>(
</p>
<p>3 + 2ε
1 + ε2
</p>
<p>)
</p>
<p>e&minus;x/ε + e.s.t.</p>
<p/>
</div>
<div class="page"><p/>
<p>158 7 Boundary Layer Theory
</p>
<p>Fig. 7.4 A plot of ycomp(x)
</p>
<p>(7.31) for a sequence of
</p>
<p>ε &rarr; 0. The boundary layer
becomes narrower as ε
</p>
<p>decreases
</p>
<p>7.4 Further Examples
</p>
<p>We present further examples to illustrate other aspects of the method of matched
</p>
<p>asymptotic expansions.
</p>
<p>Consider the problem of obtaining the leading order solution to the ODE problem
</p>
<p>on 0 &le; x &le; 1,
ε
d2y
</p>
<p>dx2
&minus; (2 &minus; x2)y = &minus;1 for ε &rarr; 0, (7.32a)
</p>
<p>with boundary conditions
</p>
<p>y&prime;(0) = 0, y(1) = 0. (7.32b)
</p>
<p>We begin by seeking the outer solution as a regular perturbation expansion, y(x) &sim;
y0 + εy1(x)+ ε2y2 + &middot; &middot; &middot; . The equation for the leading order term is
</p>
<p>&minus; (2 &minus; x2)y0 = &minus;1 =&rArr; y0(x) =
1
</p>
<p>2 &minus; x2 . (7.33)
</p>
<p>The leading order outer solution satisfies the y&prime;(0) = 0 boundary condition, i.e.
y&prime;0(0) = 0, hence no boundary layer is needed there.
</p>
<p>The outer solution has no free parameters, and it does not satisfy the boundary
</p>
<p>condition at x = 1. Therefore there must be a boundary layer at x&lowast; = 1.
So we seek a singular solution in the form y(x) = εβY (X)with X = (x&minus;1)/εα for
</p>
<p>X &le; 0. Unlike the inhomogeneous conditions in (7.23b), the homogeneous boundary
condition y(1) = 0 does not provide us information on β since εβY (0) = εβ0 = 0
for any β. However, if we can determine β using some alternative means, it will
</p>
<p>simplify the process of finding the distinguished limit for the inner solution. Turning
</p>
<p>to the asymptotic matching condition provides help; here this condition will take the
</p>
<p>form
</p>
<p>lim
x&rarr;x&lowast;
</p>
<p>y0(x) = lim
X&rarr;&minus;&infin;
</p>
<p>εβY0(X). (7.34)</p>
<p/>
</div>
<div class="page"><p/>
<p>7.4 Further Examples 159
</p>
<p>While we have not determined Y0(X), it is assumed to be O(1), and for x &rarr; 1, we
have y0(1) = 1. Since the limit of the outer solution is O(1), so must be the limit of
the inner solution, hence β = 0.
</p>
<p>Substituting y(x) = Y (X) and x = 1 + εαX into (7.32a) yields
</p>
<p>ε1&minus;2αY &prime;&prime; &minus; (2 &minus; (1 + εαX)2)Y = &minus;1
</p>
<p>and in final form:
</p>
<p>ε1&minus;2αY &prime;&prime;
︸ ︷︷ ︸
</p>
<p>(1)
</p>
<p>&minus; (1 &minus; 2εαX &minus; ε2αX2)Y
︸ ︷︷ ︸
</p>
<p>(2)
</p>
<p>= &minus;1
︸︷︷︸
</p>
<p>(3)
</p>
<p>. (7.35)
</p>
<p>On a finite domain, α &ge; 0 with α &gt; 0 describing boundary layers that narrow like
O(εα) as ε &rarr; 0. We note that for α &gt; 0 the sum of terms in the parentheses in term
(2) have leading order term (2 &minus; x2) &sim; 1, so the higher order terms there cannot
contribute to a consistent dominant balance.
</p>
<p>Balancing (2, 3) yields the distinguished limit for the outer solution, α = 0,
with term (1) being sub-dominant, O(ε) ≪ O(1). The other distinguished limit is
α = 1/2, which balances all three terms at O(1).
</p>
<p>We now have the form of the inner problem as
</p>
<p>Y &prime;&prime; &minus; (1 &minus; 2ε1/2X &minus; εX2)Y = &minus;1, Y (0) = 0, (7.36)
</p>
<p>for X &le; 0. The presence of the ε1/2 suggests the expansion of the solution should
take the form Y (X) &sim; Y0 + ε1/2Y1 + εY2 + &middot; &middot; &middot; . The leading order ODE is
</p>
<p>Y &prime;&prime;0 &minus; Y0 = &minus;1, (7.37)
</p>
<p>with solution
</p>
<p>Y0(X) = Ae&minus;X + BeX + 1. (7.38)
</p>
<p>For this solution to be matchable to the outer solution as X &rarr; &minus;&infin;, we must take
A = 0. Applying the boundary condition, Y0(0) = B + 1 = 0 then gives us the
solution,
</p>
<p>Y0(X) = 1 &minus; eX . (7.39)
</p>
<p>Since neither the leading order inner or outer solutions have any undetermined con-
</p>
<p>stants they should match automatically. This is indeed the case, and (7.34) applied
</p>
<p>to (7.33) and (7.39) shows they match with an overlap limit of 1. Hence we can
</p>
<p>construct the leading order composite solution (see Fig. 7.5)
</p>
<p>ycomp &sim;
1
</p>
<p>2 &minus; x2 &minus; e
(x&minus;1)/&radic;ε. (7.40)</p>
<p/>
</div>
<div class="page"><p/>
<p>160 7 Boundary Layer Theory
</p>
<p>Fig. 7.5 Plot of (7.40) for
</p>
<p>ε = 10&minus;n with n = 2, 3, 4, 5
</p>
<p>Getting a solution accurate to higher orders would involve obtaining further terms in
</p>
<p>the expansions of the inner and outer solutions. Despite the fact that the expansions
</p>
<p>have different gauge function (εn vs. εm/2) the solutions must match together. One
</p>
<p>approach for performing matching to higher order is given in Exercise 7.6.
</p>
<p>We now make one change to (7.32a) and illustrate how dramatically the structure
</p>
<p>of the solution is affected; consider the ODE problem on 0 &le; x &le; 1,
</p>
<p>ε
d2y
</p>
<p>dx2
&minus; (1 &minus; x2)y = &minus;1 for ε &rarr; 0, (7.41a)
</p>
<p>with boundary conditions
</p>
<p>y&prime;(0) = 0, y(1) = 0. (7.41b)
</p>
<p>The only change from the previous example is that the coefficient (2&minus; x2) in (7.32a)
has been replaced by (1 &minus; x2).
</p>
<p>As before, the outer solution can be expressed as a regular expansion and the
</p>
<p>leading order solution is given by an algebraic equation,
</p>
<p>y0 =
1
</p>
<p>1 &minus; x2 , (7.42)
</p>
<p>which blows up as x &rarr; 1 and does not satisfy the boundary condition y(1) = 0.
We again conclude that there must be a boundary layer at x&lowast; = 1, but now face the
problem of determining a boundary layer solution that can match to a diverging outer
</p>
<p>solution.
</p>
<p>We seek an inner solution in the scaled form y(x) = εβY (X)with X = (x&minus;1)/εα ,
where we expect β &lt; 0 to capture the singular nature of the magnitude of the solution
</p>
<p>and α &gt; 0 for a narrow boundary layer. Substituting into (7.41a) yields
</p>
<p>ε1&minus;2α+βY &prime;&prime;
︸ ︷︷ ︸
</p>
<p>(1)
</p>
<p>+ εα+βX (2 + εαX)Y
︸ ︷︷ ︸
</p>
<p>(2)
</p>
<p>= &minus;1
︸︷︷︸
</p>
<p>(3)
</p>
<p>. (7.43)</p>
<p/>
</div>
<div class="page"><p/>
<p>7.4 Further Examples 161
</p>
<p>We now consider the options for two-term dominant balances in this equation:
</p>
<p>(a) Terms (1, 2) balance if 1 &minus; 2α + β = α + β, namely α = 1/3. To ensure
that the balance is consistent, and these terms are larger than term (3), we need
</p>
<p>α + β &lt; 0, i.e. β &lt; &minus;1/3.
(b) Terms (1, 3) balance if 1 &minus; 2α + β = 0, yielding β = 2α &minus; 1. Term (2) is sub-
</p>
<p>dominant if α + β &gt; 0. Consequently, this and the condition β &lt; 0 determine
the range 1/3 &lt; α &lt; 1/2.
</p>
<p>(c) Terms (2, 3) balance if α + β = 0, hence β = &minus;α. Term (1) is sub-dominant
when 1 &minus; 2α + β &gt; 0, yielding 0 &lt; α &lt; 1/3.
</p>
<p>It can be useful to visualise these relations in the (α, β) parameter plane in what is
</p>
<p>called a Newton&ndash;Kruskal diagram [105], see Fig. 7.6.
</p>
<p>The leading order equations proposed by each of the above respective cases are:
</p>
<p>Y &prime;&prime;0 + 2XY0 = 0, (7.44a)
Y &prime;&prime;0 = &minus;1, (7.44b)
</p>
<p>2XY0 = &minus;1. (7.44c)
</p>
<p>Each of these equations can be shown to have some deficiency in trying to describe
</p>
<p>the inner solution. The solution of (7.44c), Y0 = &minus;1/(2X), cannot satisfy the bound-
ary condition at X = 0. The solution of (7.44b) is a parabola that cannot satisfy the
asymptotic matching condition for X &rarr; &minus;&infin;. Equation (7.44a) is less straightfor-
ward; it is a version of Airy&rsquo;s differential equation [11, 105] but it can likewise be
</p>
<p>shown that its solutions also cannot satisfy the matching condition (7.34).
</p>
<p>The above balances are self-consistent, but because they are not the most general
</p>
<p>dominant balance, they actually have a limited range of validity with the inner domain
</p>
<p>(it can be shown that (a) holds for X = O(1), (b) holds for X &rarr; 0, (c) holds for
X &rarr; &minus;&infin;). The distinguished limit for inner problem is given by the intersection
of the three cases, α = 1/3, β = &minus;1/3, with all three terms in (7.43) balancing,
</p>
<p>Y &prime;&prime;0 + 2XY0 = &minus;1, Y0(0) = 0. (7.45)
</p>
<p>Fig. 7.6 Newton&ndash;Kruskal
</p>
<p>diagram for (7.43) showing
</p>
<p>possible two-term dominant
</p>
<p>balances for cases (a, b, c) as
</p>
<p>line segments</p>
<p/>
</div>
<div class="page"><p/>
<p>162 7 Boundary Layer Theory
</p>
<p>Fig. 7.7 Numerical
</p>
<p>solutions of (7.41a, 7.41b)
</p>
<p>for a sequence of εn &rarr; 0
(colour curves) and the outer
</p>
<p>solution (7.42) (black curve)
</p>
<p>Another way to come to this choice of scalings is to use the matching condition
</p>
<p>(7.34) with the outer solution (7.42) written in terms of X as,
</p>
<p>y0 =
1
</p>
<p>1 &minus; (1 + εαX)2 &sim; &minus;
1
</p>
<p>2εαX
&sim; εβY0, (7.46)
</p>
<p>which we can recognise as case (c) above (for X &rarr; &minus;&infin;) with β = &minus;α. This would
reduce (7.43) to an equation for α, having two distinguished limits: α = 0 (the outer
solution), and the boundary layer given by α = 1/3.
</p>
<p>Constructing the composite solution would require solving (7.45) (it is an inho-
</p>
<p>mogeneous version of Airy&rsquo;s equation) and carrying out the matching from (7.46)
</p>
<p>using the approach of Exercise 7.6. Instead, in Fig. 7.7 we show that the numerical
</p>
<p>solution of the full problem is well characterised by the outer solution on most of
</p>
<p>the domain with the maximum value of the solution and the width of the boundary
</p>
<p>layer being well-predicted by the scaling of the inner solution.
</p>
<p>7.5 Further Directions
</p>
<p>The problems we have considered above provide some insight into how boundary
</p>
<p>layers and matched asymptotic expansions can separate out some of the delicate
</p>
<p>behaviours of solutions of singularly perturbed problems. The examples have shown
</p>
<p>that while the steps outlined in Sect. 7.4 are a good guide, they may be coupled to
</p>
<p>each other in different ways in each problem&mdash;for example: are the scalings of the
</p>
<p>inner solution determined by the ODE, the boundary conditions, or by matching? is
</p>
<p>matching needed to set undetermined coefficients in the inner or outer solution (or
</p>
<p>neither or both)? Many problems require creative application of these steps. Analysis
</p>
<p>of some more challenging problems remain open research problems.
</p>
<p>The form of the solutions obtained to such problem generally provides greater
</p>
<p>insight into the nature of the system. The dominant balance that determines the
</p>
<p>leading outer solution provides the simplest essential approximation of the behaviour
</p>
<p>in the problem. This approximation will be valid everywhere apart from the boundary</p>
<p/>
</div>
<div class="page"><p/>
<p>7.5 Further Directions 163
</p>
<p>layers. Matched asymptotics provides understanding of whether the boundary layers
</p>
<p>are necessary to pin-down properties of the outer solution or merely correct the
</p>
<p>solution in narrow regions. Often, knowledge of the physical system being modelled
</p>
<p>can guide expectations on boundary layer positions and dominant balances; this can
</p>
<p>sometimes simplify the mathematical steps. Sometimes, the matched asymptotics
</p>
<p>will uncover unexpected dominant balances that can highlight novel and important
</p>
<p>behaviours in the problem.
</p>
<p>This chapter only hints at the broad array of models that can be studied using
</p>
<p>matched asymptotics and the types of behaviours that can result. Some of these
</p>
<p>include boundary layers within boundary layers (nested layers or &ldquo;triple decks&rdquo;),
</p>
<p>boundary layers that begin at higher orders (&ldquo;corner layers&rdquo;), and problems with
</p>
<p>unusual gauge functions. There is a wide array of books that give further studies of
</p>
<p>boundary layer problems [47, 48, 58, 78, 92] and some primary sources on the theory
</p>
<p>of asymptotic matching are [60, 101].
</p>
<p>7.6 Exercises
</p>
<p>7.1 Evaluate limε&rarr;0 e&minus;1/ε/εn to demonstrate that exponentially small terms are
smaller than all algebraic terms.
</p>
<p>7.2 Determine the three possible dominant balances for (7.25) that could occur for
</p>
<p>x&lowast; = π/2, noting that cos(x) &rarr; 0 as x &rarr; x&lowast;.
</p>
<p>7.3 Consider the problem for y(x) on 0 &le; x &le; 1 with ε &rarr; 0,
</p>
<p>ε
d2y
</p>
<p>dx2
&minus; (4 &minus; x2)y = cos
</p>
<p>(
π
2
x
)
</p>
<p>y(0) = &minus;1 y(1) = 2
</p>
<p>(a) Determine the two distinguished limits for this problem.
</p>
<p>(b) Write the leading order outer solution y0(x).
</p>
<p>(c) Find the leading order inner solutions Y0(X).
</p>
<p>(d) Write the leading order uniformly-valid solution.
</p>
<p>7.4 Consider the initial value problem for y(x) on 0 &le; x for ε &rarr; 0,
</p>
<p>ε
d2y
</p>
<p>dx2
+ 2dy
</p>
<p>dx
&minus; 6y = 5x, y(0) = 0, y&prime;(0) = 4
</p>
<p>ε2
.
</p>
<p>You are given that the solution has a boundary layer at x&lowast; = 0.
(a) Determine the leading order inner solution.
</p>
<p>(b) Write the outer limit of the inner solution to determine a necessary matching
</p>
<p>condition on the outer solution.
</p>
<p>(c) Determine the leading order outer solution for x &gt; 0.</p>
<p/>
</div>
<div class="page"><p/>
<p>164 7 Boundary Layer Theory
</p>
<p>7.5 Consider the problem for y(x) on 0 &le; x &le; 1 with ε &rarr; 0,
</p>
<p>ε
d2y
</p>
<p>dx2
+ 2dy
</p>
<p>dx
+ ey = 0, y(0) = 0, y(1) = 0.
</p>
<p>(a) Find the general leading order outer solution y0(x).
</p>
<p>(b) Find the leading order inner solution Y0(X) and determine where the boundary
</p>
<p>layer occurs.
</p>
<p>(c) Write the leading order composite solution.
</p>
<p>(d) Determine the next term in the outer solution, y1(x).
</p>
<p>7.6 Consider the problem for y(x) on 0 &le; x &le; 1 with ε &rarr; 0,
</p>
<p>ε
d2y
</p>
<p>dx2
&minus; dy
</p>
<p>dx
+ y = 2x, y(0) = &minus;2, y(1) = 1.
</p>
<p>(a) Determine the distinguished limit for the inner problem for this equation. By
</p>
<p>solving the leading order inner problem, determine where the boundary layer
</p>
<p>occurs.
</p>
<p>(b) Obtain the first two terms in the expansion of the inner solution (with the appro-
</p>
<p>priate boundary conditions imposed),
</p>
<p>Y (X) &sim; Y0(X)+ εY1(X).
</p>
<p>(c) Determine the first two terms in the expansion of the outer solution (with the
</p>
<p>appropriate boundary conditions imposed),
</p>
<p>y(x) &sim; y0(x)+ εy1(x).
</p>
<p>(d) The inner solution will have undetermined constants. These constants can be
</p>
<p>determined using higher-order matching using intermediate variables [60, 101]
</p>
<p>via the following steps:
</p>
<p>(i) Analogous to (7.12), define small parameter η with εα ≪ η ≪ 1.
(ii) Define the intermediate variable x̂ as x̂ = (x &minus; x&lowast;)/η.
</p>
<p>(iii) Use the relations
</p>
<p>x = x&lowast; + ηx̂, X =
η
</p>
<p>εα
x̂
</p>
<p>to write the outer and inner solutions both in terms of the intermediate
</p>
<p>variable x̂ and ε, η.
</p>
<p>(iv) Use the relations εα ≪ η ≪ 1 to expand out exponential functions or
eliminate small terms in the solutions on the overlap region, with x̂ = O(1).
</p>
<p>(v) Arrange the remaining terms as an ordered asymptotic expansion involving
</p>
<p>η, ε and determine the remaining constants through matching of terms.
</p>
<p>(e) Write the uniform solution valid up through O(ε) terms.</p>
<p/>
</div>
<div class="page"><p/>
<p>7.6 Exercises 165
</p>
<p>7.7 Consider the problem for y(x) on 0 &le; x &le; 2 with ε &rarr; 0,
</p>
<p>x2 + y2 = 4 &minus; ε dy
dx
</p>
<p>, y(0) = 3
ε
.
</p>
<p>(a) Determine the first two terms in the outer solution,
</p>
<p>y &sim; y0 + εy1.
(b) Boundary layers can occur at x&lowast; = 0 and x&lowast; = 2. For each case, determine
</p>
<p>the α, β for each distinguished limit and write its corresponding leading order
</p>
<p>equation for Y0(X). Note that there are two singular distinguished limits at
</p>
<p>x&lowast; = 0.
</p>
<p>7.8 Consider the problem for y(x) on 0 &le; x &le; 1 for ε &rarr; 0,
</p>
<p>ε
d2y
</p>
<p>dx2
&minus; y = &minus;4 + ε
</p>
<p>2y
</p>
<p>(x &minus; 1)3
, y(0) = 0, y(1) = 0.
</p>
<p>The leading order outer solution is y0(x) &equiv; 4.
(a) Determine the leading order inner solution for the boundary layer at x&lowast; = 0.
(b) At x&lowast; = 1, there are two different distinguished limits. Determine α for each
</p>
<p>and obtain the respective leading order equations for each Y0(X).
</p>
<p>Since these solutions have different α&rsquo;s, one layer is nested inside the other. The
</p>
<p>&ldquo;inner-inner&rdquo; layer solution should satisfy boundary condition at x = 1. The
(wider) &ldquo;intermediate inner&rdquo; layer should asymptotically match to the outer and
</p>
<p>inner-inner solutions for the limits X &rarr; &minus;&infin; and X &rarr; 0 respectively in this
triple deck problem.</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 8
</p>
<p>Long-Wave Asymptotics for PDE Problems
</p>
<p>In this chapter we will study matched asymptotics and boundary layer theory
</p>
<p>applied to some classes of multi-dimensional problems for partial differential equa-
</p>
<p>tions (PDE). Perturbation methods offer an interesting alternative way to construct
</p>
<p>solutions that will provide different insight into the structure of some PDE problems.
</p>
<p>Wewill also see that matched asymptotics will allow us to solve problems that cannot
</p>
<p>be tackled directly by classical methods.
</p>
<p>We will illustrate the analysis in the context of problems for Laplace&rsquo;s equation,
</p>
<p>&nabla;2U &equiv;
&part;2U
</p>
<p>&part;X2
+
</p>
<p>&part;2U
</p>
<p>&part;Y2
= 0. (8.1)
</p>
<p>The Laplacian operator&nabla;2 is a fundamental element of equations describing various
</p>
<p>phenomena such as diffusion, wave propagation, and equilibrium potentials
</p>
<p>&part;U
</p>
<p>&part;T
= &nabla;2U,
</p>
<p>&part;2U
</p>
<p>&part;T2
= &nabla;2U, F(X,Y) = &nabla;2U.
</p>
<p>These equations arise in electromagnetism, heat conduction,mass transfer, fluid flow,
</p>
<p>solid mechanics, and many other areas.
</p>
<p>We will focus on electrostatics as an example application&mdash;in this case U(X,Y)
</p>
<p>represents the electric potential (voltage) that drives the flow of charges and currents
</p>
<p>in a conductor. In particular, we will describe the current flow and electric charge
</p>
<p>density in a piece of wire by solving Eq. (8.1) on a long slender domain, subject to
</p>
<p>various boundary conditions.
</p>
<p>8.1 The Classic Separation of Variables Solution
</p>
<p>We begin by briefly reviewing the traditional separation of variables approach to
</p>
<p>solving boundary value problems for Laplace&rsquo;s equation [23, 44].
</p>
<p>&copy; Springer International Publishing Switzerland 2015
</p>
<p>T. Witelski and M. Bowen, Methods of Mathematical Modelling,
</p>
<p>Springer Undergraduate Mathematics Series, DOI 10.1007/978-3-319-23042-9_8
</p>
<p>167</p>
<p/>
</div>
<div class="page"><p/>
<p>168 8 Long-Wave Asymptotics for PDE Problems
</p>
<p>For elliptic PDE such as Laplace&rsquo;s equation, to uniquely determine a solution, a
</p>
<p>problemmust provide boundary conditions around the entire boundary of the domain.
</p>
<p>In the context of electrostatics, Dirichlet boundary conditions, where the value of
</p>
<p>the solution is specified, correspond to imposing a known voltage on the edge of the
</p>
<p>domain, e.g. U (X = 0,Y) = Ū. In contrast, Neumann boundary conditions provide
</p>
<p>the value of the directional derivative of the solution normal to the boundary
</p>
<p>&part;U
</p>
<p>&part;n
&equiv; n̂ &middot; &nabla;U, (8.2)
</p>
<p>where n̂ is the unit normal vector, perpendicular to the boundary, in the outward
</p>
<p>direction, e.g. n̂ = &minus;ı̂ is the normal to the left boundary of a domain given by X &ge; 0,
</p>
<p>&part;U
</p>
<p>&part;n
</p>
<p>∣
∣
∣
∣
X=0
</p>
<p>= &minus;ı̂ &middot; (&part;XU, &part;YU) = &minus;
&part;U
</p>
<p>&part;X
</p>
<p>∣
∣
∣
∣
X=0
</p>
<p>= J (Y).
</p>
<p>Physically, Neumann conditions specify the current, or flux of the solution, out of
</p>
<p>the domain.
</p>
<p>Consider Laplace&rsquo;s equation on a rectangular domain,
</p>
<p>&part;2U
</p>
<p>&part;X2
+
</p>
<p>&part;2U
</p>
<p>&part;Y2
= 0 0 &le; X &le; L 0 &le; Y &le; H (8.3a)
</p>
<p>subject to Dirichlet boundary conditions,
</p>
<p>U(X, 0) = 0, U(L,Y) = 0, U(0,Y) = 0, U(X,H) = F(X). (8.3b)
</p>
<p>This is an elementary &lsquo;building-block&rsquo; problem where the form of the solution will
</p>
<p>be entirely due to the one inhomogeneous boundary condition. Solutions to problems
</p>
<p>on the same domain, but with inhomogeneous boundary conditions on other edges,
</p>
<p>can be built-up from linear superposition of combinations of such building block
</p>
<p>solutions.
</p>
<p>Since this is a linear problem, the overall solution can be obtained as a super-
</p>
<p>position of linearly independent trial solutions. The trial solutions can be sought in
</p>
<p>separation of variables form, as a product of functions of the independent variables:
</p>
<p>U(X,Y) =
</p>
<p>&infin;
&sum;
</p>
<p>n=1
</p>
<p>cnUn(X,Y) with Un(X,Y) = An(X)Bn(Y). (8.4)
</p>
<p>Substituting (8.4) into the homogeneous boundary condition U(0,Y) = 0 for 0 &le;
</p>
<p>Y &le; H with the assumptions that the solution U is nontrivial (not all coefficients
</p>
<p>cn = 0) and that the Un trial solutions are linearly independent yields boundary
</p>
<p>conditions on the An(X) functions for n = 1, 2, 3, . . . ,
</p>
<p>&sum;
</p>
<p>cnAn(0)Bn(Y) = 0 for 0 &lt; Y &lt; H =&rArr; An(0) = 0.</p>
<p/>
</div>
<div class="page"><p/>
<p>8.1 The Classic Separation of Variables Solution 169
</p>
<p>Similarly for the other homogeneous boundary conditions, U(L,Y) = 0 yields
</p>
<p>An(L) = 0 while U(X, 0) = 0 gives Bn(0) = 0. The inhomogeneous boundary
</p>
<p>condition in (8.3b) will be approached differently.
</p>
<p>Substituting Un(X,Y) from (8.4) into (8.3a) and requiring each trial solution to
</p>
<p>satisfy Laplace&rsquo;s equation yields
</p>
<p>d2An
</p>
<p>dX2
Bn(Y)+ An(X)
</p>
<p>d2Bn
</p>
<p>dY2
= 0
</p>
<p>which can be re-arranged to give
</p>
<p>A&prime;&prime;n(X)
</p>
<p>An(X)
= &minus;
</p>
<p>B&prime;&prime;n(Y)
</p>
<p>Bn(Y)
= sn = &plusmn;λn.
</p>
<p>Since the equality must hold for all independent values of X and Y, both sides must
</p>
<p>take the same constant value sn, called a separation constant, which here is written as
</p>
<p>a sign times the undetermined positive constant λn &ge; 0, where the subscript indicates
</p>
<p>that the separation constants are generally distinct between different trial solutions.
</p>
<p>The main result of this separation of variables approach is to split the PDE into two
</p>
<p>separate ODEs for An(X) and Bn(Y) that are linked only through λn.
</p>
<p>In order to make further progress it is convenient to begin by analysing the ODE
</p>
<p>problem satisfying homogeneous boundary conditions. In this case this selects the
</p>
<p>problem in X-direction for An(X). It can be shown that subject to the boundary
</p>
<p>conditions, obtaining nontrivial solutions of A&prime;&prime;n &minus;snAn = 0 forces sn to be negative,
</p>
<p>sn = &minus;λn [23, 44]. The problem for {An, λn} is an eigenvalue problem,
</p>
<p>A
&prime;&prime;
n + λnAn = 0, An(0) = 0, An(L) = 0, (8.5)
</p>
<p>yielding an infinite sequence of oscillatory eigenfunction solutions
</p>
<p>An(X) = sin
(nπ
</p>
<p>L
X
</p>
<p>)
</p>
<p>, λn =
n2π2
</p>
<p>L2
, n = 1, 2, 3, . . .. (8.6)
</p>
<p>Having obtained the separation constants, the ODE for Bn(Y) is now completely
</p>
<p>specified,
</p>
<p>B
&prime;&prime;
n &minus;
</p>
<p>n2π2
</p>
<p>L2
Bn = 0 =&rArr; Bn(Y) = C1 sinh(
</p>
<p>nπ
L
</p>
<p>Y)+ C2 cosh(
nπ
L
</p>
<p>Y). (8.7)
</p>
<p>Imposing theBn(0) = 0 boundary condition reduces the general solution toBn(Y) =
</p>
<p>sinh( nπ
L
</p>
<p>Y). The full solution (8.4) then takes the form
</p>
<p>U(X,Y) =
</p>
<p>&infin;
&sum;
</p>
<p>n=1
</p>
<p>cn sinh(
nπ
L
</p>
<p>Y) sin( nπ
L
</p>
<p>X); (8.8)</p>
<p/>
</div>
<div class="page"><p/>
<p>170 8 Long-Wave Asymptotics for PDE Problems
</p>
<p>all that remains is to determine the coefficients, cn. Applying the inhomogeneous
</p>
<p>boundary condition to the series at Y = H yields,
</p>
<p>U(X,H) =
</p>
<p>&infin;
&sum;
</p>
<p>n=1
</p>
<p>cn sinh(
nπ
L
</p>
<p>H)
︸ ︷︷ ︸
</p>
<p>fn
</p>
<p>sin( nπ
L
</p>
<p>X) = F(X).
</p>
<p>This equation can be interpreted as the Fourier sine series for the function F(X) (see
</p>
<p>Appendix A) and determines the coefficients in the expansion,
</p>
<p>&infin;
&sum;
</p>
<p>n=1
</p>
<p>fn sin(
nπ
L
</p>
<p>X) = F(X) =&rArr; fn =
2
</p>
<p>L
</p>
<p>&int;
L
</p>
<p>0
</p>
<p>F(X) sin( nπ
L
</p>
<p>X) dX.
</p>
<p>Finally, expressing cn in terms of fn, we obtain the solution in the form of an infinite
</p>
<p>series
</p>
<p>U(X,Y) =
</p>
<p>&infin;
&sum;
</p>
<p>n=1
</p>
<p>(
</p>
<p>2
</p>
<p>L sinh( nπ
L
</p>
<p>H)
</p>
<p>&int;
L
</p>
<p>0
</p>
<p>F(X̃) sin( nπ
L
</p>
<p>X̃) dX̃
</p>
<p>)
</p>
<p>sinh( nπ
L
</p>
<p>Y) sin( nπ
L
</p>
<p>X).
</p>
<p>(8.9)
</p>
<p>8.2 The Dirichlet Problem on a Slender Rectangle
</p>
<p>Solution (8.9) holds for all choices of H,L but working with an infinite series can be
</p>
<p>somewhat cumbersome. We will now see how a much more compact, but equivalent
</p>
<p>form of the solution can be obtained for slender rectangles, where the aspect ratio
</p>
<p>H/L ≪ 1, with, for the most-part, a dramatic simplification of the PDE problem to
</p>
<p>a sequence of simple ODE problems.
</p>
<p>Consider a problem for Laplace&rsquo;s equation on the rectangular domain, 0 &le; X &le; L,
</p>
<p>0 &le; Y &le; H (see Fig. 8.1):
</p>
<p>&part;2U
</p>
<p>&part;X2
+
</p>
<p>&part;2U
</p>
<p>&part;Y2
= 0, (8.10a)
</p>
<p>subject to the boundary conditions
</p>
<p>U(X, 0) = 0, U(X,H) = Ūf (X/L), (8.10b)
</p>
<p>U(0,Y) = Ūg0(Y/H), U(L,Y) = Ūg1(Y/H), (8.10c)
</p>
<p>where f (x), g0(y), g1(y) are given functions.</p>
<p/>
</div>
<div class="page"><p/>
<p>8.2 The Dirichlet Problem on a Slender Rectangle 171
</p>
<p>Fig. 8.1 The domain for problem (8.10), a slender rectangle in dimensional coordinates (Left) and
</p>
<p>the rescaled dimensionless domain (Right)
</p>
<p>We nondimensionalize using the scalings
</p>
<p>X = Lx, Y = Hy, U = Ūu(x, y), (8.11)
</p>
<p>yielding the scaled problem on 0 &le; x &le; 1 and 0 &le; y &le; 1,
</p>
<p>ε2uxx + uyy = 0 (8.12a)
</p>
<p>u(x, 0) = 0, u(x, 1) = f (x) for 0 &lt; x &lt; 1 (8.12b)
</p>
<p>u(0, y) = g0(y), u(1, y) = g1(y) for 0 &lt; y &lt; 1 (8.12c)
</p>
<p>where the aspect ratio, or slenderness parameter ε = H/L is small, ε &rarr; 0, corre-
</p>
<p>sponding to a long, thin domain.
</p>
<p>Using ε as a perturbation parameter, we begin by seeking an outer solution of the
</p>
<p>form
</p>
<p>u(x, y) &sim; u0(x, y)+ ε
2u1(x, y)+ ε
</p>
<p>4u2(x, y)+ &middot; &middot; &middot; . (8.13)
</p>
<p>Note that for this problem it is sufficient to use an expansion having only even powers
</p>
<p>of ε because the perturbation parameter appears in the problem only as ε2 in (8.12a).
</p>
<p>Substituting into (8.12a, 8.12b), we obtain a sequence of problems which are each
</p>
<p>essentially ODE boundary value problems in the y-direction with x entering only as
</p>
<p>a secondary parameter. At leading order we get
</p>
<p>u0yy = 0, u0(y = 0) = 0, u0(y = 1) = f (x), (8.14a)
</p>
<p>where the differential equation determines u0 to be linear with respect to y, u0 =
</p>
<p>C1y + C2. The C coefficients need not be constants; they must be independent of y
</p>
<p>but can depend on any other variable(s) present in the problem, namely u0(x, y) =
</p>
<p>C1(x)y + C2(x). Applying the boundary conditions from (8.14a), we arrive at the
</p>
<p>leading order solution
</p>
<p>u0(x, y) = f (x)y. (8.14b)</p>
<p/>
</div>
<div class="page"><p/>
<p>172 8 Long-Wave Asymptotics for PDE Problems
</p>
<p>Similarly, at higher orders,
</p>
<p>O(ε2) : u1yy = &minus;u0xx, u1(y = 0) = 0, u1(y = 1) = 0
</p>
<p>=&rArr; u1(x, y) =
1
6
</p>
<p>f &prime;&prime;(x)(y &minus; y3).
</p>
<p>O(ε4) : u2yy = &minus;u1xx, u2(y = 0) = 0, u2(y = 1) = 0
</p>
<p>=&rArr; u2(x, y) =
1
</p>
<p>360
f &prime;&prime;&prime;&prime;(x)(7y &minus; 10y3 + 3y5).
</p>
<p>If the function f (x) in the boundary condition at the top of the domain is smooth, this
</p>
<p>expansion can be continued to all orders so as to obtain the outer solution in terms of
</p>
<p>polynomials in y times derivatives of f (x). However, this solution will not in general
</p>
<p>satisfy the boundary conditions (8.12c) at x = 0 and x = 1, and hence boundary
</p>
<p>layer corrections will be needed.
</p>
<p>Noting that (8.12a) has a small parameter multiplying the highest order derivative
</p>
<p>in the x-direction, we recognise it as a singular perturbation problem of the type
</p>
<p>treated in Chap.7 and we seek boundary layers at x = 0 and x = 1. In order to
</p>
<p>analyse the structure of the inner solution with respect to x, we assume a scaled
</p>
<p>solution of the form (7.21),
</p>
<p>X =
x &minus; x&lowast;
</p>
<p>εα
, u = U(X, y), (8.15)
</p>
<p>where we have alreadymade use of the Dirichlet boundary conditions, u = g = O(1)
</p>
<p>for the scaling of U. Substituting this form into (8.12a) yields
</p>
<p>ε2&minus;2αUXX + Uyy = 0,
</p>
<p>which selects the distinguished limit α = 1 for the inner solution at both xL&lowast; = 0
</p>
<p>for the left boundary and xR&lowast; = 1 for the right boundary layer. We will describe the
</p>
<p>solution for xL&lowast; = 0 with the construction for the right boundary layer following
</p>
<p>analogously.
</p>
<p>While the inner problem with α = 1 has brought us back to solving the full
</p>
<p>Laplace&rsquo;s equation,
</p>
<p>UXX + Uyy = 0, (8.16a)
</p>
<p>there are subtle changes in the domain and boundary conditions that in this context
</p>
<p>make the inner problem more tractable than the original full problem. The domain
</p>
<p>for this inner problem is a semi-infinite strip, 0 &le; y &le; 1 with X &ge; 0. Since x = εX
</p>
<p>with X = O(1) in the left boundary layer, we can re-write the y = 1 boundary
</p>
<p>condition as
</p>
<p>U(X, 1) = f (εX) = f (0)+ εf &prime;(0)X + 1
2
ε2f &prime;&prime;(0)X2 + &middot; &middot; &middot;</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7">http://dx.doi.org/10.1007/978-3-319-23042-9_7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7">http://dx.doi.org/10.1007/978-3-319-23042-9_7</a></div>
</div>
<div class="page"><p/>
<p>8.2 The Dirichlet Problem on a Slender Rectangle 173
</p>
<p>yielding boundary conditions on the leading order inner solution as constant values
</p>
<p>U0(X, 0) = 0, U0(X, 1) = f (0). (8.16b)
</p>
<p>The boundary condition at X = 0 is unchanged from (8.12c), but now the remaining
</p>
<p>boundary condition is supplied by the analogue of the asymptoticmatching condition
</p>
<p>with the outer solution (see (7.13))
</p>
<p>lim
X&rarr;&infin;
</p>
<p>U0(X, y) = lim
x&rarr;0
</p>
<p>u(x, y). (8.16c)
</p>
<p>Consequently (8.12c), (8.16c) and (8.14b) specify the left and right boundary con-
</p>
<p>ditions as
</p>
<p>U0(0, y) = g0(y), U0(X &rarr; &infin;, y) = f (0)y. (8.16d)
</p>
<p>Noting the term f (0)y from the outer solution is present in both (8.16b, 8.16d), we
</p>
<p>observe that the problem can be expressed in terms of the boundary layer correction
</p>
<p>function V(X, y) defined by
</p>
<p>U0(X, y) = V(X, y)+ f (0)y, (8.17)
</p>
<p>where V(X, y) satisfies the problem
</p>
<p>VXX + Vyy = 0, (8.18a)
</p>
<p>V(X, 0) = 0, V(X, 1) = 0, (8.18b)
</p>
<p>V(0, y) = g0(y)&minus; f (0)y, V(X &rarr; &infin;, y) = 0. (8.18c)
</p>
<p>This matches the form of the Dirichlet &ldquo;building-block&rdquo; problem with a single in-
</p>
<p>homogeneous boundary condition described in Sect. 8.1. Here the homogeneous
</p>
<p>boundary conditions determine the oscillatory eigenfunctions to be in the y-direction
</p>
<p>with λn = nπ yielding
</p>
<p>V(X, y) =
</p>
<p>&infin;
&sum;
</p>
<p>n=1
</p>
<p>cne
&minus;nπX sin(nπy), (8.19a)
</p>
<p>where
</p>
<p>cn = 2
</p>
<p>&int; 1
</p>
<p>0
</p>
<p>[g0(y)&minus; f (0)y] sin(nπy) dy. (8.19b)
</p>
<p>We note that the e&minus;nπX factors resulted from solving the ODE A&prime;&prime;n &minus; n
2π2An = 0
</p>
<p>yielding general solutions An(X) = d0e
nπX + d1e
</p>
<p>&minus;nπX and enforcing the X &rarr; &infin;
</p>
<p>boundary condition to then eliminate theun-matchable exponentially growing modes.</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7">http://dx.doi.org/10.1007/978-3-319-23042-9_7</a></div>
</div>
<div class="page"><p/>
<p>174 8 Long-Wave Asymptotics for PDE Problems
</p>
<p>In conclusion, the leading order uniform solution can then be composed from the
</p>
<p>outer solution and the boundary layer corrections,
</p>
<p>u0unif(x, y) = u0(x, y)+ V
L(XL, y)+ VR(XR, y), (8.20)
</p>
<p>where VL(XL, y) is given by (8.19a, 8.19b) with XL = x/ε and VR(XR, y) analo-
</p>
<p>gously by the right boundary layer correction with XR = (x &minus; 1)/ε.
</p>
<p>8.3 The Insulated Wire
</p>
<p>Current flow through an insulated wire can be represented by replacing the Dirich-
</p>
<p>let conditions on the upper and lower boundaries with no-flux Neumann boundary
</p>
<p>conditions (8.2). Using the same scalings as in the previous example (8.11), the
</p>
<p>nondimensionalized problem on 0 &le; x &le; 1 and 0 &le; y &le; 1 takes the form,
</p>
<p>ε2uxx + uyy = 0, (8.21a)
</p>
<p>&part;u
</p>
<p>&part;y
</p>
<p>∣
∣
∣
∣
y=0
</p>
<p>= 0,
&part;u
</p>
<p>&part;y
</p>
<p>∣
∣
∣
∣
y=1
</p>
<p>= 0 for 0 &lt; x &lt; 1, (8.21b)
</p>
<p>u(x = 0) = g0(y), u(x = 1) = g1(y) for 0 &lt; y &lt; 1. (8.21c)
</p>
<p>This problem describes current flow in a straight insulated wire with prescribed
</p>
<p>end-voltages.
</p>
<p>We begin by constructing the outer solution in the form u &sim; u0 + ε
2u1 + ε
</p>
<p>4u2.
</p>
<p>The leading order problem for u0(x, y) is then given by
</p>
<p>u0yy = 0, u0y(y = 0) = 0, u0y(y = 1) = 0, (8.22)
</p>
<p>where the general solution of the differential equation is again a linear function of y
</p>
<p>with x-dependent coefficients, u0(x, y) = C1(x)y + C2(x). Applying the boundary
</p>
<p>conditions yields
</p>
<p>u0(x, y) = C2(x), (8.23)
</p>
<p>and so the solution has been shown to be independent of y, but is given by some as-yet
</p>
<p>undetermined function of x. Often in perturbation methods, undetermined parts of
</p>
<p>solutions will get pinned down by conditions needed for consistency appearing at
</p>
<p>higher orders, or from matching to solutions on other parts of the domain. At order
</p>
<p>O(ε2) we have the problem for u1(x, y),
</p>
<p>u1yy = &minus;u0xx, u1y(x, 0) = 0, u1y(x, 1) = 0. (8.24)</p>
<p/>
</div>
<div class="page"><p/>
<p>8.3 The Insulated Wire 175
</p>
<p>Substituting (8.23) for u0 into this problem, we obtain the general solution
</p>
<p>u1 = &minus;
1
2
</p>
<p>C&prime;&prime;2 (x)y
2 + C3(x)y + C4(x).
</p>
<p>Applying the boundary condition at y = 0 determines C3(x) &equiv; 0; applying the
</p>
<p>boundary condition at y = 1 yields
</p>
<p>d2C2
</p>
<p>dx2
= 0 for 0 &lt; x &lt; 1; (8.25)
</p>
<p>this is an ordinary differential equation for the leading order solution. Such equations
</p>
<p>determining consistency conditions on lower-order solutions, coming out of parts of
</p>
<p>higher order problems, are often called solvability conditions.
</p>
<p>Equation (8.25) has a simple linear general solution,
</p>
<p>C2(x) = D1x + D2,
</p>
<p>but in order to determine the constants D1,2, we need to impose boundary conditions.
</p>
<p>Our original problem indeed had boundary conditions at x = 0 and x = 1, (8.21c),
</p>
<p>but for general imposed functions g0(y) and g1(y), C2(x) cannot possibly satisfy
</p>
<p>those y-dependent conditions. Hence we must construct boundary layers to satisfy
</p>
<p>(8.21c) while determining the effective boundary conditions on C2(x).
</p>
<p>Following the same scaling (8.15) as in the previous problem, we determine the
</p>
<p>inner distinguished limit α = 1 for the boundary layers both at xL&lowast; = 0 and x
R
&lowast; = 1.
</p>
<p>We again recover Laplace&rsquo;s equation as the inner problem,
</p>
<p>UXX + Uyy = 0. (8.26a)
</p>
<p>Analysing the boundary layer at xL&lowast; = 0 (the analysis at x
R
&lowast; = 1 is analogous), the
</p>
<p>three boundary conditions we can draw from (8.21b, 8.21c) are straightforward,
</p>
<p>U(0, y) = g0(y), Uy(X, 0) = 0, Uy(X, 1) = 0, (8.26b)
</p>
<p>and the final boundary condition is obtained from asymptotic matching to the outer
</p>
<p>solution, using (8.16c),
</p>
<p>U(X &rarr; &infin;, y) = D2. (8.26c)
</p>
<p>Again, it is convenient to recast this problem in terms of the boundary layer correction
</p>
<p>in order to separate out the overlap from matching, so we write
</p>
<p>U(X, y) = V(X, y)+ D2, (8.27)
</p>
<p>with V(X, y) satisfying
</p>
<p>VXX + Vyy = 0, (8.28a)</p>
<p/>
</div>
<div class="page"><p/>
<p>176 8 Long-Wave Asymptotics for PDE Problems
</p>
<p>Vy(X, 0) = 0, Vy(X, 1) = 0, (8.28b)
</p>
<p>V(0, y) = g0(y)&minus; D2, V(X &rarr; &infin;, y) = 0. (8.28c)
</p>
<p>Applying separation of variables to this Neumann boundary value problem yields the
</p>
<p>solution as a cosine series,
</p>
<p>V(X, y) =
</p>
<p>&infin;
&sum;
</p>
<p>n=0
</p>
<p>cne
&minus;nπX cos(nπy), (8.29)
</p>
<p>where the matching condition eliminated the exponentially growing modes, enπX .
</p>
<p>The cn&rsquo;s are then given by the Fourier coefficients of the X = 0 boundary condition,
</p>
<p>c0 =
</p>
<p>&int; 1
</p>
<p>0
</p>
<p>[g0(y)&minus; D2] dy, and cn = 2
</p>
<p>&int; 1
</p>
<p>0
</p>
<p>[g0(y)&minus; D2] cos(nπy) dy (8.30)
</p>
<p>for n = 1, 2, . . . . For n &gt; 0 all of the cne
&minus;nπX factors in (8.29) decay to zero as
</p>
<p>X &rarr; &infin;; any finite values for cn would be compatible with the remaining boundary
</p>
<p>condition, that V(X &rarr; &infin;) = 0. The only term that contributes to the value of V for
</p>
<p>X &rarr; &infin; is the n = 0 term, the uniform constant,V(X &rarr; &infin;) &sim; c0. In order to satisfy
</p>
<p>the matching condition (8.28c), we must have c0 = 0 in (8.30). This determines the
</p>
<p>boundary condition on the outer solution (8.25) in terms of the average of the g0
boundary function,
</p>
<p>C2(0) = D2 =
</p>
<p>&int; 1
</p>
<p>0
</p>
<p>g0(y) dy.
</p>
<p>Analogous analysis of the boundary layer at x&lowast; = 1 yields the boundary condition
</p>
<p>for C2(1) in terms of the average value of g1 and determines the outer solution as
</p>
<p>u0(x, y) = x
</p>
<p>(&int; 1
</p>
<p>0
</p>
<p>g1(y)&minus; g0(y) dy
</p>
<p>)
</p>
<p>+
</p>
<p>(&int; 1
</p>
<p>0
</p>
<p>g0(y) dy
</p>
<p>)
</p>
<p>, (8.31)
</p>
<p>with the leading order uniform solution taking the same form as (8.20).
</p>
<p>It is interesting to compare the &lsquo;information flow&rsquo; or &lsquo;structural dependence&rsquo; of
</p>
<p>the perturbation solution for the past two problems. For the Dirichlet problem, the
</p>
<p>outer solution can be determined independently of the boundary layers, and sets
</p>
<p>matching conditions for the boundary layers,
</p>
<p>Problem (8.12): BL &larr; Outer &rarr; BL</p>
<p/>
</div>
<div class="page"><p/>
<p>8.3 The Insulated Wire 177
</p>
<p>while in the Neumann problem, the outer solution cannot be completely specified
</p>
<p>until the boundary layer solutions have been calculated,
</p>
<p>Problem (8.21): BL &rarr; Outer &larr; BL
</p>
<p>8.4 The Nonuniform Insulated Wire
</p>
<p>We now extend our previous analysis to consider the problem of an insulated wire
</p>
<p>whose cross-section is not of constant width,1 see Fig. 8.2. The main consequence of
</p>
<p>this change is that the domain is no longer separable2 so the method of separation of
</p>
<p>variables from Sect. 8.1 can not be used to construct an exact solution of the whole
</p>
<p>problem. However, boundary layer theory and the method of matched asymptotics
</p>
<p>again works, with just minor extensions.
</p>
<p>We begin with the dimensional problem for Laplace&rsquo;s equation on a domain with
</p>
<p>0 &le; X &le; L and 0 &le; Y &le; Hf (X/L) where f (x) is a given function describing the
</p>
<p>width of the wire,
</p>
<p>UXX + UYY = 0 (8.32a)
</p>
<p>along with the same imposed-voltage Dirichlet boundary conditions at X = 0 and
</p>
<p>X = L, but it is now notable that the lengths of the ends may differ
</p>
<p>U(0,Y) = Ūg0(Y/H) for 0 &le; Y &le; Hf(0), (8.32b)
</p>
<p>U(L,Y) = Ūg1(Y/H) for 0 &le; Y &le; Hf(1). (8.32c)
</p>
<p>The lower edge of the domain remains straight and the associated no-flux boundary
</p>
<p>condition corresponds to the first condition in (8.21b)
</p>
<p>UY(X, 0) = 0 for 0 &le; X &le; L. (8.32d)
</p>
<p>We must be a little more careful in order to properly determine the form of the no-
</p>
<p>flux condition, n̂ &middot; &nabla;U = 0 along the upper boundary. Recalling from multivariable
</p>
<p>calculus that the normal to a constant-value contour3 of a functionB(X,Y) is given by
</p>
<p>the gradient of B, we construct B(X,Y) = Y&minus;Hf (X/L). This defines our boundary
</p>
<p>as the zero-level contour of B(X,Y). To obtain a unit normal vector, we calculate
</p>
<p>the normalised gradient:
</p>
<p>1This is sometimes called a &ldquo;domain perturbation&rdquo; [61], also see Hinch [47].
2A separable domain being expressible as Cartesian products of intervals in independent variables,
</p>
<p>for example (X &isin; [0,L])&times; (Y &isin; [0,H]).
3Sometimes called a level set.</p>
<p/>
</div>
<div class="page"><p/>
<p>178 8 Long-Wave Asymptotics for PDE Problems
</p>
<p>Fig. 8.2 The domain for the
</p>
<p>non-uniform insulated wire,
</p>
<p>problem (8.32)
</p>
<p>n̂ = &plusmn;
&nabla;B
</p>
<p>|&nabla;B|
= &plusmn;
</p>
<p>(&minus;(H/L)f &prime;(X/L), 1)
&radic;
</p>
<p>1+ (H/L)2f &prime;(X/L)2
,
</p>
<p>where the &plusmn; sign is chosen so as to correspond to the unit outward normal, pointing
</p>
<p>out of the domain at the boundary (in this case + for the upper boundary). Finally,
</p>
<p>taking the dot product with the gradient &nabla;U yields the condition
</p>
<p>&minus;
H
</p>
<p>L
f &prime;(X/L)
</p>
<p>&part;U
</p>
<p>&part;X
</p>
<p>∣
∣
∣
∣
(X,Hf (X/L))
</p>
<p>+
&part;U
</p>
<p>&part;Y
</p>
<p>∣
∣
∣
∣
(X,Hf (X/L))
</p>
<p>= 0. (8.32e)
</p>
<p>Employing the previously used scalings (8.11) we arrive at the nondimensional prob-
</p>
<p>lem on 0 &le; x &le; 1 and 0 &le; y &le; f (x),
</p>
<p>ε2uxx + uyy = 0, (8.33a)
</p>
<p>subject to the boundary conditions
</p>
<p>u(0, y) = g0(y) 0 &le;y &le; f (0), (8.33b)
</p>
<p>u(1, y) = g1(y) 0 &le;y &le; f (1), (8.33c)
</p>
<p>and for 0 &le; x &le; 1
</p>
<p>uy(x, 0) = 0, uy(x, f (x))&minus; ε
2f &prime;(x)ux(x, f (x)) = 0. (8.33d)
</p>
<p>Following as in Sect. 8.3, we begin by constructing the outer solution, and at leading
</p>
<p>order obtain the problem,
</p>
<p>u0yy = 0, u0y(x, 0) = 0, u0y(x, f (x)) = 0, (8.34)</p>
<p/>
</div>
<div class="page"><p/>
<p>8.4 The Nonuniform Insulated Wire 179
</p>
<p>yielding u0(x, y) = C2(x) as in (8.23). To determine C2(x) we look to the next order
</p>
<p>problem,
</p>
<p>u0xx + u1yy = 0, u1y(x, 0) = 0, u1y(x, f ) = f
&prime;(x)u0x(x, f ). (8.35)
</p>
<p>Substituting in for u0, we find the general solution,
</p>
<p>u1(x, y) = &minus;
1
2
</p>
<p>C&prime;&prime;2 (x)y
2 + C3(x)y + C4(x). (8.36)
</p>
<p>Imposing the y = 0 boundary condition determines C3 &equiv; 0. The top boundary
</p>
<p>condition at y = f (x) then takes the form
</p>
<p>u1y(x, f (x)) = f
&prime;(x)C&prime;2(x);
</p>
<p>equating this expression with the y-derivative of the general u1(x, y) solution given
</p>
<p>by (8.36) evaluated at y = f yields the compatibility condition
</p>
<p>&minus;C&prime;&prime;2 (x)f (x) = f
&prime;(x)C&prime;2(x).
</p>
<p>Using the product rule, this result can be expressed more compactly as
</p>
<p>d
</p>
<p>dx
</p>
<p>(
</p>
<p>f (x)
dC2
</p>
<p>dx
</p>
<p>)
</p>
<p>= 0; (8.37)
</p>
<p>this is a generalisation of (8.25) for non-constant f (x). Boundary conditions for (8.37)
</p>
<p>are then determined by solving for the boundary layers at xL&lowast; = 0 and x
R
&lowast; = 1 using
</p>
<p>separation of variables as was done in Sect. 8.3 to construct the uniform solution on
</p>
<p>the whole domain (8.20).
</p>
<p>8.5 Further Directions
</p>
<p>The main asymptotic reduction considered in this chapter is based on having the
</p>
<p>aspect ratio as the limiting small parameter, ε = H/L &rarr; 0. Stemming from the
</p>
<p>historical uses of this approach in the context of many problems in fluid dynamics
</p>
<p>[1, 61] (involving theflowof oil betweenmachine parts, andother thin layers like tears
</p>
<p>films on the eye), these types of problems are sometimes called lubrication models
</p>
<p>[51, 79, 96]. They offer valuable simplifications to problems by reducing systems to
</p>
<p>lower-dimensional domains (in our case from a PDE on a two-dimensional region
</p>
<p>to an ODE on a one-dimensional interval) by separating out the &ldquo;thin&rdquo; directions
</p>
<p>to leave an underlying governing model on the &ldquo;wide&rdquo; spatial directions with the
</p>
<p>appropriate boundary conditions incorporated. These problems are also sometimes
</p>
<p>called slender body asymptotics, and reduced-dimension models.</p>
<p/>
</div>
<div class="page"><p/>
<p>180 8 Long-Wave Asymptotics for PDE Problems
</p>
<p>8.6 Exercises
</p>
<p>8.1 Consider the problem for Laplace&rsquo;s equation on 0 &le; X &le; L and 0 &le; Y &le; H,
</p>
<p>UXX + UYY = 0,
</p>
<p>with boundary conditions
</p>
<p>U(0,Y) = 0, U(L,Y) = 0 for 0 &le; Y &le; H,
</p>
<p>U(X, 0) = 0, &part;U
&part;Y
</p>
<p>∣
∣
∣
∣
Y=H
</p>
<p>= e&minus;3X/L for 0 &le; X &le; L.
</p>
<p>(a) Use separation of variables to construct the exact solutionU(X,Y) (valid for any
</p>
<p>values of H,L &gt; 0).
</p>
<p>(b) Nondimensionalize the problem and consider the slender limit of ε = H/L &rarr; 0
</p>
<p>to find the leading order outer solution u0(x, y).
</p>
<p>(c) Rescale the solution from (a) by the natural lengthscales and show that it is
</p>
<p>equivalent to the solution from (b) in the limit ε &rarr; 0.
</p>
<p>8.2 Consider the problem for Laplace&rsquo;s equation on 0 &le; X &le; L and 0 &le; Y &le; H in
</p>
<p>the limit that H &rarr; 0 with L = O(1),
</p>
<p>UXX + UYY = 0,
</p>
<p>with boundary conditions
</p>
<p>U(0,Y) = sin
(
πY
2H
</p>
<p>)
</p>
<p>, U(L,Y) = &minus;(Y/H)2 for 0 &le; Y &le; H,
</p>
<p>U(X, 0) = sin
(
5πX
</p>
<p>L
</p>
<p>)
</p>
<p>, U(X,H) = cos
(
3πX
</p>
<p>L
</p>
<p>)
</p>
<p>for 0 &le; X &le; L.
</p>
<p>(a) Determine the leading-order outer solution.
</p>
<p>(b) Determine the boundary layer corrections for the left and right leading-order
</p>
<p>inner solutions.
</p>
<p>(c) Determine the leading order uniformly valid solution.
</p>
<p>(d) Use (c) to show that the boundary layer is crucial for calculating the leading
</p>
<p>order value of the average flux at the right end of the domain:
</p>
<p>J
R =
</p>
<p>1
</p>
<p>H
</p>
<p>&int;
H
</p>
<p>0
</p>
<p>(
&part;U
&part;X
</p>
<p>∣
∣
X=L
</p>
<p>)
</p>
<p>dY.
</p>
<p>Hint: Your solution will involve a sum given by the Riemann zeta function,
&sum;&infin;
</p>
<p>k=0 1/(2k + 1)
3 = 7
</p>
<p>8
ζ(3) &asymp; 1.0518.</p>
<p/>
</div>
<div class="page"><p/>
<p>8.6 Exercises 181
</p>
<p>8.3 Consider the problem forLaplace&rsquo;s equation on the non-uniformslender domain,
</p>
<p>0 &le; X &le; L and 0 &le; Y &le; F(X) where F(X) = 15 + 5 cos(3πX/L) in the limit
</p>
<p>L &rarr; &infin; with H = 1,
</p>
<p>UXX + UYY = 0,
</p>
<p>with boundary conditions
</p>
<p>U(0,Y) = &minus; 1
100
</p>
<p>Y3, U(L,Y) = 3Y2 for 0 &le; Y &le; F(X),
</p>
<p>&part;U
&part;Y
</p>
<p>∣
∣
∣
∣
Y=0
</p>
<p>= 0, n̂ &middot; &nabla;U
</p>
<p>∣
∣
∣
∣
Y=F(X)
</p>
<p>= 0 for 0 &le; X &le; L.
</p>
<p>(a) Nondimensionalize the problem.
</p>
<p>(b) Write the equations for the outer solution up to O(ε2). Determine the first two
</p>
<p>terms in the expansion of the outer solution.
</p>
<p>(c) Determine the boundary layer corrections for the left and right leading-order
</p>
<p>inner solutions. Hint: What is yBL in 0 &le; y &le; yBL in each boundary layer?
</p>
<p>(d) Use matching to determine the x-boundary conditions for the outer solution and
</p>
<p>then obtain the leading-order outer solution.
</p>
<p>8.4 Consider the problem for Laplace&rsquo;s equation for a curved semicircular arc of
</p>
<p>wire of varying width on 0 &le; θ &le; π with R̄ &minus; Wf (θ) &le; R &le; R̄ + Wf (θ) in the
</p>
<p>limit of a large radius of curvature, R̄ &rarr; &infin;,
</p>
<p>&part;2U
</p>
<p>&part;R2
+
</p>
<p>1
</p>
<p>R
</p>
<p>&part;U
</p>
<p>&part;R
+
</p>
<p>1
</p>
<p>R2
</p>
<p>&part;2U
</p>
<p>&part;θ2
= 0,
</p>
<p>with boundary conditions
</p>
<p>n̂ &middot; &nabla;U
</p>
<p>∣
∣
∣
R=R̄&minus;Wf (θ)
</p>
<p>= 0, n̂ &middot; &nabla;U
</p>
<p>∣
∣
∣
R=R̄+Wf (θ)
</p>
<p>= 0 for 0 &le; θ &le; π,
</p>
<p>U(R, 0) = Ūg0(R/R̄), U(R, π) = Ūg1(R/R̄) for 0 &le; X &le; L.
</p>
<p>(a) Nondimensionalize the problem using R = R̄r, but show that this does not yield
</p>
<p>a scaled problem with a small parameter.
</p>
<p>(b) Let r = 1+ εy. What should be used for the aspect ratio ε? Write the complete
</p>
<p>problem satisfied by u(y, θ).
</p>
<p>(c) Write the problems for the outer solution, u(y, θ) &sim; u0(y, θ) + εu1(y, θ) +
</p>
<p>ε2u2(y, θ).
</p>
<p>8.5 The derivation of theKorteweg de Vries (KdV) equation for waves on the surface
</p>
<p>of shallow layers of water follows from similar asymptotic reductions of Laplace&rsquo;s
</p>
<p>equation with appropriate boundary conditions [31, 58, 80]. Consider the following
</p>
<p>nondimensionalized problem for a time-dependent potential φ(x, y, t) and the shape
</p>
<p>of waves on the top-surface of a fluid layer, F(x, t), on &minus;&infin; &lt; x &lt; &infin;,</p>
<p/>
</div>
<div class="page"><p/>
<p>182 8 Long-Wave Asymptotics for PDE Problems
</p>
<p>ε2φxx + φyy = 0 on 0 &le; y &le; 1+ ε
2F (8.38a)
</p>
<p>φy = 0 at y = 0 (8.38b)
</p>
<p>φt +
1
2
(ε2φ2x + φ
</p>
<p>2
y )+ F = 0 at y = 1+ ε
</p>
<p>2F (8.38c)
</p>
<p>ε2Ft + ε
4φxFx = φy at y = 1+ ε
</p>
<p>2F (8.38d)
</p>
<p>The first steps in the derivation are:
</p>
<p>(a) Expand φ = φ0+ ε
2φ1+ ε
</p>
<p>4φ2+O(ε
6) and F = F0 + ε
</p>
<p>2F1+O(ε
4) for ε &rarr; 0
</p>
<p>and use (8.38a, 8.38b) to determine φ0, φ1, φ2 in terms of polynomials in y and
</p>
<p>three un-determined functions C0(x, t),C1, (x, t),C2(x, t).
</p>
<p>(b) Determine the leading order equations for C0, f0 obtained from substituting the
</p>
<p>expansions for φ,F into (8.38c, 8.38d).
</p>
<p>(c) Determine the equations for the O(ε2) next-order equations obtained from
</p>
<p>(8.38c, 8.38d). (To be concluded in Exercise 9.12.)
</p>
<p>8.6 The derivation of the porous medium equation, introduced earlier as Eq. (5.21),
</p>
<p>&part;h
</p>
<p>&part;t
=
</p>
<p>1
</p>
<p>3
</p>
<p>&part;
</p>
<p>&part;x
</p>
<p>(
</p>
<p>h3
&part;h
</p>
<p>&part;x
</p>
<p>)
</p>
<p>,
</p>
<p>follows from a long-wave analysis for the evolution of the height of a layer of a
</p>
<p>viscous fluid y = h(x, t) [1, 79]. Consider the ε &rarr; 0 limit of the problem
</p>
<p>ε2uxx + uyy = &minus;hx on 0 &le; y &le; h (8.39a)
</p>
<p>ux + vy = 0 on 0 &le; y &le; h (8.39b)
</p>
<p>u = v = 0 at y = 0 (8.39c)
</p>
<p>uy = 0 at y = h (8.39d)
</p>
<p>ht + uhx = v at y = h (8.39e)
</p>
<p>where u(x, y, t), v(x, y, t) are the horizontal and vertical components of the fluid
</p>
<p>velocity respectively and the last three equations are boundary conditions on the first
</p>
<p>two.
</p>
<p>(a) Show that by using (8.39b, 8.39c) to express v in terms of u, Eq. (8.39e) can be
</p>
<p>written as
</p>
<p>&part;h
</p>
<p>&part;t
+
</p>
<p>&part;
</p>
<p>&part;x
</p>
<p>(
&int; h
</p>
<p>0
</p>
<p>u dy
</p>
<p>)
</p>
<p>= 0. (8.40)
</p>
<p>(b) Determine the leading order horizontal velocity, u0(x, y, t) in terms of h from
</p>
<p>(8.39a, 8.39c, 8.39d) to then obtain the porous medium equation from (8.40).</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9">http://dx.doi.org/10.1007/978-3-319-23042-9_9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5">http://dx.doi.org/10.1007/978-3-319-23042-9_5</a></div>
</div>
<div class="page"><p/>
<p>8.6 Exercises 183
</p>
<p>8.7 Note that in all of the problems considered here we assumed a perturbation
</p>
<p>expansion for the outer solution given in powers of ε2, (8.13). Sometimes this must
</p>
<p>be modified. Consider problem (8.12) with the Dirichlet condition u(x, 1) = x on the
</p>
<p>top boundary. Examine the expansion of the boundary layers to show that ifwewish to
</p>
<p>get a solution that is uniformly valid toO(ε2) then the expansion u &sim; u0+εu1+ε
2u2
</p>
<p>is needed.</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 9
</p>
<p>Weakly-Nonlinear Oscillators
</p>
<p>Many systems function through repeated cycles of operation&mdash;from the spinning of
</p>
<p>gears in a machine, the physiology of heartbeats, biological behaviour on the 24h
</p>
<p>circadian cycle, to seasonal climate changes during the motion of the earth around
</p>
<p>the sun each year. The most basic models for such systems take the form of oscillator
</p>
<p>equations, having regular predictable periodic solutions; the simplest such model is
</p>
<p>the linear oscillator equation,
</p>
<p>d2x
</p>
<p>dt2
+ ω20x = 0, (9.1)
</p>
<p>with natural frequency ω0. It has the general solution x(t) = A sin(ω0t) +
B cos(ω0t), with the constants A and B being determined by the initial conditions
</p>
<p>imposed on the system.
</p>
<p>More detailedmodels of oscillatory systems include additional terms that describe
</p>
<p>other influences that modify the solutions. If these effects are weak, as indicated by
</p>
<p>a dimensionless system parameter being small, then the model can be written as
</p>
<p>d2x
</p>
<p>dt2
+ ω20x = ε f
</p>
<p>(
</p>
<p>x, dx
dt
, t
</p>
<p>)
</p>
<p>, ε &rarr; 0. (9.2)
</p>
<p>Such models are called weakly-nonlinear oscillators since they reduce to the linear
</p>
<p>oscillator (9.1) when the perturbation terms (potentially including nonlinearities) are
</p>
<p>suppressed. In the context of mechanical systems, Eq. (9.2) can describe the small-
</p>
<p>amplitude motion of a pendulum, or a mass attached to a nonlinear spring.
</p>
<p>In the framework of the earlier chapters on perturbationmethods, (9.2)may appear
</p>
<p>to be a straightforward regular perturbation problem, but we will see that regular
</p>
<p>perturbation expansions will not be able to address the question of greatest interest
</p>
<p>for oscillating systems, which is,
</p>
<p>If we understand the behaviour of the system for a single cycle of the oscillation, can we
</p>
<p>determine how the perturbation forcing terms cumulatively affect the problem over long
</p>
<p>times and many oscillation periods?
</p>
<p>&copy; Springer International Publishing Switzerland 2015
</p>
<p>T. Witelski and M. Bowen, Methods of Mathematical Modelling,
</p>
<p>Springer Undergraduate Mathematics Series, DOI 10.1007/978-3-319-23042-9_9
</p>
<p>185</p>
<p/>
</div>
<div class="page"><p/>
<p>186 9 Weakly-Nonlinear Oscillators
</p>
<p>Two perturbation methods will be described to illustrate how weak influences can
</p>
<p>be incorporated into the leading order solution to obtain more accurate long-time
</p>
<p>predictions of oscillatory behaviour.
</p>
<p>9.1 Review of Solutions of the Linear Problem
</p>
<p>We begin by briefly reviewing the essential results for the linear oscillator equation
</p>
<p>that form the basis for the perturbation methods for (9.2). As discussed above, the
</p>
<p>unforced linear oscillator equation is characterised by a natural frequency ω0 &gt; 0
</p>
<p>and has the general homogeneous periodic solution xh(t),
</p>
<p>d2x
</p>
<p>dt2
+ ω20x = 0 =&rArr; xh(t) = A sin(ω0t)+ B cos(ω0t). (9.3)
</p>
<p>Now consider the inhomogeneous version of this equation, driven by a periodic
</p>
<p>forcing function f (t),
</p>
<p>x &prime;&prime; + ω20x = f (t).
</p>
<p>The function f canbedirectly replacedby its Fourier series, f (t) =
&sum;
</p>
<p>k Ck sin(γk t)+
Dk cos(γk t), and then by the linearity of the equation, the overall solution will be
</p>
<p>the sum of the contributions from each of the terms in the series for f , yielding
</p>
<p>x(t) = xh(t)+
&sum;
</p>
<p>k xk(t). Each Fourier term yields a problem of the form
</p>
<p>x &prime;&prime;k + ω20xk = Ck sin(γk t)+ Dk cos(γk t). (9.4)
</p>
<p>If γk �= ω0 then the general solution is given as a combination of homogeneous and
particular solutions as
</p>
<p>xk(t) = A sin(ω0t)+ B cos(ω0t)
︸ ︷︷ ︸
</p>
<p>Homogeneous solution
</p>
<p>+
Ck
</p>
<p>ω20 &minus; γ 2k
sin(γk t)+
</p>
<p>Dk
</p>
<p>ω20 &minus; γ 2k
cos(γk t)
</p>
<p>︸ ︷︷ ︸
</p>
<p>Particular solution
</p>
<p>.
</p>
<p>The particular solution can be obtained from themethod of undetermined coefficients
</p>
<p>or other elementary approaches. This solution is not valid for γk = ω0, which is
called the case of resonant forcing (forcing at a natural frequency of the system).
</p>
<p>For resonant forcing, the method of undetermined coefficients suggests a different
</p>
<p>form for the particular solution, x p(t) = c1t sin(ω0t) + c2t cos(ω0t). Substituting
this into (9.4) and matching coefficients of corresponding terms yields the general
</p>
<p>solution as
</p>
<p>xω0(t) = A sin(ω0t)+ B cos(ω0t)
︸ ︷︷ ︸
</p>
<p>Homogeneous solution
</p>
<p>+
C
</p>
<p>2ω0
t cos(ω0t)+
</p>
<p>D
</p>
<p>2ω0
t sin(ω0t)
</p>
<p>︸ ︷︷ ︸
</p>
<p>Resonant forced response
</p>
<p>.</p>
<p/>
</div>
<div class="page"><p/>
<p>9.1 Review of Solutions of the Linear Problem 187
</p>
<p>Fig. 9.1 Solutions of the
</p>
<p>forced linear oscillator
</p>
<p>equation (9.4) with ω0 = 1:
the non-resonant solution for
</p>
<p>γk = 2 and resonant solution
for γk = 1
</p>
<p>The resonant response, while being oscillatory with period 2π/ω0, is notable for
</p>
<p>having an amplitude that exhibits unbounded growth with increasing time. The terms
</p>
<p>t cosω0t and t sinω0t are commonly called secular growth terms (see Fig. 9.1). We
</p>
<p>will see that the occurrence of such terms is the central issue that must be addressed
</p>
<p>in constructing accurate long-time asymptotic solutions for perturbed oscillators.
</p>
<p>9.2 The Failure of Direct Regular Expansions
</p>
<p>In order to illustrate the shortcomings of the standard regular perturbation expansion
</p>
<p>approach, we consider two simple perturbed linear oscillator problems in the limit
</p>
<p>ε &rarr; 0, namely
x &prime;&prime; + x = &minus;εx, x(0) = 1, x &prime;(0) = 0, (9.5)
</p>
<p>and
</p>
<p>x &prime;&prime; + x = &minus;εx &prime;, x(0) = 1, x &prime;(0) = &minus; 1
2
ε. (9.6)
</p>
<p>Assuming the solutions to be perturbation expansions of the form
</p>
<p>x(t) = x0(t)+ εx1(t)+ ε2x2(t)+ &middot; &middot; &middot; , (9.7)
</p>
<p>yields an ordered sequence of initial value problems for each xn(t) with the leading
</p>
<p>order for both (9.5) and (9.6) reducing to (9.3) with ω0 = 1. Solving these sequences
of sub-problems up to O(ε2), yields the solution of (9.5) as
</p>
<p>x(t) &sim; cos t &minus; 1
2
εt sin t + 1
</p>
<p>8
ε2
</p>
<p>(
</p>
<p>t sin t &minus; t2 cos t
)
</p>
<p>, (9.8)
</p>
<p>while the solution of (9.6) is given by
</p>
<p>x(t) &sim; cos t &minus; 1
2
εt cos t + 1
</p>
<p>8
ε2
</p>
<p>(
</p>
<p>t sin t + t2 cos t
)
</p>
<p>. (9.9)</p>
<p/>
</div>
<div class="page"><p/>
<p>188 9 Weakly-Nonlinear Oscillators
</p>
<p>While these two expansions appear quite similar in form, this masks the fact that
</p>
<p>they come from problems predicting very different behaviours. Problem (9.5) can be
</p>
<p>re-written in the form (9.3) as x &prime;&prime; + (1+ ε)x = 0 and it is straight forward to show
that its exact solution is
</p>
<p>xexact(t) = cos(
&radic;
1+ ε t). (9.10)
</p>
<p>In other words, the exact solution has a slightly perturbed natural frequency, ω0 =&radic;
1+ ε, compared toω0 = 1 for the leading order problem, x &prime;&prime;0 +x0 = 0. In contrast,
</p>
<p>(9.6) is a weakly damped linear oscillator of the form x &prime;&prime;+εx &prime;+ x = 0, and its exact
solution is given by
</p>
<p>xexact(t) = e&minus;εt/2 cos
(&radic;
</p>
<p>1&minus; 1
4
ε2 t
</p>
<p>)
</p>
<p>. (9.11)
</p>
<p>The respective periodic and decaying oscillatory behaviours of these two solutions
</p>
<p>are shown in Fig. 9.2 along with plots of the expansions (9.8) and (9.9). While the
</p>
<p>expansions match their corresponding solutions for early times, both dramatically
</p>
<p>diverge when their later time behaviours become dominated by the secular growth
</p>
<p>terms.
</p>
<p>While these results might suggest that the perturbation expansions have produced
</p>
<p>incorrect descriptions, we should not dismiss them too soon. In fact, taking the Taylor
</p>
<p>series expansions of (9.10) and (9.11) for ε &rarr; 0 at fixed finite times (t = O(1))
directly reproduces (9.8) and (9.9). Equations (9.8) and (9.9) are indeed correct, but
</p>
<p>they must be used with caution.
</p>
<p>Applying the fundamental assumption of asymptotic ordering to the terms in (9.7),
</p>
<p>the expansions are valid only when
</p>
<p>|x0(t)| ≫ |εx1(t)| ≫ |ε2x2(t)| ≫ &middot; &middot; &middot; , ε &rarr; 0. (9.12)
</p>
<p>Fig. 9.2 Exact solutions and regular expansions for problem (9.5): (9.10) and (9.8) (Left) and for
</p>
<p>problem (9.6): (9.11) and (9.9) (Right), both with ε = 1/5</p>
<p/>
</div>
<div class="page"><p/>
<p>9.2 The Failure of Direct Regular Expansions 189
</p>
<p>Considering the first two terms from (9.8), | cos t | ≫ | 1
2
εt sin t | holds only if 1 ≫ εt .
</p>
<p>In otherwords, the expansions can only be expected to holdwhile this product is small
</p>
<p>(&ldquo;for a limited time only&rdquo; is an appropriate phrase, here applying for 0 &le; t ≪ 1/ε).
These examples are be a bit troubling&mdash;we have worked out higher order terms in
</p>
<p>the asymptotic expansions since the leading order solution by itself, x0(t) = cos t ,
does not capture the differences that distinguish these two problems from each other.
</p>
<p>Yet the additional terms yield contributions that restrict the validity of the expansion
</p>
<p>to relatively short times, when effects like slow growth or decay or changes in the
</p>
<p>oscillation frequency have not yet fully developed. This suggests the need for other
</p>
<p>forms of perturbation expansions that can overcome these limitations.
</p>
<p>9.3 Poincare&ndash;Lindstedt Expansions
</p>
<p>The failure of the regular expansion to describe periodicmotion on long timescales in
</p>
<p>the context of astronomy (for themotion of the planets)motivated the development of
</p>
<p>an improved approach known as the Poincare&ndash;Lindstedt method. A key idea behind
</p>
<p>the method is that the regular perturbation expansion is too restrictive in its form
</p>
<p>and does not allow for the possibility that the solution may have a frequency that is
</p>
<p>shifted from the leading order natural frequency ω0 (as in (9.10)).
</p>
<p>The Poincare&ndash;Lindstedt approach begins with a change of variables in terms of a
</p>
<p>frequency that can depend on the perturbation parameter,
</p>
<p>x(t) = x̃(θ) with θ = Ω(ε)t, (9.13)
</p>
<p>such that Ω(0) = ω0. We then seek regular perturbation expansions in terms of the
new unknowns,
</p>
<p>x̃(θ) = x̃0(θ)+ εx̃1(θ)+ &middot; &middot; &middot; , Ω(θ) = ω0 + εω1 + &middot; &middot; &middot; . (9.14)
</p>
<p>Wewill nowgive an example to illustrate how this seeminglyminor change allows the
</p>
<p>Poincare&ndash;Lindstedtmethod to eliminate secular growth terms andobtain perturbation
</p>
<p>expansions that are valid over longer times for some problems.
</p>
<p>Consider a problem similar to (9.5),
</p>
<p>x &prime;&prime; + 4x = &minus;εx, x(0) = 3, x &prime;(0) = &minus;8. (9.15)
</p>
<p>After the change of variables (9.13), we arrive at the modified problem for x̃(θ),
</p>
<p>Ω2
d2 x̃
</p>
<p>dθ2
+ 4x̃ = &minus;εx̃, x̃(0) = 3, Ω
</p>
<p>dx̃
</p>
<p>dθ
</p>
<p>∣
∣
∣
∣
θ=0
</p>
<p>= &minus;8. (9.16)</p>
<p/>
</div>
<div class="page"><p/>
<p>190 9 Weakly-Nonlinear Oscillators
</p>
<p>Substituting expansions (9.14) into (9.16) and separating by orders of ε yields, at
</p>
<p>O(ε0),
</p>
<p>ω20
d2 x̃0
</p>
<p>dθ2
+ 4x̃0 = 0, x̃0(0) = 3, ω0
</p>
<p>dx̃0
</p>
<p>dθ
</p>
<p>∣
∣
∣
∣
θ=0
</p>
<p>= &minus;8, (9.17a)
</p>
<p>and at O(ε1),
</p>
<p>ω20
d2 x̃1
</p>
<p>dθ2
+ 4x̃1 = &minus;x̃0 &minus; 2ω0ω1
</p>
<p>d2 x̃0
</p>
<p>dθ2
, (9.17b)
</p>
<p>x̃1(0) = 0, ω0 x̃ &prime;1(0) = &minus;ω1 x̃ &prime;0(0),
</p>
<p>and so on at higher orders. Note that lower-order terms from the expansion of the
</p>
<p>solution (x̃k for k = 0, 1, . . . , n &minus; 1) should be shifted to the right-hand side of the
equation for x̃n and be treated as known parts of the inhomogeneous forcing.
</p>
<p>Identifying the natural frequency as ω0 = 2 from (9.15) with ε = 0, the leading
order solution can then be obtained from (9.17a) as
</p>
<p>x̃0(θ) = &minus;4 sin θ + 3 cos θ. (9.18)
</p>
<p>Substituting these results into the O(ε) problem (9.17b) yields
</p>
<p>4
d2 x̃1
</p>
<p>dθ2
+ 4x̃1 = [16ω1 &minus; 4] sin θ + [&minus;12ω1 + 3] cos θ, (9.19)
</p>
<p>x̃1(0) = 0, 2x̃ &prime;1(0) = 4ω1.
</p>
<p>At this point ω1 is an undetermined constant. Problem (9.19) can be solved for any
</p>
<p>valueω1 to obtain x̃1(θ). However, noting the presence of the resonant forcing terms,
</p>
<p>sin θ and cos θ , on the right-hand side of the equation, the solution would include
</p>
<p>secular growth terms. But, if those resonant terms in (9.19) were eliminated by an
</p>
<p>appropriate choice of ω1, then x̃1(θ) would be bounded and x̃0 + εx̃1 would remain
asymptotically well-ordered for all times. For this problem, this criterion selects
</p>
<p>ω1 = 1/4. This choice yields x̃1(θ) = 12 sin θ , and then using (9.13) and (9.14) the
solution of the original problem can be written as
</p>
<p>x(t) &sim; (&minus;2+ 1
2
ε) sin([2+ 1
</p>
<p>4
ε]t)+ 3 cos([2+ 1
</p>
<p>4
ε]t). (9.20)
</p>
<p>This solution holds over 0 &le; t ≪ 1/ε2; compare this with (9.8), which was valid
only over 0 &le; t ≪ 1/ε, see Fig. 9.3. In fact, even without going through the work of
solving for x̃1(θ), the Poincare&ndash;Lindstedt approach has yielded an improved solution
</p>
<p>by determining ω1 through suppressing the resonant terms in the O(ε) equation; the
</p>
<p>condition on ω1 is another example of a solvability condition.</p>
<p/>
</div>
<div class="page"><p/>
<p>9.3 Poincare&ndash;Lindstedt Expansions 191
</p>
<p>Fig. 9.3 Comparison of the
</p>
<p>regular expansion and the
</p>
<p>Poincare&ndash;Lindstedt leading
</p>
<p>order solution against the
</p>
<p>exact solution of (9.15).
</p>
<p>Slight shifts between the
</p>
<p>Poincare&ndash;Lindstedt and
</p>
<p>exact solution are visible for
</p>
<p>larger times
</p>
<p>While the example above was a linear problem, the Poincare&ndash;Lindstedt method
</p>
<p>extends directly to nonlinear equations with perturbation terms of the form ε f (x).
</p>
<p>However, readers are right to suspect that the approach has some limitations. Noting
</p>
<p>that the general solution of the leading order problem has two independent solution
</p>
<p>terms, x̃0 = A sin θ + B cos θ , and that each leads to resonant forcing in (9.19),
it should be a little surprising that the coefficients of both resonant terms can be
</p>
<p>zeroed using only one degree of freedom, ω1. In fact, this is only possible when x(t)
</p>
<p>is a periodic solution, leading to a degenerate linear system for the coefficients of
</p>
<p>the resonant forcing terms. Hence, the Poincare&ndash;Lindstedt method can only be used
</p>
<p>to obtain periodic solutions, and cannot, for example, generate the slowly decaying
</p>
<p>solution (9.11). To overcome this limitation, we consider another related perturbation
</p>
<p>method.
</p>
<p>9.4 The Method of Multiple Time-Scales
</p>
<p>Like the Poincare&ndash;Lindstedt method, the method of multiple time-scales (MMTS)
</p>
<p>determines solutions to perturbed oscillators by suppressing resonant forcing terms
</p>
<p>that would yield spurious secular terms in the asymptotic expansions. The method of
</p>
<p>multiple time-scales makes a less restrictive assumption on the form of the solution
</p>
<p>than employed by the Poincare&ndash;Lindstedt method; it assumes that the solution can
</p>
<p>be expressed as a function of multiple (for our purposes, just two) time variables,
</p>
<p>x(t) = X (t, τ ), (9.21)
</p>
<p>where t is the regular (or &ldquo;fast&rdquo;) time variable and τ is a new variable describing the
</p>
<p>&ldquo;slow-time&rdquo; dependence of the solution. In a physical context, t could represent a
</p>
<p>circadian rhythm of a daily cycle, while τ might describe changes to this cycle that
</p>
<p>are only noticeable over the timespan of years.</p>
<p/>
</div>
<div class="page"><p/>
<p>192 9 Weakly-Nonlinear Oscillators
</p>
<p>The simplest approach to determining the choice of the slow time variable, is to
</p>
<p>identify the combinations of ε and t present in secular terms in the regular expansion.
</p>
<p>In the examples from Sect. 9.2, τ = εt , so we focus on this case.1
The first step is to perform the change of variables (9.21), where by using the
</p>
<p>chain rule, we arrive at
</p>
<p>dx
</p>
<p>dt
=
</p>
<p>&part;X
</p>
<p>&part;t
+
</p>
<p>&part;X
</p>
<p>&part;τ
</p>
<p>dτ
</p>
<p>dt
=
</p>
<p>&part;X
</p>
<p>&part;t
+ ε
</p>
<p>&part;X
</p>
<p>&part;τ
, (9.22)
</p>
<p>and similarly,
</p>
<p>d2x
</p>
<p>dt2
=
</p>
<p>&part;2X
</p>
<p>&part;t2
+ 2ε
</p>
<p>&part;2X
</p>
<p>&part;t&part;τ
+ ε2
</p>
<p>&part;2X
</p>
<p>&part;τ 2
. (9.23)
</p>
<p>The autonomous weakly-nonlinear oscillator equation
</p>
<p>d2x
</p>
<p>dt2
+ x = ε f
</p>
<p>(
</p>
<p>x, dx
dt
</p>
<p>)
</p>
<p>(9.24)
</p>
<p>then becomes
</p>
<p>&part;2X
</p>
<p>&part;t2
+ 2ε
</p>
<p>&part;2X
</p>
<p>&part;t&part;τ
+ ε2
</p>
<p>&part;2X
</p>
<p>&part;τ 2
+ X = ε f (X, X t + εXτ )
</p>
<p>which can be rearranged into a more useful form as
</p>
<p>&part;2X
</p>
<p>&part;t2
+ X = ε
</p>
<p>(
</p>
<p>f (X, X t + εXτ )&minus; 2X tτ
)
</p>
<p>&minus; ε2Xττ . (9.25)
</p>
<p>We still have a perturbed linear oscillator, but now, we must specify that the oscilla-
</p>
<p>tion is with respect to the fast time variable t , and we note that the right-hand side
</p>
<p>perturbation involves additional terms and derivatives with respect to t and τ . It may
</p>
<p>seem peculiar to replace the simpler ODE (9.24) by a more complicated partial dif-
</p>
<p>ferential equation, but (9.25) can still be solved through application of ODEmethods
</p>
<p>and it provides the degrees of freedom necessary to properly describe the system over
</p>
<p>longer times.
</p>
<p>The next step is to expand theMMTS solution as a regular perturbation expansion,
</p>
<p>X (t, τ ) = X0(t, τ )+ εX1(t, τ )+ O(ε2), (9.26)
</p>
<p>and substitute into (9.25). Analogous to the Poincare&ndash;Lindstedt method, we want to
</p>
<p>suppress any resonant terms that occur in order to determine the currently unspecified
</p>
<p>parts of the solution. The final step is then to reconstruct the relationship between
</p>
<p>fast and slow times, say τ = εt , to obtain the final solution as x(t) &sim; X0(t, εt).
</p>
<p>1Other problems, and additional timescales needed for higher order expansions could involve higher-
</p>
<p>order (slower) timescales such as τk = εk t for k = 2, 3, . . ..</p>
<p/>
</div>
<div class="page"><p/>
<p>9.4 The Method of Multiple Time-Scales 193
</p>
<p>As an example, we consider a damped nonlinear oscillator,
</p>
<p>d2x
</p>
<p>dt2
+ x = &minus;εκ
</p>
<p>dx
</p>
<p>dt
+ εx3, x(0) = 1, x &prime;(0) = &minus;2, (9.27)
</p>
<p>for ε &rarr; 0. Setting τ = εt , and following the method of multiple time-scales
decomposes the problem into the leading order problem
</p>
<p>X0t t + X0 = 0, X0(0, 0) = 1, X0t (0, 0) = &minus;2, (9.28a)
</p>
<p>and at O(ε),
</p>
<p>X0t t + X0 = &minus;κX0t + X30 &minus; 2X0tτ , (9.28b)
</p>
<p>X1(0, 0) = 0, X1t (0, 0) = &minus;X0τ (0, 0).
</p>
<p>With respect to the fast-time variable t , (9.28a) has a solution that is a linear com-
</p>
<p>bination of sin t and cos t . However, unlike (9.3), since other (slow time) variables
</p>
<p>appear, the coefficients in the linear combination are not constants, but are functions
</p>
<p>dependent on the slow-time variable τ ,
</p>
<p>X0(t, τ ) = A(τ ) sin t + B(τ ) cos t. (9.29)
</p>
<p>From the initial conditions on X0 at t = τ = 0, we find that
</p>
<p>A(0) = &minus;2, B(0) = 1, (9.30)
</p>
<p>but otherwise, A(τ ) and B(τ ) are as-yet undetermined functions.
</p>
<p>Moving on to the O(ε) problem (9.28b), after substituting in (9.29), we obtain
</p>
<p>X1t t + X1 =
(
</p>
<p>&minus;κA + 3
4
</p>
<p>A2B + 3
4
</p>
<p>B3 &minus; 2
d A
</p>
<p>dτ
</p>
<p>)
</p>
<p>cos t
</p>
<p>+
(
</p>
<p>κB + 3
4
</p>
<p>A3 + 3
4
</p>
<p>AB2 + 2
d B
</p>
<p>dτ
</p>
<p>)
</p>
<p>sin t
</p>
<p>+
(
1
4
</p>
<p>B3 &minus; 3
4
</p>
<p>A2B
)
</p>
<p>cos(3t)&minus;
(
1
4
</p>
<p>A3 &minus; 3
4
</p>
<p>AB2
)
</p>
<p>sin(3t). (9.31)
</p>
<p>Note that many of the terms on the right-hand side of (9.31) are a consequence of
</p>
<p>the nonlinear term X30 . The forcing terms must be expanded out as the sum of sines
</p>
<p>and cosines of the fast time scale with coefficients that can only depend on the slow
</p>
<p>time scale. For simple nonlinear products, like X30 , this can done be through the
</p>
<p>use of trigonometric identities (see Appendix A). For more complicated types of
</p>
<p>nonlinear forcing terms, the right side of (9.25) should be replaced by its Fourier
</p>
<p>series expansion (also see Appendix A). These Fourier series decompositions are
</p>
<p>essential in separating out the resonant and non-resonant forcing terms. For (9.31),
</p>
<p>cos t and sin t are resonant terms, while cos(3t), sin(3t) are non-resonant.</p>
<p/>
</div>
<div class="page"><p/>
<p>194 9 Weakly-Nonlinear Oscillators
</p>
<p>Fig. 9.4 Comparison of the
</p>
<p>regular expansion and the
</p>
<p>method of multiple
</p>
<p>time-scales leading order
</p>
<p>solution against the exact
</p>
<p>solution of (9.27)
</p>
<p>To eliminate the resonant terms that would cause expansion (9.26) to break-down,
</p>
<p>we set the respective coefficients to zero,
</p>
<p>&minus; κA+ 3
4
</p>
<p>A2B + 3
4
</p>
<p>B3&minus; 2
d A
</p>
<p>dτ
= 0, κB + 3
</p>
<p>4
A3+ 3
</p>
<p>4
AB2+ 2
</p>
<p>d B
</p>
<p>dτ
= 0. (9.32)
</p>
<p>These two equations are the solvability conditions for this problem. They are coupled
</p>
<p>ordinary differential equations in terms of the slow-time variable that describe the
</p>
<p>evolution of the amplitude coefficients A(τ ), B(τ ) in solution (9.29); consequently,
</p>
<p>they are also often called amplitude equations.
</p>
<p>Solving the amplitude equations to determine A(τ ), B(τ ) subject to their initial
</p>
<p>conditions (9.30) yields the MMTS leading order approximation of the solution
</p>
<p>(9.29), as illustrated in Fig. 9.4.
</p>
<p>9.5 Further Directions
</p>
<p>Perturbation methods for weakly nonlinear oscillators have been developed exten-
</p>
<p>sively in connection with many applications ranging from mechanical oscillations
</p>
<p>and electrical systems to population dynamics. Somemore detailed introductory pre-
</p>
<p>sentations are given in [48, 54, 56, 78], and some advanced treatments are given in
</p>
<p>[11, 47, 58, 73, 77]. Besides Poincare&ndash;Lindstedt and the method of multiple time-
</p>
<p>scales, other related approaches also exist, including the method of averaging [77,
</p>
<p>92, 102] and near-identity transformations [58, 73]. The engineering approach of
</p>
<p>harmonic balance is related to these methods.
</p>
<p>The mathematical theory underpinning the solvability conditions coming from
</p>
<p>the Poincare&ndash;Lindstedt and method of multiple time-scales approaches is the Fred-
</p>
<p>holm alternative theorem [39, 93]. The Fredholm alternative supplies a criterion
</p>
<p>for the existence or uniqueness of solutions of inhomogeneous linear problems that
</p>
<p>applies to these oscillator equations and other classes of perturbation problems (see
</p>
<p>Exercise 9.13).</p>
<p/>
</div>
<div class="page"><p/>
<p>9.6 Exercises 195
</p>
<p>9.6 Exercises
</p>
<p>9.1 Consider the problem for x(t) with ε &rarr; 0,
</p>
<p>d2x
</p>
<p>dt2
+ x = 32εx3, x(0) = e&minus;ε, x &prime;(0) = 2+ ε.
</p>
<p>Obtain the first two terms of the regular expansion, x(t) = x0(t)+ εx1(t)+ O(ε2).
Identify the homogeneous solution, resonant response and non-resonant response in
</p>
<p>x1(t).
</p>
<p>9.2 For each problem use the Poincare&ndash;Lindstedt expansion with the two-term
</p>
<p>approximation of the solution, x(t) &sim; x̃0(θ) + εx̃1(θ) with θ = (ω0 + εω1)t ,
for ε &rarr; 0 to find x̃0(θ) and ω0, ω1.
</p>
<p>(a) Are there periodic solutions for every value of a &gt; 0 for
</p>
<p>d2x
</p>
<p>dt2
+ 4x = &minus;εx3, x(0) = a, x &prime;(0) = 0?
</p>
<p>(b) Find the value for a(&gt;0) that yields a periodic solution of
</p>
<p>d2x
</p>
<p>dt2
+ 9x = &minus;ε(x2 &minus; 1)
</p>
<p>dx
</p>
<p>dt
, x(0) = a, x &prime;(0) = 0.
</p>
<p>9.3 Apply the method of multiple scales with τ = εt to the van der Pol oscillator
</p>
<p>d2x
</p>
<p>dt2
+ 9x = &minus;ε(x2 &minus; 1)
</p>
<p>dx
</p>
<p>dt
ε &rarr; 0 (9.33)
</p>
<p>to obtain a solution in the form x(t) &sim; X0(t, τ ) = A(τ ) sin(3t)+ B(τ ) cos(3t).
</p>
<p>(a) Determine the amplitude equations for A(τ ), B(τ ). Determine initial conditions
</p>
<p>for A, B in terms of x(0), x &prime;(0).
(b) Let R(τ ) =
</p>
<p>&radic;
A2 + B2. Determine the equation for d R/dτ = f (R) using the
</p>
<p>amplitude equations from part (a). Determine the equilibrium values for R.
</p>
<p>9.4 Show that the leading order MMTS solution for weakly nonlinear oscillators
</p>
<p>can be written in the polar form
</p>
<p>X0(t, τ ) = R(τ ) sin(ω0t +Φ(τ)). (9.34)
</p>
<p>(a) Relate the amplitude R and phaseΦ to the coefficients A, B introduced in (9.29).</p>
<p/>
</div>
<div class="page"><p/>
<p>196 9 Weakly-Nonlinear Oscillators
</p>
<p>(b) Show that (9.32) can be rewritten as
</p>
<p>d R
</p>
<p>dτ
= &minus; 1
</p>
<p>2
κR,
</p>
<p>dΦ
</p>
<p>dτ
= &minus; 3
</p>
<p>8
R2
</p>
<p>and solve this simpler polar system with appropriate initial conditions.
</p>
<p>9.5 Use the method of multiple scales to investigate the near-resonant behaviour of
</p>
<p>the damped, driven oscillator for x(t) for ε &rarr; 0,
</p>
<p>d2x
</p>
<p>dt2
+ εβ
</p>
<p>dx
</p>
<p>dt
+ x + εαx3 = ε cos(t + γ εt),
</p>
<p>with given parameters α, β, γ . Use the slow-timescale τ = εt . Note the presence of
τ in the forcing term on the right-hand side. (Hint: write the forcing as cos(t + γ τ))
(a) Show that the leading order solution can be written in the complex form
</p>
<p>X0(t, τ ) = C(τ )ei t + C(τ )e&minus;i t ,
</p>
<p>where z = x &minus; iy denotes the complex conjugate of z = x + iy. Relate the
complex-valued function C to the real-valued functions A, B used in (9.29).
</p>
<p>(b) Using the result of part (a) in the equation for X1(t, τ ), find the two solvability
</p>
<p>conditions. Show that these reduce to a single complex equation for dC/dτ .
</p>
<p>(c) Entrainment describes a solution locking onto the behaviour entirely set by a
</p>
<p>forcing term, leaving no direct sign of the natural frequency from the unforced
</p>
<p>problem (i.e. no homogeneous solution). Setting C(τ ) = Meiθeiγ τ in your
equation from (b), obtain an equation for M , the real-valued constant amplitude
</p>
<p>of the entrained solution, with θ being a (real-valued) phase constant. Determine
</p>
<p>the detuning relation, γ = γ (M), relating the amplitude to the frequency-offset
from resonance.
</p>
<p>9.6 Apply the method of multiple scales with τ = εt and ε &rarr; 0 to the problem
</p>
<p>d2x
</p>
<p>dt2
+ ε
</p>
<p>∣
∣
∣
∣
</p>
<p>dx
</p>
<p>dt
</p>
<p>∣
∣
∣
∣
</p>
<p>dx
</p>
<p>dt
+ x = 0, x(0) = 0, x &prime;(0) = 1.
</p>
<p>Using the polar form (9.34), derive and solve the amplitude equations for R(τ ) and
</p>
<p>Φ(τ) to obtain the leading order solution x(t) &sim; X0(t, τ ).
Hint: You will need to calculate some terms of a Fourier series. Write the series in
</p>
<p>terms of the variable s = t +Φ on &minus;π &lt; s &lt; π , namely f (s) =
&sum;
</p>
<p>k ak sin(ks)+
bk cos(ks).
</p>
<p>9.7 In Exercise 3.6, the equation for the parametrically-driven pendulum was
</p>
<p>derived; for a specific choice of parameters, it can be written as
</p>
<p>d2θ
</p>
<p>dt2
+ 4 sin θ = &minus;ε sin(4t) sin θ.</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3">http://dx.doi.org/10.1007/978-3-319-23042-9_3</a></div>
</div>
<div class="page"><p/>
<p>9.6 Exercises 197
</p>
<p>Using the scaling for small-amplitude oscillations, θ = δx for δ &rarr; 0, at leading
order this equation yields a form of the Mathieu equation,
</p>
<p>d2x
</p>
<p>dt2
+
</p>
<p>[
</p>
<p>4+ ε sin(4t)
]
</p>
<p>x = 0. (9.35)
</p>
<p>Consider solutions of the Mathieu equation for ε &rarr; 0:
</p>
<p>(a) Use the method of multiple scales with τ = εt to determine the amplitude
equations for the slowly varying coefficients in the leading order solution.
</p>
<p>(b) Solve for the leading order solution that satisfies the initial conditions
</p>
<p>x(0) = 5, x &prime;(0) = 6.
</p>
<p>9.8 Consider the equation for the complex-valued solution x(t) with ε &rarr; 0,
</p>
<p>dx
</p>
<p>dt
+ i4x = ε cos(4t)x2
</p>
<p>Apply the method of multiple time scales with τ = εt and x(t) &sim; X0(t, τ ) +
εX1(t, τ ).
</p>
<p>(a) Write the equations for X0 and X1.
</p>
<p>(b) Write the general solution of the O(1) equation.
</p>
<p>(c) Determine the amplitude equation and explain the condition that selects this
</p>
<p>result.
</p>
<p>(d) Determine the leading order solution for x(t) that satisfies the initial condition
</p>
<p>x(0) = 1+ i.
</p>
<p>9.9 For the problem with ε &rarr; 0,
</p>
<p>d2x
</p>
<p>dt2
+ x = εx2, x(0) = 1, x &prime;(0) = 0,
</p>
<p>the slow timescale for MMTS is not the usual one, τ �= εt . Attempt a regular
expansion x &sim; x0 + εx1 + ε2x2 to determine the slow time variable. Determine the
leading order solution using the Poincare&ndash;Lindstedt method.
</p>
<p>9.10 For ε &rarr; 0, show that there is a large-amplitude periodic solution of
</p>
<p>d2x
</p>
<p>dt2
+ x = εx2 + ε cos t x &prime;(0) = 0.
</p>
<p>To do this, let x(t) &sim; ε&minus;β X (t, τ ) with τ = εαt and X &sim; X0 + εγ X1 + ε2γ X2 and
select α, β, γ &gt; 0 to ensure that X0, X1, X2 have no secular growth terms.</p>
<p/>
</div>
<div class="page"><p/>
<p>198 9 Weakly-Nonlinear Oscillators
</p>
<p>9.11 Delay differential equations (DDE) are equations that involve current proper-
</p>
<p>ties of the solution coupled to the solution at earlier times [35]. Consider the DDE
</p>
<p>d2x
</p>
<p>dt2
+ x + εx(t &minus; 2) = 0.
</p>
<p>(a) This is a linear constant coefficient equation and can be solved in terms of trial
</p>
<p>solutions of the form x(t) = eλt . Write the characteristic equation determining
λ and obtain the solutions to O(ε) for ε &rarr; 0. Are the solutions of this equation
stable or unstable? (see Sect. 1.5)
</p>
<p>(b) Apply the method of multiple scales to obtain the amplitude equations.
</p>
<p>(c) Similarly analyse the weakly-delayed linear oscillator equation,
</p>
<p>d2x
</p>
<p>dt2
+ x(t &minus; ε) = 0.
</p>
<p>9.12 Now we complete the derivation of the KdV equation that was started in
</p>
<p>Exercise 8.5. There, we obtained the equations for C(x, t) = C0 + ε2C1 + &middot; &middot; &middot; and
F(x, t) = F0 + ε2F1 + &middot; &middot; &middot; , as
O(1) equations:
</p>
<p>&part;C0
</p>
<p>&part;t
+ F0 = 0,
</p>
<p>&part;F0
</p>
<p>&part;t
+
</p>
<p>&part;2C0
</p>
<p>&part;x2
= 0 (9.36)
</p>
<p>O(ε2) equations:
</p>
<p>&part;C1
</p>
<p>&part;t
+ F1 = 12
</p>
<p>&part;3C0
</p>
<p>&part;t&part;x2
&minus; 1
</p>
<p>2
</p>
<p>(
&part;C0
</p>
<p>&part;x
</p>
<p>)2
</p>
<p>, (9.37a)
</p>
<p>&part;F1
</p>
<p>&part;t
+
</p>
<p>&part;2C1
</p>
<p>&part;x2
= 1
</p>
<p>6
</p>
<p>&part;4C0
</p>
<p>&part;x4
&minus; F0
</p>
<p>&part;2C0
</p>
<p>&part;x2
&minus;
</p>
<p>&part;F0
</p>
<p>&part;x
</p>
<p>&part;C0
</p>
<p>&part;x
. (9.37b)
</p>
<p>(a) Show from the O(1) equations that C0 and F0 each satisfy the classic wave
</p>
<p>equation (2.52) with unit speed and having independent left/right movingwaves.
</p>
<p>(b) Wewill now restrict attention just to right-movingwaves. It can be shown that the
</p>
<p>O(ε2) equations would lead to solutions with secular growth, hence consider
</p>
<p>a multiple-time scale expansion of the form C = c0(z, τ ) + ε2c1(z, τ ) and
F = f0(z, τ ) + ε2 f1(z, τ ) where z = x &minus; t and τ = ε2t . Show that the O(1)
equations reduce to a single relation between c0, f0 and that the O(ε
</p>
<p>2) equations
</p>
<p>reduce to a single compatibility condition given by a partial differential equation
</p>
<p>for f0(z, τ ), the KdV equation,
</p>
<p>&part; f0
</p>
<p>&part;τ
+ 3
</p>
<p>2
f0
&part; f0
</p>
<p>&part;z
+ 1
</p>
<p>6
</p>
<p>&part;3 f0
</p>
<p>&part;z3
= 0. (9.38)</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1">http://dx.doi.org/10.1007/978-3-319-23042-9_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_8">http://dx.doi.org/10.1007/978-3-319-23042-9_8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2">http://dx.doi.org/10.1007/978-3-319-23042-9_2</a></div>
</div>
<div class="page"><p/>
<p>9.6 Exercises 199
</p>
<p>9.13 The Fredholm alternative theorem is the key principle that determines the
</p>
<p>solvability conditions in the Poincare&ndash;Lindstedt and MMTS methods, but here we
</p>
<p>illustrate how it also applied to determining the eigenvalues of perturbed matrices
</p>
<p>[47].
</p>
<p>Consider the matrix
</p>
<p>A(ε) =
(
</p>
<p>&minus;eε 3&minus; 3ε
3+ ε &minus;1+ 2 sin ε
</p>
<p>)
</p>
<p>.
</p>
<p>For the limit ε &rarr; 0, use the following steps to solve the eigenvalue problem,
</p>
<p>Ax = λx.
</p>
<p>(a) Write the asymptotic expansion for the matrix in powers of ε, A &sim; A0 + εA1 +
ε2A2 and similar expansions for each eigenvector and corresponding eigenvalue
</p>
<p>x &sim; x0 + εx1 + ε2x2, and λ &sim; λ0 + ελ1 + ε2λ2.
(b) The leading order problem, A0x0 = λ0x0, can be written in the form of a
</p>
<p>homogeneous problem,
</p>
<p>(A0 &minus; λ0I)x0 = 0
</p>
<p>Obtain the eigensolutions for this matrix, {λ(k)0 , x
(k)
0 }.
</p>
<p>(c) For this problem, every vector v can be written as a linear combination of the
</p>
<p>leading order eigenvectors, v = c(1)x(1)0 + c(2)x
(2)
0 . Write the formulas for c(k)
</p>
<p>for k = 1, 2 in terms of v and x(k)0 .
(d) Write the O(ε) equation in the form of an inhomogeneous problem with the
</p>
<p>same matrix operator as the O(1) equation,
</p>
<p>(A0 &minus; λ0I)x1 = f1(x0,A1, λ1).
</p>
<p>Note the similarities between these equations for x0, x1 and the oscillator prob-
</p>
<p>lems, (9.17a) and (9.17b) or (9.28a) and (9.28b). The Fredholm alternative essen-
</p>
<p>tially states that
</p>
<p>The solution of the O(εn) inhomogeneous problem will exist and be unique if the forcing
</p>
<p>term has no contribution from the solution of the O(ε0) homogeneous problem.2
</p>
<p>For oscillator problems, this addresses the existence of periodic solutions in the
</p>
<p>absence of resonant forcing terms.
</p>
<p>2This is the simplified version for symmetric matrices and self-adjoint differential equations. The
</p>
<p>general version of the Fredholm alternative is similar:
</p>
<p>The solution of the non-homogeneous problem A0x = b will be unique if and only if the
adjoint problem A
</p>
<p>&dagger;
0y = 0 has only the trivial solution [39, 93].</p>
<p/>
</div>
<div class="page"><p/>
<p>200 9 Weakly-Nonlinear Oscillators
</p>
<p>For matrix equations, non-existence or non-uniqueness will result if the forcing
</p>
<p>term includes contributions from the x
(k)
0 nullvector corresponding to the λ
</p>
<p>(k) in
</p>
<p>the matrix operator. Select the values of λ1 to eliminate those contributions and
</p>
<p>obtain the first two terms in the expansions of the eigenvalues,λ(k) &sim; λ(k)0 +ελ
(k)
1
</p>
<p>for k = 1, 2.</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 10
</p>
<p>Fast/slow Dynamical Systems
</p>
<p>In previous chapters we employed perturbation methods to study problems in differ-
</p>
<p>ential equations where the solution of the leading order problem could be obtained
</p>
<p>in a simple explicit form. For problems where the leading order solution cannot be
</p>
<p>obtained in a simple form, a different approach is needed. Here we show that ideas
</p>
<p>from phase plane analysis (Chap. 1) can be used to circumvent these difficulties
</p>
<p>and allow us to apply boundary layer methods (Chap. 7) to separate problems into
</p>
<p>dynamics occurring at different scales.
</p>
<p>The fundamental principles for formulating rate equations given in Chap. 1 are
</p>
<p>universally applicable for constructing models. But when the number of equations
</p>
<p>in the resulting system is large or the leading order problem for ε = 0 is nonlinear,
</p>
<p>then some of the direct approaches that we have seen in previous chapters become
</p>
<p>cumbersome and may not be useful.
</p>
<p>Similarly, Chap. 9 introduced approaches based on perturbation methods to esti-
</p>
<p>mate the behaviour of some models yielding oscillatory behaviours. But those meth-
</p>
<p>ods were limited to weakly nonlinear problems, where the leading order solution
</p>
<p>satisfied a linear oscillator equation and could be calculated explicitly in terms of
</p>
<p>sines and cosines. For some more general nonlinear problems, we will show that
</p>
<p>properties of the system can be determined without the need for a closed-form solu-
</p>
<p>tion.
</p>
<p>The common structure for problems that we will investigate in this chapter is that
</p>
<p>of singularly-perturbed dynamical systems. In Chap. 7, we&rsquo;ve learned that singularly
</p>
<p>perturbed differential equations exhibit separation of spatial scales, having rapid
</p>
<p>variations in boundary layers in contrast to slowly-varying outer solutions. Likewise
</p>
<p>in Chap. 9, a separation of time-scales occurred between the oscillations on the fast
</p>
<p>time scale and evolution of the amplitude functions on slow scales. Extending this
</p>
<p>approach to more general dynamical systems, we seek to decompose each problem
</p>
<p>into two sub-systems:
</p>
<p>&bull; The slow system: the problem in terms of the original (&ldquo;slow-time&rdquo;) variable,
</p>
<p>whose solution will be treated analogously to the outer solution in a boundary
</p>
<p>layer problem.
</p>
<p>&copy; Springer International Publishing Switzerland 2015
</p>
<p>T. Witelski and M. Bowen, Methods of Mathematical Modelling,
</p>
<p>Springer Undergraduate Mathematics Series, DOI 10.1007/978-3-319-23042-9_10
</p>
<p>201</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1">http://dx.doi.org/10.1007/978-3-319-23042-9_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7">http://dx.doi.org/10.1007/978-3-319-23042-9_7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1">http://dx.doi.org/10.1007/978-3-319-23042-9_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9">http://dx.doi.org/10.1007/978-3-319-23042-9_9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7">http://dx.doi.org/10.1007/978-3-319-23042-9_7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9">http://dx.doi.org/10.1007/978-3-319-23042-9_9</a></div>
</div>
<div class="page"><p/>
<p>202 10 Fast/slow Dynamical Systems
</p>
<p>&bull; The fast system: a rescaling of the system describing rapid evolution occurring
</p>
<p>over shorter times, analogous to the inner solution of a boundary layer problem.
</p>
<p>The solution of each sub-system will be sought in the form of a regular perturbation
</p>
<p>expansion. For singularly-perturbed problems, the sub-systems will have simpler
</p>
<p>structures than the full problem and allow for the slow- and fast-dynamics to poten-
</p>
<p>tially be characterised in terms of reduced phase line or phase plane dynamics.
</p>
<p>We will study two problems that could be considered directly in terms of a standard
</p>
<p>phase plane analysis, but through the use of perturbation theory (that is also applicable
</p>
<p>to higher order systems), we will show that the underlying dynamics can be separated
</p>
<p>into more convenient forms.
</p>
<p>10.1 Strongly-Nonlinear Oscillators: The van der Pol
</p>
<p>Equation
</p>
<p>For oscillatory systems where the leading problem for ε &rarr; 0 does not yield the
</p>
<p>harmonic oscillator equation, x&prime;&prime;0 (t)+ x0(t) = 0, the approaches from Chap. 9 cannot
</p>
<p>be applied in a straightforward manner. As an example of a &ldquo;strongly nonlinear&rdquo;
</p>
<p>oscillator, we will show how to construct solutions of the van der Pol oscillator,
</p>
<p>ε
d2x
</p>
<p>dt2
+ (x2 &minus; 1)
</p>
<p>dx
</p>
<p>dt
+ x = 0 for ε &rarr; 0. (10.1)
</p>
<p>This equation is similar to the weakly-nonlinear damped oscillator (9.33), but here
</p>
<p>the first-order damping term is part of the leading order equation while the second
</p>
<p>derivative term is a singular perturbation.1 Since the perturbation parameter here mul-
</p>
<p>tiplies the highest order derivative, this type of problem could be called a &ldquo;singularly
</p>
<p>perturbed oscillator&rdquo; but the more common name is a relaxation oscillator.
</p>
<p>We begin by re-writing (10.1) in terms of a convenient formulation for a phase
</p>
<p>plane analysis but will use a different choice of intermediate variable y(t) than the
</p>
<p>standard velocity (1.37). Notice that the first two terms in (10.1) can be written as a
</p>
<p>total derivative,
d
</p>
<p>dt
</p>
<p>(
</p>
<p>ε
dx
</p>
<p>dt
+ 1
</p>
<p>3
x3 &minus; x
</p>
<p>)
</p>
<p>+ x = 0.
</p>
<p>Defining the expression in parentheses as y = εx&prime;+ 1
3
</p>
<p>x3&minus;x, we obtain an autonomous
</p>
<p>system for (x(t), y(t)),
</p>
<p>ε
dx
</p>
<p>dt
= y + x &minus; 1
</p>
<p>3
x3,
</p>
<p>dy
</p>
<p>dt
= &minus;x, (10.2)
</p>
<p>1Attempting to put this equation in the form (9.2) fails because dividing by ε suggests a very fast
</p>
<p>oscillation, ω0 = ε
&minus;1/2 &rarr; &infin;, and a large (O(ε&minus;1) &rarr; &infin;) rather than small perturbation term.</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9">http://dx.doi.org/10.1007/978-3-319-23042-9_9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9">http://dx.doi.org/10.1007/978-3-319-23042-9_9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1">http://dx.doi.org/10.1007/978-3-319-23042-9_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9">http://dx.doi.org/10.1007/978-3-319-23042-9_9</a></div>
</div>
<div class="page"><p/>
<p>10.1 Strongly-Nonlinear Oscillators: The van der Pol Equation 203
</p>
<p>which is called the Li&eacute;nard transformation of the van der Pol equation. The
</p>
<p>singularly-perturbed nature of this system is clear: for ε = 0, the ODE for x(t)
</p>
<p>reduces to an algebraic relation.
</p>
<p>We begin by determining the outer (&ldquo;slow&rdquo;) solution using regular perturbation
</p>
<p>expansions for both x, y:
</p>
<p>x(t) = x0(t)+ εx1(t)+ O(ε
2), y(t) = y0(t)+ εy1(t)+ O(ε
</p>
<p>2).
</p>
<p>Collecting the O(1) terms in the expansions of (10.2), we obtain the leading order
</p>
<p>slow system,
</p>
<p>0 = y0 + x0 &minus;
1
3
</p>
<p>x30,
dy0
</p>
<p>dt
= &minus;x0. (10.3)
</p>
<p>The differential equation for y0(t) allows us to qualitatively describe the dynamics
</p>
<p>of the solution in terms of vertical motion in the phase plane as
</p>
<p>y0(t) is
</p>
<p>{
</p>
<p>decreasing for x0 &gt; 0,
</p>
<p>increasing for x0 &lt; 0;
(10.4a)
</p>
<p>hence the y0-axis is the y-nullcline curve (see Sect. 1.5.1) for both the full problem
</p>
<p>and the slow system. The remaining equation in (10.3) restricts the slow-time solution
</p>
<p>to evolve only on the curve
</p>
<p>y0(x0) =
1
3
x30 &minus; x0 &equiv; S(x0), (10.4b)
</p>
<p>which is called the slow manifold (or &ldquo;slow solution curve&rdquo;) and is shown in Fig. 10.1.
</p>
<p>Restricting the solution to stay on the slow manifold while following the evolution
</p>
<p>described by (10.4a) suggests that starting from any x0 &lt; 0 will drive the solution
</p>
<p>upward to approach the local maximum of the curve at y0(&minus;1) = 2/3, while the
</p>
<p>dynamics in the right half plane, with x0 &gt; 0 will force solutions to evolve toward
</p>
<p>the local minimum at y0(1) = &minus;2/3. At those critical points (extrema), the vertical
</p>
<p>motion still follows (10.4a) even though there is no obvious place to go on the slow
</p>
<p>Fig. 10.1 Arrows indicating
</p>
<p>dynamics of the leading
</p>
<p>order solution on the slow
</p>
<p>manifold (10.4b) and at the
</p>
<p>two critical points of the
</p>
<p>curve</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1">http://dx.doi.org/10.1007/978-3-319-23042-9_1</a></div>
</div>
<div class="page"><p/>
<p>204 10 Fast/slow Dynamical Systems
</p>
<p>manifold. The solution therefore gets pushed off the slow manifold2; everything off
</p>
<p>the slow manifold in the phase plane is part of the fast problem, to which we now
</p>
<p>turn our attention.
</p>
<p>Following the analysis in Chaps. 6 and 7, in order to find singular solutions, we
</p>
<p>rescale the original system in terms of new variables. To determine the fast variables,
</p>
<p>we substitute the general scalings
</p>
<p>T =
t &minus; t&lowast;
</p>
<p>εα
, x = εβX(T), y = εγ Y(T), (10.5)
</p>
<p>into (10.2) where the scaling exponentsα,β, γ and the time t&lowast; when the fast dynamics
</p>
<p>occur are to be determined. For this problem, it can be shown that x, y are always
</p>
<p>O(1), so we take β = γ = 0 and determine the value for α(&ge;0) from dominant
</p>
<p>balance in
</p>
<p>ε1&minus;α
dX
</p>
<p>dT
= Y + X &minus; 1
</p>
<p>3
X3, ε&minus;α
</p>
<p>dY
</p>
<p>dT
= &minus;X.
</p>
<p>In applying the method of dominant balance to systems of equations, distinguished
</p>
<p>limits will typically yield a balance in one equation at a time, while the other equa-
</p>
<p>tions yield sub-dominant contributions, where the rate of change will be o(1). The
</p>
<p>distinguished limit α = 0 balances the terms in the second equation and reproduces
</p>
<p>the original slow system we have already considered, (10.2). The choice α = 1
</p>
<p>balances all of the terms in the first equation,
</p>
<p>dX
</p>
<p>dT
= Y + X &minus; 1
</p>
<p>3
X3,
</p>
<p>dY
</p>
<p>dT
= &minus;εX, (10.6)
</p>
<p>where we have multiplied the second equation by εα .
</p>
<p>Seeking the fast solutions as regular expansions,
</p>
<p>X(T) = X0(T)+ εX1(T)+ O(ε
2), Y(T) = Y0(T)+ εY1(T)+ O(ε
</p>
<p>2),
</p>
<p>yields the leading order fast system,
</p>
<p>dX0
</p>
<p>dT
= Y0 + X0 &minus;
</p>
<p>1
3
</p>
<p>X30 ,
dY0
</p>
<p>dT
= 0. (10.7)
</p>
<p>The second equation shows that the dynamics in the fast system (everywhere in
</p>
<p>the phase plane away from the slow manifold) must have Y0(T) &equiv; constant, i.e.
</p>
<p>only horizontal motion is admissible. With this in mind, the first equation can be
</p>
<p>interpreted as describing motion on a phase-line for X0(T),
</p>
<p>dX0
</p>
<p>dT
= Y0 &minus; S(X0), (10.8)
</p>
<p>2At which point, the solution is no longer described by the dynamics of the slow system.</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6">http://dx.doi.org/10.1007/978-3-319-23042-9_6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7">http://dx.doi.org/10.1007/978-3-319-23042-9_7</a></div>
</div>
<div class="page"><p/>
<p>10.1 Strongly-Nonlinear Oscillators: The van der Pol Equation 205
</p>
<p>where the value of Y0 selects a &ldquo;slice&rdquo; through the slow-manifold analogous to
</p>
<p>(1.29) from Chap. 1. The equilibrium points of (10.8) are given by the solutions of
</p>
<p>S(X0) = Y0 with their stability being determined by the sign of &minus;S
&prime;(X0), while all
</p>
<p>other values for X0 give monotonic increasing or decreasing solutions.
</p>
<p>In summary, for the slow system, we have identified the slow manifold and
</p>
<p>described how the dynamics on the slow manifold approach the critical points. Tak-
</p>
<p>ing those as departure points into the fast system, the subsequent motion is given by
</p>
<p>the rapid evolution of x on horizontal lines that terminate at points of intersection
</p>
<p>with the slow curve. This qualitative description allows us to sketch the form of tra-
</p>
<p>jectories starting from any point in the (x, y) phase plane and identify the four-stage
</p>
<p>structure (and global stability) of the stable finite-amplitude limit cycle solution, see
</p>
<p>Figs. 10.2 and 10.3. The general features of the limit cycle (maximum, minimum val-
</p>
<p>ues and period) can be obtained from these results (see Exercise 10.1). The fast-time
</p>
<p>dynamics can be asymptotically matched to outer solutions (slow solutions), and so
</p>
<p>the fast-dynamics act as &ldquo;interior&rdquo; boundary layers (in the terminology of Chap. 7).
</p>
<p>Fig. 10.2 Starting from general initial conditions not on the slow manifold, there will first be a
</p>
<p>rapid horizontal transition or &ldquo;jump&rdquo; 1 to a stable branch of the slow manifold followed by slow
</p>
<p>evolution down that branch 2 to the equilibrium point. Dropping off the minimum yields another
</p>
<p>fast jump 3 across to the other stable branch of the slow manifold, where slow dynamics drive the
</p>
<p>solution upwards 4 to the maximum and on to another fast jump back across to the previous stable
</p>
<p>branch of the slow manifold. The resulting (periodic) dynamics correspond to an attracting limit
</p>
<p>cycle
</p>
<p>Fig. 10.3 Sketch of the
</p>
<p>time-profile illustrating the
</p>
<p>four stages in the van der Pol
</p>
<p>limit cycle</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1">http://dx.doi.org/10.1007/978-3-319-23042-9_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7">http://dx.doi.org/10.1007/978-3-319-23042-9_7</a></div>
</div>
<div class="page"><p/>
<p>206 10 Fast/slow Dynamical Systems
</p>
<p>10.2 Complex Chemical Reactions: The Michaelis-Menten
</p>
<p>Model
</p>
<p>The reactions described in Sect. 1.2 can be said to be &ldquo;what you see is what you
</p>
<p>get&rdquo; elementary reactions if the rate equations obtained from direct applications of
</p>
<p>the the law of mass action predicts the rates as would be observed in experimental
</p>
<p>studies of the systems. However, for general reactions, collisions of three or more
</p>
<p>molecules almost never happen exactly simultaneously (only single-molecule decay
</p>
<p>or binary collisions typically occur as elementary steps). The term non-elementary
</p>
<p>reactions describes the overall relation between reactants and products, but with the
</p>
<p>molecular collisions and mass action kinetics involved actually occurring in many
</p>
<p>&ldquo;hidden&rdquo; intermediate sub-stages. For example, a non-elementary version of (1.14a)
</p>
<p>could be
</p>
<p>n A + m B &rarr; (???) &rarr; (???) &rarr; (???) &rarr; p C + q D.
</p>
<p>The temporary products from intermediate reactions are called complexes and are
</p>
<p>often unstable compounds that exist only briefly.
</p>
<p>To obtain the overall rate of creation of products, we need to analyse the full system
</p>
<p>with all intermediate stages expanded out as elementary reactions. Part of the very
</p>
<p>difficult work of chemists and bio-chemists is to determine all of the intermediate
</p>
<p>reactions. If all of the intermediate reactions are known, then we may have a very
</p>
<p>complicated system of rate ODEs. Our goal is to try to condense the system down to
</p>
<p>just the overall reaction
</p>
<p>reactants � products
</p>
<p>and to determine the effective rate equation for the products. The theory of dynamical
</p>
<p>systems can be applied to accomplish this for many chemical reaction systems.
</p>
<p>Given a complete system of reactions and initial conditions, we illustrate through an
</p>
<p>example how to obtain a simple model for the rate equations of the products.
</p>
<p>A simple version of an enzyme-mediated chemical reaction process is given by
</p>
<p>the system,
</p>
<p>S + E
k1
&minus;⇀↽&minus;
k2
</p>
<p>C
k3
&minus;&rarr; P + E, (10.9)
</p>
<p>where S is the &ldquo;substrate&rdquo; reactant and P is the concentration of the desired product.
</p>
<p>An enzyme (or catalyst) is a compound whose special property is that it allows for
</p>
<p>intermediate reaction steps that lead to the overall reaction, in this case
</p>
<p>S &rarr; P, (10.10)
</p>
<p>or allow it proceed more rapidly than without the enzyme; in some cases this direct
</p>
<p>transformation might not be possible at all without the enzyme.
</p>
<p>Let E be the concentration of the enzyme, and C is the intermediate &ldquo;complex&rdquo; of
</p>
<p>SE bound together. The enzyme is typically a complicated and expensive compound,</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1">http://dx.doi.org/10.1007/978-3-319-23042-9_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1">http://dx.doi.org/10.1007/978-3-319-23042-9_1</a></div>
</div>
<div class="page"><p/>
<p>10.2 Complex Chemical Reactions: The Michaelis-Menten Model 207
</p>
<p>but notably it is not actually consumed by (10.9). Consequently, the enzyme may be
</p>
<p>given in a small initial concentration E0. The complex C is an unstable temporary
</p>
<p>state and none would be present before the reaction starts. We will assume that the
</p>
<p>production process begins with no product, and a large initial supply of reactant, S0,
</p>
<p>all to be converted into P. Assuming the reaction rate constants k1, k2, k3 are known
</p>
<p>finite values, our goal is to determine the rate of production for P and how it can be
</p>
<p>represented in simplest form.
</p>
<p>Beginning by expanding (10.9) into its full set of elementary reactions,
</p>
<p>S + E
k1
&minus;&rarr; C S + E
</p>
<p>k2
&larr;&minus; C C
</p>
<p>k3
&minus;&rarr; P + E, (10.11)
</p>
<p>the law of mass action yields the rate equations for consumption/production of each
</p>
<p>chemical species in the dimensional form
</p>
<p>dP
</p>
<p>dT
= k3C,
</p>
<p>dC
</p>
<p>dT
= k1SE &minus; k2C &minus; k3C, (10.12a)
</p>
<p>dS
</p>
<p>dT
= &minus;k1SE + k2C,
</p>
<p>dE
</p>
<p>dT
= &minus;k1SE + k2C + k3C,
</p>
<p>subject to initial conditions at t = 0,
</p>
<p>S(0) = S0, E(0) = E0, C(0) = 0, P(0) = 0. (10.12b)
</p>
<p>We now nondimensionalize system (10.12a, 10.12b). Given the one-to-one corre-
</p>
<p>spondence between S and P and between E and C as reactants/products in (10.11),
</p>
<p>we scale these pairs by the respective initial concentrations
</p>
<p>S(T) = S0s(t), P(T) = S0p(t), (10.13)
</p>
<p>E(T) = E0e(t), C(T) = E0c(t), T = Tt.
</p>
<p>We will go on to select the timescale T later below. Through these scalings, the
</p>
<p>nondimensional concentrations are all normalised such that
</p>
<p>0 &le; {s(t), p(t), e(t), c(t)} &le; 1.
</p>
<p>Our previous intuition related to the transformation of enzyme to complex molecules,
</p>
<p>E ⇋ C, can be made concrete by noting that the total amount of the two substances
</p>
<p>is conserved for all times, following directly from (10.12a),
</p>
<p>d
</p>
<p>dT
(C + E) = 0 =&rArr; C(T)+ E(T) = E0,
</p>
<p>so that c + e = 1. This allows us to use e = 1 &minus; c to eliminate the enzyme from the
</p>
<p>system, leaving the problem in terms of s, c, p.</p>
<p/>
</div>
<div class="page"><p/>
<p>208 10 Fast/slow Dynamical Systems
</p>
<p>We take the initial amount of substrate to be finite, S0 = O(1), and assume that
</p>
<p>we begin with a relatively small amount of enzyme, E0 ≪ S0. We now select the
</p>
<p>timescale T in order to make the consumption rate ds/dt = O(1). This choice yields
</p>
<p>T = 1/(k1E0). The resulting scaled system is therefore given by
</p>
<p>ds
</p>
<p>dt
= &minus;s(1 &minus; c)+ λc, s(0) = 1, (10.14)
</p>
<p>ε
dc
</p>
<p>dt
= s(1 &minus; c)&minus; μc, c(0) = 0,
</p>
<p>dp
</p>
<p>dt
= (μ&minus; λ)c, p(0) = 0,
</p>
<p>where we have relabelled dimensionless combinations of parameters as
</p>
<p>ε =
E0
</p>
<p>S0
≪ 1 λ =
</p>
<p>k2
</p>
<p>k1S0
= O(1) μ =
</p>
<p>k2 + k3
</p>
<p>k1S0
= O(1). (10.15)
</p>
<p>We will consider the limit of a very small amount of enzyme in the system (ε &rarr; 0)
</p>
<p>for our perturbation analysis. Noting that the equations for s, c are independent of
</p>
<p>p, we first solve for the s, c system and then use the results to determine p from the
</p>
<p>final equation in (10.14).
</p>
<p>Since (10.14) is a singularly perturbed system for ε &rarr; 0, we expect a separation
</p>
<p>between fast and slow time scales. Beginning with the slow system, we consider reg-
</p>
<p>ular expansions for the solutions, s = s0(t) + O(ε), c = c0(t) + O(ε). Substituting
</p>
<p>these into (10.14) yields the leading order slow system,
</p>
<p>ds0
</p>
<p>dt
= &minus;s0(1 &minus; c0)+ λc0, 0 = s0(1 &minus; c0)&minus; μc0, (10.16)
</p>
<p>with the second equation giving an algebraic relationship between the complex and
</p>
<p>substrate concentrations,
</p>
<p>s0(c0) =
μc0
</p>
<p>1 &minus; c0
; (10.17)
</p>
<p>this is the slow manifold for this problem.
</p>
<p>We note that our initial conditions, c(t = 0) = 0, s(t = 0) = 1 do not lie on the
</p>
<p>slow manifold and hence there must be a brief initial layer at t&lowast; = 0, governed by the
</p>
<p>dynamics of the fast system, that describes the transition from the initial conditions to
</p>
<p>the slow manifold. To determine the form of the fast system, we rescale the variables
</p>
<p>as
</p>
<p>s = S(T), c = C(T), T =
t
</p>
<p>εα
,
</p>
<p>yielding
</p>
<p>ε&minus;α
dS
</p>
<p>dT
= &minus;S(1 &minus; C)+ λC, ε1&minus;α
</p>
<p>dC
</p>
<p>dT
= S(1 &minus; C)&minus; μC.</p>
<p/>
</div>
<div class="page"><p/>
<p>10.2 Complex Chemical Reactions: The Michaelis-Menten Model 209
</p>
<p>The distinguished limit for the fast system is found to occur when α = 1 and the
</p>
<p>leading order fast system is then given by
</p>
<p>dS0
</p>
<p>dT
= 0,
</p>
<p>dC0
</p>
<p>dT
= S0(1 &minus; C0)&minus; μC0, (10.18)
</p>
<p>with initial conditions S0(0) = 1 and C0(0) = 0. Consequently there is no change
</p>
<p>to the substrate concentration in the initial layer at leading order, and it remains at
</p>
<p>its initial value, S0(T) &equiv; 1. For completeness, we could determine C0(T) from this
</p>
<p>system, but bearing in mind that our final goal is to determine p(t), we only actually
</p>
<p>need to find s(t) as we can replace c(t) in terms of s(t) (at leading order) in (10.14)
</p>
<p>using the slow manifold (10.17). Asymptotic matching of the fast and slow solutions
</p>
<p>for s yields the initial conditions for the slow solution,
</p>
<p>lim
T&rarr;&infin;
</p>
<p>S0(T) = 1 = lim
t&rarr;0
</p>
<p>s0(t).
</p>
<p>Hence, while the initial layer has a dramatic effect on the concentration of the com-
</p>
<p>plex, it essentially leaves the initial condition on s from (10.14) unchanged. The
</p>
<p>initial layer is effectively a boundary layer with respect to time for the initial value
</p>
<p>problem for c in (10.14). Figure 10.4 shows a comparison of the numerical solution
</p>
<p>of (10.14) against the leading order fast/slow dynamics (the slow manifold being
</p>
<p>described by (10.17)).
</p>
<p>Substituting (10.17) into (10.14), we get the slow system,
</p>
<p>ds0
</p>
<p>dt
= &minus;
</p>
<p>μ&minus; λ
</p>
<p>μ+ s0
s0,
</p>
<p>dp0
</p>
<p>dt
=
</p>
<p>μ&minus; λ
</p>
<p>μ+ s0
s0, (10.19)
</p>
<p>and we can finally confirm our expectation that the total of the substrate and product
</p>
<p>is conserved, d(s0 + p0)/dt = 0. Using the initial conditions, we have effectively
</p>
<p>reduced the original problem to solving a single first order ODE for s0(t), with p0(t)
</p>
<p>then being given by p0(t) = 1 &minus; s0(t). This effective nonlinear rate law is called
</p>
<p>the Michaelis-Menten law and is used extensively in the modelling of biochemical
</p>
<p>systems.
</p>
<p>Fig. 10.4 The cs phase
</p>
<p>plane showing the slow
</p>
<p>manifold curve (10.17) and a
</p>
<p>numerical solution of the full
</p>
<p>system (10.14) for ε = 1/5
</p>
<p>starting from initial
</p>
<p>condition (c, s) = (0, 1)</p>
<p/>
</div>
<div class="page"><p/>
<p>210 10 Fast/slow Dynamical Systems
</p>
<p>10.3 Further Directions
</p>
<p>More extensive presentations of dynamical systems are given in many texts, both
</p>
<p>from more theoretical [43, 70], and more applied standpoints [54, 94]. Many books
</p>
<p>illustrate in detail the use of perturbation methods for studying dynamical systems
</p>
<p>[47, 54, 56, 73, 102], with the van der Pol oscillator being a classic example. Mod-
</p>
<p>elling and applications of chemical kinetic systems are presented more thoroughly
</p>
<p>in [37, 49, 57, 74]. Some alternative limiting cases of the enzyme kinetics system
</p>
<p>are explored in [87, 90].
</p>
<p>10.4 Exercises
</p>
<p>10.1 Consider the van der Pol equation for x(t) with 0 &lt; ε ≪ 1,
</p>
<p>ε
d2x
</p>
<p>dt2
+ (3x2 &minus; 6x &minus; 9)
</p>
<p>dx
</p>
<p>dt
+ 4x = 0.
</p>
<p>(a) Determine f (x) so that this equation can be written as a Li&eacute;nard phase plane
</p>
<p>system in the form
</p>
<p>ε
dx
</p>
<p>dt
= f (x)+ 4y,
</p>
<p>dy
</p>
<p>dt
= &minus;x.
</p>
<p>(b) For fixed ε &gt; 0, find the equilibrium point(s) in the phase plane, find their
</p>
<p>eigenvalues, and classify their linear stability.
</p>
<p>(c) Use the expansions x(t) = x0(t)+εx1(t)+O(ε
2), y(t) = y0(t)+εy1(t)+O(ε
</p>
<p>2),
</p>
<p>to determine the equations for the leading order slow solution. Sketch the slow
</p>
<p>manifold, indicate the direction of motion on each part, and identify the two
</p>
<p>attracting points on the curve.
</p>
<p>(d) Use the expansions x(t) = X0(T)+ εX1(T)+O(ε
2), y(t) = Y0(T)+ εY1(T)+
</p>
<p>O(ε2) with T = t/ε to obtain the equations for the leading order fast solution.
</p>
<p>(e) Use the phase plane to determine the maximum and minimum values of x(t)
</p>
<p>during an oscillation, see Fig. 10.2. Sketch x(t) as a function of time, see Fig. 10.3.
</p>
<p>(f) Using the time required for the slow motions in (c) (neglecting the short times
</p>
<p>for the fast solutions (d)), determine the leading order estimate for the period P
</p>
<p>of oscillation of the limit cycle.
</p>
<p>Hint: Find the time spent moving along each of the slow curves by obtaining an
</p>
<p>equation dx0/dt = g(x0) from (c) and then separate variables to write
</p>
<p>dx0
</p>
<p>dt
= g(x0) =&rArr; P =
</p>
<p>&int; tend
</p>
<p>tstart
</p>
<p>dt =
</p>
<p>&int; xend
</p>
<p>xstart
</p>
<p>dx
</p>
<p>g(x)</p>
<p/>
</div>
<div class="page"><p/>
<p>10.4 Exercises 211
</p>
<p>and finally integrate over the ranges in x that are appropriate to each of the two
</p>
<p>slow segments and adding together those two times.
</p>
<p>10.2 We now consider different limits for a dynamical system describing a chemical
</p>
<p>reaction problem in terms of three variables, see (4.50). Consider the limit ε &rarr; 0
</p>
<p>for each of the following cases,
</p>
<p>(a) For the system
</p>
<p>dx
</p>
<p>dt
= 2 &minus; y, x(0) = 1,
</p>
<p>dy
</p>
<p>dt
= x &minus; z, y(0) = 3, (10.20)
</p>
<p>ε
dz
</p>
<p>dt
= y &minus; y2 + 1
</p>
<p>3
y3 &minus; z, z(0) = 0.
</p>
<p>Identify the surface z = S(x, y) that defines the slow manifold. Find the equi-
</p>
<p>librium point of the leading order slow phase plane system and show that it is
</p>
<p>asymptotically stable for t &rarr; &infin;. Also determine the form of the initial layer
</p>
<p>that describes the transition from the initial conditions to the slow manifold.
</p>
<p>(b) For the system
</p>
<p>dx
</p>
<p>dt
= 2 &minus; y, x(0) = 0,
</p>
<p>ε
dy
</p>
<p>dt
= x &minus; z, y(0) = 3, (10.21)
</p>
<p>dz
</p>
<p>dt
= y &minus; y2 + 1
</p>
<p>3
y3 &minus; z, z(0) = 1.
</p>
<p>Show that the slow manifold reduces to a curve that could be written in parametric
</p>
<p>form as x = x(z), y = y(z), z = z. Determine the asymptotic solution for
</p>
<p>t &rarr; &infin;. Also determine the form of the initial layer that describes the transition
</p>
<p>from the initial conditions to the slow manifold.
</p>
<p>10.3 Consider the problem of forming a &ldquo;tri-mer&rdquo; (a three segment polymer mole-
</p>
<p>cule) from three mono-mer molecules,
</p>
<p>3A &rarr; A3.
</p>
<p>This is an example of polymerisation. It is a non-elementary reaction and takes place
</p>
<p>via intermediate stages. Call the tri-mer &ldquo;C&rdquo; and the di-mer (A2) &ldquo;B&rdquo;. Suppose that
</p>
<p>the full reaction mechanism is given by
</p>
<p>A + A
k1
&minus;⇀↽&minus;
k2
</p>
<p>B A + B
k3
&minus;&rarr; C</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4">http://dx.doi.org/10.1007/978-3-319-23042-9_4</a></div>
</div>
<div class="page"><p/>
<p>212 10 Fast/slow Dynamical Systems
</p>
<p>(a) Write the dimensional rate equations.
</p>
<p>(b) Nondimensionalize using the scalings
</p>
<p>A(T) = A0a(t) B(T) = B0b(t) C(T) = A0c(t) T = Tt
</p>
<p>where A0 is the initial concentration.
</p>
<p>(c) Let T = 1/(k1A0) and assume that ε = B0/A0 &rarr; 0.
</p>
<p>Identify the other dimensionless parameters (call them Π1,Π2) and state what
</p>
<p>asymptotic relations on the rate constants kn must hold if we assume that only
</p>
<p>the εdb/dt terms vanishes from the leading order slow system.
</p>
<p>Hint: Normalise the coefficient of the +a2 term.
</p>
<p>(d) Find the leading order slow manifold and write the dimensional equations for
</p>
<p>the long-term rate of production, and hence find G(A) and F(A) in
</p>
<p>dA
</p>
<p>dT
= &minus;G(A),
</p>
<p>dC
</p>
<p>dT
= F(A).
</p>
<p>10.4 Consider the system of chemical reactions
</p>
<p>A + X
k1
&minus;&rarr; Y A + Y
</p>
<p>k2
&minus;&rarr; 2X A
</p>
<p>k3
&minus;&rarr; Y 2Y
</p>
<p>k4
&minus;&rarr; P
</p>
<p>where the concentration of A is kept constant and k1, k2, k3, k4 are given.
</p>
<p>(a) Write the rate equations for x(t) and y(t).
</p>
<p>(b) Nondimensionalize using T = Tt, X = Xx, Y = Yy. Let T = 1/(k1A).
</p>
<p>Determine X and Y so that: (1) all of the terms in the dx/dt equation and (2) the
</p>
<p>y2 term in the dy/dt equation are normalised.
</p>
<p>(c) Determine the remaining independent dimensionless parameters (call themα, β)
</p>
<p>and write the nondimensionalized equations.
</p>
<p>(d) In terms of α, β, determine the concentrations x, y for the positive equilibrium
</p>
<p>solution.
</p>
<p>10.5 In chemistry, a widely-used short-cut avoiding the full scaling and slow/fast
</p>
<p>perturbation analysis is to jump to the leading order slow equations using the assump-
</p>
<p>tion that the rate of production of all intermediates equilibrate (i.e. reduce to steady
</p>
<p>algebraic relations, like ε dc
dt
</p>
<p>= 0); this is called the Quasi-Steady-State Assumption
</p>
<p>(QSSA).
</p>
<p>Use the QSSA approach to consider the overall reaction for the formation of
</p>
<p>hydrogen-bromide: H2 + Br2 &rarr; 2HBr. The reaction takes place through several
</p>
<p>steps:
</p>
<p>Br2
k1
&minus;⇀↽&minus;
k2
</p>
<p>2Br Br + H2
k3
&minus;⇀↽&minus;
k4
</p>
<p>H + HBr H + Br2
k5
&minus;&rarr; HBr + Br
</p>
<p>Consider the atomic forms H and Br to be unstable intermediates (similar to com-
</p>
<p>plexes being unstable intermediates). Apply the QSSA to obtain the dimensional</p>
<p/>
</div>
<div class="page"><p/>
<p>10.4 Exercises 213
</p>
<p>rate law for the production of HBr (written here using the chemistry-notation of [X]
</p>
<p>being the concentration of chemical X) [6],
</p>
<p>d[HBr]
</p>
<p>dT
=
</p>
<p>α[H2][Br2]
3/2
</p>
<p>[Br2] + β[HBr]
</p>
<p>Find α, β. Hint: Write A = [H2],B = [Br2],C = [Br],D = [H],P = [HBr] for
</p>
<p>doing your algebra.</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 11
</p>
<p>Reduced Models for PDE Problems
</p>
<p>In previous chapters, we have considered methods for solving problems in partial
</p>
<p>differential equations: the method of characteristics in Chap. 2, similarity solutions
</p>
<p>in Chap.5, and Fourier series in Chap. 8. Now we pursue another approach that can
</p>
<p>be applied to problems where we want to obtain certain properties of the solution,
</p>
<p>but do not need an explicit representation of the entire solution. We will see that in
</p>
<p>some cases, this leads to substantially shorter calculations.
</p>
<p>The approach of reduced models is to reformulate a problem into a simpler form
</p>
<p>that preserves the properties of interest, but decouples them from the calculation of
</p>
<p>other details of the solution&rsquo;s behaviour. We will describe the method of moments,
</p>
<p>which produces reduced models that can describe the evolution of some quantities
</p>
<p>for the solution averaged over the domain.1
</p>
<p>11.1 The Method of Moments
</p>
<p>For a solution ρ(x, t) of a PDE problem on a domain D, we can define the moment
</p>
<p>integrals,
</p>
<p>Mn(t) &equiv;
&int;
</p>
<p>D
</p>
<p>xnρ(x, t) dx n = 0, 1, 2, . . . (11.1)
</p>
<p>If ρ represents a density, then the n = 0 integral corresponds to the total mass. For
some problems, we can determine a simple set of equations governing the evolution
</p>
<p>of the moment integrals (without explicitly finding the solution ρ(x, t)) and then use
</p>
<p>those results to infer information about the behaviour of the solution to the problem.
</p>
<p>1Wehave already encountered reduced dimension models inChap.8,wherewe developed amethod-
</p>
<p>ology for solving PDEs on slender two-dimensional domains by replacing themwithODE problems
</p>
<p>for an asymptotic solution applying on most of the domain.
</p>
<p>&copy; Springer International Publishing Switzerland 2015
</p>
<p>T. Witelski and M. Bowen, Methods of Mathematical Modelling,
</p>
<p>Springer Undergraduate Mathematics Series, DOI 10.1007/978-3-319-23042-9_11
</p>
<p>215</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2">http://dx.doi.org/10.1007/978-3-319-23042-9_2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5">http://dx.doi.org/10.1007/978-3-319-23042-9_5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_8">http://dx.doi.org/10.1007/978-3-319-23042-9_8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_8">http://dx.doi.org/10.1007/978-3-319-23042-9_8</a></div>
</div>
<div class="page"><p/>
<p>216 11 Reduced Models for PDE Problems
</p>
<p>We illustrate this approach for the heat equation on &minus;&infin; &lt; x &lt; &infin;
</p>
<p>&part;ρ
</p>
<p>&part;t
= &part;
</p>
<p>2ρ
</p>
<p>&part;x2
, (11.2a)
</p>
<p>with far-field boundary conditions u &rarr; 0 as |x | &rarr; &infin; and initial condition
</p>
<p>ρ(x, t = 0) = f (x), (11.2b)
</p>
<p>where f &rarr; 0 rapidly as |x | &rarr; &infin;.
Consider the zeroth moment (mass) integral,
</p>
<p>M0(t) =
&int; &infin;
</p>
<p>&minus;&infin;
ρ(x, t) dx .
</p>
<p>In order to obtain an equation to describe the evolution of M0(t), we calculate its
</p>
<p>rate of change with respect to time
</p>
<p>d M0
</p>
<p>dt
= d
</p>
<p>dt
</p>
<p>&int; &infin;
</p>
<p>&minus;&infin;
ρ dx =
</p>
<p>&int; &infin;
</p>
<p>&minus;&infin;
</p>
<p>&part;ρ
</p>
<p>&part;t
dx,
</p>
<p>where we have interchanged the order of differentiation (with respect to time) and
</p>
<p>integration (over space). Using the PDE (11.2a) to replace the time derivative with
</p>
<p>the second order spatial derivative and then integrating yields
</p>
<p>d M0
</p>
<p>dt
=
</p>
<p>&int; &infin;
</p>
<p>&minus;&infin;
</p>
<p>&part;2ρ
</p>
<p>&part;x2
dx = &part;ρ
</p>
<p>&part;x
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>&infin;
</p>
<p>&minus;&infin;
= 0&minus; 0 = 0,
</p>
<p>where we have used that ρx &rarr; 0 as |x | &rarr; &infin; for smooth ρ &rarr; constant (specifically
ρ &rarr; 0) in evaluating the boundary terms. Consequently, we have
</p>
<p>d M0
</p>
<p>dt
= 0,
</p>
<p>so that the total mass is constant in the problem and its value for problem(11.2a,
</p>
<p>11.2b) is determined by its initial value at t = 0,
</p>
<p>M0(0) =
&int; &infin;
</p>
<p>&minus;&infin;
f (x) dx . (11.3)</p>
<p/>
</div>
<div class="page"><p/>
<p>11.1 The Method of Moments 217
</p>
<p>We can proceed similarly for the first moment, M1(t) =
&int; &infin;
&minus;&infin; xρ dx, for which we
</p>
<p>find
</p>
<p>d M1
</p>
<p>dt
= d
</p>
<p>dt
</p>
<p>&int; &infin;
</p>
<p>&minus;&infin;
xρ dx =
</p>
<p>&int; &infin;
</p>
<p>&minus;&infin;
x
&part;ρ
</p>
<p>&part;t
dx =
</p>
<p>&int; &infin;
</p>
<p>&minus;&infin;
x
&part;2ρ
</p>
<p>&part;x2
dx .
</p>
<p>Making use of integration by parts and employing further assumptions about the
</p>
<p>decay of the solution as |x | &rarr; &infin; being sufficiently rapid to eliminate boundary
terms from integration by parts, we obtain
</p>
<p>d M1
</p>
<p>dt
= x &part;ρ
</p>
<p>&part;x
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>&infin;
</p>
<p>&minus;&infin;
&minus;
</p>
<p>&int; &infin;
</p>
<p>&minus;&infin;
</p>
<p>&part;ρ
</p>
<p>&part;x
dx = 0.
</p>
<p>Therefore, M1 is also a constant, also set by the initial conditions as
</p>
<p>M1(0) =
&int; &infin;
</p>
<p>&minus;&infin;
x f (x) dx . (11.4)
</p>
<p>Having these moments allow us to evaluate the centre of mass (the average value
</p>
<p>of position weighted by the density), defined by the ratio of the first moment to the
</p>
<p>mass,
</p>
<p>x̄(t) = M1
M0
</p>
<p>=
&int;
</p>
<p>x f dx
&int;
</p>
<p>f dx
. (11.5)
</p>
<p>Investigating the evolution of x̄ can provide an understanding of whether the solution
</p>
<p>is generally moving in some direction or remaining in a fixed location; in this case,
</p>
<p>x̄ remains fixed at its initial position as both M0 and M1 are constants.
</p>
<p>Proceeding to the second moment, we find
</p>
<p>d M2
</p>
<p>dt
=
</p>
<p>&int; &infin;
</p>
<p>&minus;&infin;
x2
</p>
<p>&part;ρ
</p>
<p>&part;t
dx =
</p>
<p>&int; &infin;
</p>
<p>&minus;&infin;
x2
</p>
<p>&part;2ρ
</p>
<p>&part;x2
dx
</p>
<p>= x2 &part;ρ
&part;x
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>&infin;
</p>
<p>&minus;&infin;
&minus;
</p>
<p>&int;
</p>
<p>2x
&part;ρ
</p>
<p>&part;x
dx
</p>
<p>= &minus;2
(
</p>
<p>xρ
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>&infin;
</p>
<p>&minus;&infin;
&minus;
</p>
<p>&int; &infin;
</p>
<p>&minus;&infin;
ρ dx
</p>
<p>)
</p>
<p>,
</p>
<p>where the boundary conditions have been used to successively eliminate the boundary
</p>
<p>terms from the two applications of integration by parts. Consequently, the rate of
</p>
<p>change of the second moment is given in terms of the mass M0,</p>
<p/>
</div>
<div class="page"><p/>
<p>218 11 Reduced Models for PDE Problems
</p>
<p>d M2
</p>
<p>dt
= 2M0. (11.6)
</p>
<p>For the heat equation, we have already shown that the mass is constant and so the
</p>
<p>second moment increases at a constant rate. We can therefore express M2 in terms
</p>
<p>of the initial conditions as
</p>
<p>M2(t) = 2t
&int; &infin;
</p>
<p>&minus;&infin;
f dx +
</p>
<p>&int; &infin;
</p>
<p>&minus;&infin;
x2 f dx . (11.7)
</p>
<p>The variance is defined as the second moment of ρ with respect to the centre of mass
</p>
<p>and yields a fundamental measure of the spreading of the solution
</p>
<p>V (t) =
&int; &infin;
</p>
<p>&minus;&infin;
(x &minus; x̄)2ρ dx
</p>
<p>=
&int; &infin;
</p>
<p>&minus;&infin;
x2ρ dx &minus; 2x̄
</p>
<p>&int; &infin;
</p>
<p>&minus;&infin;
xρ dx + x̄2
</p>
<p>&int; &infin;
</p>
<p>&minus;&infin;
ρ dx
</p>
<p>= M2 &minus; 2x̄ M1 + x̄2M0
</p>
<p>= M2 &minus; 2
M21
</p>
<p>M0
+ M
</p>
<p>2
1
</p>
<p>M20
M0
</p>
<p>= M2 &minus;
M21
</p>
<p>M0
.
</p>
<p>The variance is also used to define the standard deviation in terms of its square-root,
</p>
<p>σ =
&radic;
|V |, yielding
</p>
<p>σ 2(t) =
∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>M2 &minus;
M21
</p>
<p>M0
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>. (11.8)
</p>
<p>While the terminology used above comes from probability and statistics, the defin-
</p>
<p>itions are direct analogues of the formulas for the moment of inertia (V &rarr; I ) and
radius of gyration (σ &rarr; R) used in mechanics for describing the motion of objects
[40, 67].
</p>
<p>A somewhatmore direct approach for constructingmoment equations is to directly
</p>
<p>the integrate the product of the weight function with the PDE over the domain,
</p>
<p>&int;
</p>
<p>D
</p>
<p>xn(PDE) dx .</p>
<p/>
</div>
<div class="page"><p/>
<p>11.1 The Method of Moments 219
</p>
<p>Consider for example the following problem for the wave equation on the finite
</p>
<p>domain, 0 &le; x &le; 1,
&part;2ρ
</p>
<p>&part;t2
= &part;
</p>
<p>2ρ
</p>
<p>&part;x2
(11.9a)
</p>
<p>subject to boundary conditions
</p>
<p>&part;ρ
</p>
<p>&part;x
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>x=0
= et , &part;ρ
</p>
<p>&part;x
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>x=1
= 12t2, (11.9b)
</p>
<p>and initial conditions
</p>
<p>ρ(x, 0) = 1 &part;ρ
&part;t
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>t=0
= cos(3πx). (11.9c)
</p>
<p>Integrating (11.9a) over the domain and the applying boundary conditions yields an
</p>
<p>ODE for the zeroth moment,
</p>
<p>&int; 1
</p>
<p>0
</p>
<p>(ρt t = ρxx ) dx =&rArr;
d2M0
</p>
<p>dt2
= &part;ρ
</p>
<p>&part;x
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>x=1
</p>
<p>x=0
=&rArr; d
</p>
<p>2M0
</p>
<p>dt2
= 12t2 &minus; et .
</p>
<p>Integrating the initial conditions for ρ generates initial conditions for M0, M0(0) = 1
and M &prime;0(0) = 0 and consequently yields M0(t) = t4 + t + 2&minus; et .
</p>
<p>In general, themethod ofmoments is considered to be successful when it produces
</p>
<p>a finite, closed set of ODEs that can used to describe selected solution properties. If
</p>
<p>the moment equations depend on an indefinite number of further moments or other
</p>
<p>properties of ρ, then the system is not closed. In such cases, the system may be
</p>
<p>approximated through the use of problem-specific closure relations, as used in the
</p>
<p>modelling of turbulent fluid flows. While this method has been described here as
</p>
<p>an analytical approach, similar analysis is used to reduce PDE problems to simpler
</p>
<p>systems of equations that can be evaluated computationally in numerical methods
</p>
<p>such as Galerkin projection methods.
</p>
<p>We now go on to consider two classic applied mathematics problems that have
</p>
<p>different relations to the method of moments.
</p>
<p>11.2 Turing Instability and Pattern Formation
</p>
<p>In this section, we present an example of how to analyse the development of patterns
</p>
<p>in PDE models, as occur in important systems in mathematical biology and other
</p>
<p>applications. The problem considered will also show that predictions from reduced
</p>
<p>models can sometimes be misleading and must be considered with caution.</p>
<p/>
</div>
<div class="page"><p/>
<p>220 11 Reduced Models for PDE Problems
</p>
<p>We have observed that solutions of the heat equation will generically exhibit dif-
</p>
<p>fusive spreading (as implied by σ(t) increasing with time from (11.8) and similarity
</p>
<p>solutions having x = O(
&radic;
</p>
<p>t) from Sect. 5.5). Consider the problem for the heat
</p>
<p>equation on a finite domain with no-flux boundary conditions,
</p>
<p>&part;ρ
</p>
<p>&part;t
= &part;
</p>
<p>2ρ
</p>
<p>&part;x2
, 0 &le; x &le; π,
</p>
<p>&part;ρ
</p>
<p>&part;x
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>x=0
= 0, &part;ρ
</p>
<p>&part;x
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>x=π
= 0,
</p>
<p>with a given initial condition
</p>
<p>ρ(x, 0) = f (x).
</p>
<p>The mass of the solution will be conserved for all times. Further, it can be shown that
</p>
<p>for t &rarr; &infin;, the solution will approach the average value set by the initial condition
</p>
<p>ρ(x, t &rarr; &infin;) &rarr; f̄ where f̄ = 1
π
</p>
<p>&int; π
</p>
<p>0
</p>
<p>f (x) dx .
</p>
<p>Similarly, adding diffusive effects to a transport equation can generally be expected
</p>
<p>to cause the solution to both spread and smooth out. Likewise, if diffusion is incor-
</p>
<p>porated into a model for chemical reaction kinetics to yield a partial differential
</p>
<p>equation, as in
</p>
<p>dc
</p>
<p>dt
= &minus;c =&rArr; &part;c
</p>
<p>&part;t
= &part;
</p>
<p>2c
</p>
<p>&part;x2
&minus; c,
</p>
<p>then it can be shown that the spatial variation in the initial condition c(x, 0) will
</p>
<p>eventually level-out as the solution approaches the solution of the original ODE,
</p>
<p>c(x, t) &rarr; c(t) (see Exercise11.3).
However, the work of Alan Turing (1912&ndash;1954) showed that this intuition is not
</p>
<p>always a good guide for more complicated systems. In the context of developmental
</p>
<p>biology [100], he showed that the addition of diffusive effects to a system of reactions
</p>
<p>could enhance spatial structure rather than suppressing it.
</p>
<p>To illustrate this effect, let us consider a simple system involving two chemicals, P
</p>
<p>and Q, that interact and are also supplied into or drained out of the system according
</p>
<p>to
</p>
<p>P + Q &rarr; 2P P &rarr; (drain) Q &rarr; 2Q (source) &rarr; Q.
</p>
<p>These two substances may diffuse at different rates, so we will describe their spa-
</p>
<p>tial evolution using diffusion terms with different coefficients. Hence, consider the
</p>
<p>nondimensionalized governing equations,</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5">http://dx.doi.org/10.1007/978-3-319-23042-9_5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_11">http://dx.doi.org/10.1007/978-3-319-23042-9_11</a></div>
</div>
<div class="page"><p/>
<p>11.2 Turing Instability and Pattern Formation 221
</p>
<p>&part;p
</p>
<p>&part;t
= 2pq &minus; 4+ &part;
</p>
<p>2 p
</p>
<p>&part;x2
,
</p>
<p>&part;q
</p>
<p>&part;t
= &minus;2pq + q + 3+ D &part;
</p>
<p>2q
</p>
<p>&part;x2
(11.10a)
</p>
<p>where D &ge; 1 is the ratio of diffusion coefficients giving the relative spreading rate of
Q compared to P . Let the domain be 0 &le; x &le; π , with no-flux boundary conditions,
</p>
<p>&part;p
</p>
<p>&part;x
= 0 and &part;q
</p>
<p>&part;x
= 0 at x = 0 and x = π (11.10b)
</p>
<p>and initial conditions at t = 0,
</p>
<p>p(x, 0) = p0(x), q(x, 0) = q0(x). (11.10c)
</p>
<p>This is a simple example of a reaction-diffusion system. Research on similar systems
</p>
<p>has shown that they can produce surprisingly complicated results, so the general
</p>
<p>approach to studying reaction-diffusion problems is to start with the simplest possible
</p>
<p>solutions and build up an understanding from there.
</p>
<p>Seeking time-independent steady states reduces the PDEs for p(x, t), q(x, t) to
</p>
<p>two coupled nonlinear ODEs for p̄(x), q̄(x), which can still be difficult to solve.
</p>
<p>Hence, we further constrain our search and obtain spatially uniform (constant) solu-
</p>
<p>tions, p&lowast;, q&lowast; from the algebraic relations
</p>
<p>0 = 2p&lowast;q&lowast; &minus; 4, 0 = &minus;2p&lowast;q&lowast; + q&lowast; + 3, (11.11)
</p>
<p>which yield the equilibrium solution p&lowast; = 2, q&lowast; = 1. To explore the stability of this
state to small perturbations, let
</p>
<p>p = p&lowast; + ε p̃(x, t), q = q&lowast; + εq̃(x, t) (11.12)
</p>
<p>with ε &rarr; 0. Treating these expression as perturbation expansions, we substitute
into (11.10a). At leading order we recover the steady-state equations (11.11), while
</p>
<p>at O(ε) we get the linearised version of (11.10a),
</p>
<p>&part; p̃
</p>
<p>&part;t
= 2 p̃ + 4q̃ + &part;
</p>
<p>2 p̃
</p>
<p>&part;x2
,
</p>
<p>&part; q̃
</p>
<p>&part;t
= &minus;2 p̃ &minus; 3q̃ + D &part;
</p>
<p>2q̃
</p>
<p>&part;x2
. (11.13)
</p>
<p>Applying the method of moments to this system, we can determine the evolution
</p>
<p>of the mean values of p̃ and q̃ from the zeroth moment integrals,
</p>
<p>P0(t) =
1
</p>
<p>π
</p>
<p>&int; π
</p>
<p>0
</p>
<p>p̃(x, t) dx, Q0(t) =
1
</p>
<p>π
</p>
<p>&int; π
</p>
<p>0
</p>
<p>q̃(x, t) dx .
</p>
<p>Integrating (11.13) over the domain and applying the boundary conditions yields the
</p>
<p>coupled ODEs,</p>
<p/>
</div>
<div class="page"><p/>
<p>222 11 Reduced Models for PDE Problems
</p>
<p>d P0
</p>
<p>dt
= 2P0 + 4Q0,
</p>
<p>d Q0
</p>
<p>dt
= &minus;2P0 &minus; 3Q0. (11.14)
</p>
<p>Note that (11.14) corresponds to (11.13) restricted to spatially uniform solutions.
</p>
<p>A phase plane analysis of this system shows that (P0, Q0) = (0, 0) is the only
equilibrium point and has eigenvalues λ = (&minus;1 &plusmn; i
</p>
<p>&radic;
7)/2, so it is a stable spiral
</p>
<p>point. Hence all solutions of (11.14) will converge to (P0, Q0) = (0, 0) as t &rarr; &infin;.
While this correctly predicts the evolution of the means of the perturbations p̃ and
</p>
<p>q̃ , further analysis is needed to describe their spatial structure.
</p>
<p>The process of reducing a nonlinear problem, like (11.10a), to a linear problem,
</p>
<p>(11.13), by focusing on the evolution of solutions starting near an equilibrium state
</p>
<p>is a classic example of linear stability analysis. We applied this approach to ODEs in
</p>
<p>Chap.1; this is also one of the most general approaches to exploring the behaviour
</p>
<p>of nonlinear PDEs [26].
</p>
<p>To complete the analysis, we make use of the linearity of system (11.13) to obtain
</p>
<p>solutions as linear superpositions of eigenmodes, p̃ =
&sum;
</p>
<p>k p̃k(x, t), and apply sep-
</p>
<p>aration of variables to express the eigenmodes as products p̃k(x, t) = fk(x)gk(t)
[44]. Requiring each eigenmode to satisfy the boundary conditions (11.10b) yields
</p>
<p>(
</p>
<p>pk(x, t)
</p>
<p>qk(x, t)
</p>
<p>)
</p>
<p>=
(
</p>
<p>ak
bk
</p>
<p>)
</p>
<p>cos(kx)eλk t , (11.15)
</p>
<p>where ak, bk, λk are constants depending on the wavenumber k = 0, 1, 2, . . . . Sub-
stituting each independent mode into (11.13) and eliminating common factors, we
</p>
<p>arrive at the matrix eigenvalue problem
</p>
<p>λk
</p>
<p>(
</p>
<p>ak
bk
</p>
<p>)
</p>
<p>=
(
</p>
<p>2&minus; k2 4
&minus;2 &minus;3&minus; k2D
</p>
<p>) (
</p>
<p>ak
bk
</p>
<p>)
</p>
<p>. (11.16)
</p>
<p>For k = 0, this is the eigenvalue problem that would be obtained from the stability
analysis of the ODE system (11.14). More generally, for k &ge; 0, we can determine
the stability of the eigenmodes from solving the characteristic polynomial for λk
</p>
<p>(λk + k2 &minus; 2)(λk + k2D + 3)+ 8 = 0. (11.17)
</p>
<p>The relation between the spatial wavenumber and the real part of the dominant
</p>
<p>eigenvalue, σ(k) = Re(λ+k ) is often called the dispersion relation and concisely
conveys the PDE stability results with respect to all admissible types of perturbations,
</p>
<p>as represented by the eigenmodes with different values of k.
</p>
<p>For the case where Q diffuses muchmore rapidly than P (D ≫ 1) it can be shown
thatRe(λ+k ) can becomepositive and hence some eigenmodeswill grow in amplitude;
this is known as a Turing instability. The growth rates for system (11.13) when D =
100 are plotted in Fig. 11.1, where it can be seen that k = 1 is selected as the dominant
growing mode (the only integer-valued k with a positive growth rate). Consequently,
</p>
<p>this mode will eventually dominate the dynamics of the system and produce a pattern</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1">http://dx.doi.org/10.1007/978-3-319-23042-9_1</a></div>
</div>
<div class="page"><p/>
<p>11.2 Turing Instability and Pattern Formation 223
</p>
<p>Fig. 11.1 The dispersion
</p>
<p>relation showing growth
</p>
<p>rates of eigenmodes (11.15)
</p>
<p>with k = 0, 1, 2, . . . of the
linearised system (11.13)
</p>
<p>with D = 100
</p>
<p>resembling cos(x) unless the initial conditions (11.10c) have no contribution from the
</p>
<p>k = 1 unstable mode, i.e.
&int; π
</p>
<p>0
(p0, q0) cos(x) dx = (0, 0). We note that the influence
</p>
<p>of the parameter D (giving the relative rates of diffusion) dramatically changes the
</p>
<p>stability of the equilibrium solution for different wavenumbers: a stable spiral for
</p>
<p>k = 0, a saddle point for k = 1, and stable node for k = 2, 3, . . . .
For different choices of system parameters, there may be a band of unstable
</p>
<p>wavenumbers, k &isin; {1, 2, . . . , kc} with σ(k) &gt; 0, that will all grow until nonlinear
coupling effects take over to determine the further dynamics of the solution. Systems
</p>
<p>having σ(k) &ge; 0 below some critical wavenumber, 0 &le; k &le; kc, are often called
long-wave unstable since they involve spatial variations involving only the longest
</p>
<p>wavelength eigenmodes. The Turing instability has been used in many studies as a
</p>
<p>model for biological pattern formation, such as the spots and stripes on animal coats
</p>
<p>[26, 42, 74].
</p>
<p>We note that in attempting to use the method of moments for this problem, we
</p>
<p>considered the zeroth moments of the perturbations in the linearised system (11.13)
</p>
<p>rather than in the original nonlinear system. There would have been a difficulty in
</p>
<p>integrating (11.10a) directly, as it might not be immediately clear how to analyse the
</p>
<p>integral of the nonlinear term,
&int; π
</p>
<p>0 pq dx . In the next section, we will see how this
</p>
<p>type of issue can be dealt with in the context of a different system.
</p>
<p>11.3 Taylor Dispersion and Enhanced Diffusion
</p>
<p>Wenowdescribe a classicmodel fromfluid dynamics that illustrates the effectiveness
</p>
<p>of reduction via the moment-type approach.
</p>
<p>If a substance (called the solute) is released into a channel containing a flowing
</p>
<p>stream of fluid, the substance will spread out as it is carried downstream by the flow.
</p>
<p>Part of this behaviour is due to standard &ldquo;molecular diffusion&rdquo; effects, but spatial
</p>
<p>variations in the flow velocity also contribute since the different transport speeds will
</p>
<p>broaden the area of distribution of the solute.</p>
<p/>
</div>
<div class="page"><p/>
<p>224 11 Reduced Models for PDE Problems
</p>
<p>This problem was studied by G.I. Taylor (1886&ndash;1975), who explained how the
</p>
<p>full transport problem for the solute could be reduced to a one-dimensional model.
</p>
<p>Taylor&rsquo;s model showed that convective effects can increase the effect of diffusion;
</p>
<p>this has come to be known as Taylor dispersion and has been applied to describe the
</p>
<p>spread of pollutants in rivers, drugs in blood flow as well as in many other settings.
</p>
<p>Taylor&rsquo;s original paper [98] was presented in his unique and very physically intuitive
</p>
<p>style; it is deceptively short and challenging to follow. Here we present a derivation
</p>
<p>of Taylor&rsquo;s result that is very similar to the approach given by Leal [61, Sect. 3H]
</p>
<p>(also see [20]).
</p>
<p>Consider a dimensional transport problem for the concentration of a solute
</p>
<p>C (X,Y,T), given by the advection-diffusion equation
</p>
<p>&part;C
</p>
<p>&part;T
+ &nabla; &middot; (CU) = D&nabla;2C, (11.18a)
</p>
<p>where U(X,Y,T) is the fluid velocity field and D is the constant of molecular
</p>
<p>diffusion. We choose the domain to be a two-dimensional long slender channel,
</p>
<p>&minus;&infin;&lt; X &lt;&infin;, &minus;H&le;Y&le;H, and let the velocity field take the classic Poiseuille
flow parabolic profile
</p>
<p>U = U0
(
</p>
<p>1&minus; Y
2
</p>
<p>H2
</p>
<p>)
</p>
<p>l̂ &minus; H &le; Y &le; H, (11.18b)
</p>
<p>where U0 is the maximum speed of the flow (see Fig. 11.2 for a schematic of the
</p>
<p>problem). We assume that there is no flux of the solute out of the sides of the domain,
</p>
<p>n̂ &middot; &nabla;C = 0, which for the uniform width channel, simplifies to
</p>
<p>&part;C
</p>
<p>&part;Y
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>Y=&plusmn;H
= 0. (11.18c)
</p>
<p>While inmost common situations, diffusion occurs at the same rate in every direction
</p>
<p>(so-called isotropic behaviour), to help distinguish different effects, we label the
</p>
<p>diffusion coefficients in the direction of and transverse to the imposed flow as Dx
</p>
<p>Fig. 11.2 Schematic
</p>
<p>behaviour of solute
</p>
<p>dispersion (green contours)
</p>
<p>in a long channel starting
</p>
<p>from a small release area due
</p>
<p>to a velocity field (red)</p>
<p/>
</div>
<div class="page"><p/>
<p>11.3 Taylor Dispersion and Enhanced Diffusion 225
</p>
<p>and Dy respectively. In this anisotropic context, the transport equation (11.18a) takes
</p>
<p>the form
</p>
<p>&part;TC +&nabla; &middot; (CV) = 0, V = U &minus; D&nabla;C,
</p>
<p>where D is a diffusion coefficient matrix, D =
(
</p>
<p>Dx 0
</p>
<p>0 Dy
</p>
<p>)
</p>
<p>. For the isotropic case,
</p>
<p>where Dx = Dy = D, this equation reduces to (11.18a).
We nondimensionalize by taking
</p>
<p>C = C0c, X = Lx, Y = Hy, T = (L/U0)t,
</p>
<p>where C0 is a concentration scale that could be set by the initial conditions and L
</p>
<p>is a typical length scale along the channel. Consequently, the scaled problem on
</p>
<p>&minus;&infin;&lt; x &lt;&infin;, &minus;1&le; y &le; 1 becomes
</p>
<p>&part;c
</p>
<p>&part;t
+ (1&minus; y2) &part;c
</p>
<p>&part;x
= 1
</p>
<p>Pex
</p>
<p>&part;2c
</p>
<p>&part;x2
+ 1
</p>
<p>Pey
</p>
<p>&part;2c
</p>
<p>&part;y2
, (11.19)
</p>
<p>with boundary conditions &part;yc|y=&plusmn;1 = 0. The Peclet numbers,
</p>
<p>Pex =
U0L
</p>
<p>Dx
, Pey =
</p>
<p>U0H
2
</p>
<p>DyL
,
</p>
<p>give the relative importance of the convective flow along the channel versus diffusive
</p>
<p>effects in the x and y directions respectively. As the flow carries the solute along the
</p>
<p>channel, the concentration will disperse across the full width of the channel. Taylor
</p>
<p>showed that the average concentration across the channel at each x position could
</p>
<p>be estimated from a reduced model.
</p>
<p>We note that the concentration can be separated into the average across the channel
</p>
<p>and deviation from the average
</p>
<p>c(x, y, t) = c̄(x, t)+ c̃(x, y, t), (11.20a)
</p>
<p>where the average c̄ is defined by
</p>
<p>c̄(x, t) &equiv; 1
2
</p>
<p>&int; 1
</p>
<p>&minus;1
c(x, y, t) dy. (11.20b)
</p>
<p>A consequence of this definition of c̄ is that the deviation c̃ has zero-mean, i.e.
</p>
<p>&int; 1
</p>
<p>&minus;1
c̃(x, y, t) dy = 0. (11.20c)</p>
<p/>
</div>
<div class="page"><p/>
<p>226 11 Reduced Models for PDE Problems
</p>
<p>Similarly, we can separate the flow, u(y) = 1 &minus; y2, into mean flow and deviation
from the mean,
</p>
<p>u(y) = ū + ũ(y), (11.21a)
</p>
<p>ū = 1
2
</p>
<p>&int; 1
</p>
<p>&minus;1
1&minus; y2 dy = 2
</p>
<p>3
, ũ(y) = 1
</p>
<p>3
&minus; y2. (11.21b)
</p>
<p>The PDE (11.19) can now be expanded as
</p>
<p>&part; c̄
</p>
<p>&part;t
+ &part; c̃
</p>
<p>&part;t
+ ū &part; c̄
</p>
<p>&part;x
+ ũ &part; c̄
</p>
<p>&part;x
+ ū &part; c̄
</p>
<p>&part;x
+ ũ &part; c̄
</p>
<p>&part;x
</p>
<p>= 1
Pex
</p>
<p>&part;2c̄
</p>
<p>&part;x2
+ 1
</p>
<p>Pex
</p>
<p>&part;2c̃
</p>
<p>&part;x2
+ 1
</p>
<p>Pey
</p>
<p>&part;2c̃
</p>
<p>&part;y2
. (11.22)
</p>
<p>This equation can be integrated term by term across the width of the channel,
</p>
<p>1
</p>
<p>2
</p>
<p>&int; 1
</p>
<p>&minus;1
(11.2) dy,
</p>
<p>to give an evolution equation for c̄(x, t). The integrals of the deviations vanish, thus
</p>
<p>&int; 1
</p>
<p>&minus;1
c̃t dy = ū
</p>
<p>&int; 1
</p>
<p>&minus;1
c̃x dy = c̄
</p>
<p>&int; 1
</p>
<p>&minus;1
ũ dy = 0.
</p>
<p>The boundary conditions on c yield corresponding no-flux boundary conditions on
</p>
<p>c̃ and hence the integral of the last term in the PDE also vanishes,
</p>
<p>&part; c̃
</p>
<p>&part;y
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>y=&plusmn;1
= 0 =&rArr;
</p>
<p>&int; 1
</p>
<p>&minus;1
</p>
<p>&part;2c̃
</p>
<p>&part;y2
dy = &part; c̃
</p>
<p>&part;y
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>1
</p>
<p>&minus;1
= 0. (11.23)
</p>
<p>The remaining terms determine the evolution of the mean concentration,
</p>
<p>&part; c̄
</p>
<p>&part;t
+ ū &part; c̄
</p>
<p>&part;x
+ 1
</p>
<p>2
</p>
<p>&int; 1
</p>
<p>&minus;1
ũ
&part; c̃
</p>
<p>&part;x
dy = 1
</p>
<p>Pex
</p>
<p>&part;2c̄
</p>
<p>&part;x2
. (11.24)
</p>
<p>In the absence of the integral term, thiswould be a linear advection-diffusion equation
</p>
<p>for c̄(x, t). While the integral involves only perturbation terms, it is not valid to
</p>
<p>neglect it since while the mean of each deviation factor is zero, the average of a
</p>
<p>product is generally not equal to the product of the averages. Consequently, additional
</p>
<p>analysis on the properties of c̃ is needed.</p>
<p/>
</div>
<div class="page"><p/>
<p>11.3 Taylor Dispersion and Enhanced Diffusion 227
</p>
<p>Subtracting the averaged Eq. (11.24) from the full problem (11.22) we obtain an
</p>
<p>equation for c̃(x, y, t),
</p>
<p>&part; c̃
</p>
<p>&part;t
+ ũ &part; c̄
</p>
<p>&part;x
+ ū &part; c̃
</p>
<p>&part;x
+ ũ &part; c̃
</p>
<p>&part;x
&minus; 1
</p>
<p>2
</p>
<p>&int; 1
</p>
<p>&minus;1
ũ
&part; c̃
</p>
<p>&part;x
dy = 1
</p>
<p>Pex
</p>
<p>&part;2c̃
</p>
<p>&part;x2
+ 1
</p>
<p>Pey
</p>
<p>&part;2c̃
</p>
<p>&part;y2
. (11.25)
</p>
<p>Taylor&rsquo;s approach can then be expressed in terms of two assumptions: (i) the deviation
</p>
<p>is generally smaller than the mean, c̃ ≪ c̄, and (ii) the channel can be assumed to be
slender (similarly to problems in Chap.8) and the y-derivative terms will dominate
</p>
<p>the corresponding x-derivatives, &part;y ≫ &part;x . The leading order dominant balance of
the largest terms from the left and right sides of (11.25) then yields
</p>
<p>(
</p>
<p>1
3
&minus; y2
</p>
<p>) &part; c̄
</p>
<p>&part;x
= 1
</p>
<p>Pey
</p>
<p>&part;2c̃
</p>
<p>&part;y2
. (11.26)
</p>
<p>Since c̄ does not depend on y, we can integrate this equation once with respect to y
</p>
<p>to get
</p>
<p>&part; c̃
</p>
<p>&part;y
= Pey
</p>
<p>&part; c̄
</p>
<p>&part;x
</p>
<p>(
</p>
<p>1
3
</p>
<p>y &minus; 1
3
</p>
<p>y3 + A1(x, t)
)
</p>
<p>.
</p>
<p>Applying the no-flux boundary conditions (11.23) at y = &plusmn;1 determines the function
of integration to be A1(x, t) &equiv; 0, so we can proceed by integrating again to yield
</p>
<p>c̃ = Pey
&part; c̄
</p>
<p>&part;x
</p>
<p>(
</p>
<p>1
</p>
<p>6
y2 &minus; 1
</p>
<p>12
y4 + A2(x, t)
</p>
<p>)
</p>
<p>,
</p>
<p>where A2 is a second function of integration.Bydefinition, the perturbationmust have
</p>
<p>zeromean, namely,
&int; 1
&minus;1 c̄ dy = 0. Applying this condition determines A2 &equiv; &minus;7/180
</p>
<p>and hence we conclude that
</p>
<p>c̃ = Pey
&part; c̄
</p>
<p>&part;x
</p>
<p>(
</p>
<p>1
</p>
<p>6
y2 &minus; 1
</p>
<p>12
y4 &minus; 7
</p>
<p>180
</p>
<p>)
</p>
<p>. (11.27)
</p>
<p>We can now use this to calculate the integral term from (11.24),
</p>
<p>1
</p>
<p>2
</p>
<p>&int; 1
</p>
<p>&minus;1
ũ
&part; c̃
</p>
<p>&part;x
dy = &minus;8Pey
</p>
<p>945
</p>
<p>&part;2c̄
</p>
<p>&part;x2
.
</p>
<p>Consequently, we can complete our model equation for the evolution of the average
</p>
<p>density across the channel (11.24) as</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_8">http://dx.doi.org/10.1007/978-3-319-23042-9_8</a></div>
</div>
<div class="page"><p/>
<p>228 11 Reduced Models for PDE Problems
</p>
<p>&part; c̄
</p>
<p>&part;t
+ ū &part; c̄
</p>
<p>&part;x
= α &part;
</p>
<p>2c̄
</p>
<p>&part;x2
α = 1
</p>
<p>Pex
</p>
<p>(
</p>
<p>1+ 8
945
</p>
<p>U20H
2
</p>
<p>DxDy
</p>
<p>)
</p>
<p>, (11.28)
</p>
<p>where α is called the Taylor enhanced diffusion coefficient.
</p>
<p>In comparison with the original two-dimensional problem(11.19), we have
</p>
<p>obtained a reduced model. Equation (11.28) is a one-dimensional linear convection-
</p>
<p>diffusion equation. Considering the left side of the model, we can identify a convec-
</p>
<p>tive derivative with constant speed ū and in fact, making a change of variables with
</p>
<p>this wave speed, c̄(x, t) = F(x &minus; ūt, t), yields the classical diffusion equation for F ,
</p>
<p>&part;F
</p>
<p>&part;t
= α &part;
</p>
<p>2F
</p>
<p>&part;z2
. (11.29)
</p>
<p>As we have seen in Chap.5, this can be solved using similarity solutions, the one
</p>
<p>appropriate for a point source (consistent with initial conditions describing release
</p>
<p>of solute at a single location) is F(z, t) = M0 exp(&minus;z2/(4αt))/
&radic;
4παt and hence
</p>
<p>we can predict the large-time behaviour as
</p>
<p>c̄(x, t) &sim; M0&radic;
4παt
</p>
<p>exp
</p>
<p>(
</p>
<p>&minus; (x &minus; ūt)
2
</p>
<p>4αt
</p>
<p>)
</p>
<p>, (11.30)
</p>
<p>where M0 is the mass of solute (determined from the initial conditions).
</p>
<p>11.4 Further Directions
</p>
<p>In this chapter, we have sought to present approaches for obtaining information
</p>
<p>about the behaviour of solutions of PDEs that do not rely as heavily on perturbation
</p>
<p>methods as some of the previous chapters. The derivation of the Taylor dispersion
</p>
<p>results can be made more rigorous in terms of an asymptotic analysis similar to that
</p>
<p>used in Chap.8 (see Fowler [37, pp. 222&ndash;223] and [58]).
</p>
<p>11.5 Exercises
</p>
<p>11.1 In Chap.5 we derived the Gaussian self-similar solution of the heat equation
</p>
<p>ρr = ρxx . The most general form of this solution is
</p>
<p>ρ(x, t) = C1&radic;
4π(t + C2)
</p>
<p>exp
</p>
<p>(
</p>
<p>&minus; (x &minus; C3)
2
</p>
<p>4(t + C2)
</p>
<p>)
</p>
<p>,</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5">http://dx.doi.org/10.1007/978-3-319-23042-9_5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_8">http://dx.doi.org/10.1007/978-3-319-23042-9_8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5">http://dx.doi.org/10.1007/978-3-319-23042-9_5</a></div>
</div>
<div class="page"><p/>
<p>11.5 Exercises 229
</p>
<p>which contains three arbitrary constants. Evaluate the M0, M1, M2 moment integrals
</p>
<p>for this solution and determine C1,C2,C3 in terms of the results for (11.2a, 11.2b).
</p>
<p>This can be shown to select the t &rarr; &infin; asymptotic solution of the initial value
problem for the heat equation [108].
</p>
<p>11.2 Consider the convection-diffusion-reaction equation
</p>
<p>&part;ρ
</p>
<p>&part;t
+ 2 &part;ρ
</p>
<p>&part;x
= 3&part;
</p>
<p>2ρ
</p>
<p>&part;x2
+ 4ρ
</p>
<p>subject to the following conditions:
</p>
<p>(a) On thedomain&minus;&infin;&lt; x &lt;&infin;with initial conditionρ(x, 0) = e&minus;x2 andboundary
conditions ρ &rarr; 0 as |x | &rarr; &infin;. Define the moment integrals as
</p>
<p>Mn(t) =
&int; &infin;
</p>
<p>&minus;&infin;
xnρ(x, t) dx .
</p>
<p>Find M0(t), M1(t), M2(t).
</p>
<p>(b) For the same equation on a semi-infinite domain, 0&le; x &lt;&infin;, with initial condi-
tion ρ(x, 0) = e&minus;x and boundary conditions
</p>
<p>ρ(0, t) = 1, ρ(x &rarr; &infin;, t) = 0.
</p>
<p>Define the moment integrals as
</p>
<p>Mn(t) =
&int; &infin;
</p>
<p>0
</p>
<p>xnρ(x, t) dx .
</p>
<p>Write the differential equations and initial conditions for d M0/dt and d M1/dt .
</p>
<p>Write what additional information you would need in order to solve for M0(t)
</p>
<p>and M1(t).
</p>
<p>11.3 Consider the reaction-diffusion equation
</p>
<p>&part;ρ
</p>
<p>&part;t
= &part;
</p>
<p>2ρ
</p>
<p>&part;x2
&minus; ρ,
</p>
<p>on 0 &le; x &le; π with no-flux boundary conditions,
</p>
<p>&part;ρ
</p>
<p>&part;x
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>x=0
= 0, &part;ρ
</p>
<p>&part;x
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>∣
</p>
<p>x=π
= 0,
</p>
<p>and the initial condition, ρ(x, 0) = f (x).</p>
<p/>
</div>
<div class="page"><p/>
<p>230 11 Reduced Models for PDE Problems
</p>
<p>(a) Derive the problem for the evolution of the mass M0(t), but show that the equa-
</p>
<p>tions for the higher moments are not closed.
</p>
<p>(b) Show that separation of variables can be used to write the solution in the form
</p>
<p>ρ(x, t) =
&infin;
&sum;
</p>
<p>k=0
ake
</p>
<p>&minus;λk t cos(kx).
</p>
<p>Determine the coefficients ak in terms of the initial condition. Show that
</p>
<p>ρ(x, t) &sim; M0(t)
π
</p>
<p>as t &rarr; &infin;.
</p>
<p>(c) If the domain is changed to be&minus;&infin;&lt; x &lt;&infin;, and the first threemoment integrals
of f (x) converge, the exact solution can be written as
</p>
<p>ρ(x, t) = e
&minus;t
</p>
<p>&radic;
4π t
</p>
<p>&int; &infin;
</p>
<p>&minus;&infin;
f (x &minus; y)e&minus;y2/(4t) dy.
</p>
<p>Using results on integrals of theGaussian andbasic properties of double integrals,
</p>
<p>show that moments of this formula for the exact solution reproduce the results
</p>
<p>for M0, M1, M2 that can be obtained from using the PDE alone.
</p>
<p>11.4 The Von Foerster/McKendrick model describes the evolution of populations
</p>
<p>where age-distribution of individuals is of interest (called an age-structured pop-
</p>
<p>ulation model). Consider a population described by a density function ρ(a, t) of
</p>
<p>individuals with ages a &ge; 0 [74]. Let the density for 0 &lt; a &lt; &infin; evolve according
to the transport equation
</p>
<p>&part;ρ
</p>
<p>&part;t
+ &part;ρ
</p>
<p>&part;a
= &minus;2ρ (11.31)
</p>
<p>with ρ(a &rarr; &infin;) &rarr; 0 (describing that no-one lives forever).
(a) Suppose that the new births at any time are proportional to the total population
</p>
<p>size,
</p>
<p>ρ(0, t) = β
&int; &infin;
</p>
<p>0
</p>
<p>ρ(a, t) da.
</p>
<p>Show that the model can be reduced to a single ODE for the total population,
</p>
<p>M0(t) =
&int; &infin;
0 ρ(a, t) da.
</p>
<p>(b) One possible refinement of the birth condition could be to account for the fact
</p>
<p>that reproductive activity of individuals tends to decrease with increasing age.
</p>
<p>Consider the revised birth condition</p>
<p/>
</div>
<div class="page"><p/>
<p>11.5 Exercises 231
</p>
<p>ρ(0, t) =
&int; &infin;
</p>
<p>0
</p>
<p>e&minus;3aρ(a, t) da.
</p>
<p>Cushing [28] describes an approach that can reduce age-structured models to
</p>
<p>ODE systems in terms of weighted moment integrals. Show that the model with
</p>
<p>this birth condition can be reduced to a system of two ODEs for
</p>
<p>M0(t) =
&int; &infin;
</p>
<p>0
</p>
<p>ρ da, M1(t) =
&int; &infin;
</p>
<p>0
</p>
<p>e&minus;3aρ da.
</p>
<p>11.5 In Chap.5 a similarity solution of the porous medium equation was derived
</p>
<p>using the same approach that was used for the heat equation. To see how the method
</p>
<p>of moments applies to nonlinear equations, consider
</p>
<p>&part;ρ
</p>
<p>&part;t
= &part;
</p>
<p>&part;x
</p>
<p>(
</p>
<p>ρ3
&part;ρ
</p>
<p>&part;x
</p>
<p>)
</p>
<p>,
</p>
<p>with ρ &rarr; 0 for |x | &rarr; &infin; and initial condition ρ(x, 0) = f (x) &ge; 0 on &minus;&infin; &lt; x &lt;
&infin;.
(a) Show that M0, M1 are constant for this problem.
</p>
<p>(b) Show that while the moment model is not closed for M2, M2(t) is a strictly
</p>
<p>increasing function.
</p>
<p>11.6 While describing the spreading of the solute in the transverse direction depends
</p>
<p>on the presence of diffusion, justify the curved shape of the solute contours sketched
</p>
<p>in Fig. 11.2 using the method of characteristics for the PDE
</p>
<p>&part;c
</p>
<p>&part;t
+ (1&minus; y2) &part;c
</p>
<p>&part;x
= 0
</p>
<p>starting from the initial conditions
</p>
<p>c(x, y, t = 0) =
{
</p>
<p>1
4
&minus; (x2 + y2) x2 + y2 &le; 1
</p>
<p>4
</p>
<p>0 elsewhere
</p>
<p>Hint: Recall Exercise 2.8.
</p>
<p>11.7 Examine how the Taylor dispersion derivation changes for different velocity
</p>
<p>fields:
</p>
<p>(a) for the uniform &ldquo;plug flow&rdquo; U = U0 l̂,
(b) for linear shear flow U = U0(1&minus; Y/H)l̂,</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5">http://dx.doi.org/10.1007/978-3-319-23042-9_5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2">http://dx.doi.org/10.1007/978-3-319-23042-9_2</a></div>
</div>
<div class="page"><p/>
<p>232 11 Reduced Models for PDE Problems
</p>
<p>11.8 Derive the Taylor diffusion model for laminar axisymmetric flow in a circular
</p>
<p>pipe of radius R = R0:
</p>
<p>&part;C
</p>
<p>&part;T
+ U0
</p>
<p>(
</p>
<p>1&minus; R
2
</p>
<p>R20
</p>
<p>)
</p>
<p>&part;C
</p>
<p>&part;X
= Dx
</p>
<p>&part;2C
</p>
<p>&part;X2
+ Dr
</p>
<p>R
</p>
<p>&part;
</p>
<p>&part;R
</p>
<p>(
</p>
<p>R
&part;C
</p>
<p>&part;R
</p>
<p>)
</p>
<p>with no flux boundary conditions at the pipe wall.
</p>
<p>11.9 The key detail obtained in the derivation of the Taylor diffusion model (11.28)
</p>
<p>was the coefficient 8/945. The corresponding correction factor in Exercise11.8 or
</p>
<p>for other geometries will be different constants. For the problem of two-dimensional
</p>
<p>laminar flows (11.19), some books and articles may give the &ldquo;magic number&rdquo; 2/105
</p>
<p>instead. Show that this result does not clash with 8/945 given in the derivation above.
</p>
<p>Hint: Consider a different choice for the scaling of the flow velocity.</p>
<p/>
</div>
<div class="page"><p/>
<p>Part III
</p>
<p>Case Studies</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 12
</p>
<p>Modelling in Applied Fluid Dynamics
</p>
<p>This chapter differs substantially from the previous chapters in that we do not aim to
</p>
<p>explain any new methodologies here. Instead, we will make use the approaches devel-
</p>
<p>oped earlier to illustrate two case studies of how mathematical models of physical
</p>
<p>problems can be formulated and analysed.
</p>
<p>Our two examples applications come from problems in fluid dynamics, on air
</p>
<p>bearing sliders and wedge-rivulet flow. We begin by deriving a common core-model,
</p>
<p>called lubrication theory, that forms the basis for both applications. While the deriva-
</p>
<p>tion of lubrication theory draws extensively on the methods for long-wave asymptot-
</p>
<p>ics that were introduced in Chap. 8, we will not attempt to individually identify the
</p>
<p>many other connections between the material in this chapter and the methods given
</p>
<p>in the other earlier chapters. Having this background, readers should be comfortable
</p>
<p>with the presentations here, which are at levels that are typical of basic modelling
</p>
<p>in current applied research and case studies in more advanced books on modelling
</p>
<p>[27, 37, 96]. For further examples of case studies in mathematical modelling see
</p>
<p>[51, 53, 69].
</p>
<p>12.1 Lubrication Theory
</p>
<p>The Navier-Stokes equations comprise the fundamental continuum mechanics math-
</p>
<p>ematical model for the dynamics of fluids having viscosity (namely, realistic dissipa-
</p>
<p>tion or internal friction). These partial differential equations are conservation laws for
</p>
<p>mass and momentum of fluids and universally applicable. However, for a number of
</p>
<p>analytical and computational reasons, they can be very challenging to solve for most
</p>
<p>problems. Consequently, to make progress, most applied studies make use of spe-
</p>
<p>cific forms of their problems to further reduce the Navier-Stokes equations to more
</p>
<p>tractable models. For problems that involve slender layers of viscous fluids, lubri-
</p>
<p>cation models can be derived from the Navier-Stokes equations using asymptotics
</p>
<p>in terms of the dominance of viscous effects and the slenderness of the layer. Dat-
</p>
<p>&copy; Springer International Publishing Switzerland 2015
</p>
<p>T. Witelski and M. Bowen, Methods of Mathematical Modelling,
</p>
<p>Springer Undergraduate Mathematics Series, DOI 10.1007/978-3-319-23042-9_12
</p>
<p>235</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_8">http://dx.doi.org/10.1007/978-3-319-23042-9_8</a></div>
</div>
<div class="page"><p/>
<p>236 12 Modelling in Applied Fluid Dynamics
</p>
<p>ing back to the work of Osborne Reynolds (1842&ndash;1912), such models have become
</p>
<p>essential for advancing the analysis of problems from a diverse range of applications.
</p>
<p>We begin with the Navier-Stokes equations for a compressible viscous Newtonian
</p>
<p>fluid. Written in vector form, the continuity equation and momentum balance are
</p>
<p>&part;ρ̃
</p>
<p>&part;T
+ &nabla; &middot; (ρ̃V) = 0, ρ̃
</p>
<p>(
&part;V
</p>
<p>&part;T
+ V &middot; &nabla;V
</p>
<p>)
= &minus;&nabla;P + &micro;&nabla;2V, (12.1)
</p>
<p>where &micro; is the viscosity coefficient, ρ̃(X,Y,Z,T) is the fluid density, P(X,Y,Z,T)
</p>
<p>is the pressure, and the fluid velocity field is V(X,Y,Z,T) = (U,V,W). Expanded
out componentwise (12.1) yields a system of four coupled nonlinear PDEs,
</p>
<p>ρ̃T + (ρ̃U)X + (ρ̃V)Y + (ρ̃W)Z = 0, (12.2a)
ρ̃(UT + UUX + VUY + WUZ) = &minus;PX + &micro;(UXX + UYY + UZZ), (12.2b)
ρ̃(VT + UVX + VVY + WVZ) = &minus;PY + &micro;(VXX + VYY + VZZ), (12.2c)
</p>
<p>ρ̃(WT + UWX + VWY + WWZ) = &minus;PZ + &micro;(WXX + WYY + WZZ). (12.2d)
</p>
<p>For convenience, we simplify our presentation to the two-dimensional problem1
</p>
<p>where W &equiv; 0 and all properties are independent of Z (i.e. &part;Z &equiv; 0) and hence
consider the system,
</p>
<p>ρ̃T + (ρ̃U)X + (ρ̃V)Y = 0, (12.3a)
ρ̃(UT + UUX + VUY) = &minus;PX + &micro;(UXX + UYY), (12.3b)
ρ̃(VT + UVX + VVY) = &minus;PY + &micro;(VXX + VYY). (12.3c)
</p>
<p>We consider the dynamics of a thin layer of viscous fluid spreading on a flat solid
</p>
<p>surface, as shown in Fig. 12.1, with the average height given by H̄ and the lateral
</p>
<p>lengthscale given by L̄. We formally nondimensionalize using the scalings
</p>
<p>X = L̄x, Y = H̄y, T = T̄t, (12.4a)
</p>
<p>U = Ūu, V = V̄v, P = P̄ p, ρ̃ = ρ̄ρ. (12.4b)
</p>
<p>We go on to use the aspect ratio ε = H/L as an asymptotic parameter, ε &rarr; 0.
Applying the scalings to (12.3a) yields the nondimensional form
</p>
<p>&part;ρ
</p>
<p>&part;t
+
</p>
<p>(
ŪT̄
</p>
<p>L̄
</p>
<p>)
&part;
</p>
<p>&part;x
(ρu)+
</p>
<p>(
V̄T̄
</p>
<p>H̄
</p>
<p>)
&part;
</p>
<p>&part;y
(ρv) = 0.
</p>
<p>Conservation of mass is a fundamental property and it should hold exactly, inde-
</p>
<p>pendent of the geometry or any considerations of flow speed. Hence, independent
</p>
<p>of the final choice of characteristic scales, we should retain the general form given
</p>
<p>1The derivation for the full three-dimensional system follows analogously.</p>
<p/>
</div>
<div class="page"><p/>
<p>12.1 Lubrication Theory 237
</p>
<p>Fig. 12.1 A thin film of a
</p>
<p>viscous fluid coating a flat
</p>
<p>solid surface
</p>
<p>by (12.3a). This motivates selecting scales to make the continuity equation scale-
</p>
<p>invariant; namely we pick a convective timescale T = L/U and a vertical velocity
scale based on the horizontal velocity and the aspect ratio, V = εU, to yield the final
dimensionless equation,
</p>
<p>&part;ρ
</p>
<p>&part;t
+
</p>
<p>&part;
</p>
<p>&part;x
(ρu)+
</p>
<p>&part;
</p>
<p>&part;y
(ρv) = 0. (12.5)
</p>
<p>Turning to the momentum equations, using the scalings, the non-dimensional
</p>
<p>forms of (12.3b, 12.3c) are
</p>
<p>(
ε2
</p>
<p>ρ̄ŪL̄
</p>
<p>&micro;
</p>
<p>)
(ut + uux + vu y) = &minus;
</p>
<p>(
ε2
</p>
<p>P̄L̄
</p>
<p>&micro;Ū
</p>
<p>)
px + ε2uxx + uyy, (12.6a)
</p>
<p>(
ε2
</p>
<p>ρ̄ŪL̄
</p>
<p>&micro;
</p>
<p>)
(vt + uvx + vvy) = &minus;
</p>
<p>(
P̄L̄
</p>
<p>&micro;Ū
</p>
<p>)
py + ε2vxx + vyy. (12.6b)
</p>
<p>Apart from the aspect ratio, these equations contain two dimensionless parameters.
</p>
<p>The reduced Reynolds number gives the ratio of effects of inertial acceleration relative
</p>
<p>to viscous forces,
</p>
<p>R̃e = ε2
ρ̄ŪL̄
</p>
<p>&micro;
≪ 1, (12.7)
</p>
<p>To assert the dominance of viscous effects, we assume that this parameter is negligibly
</p>
<p>small.
</p>
<p>Consequently, (12.6a, 12.6b) reduces to
</p>
<p>0 = &minus;
(
ε2
</p>
<p>P̄L̄
</p>
<p>&micro;Ū
</p>
<p>)
px + ε2uxx + uyy, (12.8a)
</p>
<p>0 = &minus;
(
</p>
<p>P̄L̄
</p>
<p>&micro;Ū
</p>
<p>)
py + ε2vxx + vyy. (12.8b)</p>
<p/>
</div>
<div class="page"><p/>
<p>238 12 Modelling in Applied Fluid Dynamics
</p>
<p>We note that this reduction of the Navier Stokes equations (having removed the
</p>
<p>nonlinear inertial acceleration terms) is called the Stokes equations, and for the
</p>
<p>incompressible (constant density) case, their dimensional form is
</p>
<p>0 = &minus;&nabla;P + &micro;&nabla;2V, &nabla; &middot; V = 0. (12.9)
</p>
<p>The choice of the pressure scaling in (12.8a, 12.8b) remains. One option is to
</p>
<p>apply dominant balance to the y-momentum equation, yielding the derived scale
</p>
<p>P̄ = &micro;Ū/L̄ = O(1), which is called a viscous pressure scale since it balances
viscous and pressure-gradient effects. However it can be shown from the resulting
</p>
<p>leading order x-equation, u0yy = 0, that for many problems, this choice can be too
restrictive and may to lead to solutions that will not capture the full structure of
</p>
<p>the flow. The other option is dominant balance in the x-equation, yielding another
</p>
<p>version of the viscous pressure scale, P̄ = &micro;Ū/(ε2L̄) = O(ε&minus;2). This leads to the
leading order system,
</p>
<p>&part;p0
</p>
<p>&part;x
=
</p>
<p>&part;2u0
</p>
<p>&part;y2
,
</p>
<p>&part;p0
</p>
<p>&part;y
= 0. (12.10)
</p>
<p>The second equation determines that p0 is independent of y, namely p0 = p0(x, t).
Consequently the first equation can be integrated with respect to y to yield a parabolic
</p>
<p>form, sometimes called the Nusselt velocity profile,
</p>
<p>u0 = 12
&part;p0
</p>
<p>&part;x
y2 + C1 y + C2, (12.11)
</p>
<p>where C1,C2 are constants of integration with respect to y. These constants are
</p>
<p>determined by boundary conditions on the lateral velocity u at the top and bottom of
</p>
<p>the fluid layer for the particular problem at hand.
</p>
<p>For viscous fluids in contact with solids, the no-slip boundary condition states
</p>
<p>that the velocity of the fluid tangential to the solid must match that of the solid. In this
</p>
<p>problem the solid surface is y = 0, and the no-slip condition specifies that u0(0) = 0,
which determines C2 = 0 in (12.11). At the surface of the layer, y = h(x, t), if the
fluid were not subjected to any forces (surface stresses) then the lateral speed at the
</p>
<p>surface should be the same as the bulk of the fluid; the simplest form of the stress-free
</p>
<p>boundary condition is then
</p>
<p>du0
</p>
<p>dy
</p>
<p>∣∣∣∣
y=h
</p>
<p>= 0 =&rArr; C1 = &minus;p0x (x, t)h(x, t). (12.12)
</p>
<p>Consequently, we have determined that for films spreading on flat surfaces,
</p>
<p>u0(x, y, t) = 12 p0x (y
2 &minus; 2hy). (12.13)</p>
<p/>
</div>
<div class="page"><p/>
<p>12.1 Lubrication Theory 239
</p>
<p>To complete the derivation of the lubrication model, we return to the equation for
</p>
<p>the conservation of mass, (12.5), and integrate it over the thickness of the layer,
</p>
<p>&int; h
</p>
<p>0
</p>
<p>[
&part;ρ
</p>
<p>&part;t
+
</p>
<p>&part;
</p>
<p>&part;x
(ρu)+
</p>
<p>&part;
</p>
<p>&part;y
(ρv)
</p>
<p>]
dy = 0.
</p>
<p>The final term can be integrated directly to give a relation between the fluxes through
</p>
<p>the bottom and top of the layer,
</p>
<p>ρv
</p>
<p>∣∣∣∣
y=h
</p>
<p>y=0
= &minus;
</p>
<p>&int; h
</p>
<p>0
</p>
<p>[
&part;ρ
</p>
<p>&part;t
+
</p>
<p>&part;
</p>
<p>&part;x
(ρu)
</p>
<p>]
dy. (12.14)
</p>
<p>At y = 0, the fluid rests on an impermeable solid surface, so there should be no flux
through it, hence the no-flux boundary condition gives v(y = 0) = 0. At the top of
the layer, the fluid has a free boundary, and the vertical component of the velocity
</p>
<p>there should follow the motion of the surface y = h(x, t). Consider a particle on the
surface that is carried by the flow, having position (X (t), Y (t)), and remains on the
</p>
<p>surface for all times, so Y (t) = h(X (t), t). Then, using the chain rule and recalling
the Lagrangian description of the velocity, the rate of change of the vertical position
</p>
<p>of any point on a free boundary is given by
</p>
<p>dY
</p>
<p>dt
=
</p>
<p>&part;h
</p>
<p>&part;t
+
</p>
<p>&part;h
</p>
<p>&part;x
</p>
<p>dX
</p>
<p>dt
=&rArr; v
</p>
<p>∣∣∣∣
y=h
</p>
<p>=
&part;h
</p>
<p>&part;t
+ u
</p>
<p>&part;h
</p>
<p>&part;x
</p>
<p>∣∣∣∣
y=h
</p>
<p>, (12.15)
</p>
<p>which is called the kinematic boundary condition. Applying these two boundary
</p>
<p>conditions to (12.14) yields
</p>
<p>(
ρ
&part;h
</p>
<p>&part;t
+ ρu
</p>
<p>&part;h
</p>
<p>&part;x
</p>
<p>) ∣∣∣∣
y=h
</p>
<p>+
&int; h
</p>
<p>0
</p>
<p>[
&part;ρ
</p>
<p>&part;t
+
</p>
<p>&part;
</p>
<p>&part;x
(ρu)
</p>
<p>]
dy = 0.
</p>
<p>Applying Leibniz&rsquo;s rule (in reverse, with respect to x and t separately) then gives a
</p>
<p>transport equation describing conservation of mass
</p>
<p>&part;
</p>
<p>&part;t
</p>
<p>(&int; h
</p>
<p>0
</p>
<p>ρ dy
</p>
<p>)
+
</p>
<p>&part;
</p>
<p>&part;x
</p>
<p>(&int; h
</p>
<p>0
</p>
<p>ρu dy
</p>
<p>)
= 0. (12.16)
</p>
<p>If we take ρ = ρ(x, t) then this reduces to
</p>
<p>&part;(ρh)
</p>
<p>&part;t
+
</p>
<p>&part;
</p>
<p>&part;x
</p>
<p>(
ρ
</p>
<p>&int; h
</p>
<p>0
</p>
<p>u dy
</p>
<p>)
= 0. (12.17)</p>
<p/>
</div>
<div class="page"><p/>
<p>240 12 Modelling in Applied Fluid Dynamics
</p>
<p>Finally, using the velocity profile (12.13) to evaluate the integral yields
</p>
<p>&part;(ρh)
</p>
<p>&part;t
=
</p>
<p>1
</p>
<p>3
</p>
<p>&part;
</p>
<p>&part;x
</p>
<p>(
ρh3
</p>
<p>&part;p
</p>
<p>&part;x
</p>
<p>)
. (12.18)
</p>
<p>This is a form of the Reynolds equation that forms the basis of lubrication models
</p>
<p>in a wide array of applications involving free-surface thin film flows [25, 75, 79, 82]
</p>
<p>and fluid-structure interactions involving lubricating fluid layers [12, 46].
</p>
<p>12.2 Dynamics of an Air Bearing Slider
</p>
<p>One of the historical motivations for the development of lubrication theory has been
</p>
<p>the use of fluids as cushioning layers between moving surfaces&mdash;an everyday appli-
</p>
<p>cation is oil lubricating parts of an engine to allow relative motion without metal
</p>
<p>surfaces scratching against each other.
</p>
<p>Lubrication theory is also used in modern technology [12]&mdash;in computer hard
</p>
<p>disk drives, air acts as a lubricating gas layer separating the electronic read/write
</p>
<p>head from the rapidly rotating rigid data disks. To maximize the data density on the
</p>
<p>disk, the write head must be kept very close to the surface, and to maximize data
</p>
<p>access speed, the disk speed should be high. However both of these effects might
</p>
<p>suggest the system could be sensitive to any variations in disk speed, external forces
</p>
<p>and motion of the system, or variations of pressure that might lead the head to collide
</p>
<p>with the disk. Hence it is very important to have a model of the system that can guide
</p>
<p>the design process to configurations that are stable to perturbations.
</p>
<p>The one-dimensional2 version of the geometry we are considering is shown in
</p>
<p>Fig. 12.2. The read/write head, sometimes also called a slider bearing [79], has
</p>
<p>a particular length L̄ and has its lateral position fixed, but it is allowed to move
</p>
<p>vertically. The disk is a flat surface (Y = 0) moving horizontally at local speed Ū.
The motion of the disk will generate a flow of air under the slider due to the no-slip
</p>
<p>boundary condition on the gas. This flow will generate a lift force on the slider that
</p>
<p>will balance against the weight of the slider and any other applied downward forces.
</p>
<p>The desired average gap height H̄ sets a vertical lengthscale. The gap height between
</p>
<p>the disk and slider surfaces is given by
</p>
<p>H(X,T) = A(T)+ S(X), (12.19)
</p>
<p>where A is the vertical position of the leading edge of the slider and S(X) gives the
</p>
<p>shape of the slider&rsquo;s lower surface, with S(0) = 0. Outside of the region under the
slider, the air pressure will be assumed to be the usual atmospheric pressure, Patm.
</p>
<p>2Referring to the number of lateral dimensions.</p>
<p/>
</div>
<div class="page"><p/>
<p>12.2 Dynamics of an Air Bearing Slider 241
</p>
<p>Fig. 12.2 The geometry of the problem for an air bearing slider. Lubrication theory can be applied
</p>
<p>to model the air flow in the thin gap between the moving disk and slider surfaces
</p>
<p>Under the assumption that the reduced Reynolds number is small, (12.7), and that
</p>
<p>the aspect ratio of the gap is small, ε &equiv; H̄/L̄ ≪ 1, lubrication theory can be applied.
Written in dimensional form, the parabolic velocity profile (12.11) in the gap is
</p>
<p>U =
1
</p>
<p>2&micro;
</p>
<p>&part;P
</p>
<p>&part;X
Y
</p>
<p>2 + C1Y + C2. (12.20)
</p>
<p>The scalings and boundary conditions appropriate to this problem must be applied
</p>
<p>to this general form. At the disk and slider surfaces, no-slip boundary conditions
</p>
<p>impose the lateral speeds on the gas flow,
</p>
<p>U(Y = 0) = Ū, U(Y = H) = 0.
</p>
<p>These conditions select the constants of integration in (12.20) to yield
</p>
<p>U =
1
</p>
<p>2&micro;
</p>
<p>&part;P
</p>
<p>&part;X
(Y2 &minus; HY)+ Ū
</p>
<p>(
1 &minus;
</p>
<p>Y
</p>
<p>H
</p>
<p>)
, (12.21)
</p>
<p>where we have separated the contributions due to the pressure-gradient driven
</p>
<p>Poiseuille flow term and the linear shear-flow Couette flow term. The next step
</p>
<p>is to use this velocity profile in the equation of conservation of mass to derive the
</p>
<p>appropriate form of the Reynolds equation for this problem.
</p>
<p>While Eq. (12.16) was derived under a different type of boundary condition on the
</p>
<p>upper surface of the fluid layer, it can be shown that the same equation is obtained
</p>
<p>when the kinematic boundary condition is replaced by a no-flux condition appropriate
</p>
<p>to the interface with the slider surface at Y = H [46]. This could be expected from
physical considerations of (12.17) as a transport equation; since the mass of air in
</p>
<p>any column, ρ̃H, is conserved, its rate of change can only be due to transport to other
</p>
<p>positions in the gap by the flux. Consequently, we obtain the dimensional equation
</p>
<p>&part;(ρ̃H)
</p>
<p>&part;T
+
</p>
<p>Ū
</p>
<p>2
</p>
<p>&part;(ρ̃H)
</p>
<p>&part;X
=
</p>
<p>1
</p>
<p>12&micro;
</p>
<p>&part;
</p>
<p>&part;X
</p>
<p>(
ρ̃H3
</p>
<p>&part;P
</p>
<p>&part;X
</p>
<p>)
. (12.22)</p>
<p/>
</div>
<div class="page"><p/>
<p>242 12 Modelling in Applied Fluid Dynamics
</p>
<p>To nondimensionalize this equation, we need to select characteristic scales. For the
</p>
<p>velocity scale, it is natural to use the imposed disk speed Ū. For the lateral length
</p>
<p>scale, the length of the slider, L̄, is a convenient choice; the derived convective
</p>
<p>timescale is then T̄ = L̄/Ū. In the vertical direction, the reference height H̄ can
be used. Equation (12.22) is linear with respect to ρ̃, so whatever the choice of the
</p>
<p>characteristic density, it will scale out. The boundary conditions on the pressure at the
</p>
<p>edges of the slider give an imposed pressure scale, P̄ = Patm. Using these scalings
in (12.4) and writing H = H̄h we obtain the dimensionless equation [30, 46]
</p>
<p>&part;(ρh)
</p>
<p>&part;t
+ 1
</p>
<p>2
</p>
<p>&part;(ρh)
</p>
<p>&part;x
=
</p>
<p>1
</p>
<p>Λ
</p>
<p>&part;
</p>
<p>&part;x
</p>
<p>(
ρh3
</p>
<p>&part;p
</p>
<p>&part;x
</p>
<p>)
,
</p>
<p>containing one dimensionless parameter, called the bearing number,
</p>
<p>Λ =
12&micro;L̄Ū
</p>
<p>PatmH̄2
, (12.23)
</p>
<p>which gives the ratio of the relative effects of the convective (Couette) to diffusive
</p>
<p>(Poiseuille) terms, analogous to a Peclet number. For applications of interest, small
</p>
<p>gap heights, small aspect ratios and high speeds all point to large bearing numbers;
</p>
<p>hence we define δ = 1/Λ as a small parameter.
To complete the formulation of the model, we need to specify a relation between
</p>
<p>the pressure and the gas density. The simplest choice for the equation of state is the
</p>
<p>ideal gas law, which states that the pressure is proportional to the product of the
</p>
<p>density with the temperature. Assuming the temperature to be held fixed, this gives
</p>
<p>ρ = kp and reduces the Reynolds equation to a PDE for the evolution of the product
p(x, t)h(x, t),
</p>
<p>&part;(ph)
</p>
<p>&part;t
+ 1
</p>
<p>2
</p>
<p>&part;(ph)
</p>
<p>&part;x
= δ
</p>
<p>&part;
</p>
<p>&part;x
</p>
<p>(
ph3
</p>
<p>&part;p
</p>
<p>&part;x
</p>
<p>)
, (12.24a)
</p>
<p>on the domain 0 &le; x &le; 1 and is subject to the boundary conditions on the pressure,
</p>
<p>p(0, t) = 1, p(1, t) = 1. (12.24b)
</p>
<p>For δ &rarr; 0, this is a singularly perturbed boundary value problem and can be shown
to generate a boundary layer in the pressure at x&lowast; = 1, the trailing edge of the slider.
On the rest of the domain, 0 &le; x &lt; 1, we can approximate the solution by the
solution of the leading order outer problem,
</p>
<p>&part;(p0h)
</p>
<p>&part;t
+ 1
</p>
<p>2
</p>
<p>&part;(p0h)
</p>
<p>&part;x
= 0. (12.25)
</p>
<p>This is a linear advection equation and yields the solution as a traveling wave with
</p>
<p>speed one half, F(x &minus; 1
2
</p>
<p>t), which can also be expressed as</p>
<p/>
</div>
<div class="page"><p/>
<p>12.2 Dynamics of an Air Bearing Slider 243
</p>
<p>p0(x, t)h(x, t) = f (t &minus; 2x), (12.26)
</p>
<p>for some choice of function f (s). Applying the boundary condition on the pressure
</p>
<p>at x = 0 and evaluating the gap height there, from (12.19), h(0, t) = a(t), and
we determine f (t) &equiv; a(t). Consequently the solution of this signaling-type wave
problem for the pressure can be expressed as
</p>
<p>p0(x, t) =
a(t &minus; 2x)
</p>
<p>a(t)+ s(x)
, (12.27)
</p>
<p>from p0 = f/h. We can now use this representation of the pressure to return to the
primary question of the stability and dynamics of the slider.
</p>
<p>The motion of the slider is characterized by the height of the leading edge,
</p>
<p>y = a(t), hence we seek an evolution equation for a(t). This will be provided
by a force balance in the vertical direction. As described above, the air flow gener-
</p>
<p>ates a lift force on the slider, this is given by the integral of the excess pressure over
</p>
<p>the domain of the slider,
</p>
<p>FL(t) =
&int; 1
</p>
<p>0
</p>
<p>(p(x, t)&minus; 1) dx.
</p>
<p>This balances against the downward applied load imposed on the slider by structural
</p>
<p>constraints, FS to yield the force balance equation
</p>
<p>m
d2a
</p>
<p>dt2
=
</p>
<p>&int; 1
</p>
<p>0
</p>
<p>a(t &minus; 2x)
a(t)+ s(x)
</p>
<p>dx &minus; (FS + 1), (12.28)
</p>
<p>where m is the scaled mass of the slider. We note that by neglecting the trailing edge
</p>
<p>boundary layer in the pressure, we only make a small error, O(Λ&minus;1) in calculating
the lift integral.
</p>
<p>We can obtain a time-independent steady-state, a = ā, by solving an algebraic
equation,
</p>
<p>ā
</p>
<p>&int; 1
</p>
<p>0
</p>
<p>dx
</p>
<p>ā + s(x)
= FS + 1.
</p>
<p>Then, we can examine the linear stability of this steady solution to small deviations
</p>
<p>by assuming a perturbed solution, a(t) = ā + σeλt , for σ &rarr; 0. Substituting this
form into (12.28) yields an equation for the exponential growth rate λ at O(σ ),
</p>
<p>mλ2 =
&int; 1
</p>
<p>0
</p>
<p>e&minus;2λx
</p>
<p>ā + s(x)
dx &minus;
</p>
<p>&int; 1
</p>
<p>0
</p>
<p>ā
</p>
<p>(ā + s(x))2
dx. (12.29)
</p>
<p>If the governing equation for a(t) were an autonomous ODE, then λ would be given
</p>
<p>by the roots of a characteristic polynomial. However due to the unusual shifted depen-</p>
<p/>
</div>
<div class="page"><p/>
<p>244 12 Modelling in Applied Fluid Dynamics
</p>
<p>dence on the solution in the integral, (12.28) can be related to a delay-differential
</p>
<p>equation and yields a more challenging transcendental equation for the linear stability
</p>
<p>analysis. Careful consideration of this problem was explored in [109].
</p>
<p>12.3 Rivulets in a Wedge Geometry
</p>
<p>In the previous section, we considered a scenario where the substrate was uniformly
</p>
<p>flat. Here, we investigate a lubrication-type problem for a rivulet (slender thread)
</p>
<p>of viscous fluid constrained within a wedge geometry3 (see Fig. 12.3). In particular,
</p>
<p>we will study the so-called large-time dynamics of the problem using asymptotic
</p>
<p>approximations and self-similar solutions. As well as being a well-observed phys-
</p>
<p>ical phenomena, interesting in its own right, the results that we obtain also have
</p>
<p>application to the study of foam drainage, where the flow takes place within the &ldquo;tri-
</p>
<p>angular&rdquo; shaped region of the Plateau borders4 (see [103] for a general discussion
</p>
<p>of the dynamics of foams).
</p>
<p>We shall take X to represent the distance along the wedge, with Y as the vertical
</p>
<p>upward distance from the base of the wedge, and Z as the transverse distance from
</p>
<p>the centreline of the wedge (along with the respective velocities U, V and W).
</p>
<p>We begin with the dimensional Navier-Stokes equations in three-dimensions
</p>
<p>(12.2); the dimensional density ρ̃ is taken to be constant. We apply the nondimen-
</p>
<p>sionalisation
</p>
<p>X = L̄x, Y = H̄y, Z = H̄z, T = T̄t, (12.30a)
</p>
<p>U = V̄u/ε, V = V̄v, W = V̄w, P = P̄ p, (12.30b)
</p>
<p>where H̄ is a typical fluid depth and V̄ = ε2γ /&micro; is a representative velocity scale
(here, γ is the coefficient of surface tension for the free surface of the liquid). The
</p>
<p>expressions (12.30) imply that we consider the magnitude of the flows in the vertical
</p>
<p>and transverse directions to be of the same order, and (as in the previous section) the
</p>
<p>aspect ratio ε = H/L ≪ 1. After substitution and collecting terms in orders of ε, the
leading order equations are found to be
</p>
<p>&part;p
</p>
<p>&part;x
=
</p>
<p>&part;2u
</p>
<p>&part;y2
+
</p>
<p>&part;2u
</p>
<p>&part;z2
,
</p>
<p>&part;p
</p>
<p>&part;y
= 0,
</p>
<p>&part;p
</p>
<p>&part;z
= 0, (12.31)
</p>
<p>being a reduced version of the Stokes equations (12.9). The last two equations of
</p>
<p>(12.31) show that to leading order the pressure field is independent of both y and z,
</p>
<p>and hence p = P(x, t). Furthermore, geometric considerations can be used to show
</p>
<p>3This analysis is based on the paper [16] to which we refer the interested reader for more details.
4The sides of a Plateau border are actually circular arcs and there is no free-surface, but the model
</p>
<p>equations that we derive here are still applicable. This is an example of how modelling and inves-
</p>
<p>tigating one problem can also provide useful information for other related problems.</p>
<p/>
</div>
<div class="page"><p/>
<p>12.3 Rivulets in a Wedge Geometry 245
</p>
<p>Fig. 12.3 Schematic of the problem geometry
</p>
<p>that P &prop; A&minus;1/2, where A(x, t) is the cross-sectional area of the rivulet at location
x and time t . The first equation of (12.31) can be solved subject to no-slip boundary
</p>
<p>conditions on the substrate and pressure jump conditions across the free surface of
</p>
<p>the liquid to yield u &prop; A2&part;P/&part;x .
The conservation of mass result for the cross-sectional area A(x, t) takes the form
</p>
<p>&part;A
</p>
<p>&part;t
+
</p>
<p>&part;
</p>
<p>&part;z
</p>
<p>⎛
⎝
&int;
</p>
<p>D
</p>
<p>u dy dz
</p>
<p>⎞
⎠ = 0, (12.32)
</p>
<p>where D is the area of the (y, z) plane occupied by liquid at fixed x and t . Substituting
</p>
<p>in the relevant expressions for u and P from above consequently results in a PDE
</p>
<p>for the evolution of A(x, t) which takes the (porous-medium-equation-type) form
</p>
<p>&part;A
</p>
<p>&part;t
=
</p>
<p>&part;
</p>
<p>&part;x
</p>
<p>(
A1/2
</p>
<p>&part;A
</p>
<p>&part;x
</p>
<p>)
, 0 &le; x &lt; &infin; (12.33)
</p>
<p>and is the basic equation that we will further analyse. For initial data, we impose
</p>
<p>A(x, 0) =
{
</p>
<p>M 0 &le; x &lt; 1,
0 x &ge; 1,
</p>
<p>(12.34)
</p>
<p>corresponding to a constant cross-section of fluid over 0 &le; x &lt; 1 with a dry wedge
for x &gt; 1; the initial volume of liquid is consequently also given by M .
</p>
<p>Once the liquid is in motion (t &gt; 0), there will be a moving free-boundary
</p>
<p>x = s(t) (with A &equiv; 0 for x &gt; s(t)), on which we impose the physically sensible
conditions A = 0 (zero height) and A1/2 Ax = 0 (zero flux across the interface). At
x = 0, we also impose zero flux (corresponding to a solid wall), so that the total
mass of liquid in the wedge is conserved for all time, i.e.</p>
<p/>
</div>
<div class="page"><p/>
<p>246 12 Modelling in Applied Fluid Dynamics
</p>
<p>d
</p>
<p>dt
</p>
<p>&int; s(t)
</p>
<p>0
</p>
<p>A(x, t) dx = 0 =&rArr;
&int; s(t)
</p>
<p>0
</p>
<p>A(x, t) dx =
&int; s(t)
</p>
<p>0
</p>
<p>A(x, 0) dx = M.
(12.35)
</p>
<p>The nonlinear diffusion equation (12.33) coupled with the conservation law
</p>
<p>(12.35) admits a similarity solution
</p>
<p>A = t&minus;2/5 f (η), η =
x
</p>
<p>t2/5
, (12.36)
</p>
<p>where f (η) satisfies
</p>
<p>&minus;
2
</p>
<p>5
</p>
<p>(
f + η
</p>
<p>d f
</p>
<p>dη
</p>
<p>)
=
</p>
<p>d
</p>
<p>dη
</p>
<p>(
f 1/2
</p>
<p>d f
</p>
<p>dη
</p>
<p>)
,
</p>
<p>with solution
</p>
<p>f (η) =
1
</p>
<p>100
(η20 &minus; η2)
</p>
<p>2
</p>
<p>+; (12.37)
</p>
<p>the subscripted plus sign here denotes that we are only interested in the non-negative
</p>
<p>part of the solution, with the moving interface x = s(t) corresponding to η = η0 in
terms of the similarity variables. Of course, (12.36) is singular in the limit t &rarr; 0+
and so cannot satisfy the initial condition (12.35). However, it is well-known that
</p>
<p>similarity solutions often act as large-time attractors for the dynamics of nonlinear
</p>
<p>diffusion equations and so we can expect A(x, t) to approach (12.36) and (12.37) at
</p>
<p>large times.
</p>
<p>12.3.1 Imbibition in a Vertical Wedge
</p>
<p>Suppose now that we orient the wedge so that it is vertical, with the base located
</p>
<p>at x = 0. In such a geometry, we can no longer neglect gravity and it will be the
competing effects of gravity (acting downwards) and capillarity (acting upwards)
</p>
<p>that drives the motion of the fluid.
</p>
<p>Taking gravity to act equally everywhere on the fluid leads to a convective flow in
</p>
<p>the downward direction that requires the evolution Eq. (12.33) to be adjusted to read
</p>
<p>&part;A
</p>
<p>&part;t
&minus; 2A
</p>
<p>&part;A
</p>
<p>&part;x
=
</p>
<p>&part;
</p>
<p>&part;x
</p>
<p>(
A1/2
</p>
<p>&part;A
</p>
<p>&part;x
</p>
<p>)
, 0 &le; x &lt; &infin;; (12.38)
</p>
<p>we note that the left-hand-side terms of (12.38) correspond to a quasilinear convection
</p>
<p>equation that can be tackled by the method of characteristics (starting from the initial
</p>
<p>data (12.34)) and shown to have smooth solutions for all t &gt; 0.</p>
<p/>
</div>
<div class="page"><p/>
<p>12.3 Rivulets in a Wedge Geometry 247
</p>
<p>Physically, we expect the amount of liquid that can be pulled up the wedge by
</p>
<p>capillarity to be small compared to the bulk mass. We therefore assume that the
</p>
<p>solution in the latter region will effectively be a steady-state solution of (12.38) and
</p>
<p>consequently find
</p>
<p>A =
4
</p>
<p>(x + x0)2
for x = O(1). (12.39)
</p>
<p>The value of x0 is set (to leading order) by the mass constraint (12.35), by which we
</p>
<p>calculate x0 = 4/M . The steady-state inner solution (12.39) will match to the outer
solution governed by capillary action.
</p>
<p>In the capillary flow region, we cannot neglect the time-dependence in (12.38).
</p>
<p>We do not attempt to derive an exact solution of (12.38), but note that it admits a
</p>
<p>similarity solution of the form
</p>
<p>A = t&minus;2/3g(&micro;), &micro; =
x
</p>
<p>t1/3
, (12.40)
</p>
<p>with g(&micro;) satisfying
</p>
<p>&minus;
2
</p>
<p>3
g &minus;
</p>
<p>1
</p>
<p>3
&micro;g&micro; =
</p>
<p>(
g1/2g&micro; &minus; g2
</p>
<p>)
&micro;
.
</p>
<p>Close to x = s(t), with s(t) = &micro;0t1/3 in terms of the similarity variables,
</p>
<p>g &sim;
&micro;20
</p>
<p>36
(&micro;0 &minus; &micro;)2 as &micro; &rarr; &micro;&minus;0 ,
</p>
<p>so that the solution has zero contact angle at &micro; = &micro;0. As &micro; &rarr; 0+ we must match
with (12.39) as x &rarr; &infin; and this requires that
</p>
<p>g &sim;
4
</p>
<p>&micro;2
as &micro; &rarr; 0+.
</p>
<p>A schematic of the overall (large-time) solution structure is shown in Fig. 12.4.
</p>
<p>Fig. 12.4 Schematic of the
</p>
<p>large-time solution for
</p>
<p>gravity opposing capillarity
</p>
<p>based on the solution of
</p>
<p>Eq. (12.38)</p>
<p/>
</div>
<div class="page"><p/>
<p>248 12 Modelling in Applied Fluid Dynamics
</p>
<p>12.3.2 Draining in a Vertical Wedge
</p>
<p>In this scenario, x = 0 is taken to be at the top of the wedge, with the liquid moving
downwards (again starting from (12.34)) under the now combined effects of gravity
</p>
<p>and capillarity. The evolution equation takes the same form as (12.38), except for a
</p>
<p>different sign on the convective term
</p>
<p>&part;A
</p>
<p>&part;t
+ 2A
</p>
<p>&part;A
</p>
<p>&part;x
=
</p>
<p>&part;
</p>
<p>&part;x
</p>
<p>(
A1/2
</p>
<p>&part;A
</p>
<p>&part;x
</p>
<p>)
, 0 &le; x &lt; &infin;; (12.41)
</p>
<p>notably, in contrast to the case of imbibition, the quasilinear equation allows shocks
</p>
<p>to form and we will observe this phenomena in the large time solution to (12.41).
</p>
<p>Away from x = 0, the dynamics of the (outer region) solution are primarily
controlled by the effects of gravity and the reduced PDE is consequently given by
</p>
<p>&part;A
</p>
<p>&part;t
&sim; &minus;2A
</p>
<p>&part;A
</p>
<p>&part;x
, (12.42)
</p>
<p>with a solution of self-similar form
</p>
<p>A = t&minus;1/2h(v), v =
x
</p>
<p>t1/2
. (12.43)
</p>
<p>Here, h(v) satisfies
1
</p>
<p>2
</p>
<p>d
</p>
<p>dv
(hv) =
</p>
<p>d
</p>
<p>dv
(h2),
</p>
<p>so that
</p>
<p>h =
{
</p>
<p>1
2
</p>
<p>v 0 &lt; v &lt; v0,
</p>
<p>0 v &gt; v0.
(12.44)
</p>
<p>Standard matching arguments imply that A &sim; z/2t as v &rarr; 0+, while conservation
of mass (12.35) determines the shock location v0 = 2
</p>
<p>&radic;
M . Across the shock, the
</p>
<p>effects of capillarity are important and smooth the solution over a narrow interior
</p>
<p>layer with scalings
</p>
<p>x = s(t)+ t1/4ξ, s &sim; v0t1/2, A &sim; t&minus;1/2Φ(ξ).
</p>
<p>As a result, we find
</p>
<p>Φ(ξ) =
v0
</p>
<p>2
tanh2
</p>
<p>(
1
</p>
<p>2
</p>
<p>&radic;
v0
</p>
<p>2
ξ
</p>
<p>)
, (12.45)
</p>
<p>which corresponds to a travelling wave solution of (12.41).</p>
<p/>
</div>
<div class="page"><p/>
<p>12.3 Rivulets in a Wedge Geometry 249
</p>
<p>Fig. 12.5 Schematic of the large-time solution for gravity assisting capillarity based on the solution
</p>
<p>of Eq. (12.41)
</p>
<p>The (inner solution) behaviour close to x = 0 is again given by (12.40), with
g &sim; &micro;/2 as &micro; &rarr; &infin; in order to match with the outer solution. Finally, as u &rarr; 0+,
we have g &sim; g0 + g3/20 v as a consequence of the zero-flux boundary condition
imposed at x = 0; numerical calculations yield g0 &asymp; 0.5885. The entire large-time
solution structure is illustrated schematically in Fig. 12.5.
</p>
<p>A number of extensions of this problem are possible, such as the introduction
</p>
<p>of an influx of liquid at x = 0 and the investigation of different geometries for the
wedge shape (see [16] for a detailed description of the previous analysis and further
</p>
<p>extensions).</p>
<p/>
</div>
<div class="page"><p/>
<p>Epilogue
</p>
<p>The approaches andmethods described in this book have long histories and have been
</p>
<p>employed to make major advances in research on many challenging fundamental
</p>
<p>problems. These approaches to modelling and problem reduction still form the basis
</p>
<p>for a great deal of current research on more advanced problems. As one example, the
</p>
<p>quasi-steady state assumption from Chap.10 is used as the basis for handling large
</p>
<p>systems of complex bio-chemical reactions.
</p>
<p>Current directions in modelling of physical systems have also put a new focus on
</p>
<p>complex systems [86] and multiscale modelling [33]. These are models that seek to
</p>
<p>constructively incorporate layers of understanding that come from different physi-
</p>
<p>cal scales, often referred to as micro-, meso-, and macro-scales. Examples include
</p>
<p>(i) improved models for materials properties in continuum model settings that are
</p>
<p>derived from microscale models at the atomic scale and (ii) systems biology models
</p>
<p>of organs or entire physiological systems building frommodels of cells and biochem-
</p>
<p>ical reactions.
</p>
<p>One ofmany active forums for current work onmodelling is the journalMultiscale
</p>
<p>Modeling and Simulation published by the Society of Industrial and Applied Math-
</p>
<p>ematics (SIAM). Many multiscale models make use of asymptotic approaches1 to
</p>
<p>implement matching of descriptions at different scales in combination with numer-
</p>
<p>ical computations to make progress on fundamental questions in a broad array of
</p>
<p>application areas. We hope that this book has given readers a strong starting point
</p>
<p>for moving on to such advanced and challenging problems.
</p>
<p>TW and MB
</p>
<p>1Including boundary layers and other extensions of multiple scales, like averaging [73, 102] and
</p>
<p>homogenisation theory [49].
</p>
<p>&copy; Springer International Publishing Switzerland 2015
</p>
<p>T. Witelski and M. Bowen, Methods of Mathematical Modelling,
</p>
<p>Springer Undergraduate Mathematics Series, DOI 10.1007/978-3-319-23042-9
</p>
<p>251</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_10">http://dx.doi.org/10.1007/978-3-319-23042-9_10</a></div>
</div>
<div class="page"><p/>
<p>Appendix A
</p>
<p>Trigonometric Identities and Fourier Series
</p>
<p>A brief summary of useful trigonometric identities:
</p>
<p>sin2 x + cos2 x = 1
</p>
<p>sin x cos y + cos x sin y = sin(x + y) cos x cos y &minus; sin x sin y = cos(x + y)
</p>
<p>sin x cos y = 1
2
(sin(x &minus; y)+ sin(x + y)) sin x sin y = 1
</p>
<p>2
(cos(x &minus; y)&minus; cos(x + y))
</p>
<p>cos x cos y = 1
2
(cos(x &minus; y)+ cos(x + y))
</p>
<p>sin(2t) = 2 sin t cos t cos(2t) = 2 cos2 t &minus; 1
</p>
<p>sin2 t =
1&minus; cos 2t
</p>
<p>2
cos2 t =
</p>
<p>1+ cos 2t
2
</p>
<p>sin3 t =
3 sin t &minus; sin 3t
</p>
<p>4
cos3 t =
</p>
<p>3 cos t + cos 3t
4
</p>
<p>sin2 t cos t =
cos t &minus; cos 3t
</p>
<p>4
sin t cos2 t =
</p>
<p>sin t + sin 3t
4
</p>
<p>All trigonometric identities can be derived from successive applications of the for-
</p>
<p>mulas for the sum or difference of angles (x &plusmn; y) and further algebra.
The need for these identities can be eliminated by using Euler&rsquo;s formula, eiθ =
</p>
<p>cos θ + i sin θ , to replace cosine and sine by their complex representations,
</p>
<p>cos t = Re(eit) =
eit + e&minus;it
</p>
<p>2
sin t = Im(eit) =
</p>
<p>eit &minus; e&minus;it
</p>
<p>2i
,
</p>
<p>then all results follow from algebra and re-grouping e&plusmn;int to determine coefficients
of cos(nt) and sin(nt) terms.
</p>
<p>&copy; Springer International Publishing Switzerland 2015
</p>
<p>T. Witelski and M. Bowen, Methods of Mathematical Modelling,
</p>
<p>Springer Undergraduate Mathematics Series, DOI 10.1007/978-3-319-23042-9
</p>
<p>253</p>
<p/>
</div>
<div class="page"><p/>
<p>254 Appendix A: Trigonometric Identities and Fourier Series
</p>
<p>A.1 Trigonometric Fourier Series
</p>
<p>Analogous to the way that every nth order polynomial can be expressed as a finite
</p>
<p>Taylor polynomial, the trigonometric identities allow every nth order product of sines
</p>
<p>and cosines to be written as a sum of sines and cosines. Fourier series generalise this
</p>
<p>to represent all integrable periodic functions in terms of an infinite series of sines
</p>
<p>and cosines.
</p>
<p>Expansions of given periodic functions, f (x) on &minus;L &lt; x &lt; L can be written as
</p>
<p>f (x) =
a0
</p>
<p>2
+
</p>
<p>&infin;
&sum;
</p>
<p>n=1
an cos(
</p>
<p>nπ
L
</p>
<p>x)+
&infin;
&sum;
</p>
<p>n=1
bn sin(
</p>
<p>nπ
L
</p>
<p>x) (A.1a)
</p>
<p>where for n = 0, 1, 2, . . .
</p>
<p>an =
1
</p>
<p>L
</p>
<p>&int; L
</p>
<p>&minus;L
f (x) cos( nπ
</p>
<p>L
x) dx bn =
</p>
<p>1
</p>
<p>L
</p>
<p>&int; L
</p>
<p>&minus;L
f (x) sin( nπ
</p>
<p>L
x) dx. (A.1b)
</p>
<p>The Fourier series for a function f will converge to the value of the function at all
</p>
<p>points where f (x) is continuous.
</p>
<p>The Fourier expansion can also be written in complex form as
</p>
<p>f (x) =
&infin;
&sum;
</p>
<p>n=&minus;&infin;
cne
</p>
<p>inπx/L cn =
1
</p>
<p>2L
</p>
<p>&int; L
</p>
<p>&minus;L
f (x)e&minus;inπx/L dx. (A.2)
</p>
<p>The Fourier cosine series for a function F(x) given on 0 &le; x &lt; L can be derived
from the general Fourier series by defining f (x) to be the even extension of F(x) :
</p>
<p>f (x) =
{
</p>
<p>F(x) 0 &le; x &lt; L,
F(&minus;x) &minus;L &lt; x &le; 0
</p>
<p>F(x) =
a0
</p>
<p>2
+
</p>
<p>&infin;
&sum;
</p>
<p>n=1
an cos(
</p>
<p>nπ
L
</p>
<p>x) an =
2
</p>
<p>L
</p>
<p>&int; L
</p>
<p>0
</p>
<p>F(x) cos( nπ
L
</p>
<p>x) dx. (A.3)
</p>
<p>Similarly, the Fourier sine series for a function F(x) given on 0 &le; x &lt; L can be
derived from the general Fourier series by defining f (x) to be the odd extension of
</p>
<p>F(x) :
</p>
<p>f (x) =
{
</p>
<p>F(x) 0 &le; x &lt; L,
&minus;F(&minus;x) &minus;L &lt; x &le; 0
</p>
<p>F(x) =
&infin;
&sum;
</p>
<p>n=1
bn sin(
</p>
<p>nπ
L
</p>
<p>x) bn =
2
</p>
<p>L
</p>
<p>&int; L
</p>
<p>0
</p>
<p>F(x) sin( nπ
L
</p>
<p>x) dx. (A.4)</p>
<p/>
</div>
<div class="page"><p/>
<p>Solutions to Selected Problems
</p>
<p>Chapter1
</p>
<p>1.1 Solving the ODE for m first yields m(t) = m0e&minus;t . After substituting m(t) into
the equation for z(t), this equation can be integrated twice and with z&prime;(0) = 0 yields
z(t) = (τ &minus; g)(et &minus; t &minus; 1). From this solution we can see that lift-off occurs (z &gt; 0
for t &gt; 0) if τ &gt; g.
</p>
<p>1.2 For (1.8), direct integration yields A(t) = A0 + kt. For (1.9), separation of
variables yields A(t) = A0e&minus;kt and for (1.10) substitution into the equation for
B(t) yields B(t) = B0 + A0 &minus; A0e&minus;kt . For (1.12), note that dA/dt = dB/dt so
B(t) = A(t)+ cwhere from the IC&rsquo;s c = B0 &minus; A0, then substituting into theODE for
A, separation of variables yieldsA(t) = A0(B0 &minus; A0)/(B0 exp(&minus;k(A0 &minus; B0)t)&minus; A0).
</p>
<p>1.3 See (10.12a).
</p>
<p>1.4 See Exercise4.5 and set F = 0 in (4.49).
</p>
<p>1.5 (a) All solutions starting from x0 �= 0 approach either x = &plusmn;1. The basin
of attraction of x = &minus;1 is x0 &lt; 0 and all solutions having x(t &rarr; &infin;) &rarr; 1
have x0 &gt; 0. (b) Second-order equilibria occur where f = 0 has a double root,
f &prime;(x&lowast;) = 1 &minus; 3x2&lowast; = 0, namely x&lowast; = &plusmn;1/
</p>
<p>&radic;
3. Substituting these x&lowast; into f (x&lowast;) = 0
</p>
<p>yields k&plusmn; = &plusmn;2
&radic;
3/9. Plotting directions on the phase lines shows these bifurcation
</p>
<p>values correspond to the changes in qualitative behaviours.
</p>
<p>Chapter2
</p>
<p>2.1 Using the hint, we can express the problem as
</p>
<p>dfavg
</p>
<p>dt
= lim
</p>
<p>ε&rarr;0
</p>
<p>d
</p>
<p>dt
</p>
<p>(
</p>
<p>1
</p>
<p>εh(t)
</p>
<p>&int; a(t)+εh(t)
</p>
<p>a(t)
</p>
<p>f (x, t) dx
</p>
<p>)
</p>
<p>.
</p>
<p>&copy; Springer International Publishing Switzerland 2015
</p>
<p>T. Witelski and M. Bowen, Methods of Mathematical Modelling,
</p>
<p>Springer Undergraduate Mathematics Series, DOI 10.1007/978-3-319-23042-9
</p>
<p>255</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1">http://dx.doi.org/10.1007/978-3-319-23042-9_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1">http://dx.doi.org/10.1007/978-3-319-23042-9_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1">http://dx.doi.org/10.1007/978-3-319-23042-9_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1">http://dx.doi.org/10.1007/978-3-319-23042-9_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_1">http://dx.doi.org/10.1007/978-3-319-23042-9_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_10">http://dx.doi.org/10.1007/978-3-319-23042-9_10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4">http://dx.doi.org/10.1007/978-3-319-23042-9_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4">http://dx.doi.org/10.1007/978-3-319-23042-9_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2">http://dx.doi.org/10.1007/978-3-319-23042-9_2</a></div>
</div>
<div class="page"><p/>
<p>256 Solutions to Selected Problems
</p>
<p>We are taking a derivative of a product of functions with the second factor being an
integral, hence we apply Leibniz&rsquo;s rule (with respect to t) to it,
</p>
<p>=
1
</p>
<p>ε
</p>
<p>(
</p>
<p>&minus;
h&prime;
</p>
<p>h2
</p>
<p>&int; a+εh
</p>
<p>a
f dx +
</p>
<p>1
</p>
<p>h
</p>
<p>[
&int; a+εh
</p>
<p>a
</p>
<p>&part;f
</p>
<p>&part;t
dx + f (a + εh, t)
</p>
<p>d(a + εh)
dt
</p>
<p>&minus; f (a, t)
da
</p>
<p>dt
</p>
<p>])
</p>
<p>Now we are ready to consider the limit for ε &rarr; 0. We will expand out the first two
terms in the Taylor series for ε &rarr; 0, using Leibniz&rsquo;s rule again, to take the derivative
of integrals (with respect to ε),
</p>
<p>&asymp;
1
</p>
<p>ε
</p>
<p>(
</p>
<p>&minus;
h&prime;
</p>
<p>h2
</p>
<p>[&int; a
</p>
<p>a
f dx + εf (a, t)&minus; 0
</p>
<p>]
</p>
<p>+
1
</p>
<p>h
</p>
<p>[&int; a
</p>
<p>a
</p>
<p>&part;f
</p>
<p>&part;t
dx + ε
</p>
<p>&part;f
</p>
<p>&part;t
h
</p>
<p>∣
∣
∣
∣
x=a
</p>
<p>+
(
</p>
<p>f + εh
&part;f
</p>
<p>&part;x
</p>
<p>) ∣
∣
∣
∣
x=a
</p>
<p>(
da
</p>
<p>dt
+ ε
</p>
<p>dh
</p>
<p>dt
</p>
<p>)
</p>
<p>&minus; f (a, t)
da
</p>
<p>dt
</p>
<p>])
</p>
<p>Eliminating null integrals,
&int; a
</p>
<p>a
g dx = 0, and cancelling terms reduces this to
</p>
<p>=
1
</p>
<p>ε
</p>
<p>(
</p>
<p>&minus;
εfh&prime;
</p>
<p>h
+
</p>
<p>1
</p>
<p>h
</p>
<p>[
</p>
<p>ε
&part;f
</p>
<p>&part;t
h + εf
</p>
<p>dh
</p>
<p>dt
+ εh
</p>
<p>&part;f
</p>
<p>&part;x
</p>
<p>da
</p>
<p>dt
+ ε2h
</p>
<p>&part;f
</p>
<p>&part;x
</p>
<p>dh
</p>
<p>dt
</p>
<p>] ∣
∣
∣
∣
x=a
</p>
<p>)
</p>
<p>=
&part;f
</p>
<p>&part;t
+
</p>
<p>&part;f
</p>
<p>&part;x
</p>
<p>da
</p>
<p>dt
+ ε
</p>
<p>&part;f
</p>
<p>&part;x
</p>
<p>dh
</p>
<p>dt
</p>
<p>∣
∣
∣
∣
x=a
</p>
<p>Hence we obtain the limit as the convective derivative at x = a(t),
</p>
<p>lim
ε&rarr;0
</p>
<p>dfavg
</p>
<p>dt
=
</p>
<p>&part;f
</p>
<p>&part;t
+ v
</p>
<p>&part;f
</p>
<p>&part;x
</p>
<p>∣
∣
∣
∣
x=a
</p>
<p>In three dimensions it can be shown that
</p>
<p>favg(t) =
&int;&int;&int;
</p>
<p>D(t)
f dV
</p>
<p>&int;&int;&int;
</p>
<p>D(t)
dV
</p>
<p>=&rArr; lim
D(t)&rarr;0
</p>
<p>dfavg
</p>
<p>dt
=
</p>
<p>&part;f
</p>
<p>&part;t
+ v &middot; &nabla;f
</p>
<p>∣
∣
∣
∣
x=a
</p>
<p>.
</p>
<p>2.2 Expand the left-hand side of the conservation of momentum equation using the
</p>
<p>product rule
</p>
<p>&part;(ρv)
</p>
<p>&part;t
+
</p>
<p>&part;(ρv2)
</p>
<p>&part;x
= ρ
</p>
<p>&part;v
</p>
<p>&part;t
+ v
</p>
<p>&part;ρ
</p>
<p>&part;t
+ ρv
</p>
<p>&part;v
</p>
<p>&part;x
+ v
</p>
<p>&part;(ρv)
</p>
<p>&part;x
</p>
<p>= ρ
&part;v
</p>
<p>&part;t
+ ρv
</p>
<p>&part;v
</p>
<p>&part;x
+ v
</p>
<p>[
&part;ρ
</p>
<p>&part;t
+
</p>
<p>&part;(ρv)
</p>
<p>&part;x
</p>
<p>]
</p>
<p>︸ ︷︷ ︸
</p>
<p>=0
</p>
<p>= ρ
(
&part;v
</p>
<p>&part;t
+ v
</p>
<p>&part;v
</p>
<p>&part;x
</p>
<p>)</p>
<p/>
</div>
<div class="page"><p/>
<p>Solutions to Selected Problems 257
</p>
<p>where the terms on the second line vanish by virtue of the continuity equation (the
</p>
<p>conservation of mass).
</p>
<p>2.3 (a) Use the trigonometric identity cos a cos b = 2 cos( 1
2
[a + b]) cos( 1
</p>
<p>2
[a &minus; b])
</p>
<p>to re-write ρ as
</p>
<p>ρ = 2 cos
(
</p>
<p>1
2
[(k + k + ε)x &minus; (ω(k)+ ω(k + ε))t]x
</p>
<p>)
</p>
<p>cos
</p>
<p>(
</p>
<p>1
2
[(k + ε &minus; k)x &minus; (ω(k + ε)&minus; ω(k))t]
</p>
<p>)
</p>
<p>For ε &rarr; 0 the Taylor series gives ω(k + ε) = ω(k)+ ω&prime;(k)ε + &middot; &middot; &middot; ; using this, for
ε &rarr; 0 we get
</p>
<p>ω(k + ε)&minus; ω(k) &asymp; ω&prime;(k)ε, ω(k + ε)+ ω(k) &asymp; 2ω(k)
</p>
<p>and then the first term in the expansion of ρ is
</p>
<p>ρ &asymp; 2 cos(kx &minus; ω(k)t) cos
(
</p>
<p>1
2
ε[x &minus; ω&prime;(k)t]
</p>
<p>)
</p>
<p>= 2 cos
(
</p>
<p>k
</p>
<p>[
</p>
<p>x &minus;
ω(k)
</p>
<p>k
t
</p>
<p>])
</p>
<p>cos
(
1
2
ε[x &minus; ω&prime;(k)t]
</p>
<p>)
</p>
<p>,
</p>
<p>Matching terms to the prescribed form identifies the phase and group velocities as
</p>
<p>cp(k) =
ω(k)
</p>
<p>k
, cg(k) =
</p>
<p>dω
</p>
<p>dk
.
</p>
<p>(b) Substituting ρ = cos(kx &minus; ωt) in the PDE yields
</p>
<p>ρt + ρx &minus; ρxxt = (ω &minus; k + ωk2) sin(kx &minus; ωt) = 0
</p>
<p>and forcing the coefficient to vanish yields the dispersion relation,
</p>
<p>ω(k) =
k
</p>
<p>1+ k2
.
</p>
<p>Similarly, substituting ρ = exp(kx &minus; ω̃t) yields
</p>
<p>ρt + ρx &minus; ρxxt = (&minus;ω̃ + k + ω̃k2) exp(kx &minus; ω̃t) = 0
</p>
<p>yielding the modified dispersion relation
</p>
<p>ω̃(k) =
k
</p>
<p>1&minus; k2
.
</p>
<p>2.4 (a) Substituting ρ = P(x &minus; ct) in the BBM PDE yields
</p>
<p>&minus;c
dP
</p>
<p>ds
+
</p>
<p>dP
</p>
<p>ds
+ 6P
</p>
<p>dP
</p>
<p>ds
+ c
</p>
<p>d3P
</p>
<p>ds3
= 0</p>
<p/>
</div>
<div class="page"><p/>
<p>258 Solutions to Selected Problems
</p>
<p>(b) Note that we can integrate the ODE to yield
</p>
<p>d &minus; cP + P + 3P2 + c
d2P
</p>
<p>ds2
= 0
</p>
<p>Now considering P(s) = Asech2(Bs); for |s| &rarr; &infin;, P &rarr; 0 and similarly all deriv-
atives P&prime;,P&prime;&prime;, . . . &rarr; 0. Hence, evaluating the ODE for |s| &rarr; &infin; we can conclude
that the constant of integration is d = 0,
</p>
<p>(1&minus; c)P + 3P2 + c
d2P
</p>
<p>ds2
= 0
</p>
<p>Substituting in the sech2 solution form, after some algebra the ODE gives,
</p>
<p>(4A + 16cAB2 &minus; 4cA) cosh(2Bs)+ (24A2 + 4A &minus; 32cAB2 &minus; 4cA) = 0
</p>
<p>The equation is satisfied for all s if the coefficients (in parentheses) are each zero.
</p>
<p>The first coefficient yields
</p>
<p>(1+ c)+ 4cB2 = 0 =&rArr; B =
&radic;
</p>
<p>c &minus; 1
4c
</p>
<p>,
</p>
<p>then the second coefficient is obtained from
</p>
<p>6A + 1&minus; 8cB2 &minus; c = 0 =&rArr; A =
c &minus; 1
2
</p>
<p>.
</p>
<p>Hence the soliton is
</p>
<p>ρ(x, t) = P(x &minus; ct) =
c &minus; 1
2
</p>
<p>sech2
</p>
<p>(&radic;
</p>
<p>c &minus; 1
4c
</p>
<p>(x &minus; ct)
)
</p>
<p>=
c &minus; 1
2
</p>
<p>sech2
</p>
<p>(
</p>
<p>1
</p>
<p>2
</p>
<p>[&radic;
</p>
<p>c &minus; 1
c
</p>
<p>x &minus;
&radic;
</p>
<p>c2 &minus; c t
])
</p>
<p>,
</p>
<p>where the final line is meant to be of the wavenumber-frequency form, ρ =
G(kx &minus; ω̃t). To check if this satisfies the modified dispersion relationship found
in the previous exercise, consider if
</p>
<p>k(c) =
&radic;
</p>
<p>c &minus; 1
c
</p>
<p>ω̃(c) =
&radic;
</p>
<p>c2 &minus; c,</p>
<p/>
</div>
<div class="page"><p/>
<p>Solutions to Selected Problems 259
</p>
<p>are parametric equations for
</p>
<p>ω̃(k) =
k
</p>
<p>1&minus; k2
=
</p>
<p>&radic;
(c &minus; 1)/c
</p>
<p>1&minus; (c &minus; 1)/c
= c
</p>
<p>&radic;
</p>
<p>c &minus; 1
c
</p>
<p>=
&radic;
</p>
<p>c2 &minus; c = ω̃(c),
</p>
<p>so yes, this is verified. Also, the definition of the phase speed, c = ω̃/k = c holds.
One of many special properties of solitons is that they satisfy dispersion relations
</p>
<p>obtained from the linearised version of the PDE while having their form determined
</p>
<p>by the full, nonlinear equation.
</p>
<p>2.5 Using the given forms, the third equation, φt(x, 1, t) = &minus;f = &minus;A cos(kx &minus; ωt)
reduces to &minus;ωB(1) = &minus;A. Similarly, the fourth equation, ft = φy = B&prime;(1) cos(kx &minus;
ωt) yields ωA = B&prime;(1). The second equation φy = B&prime;(0) sin(kx &minus; ωt) reduces to
B&prime;(0) = 0. Finally, substituting φ into φxx + φyy = 0 yields
</p>
<p>&minus;k2B +
d2B
</p>
<p>dy2
= 0 =&rArr; B(y) = c1eky + c2e&minus;ky.
</p>
<p>Applying the boundary condition B&prime;(0) = 0 and B&prime;(1) = ωA to the general solution
of the ODE yields
</p>
<p>c1k &minus; c2k = 0, c1kek &minus; c2ke&minus;k = ωA c1 = c2 =
ωA
</p>
<p>2k sinh(k)
,
</p>
<p>then B(1) = A/ω yields the dispersion relation,
</p>
<p>ωA
</p>
<p>k sinh(k)
cosh(k) =
</p>
<p>ωA
</p>
<p>k
tanh(k) =
</p>
<p>A
</p>
<p>ω
=&rArr; ω(k) =
</p>
<p>&radic;
</p>
<p>k tanh(k).
</p>
<p>2.6 (a) The initial value problems for the characteristic ODEs are
</p>
<p>dX
</p>
<p>dt
= e2t X(0) = A,
</p>
<p>dP
</p>
<p>dt
= P + X + t P(0) = cos(A)
</p>
<p>First solving for X yields X(t) = A+ 1
2
(e2t &minus; 1) which can then be plugged into the
</p>
<p>equation for P to yield
</p>
<p>P(t) = (A + cos(A))et &minus; A &minus; t &minus; 1
2
(1&minus; e2t)
</p>
<p>On each characteristic curve, we can invert X(t,A) to get A = x + 1
2
[1&minus; e2t], then
</p>
<p>substituting into P yields
</p>
<p>ρ(x, t) =
(
</p>
<p>x + 1
2
[1&minus; e2t] + cos(x + 1
</p>
<p>2
[1&minus; e2t])
</p>
<p>)
</p>
<p>et
</p>
<p>&minus;
(
</p>
<p>x + 1
2
[1&minus; e2t]
</p>
<p>)
</p>
<p>&minus; t &minus; 1
2
(1&minus; e2t).</p>
<p/>
</div>
<div class="page"><p/>
<p>260 Solutions to Selected Problems
</p>
<p>(b) The characteristic ODEs are
</p>
<p>dX
</p>
<p>dt
= X + 4,
</p>
<p>dP
</p>
<p>dt
= &minus;2P.
</p>
<p>The general solutions of these equations are
</p>
<p>X(t) = c1et &minus; 4, P(t) = c2e&minus;2t .
</p>
<p>The side conditions give data in two parts.
</p>
<p>For A &gt; 0, we have X(0) = A,P(0) = e&minus;A at t = 0. Applying this to the general
solution yields
</p>
<p>X(t) = (A + 4)et &minus; 4, P(t) = e&minus;A&minus;2t .
</p>
<p>Inverting x = X(t,A) yields A = (x + 4)e&minus;t &minus; 4 &gt; 0 and substituting this into P(t)
yields
</p>
<p>ρ(x, t) = exp
(
</p>
<p>4&minus; (x + 4)e&minus;t &minus; 2t
)
</p>
<p>for x &gt; 4(et &minus; 1).
</p>
<p>The second part of the data is given at x = 0 =&rArr; X(T) = 0 with P(T) = cos(T)
for t &gt; 0 =&rArr; T &gt; 0. Applying these conditions to the general solution yields
</p>
<p>X(t) = 4et&minus;T &minus; 4, P(t) = cos(T)e&minus;2t+2T .
</p>
<p>Inverting x = X(t,T) yields T = t &minus; ln(1+ x/4) &gt; 0 and substituting this into P(t)
yields
</p>
<p>ρ(x, t) = cos
(
</p>
<p>t &minus; ln
(
</p>
<p>1+
x
</p>
<p>4
</p>
<p>)) (
</p>
<p>1+
x
</p>
<p>4
</p>
<p>)&minus;2
for x &lt; 4(et &minus; 1).
</p>
<p>2.7 (a) Expanding out the product rule and using the given velocity yields the PDE
</p>
<p>&part;ρ
</p>
<p>&part;t
+ x2e&minus;3t
</p>
<p>&part;ρ
</p>
<p>&part;x
= &minus;2xe&minus;3tρ
</p>
<p>and consequently the characteristic ODEs
</p>
<p>dX
</p>
<p>dt
= X2e&minus;3t, X(0) = A, for 1 &le; A &le; 2.
</p>
<p>and
</p>
<p>dP
</p>
<p>dt
= &minus;2XPe&minus;3t, P(0) = 1.</p>
<p/>
</div>
<div class="page"><p/>
<p>Solutions to Selected Problems 261
</p>
<p>The problem for X(t) yields
</p>
<p>X(t,A) =
(
1
</p>
<p>A
+ 1
</p>
<p>3
e&minus;3t &minus; 1
</p>
<p>3
</p>
<p>)&minus;1
,
</p>
<p>and the problem for P(t) yields
</p>
<p>P(t,A) =
A2
</p>
<p>9
</p>
<p>(
</p>
<p>e&minus;3t &minus; 1+
3
</p>
<p>A
</p>
<p>)2
</p>
<p>.
</p>
<p>Inverting x = X(t,A) for A yields
</p>
<p>A =
(
1
</p>
<p>x
+ 1
</p>
<p>3
&minus; 1
</p>
<p>3
e&minus;3t
</p>
<p>)&minus;1
,
</p>
<p>and substituting this into P(t,A) yields
</p>
<p>ρ(x, t) =
(x
</p>
<p>3
[e&minus;3t &minus; 1] &minus; 1
</p>
<p>)&minus;2
.
</p>
<p>2.10 (a) Substituting in the definitions of p, q in the first equation yields φtt &minus; c2
φxx = 0 (the wave equation) and φxt &minus; φtx = 0, always true by the identity of mixed
partial derivatives of smooth functions.
</p>
<p>(b) The system can be written as
</p>
<p>&part;
</p>
<p>&part;t
</p>
<p>(
</p>
<p>p
</p>
<p>q
</p>
<p>)
</p>
<p>+
(
</p>
<p>0 &minus;c2
&minus;1 0
</p>
<p>)
</p>
<p>︸ ︷︷ ︸
</p>
<p>M
</p>
<p>&part;
</p>
<p>&part;x
</p>
<p>(
</p>
<p>p
</p>
<p>q
</p>
<p>)
</p>
<p>=
(
</p>
<p>0
</p>
<p>0
</p>
<p>)
</p>
<p>.
</p>
<p>Following the approach given in Sect. 2.4, we obtain the wavespeeds from
</p>
<p>|MT &minus; λI| =
∣
∣
∣
∣
</p>
<p>&minus;λ &minus;1
&minus;c2 &minus;λ
</p>
<p>∣
∣
∣
∣
= λ2 &minus; c2 = 0 =&rArr; λ = &plusmn;c.
</p>
<p>The corresponding eigenvectors are then
</p>
<p>λ1 = c W1(x &minus; ct) = p(x, t)&minus; cq(x, t)
λ2 = &minus;c W2(x + ct) = p(x, t)+ cq(x, t)
</p>
<p>(b) Then the solutions can be expressed in terms of W1,W2 are
</p>
<p>p(x, t) =
1
</p>
<p>2
(W1(x &minus; ct)+ W2(x + ct)) q(x, t) =
</p>
<p>1
</p>
<p>2c
(W2(x + ct)&minus; W1(x &minus; ct)).</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2">http://dx.doi.org/10.1007/978-3-319-23042-9_2</a></div>
</div>
<div class="page"><p/>
<p>262 Solutions to Selected Problems
</p>
<p>(c) We can relate A,B to W1,W2 from
</p>
<p>p =
&part;φ
</p>
<p>&part;t
=
</p>
<p>1
</p>
<p>2
(W1(x &minus; ct)+ W2(x + ct)) = &minus;cA&prime;(x &minus; ct)+ cB&prime;(x + ct)
</p>
<p>q =
&part;φ
</p>
<p>&part;x
=
</p>
<p>1
</p>
<p>2c
(W2(x + ct)&minus; W1(x &minus; ct)) = A&prime;(x &minus; ct)+ B&prime;(x + ct)
</p>
<p>Both of which yield
</p>
<p>A&prime;(x &minus; ct) = &minus;
1
</p>
<p>2c
W1(x &minus; ct) B&prime;(x + ct) =
</p>
<p>1
</p>
<p>2c
W2(x + ct).
</p>
<p>(d) At t = 0 the initial condition φ(x, 0) = f (x) implies φx(x, 0) = q(x, 0) = f &prime;(x)
and φt(x, 0) = p(x, 0) = g(x), and consequently
</p>
<p>W1(x) = g(x)&minus; cf &prime;(x) W2(x) = g(x)+ cf &prime;(x)
</p>
<p>Hence, from part (c)
</p>
<p>A&prime;(x) = &minus;
1
</p>
<p>2c
</p>
<p>(
</p>
<p>g(x)&minus; cf &prime;(x)
)
</p>
<p>A(x) =
&int; x
</p>
<p>0
</p>
<p>A&prime;(x̃) dx̃ + a =
f (x)&minus; f (0)
</p>
<p>2
&minus;
</p>
<p>1
</p>
<p>2c
</p>
<p>&int; x
</p>
<p>0
</p>
<p>g(x̃) dx̃ + a
</p>
<p>B&prime;(x) =
1
</p>
<p>2c
</p>
<p>(
</p>
<p>g(x)+ cf &prime;(x)
)
</p>
<p>B(x) =
&int; x
</p>
<p>0
</p>
<p>B&prime;(x̃) dx̃ + b =
f (x)&minus; f (0)
</p>
<p>2
+
</p>
<p>1
</p>
<p>2c
</p>
<p>&int; x
</p>
<p>0
</p>
<p>g(x̃) dx̃ + b,
</p>
<p>where a, b are constants of integration.
</p>
<p>So using φ(x, t) = A(x &minus; ct)+ B(x + ct),
</p>
<p>φ = 1
2
(f (x &minus; ct)&minus; f (0))&minus;
</p>
<p>1
</p>
<p>2c
</p>
<p>&int; x&minus;ct
</p>
<p>0
</p>
<p>g(x̃) dx̃ + a
</p>
<p>+ 1
2
(f (x + ct)&minus; f (0))+
</p>
<p>1
</p>
<p>2c
</p>
<p>&int; x+ct
</p>
<p>0
</p>
<p>g(x̃) dx̃ + b
</p>
<p>= 1
2
(f (x + ct)+ f (x &minus; ct))+
</p>
<p>1
</p>
<p>2c
</p>
<p>&int; x+ct
</p>
<p>x&minus;ct
g(x̃) dx̃ + (a + b &minus; f (0)).
</p>
<p>Checking the initial condition, φ(x, 0) = f (x),
</p>
<p>φ(x, 0) = 1
2
(f (x)+ f (x))+
</p>
<p>1
</p>
<p>2c
</p>
<p>&int; x
</p>
<p>x
</p>
<p>g(x̃) dx̃
</p>
<p>︸ ︷︷ ︸
</p>
<p>=0
</p>
<p>+(a + b &minus; f (0)),</p>
<p/>
</div>
<div class="page"><p/>
<p>Solutions to Selected Problems 263
</p>
<p>so the constants of integration should be chosen so that a + b &minus; f (0) = 0, yielding
the D&rsquo;Alembert solution.
</p>
<p>2.12 The conservation law pt + q(p)x = 0 can be re-written as pt + q&prime;(p)px = 0,
from which we can write the characteristic equations as
</p>
<p>dP
</p>
<p>dt
= 0 =&rArr; P = f (A) = constant
</p>
<p>dX
</p>
<p>dt
= q&prime;(P) =&rArr; X = q&prime;(f (A))t + A
</p>
<p>(a) The two characteristic curves will intersect when X(t0,1,A0) = X(t0,1,A1),
namely
</p>
<p>q&prime;(f (A0))t0,1 + A0 = q&prime;(f (A1))t0,1 + A1 =&rArr; t0,1 = &minus;
A1 &minus; A0
</p>
<p>q&prime;(f (A1))&minus; q&prime;(f (A0))
</p>
<p>and subsequently using this value of t0,1, x0,1 = q&prime;(f (A0))t0,1 + A0 (or equivalently
in terms of A1).
</p>
<p>(b) Minimising t0,1 over all possible A0,A1 to get t&lowast;, consider A1 = A0 + ε,
</p>
<p>t&lowast; = min
A0,A1
</p>
<p>&minus;
A1 &minus; A0
</p>
<p>q&prime;(f (A1))&minus; q&prime;(f (A0))
= min
</p>
<p>A0,ε
&minus;
</p>
<p>ε
</p>
<p>q&prime;(f (A0 + ε))&minus; q&prime;(f (A0))
</p>
<p>Taking the limit ε &rarr; 0 and recalling the limit definition of the derivative,
</p>
<p>t&lowast; = min
x
</p>
<p>[
</p>
<p>&minus;
1
</p>
<p>q&prime;&prime;(f (x))f &prime;(x)
</p>
<p>]
</p>
<p>&ge; 0.
</p>
<p>2.13 (a) The characteristic ODEs are dX/dt = P, dP/dt = 0, as in (2.41). Applying
the given initial conditions yields the parametric solutions
</p>
<p>{
</p>
<p>X(t,A) = (9&minus; A2)t + A, P(t,A) = 9&minus; A2 |A| &le; 3
X(t,A) = A, P(t,A) = 0 |A| &gt; 3
</p>
<p>(b) To invert X(t,A) = x for the nontrivial part of the solution, we recognise it as a
quadratic equation for A,
</p>
<p>A2t &minus; A + (x &minus; 9t) = 0 =&rArr; A =
1&plusmn;
</p>
<p>&radic;
</p>
<p>1&minus; 4(xt &minus; 9t2)
2t</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2">http://dx.doi.org/10.1007/978-3-319-23042-9_2</a></div>
</div>
<div class="page"><p/>
<p>264 Solutions to Selected Problems
</p>
<p>then we can substitute into P to obtain
</p>
<p>p(x, t) = 9&minus;
(
</p>
<p>1&plusmn;
&radic;
</p>
<p>1&minus; 4(xt &minus; 9t2)
2t
</p>
<p>)2
</p>
<p>Formore general initial conditions, p(x, 0) = f (x), for the inviscid Burgers&rsquo; equation
we have X = Pt+A with P on a characteristic curve, so we can still write A = x&minus;Pt
to obtain an implicit equation for the solution, p = f (x&minus;pt), here p = 9&minus; (x&minus;pt)2,
to yield the equivalent form
</p>
<p>p(x, t) =
2xt &minus; 1&plusmn;
</p>
<p>&radic;
36t2 &minus; 4xt + 1
2t2
</p>
<p>See below for a graph of this multi-valued solution at time t = 1.
</p>
<p>(c) The result of Exercise2.12 gives that the time at which the shock forms is deter-
</p>
<p>mined by the initial conditions,
</p>
<p>t&lowast; = min
x
</p>
<p>(
</p>
<p>&minus;
1
</p>
<p>f &prime;(x)
</p>
<p>)
</p>
<p>=&rArr; t&lowast; = min
x&isin;[&minus;3,3]
</p>
<p>(
</p>
<p>&minus;
1
</p>
<p>2x
</p>
<p>)
</p>
<p>=
1
</p>
<p>6
,
</p>
<p>and the shock will first form at x&lowast; = 3.
(d) The Rankine-Hugoniot equation for the inviscid Burgers&rsquo; equation (2.49) and the
</p>
<p>result from part (c) give the ODE problem for the shock position as
</p>
<p>dxs
</p>
<p>dt
= &minus;
</p>
<p>2xst &minus; 1+
&radic;
</p>
<p>36t2 &minus; 4xst + 1
4t2
</p>
<p>, xs(1/6) = 3,
</p>
<p>where the solution ahead of the shock is p+(x, t) &equiv; 0 and the solution behind the
shock, p&minus;(x, t) is given by the solution abovewith the positive sign on the square root.</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2">http://dx.doi.org/10.1007/978-3-319-23042-9_2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_2">http://dx.doi.org/10.1007/978-3-319-23042-9_2</a></div>
</div>
<div class="page"><p/>
<p>Solutions to Selected Problems 265
</p>
<p>(e) The inviscid Burgers equation is a conservation law for the integral,
&int;
</p>
<p>p dx,
</p>
<p>pt +
(
1
2
</p>
<p>p2
)
</p>
<p>x
= 0 =&rArr;
</p>
<p>d
</p>
<p>dt
</p>
<p>(&int;
</p>
<p>p dx
</p>
<p>)
</p>
<p>= 0
</p>
<p>Hence the conserved value is set by the area under the initial condition
&int;
</p>
<p>(9&minus;x2) dx =
36. Using the form of the solution with the shock, the equation that
</p>
<p>&int;
</p>
<p>p(x, t) dx = 36
becomes (for t &gt; 1/6, after the shock forms),
</p>
<p>&int; xs(t)
</p>
<p>&minus;3
</p>
<p>2xt &minus; 1+
&radic;
36t2 &minus; 4xt + 1
2t2
</p>
<p>dx = 36.
</p>
<p>Evaluating the integral yields an implicit algebraic equation for xs(t),
</p>
<p>1
</p>
<p>12t3
</p>
<p>(
</p>
<p>6x2s t
2 &minus; (1&minus; 4xst + 36t2)3/2 &minus; 6xst + 216t3 + 54t2 + 1
</p>
<p>)
</p>
<p>= 36.
</p>
<p>Chapter3
</p>
<p>3.1 (a, b) Both approaches give
</p>
<p>&minus;y&prime;&prime; +
k
</p>
<p>x2
y + x2 = 0.
</p>
<p>Multiplying across by x2, this equation can be recognised as an inhomogeneous
</p>
<p>Cauchy-Euler equation, x2y&prime;&prime;&minus;ky = &minus;x4, solvable in terms of a sumof homogeneous
and particular solutions.
</p>
<p>(c) For k = 0 the general solution is y(x) = x4/12 + c1x + c2. Applying the
boundary conditions yields c1 = &minus;1/12, c2 = 1.
(d) For k = 2 the general solution is y(x) = x4/10+ c1x2 + c2/x. Applying the first
boundary conditions yields c1 = 9/10, c2 = 0. The condition y(0) = 1 cannot be
satisfied because unless c2 = 0 that term would diverge and the other terms in the
general solution vanish for x = 0.</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3">http://dx.doi.org/10.1007/978-3-319-23042-9_3</a></div>
</div>
<div class="page"><p/>
<p>266 Solutions to Selected Problems
</p>
<p>3.2
</p>
<p>δ2J = 1
2
</p>
<p>&int; 1
</p>
<p>0
</p>
<p>(h&prime;)2
</p>
<p>(1+ (y&prime;)2)3/2
dx =&rArr; δ2J&lowast; = 12
</p>
<p>&int; 1
</p>
<p>0
</p>
<p>(h&prime;)2
</p>
<p>(1+ b2)3/2
dx &ge; 0,
</p>
<p>where δ2J&lowast;will be strictly positive unlessh&prime;(x) &equiv; 0, but from theboundary conditions
on y, the boundary conditions on h are h(0) = h(1) = 0. Hence h&prime; &equiv; 0 only if h &equiv; 0.
</p>
<p>3.4 (a) The x(t) Euler-Lagrange equation can be simplified to
</p>
<p>(y&prime;&prime;x&prime;y&prime; &minus; x&prime;&prime;(y&prime;)2)(1+ 4k2(x2 + y2))+ 4k2((x&prime;)2 + (y&prime;)2)(x&prime;y &minus; xy&prime;)y&prime; = 0.
</p>
<p>The y Euler-Lagrange equation takes the same form after interchanging x &harr; y.
(b) The Euler-Lagrange equation for y(x) can be reduced to
</p>
<p>y&prime;&prime; =
4k2(1+ (y&prime;)2)(xy&prime; &minus; y)
</p>
<p>1+ 4k2(x2 + y2)
.
</p>
<p>(c) For (ii), since z is constant on the semicircle, the distance is just the arclength of
</p>
<p>the semi-circle, Jii = π for all k.
For (i), we have y = 0 and z = kx2, hence the arclength can be calculated from
</p>
<p>Ji(k) =
&int; 1
</p>
<p>&minus;1
</p>
<p>&radic;
</p>
<p>1+ 4k2x2 dx =
&radic;
</p>
<p>1+ 4k2 +
1
</p>
<p>2k
arcsinh(2k).
</p>
<p>For k = 0, Ji(0) = 2 giving the length of the straight line in the xy plane, while for
k &gt; 0 Ji is an unbounded monotone increasing function of k, Ji(k &rarr; &infin;) &rarr; &infin;.
Let k&lowast; be the value of k for which Ji(k&lowast;) = π . Then for 0 &le; k &lt; k&lowast;, the straight-line
path will be shorter than the semi-circle detours. But for k &gt; k&lowast;, the semi-circle is
shorter.
</p>
<p>3.5 (a) After the substitution, the action in terms of θ(t) is
</p>
<p>I =
&int;
</p>
<p>1
2
</p>
<p>mℓ2(θ &prime;)2 + mgℓ cos θ dt
</p>
<p>and from (3.21) applied to θ(t) the resulting Euler-Lagrange is the equation of the
</p>
<p>pendulum,
</p>
<p>θ &prime;&prime; +
g
</p>
<p>ℓ
sin θ = 0.
</p>
<p>(b) See Exercise3.27 for the Euler-Lagrange equation for x(t).</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3">http://dx.doi.org/10.1007/978-3-319-23042-9_3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3">http://dx.doi.org/10.1007/978-3-319-23042-9_3</a></div>
</div>
<div class="page"><p/>
<p>Solutions to Selected Problems 267
</p>
<p>3.6 Substituting the parametric equation for x, y into the general Lagrangian, L =
1
2
</p>
<p>m((x&prime;)2 + (y&prime;)2)&minus; mgy yields
</p>
<p>L = 12mℓ
2(θ &prime;)2 + mgℓ cos θ &minus; σm
</p>
<p>(
</p>
<p>ℓωθ &prime; cos(ωt) sin θ &minus; g sin(ωt)
)
</p>
<p>+ 12mσ
2ω2 cos2(ωt)
</p>
<p>Applying (3.21) then yields the (vertically-oscillated) parametrically-driven pendu-
</p>
<p>lum equation,
</p>
<p>θ &prime;&prime; +
g
</p>
<p>ℓ
sin θ = &minus;
</p>
<p>ω2σ
</p>
<p>ℓ
sin(ωt) sin θ.
</p>
<p>3.7 (a) Starting from H = &minus;L + y&prime;&part;y&prime;L,
</p>
<p>dH
</p>
<p>dt
=
</p>
<p>d
</p>
<p>dt
</p>
<p>(
</p>
<p>&minus;L + y&prime;
&part;L
</p>
<p>&part;y&prime;
</p>
<p>)
</p>
<p>= &minus;
(
&part;L
</p>
<p>&part;t
+
</p>
<p>&part;L
</p>
<p>&part;y
</p>
<p>dy
</p>
<p>dt
+
</p>
<p>&part;L
</p>
<p>&part;y&prime;
d2y
</p>
<p>dt2
</p>
<p>)
</p>
<p>+
d2y
</p>
<p>dt2
</p>
<p>&part;L
</p>
<p>&part;y&prime;
+ y&prime;
</p>
<p>d
</p>
<p>dt
</p>
<p>(
&part;L
</p>
<p>&part;y&prime;
</p>
<p>)
</p>
<p>= &minus;
&part;L
</p>
<p>&part;t
&minus; y&prime;
</p>
<p>[
&part;L
</p>
<p>&part;y
&minus;
</p>
<p>d
</p>
<p>dt
</p>
<p>(
&part;L
</p>
<p>&part;y&prime;
</p>
<p>)]
</p>
<p>= 0,
</p>
<p>where the final step makes use of the assumption that &part;tL = 0 to leave&minus;y&prime; times the
Euler-Lagrange equation. Hence H &prime; = 0 and H is a constant, justifying (3.59).
(b) Writing the Lagrangian as L = T(t, y, y&prime;)&minus;V(t, y) the condition that the Hamil-
tonian is the total energy is
</p>
<p>H = &minus;T + V + y&prime;
&part;T
</p>
<p>&part;y&prime;
= T + V =&rArr; y&prime;
</p>
<p>&part;T
</p>
<p>&part;y&prime;
= 2T
</p>
<p>This is a first order separable ODE for T as a function of y&prime; and yields T(t, y, y&prime;) =
A(t, y)(y&prime;)2 where A(t, y) is any function of t and y.
</p>
<p>3.8 (a) At t = 0, the mass starts at x = 0, y = 1 from rest, v = 0, hence the initial
energy is E0 = mg. Equating the energy at later times with E0 yields
</p>
<p>1
2
</p>
<p>mv2 + mgy = mg =&rArr; v(y) =
&radic;
</p>
<p>2g(1&minus; y)
</p>
<p>Consequently the functional for the time of travel is
</p>
<p>T =
&int; 1
</p>
<p>0
</p>
<p>&radic;
</p>
<p>1+ (y&prime;)2
2g(1&minus; y)
</p>
<p>dx L(y, y&prime;) =
</p>
<p>&radic;
</p>
<p>1+ (y&prime;)2
2g(1&minus; y)</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3">http://dx.doi.org/10.1007/978-3-319-23042-9_3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3">http://dx.doi.org/10.1007/978-3-319-23042-9_3</a></div>
</div>
<div class="page"><p/>
<p>268 Solutions to Selected Problems
</p>
<p>(b) The Euler-Lagrange equation for y(x) can be simplified down to
</p>
<p>1
2
</p>
<p>(
1+ (y&prime;)2
</p>
<p>(1&minus; y)3
</p>
<p>)1/2
</p>
<p>&minus;
d
</p>
<p>dx
</p>
<p>(
</p>
<p>y&prime;
&radic;
</p>
<p>(1+ (y&prime;)2)(1&minus; y)
</p>
<p>)
</p>
<p>= 0,
</p>
<p>but this is a difficult looking equation, so we turn to a different approach.
</p>
<p>(c) The Beltrami identity (3.59) is applicable since L does not explicitly depend on
</p>
<p>x, so
</p>
<p>H = L &minus; y&prime;
&part;L
</p>
<p>&part;y&prime;
</p>
<p>=
</p>
<p>&radic;
</p>
<p>1+ (y&prime;)2
2g(1&minus; y)
</p>
<p>&minus;
(y&prime;)2
</p>
<p>&radic;
</p>
<p>2g(1+ (y&prime;)2)(1&minus; y)
</p>
<p>=
1
</p>
<p>&radic;
</p>
<p>2g(1+ (y&prime;)2)(1&minus; y)
= C
</p>
<p>At x = 0, y = 1 and to make C finite, the slope would have to diverge, y&prime; &rarr; &minus;&infin;,
so this form is indeterminate. At x = 1, we have y = 0, so C = 1/
</p>
<p>&radic;
</p>
<p>2g(1+ y&prime;(1)2),
but we don&rsquo;t know y&prime;(1). Still, we can write a singular ODE problem for y(x),
</p>
<p>dy
</p>
<p>dx
= &minus;
</p>
<p>&radic;
</p>
<p>1
</p>
<p>2gC2(1&minus; y)
&minus; 1, y(0) = 1, y(1) = 0.
</p>
<p>(d) Substituting the parametric equations of the cycloid (3.60) into the ODE gives
</p>
<p>a necessary relation between C and k, 1 = 4gC2k. The initial conditions at θ = 0,
x(0) = 0 and y(0) = 1 are satisfied automatically for any k. The final state, x = 1
and y = 0 at some θ = θ&lowast; yield two coupled equations for finding (k, θ&lowast;):
</p>
<p>k(θ&lowast; &minus; sin θ&lowast;) = 0 1&minus; k(1&minus; cos θ&lowast;) = 0.
</p>
<p>3.10 Following the approachgiven inSect. 3.4.2with f (x) = 1+(x&minus;1)2, ỹ = y&lowast;+εh
and b̃ = b&lowast; + εc, we obtain the first variation as
</p>
<p>δJ&lowast; = y&prime;&lowast;h
∣
∣
∣
∣
</p>
<p>b&lowast;
</p>
<p>0
</p>
<p>&minus;
&int; b&lowast;
</p>
<p>0
</p>
<p>y&prime;&prime;&lowast;h dx + 12y
&prime;
&lowast;(b)
</p>
<p>2c.
</p>
<p>The boundary condition at the origin determines that h(0) = 0. Expanding out the
boundary condition ỹ(b̃) = f (b̃) yields
</p>
<p>y&lowast;(b&lowast;) = f (b&lowast;), y&prime;&lowast;(b&lowast;)c + h(b&lowast;) = f &prime;(b&lowast;)c</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3">http://dx.doi.org/10.1007/978-3-319-23042-9_3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3">http://dx.doi.org/10.1007/978-3-319-23042-9_3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3">http://dx.doi.org/10.1007/978-3-319-23042-9_3</a></div>
</div>
<div class="page"><p/>
<p>Solutions to Selected Problems 269
</p>
<p>consequently, c = h(b&lowast;)/(f &prime;(b&lowast;) &minus; y&prime;&lowast;(b&lowast;)). Using this, the first variation can be
re-written as
</p>
<p>δJ&lowast; = y&prime;&lowast;(b&lowast;)
(
</p>
<p>1+
y&prime;&lowast;(b&lowast;)
</p>
<p>2(f &prime;(b&lowast;)&minus; y&prime;&lowast;(b))
</p>
<p>)
</p>
<p>h(b&lowast;)&minus;
&int; b&lowast;
</p>
<p>0
</p>
<p>y&prime;&prime;&lowast;h dx.
</p>
<p>There are two possible choices for natural boundary conditions that would make
</p>
<p>the boundary term vanish for all possible choices of h(b): either y&prime;&lowast;(b&lowast;) = 0 or
(after some algebra) y&prime;&lowast;(b&lowast;) = 2f &prime;(b&lowast;) (we will explore both possibilities). Subject
to natural boundary conditions, applying the fundamental lemma to the critical point
</p>
<p>condition δJ&lowast; = 0, we obtain the Euler-Lagrange equation y&prime;&prime;&lowast; = 0. After applying
the boundary condition y(0) = 0, viable solutions are of the form y&lowast;(x) = Ax. The
boundary condition y&prime;&lowast;(b&lowast;) = 0 would yield A = 0, but this option must be rejected
since the solutionwould not reach the curve y = f (x). Hence, using y&prime;&lowast;(b&lowast;) = 2f &prime;(b&lowast;),
we get A = 4(b&lowast; &minus; 1) and then y&lowast;(b&lowast;) = f (b&lowast;) yields the quadratic equation,
3b2&lowast; &minus; 2b&lowast; &minus; 2 = 0 and the solution
</p>
<p>y&lowast;(x) =
4
</p>
<p>3
(
&radic;
7&minus; 2)x 0 &le; x &le;
</p>
<p>1+
&radic;
7
</p>
<p>3
.
</p>
<p>3.12 Beginning by substituting ỹ = y&lowast; + εh and expanding for ε &rarr; 0 yields
</p>
<p>J̃ = J&lowast; + ε
&int; 1
</p>
<p>0
</p>
<p>h&prime;y&prime;&prime;&prime;&lowast; + y&prime;&lowast;h&prime;&prime;&prime; &minus; 240xh dx + &middot; &middot; &middot;
</p>
<p>Using integration by parts to get the derivatives off of the h&rsquo;s, we arrive at a form
</p>
<p>where the fundamental lemma can be applied to critical point condition, yielding the
</p>
<p>ODE,
</p>
<p>&minus;2y&prime;&prime;&prime;&lowast; &minus; 240x = 0.
</p>
<p>Note that all of the boundary terms vanish thanks to
</p>
<p>y&prime;(0) given =&rArr; h&prime;(0) = 0 y&prime;&prime;(1) given =&rArr; h&prime;&prime;(1) = 0
</p>
<p>y&prime;&prime;&prime;(0) given =&rArr; h&prime;&prime;&prime;(0) = 0 y(1) given =&rArr; h(1) = 0
</p>
<p>TheODEcanbe integrateddirectly to give the solution as a polynomial, after applying
</p>
<p>the four boundary conditions, the final solution is
</p>
<p>y&lowast;(x) = &minus;x5 + 10x2 &minus; 4.</p>
<p/>
</div>
<div class="page"><p/>
<p>270 Solutions to Selected Problems
</p>
<p>3.13 Beginning by substituting ỹ = y&lowast; + εh and expanding for ε &rarr; 0 yields
</p>
<p>J̃ = J&lowast; + ε
&int;
</p>
<p>0
</p>
<p>[
</p>
<p>2y&prime;&lowast;h
&prime; + (1&minus; 2x)
</p>
<p>&int; x
</p>
<p>0
</p>
<p>2y&lowast;(t)h(t)dt
</p>
<p>]
</p>
<p>dx + &middot; &middot; &middot;
</p>
<p>Applying integration by parts yields the first variation as
</p>
<p>(
</p>
<p>2y&prime;&lowast;h + (x &minus; x2)
&int; x
</p>
<p>0
</p>
<p>2y&lowast;h dt
</p>
<p>) ∣
∣
∣
∣
</p>
<p>1
</p>
<p>0
</p>
<p>&minus;
&int; 1
</p>
<p>0
</p>
<p>(
</p>
<p>2y&prime;&prime;&lowast; + 2(x &minus; x2)y&lowast;
)
</p>
<p>hdx
</p>
<p>The second boundary term vanishes automatically at x = 0 and x = 1 due to
the x(1 &minus; x) factor. The first boundary term vanishes under the natural boundary
conditions
</p>
<p>2y&prime;&lowast;(0)h(0) = 0 =&rArr; {y&prime;&lowast;(0) = 0 or h(0) = 0 =&rArr; y&lowast;(0) = A}
</p>
<p>and
</p>
<p>2y&prime;&lowast;(1)h(1) = 1 =&rArr; {y&prime;&lowast;(1) = 0 or h(1) = 0 =&rArr; y&lowast;(1) = B}
</p>
<p>3.14 Beginning by substituting ỹ = y&lowast; + εh and expanding for ε &rarr; 0 yields
</p>
<p>J̃ = J&lowast; + ε
(&int; 1
</p>
<p>0
</p>
<p>2y&lowast;y
&prime;&prime;
&lowast;h
</p>
<p>&prime;&prime; + (y&prime;&prime;&lowast;)2h + 2y&lowast;h dx + y&prime;&lowast;(0)h&prime;(1)+ y&prime;&lowast;(1)h&prime;(0)
)
</p>
<p>+ &middot; &middot; &middot;
</p>
<p>Integrating by parts yields the first variation as
</p>
<p>(
</p>
<p>2y&lowast;(1)y
&prime;&prime;
&lowast;(1)+ y&prime;&lowast;(0)
</p>
<p>)
</p>
<p>h&prime;(1)+
(
</p>
<p>&minus;2y&lowast;(0)y&prime;&prime;&lowast;(0)+ y&prime;&lowast;(1)
)
</p>
<p>h&prime;(0)
</p>
<p>+
&int; 1
</p>
<p>0
</p>
<p>(
</p>
<p>2(y&lowast;y
&prime;&prime;
&lowast;)
</p>
<p>&prime;&prime; + (y&prime;&prime;&lowast;)2 + 2y
)
</p>
<p>h dx
</p>
<p>Hence the Euler-Lagrange equation is
</p>
<p>(
d2y&lowast;
dx2
</p>
<p>)2
</p>
<p>+ 2
d2
</p>
<p>dx2
</p>
<p>(
</p>
<p>y&lowast;
d2y&lowast;
dx2
</p>
<p>)
</p>
<p>+ 2y&lowast; = 0
</p>
<p>and the further natural boundary conditions needed are
</p>
<p>{2y&lowast;(1)y&prime;&prime;&lowast;(1)+ y&prime;&lowast;(0) = 0 or h&prime;(1) = 0 =&rArr; y&prime;&lowast;(1) = A}
</p>
<p>and
</p>
<p>{&minus;2y&lowast;(0)y&prime;&prime;&lowast;(0)+ y&prime;&lowast;(1) = 0 or h&prime;(0) = 0 =&rArr; y&prime;&lowast;(0) = B}</p>
<p/>
</div>
<div class="page"><p/>
<p>Solutions to Selected Problems 271
</p>
<p>3.15 (a) Using v = c/n(x), functional (3.6) becomes
</p>
<p>T(y) =
1
</p>
<p>c
</p>
<p>&int; 1
</p>
<p>0
</p>
<p>n(x)
</p>
<p>&radic;
</p>
<p>1+ (y&prime;)2 dx =&rArr; L(x, y&prime;) =
n(x)
</p>
<p>c
</p>
<p>&radic;
</p>
<p>1+ (y&prime;)2
</p>
<p>Applying (3.21) to this Lagrangian yields
</p>
<p>0&minus;
d
</p>
<p>dx
</p>
<p>(
</p>
<p>n(x)y&prime;
&radic;
</p>
<p>1+ (y&prime;)2
</p>
<p>)
</p>
<p>= 0,
</p>
<p>which can be integrated once, and applying the initial condition yields
</p>
<p>n(x)y&prime;
&radic;
</p>
<p>1+ (y&prime;)2
= C =
</p>
<p>n(0)
&radic;
2
</p>
<p>=&rArr;
dy
</p>
<p>dx
=
</p>
<p>n(0)
&radic;
</p>
<p>2n(x)2 &minus; n(0)2
</p>
<p>(b) Yes, n1 sin θ1 = n2 sin θ2.
(c) L(x, y, y&prime;) = n(x, y)
</p>
<p>&radic;
</p>
<p>1+ (y&prime;)2/c yields the Euler-Lagrange equation
</p>
<p>&radic;
</p>
<p>1+ (y&prime;)2
&part;n
</p>
<p>&part;y
&minus;
</p>
<p>d
</p>
<p>dx
</p>
<p>(
</p>
<p>n(x, y)y&prime;
&radic;
</p>
<p>1+ (y&prime;)2
</p>
<p>)
</p>
<p>= 0.
</p>
<p>3.16 (a) The total kinetic and potential energies are given by
</p>
<p>T =
&int; ℓ
</p>
<p>0
</p>
<p>1
2
ρu2t dx V =
</p>
<p>&int; ℓ
</p>
<p>0
</p>
<p>1
2
</p>
<p>EIu2x dx
</p>
<p>(b) L = T &minus; V then the action is
</p>
<p>J =
&int; t1
</p>
<p>t0
</p>
<p>L dt =
&int; t1
</p>
<p>t0
</p>
<p>&int; ℓ
</p>
<p>0
</p>
<p>(
1
2
ρu2t &minus; 12EIu
</p>
<p>2
x
</p>
<p>)
</p>
<p>dx dt
</p>
<p>(c) Substituting ũ(x, t) = u&lowast;(x, t)+ εh(x, t) and expanding for ε &rarr; 0 yields
</p>
<p>J̃ = J&lowast; + ε
&int; t1
</p>
<p>t0
</p>
<p>&int; ℓ
</p>
<p>0
</p>
<p>(ρu&lowast;tht &minus; EIu&lowast;xxhxx) dx dt + &middot; &middot; &middot;
</p>
<p>Splitting theO(ε) term into separate integrals, we interchange the order of integration
</p>
<p>on the first,
&int; ℓ
</p>
<p>0
</p>
<p>&int; t1
</p>
<p>t0
</p>
<p>ρu&lowast;tht dt dx &minus;
&int; t1
</p>
<p>t0
</p>
<p>&int; ℓ
</p>
<p>0
</p>
<p>EIu&lowast;xxhxx dx dt</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3">http://dx.doi.org/10.1007/978-3-319-23042-9_3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_3">http://dx.doi.org/10.1007/978-3-319-23042-9_3</a></div>
</div>
<div class="page"><p/>
<p>272 Solutions to Selected Problems
</p>
<p>Applying integration by parts with respect to the inner integrals respectively yields
</p>
<p>ρ
</p>
<p>(
&int; ℓ
</p>
<p>0
</p>
<p>[
</p>
<p>u&lowast;th
</p>
<p>∣
∣
∣
∣
</p>
<p>t1
</p>
<p>t0
</p>
<p>]
</p>
<p>dx &minus;
&int; t1
</p>
<p>t0
</p>
<p>&int; ℓ
</p>
<p>0
</p>
<p>u&lowast;tth dx dt
</p>
<p>)
</p>
<p>+ EI
(
&int; t1
</p>
<p>t0
</p>
<p>[
</p>
<p>u&lowast;xxhx &minus; u&lowast;xxxh
∣
∣
∣
∣
</p>
<p>ℓ
</p>
<p>0
</p>
<p>]
</p>
<p>dt &minus;
&int; t1
</p>
<p>t0
</p>
<p>&int; ℓ
</p>
<p>0
</p>
<p>u&lowast;xxxxh dx dt
</p>
<p>)
</p>
<p>The perturbation in the solution at initial and final times t = t0, t1 can be assumed
to be zero h(x, t0) &equiv; h(x, t1) &equiv; 0 to eliminate the first boundary terms. Eliminating
the second boundary term defines natural boundary conditions to remove the u&lowast;xxhx
and u&lowast;xxxh terms at each time,
</p>
<p>{u&lowast;xx(0, t) = 0 or hx(0) = 0 =&rArr; u&lowast;x(0, t) = A(t)}
</p>
<p>and
</p>
<p>{u&lowast;xxx(0, t) = 0 or h(0) = 0 =&rArr; u&lowast;(0, t) = B(t)}
</p>
<p>and similarly for the boundary conditions at x = 1.
Applying the fundamental lemma to
</p>
<p>&int;&int;
</p>
<p>(ρu&lowast;tt + EIu&lowast;xxxx)h dx dt = 0 yields the
beam equation PDE as the Euler-Lagrange equation,
</p>
<p>ρ
&part;2u
</p>
<p>&part;t2
+ EI
</p>
<p>&part;4u
</p>
<p>&part;x4
= 0.
</p>
<p>3.17 Substituting ũ(x, y) = u&lowast;(x, y)+ εh(x, y) and expanding for ε &rarr; 0 yields
</p>
<p>J̃ = J&lowast; + ε
&int;&int;
</p>
<p>D
</p>
<p>k
(
</p>
<p>u&lowast;xhx + u&lowast;yhy
)
</p>
<p>dA + &middot; &middot; &middot;
</p>
<p>The first variation can be written in vector form as
&int;&int;
</p>
<p>k&nabla;u&lowast; &middot; &nabla;h dA then matching
to the product rule with g = k&nabla;u&lowast; and f = h, it can be expressed as
</p>
<p>δJ&lowast; =
&int;&int;
</p>
<p>D
</p>
<p>&nabla; &middot; (hk&nabla;u&lowast;) dA &minus;
&int;&int;
</p>
<p>D
</p>
<p>&nabla; &middot; (k&nabla;u&lowast;)h dA
</p>
<p>Applying the divergence theorem to the first integral changes it to an integral on the
</p>
<p>boundary
</p>
<p>δJ&lowast; =
∮
</p>
<p>&part;D
</p>
<p>h(kn &middot; &nabla;u&lowast;) ds &minus;
&int;&int;
</p>
<p>D
</p>
<p>&nabla; &middot; (k&nabla;u&lowast;)h dA</p>
<p/>
</div>
<div class="page"><p/>
<p>Solutions to Selected Problems 273
</p>
<p>Eliminating the boundary integral leads to two choices for natural boundary con-
</p>
<p>ditions: (i) homogeneous Neumann conditions, n &middot; &nabla;u = &part;u
&part;n
</p>
<p>= 0, or (ii) specified
Dirichlet conditions, h(&part;D) = 0 =&rArr; u(&part;D) = f (&part;D) given. Subsequently, the fun-
damental lemma can be applied to the remaining double integral to yield the elliptic
</p>
<p>PDE
</p>
<p>&nabla; &middot; (k&nabla;u) = 0.
</p>
<p>3.19 (a) The augmented Lagrangian for this problem is
</p>
<p>L = 1+ (y&prime;)2 &minus; λ
(
</p>
<p>y2 &minus; 80
π
</p>
<p>)
</p>
<p>,
</p>
<p>then the Euler-Lagrange problem is
</p>
<p>d2y
</p>
<p>dx2
+ λy = 0, y(0) = 0, y(π) = 1,
</p>
<p>&int; π
</p>
<p>0
</p>
<p>y2 dx = 80.
</p>
<p>The ODE is a linear-constant coefficient equation; it breaks down into two cases,
</p>
<p>depending on the value of λ ≷ 0.
</p>
<p>If λ = &minus;α2 &lt; 0 then the solution of the boundary value problem for the ODE is
</p>
<p>y&minus;(x) =
sinh(αx)
</p>
<p>sinh(απ)
.
</p>
<p>If λ = α2 &gt; 0 then the solution is
</p>
<p>y+(x) =
sin(αx)
</p>
<p>sin(απ)
.
</p>
<p>In the two cases, the integral becomes
</p>
<p>I&plusmn;(α) =
&int; π
</p>
<p>0
</p>
<p>y2&plusmn; dx =
{
</p>
<p>2απ &minus; sin(2απ)
4α sin2(απ)
</p>
<p>,
sinh(2απ)&minus; 2απ
4α sinh2(απ)
</p>
<p>}
</p>
<p>I+(α) &ge; π/3 and has multiple solutions for any value of the constraint greater than
π/3 &asymp; 1.047. Meanwhile 0 &le; I&minus;(α) &le; π/3 and is monotone decreasing, so there is
a single solution for each value of the constraint.</p>
<p/>
</div>
<div class="page"><p/>
<p>274 Solutions to Selected Problems
</p>
<p>3.20 (a) Recall Green&rsquo;s theorem,
</p>
<p>∮
</p>
<p>&part;D
</p>
<p>P(x, y) dx + Q(x, y) dy =
&int;&int;
</p>
<p>D
</p>
<p>(
&part;Q
</p>
<p>&part;x
&minus;
</p>
<p>&part;P
</p>
<p>&part;y
</p>
<p>)
</p>
<p>dA
</p>
<p>We have
</p>
<p>1
</p>
<p>2
</p>
<p>&int; 1
</p>
<p>0
</p>
<p>[
</p>
<p>x(t)y&prime;(t)&minus; y(t)x&prime;(t)
]
</p>
<p>dt =
∮
</p>
<p>1
2
</p>
<p>x dy &minus; 1
2
</p>
<p>y dx.
</p>
<p>We can identify P = &minus; 1
2
</p>
<p>y,Q = 1
2
</p>
<p>x, therefore,
</p>
<p>1
</p>
<p>2
</p>
<p>&int; 1
</p>
<p>0
</p>
<p>[
</p>
<p>x(t)y&prime;(t)&minus; y(t)x&prime;(t)
]
</p>
<p>dt =
&int;&int;
</p>
<p>(
1
2
+ 1
</p>
<p>2
</p>
<p>)
</p>
<p>dA = Area.
</p>
<p>(b) The Euler-Lagrange equations are
</p>
<p>d
</p>
<p>dt
</p>
<p>(
</p>
<p>y +
λx&prime;
</p>
<p>&radic;
</p>
<p>(x&prime;)2 + (y&prime;)2
</p>
<p>)
</p>
<p>= 0
d
</p>
<p>dt
</p>
<p>(
</p>
<p>&minus;x +
λy&prime;
</p>
<p>&radic;
</p>
<p>(x&prime;)2 + (y&prime;)2
</p>
<p>)
</p>
<p>= 0
</p>
<p>(c) Integrating once yields
</p>
<p>y +
λx&prime;
</p>
<p>&radic;
</p>
<p>(x&prime;)2 + (y&prime;)2
= c1 &minus; x +
</p>
<p>λy&prime;
&radic;
</p>
<p>(x&prime;)2 + (y&prime;)2
= c2
</p>
<p>and can be re-arranged to yield
</p>
<p>(c1 &minus; y)2 + (c2 + x)2 = λ2
(
(x&prime;)2 + (y&prime;)2
</p>
<p>(x&prime;)2 + (y&prime;)2
</p>
<p>)2
</p>
<p>= λ2</p>
<p/>
</div>
<div class="page"><p/>
<p>Solutions to Selected Problems 275
</p>
<p>Hence we have the equation of a circle with radius λ = P/(2π) and centre (&minus;c2, c1).
Having the origin on the circle means that c21 + c22 = λ2, hence we can take c1 =
λ sin θ, c2 = λ cos θ for any θ .
</p>
<p>3.23 (a) The augmented functional is
</p>
<p>I =
&int; 2
</p>
<p>1
</p>
<p>[
</p>
<p>6y2 + x2
(
</p>
<p>dy
</p>
<p>dx
</p>
<p>)2
</p>
<p>+ x7 &minus; λ(24xy &minus; 5)
]
</p>
<p>dx.
</p>
<p>(b) Substituting ỹ(x) = y&lowast;(x) + εh(x) and expanding for ε &rarr; 0 yields the first
variation as
</p>
<p>δI =
&int; 2
</p>
<p>1
</p>
<p>12y&lowast;h + 2x2y&prime;&lowast;h&prime; &minus; 24xh dx
</p>
<p>Examining the boundary condition ỹ(2) = ỹ(1) + 3 gives that h(2) = h(1),
and applied to the boundary terms produced by integration by parts, 2x2y&prime;&lowast;h|21 =
2(4y&prime;&lowast;(2)&minus; y&prime;&lowast;(1))h(1), hence we determine the natural boundary condition
</p>
<p>4y&prime;&lowast;(2)&minus; y&prime;&lowast;(1) = 0
</p>
<p>and then the Euler-Lagrange equation is
</p>
<p>12y &minus; (2x2y&prime;)&prime; &minus; 24λx = 0 =&rArr; x2y&prime;&prime; + 2xy&prime; &minus; 6y = &minus;12λx.
</p>
<p>This is an inhomogeneous Cauchy-Euler equation with solution
</p>
<p>y = c1x2 + c2x&minus;3 + 3λx
</p>
<p>(c) Substituting into the boundary condition, the natural boundary condition and the
</p>
<p>integral constraint yields three equations for c1, c2, λ,
</p>
<p>3c1 &minus;
7
</p>
<p>8
c2 + 3λ = 3, 14c1 +
</p>
<p>9
</p>
<p>4
c2 + 9λ = 0, 90c1 + 12c2 + 168λ = 5.
</p>
<p>3.24 The augmented functional for the constrained problem is
</p>
<p>I =
&int; 2
</p>
<p>1
</p>
<p>3y2
</p>
<p>x5
&minus;
</p>
<p>(y&prime;)2
</p>
<p>x3
&minus; λ(y + 3) dx
</p>
<p>The resulting Euler-Lagrange equation for y = y&lowast;(x) is
</p>
<p>x2y&prime;&prime; &minus; 3xy&prime; + 3y = 1
2
λx5.</p>
<p/>
</div>
<div class="page"><p/>
<p>276 Solutions to Selected Problems
</p>
<p>The solution of this inhomogeneous Cauchy-Euler equation is
</p>
<p>y = c1x + c2x3 +
λ
</p>
<p>16
x5.
</p>
<p>Applying the boundary conditions and the integral constraint determine c1= 11,
c2 = &minus;8, λ = 16.
</p>
<p>3.26 (a) The Hamiltonian is
</p>
<p>H = L + λf = 4x2 + 3xu + u2 + λ(3x + u).
</p>
<p>The PMP yields
</p>
<p>dx
</p>
<p>dt
= 3x + u,
</p>
<p>dλ
</p>
<p>dt
= &minus;8x &minus; 3u &minus; 3λ, 3x + 2u + λ = 0.
</p>
<p>Eliminating λ reduces the problem to a system of two linear ODEs in x, u,
</p>
<p>dx
</p>
<p>dt
= 3x + u
</p>
<p>du
</p>
<p>dt
= &minus;5x &minus; 3u
</p>
<p>having the general solution
</p>
<p>x(t) = c1e2t + c2e&minus;2t u(t) = &minus;c1e2t &minus; 5c2e&minus;2t
</p>
<p>Substituting these into the Hamiltonian yields H = 16c1c2. The Hamiltonian is
indeed a constant, and to enforce H = 0 we need either c1 = 0 or c2 = 0. The
possibility of c1 = c2 = 0 can be excluded because it would give the trivial solution
and could not satisfy the initial condition x(0) = 2. Consider c2 = 0, then c1 = 2;
this yields a monotone increasing function for x(t) &ge; 2 and could never satisfy the
target condition x(T) = 1. Hence c1 = 0 yielding x(t) = 2e&minus;2t and the target
condition determines T&lowast; = 12 ln 2.
(b) Everything remains the same, but since T = 1
</p>
<p>4
is imposed, we lose the natural
</p>
<p>boundary condition, that H = 0, so imposing x(0) = 2 and x( 1
4
) = 1 determine
</p>
<p>the constants, and
</p>
<p>x(t) =
(
</p>
<p>e1/2 &minus; 2
e &minus; 1
</p>
<p>)
</p>
<p>e2t +
(
2e &minus; e1/2
</p>
<p>e &minus; 1
</p>
<p>)
</p>
<p>e&minus;2t u(t) = &minus;10e&minus;2t .
</p>
<p>For this solution, the value of the Hamiltonian is
</p>
<p>H = &minus;
16(e &minus; 2)(2e1/2 &minus; 1)
</p>
<p>(e &minus; 1)2
&asymp; &minus;7.21 &lt; 0.</p>
<p/>
</div>
<div class="page"><p/>
<p>Solutions to Selected Problems 277
</p>
<p>This illustrates the maximum in PMP, at the optimal solution (having the optimal
</p>
<p>stopping time), the value of the Hamiltonian will be maximised; in general H &le; 0.
</p>
<p>Chapter4
</p>
<p>4.1 For cases (i, ii, iii) the scaled problem is
</p>
<p>d2y
</p>
<p>dt2
= &minus;
</p>
<p>Π1
</p>
<p>(1+Π2y)2
y(0) = Π3 y&prime;(0) = &minus;Π4
</p>
<p>Π1 =
4πGρERET
</p>
<p>2
</p>
<p>3L
Π2 =
</p>
<p>L
</p>
<p>RE
Π3 =
</p>
<p>2
</p>
<p>L
Π4 =
</p>
<p>V0T
</p>
<p>L
</p>
<p>(i) Starting with Π4 = 1 we get L = V0T then Π3 = 1 sets L = 2,T = 2/V0,
Π1 = 8πGρERE/(3V20) = ε &rarr; 0
</p>
<p>d2y
</p>
<p>dt2
= &minus;
</p>
<p>ε
</p>
<p>(1+Π2y)2
y(0) = 1 y&prime;(0) = &minus;1
</p>
<p>(ii) Starting with Π1 = 1 we get L = 4πGρERET2/3 then Π3 = 1 sets T =&radic;
3/(2πGρERE) and L = 2 and Π4 = V0
</p>
<p>&radic;
</p>
<p>3/(8πGρERE) = ε &rarr; 0
</p>
<p>d2y
</p>
<p>dt2
= &minus;
</p>
<p>1
</p>
<p>(1+Π2y)2
y(0) = 1 y&prime;(0) = &minus;ε
</p>
<p>(iii) Starting with Π3 = 1, we get L = 2, then Π4 = 1 sets T = 2/V0 and
Π1 = 8πGρERE/(3V20) = ε &rarr; 0
</p>
<p>d2y
</p>
<p>dt2
= &minus;
</p>
<p>ε
</p>
<p>(1+Π2y)2
y(0) = 1 y&prime;(0) = &minus;1
</p>
<p>For (iv) the scaled problem is
</p>
<p>d2y
</p>
<p>dt2
= &minus;
</p>
<p>Π1
</p>
<p>(y +Π2)2
y(0) = Π3 y&prime;(0) = &minus;Π4
</p>
<p>Π1 =
GMET
</p>
<p>2
</p>
<p>L3
Π2 =
</p>
<p>RE
</p>
<p>L
Π3 =
</p>
<p>2
</p>
<p>L
Π4 =
</p>
<p>V0T
</p>
<p>L
</p>
<p>Setting Π3 = Π4 = 1 yields L = 2 and T = 2/V0 and Π2 = RE/2 = ε &rarr; 0
</p>
<p>d2y
</p>
<p>dt2
= &minus;
</p>
<p>Π1
</p>
<p>(y + ε)2
y(0) = 1 y&prime;(0) = &minus;1</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4">http://dx.doi.org/10.1007/978-3-319-23042-9_4</a></div>
</div>
<div class="page"><p/>
<p>278 Solutions to Selected Problems
</p>
<p>4.2 Defining the nondimensionalized solution as X = Lx(t) with T = Tt, we can
write the scaled problem as
</p>
<p>x&prime;&prime; + x = Π1 sin(Π2t), x(0) = 1, x&prime;(0) = Π3
</p>
<p>with L = X0 being an imposed scale set by the IC and derived timescale T =
&radic;
</p>
<p>M/K
</p>
<p>being the inverse of the natural frequency ω0 =
&radic;
</p>
<p>K/M and
</p>
<p>Π1 =
F
</p>
<p>KX0
, Π2 =
</p>
<p>Ω
</p>
<p>ω0
, Π3 =
</p>
<p>ω0V0
</p>
<p>X0
.
</p>
<p>4.3 The choice of scalings L = B/
&radic;
</p>
<p>KM,T = M/B yields the nondimensional
problem
</p>
<p>x&prime;&prime; + x&prime; + x3 = Π1 sin(Π2t), x(0) = Π3, x&prime;(0) = Π4,
</p>
<p>with parameters
</p>
<p>Π1 =
FK1/2M3/2
</p>
<p>B3
, Π2 = ω
</p>
<p>M
</p>
<p>B
, Π3 =
</p>
<p>AK1/2M1/2
</p>
<p>B1
, Π4 =
</p>
<p>CK1/2M3/2
</p>
<p>B2
.
</p>
<p>4.5 (a) After some algebra, we get the scalings
</p>
<p>X =
DE2
</p>
<p>CFH
, Y =
</p>
<p>E
</p>
<p>F
, Z =
</p>
<p>E2
</p>
<p>FH
, T =
</p>
<p>DE
</p>
<p>BCH
,
</p>
<p>then the dimensionless parameters follow as
</p>
<p>α =
AF
</p>
<p>BE
, β =
</p>
<p>BCH2
</p>
<p>D2E2
, γ =
</p>
<p>BC
</p>
<p>DE
, δ =
</p>
<p>3GE
</p>
<p>F2
</p>
<p>and μ = X0/X, σ = Y0/Y, ω = Z0/Z
(b) x&prime; = α &minus; y, βy&prime; = x &minus; z and 0 = y &minus; y2 + 1
</p>
<p>3
δy3 &minus; z. Solving the last equation
</p>
<p>for z = f (y) yields a phase plane system for (x, y)
</p>
<p>x&prime; = α &minus; y βy&prime; = x &minus; y + y2 &minus; 1
3
δy3
</p>
<p>A mismatch will occur unless the initial conditions satisfy ω = f (σ ).
(c) x&prime; = α &minus; y, 0 = x &minus; z, γ z&prime; = y &minus; y2 + 1
</p>
<p>3
δy3 &minus; z. Using the second equation, the
</p>
<p>other two reduce to
</p>
<p>x&prime; = α &minus; y βx&prime; = y &minus; y2 + 1
3
δy3 &minus; x.</p>
<p/>
</div>
<div class="page"><p/>
<p>Solutions to Selected Problems 279
</p>
<p>Equating the two expressions for x&prime; yields γ (α &minus; y) = y &minus; y2 + 1
3
δy3 &minus; x. Finally,
</p>
<p>implicitly differentiating and using the equation for x&prime; yields
</p>
<p>y&prime; =
α &minus; y
</p>
<p>1+ γ &minus; 2y + δy2
</p>
<p>A mismatch will occur unless the initial conditions satisfy ω = μ.
</p>
<p>4.7 The final nondimensionalized system is
</p>
<p>ht + hux + uhx = 0 ut + uux +
1
</p>
<p>Fr2
hx = 0
</p>
<p>where the Froude number is defined as Fr = U/
&radic;
</p>
<p>gH.
</p>
<p>4.9 (a) Let δ = W/L then Π1 = 4(1+ δ)(1+ 1/δ).
(b) Π1 = π((3(1 + δ) &minus;
</p>
<p>&radic;
(3+ δ)(1+ 3δ))(3(1 + 1/δ) &minus;
</p>
<p>&radic;
(3/δ + 1)(1/δ + 3).
</p>
<p>Π1,ellipse &gt; Π1,rect if the aspect ratio is sufficiently large or small.
</p>
<p>(c) Let x = Π2, y = Π3 and z = 1/Π21 for a more convenient calculations: z =
g(x, y) = 1
</p>
<p>2
( 1
2
&minus; x)( 1
</p>
<p>2
&minus; y)(x + y &minus; 1
</p>
<p>2
). Using multivariable calculus, determine the
</p>
<p>critical points of g: gx(x, y) = gy(x, y) = 0 yielding (x, y) = (0, 12 ), (
1
2
, 1
2
), ( 1
</p>
<p>2
, 0)
</p>
<p>or ( 1
3
, 1
3
). Of these possibilities, ( 1
</p>
<p>3
, 1
3
) maximises g = 1/432 and hence minimises
</p>
<p>Π1,tri &ge; 12
&radic;
3. Note that (12
</p>
<p>&radic;
3 &asymp; 20.78) &gt; (12.56 &asymp; 4π) as is expected from the
</p>
<p>result that the circle minimises the perimeter-to-area ratio, Π1,circ = 4π .
</p>
<p>4.11 Π1 = AT/B,Π2 = AC/B2,Π3 = A2D/B3,T = (B/A)f (AC/B2,A2D/B3)
</p>
<p>4.12 (a) The equations for the dimensional exponents for cancelling out units in the
</p>
<p>Π &rsquo;s are:
</p>
<p>A &minus; 3B &minus; C + E + F = 0 [m]
B + C + D = 0 [kg]
</p>
<p>&minus;2A &minus; C &minus; 2D &minus; F = 0 [s]
</p>
<p>These three equations are linearly independent (as can be seen by reducing them to
</p>
<p>echelon form), so r̃ = 3. There are 6 given quantities and 3 base units (r = 3), so
we get n &minus; r̃ = 6&minus; 3 = 3 free parameters.
</p>
<p>Chapter5
</p>
<p>5.1 Using the rescaled solution (5.1), we can rewrite Burgers&rsquo; equation as
</p>
<p>ut +
(
</p>
<p>UT
</p>
<p>L
</p>
<p>)
</p>
<p>uux =
(
</p>
<p>T
</p>
<p>L
</p>
<p>)
</p>
<p>κuxx.
</p>
<p>To make this scale invariant, the coefficient factors need to be set to one. The nor-
</p>
<p>malising the first yields U = L/T. Normalising the second yields L = T1/2 and</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5">http://dx.doi.org/10.1007/978-3-319-23042-9_5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5">http://dx.doi.org/10.1007/978-3-319-23042-9_5</a></div>
</div>
<div class="page"><p/>
<p>280 Solutions to Selected Problems
</p>
<p>subsequently U = T&minus;1/2. A scale-invariant similarity variable can be obtained from
Π1 = LTc = T1/2T1/2 = T0, hence c = 1/2 and hence determines η = xt&minus;1/2.
Likewise a scale-invariant similarity function is determined by Π2 = UTd =
T&minus;1/2Td = T0, hence d = 1/2 and f (η) = t1/2u yielding the similarity solution
form u(x, t) = t&minus;1/2f (η). Substituting this into Burgers&rsquo; equation yields
</p>
<p>1
2
</p>
<p>(
</p>
<p>f + η
df
</p>
<p>dη
</p>
<p>)
</p>
<p>+ f
df
</p>
<p>dη
= κ
</p>
<p>d2f
</p>
<p>dη2
.
</p>
<p>5.2 Applying (5.1)&ndash;(5.3) and the integral yields
</p>
<p>ut +
(
</p>
<p>UT
</p>
<p>L
</p>
<p>)
</p>
<p>uux = 0, (U2L)
&int; &infin;
</p>
<p>0
</p>
<p>u2 dx = 1.
</p>
<p>Making the PDE scale invariant selects the scaling relation U = L/T. Then making
the integral scale-invariant determines L = T2/3 and consequently U = T&minus;1/3.
Further, this determines the similarity variable η = x/t2/3 and the similarity solution
as u(x, t) = t&minus;1/3f (η). Substituting this into the inviscid Burgers equation yields the
ODE for f (η),
</p>
<p>&minus; 1
3
</p>
<p>(
</p>
<p>f + η
df
</p>
<p>dη
</p>
<p>)
</p>
<p>+ f
df
</p>
<p>dη
= 0
</p>
<p>&int; &infin;
</p>
<p>0
</p>
<p>f 2 dη = 1.
</p>
<p>The similarity solution likewise reduces the generalised Burgers equation, u(ut +
uux) = κuxx, to the ODE
</p>
<p>&minus; 1
3
</p>
<p>f
</p>
<p>(
</p>
<p>f + 2η
df
</p>
<p>dη
</p>
<p>)
</p>
<p>+ f 2
df
</p>
<p>dη
= κ
</p>
<p>d2f
</p>
<p>dη2
.
</p>
<p>5.3 (a, b) Applying (5.1) to the PDE yields
</p>
<p>&part;u
</p>
<p>&part;t
+
</p>
<p>(
UT
</p>
<p>L
</p>
<p>)
</p>
<p>u
&part;u
</p>
<p>&part;x
= (Tσ+1U3)tσu4.
</p>
<p>To make this equation scale invariant, we need U = L/T (from the first coefficient)
and Tσ+1U3 = 1 in the second one. The boundary condition must be scale invariant
as well,
</p>
<p>u(0, t) =
(
</p>
<p>T3
</p>
<p>U
</p>
<p>)
</p>
<p>t3 =&rArr; U = T3,
</p>
<p>consequently L = T4 (from L = UT). Satisfying the second condition for the scale
invariance of the PDE, Tσ+1U3 = Tσ+1T9 = T0 determines σ = &minus;10.</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5">http://dx.doi.org/10.1007/978-3-319-23042-9_5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5">http://dx.doi.org/10.1007/978-3-319-23042-9_5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5">http://dx.doi.org/10.1007/978-3-319-23042-9_5</a></div>
</div>
<div class="page"><p/>
<p>Solutions to Selected Problems 281
</p>
<p>(c) The scale-invariant similarity variable is η = x/t4 and the form of the similarity
solution is u(x, t) = t3f (η). Substituting this form into the PDE reduces it to the
ODE,
</p>
<p>3f &minus; 4η
df
</p>
<p>dη
+ f
</p>
<p>df
</p>
<p>dη
= f 4.
</p>
<p>5.4 Satisfying scale-invariance in the heat equation determines L = T1/2 and the
similarity variable η = x/t1/2.
(a) The boundary condition will be scale invariant for U = T2. This yields the form
of the similarity solution as u(x, t) = t2f (η). Substituting in the PDE yields the ODE
problem
</p>
<p>2f &minus; 1
2
ηf &prime; = f &prime;&prime;, f (0) = 1, f (η &rarr; &infin;) &rarr; 0.
</p>
<p>(b) Here the boundary condition will be scale-invariant if U = L = T1/2 yielding
the similarity solution u(x, t) = t1/2f (η), satisfying the ODE problem,
</p>
<p>1
2
(f &minus; ηf &prime;) = f &prime;&prime;, f &prime;(0) = 2, f (η &rarr; &infin;) &rarr; 0.
</p>
<p>(c) Here the boundary condition will be scale-invariant ifU = 1/L = T&minus;1/2 yielding
the similarity solution u(x, t) = t&minus;1/2f (η), satisfying the ODE problem,
</p>
<p>&minus; 1
2
(f + ηf &prime;) = f &prime;&prime;, f &prime;(0) = f (0)2, f (η &rarr; &infin;) &rarr; 0.
</p>
<p>(d) Here the integral condition will be scale-invariant if L3U = 1, or U = T&minus;3/2
yielding the similarity solution u(x, t) = t&minus;3/2f (η), satisfying the ODE problem,
</p>
<p>&minus; 1
2
(3f + ηf &prime;) = f &prime;&prime;,
</p>
<p>&int; &infin;
</p>
<p>0
</p>
<p>η2f dη = 1, f (η &rarr; &infin;) &rarr; 0.
</p>
<p>(e) Here L = T = 1 but U is a free parameter. The solution can be written as
u(x, t) = Cete&minus;x , which is actually a travelling wave, u = Ce&minus;(x&minus;t).
</p>
<p>5.5 Applying (5.1) to the PDE yields
</p>
<p>&part;u
</p>
<p>&part;t
=
</p>
<p>(
T
</p>
<p>L2
</p>
<p>)
&part;2u
</p>
<p>&part;x2
+
</p>
<p>(
</p>
<p>U
3
T
</p>
<p>)
</p>
<p>u4.
</p>
<p>The two coefficients must be normalised in order to make the PDE scale-invariant.
</p>
<p>The first coefficient determines L = T1/2 and the second sets U = T&minus;1/3. The scale-
invariant similarity variable is η = x/t1/2 and the form of the similarity solution is
u(x, t) = t&minus;1/3f (η), satisfying the ODE
</p>
<p>&minus; 1
3
</p>
<p>f &minus; 1
2
ηf &prime; = f &prime;&prime; + f 4.</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5">http://dx.doi.org/10.1007/978-3-319-23042-9_5</a></div>
</div>
<div class="page"><p/>
<p>282 Solutions to Selected Problems
</p>
<p>5.6 (a) Applying (5.1) to the PDE yields
</p>
<p>&part;u
</p>
<p>&part;t
= &minus;
</p>
<p>(
U3T
</p>
<p>L2
</p>
<p>)
&part;
</p>
<p>&part;x
</p>
<p>(
</p>
<p>u3
&part;u
</p>
<p>&part;x
</p>
<p>)
</p>
<p>&minus;
(
</p>
<p>UT
</p>
<p>L4
</p>
<p>)
&part;
</p>
<p>&part;x
</p>
<p>(
</p>
<p>u
&part;3u
</p>
<p>&part;x3
</p>
<p>)
</p>
<p>The two coefficients must be normalised in order to make the PDE scale-invariant.
</p>
<p>The first coefficient determinesL2 = U3T; substituting this intoL4 = UT determines
U = T&minus;1/5 and subsequentlyL = T1/5. The scale-invariant similarity variable is then
η = x/t1/5 and the form of the similarity solution is u(x, t) = t&minus;1/5f (η), satisfying
the ODE
</p>
<p>&minus; 1
5
(f + ηf &prime;) = &minus;(f 3f &prime;)&prime; &minus; (ff &prime;&prime;&prime;)&prime;.
</p>
<p>Note that the form and scaling of the similarity solution has already been determined,
</p>
<p>the additional integral condition happens to be consistent,
&int;
</p>
<p>f dη = 1.
(b) Applying
</p>
<p>u(x, t) = Uũ(x̃, t̃ ), x = Lx̃, t = tc + Tt̃
</p>
<p>to thePDEyields the same scalings,U = T&minus;1/5 andL = T1/5. However the similarity
variable and solution now take a modified form,
</p>
<p>η =
x
</p>
<p>(tc &minus; t)1/5
u(x, t) = (tc &minus; t)&minus;1/5f (η),
</p>
<p>and the similarity function satisfies the modified ODE
</p>
<p>1
5
(f + ηf &prime;) = &minus;(f 3f &prime;)&prime; &minus; (ff &prime;&prime;&prime;)&prime;.
</p>
<p>In part (a), the similarity solution evolves to a limitingbehaviour asT &rarr; &infin; (t &rarr; &infin;),
while for this finite-time blow-up case, divergence occurs as T &rarr; 0 (t &rarr; tc).
</p>
<p>5.8 The similarity solutions are
</p>
<p>h(x, t) = t&minus;1/2f (xt&minus;3/8), u(x, t) = t&minus;5/8g(xt&minus;3/8).
</p>
<p>Chapter6
</p>
<p>6.2 At leading order it is straightforward to identify δ0 = 1 and x0 = 3 as a triple root
of (x0&minus;3)3 = 0. The next iteration, x &sim; 3+δ1x1 yields δ31x31 = 216ε hence δ1 = ε1/3
and x1 is given by the one of the three cube roots of 216, namely x1 = 6ei2πk/3 for
k = 0, 1, 2. Going on, we will get δ2 = ε2/3 and
</p>
<p>x &sim; 3+ 6ε1/3 + 8ε2/3, x &sim; 3&minus; (3&plusmn; i3
&radic;
3)ε1/3 &minus; (4∓ i4
</p>
<p>&radic;
3)ε2/3
</p>
<p>6.3 Observe that setting ε = 0 in the equation yields a contradiction (&lsquo;60 = 0&rsquo;),
hence the solutions must be singular in order to yields valid balances. Let x = δX to
yield</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_5">http://dx.doi.org/10.1007/978-3-319-23042-9_5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_6">http://dx.doi.org/10.1007/978-3-319-23042-9_6</a></div>
</div>
<div class="page"><p/>
<p>Solutions to Selected Problems 283
</p>
<p>ε6δ3X3
︸ ︷︷ ︸
</p>
<p>(1)
</p>
<p>&minus; 5ε3δ2X2
︸ ︷︷ ︸
</p>
<p>(2)
</p>
<p>&minus; 20εδX
︸ ︷︷ ︸
</p>
<p>(3)
</p>
<p>+ 60
︸︷︷︸
</p>
<p>(4)
</p>
<p>= 0.
</p>
<p>Consider the different possibilities for dominant balances to determine the distin-
</p>
<p>guished limits yielding solutions. This is a third order polynomial, so there must be
</p>
<p>exactly three roots that must represented within the set of distinguished limits.
</p>
<p>These distinguished limits are given by
</p>
<p>&bull; Balancing terms (3, 4): δ = ε&minus;1, x &sim; 3/ε
&bull; Balancing terms (2, 3): δ = ε&minus;2, x &sim; &minus;4/ε2
&bull; Balancing terms (1, 2): δ = ε&minus;3, x &sim; 5/ε3
</p>
<p>6.5 (a) The solution is given by
</p>
<p>v(t) &sim; &minus; 1
2
</p>
<p>t2 &minus; 1
20
εt5 &minus; 1
</p>
<p>160
ε2t8.
</p>
<p>(b) Note that after factoring out t2, the magnitude of the terms follows
</p>
<p>O(1) ≫ O(εt3) ≫ O(ε2t6)
</p>
<p>with the ordering being preserved if εt3 ≪ 1, namely 0 &le; t ≪ O(ε&minus;1/3).
</p>
<p>6.6 Observe that setting ε = 0 in the equations yields &minus;y = 1 and y = 4, hence
we get a contradiction (y is overdetermined). Rescale each variable independently,
</p>
<p>x = δ(ε)X and y = σ(ε)Y and carry out dominant balance of the system to obtain
δ = ε&minus;1 (from a dominant balance in the first equation) and σ = ε0 (from a dominant
balance in the second equation). Subsequently,
</p>
<p>x &sim;
1
</p>
<p>ε
(5&minus; 5ε) y &sim; 4&minus; 5ε.
</p>
<p>6.7 Taking the logarithm of the equation, we get
</p>
<p>ln(2)+ 2 ln(x)&minus; 5x = 3 ln(2)+ ln(ε)
</p>
<p>It is easy to identify ln(ε) &rarr; &minus;&infin; as the dominant term on the righthand side. Now,
substitute x = δ0x0 with the assumption that δ0 &rarr; &infin;,
</p>
<p>ln(2)+ 2 ln(δ0)+ 2 ln(x0)&minus; 5δ0x0 = 3 ln(2)+ ln(ε)
</p>
<p>Since x0 = O(1), so is its log. Since z ≫ ln(z) as z &rarr; &infin; the 5δ0x0 term is the
largest term on the left-hand side of the equation. Hence we get that x0 = 1/5
and δ0 = &minus; ln(ε). Note that we have put the negative sign in δ0 rather than in the
coefficient so that the gauge function is positive (ln(z) &rarr; &minus;&infin; for z &rarr; 0). In general
for dealing with logarithms, it may be better to write them as δ0 = ln( 1ε ). The next
iteration, x &sim; δ0x0 + δ1x1 (with δ0 ≫ δ1) yields a dominant balance between terms</p>
<p/>
</div>
<div class="page"><p/>
<p>284 Solutions to Selected Problems
</p>
<p>coming from the original 2 ln(x) and 5x terms to determine δ1 = ln(ln( 1ε )) and the
solution as
</p>
<p>x &sim; 1
5
ln( 1
</p>
<p>ε
)+ 2
</p>
<p>5
ln(ln( 1
</p>
<p>ε
)).
</p>
<p>6.10 (a) Substituting h = 1+ εη and u = 1+ εν into the PDEs and then collecting
O(ε) terms yields the linearised system
</p>
<p>ηt + νx + ηx = 0 νt + νx + Fr&minus;2ηx = 0
</p>
<p>(b) We can then write the system in the form
</p>
<p>&part;
</p>
<p>&part;t
</p>
<p>(
</p>
<p>η
</p>
<p>ν
</p>
<p>)
</p>
<p>+
(
</p>
<p>1 1
</p>
<p>Fr&minus;2 1
</p>
<p>)
</p>
<p>︸ ︷︷ ︸
</p>
<p>M
</p>
<p>&part;
</p>
<p>&part;x
</p>
<p>(
</p>
<p>η
</p>
<p>ν
</p>
<p>)
</p>
<p>=
(
</p>
<p>0
</p>
<p>0
</p>
<p>)
</p>
<p>Consequently the determinant condition for the wavespeeds is
</p>
<p>|MT &minus; λI| =
∣
∣
∣
∣
</p>
<p>1&minus; λ Fr&minus;2
1 1&minus; λ
</p>
<p>∣
∣
∣
∣
= 0 =&rArr; (1&minus; λ)2 = Fr&minus;2
</p>
<p>and hence the waves generated will have speeds
</p>
<p>λ = 1&plusmn; Fr&minus;1
</p>
<p>and if Fr &gt; 1 then λ&plusmn; &gt; 0 and all waves will move to the right (downstream,
subcritical), while if Fr &lt; 1 then λ&plusmn; ≷ 0 and the two classes of waves move in
opposite directions.
</p>
<p>Chapter7
</p>
<p>7.3 Noting that the inhomogeneous boundary conditions are O(1), the dominant is
</p>
<p>finite and the coefficient 3 &le; (4&minus; x2) &le; 4 is bounded on the domain, we expect the
solution to be finite and bounded, hence we will assume β = 0 and seek solutions
of the form y = Y(X). Letting X = (x &minus; x&lowast;)/εα for α &ge; 0, equivalently we have
x = x&lowast; + εαX. The inhomogeneous term then becomes
</p>
<p>cos(π
2
</p>
<p>x) = cos(π
2
</p>
<p>x&lowast; + εα π2 X)
</p>
<p>There are two cases that need to be considered for the scaling of this termwith respect
</p>
<p>to the position of the boundary layer:
</p>
<p>x&lowast; = 0 =&rArr; cos(π2 x) = cos(ε
α π
2
</p>
<p>X) &sim; 1
x&lowast; = 1 =&rArr; cos(π2 x) = &minus; sin(ε
</p>
<p>α π
2
</p>
<p>X) &sim; &minus;εα π
2
</p>
<p>X</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7">http://dx.doi.org/10.1007/978-3-319-23042-9_7</a></div>
</div>
<div class="page"><p/>
<p>Solutions to Selected Problems 285
</p>
<p>To determine the dominant balances, examine
</p>
<p>ε1&minus;2αY &prime;&prime;
︸ ︷︷ ︸
</p>
<p>(1)
</p>
<p>+ ε0(4&minus; x2&lowast;)Y
︸ ︷︷ ︸
</p>
<p>(2)
</p>
<p>= cos(π
2
</p>
<p>x)
︸ ︷︷ ︸
</p>
<p>(3)
</p>
<p>,
</p>
<p>where term (3) is either O(ε0) or O(εα) as described above.
</p>
<p>For α = 0, we recover the outer distinguished limit which yields the leading order
outer solution
</p>
<p>y0(x) = &minus;
cos(π
</p>
<p>2
x)
</p>
<p>4&minus; x2
.
</p>
<p>Note that this solution does not satisfy either boundary condition (with y0(0) = &minus;1/4
and y0(1) = 0, so we will need boundary layers at both x&lowast; = 0 and x&lowast; = 1. First
consider the case that the boundary layer is on the left edge of the domain, x&lowast; = 0,
making term (3) be O(1). Then the dominant balance for the singular distinguished
</p>
<p>limit is between terms (1, 2) yielding α = 1
2
. Term (3) is of the same order, O(1),
</p>
<p>and hence also takes part in the dominant balance. The resulting leading order inner
</p>
<p>problem for y = Y(X) with X = x/ε1/2 is
</p>
<p>Y &prime;&prime;0 &minus; 4Y0 = 1, Y0(0) = &minus;1 =&rArr; YL0 = &minus;
3
</p>
<p>4
e&minus;2X &minus;
</p>
<p>1
</p>
<p>4
,
</p>
<p>where we note that we have eliminated an un-matchable exponentially growing term
</p>
<p>for X &rarr; &infin;. Applying the matching condition between this inner solution and the
outer solution,
</p>
<p>lim
X&rarr;&infin;
</p>
<p>YL0 = lim
x&rarr;0
</p>
<p>y0 = &minus;
1
</p>
<p>4
,
</p>
<p>which fortunately yields consistency and gives the overlap as &minus;1/4.
For the boundary layer at x&lowast; = 1, term (3) is O(εα). The singular distinguished
</p>
<p>limit is still α = 1
2
but now only terms (1, 2) are involved in the dominant balance,
</p>
<p>yielding the leading order inner problem for y = Y(X) with X = (x &minus; 1)/ε1/2,
</p>
<p>Y &prime;&prime;0 &minus; 3Y0 = 0, Y0(0) = 2 =&rArr; YR0 = 2e
&radic;
3X ,
</p>
<p>and again, an unmatchable exponentially growing term (for X &rarr; &minus;&infin;) has be
excluded. Here, applying the matching condition between this inner solution and the
</p>
<p>outer solution,
</p>
<p>lim
X&rarr;&minus;&infin;
</p>
<p>YR0 = lim
x&rarr;1
</p>
<p>y0 = 0,
</p>
<p>again yielding consistency of the construction process, here with zero overlap.
</p>
<p>Forming the left and right boundary layer corrections by subtracting the respective
</p>
<p>matching overlaps from their inner solutions, we can write the composite solution
</p>
<p>(7.22) as</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_7">http://dx.doi.org/10.1007/978-3-319-23042-9_7</a></div>
</div>
<div class="page"><p/>
<p>286 Solutions to Selected Problems
</p>
<p>y &sim; &minus;
cos(π
</p>
<p>2
x)
</p>
<p>4&minus; x2
&minus;
</p>
<p>3
</p>
<p>4
e&minus;2x/
</p>
<p>&radic;
ε + 2e
</p>
<p>&radic;
3/ε(x&minus;1).
</p>
<p>7.4 (a) Given that the boundary occurs at x&lowast; = 0, the singular solution will have the
form y = εβY(X) with X = x/εα and α &gt; 0. The homogeneous initial condition
provides no information. The second initial condition gives
</p>
<p>y&prime;(0) =
4
</p>
<p>ε2
=&rArr; εβ&minus;αY &prime;(0) = 4ε&minus;2,
</p>
<p>hence Y &prime;(0) = 0 and β &minus; α = &minus;2. Using this in the ODE, we get
</p>
<p>ε&minus;1&minus;αY &prime;&prime;
︸ ︷︷ ︸
</p>
<p>(1)
</p>
<p>+ 2ε&minus;2Y &prime;
︸ ︷︷ ︸
</p>
<p>(2)
</p>
<p>&minus; 6ε&minus;2+αY
︸ ︷︷ ︸
</p>
<p>(3)
</p>
<p>= 5εαX
︸ ︷︷ ︸
</p>
<p>(4)
</p>
<p>.
</p>
<p>It can be shown that the only consistent singular dominant balance is between terms
</p>
<p>(1, 2), yielding α = 1, hence β = &minus;1. Consequently, the inner problem is
</p>
<p>Y &prime;&prime; + 2Y &prime; &minus; 6εY = 5ε3X, Y(0) = 0, Y &prime;(0) = 4,
</p>
<p>which reduces to the leading order problem
</p>
<p>Y &prime;&prime;0 + 2Y &prime;0 = 0 =&rArr; Y0(X) = 2(1&minus; e&minus;2X),
</p>
<p>satisfying both initial conditions.
</p>
<p>(b) Applying the matching condition,
</p>
<p>lim
X&rarr;&infin;
</p>
<p>εβinnerYinner(X) = lim
x&rarr;0
</p>
<p>εβouteryouter(x),
</p>
<p>we get from the inner solution that the limit is 2/ε hence the outer solution must be
</p>
<p>scaled by βouter = &minus;1 and satisfy initial condition youter(0) = 2.
(c) Using β = &minus;1, α = 0 for the scaling of the outer solution yields the equation for
y = youter
</p>
<p>ε0y&prime;&prime; + 2ε&minus;1y&prime; &minus; 6ε&minus;1y = 5x, y(0) = 2
</p>
<p>which at leading order reduces to
</p>
<p>2y&prime;0 &minus; 6y0 = 0 y0(x) = 2e3x.
</p>
<p>Consequently, we can construct the composite solution from the outer solution plus
</p>
<p>the inner solution minus the overlap as
</p>
<p>y &sim;
2
</p>
<p>ε
e3x +
</p>
<p>2
</p>
<p>ε
</p>
<p>(
</p>
<p>1&minus; e&minus;2x/ε
)
</p>
<p>&minus;
2
</p>
<p>ε
=
</p>
<p>2
</p>
<p>ε
</p>
<p>(
</p>
<p>e3x &minus; e&minus;2x/ε
)
</p>
<p>.</p>
<p/>
</div>
<div class="page"><p/>
<p>Solutions to Selected Problems 287
</p>
<p>7.5 (a) The leading order outer solution is given by
</p>
<p>2y&prime; = ey0 = 0 =&rArr; y0(x) = &minus; ln
(
1
2
(x &minus; c)
</p>
<p>)
</p>
<p>,
</p>
<p>where the choice of the constant of integration depends on which boundary condition
</p>
<p>applies to the outer solution.
</p>
<p>(b) Assuming the solution to be finite, y = O(1), hence β = 0, dominant balances
are determined by
</p>
<p>ε1&minus;2αY &prime;&prime;
︸ ︷︷ ︸
</p>
<p>(1)
</p>
<p>+ 2ε&minus;αY &prime;
︸ ︷︷ ︸
</p>
<p>(2)
</p>
<p>&minus; ε0eY
︸︷︷︸
</p>
<p>(3)
</p>
<p>= 0.
</p>
<p>The outer distinguished limit is obtained by balancing terms (2,3) at α = 0. The
singular distinguished limited follows from balancing terms (1,2) at α = 1. The
leading order inner problem and its general solution is
</p>
<p>Y &prime;&prime;0 + 2Y &prime;0 = 0 =&rArr; Y0(X) = C1 + C2e&minus;2X .
</p>
<p>As yet we have not determined the position of the boundary layer (x&lowast;), but from the
form of Y0(X) we can see that only the choice x&lowast; = 0 can yield a nontrivial inner
solution. Consequently, applying the boundary condition
</p>
<p>Y0(0) = 0 =&rArr; Y0(X) = C1(1&minus; e&minus;2X).
</p>
<p>(c) Meanwhile we know that the other boundary condition, y(1) = 0 must apply to
the outer solution (since there is no boundary possible at x&lowast; = 1), hence the final
form of the outer solution becomes
</p>
<p>y0(x) = &minus; ln
(
1
2
(x + 1)
</p>
<p>)
</p>
<p>.
</p>
<p>Asymptotic matching to the inner solution then determines that C1 = ln(2). Conse-
quently the leading order composite solution is
</p>
<p>y &sim; &minus; ln
(
1
2
(x + 1)
</p>
<p>)
</p>
<p>&minus; ln(2)e&minus;2x/ε.
</p>
<p>(d) Expanding the outer solution as y &sim; y0+εy1, the exponential term can be written
as
</p>
<p>ey &sim; ey0+εy1 = ey0eεy1 &sim; ey0
(
</p>
<p>1+ εy0 + 12ε
2y21 + &middot; &middot; &middot;
</p>
<p>)
</p>
<p>.</p>
<p/>
</div>
<div class="page"><p/>
<p>288 Solutions to Selected Problems
</p>
<p>Collecting O(ε) terms in the ODE, the equation for y1 is then
</p>
<p>y&prime;&prime;0 + 2y&prime;1 + y1ey0 = 0 =&rArr; y1(x) = &minus;
ln
(
1
2
(x + 1)
</p>
<p>)
</p>
<p>2(x + 1)
.
</p>
<p>7.7 (a) The outer solution is given by
</p>
<p>y &sim; &plusmn;
&radic;
</p>
<p>4&minus; x2 +
ε
</p>
<p>2(4&minus; x2)
.
</p>
<p>(b) At x&lowast; = 2, the limiting behaviour of the outer solution for x &rarr; 2 determines
that β = 1
</p>
<p>2
α and the dominant balance of terms in the ODE determines the singular
</p>
<p>distinguished limit as α = 2
3
, β = 1
</p>
<p>3
with the inner problem being
</p>
<p>4X + ε2/3X2 + Y2 = &minus;Y &prime; X =
x &minus; 2
ε2/3
</p>
<p>.
</p>
<p>At x&lowast; = 0, there is one inner solution that must be matchable to the outer solution,
y(x &rarr; 0) &sim; &plusmn;2 = O(1), hence it must have β = 0. A dominant balance in the ODE
yields α = 1 with the inner problem
</p>
<p>ε2X2 + Y2 = 4&minus; Y &prime;, X =
x
</p>
<p>ε
.
</p>
<p>At x&lowast; = 0 there is a different inner solution that satisfies the initial condition y(0) =
3/ε, hence having β = &minus;1. Determination of the dominant balance with this value
of β yields α = 2 and the ODE
</p>
<p>ε6X2 + Y2 = 4ε2 &minus; Y &prime; X =
x
</p>
<p>ε2
,
</p>
<p>since this solution exists on a narrower domain (ε2 ≪ ε), this is sometimes called
an inner-inner solution.
</p>
<p>Chapter8
</p>
<p>8.1 (a) Using the method of separation of variables, we get (8.8),
</p>
<p>U(X,Y) =
&infin;
&sum;
</p>
<p>n=1
cn sinh(
</p>
<p>nπ
L
</p>
<p>Y) sin( nπ
L
</p>
<p>X)</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_8">http://dx.doi.org/10.1007/978-3-319-23042-9_8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_8">http://dx.doi.org/10.1007/978-3-319-23042-9_8</a></div>
</div>
<div class="page"><p/>
<p>Solutions to Selected Problems 289
</p>
<p>Evaluating the boundary condition along Y = H yields
</p>
<p>&part;U
</p>
<p>&part;Y
</p>
<p>∣
∣
∣
∣
Y=H
</p>
<p>=
&infin;
&sum;
</p>
<p>n=1
</p>
<p>(nπcn
</p>
<p>L
cosh( nπ
</p>
<p>L
H)
</p>
<p>)
</p>
<p>sin( nπ
L
</p>
<p>X) = e&minus;3X/L
</p>
<p>and the Fourier sine series determines the final form of the solution as
</p>
<p>U(X,Y) =
&infin;
&sum;
</p>
<p>n=1
</p>
<p>⎛
</p>
<p>⎝
2
</p>
<p>nπ cosh
(
</p>
<p>nπH
L
</p>
<p>)
</p>
<p>&int; L
</p>
<p>0
</p>
<p>e&minus;3X̃/L sin( nπ
L
</p>
<p>X̃) dX̃
</p>
<p>⎞
</p>
<p>⎠ sinh( nπ
L
</p>
<p>Y) sin( nπ
L
</p>
<p>X)
</p>
<p>(b) The leading order outer problem, scaled with Ū = 1m is
</p>
<p>u0yy = 0, u0(x, 0) = 0, u0y = He&minus;3x
</p>
<p>yielding u0(x, y) = He&minus;3xy.
(c) Substituting X = Lx,Y = Hy and taking the ε &rarr; 0 limit of the separation of
variables solution yields U = (Fourier sine series of e&minus;3x)Hy.
</p>
<p>8.2 (a) The leading order outer problem is
</p>
<p>u0yy = 0, u0(x, 0) = sin(5πx), u0(x, 1) = cos(3πx)
</p>
<p>yielding u0(x, y) = (cos(3πx)&minus; sin(5πx))y + sin(5πx).
(b) Since limx&rarr;0 u0(x, y) = y, the boundary layer correction at xL&lowast; = 0 can be
expressed asVL(X, y) = U(x, y)&minus;ywithVL(0, y) = sin( 1
</p>
<p>2
πy)&minus;y andhomogeneous
</p>
<p>Dirichlet boundary conditions on rest of the boundary of the semi-infinite strip,
</p>
<p>0 &le; y &le; 1, x &ge; 0. Then
</p>
<p>VL(XL, y) = &minus;2
&infin;
&sum;
</p>
<p>n=1
</p>
<p>(&minus;1)n
</p>
<p>(4n2 &minus; 1)nπ
e&minus;nπX
</p>
<p>L
</p>
<p>sin(nπy) XL =
x
</p>
<p>ε
&ge; 0.
</p>
<p>Similarly, the right boundary layer correction can be determined to be
</p>
<p>VR(XR, y) =
&infin;
&sum;
</p>
<p>k=0
</p>
<p>8
</p>
<p>(2k + 1)3π3
e(2k+1)πX
</p>
<p>R
</p>
<p>sin((2k + 1)πy) XR =
x &minus; 1
ε
</p>
<p>&le; 0.
</p>
<p>(d) The nondimensional form of the flux is
</p>
<p>JR =
1
</p>
<p>L
</p>
<p>&int; 1
</p>
<p>0
</p>
<p>ux(1, y) dy &sim;
1
</p>
<p>L
</p>
<p>&int; 1
</p>
<p>0
</p>
<p>5π(y &minus; 1)+
1
</p>
<p>ε
</p>
<p>&infin;
&sum;
</p>
<p>k=0
</p>
<p>8 sin((2k + 1)πy)
(2k + 1)2π2
</p>
<p>dy.</p>
<p/>
</div>
<div class="page"><p/>
<p>290 Solutions to Selected Problems
</p>
<p>The value of the flux is dominated by the O(1/ε) contribution from the boundary
</p>
<p>layer correction
</p>
<p>JR &sim;
1
</p>
<p>εL
</p>
<p>&infin;
&sum;
</p>
<p>k=0
</p>
<p>16
</p>
<p>(2k + 1)3π3
&asymp;
</p>
<p>16
</p>
<p>Hπ3
(1.0518) &asymp;
</p>
<p>0.543
</p>
<p>H
.
</p>
<p>8.3 Let f (x) = F(X). (a) The scaled form of the no-flux condition on the top
boundary is
</p>
<p>uy + ε215π sin(3πx)ux = 0 at y = f (x) = 15+ 5 cos(3πx).
</p>
<p>(b) The O(1) outer problem is
</p>
<p>u0yy = 0 u0y(x, 0) = 0 u0y(x, f (x)) = 0
</p>
<p>The O(ε) outer problem is
</p>
<p>u0xx + u1yy = 0 u1y(x, 0) = 0 u1y(x, f )+ 15π sin(3πx)u0x(x, f ) = 0
</p>
<p>yielding the solutions
</p>
<p>u0(x, y) = C2(x), u1(x, y) = &minus; 12C
&prime;&prime;
2 (x)y
</p>
<p>2 + C4(x)
</p>
<p>where the top boundary condition gives the compatibility condition
</p>
<p>&minus;
d
</p>
<p>dx
</p>
<p>(
</p>
<p>(15+ 5 cos(3πx))
dC2
</p>
<p>dx
</p>
<p>)
</p>
<p>= 0
</p>
<p>(d)Applyingmatching of the outer solution to the boundary layers implies zeroing the
</p>
<p>n = 0 coefficients in the cosine series expansions of the boundary layer corrections
yields the boundary conditions on C2(x),
</p>
<p>c0 =
1
</p>
<p>20
</p>
<p>&int; 20
</p>
<p>0
</p>
<p>[
</p>
<p>&minus;
y3
</p>
<p>100
&minus; C2(0)
</p>
<p>]
</p>
<p>dy = 0 =&rArr; C2(0) = &minus;20,
</p>
<p>d0 =
1
</p>
<p>10
</p>
<p>&int; 10
</p>
<p>0
</p>
<p>[
</p>
<p>3y2 &minus; C2(1)
]
</p>
<p>dy = 0 =&rArr; C2(1) = 100.
</p>
<p>8.5 (a) The O(1) problem is
</p>
<p>φ0yy = 0, φ0y(x, 0) = 0 =&rArr; φ0(x, y) = C0(x, t).
</p>
<p>The O(ε2) problem is
</p>
<p>φ1yy + φ0xx = 0, φ1y(x, 0) = 0 =&rArr; φ1(x, y) = &minus; 12C0xx(x, t)+ C1(x, t).</p>
<p/>
</div>
<div class="page"><p/>
<p>Solutions to Selected Problems 291
</p>
<p>The O(ε4) problem is
</p>
<p>φ2yy + φ1xx = 0, φ2y(x, 0) = 0 =&rArr; φ1(x, y) = 124C0xxxx(x, t)&minus;
1
2C1xx(x, t)y
</p>
<p>2 + C2(x, t).
</p>
<p>(b, c) See Exercise9.12.
</p>
<p>Chapter9
</p>
<p>9.1 Using the initial conditions, x0(t) = cos(t)+ 2 sin(t). Using the O(ε) equation
with x0(t) specified and the initial conditions x1(0) = &minus;1, x&prime;1(0) = 1, x1(t) =
[115 sin(t)&minus; 12 cos(t)] + [60t sin(t)&minus; 120t cos(t)] + [11 cos(3t)+ 2 sin(3t)] with
the homogeneous, secular and non-resonant respond terms grouped respectively.
</p>
<p>9.2 (a) x̃0 = a cos θ with θ &sim; (2 + 316εa
2)t works for any a &gt; 0. (b) x̃0 = a cos θ
</p>
<p>with ω0 = 3, ω1 = 0 satisfies the problem only for a = 2.
</p>
<p>9.3 (a) The amplitude equations are
</p>
<p>dA
</p>
<p>dτ
= 1
</p>
<p>2
A &minus;
</p>
<p>A
</p>
<p>8
(A2 + B2),
</p>
<p>dB
</p>
<p>dτ
= 1
</p>
<p>2
B &minus;
</p>
<p>B
</p>
<p>8
(B2 + A2).
</p>
<p>(b) Note that d(R
2)
</p>
<p>dτ
= 2A dA
</p>
<p>dτ
+ 2B dB
</p>
<p>dτ
= 2R dR
</p>
<p>dτ
. Expanding out 2R dR
</p>
<p>dτ
yields
</p>
<p>dR
</p>
<p>dτ
= 1
</p>
<p>2
R(1&minus; 1
</p>
<p>4
R2)
</p>
<p>which has R&lowast; = 2 as an equilibrium. Note that this matches the periodic solution
determined in Exercise9.2(b), but now, using MMTS, we have a prediction for rate
</p>
<p>of convergence to the limit cycle.
</p>
<p>9.5 (b) Suppressing the e&plusmn;it resonant forcing terms in theO(ε) equation forX1 yields
</p>
<p>dC
</p>
<p>dτ
= &minus; 1
</p>
<p>2
βC +
</p>
<p>3
</p>
<p>2
iα|C|2C + 1
</p>
<p>2
eiγ τ ,
</p>
<p>with the second solvability condition being exactly the complex conjugate of the
</p>
<p>above equation (and hence yielding no independent information).
</p>
<p>(c) Substituting into the amplitude ODE for C reduces to the algebraic equation
</p>
<p>γ = 1
2
</p>
<p>iβ +
3
</p>
<p>2
αM2 &minus;
</p>
<p>1
</p>
<p>4M
e&minus;iθ .</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9">http://dx.doi.org/10.1007/978-3-319-23042-9_9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9">http://dx.doi.org/10.1007/978-3-319-23042-9_9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9">http://dx.doi.org/10.1007/978-3-319-23042-9_9</a></div>
</div>
<div class="page"><p/>
<p>292 Solutions to Selected Problems
</p>
<p>Separating real and imaginary parts of this equation yields
</p>
<p>γ = 3
2
αM2 &minus;
</p>
<p>cos θ
</p>
<p>4M
, 0 = 1
</p>
<p>2
β +
</p>
<p>sin θ
</p>
<p>4M
.
</p>
<p>For fixed α, β, expressing sin θ = &plusmn;
&radic;
1&minus; cos2 θ , we can solve the second equation
</p>
<p>to get cos θ = &plusmn;
&radic;
</p>
<p>1&minus; 4β2M2. Substituting this into the first equation gives the final
(real-valued) form of the detuning relation:
</p>
<p>γ (M) = 3
2
αM2 &plusmn;
</p>
<p>&radic;
</p>
<p>1&minus; 4β2M2
4M
</p>
<p>.
</p>
<p>Entrained solutions exist up to a critical amplitude set by the damping, M &le; Mc =
1/(2β). Noting that the terms f = x+εαx3 can be interpreted as a restoring force due
to a spring, the case of α &gt; 0 is called a hardening spring since the restoring force
</p>
<p>is stronger than for the corresponding linear Hooke&rsquo;s law spring [54]. Conversely,
</p>
<p>the case α &lt; 0 is called a softening spring. In contrast to the case of a linear oscil-
</p>
<p>lator near resonance (see Fig. 4.1), for α �= 0, the amplitude of the forced solution
is shifted away from the oscillator&rsquo;s natural frequency by the amplitude-dependent
</p>
<p>detuning, γ (M). For hardening (softening) springs, the resonant peak gets shifted
</p>
<p>above (below) the (zero-amplitude) linear natural frequency. See below for a plot
</p>
<p>of the detuning relation plotted for a hardening spring case, α &gt; 0 along with the
</p>
<p>(undamped) resonant &ldquo;backbone&rdquo; curve γ = 3
2
αM2.
</p>
<p>9.6 The amplitude equations are d�
dτ
</p>
<p>= 0 and dR
dτ
</p>
<p>= &minus; 4R2
3π
</p>
<p>yielding the solution
</p>
<p>x(t) &sim;
sin(t)
</p>
<p>1+ 4εt
3π
</p>
<p>.
</p>
<p>9.7 The amplitude equations are dA
dτ
</p>
<p>+ 1
8
</p>
<p>A = 0, dB
dτ
</p>
<p>&minus; 1
8
B = 0.</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_4">http://dx.doi.org/10.1007/978-3-319-23042-9_4</a></div>
</div>
<div class="page"><p/>
<p>Solutions to Selected Problems 293
</p>
<p>9.8 (c, d) The amplitude equation is determined by forcing the coefficient of the
</p>
<p>resonant forcing term (e&minus;i4t) in the equation for X1 to vanish,
dA
dτ
</p>
<p>&minus; 1
2
</p>
<p>A2 = 0,
yielding the solution x &sim; 2
</p>
<p>1&minus;i&minus;εt e
&minus;i4t .
</p>
<p>9.10 Substituting the expansion into the ODE, at leading order we get
</p>
<p>X0tt + X0 = ε1&minus;βX20 + ε1+β cos t.
</p>
<p>The inhomogeneous forcing terms will be higher order if &minus;1 &lt; β &lt; 1 to yield
X0(t, τ ) = A(τ )eit + B(τ )e&minus;it. In the equation for X1, deferring the resonant terms
to higher order requires α&minus;γ &gt; 0 and 1+β&minus;γ &gt; 0 with 1&minus;β&minus;γ = 0 needed to
make the remaining forcing term be O(1). Finally, in the equation for X2 balancing
</p>
<p>resonant terms leads to α = 4/3, β = 1/3, γ = 2/3 with amplitude equations
</p>
<p>&minus;2i
dA
</p>
<p>dτ
+
</p>
<p>1
</p>
<p>2
+
</p>
<p>10
</p>
<p>3
A2B = 0 2i
</p>
<p>dB
</p>
<p>dτ
+
</p>
<p>1
</p>
<p>2
+
</p>
<p>10
</p>
<p>3
AB2 = 0,
</p>
<p>yielding a stable limit cycle with X0(t) = &minus;(6/5)1/3 cos t.
</p>
<p>9.11 (a) The trivial solution x &equiv; 0 is an equilibrium state. Linear stability analysis
yields λ2+1+ εe&minus;2λ = 0 with O(1) solutions λ &sim; &plusmn;i&plusmn; ε 1
</p>
<p>2
ie∓2i, both of these have
</p>
<p>Re(λ) &gt; 0 so the trivial solution is unstable. (b) The amplitude equations are
</p>
<p>dA
</p>
<p>dτ
&minus; 1
</p>
<p>2
(A sin 2+ B cos 2) = 0,
</p>
<p>dB
</p>
<p>dτ
+ 1
</p>
<p>2
(A cos 2&minus; B sin 2) = 0.
</p>
<p>9.12 (a) Taking &part;t of the first equation in (9.36) yieldsF0t = &minus;C0tt and henceC0tt =
C0xx from the second equation. Taking &part;xx of the first equation yields F0xx = &minus;C0txx
then using this in &part;t of the second equation yields F0tt = F0xx.
(b) The O(1) equations determine that f0 = c0z at leading order. There is one ε2&part;τ
term from the O(1) equations that gets added to the O(ε2) (9.37) equations. The sum
</p>
<p>of &part;z of the first equation plus the second cancels the c1, f1 terms to yield the KdV
</p>
<p>equation (9.38) depending only on f0(z, τ ).
</p>
<p>9.13 λ(1) &sim; 2&minus; 1
2
ε, λ(2) &sim; &minus;4+ 3
</p>
<p>2
ε
</p>
<p>Chapter10
</p>
<p>10.1 (a) f (x) = &minus;x3 + 9x + 3x2,
(b) (x&lowast;, y&lowast;) = (0, 0) is the only equilibrium point; the eigenvalues from its linear
stability are λ = (9&plusmn;
</p>
<p>&radic;
81&minus; 16ε)/(2ε) &gt; 0, so it is an unstable node.
</p>
<p>(c) The slow manifold is y0(x0) = (x30 &minus; 3x20 &minus; 9x0)/4.
(e) The slow manifold has local extrema at y(&minus;1) = 5/4 and y(3) = &minus;27/4. In
the fast evolution stages, y is constant and x evolves from the extrema value to the
</p>
<p>other value on the slow manifold, satisfying y = S(x). Solving the cubic S(x) = 5/4
yields xmax = 5 and solving S(x) = &minus;27/4 yields xmin = &minus;3.</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9">http://dx.doi.org/10.1007/978-3-319-23042-9_9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9">http://dx.doi.org/10.1007/978-3-319-23042-9_9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_9">http://dx.doi.org/10.1007/978-3-319-23042-9_9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_10">http://dx.doi.org/10.1007/978-3-319-23042-9_10</a></div>
</div>
<div class="page"><p/>
<p>294 Solutions to Selected Problems
</p>
<p>(f) Implicitly differentiating the equation for the slow manifold, d
dt
(y = S(x)), and
</p>
<p>applying
dy
dt
</p>
<p>= &minus;x yields the equation for evolution on the slow manifold,
</p>
<p>dx
</p>
<p>dt
= &minus;
</p>
<p>4x
</p>
<p>3x2 &minus; 6x &minus; 9
&rarr;
</p>
<p>&int;
dx
</p>
<p>g(x)
= &minus;
</p>
<p>&int;
3x2 &minus; 6x &minus; 9
</p>
<p>4x
dx
</p>
<p>The limit cycle is composed of two fast and two slow stages, P = Tfast,1 + Tslow,2 +
Tfast,3 + Tslow,4 &sim; Tslow,2 + Tslow,4. Stage 2 starts at x = 5 and ends at x = 3,
</p>
<p>Tslow,2 =
1
</p>
<p>4
</p>
<p>&int; 3
</p>
<p>5
</p>
<p>9
</p>
<p>x
+ 6&minus; 3x dx = 3+
</p>
<p>9
</p>
<p>4
ln(3/5).
</p>
<p>Similarly, stage 4 starts at x = &minus;3 and ends at x = &minus;1,
</p>
<p>Tslow,4 =
1
</p>
<p>4
</p>
<p>&int; &minus;1
</p>
<p>&minus;3
</p>
<p>9
</p>
<p>x
+ 6&minus; 3x dx = 6&minus;
</p>
<p>9
</p>
<p>4
ln(3).
</p>
<p>Therefore the period is P &sim; 9&minus; (9/4) ln(5) &asymp; 5.38.
</p>
<p>10.2 (a) Setting ε = 0 in the z&prime; equation yields the slow manifold as z = S(y) =
y &minus; y2 + 1
</p>
<p>3
y3 and then the leading order slow system is
</p>
<p>dx0
</p>
<p>dt
= 2&minus; y0
</p>
<p>dy0
</p>
<p>dt
= x0 &minus; y0 + y20 &minus; 13y
</p>
<p>3
0
</p>
<p>The only equilibrium point of the slow system is (x&lowast;, y&lowast;) = ( 23 , 2), which is a stable
spiral point with eigenvalues λ = 1
</p>
<p>2
(&minus;1 &plusmn; 3i). Consequently the t &rarr; &infin; solution
</p>
<p>will be (x, y, z) &sim; ( 2
3
, 2, 2
</p>
<p>3
= S(2)).
</p>
<p>Note that the initial condition is not on the slowmanifold since 0 �= S(3), therefore
there will be an initial layer governed by the fast system (for the distinguished limit
</p>
<p>with α = 1 set by the z&prime; equation),
</p>
<p>dX
</p>
<p>dT
= ε(2&minus; Y),
</p>
<p>dY
</p>
<p>dT
= ε(X &minus; Z),
</p>
<p>dZ
</p>
<p>dT
= Y &minus; Y2 + 1
</p>
<p>3
Y3 &minus; Z
</p>
<p>At leadingorder, the initial layerwill haveX0(T) &equiv; 1,Y0(T) &equiv; 3, constants set by the
initial conditions. Then the last relation is Z &prime;0 = 3&minus;Z0 yielding Z0(T) = 3(1&minus; e&minus;T )
which connections the initial condition to the point (x, y, z) = (1, 3, 3) on the slow
manifold.
</p>
<p>(b) Setting ε = 0 in the y&prime; equation yields the relation x = z. Using that result in
the x&prime; gives a second expression for z&prime; that could be matched to the z&prime; equation to
yield 2&minus; y = y &minus; y2 + 1
</p>
<p>3
y3 &minus; z. The expression for z = z(y) is monotone increasing
</p>
<p>and hence could be inverted to yield y = y(z) to describe the slow manifold as a
parametric curve in 3D. Implicitly differentiation gives motion on this curve as</p>
<p/>
</div>
<div class="page"><p/>
<p>Solutions to Selected Problems 295
</p>
<p>dy
</p>
<p>dt
=
</p>
<p>2&minus; y
2&minus; 2y + y2
</p>
<p>,
</p>
<p>which has a stable equilibrium point at y&lowast; = 2. Consequently the solution for t &rarr; &infin;
will approach (x, y, z) &sim; ( 2
</p>
<p>3
= x( 2
</p>
<p>3
), 2, 2
</p>
<p>3
= z(2)).
</p>
<p>Since the initial condition does not lie on the slowmanifold, there will be an initial
</p>
<p>layer governed by the fast system,
</p>
<p>dX
</p>
<p>dT
= ε(2&minus; Y),
</p>
<p>dY
</p>
<p>dT
= X &minus; Z,
</p>
<p>dZ
</p>
<p>dT
= ε
</p>
<p>(
</p>
<p>Y &minus; Y2 + 1
3
Y3 &minus; Z
</p>
<p>)
</p>
<p>.
</p>
<p>At leading order, the initial layer will have X0(T) &equiv; 0,Z0(T) &equiv; 1, constants set by
the initial conditions. Then the last relation is Y &prime;0 = &minus;1, describing linear decrease
of Y0 from the initial value Y0(0) = 3 until it reaches the slow manifold, at z(y) = 1
(at y &asymp; 2.1517).
</p>
<p>10.3 (a) The dimensional rate equations are
</p>
<p>dA
</p>
<p>dT
= &minus;2k1A2 + 2k2B &minus; k3AB,
</p>
<p>dB
</p>
<p>dT
= k1A2 &minus; k2B &minus; k3AB,
</p>
<p>dC
</p>
<p>dT
= k3AB.
</p>
<p>(c) The scaled problem is
</p>
<p>da
</p>
<p>dt
= &minus;2a2 + 2Π1b &minus;Π2ab, ε
</p>
<p>db
</p>
<p>dt
= a2 &minus;Π1b &minus;Π2ab,
</p>
<p>dc
</p>
<p>dt
= Π2ab
</p>
<p>where
</p>
<p>ε =
B0
</p>
<p>A0
, Π1 =
</p>
<p>k2B0
</p>
<p>k1A
2
</p>
<p>0
</p>
<p>, Π2 =
k3B0
</p>
<p>k1A0
.
</p>
<p>(d) By setting ε = 0 in the b&prime; equation, we get the slow manifold, b = S(a) =
a2/(Π1 +Π2a). Substituting the slow manifold for b in the rate equations for a&prime;, c&prime;
yields
</p>
<p>da
</p>
<p>dt
= &minus;
</p>
<p>3Π2a
3
</p>
<p>Π1 +Π2a
dc
</p>
<p>dt
=
</p>
<p>Π2a
3
</p>
<p>Π1 +Π2a
,
</p>
<p>which is consistent with the overall expectation of the sum c + 1
3
</p>
<p>a being conserved.
</p>
<p>Undoing the dimensional scalings, we get
</p>
<p>dA
</p>
<p>dT
= &minus;
</p>
<p>3k1k3A
3
</p>
<p>k2 + k3A
= &minus;G(A) and F(A) = 1
</p>
<p>3
G(A).</p>
<p/>
</div>
<div class="page"><p/>
<p>296 Solutions to Selected Problems
</p>
<p>10.5 The reactions take the form
</p>
<p>A + B &rarr; 2P B ⇋ 2C C + A ⇋ D + P D + B &rarr; P + C
</p>
<p>The rate equations are
</p>
<p>dA
</p>
<p>dT
= &minus;k3AC + k4DP
</p>
<p>dB
</p>
<p>dT
= &minus;k1B + k2C2 &minus; k5BD
</p>
<p>dC
</p>
<p>dT
= 2k1B &minus; 2k2C2 &minus; k3AC + k4DP + k5BD
</p>
<p>dD
</p>
<p>dT
= k3AC &minus; k4DP &minus; k5BD
</p>
<p>dP
</p>
<p>dT
= k3AC &minus; k4DP + k5BD
</p>
<p>Using the QSSA applied to the intermediates sets C&prime; = D&prime; = 0 yielding the slow
manifold-type relations
</p>
<p>C =
</p>
<p>&radic;
</p>
<p>k1B
</p>
<p>k2
D =
</p>
<p>k3A
</p>
<p>k4P + k5B
</p>
<p>&radic;
</p>
<p>k1B
</p>
<p>k2
</p>
<p>Substituting these into the rate equation for P&prime; yields
</p>
<p>dP
</p>
<p>dT
=
</p>
<p>αAB3/2
</p>
<p>B + βA
α = 2k3
</p>
<p>&radic;
</p>
<p>k1
</p>
<p>k2
β =
</p>
<p>k4
</p>
<p>k5
.
</p>
<p>Chapter11
</p>
<p>11.1 Integrals of the Gaussian yield
</p>
<p>&int; &infin;
</p>
<p>&minus;&infin;
ρ(x, t) dx = C1,
</p>
<p>&int; &infin;
</p>
<p>&minus;&infin;
xρ(x, t) dx = C1C3,
</p>
<p>&int; &infin;
</p>
<p>&minus;&infin;
x2ρ(x, t) dx = C1
</p>
<p>(
</p>
<p>C23 + 2(t + C2)
)
</p>
<p>.
</p>
<p>Matching these results with (11.3), (11.4) and (11.7) determines
</p>
<p>C1 = M0 =
&int;
</p>
<p>f dx, C3 =
M1
</p>
<p>M0
=
</p>
<p>1
</p>
<p>M0
</p>
<p>&int;
</p>
<p>xf dx, C2 =
1
</p>
<p>2M0
</p>
<p>&int;
</p>
<p>x2f dx &minus;
M21
</p>
<p>2M20
.
</p>
<p>11.2 (a) Integrating the PDE against xn and applying the boundary conditions yields
</p>
<p>(noting that ρ(|x| &rarr; &infin;) &rarr; 0 implies that &part;xρ(|x| &rarr; &infin;) &rarr; 0)
</p>
<p>dM0
</p>
<p>dt
= 4M0,
</p>
<p>dM1
</p>
<p>dt
&minus; 2M0 = 4M1,
</p>
<p>dM2
</p>
<p>dt
&minus; 4M1 = 6M0 + 4M2.
</p>
<p>Solving this system of linear ODEs and applying the initial conditions, M0(0) =&radic;
π,M1(0) = 0,M2(0) = 12
</p>
<p>&radic;
π yields</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_11">http://dx.doi.org/10.1007/978-3-319-23042-9_11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_11">http://dx.doi.org/10.1007/978-3-319-23042-9_11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_11">http://dx.doi.org/10.1007/978-3-319-23042-9_11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-3-319-23042-9_11">http://dx.doi.org/10.1007/978-3-319-23042-9_11</a></div>
</div>
<div class="page"><p/>
<p>Solutions to Selected Problems 297
</p>
<p>M0(t) =
&radic;
πe4t, M1(t) = 2
</p>
<p>&radic;
π te4t, M2(t) =
</p>
<p>&radic;
π
</p>
<p>(
</p>
<p>4t2 + 6t + 1
2
</p>
<p>)
</p>
<p>e4t .
</p>
<p>(b) Integrating the PDE against x0, x1 and applying the boundary conditions yields
</p>
<p>dM0
</p>
<p>dt
&minus; 2 = &minus;3
</p>
<p>&part;ρ
</p>
<p>&part;x
</p>
<p>∣
∣
∣
∣
x=0
</p>
<p>+ 4M0,
dM1
</p>
<p>dt
&minus; 2M0 = 3+ 4M1.
</p>
<p>11.3 (a) Integrating the PDE against x0, x1 and applying the boundary conditions
</p>
<p>yields
</p>
<p>dM0
</p>
<p>dt
= &minus;M0,
</p>
<p>dM1
</p>
<p>dt
= &minus;M1 &minus; (ρ(π, t)&minus; ρ(0, t)),
</p>
<p>(b) Substituting the separation of variables form into the PDE yields that λk = 1+k2
for k = 0, 1, 2, . . . . Namely, all modes decay exponentially since λk &gt; 0, but λ0 = 1
decays the least rapidly.
</p>
<p>Examining the initial condition at t = 0, ρ(x, 0) = f (x) and obtaining the Fourier
cosine series coefficients (see AppendixA) yields
</p>
<p>a0 =
1
</p>
<p>π
</p>
<p>&int; π
</p>
<p>0
</p>
<p>f dx, ak =
2
</p>
<p>π
</p>
<p>&int; π
</p>
<p>0
</p>
<p>f cos(kx) dx.
</p>
<p>Retaining the slowest-decaying mode from the series for ρ(x, t) then yields
</p>
<p>ρ(x, t) &sim;
e&minus;t
</p>
<p>π
</p>
<p>&int; π
</p>
<p>0
</p>
<p>f dx as t &rarr; &infin;.
</p>
<p>(b) Integrating the PDE against x0, x1 and applying the boundary conditions (ρ &rarr; 0
as |x| &rarr; &infin;) yields
</p>
<p>dM0
</p>
<p>dt
= &minus;M0,
</p>
<p>dM1
</p>
<p>dt
= &minus;M1,
</p>
<p>dM2
</p>
<p>dt
= 2M0 &minus; M2.
</p>
<p>11.4 (a) Integrating the PDE directly yields M &prime;0(t)+ρ(&infin;, t)&minus;ρ(0, t) = &minus;2M0(t),
then applying the boundary conditions yields
</p>
<p>dM0
</p>
<p>dt
= (β &minus; 2)M0.
</p>
<p>(b) Integrating the PDE directly yields the same initial form as in part (a), but the
</p>
<p>new birth condition yields the ODE
</p>
<p>dM0
</p>
<p>dt
= &minus;2M0 + M1.</p>
<p/>
</div>
<div class="page"><p/>
<p>298 Solutions to Selected Problems
</p>
<p>Integrating the PDE against e&minus;3a similarly yields
</p>
<p>dM1
</p>
<p>dt
= &minus;4M1.
</p>
<p>11.5 (a) M0 =
&int;
</p>
<p>f dx,M1 =
&int;
</p>
<p>xf dx.
</p>
<p>(b) Note that the porous medium equation can be re-written as ρt = 14 (ρ
4)xx to make
</p>
<p>integration by parts more convenient,
</p>
<p>dM2
</p>
<p>dt
= 1
</p>
<p>4
</p>
<p>&int;
</p>
<p>x2(ρ4)xx dx = 14
</p>
<p>(
</p>
<p>x2(ρ4)x &minus; 2xρ4
∣
∣
∣
∣
+ 2
</p>
<p>&int;
</p>
<p>ρ4 dx
</p>
<p>)
</p>
<p>&ge; 0,
</p>
<p>where the boundary terms vanish due to the boundary conditions and the integral is
</p>
<p>positive-definite.</p>
<p/>
</div>
<div class="page"><p/>
<p>References
</p>
<p>1. D.J. Acheson, Elementary Fluid Dynamics (Oxford University Press, New York, 1990)
2. W.F. Ames, Nonlinear Partial Differential Equations in Engineering (Academic Press, New
</p>
<p>York, 1965)
3. W.F. Ames,Nonlinear Partial Differential Equations in Engineering, vol. II (Academic Press,
</p>
<p>New York, 1972)
4. R. Aris, Mathematical Modelling Techniques (Dover Publications Inc., New York, 1994)
5. D.K. Arrowsmith, C.M. Place, An Introduction to Dynamical Systems (Cambridge University
</p>
<p>Press, Cambridge, 1990)
6. P.W. Atkins, Physical Chemistry (W.H. Freeman, New York, 1986)
7. G.L. Baker, J.A. Blackburn, The Pendulum (Oxford University Press, Oxford, 2005)
8. H.T. Banks, H.T. Tran, Mathematical and Experimental Modeling of Physical and Biological
</p>
<p>Processes. Textbooks in Mathematics (CRC Press, Boca Raton, 2009)
9. G.I. Barenblatt, Scaling, Self-similarity, and Intermediate Asymptotics (CambridgeUniversity
</p>
<p>Press, Cambridge, 1996)
10. G.I. Barenblatt, Scaling (Cambridge University Press, Cambridge, 2003)
11. C.M. Bender, S.A. Orszag, Advanced Mathematical Methods for Scientists and Engineers
</p>
<p>(Springer, New York, 1999)
12. B. Bhushan, Principles and Applications of Tribology (Wiley, New York, 2013)
13. N. Bleistein, R.A. Handelsman, Asymptotic Expansions of Integrals, 2nd edn. (Dover Publi-
</p>
<p>cations Inc., New York, 1986)
14. G.W. Bluman, J.D. Cole, Similarity Methods for Differential Equations (Springer, New York,
</p>
<p>1974)
15. J.M. Borwein, R.E. Crandall, Closed forms: what they are and why we care. Not. AMS 60(1),
</p>
<p>50&ndash;65 (2013)
16. M. Bowen, J.R. King, Dynamics of a viscous thread on a non-planar substrate. J. Eng. Math.
</p>
<p>80, 39&ndash;62 (2013)
17. G.E.P. Box, N.R. Draper, Empirical Model-Building and Response Surfaces (Wiley, New
</p>
<p>York, 1987)
18. F. Brauer, C.Castillo-Chavez,Mathematical Models in Population Biology and Epidemiology.
</p>
<p>Texts in Applied Mathematics, 2nd edn. vol. 40 (Springer, New York, 2012)
19. F. Brauer, C. Castillo-Chavez, Mathematical Models for Communicable Diseases. CBMS-
</p>
<p>NSF Regional Conference Series in Applied Mathematics, vol. 84 (Society for Industrial and
</p>
<p>Applied Mathematics (SIAM), Philadelphia, 2013)
20. M.P. Brenner, H.A. Stone, Modern classical physics through the work of G.I. Taylor. Phys.
</p>
<p>Today 53(5), 30&ndash;35 (2000)
</p>
<p>&copy; Springer International Publishing Switzerland 2015
</p>
<p>T. Witelski and M. Bowen, Methods of Mathematical Modelling,
</p>
<p>Springer Undergraduate Mathematics Series, DOI 10.1007/978-3-319-23042-9
</p>
<p>299</p>
<p/>
</div>
<div class="page"><p/>
<p>300 References
</p>
<p>21. R.C. Buck, Advanced Calculus, 3rd edn. (McGraw-Hill Book Co., New York, 1978)
</p>
<p>22. B.J. Cantwell, Introduction to Symmetry Analysis (Cambridge University Press, Cambridge,
</p>
<p>2002)
</p>
<p>23. R.V. Churchill, J.W. Brown, Fourier Series and Boundary Value Problems (McGraw-Hill
</p>
<p>Book Co., New York, 1987)
</p>
<p>24. S.J. Colley, Vector Calculus, 3rd edn. (Prentice Hall, New Jersey, 2006)
</p>
<p>25. R.V. Craster, O.K. Matar, Dynamics and stability of thin liquid films. Rev. Mod. Phys. 81(3),
</p>
<p>1131 (2009)
</p>
<p>26. M.C. Cross, P.C. Hohenberg, Pattern-formation outside of equilibrium. Rev.Mod. Phys. 65(3,
</p>
<p>2), 851&ndash;1112 (1993)
</p>
<p>27. E. Cumberbatch, A. Fitt, Mathematical Modeling: Case Studies from Industry (Cambridge
</p>
<p>University Press, New York, 2001)
</p>
<p>28. J.M. Cushing, An Introduction to Structured Population Dynamics (Society for Industrial and
</p>
<p>Applied Mathematics (SIAM), Philadelphia, 1998)
</p>
<p>29. N.G. de Bruijn,Asymptotic Methods in Analysis, 3rd edn. (Dover Publications Inc., NewYork,
</p>
<p>1981)
</p>
<p>30. R.C.DiPrima,Asymptoticmethods for an infinitely long slider squeeze-filmbearing. J. Tribol.
</p>
<p>90(1), 173&ndash;183 (1968)
</p>
<p>31. P.G. Drazin, R.S. Johnson, Solitons: An Introduction (Cambridge University Press, Cam-
</p>
<p>bridge, 1989)
</p>
<p>32. L. Dresner,Applications of Lie&rsquo;s Theory of Ordinary and Partial Differential Equations (Insti-
</p>
<p>tute of Physics Publishing, Bristol, 1999)
</p>
<p>33. E. Weinan, Principles of Multiscale Modeling (Cambridge University Press, Cambridge,
</p>
<p>2011)
</p>
<p>34. A. Einstein, On the method of theoretical physics. Philos. Sci. 1(2), 163&ndash;169 (1934)
</p>
<p>35. T. Erneux, Applied Delay Differential Equations (Springer, New York, 2009)
</p>
<p>36. L.C. Evans, An Introduction to Stochastic Differential Equations (American Mathematical
</p>
<p>Society, Providence, 2013)
</p>
<p>37. A.C. Fowler, Mathematical Models in the Applied Sciences (Cambridge University Press,
</p>
<p>Cambridge, 1997)
</p>
<p>38. A. Friedman, W. Littman, Industrial Mathematics (Society for Industrial and Applied Math-
</p>
<p>ematics (SIAM), Philadelphia, 1994)
</p>
<p>39. B. Friedman, Principles and Techniques of Applied Mathematics (Dover Publications Inc.,
</p>
<p>New York, 1990)
</p>
<p>40. H. Goldstein, Classical Mechanics (Addison-Wesley, London, 1980)
</p>
<p>41. O. Gonzalez, A.M. Stuart, A First Course in Continuum Mechanics. Cambridge Texts in
</p>
<p>Applied Mathematics (Cambridge University Press, Cambridge, 2008)
</p>
<p>42. P.Grindrod,The Theory and Applications of Reaction-Diffusion Equations (OxfordUniversity
</p>
<p>Press, New York, 1996)
</p>
<p>43. J. Guckenheimer, P. Holmes, Nonlinear Oscillations, Dynamical Systems, and Bifurcations
</p>
<p>of Vector Fields (Springer, New York, 1990)
</p>
<p>44. R. Haberman, Elementary Applied Partial Differential Equations (Prentice Hall Inc., Engle-
</p>
<p>wood Cliffs, 1987)
</p>
<p>45. R.Haberman,Mathematical Models (Society for Industrial andAppliedMathematics (SIAM),
</p>
<p>Philadelphia, 1998)
</p>
<p>46. B.J. Hamrock, S.R. Schmid, B.O. Jacobson, Fundamentals of Fluid Film Lubrication (CRC
</p>
<p>press, Boca Raton, 2004)
</p>
<p>47. E.J. Hinch, Perturbation Methods (Cambridge University Press, Cambridge, 1991)
</p>
<p>48. M.H. Holmes, Introduction to Perturbation Methods (Springer, New York, 1995)
</p>
<p>49. M.H. Holmes, Introduction to the Foundations of Applied Mathematics (Springer, New York,
</p>
<p>2009)
</p>
<p>50. P. Howell, G. Kozyreff, J. Ockendon, Applied Solid Mechanics. Cambridge Texts in Applied
</p>
<p>Mathematics (Cambridge University Press, Cambridge, 2009)
</p>
<p>51. S. Howison, Practical Applied Mathematics (Cambridge University Press, Cambridge, 2005)</p>
<p/>
</div>
<div class="page"><p/>
<p>References 301
</p>
<p>52. P.E.Hydon, Symmetry Methods for Differential Equations (CambridgeUniversity Press, Cam-
</p>
<p>bridge, 2000)
</p>
<p>53. R. Illner, C.S. Bohun, S. McCollum, T. van Roode, Mathematical Modelling: A Case Studies
</p>
<p>Approach, vol. 27 (American Mathematical Society, Providence, 2005)
</p>
<p>54. D.W. Jordan, P. Smith, Nonlinear Ordinary Differential Equations, 3rd edn. (Oxford Univer-
</p>
<p>sity Press, Oxford, 1999)
</p>
<p>55. M. Kac, Some mathematical models in science. Science 166, 695&ndash;699 (1969)
</p>
<p>56. P.B.Kahn,Mathematical Methods for Scientists and Engineers: Linear and Nonlinear Systems
</p>
<p>(Dover Publications, New York, 2004)
</p>
<p>57. J. Keener, J. Sneyd, Mathematical Physiology (Springer, New York, 1998)
</p>
<p>58. J. Kevorkian, J.D. Cole, Multiple Scale and Singular Perturbation Methods (Springer, New
</p>
<p>York, 1996)
</p>
<p>59. D.E. Kirk, Optimal Control Theory, An Introduction (Dover, New York, 1998)
</p>
<p>60. P.A. Lagerstrom, Matched Asymptotic Expansions (Springer, New York, 1988)
</p>
<p>61. L.G. Leal, Advanced Transport Phenomena (Cambridge University Press, Cambridge, 2007)
</p>
<p>62. M. Levi, Classical Mechanics with Calculus of Variations and Optimal Control. Student
</p>
<p>Mathematical Library, vol. 69 (American Mathematical Society, Providence, 2014)
</p>
<p>63. C.C. Lin, L.A. Segel, Mathematics Applied to Deterministic Problems in the Natural Sciences
</p>
<p>(Society for Industrial and Applied Mathematics (SIAM), Philadelphia, 1988)
</p>
<p>64. J.D. Logan, Applied Mathematics, 3rd edn. (Wiley-Interscience, Hoboken, 2006)
</p>
<p>65. J.D. Logan, An Introduction to Nonlinear Partial Differential Equations, 2nd edn. (Wiley-
</p>
<p>Interscience, Hoboken, 2008)
</p>
<p>66. C.R. MacCluer, Calculus of Variations (Pearson Prentice Hall, Upper Saddle River, 2005)
</p>
<p>67. J.B.Marion,Classical Dynamics of Particles and Systems (Academic Press, NewYork, 1970)
</p>
<p>68. J.E. Marsden, A.J. Tromba, Vector Calculus, 5th edn. (W.H. Freeman, New York, 2003)
</p>
<p>69. R.M.M.Mattheij, S.W.Rienstra, J.H.M. tenThijeBoonkkamp,Partial Differential Equations:
</p>
<p>Modeling, Analysis, Computation (SIAM, Philadelphia, 2005)
</p>
<p>70. J.D. Meiss, Differential Dynamical Systems (Society for Industrial and Applied Mathematics
</p>
<p>(SIAM), Philadelphia, 2007)
</p>
<p>71. M. Mesterton-Gibbons, A Primer on the Calculus of Variations and Optimal Control Theory
</p>
<p>(American Mathematical Society, Providence, 2009)
</p>
<p>72. P.D.Miller,Applied Asymptotic Analysis. Graduate Studies inMathematics, vol. 75 (American
</p>
<p>Mathematical Society, Providence, 2006)
</p>
<p>73. J.A. Murdock, Perturbations (Society for Industrial and Applied Mathematics (SIAM),
</p>
<p>Philadelphia, 1999)
</p>
<p>74. J.D. Murray, Mathematical Biology, 2nd edn. (Springer, Berlin, 1993)
</p>
<p>75. T.G. Myers, Thin films with high surface tension. SIAM Rev. 40(3), 441&ndash;462 (1998)
</p>
<p>76. R. Narasimha, Divide, conquer and unify. Nature 432, 807 (2004)
</p>
<p>77. A.H. Nayfeh, Perturbation Methods (Wiley-Interscience, New York, 1973)
</p>
<p>78. A.H. Nayfeh, Introduction to Perturbation Techniques (Wiley-Interscience, New York, 1981)
</p>
<p>79. H. Ockendon, J.R. Ockendon, Viscous Flow (Cambridge University Press, Cambridge, 1995)
</p>
<p>80. H. Ockendon, J.R. Ockendon, Waves and Compressible Flow (Springer, New York, 2004)
</p>
<p>81. J. Ockendon, S. Howison, A. Lacey, A. Movchan, Applied Partial Differential Equations
</p>
<p>(Oxford University Press, Oxford, 2003)
</p>
<p>82. A. Oron, S.H. Davis, S.G. Bankoff, Long-scale evolution of thin liquid films. Rev. Mod. Phys.
</p>
<p>69(3), 931 (1997)
</p>
<p>83. R.C. Pankhurst, Dimensional Analysis and Scale Factors (Chapman and Hall, London, 1964)
</p>
<p>84. E.R. Pinch, Optimal Control and the Calculus of Variations (Oxford University Press, New
</p>
<p>York, 1993)
</p>
<p>85. S. Ramanujan, Modular Equations and Approximations to π . Q. J. Math. 45 (1914), 350&ndash;372.
</p>
<p>Collected Papers of Srinivasa Ramanujan (AMS Chelsea Publication, Providence, 2000), pp.
</p>
<p>23&ndash;39
</p>
<p>86. A .J. Roberts, Model Emergent Dynamics in Complex Systems (SIAM, Philadelphia, 2014)</p>
<p/>
</div>
<div class="page"><p/>
<p>302 References
</p>
<p>87. S. Schnell, P.K. Maini, Enzyme kinetics at high enzyme concentration. Bull. Math. Biol. 62,
</p>
<p>482&ndash;499 (2000)
</p>
<p>88. L.I. Sedov, Similarity and Dimensional Methods in Mechanics (Academic Press, New York,
</p>
<p>1959)
</p>
<p>89. L.A. Segel, Simplification and scaling. SIAM Rev. 14, 547&ndash;571 (1972)
</p>
<p>90. L.A. Segel, M. Slemrod, The quasi-steady-state assumption: a case study in perturbation.
</p>
<p>SIAM Rev. 31(3), 446&ndash;477 (1989)
</p>
<p>91. R.A. Serway, Physics for Scientists and Engineers (Brooks/Cole, Boston, 2014)
</p>
<p>92. D.R. Smith, Singular-Perturbation Theory: An Introduction with Applications (Cambridge
</p>
<p>University Press, Cambridge, 1985)
</p>
<p>93. I. Stakgold, Green&rsquo;s Functions and Boundary Value Problems (Wiley, New York, 1998)
</p>
<p>94. S.H. Strogatz, Nonlinear Dynamics and Chaos: with Applications to Physics, Biology, Chem-
</p>
<p>istry, and Engineering. Advanced Book Program (Westview Press, Cambridge, 1994)
</p>
<p>95. T. Szirtes, Applied Dimensional Analysis and Modelling (McGraw-Hill, New York, 1997)
</p>
<p>96. A.B. Tayler, Mathematical Models in Applied Mechanics (Oxford University Press, Oxford,
</p>
<p>2001)
</p>
<p>97. B.N. Taylor, A. Thompson (eds.) The International System of Units. National Institute of
</p>
<p>Standards and Technology, U.S. Department of Commerce 2008, Publication 330
</p>
<p>98. G.I. Taylor, Dispersion of soluble matter in solvent flowing slowly through a tube. Proc. R.
</p>
<p>Soc. Lond. Ser. A 219, 186&ndash;203 (1953)
</p>
<p>99. J.L. Troutman, Variational Calculus and Optimal Control (Springer, New York, 1996)
</p>
<p>100. A.M. Turing, The chemical basis of morphogenesis. Philos. Trans. R. Soc. Lond. Ser. B-Biol.
</p>
<p>Sci. 237(641), 37&ndash;72 (1952)
</p>
<p>101. M. Van Dyke, Perturbation Methods in Fluid Mechanics (The Parabolic Press, Stanford,
</p>
<p>1975)
</p>
<p>102. F. Verhulst, Methods and Applications of Singular Perturbations (Springer, New York, 2005)
</p>
<p>103. D. Weaire, S. Hutzler, The Physics of Foams (Clarendon Press, Oxford, 1999)
</p>
<p>104. R. Weinstock, Calculus of Variations (Dover Publications Inc., New York, 1974)
</p>
<p>105. R.B. White, Asymptotic Analysis of Differential Equations, Revised edn. (Imperial College
</p>
<p>Press, London, 2010)
</p>
<p>106. G.B. Whitham, Linear and Nonlinear Waves (Wiley, New York, 1999)
</p>
<p>107. Wikiquote, Albert Einstein&mdash;Wikiquote (2015). http://en.wikiquote.org/w/index.php?title=
</p>
<p>Albert_Einstein&amp;oldid=1859225. Accessed 15 March 2015
</p>
<p>108. T.P. Witelski, A.J. Bernoff, Self-similar asymptotics for linear and nonlinear diffusion equa-
</p>
<p>tions. Stud. Appl. Math. 100(2), 153&ndash;193 (1998)
</p>
<p>109. T.P. Witelski, Dynamics of air bearing sliders. Phys. Fluids 10(3), 698&ndash;708 (1998)</p>
<p/>
<div class="annotation"><a href="http://en.wikiquote.org/w/index.php?title=Albert_Einstein&amp;oldid=1859225">http://en.wikiquote.org/w/index.php?title=Albert_Einstein&amp;oldid=1859225</a></div>
<div class="annotation"><a href="http://en.wikiquote.org/w/index.php?title=Albert_Einstein&amp;oldid=1859225">http://en.wikiquote.org/w/index.php?title=Albert_Einstein&amp;oldid=1859225</a></div>
</div>
<div class="page"><p/>
<p>Index
</p>
<p>A
</p>
<p>Advection equation, 28
</p>
<p>Amplitude equation, 194
</p>
<p>Asymptotic equivalence, 127
</p>
<p>Asymptotic expansion, 129
</p>
<p>Asymptotic matching, 247
</p>
<p>Asymptotic stability, 11
</p>
<p>B
</p>
<p>Basin of attraction, 20
</p>
<p>Beam equation, 79
</p>
<p>Beltrami identity, 77
</p>
<p>Benjamin-Bona-Mahony equation, 40
</p>
<p>Bifurcation, 12
</p>
<p>Bifurcation points, 20
</p>
<p>Binomial expansion, 133
</p>
<p>Bi-stability, 20
</p>
<p>Blow-up solution, 124
</p>
<p>Boundary layer, 149
</p>
<p>Brachistochrone, 47, 77
</p>
<p>Breaking wave, 35
</p>
<p>Buckingham Pi theorem, 101
</p>
<p>Burgers equation, 44, 95, 105
</p>
<p>inviscid, 34, 43, 114
</p>
<p>C
</p>
<p>Carleman&rsquo;s model, 144
</p>
<p>Carrying capacity, 8
</p>
<p>Cauchy momentum equation, 28
</p>
<p>Characteristic equations, 32
</p>
<p>Characteristic scale, 104
</p>
<p>Conservation law, 27
</p>
<p>chemical, 7
</p>
<p>Constitutive relation, 28
</p>
<p>Continuity equation, 27
</p>
<p>Continuum hypothesis, 3, 23
</p>
<p>Control function, 69
</p>
<p>Convective derivative, 25
</p>
<p>Couette flow, 241
</p>
<p>D
</p>
<p>D&rsquo;Alembert solution, 42
</p>
<p>Defocusing solution, 124
</p>
<p>Delay differential equation, 198, 244
</p>
<p>Derived scale, 89
</p>
<p>Differential algebraic equations, 69
</p>
<p>Dimensional homogeneity, 87
</p>
<p>Dimensionless parameter, 89, 92
</p>
<p>Dimensionless variable, 89
</p>
<p>Dispersion relation, 29, 222
</p>
<p>Divergence theorem, 26
</p>
<p>Dominant balance, 134
</p>
<p>Du Bois-Reymond lemma, 27
</p>
<p>Dynamical systems, 4
</p>
<p>E
</p>
<p>Entrainment, 196
</p>
<p>Error function, 121, 125
</p>
<p>Euler equations, 39
</p>
<p>Eulerian description, 24
</p>
<p>Euler&ndash;Lagrange equation, 56
</p>
<p>Expansion fan, 35, 118
</p>
<p>Exponentially small terms, 149
</p>
<p>F
</p>
<p>Fermat&rsquo;s principle, 47, 79
</p>
<p>Fermi estimate, 85
</p>
<p>Focusing solution, 124
</p>
<p>Fourier series, 193
</p>
<p>&copy; Springer International Publishing Switzerland 2015
</p>
<p>T. Witelski and M. Bowen, Methods of Mathematical Modelling,
</p>
<p>Springer Undergraduate Mathematics Series, DOI 10.1007/978-3-319-23042-9
</p>
<p>303</p>
<p/>
</div>
<div class="page"><p/>
<p>304 Index
</p>
<p>Fredholm alternative theorem, 194, 199
</p>
<p>Free boundary, 60
</p>
<p>Froude number, 108
</p>
<p>Functional, 49
</p>
<p>FundamentalLemmaof theCalculus ofVari-
</p>
<p>ations, 53
</p>
<p>generalised, 58
</p>
<p>G
</p>
<p>Gauge function, 129
</p>
<p>Geodesic, 75
</p>
<p>Group velocity, 39
</p>
<p>H
</p>
<p>Hamiltonian, 72, 76
</p>
<p>Hamilton-Jacobi equation, 45
</p>
<p>Hamilton&rsquo;s principle, 47, 57
</p>
<p>Holonomic problems, 68
</p>
<p>Hyperbolic system, 31
</p>
<p>I
</p>
<p>Imposed scale, 89
</p>
<p>Initial layer, 208
</p>
<p>Inner region, 149
</p>
<p>Inner solution, 149
</p>
<p>Isoperimetric problems, 65
</p>
<p>K
</p>
<p>Korteweg de Vries equation, 181, 198
</p>
<p>L
</p>
<p>Lagrange multiplier, 63
</p>
<p>Lagrangian, 49, 55
</p>
<p>Lagrangian derivative, 25
</p>
<p>Lagrangian description, 25
</p>
<p>Law of mass action, 5
</p>
<p>Legendre transform, 71, 76
</p>
<p>Leibniz&rsquo;s rule, 26, 37, 61
</p>
<p>Li&eacute;nard transformation, 203
</p>
<p>Limit cycle, 205
</p>
<p>Linear stability analysis, 11, 222
</p>
<p>Logistic equation, 8
</p>
<p>Long-wave unstable, 223
</p>
<p>Lotka-Volterra model, 9
</p>
<p>M
</p>
<p>Maple, 130
</p>
<p>Material blob, 25
</p>
<p>Material derivative, 25
</p>
<p>Mathieu equation, 197
</p>
<p>McKendrick model, 230
</p>
<p>Method of multiple time scales, 191
</p>
<p>Michaelis-Menten rate law, 209
</p>
<p>Moment integral, 215
</p>
<p>Monomial form, 86
</p>
<p>N
</p>
<p>Natural boundary condition, 59
</p>
<p>Navier-Stokes equations, 28
</p>
<p>Newton&rsquo;s second law, 4
</p>
<p>Noether&rsquo;s theorem, 77
</p>
<p>Nullcline, 203
</p>
<p>O
</p>
<p>Objective function, 47
</p>
<p>Optimal control theory, 69
</p>
<p>Order symbol
</p>
<p>O(), 51
</p>
<p>Outer solution, 149
</p>
<p>P
</p>
<p>Passive transport, 24
</p>
<p>Peclet number, 97, 225, 242
</p>
<p>Pendulum, 106
</p>
<p>Phase plane analysis, 4
</p>
<p>Phase velocity, 29, 39
</p>
<p>Plane wave, 29
</p>
<p>Poincare&ndash;Lindstedt, 189
</p>
<p>Poiseuille flow, 224, 241
</p>
<p>Pontryagin maximum principle, 83
</p>
<p>Population dynamics, 8, 23, 230
</p>
<p>Population, age-structured, 230
</p>
<p>Porousmedium equation, 121, 182, 231, 245
</p>
<p>Projectile motion, 87
</p>
<p>Q
</p>
<p>Quasi-steady state assumption (QSSA), 212,
</p>
<p>297
</p>
<p>Quasilinear wave equation, 34
</p>
<p>R
</p>
<p>Rankine-Hugoniot equation, 37
</p>
<p>Rarefaction wave, 35, 118
</p>
<p>Rate constant, 5
</p>
<p>Relaxation oscillator, 202
</p>
<p>Resonant forcing, 186, 187
</p>
<p>Reynolds equation, 240
</p>
<p>Reynolds transport theorem, 26</p>
<p/>
</div>
<div class="page"><p/>
<p>Index 305
</p>
<p>S
</p>
<p>Scaling constants, 96
</p>
<p>Scaling principles, 89, 90
</p>
<p>Scaling symmetry, 115
</p>
<p>Secular growth, 187
</p>
<p>Semilinear wave equation, 32
</p>
<p>Separation of variables, 222
</p>
<p>Shock, 36
</p>
<p>Signalling problem, 40, 243
</p>
<p>Similarity function, 116
</p>
<p>Similarity variable, 116
</p>
<p>SIR model, 9
</p>
<p>Slender body limit, 179
</p>
<p>Slow manifold, 203
</p>
<p>Solvability condition, 175, 190, 194
</p>
<p>Source-type similarity solution, 119, 229,
</p>
<p>246
</p>
<p>State equation, 69
</p>
<p>Strong form, 27, 54
</p>
<p>Sub-dominant terms, 134
</p>
<p>Surface waves, 40, 181
</p>
<p>T
</p>
<p>Taylor series, 10, 130
</p>
<p>Translation invariance, 120
</p>
<p>Transport equation, 24
</p>
<p>Travelling wave, 28, 248
</p>
<p>Triple deck, 163, 165
</p>
<p>V
</p>
<p>Van der Pol equation, 195, 202, 210
</p>
<p>Variation
</p>
<p>first, 51
</p>
<p>second, 51, 74
</p>
<p>Verhulst equation, 8
</p>
<p>von Foerster model, 230
</p>
<p>W
</p>
<p>Weak form, 27, 54
</p>
<p>Weakly nonlinear oscillator, 185</p>
<p/>
</div>
<ul>	<li>Preface</li>
	<li>Acknowledgments</li>
	<li>Contents</li>
	<li>Part I Formulation of Models&#13;</li>
	<li>1 Rate Equations</li>
<ul>	<li>1.1 The Motion of Particles</li>
	<li>1.2 Chemical Reaction Kinetics</li>
	<li>1.3 Ecological and Biological Models</li>
	<li>1.4 One-Dimensional Phase-Line Dynamics</li>
	<li>1.5 Two-Dimensional Phase Plane Analysis</li>
<ul>	<li>1.5.1 Nullclines</li>
</ul>
	<li>1.6 Further Directions</li>
	<li>1.7 Exercises</li>
</ul>
	<li>2 Transport Equations</li>
<ul>	<li>2.1 The Reynolds Transport Theorem</li>
	<li>2.2 Deriving Conservation Laws</li>
	<li>2.3 The Linear Advection Equation</li>
	<li>2.4 Systems of Linear Advection Equations</li>
	<li>2.5 The Method of Characteristics</li>
	<li>2.6 Shocks in Quasilinear Equations</li>
	<li>2.7 Further Directions</li>
	<li>2.8 Exercises</li>
</ul>
	<li>3 Variational Principles</li>
<ul>	<li>3.1 Review and Generalisation from Calculus</li>
<ul>	<li>3.1.1 Functionals</li>
</ul>
	<li>3.2 General Approach and Basic Examples</li>
<ul>	<li>3.2.1 The Simple Shortest Curve Problem</li>
	<li>3.2.2 The Classic Euler--Lagrange Problem</li>
</ul>
	<li>3.3 The Variational Formation of Classical Mechanics</li>
<ul>	<li>3.3.1 Motion with Multiple Degrees of Freedom</li>
</ul>
	<li>3.4 The Influence of Boundary Conditions</li>
<ul>	<li>3.4.1 Problems with a Free Boundary</li>
	<li>3.4.2 Problems with a Variable Endpoint</li>
</ul>
	<li>3.5 Optimisation with Constraints</li>
<ul>	<li>3.5.1 Review of Lagrange Multipliers</li>
</ul>
	<li>3.6 Integral Constraints: Isoperimetric Problems</li>
	<li>3.7 Geometric Constraints: Holonomic Problems</li>
	<li>3.8 Differential Equation Constraints: Optimal Control</li>
	<li>3.9 Further Directions</li>
	<li>3.10 Exercises</li>
</ul>
	<li>4 Dimensional Scaling Analysis</li>
<ul>	<li>4.1 Dimensional Quantities</li>
<ul>	<li>4.1.1 The SI System of Base Units</li>
</ul>
	<li>4.2 Dimensional Homogeneity</li>
	<li>4.3 The Process of Nondimensionalisation</li>
<ul>	<li>4.3.1 Projectile Motion</li>
	<li>4.3.2 Terminal Velocity of a Falling Sphere in a Fluid</li>
	<li>4.3.3 The Burgers Equation</li>
</ul>
	<li>4.4 Further Applications of Dimensional Analysis</li>
<ul>	<li>4.4.1 Projectile Motion (Revisited)</li>
	<li>4.4.2 Closed Curves in the Plane</li>
</ul>
	<li>4.5 The Buckingham Pi Theorem</li>
<ul>	<li>4.5.1 Mathematical Consequences</li>
	<li>4.5.2 Application to the Quadratic Equation</li>
</ul>
	<li>4.6 Further Directions</li>
	<li>4.7 Exercises</li>
</ul>
	<li>Part II Solution Techniques&#13;</li>
	<li>5 Self-Similar Scaling Solutions of Differential Equations</li>
<ul>	<li>5.1 Finding Scaling-Invariant Symmetries</li>
	<li>5.2 Determining the Form of the Similarity Solution</li>
	<li>5.3 Solving for the Similarity Function</li>
	<li>5.4 Further Comments on Self-Similar Solutions</li>
	<li>5.5 Similarity Solutions of the Heat Equation</li>
<ul>	<li>5.5.1 Source-Type Similarity Solutions</li>
	<li>5.5.2 The Boltzmann Similarity Solution</li>
</ul>
	<li>5.6 A Nonlinear Diffusion Equation</li>
	<li>5.7 Further Directions</li>
	<li>5.8 Exercises</li>
</ul>
	<li>6 Perturbation Methods</li>
<ul>	<li>6.1 Asymptotic Analysis: Concepts and Notation</li>
	<li>6.2 Asymptotic Expansions</li>
<ul>	<li>6.2.1 Divergence of Asymptotic Expansions</li>
</ul>
	<li>6.3 The Calculation of Asymptotic Expansions</li>
<ul>	<li>6.3.1 The Expansion Method</li>
	<li>6.3.2 The Iteration Method</li>
	<li>6.3.3 Further Examples</li>
</ul>
	<li>6.4 A Regular Expansion for a Solution of an ODE Problem</li>
	<li>6.5 Singular Perturbation Problems</li>
<ul>	<li>6.5.1 Rescaling to Obtain Singular Solutions</li>
</ul>
	<li>6.6 Further Directions</li>
	<li>6.7 Exercises</li>
</ul>
	<li>7 Boundary Layer Theory</li>
<ul>	<li>7.1 Observing Boundary Layer Structure in Solutions</li>
	<li>7.2 Asymptotics of the Outer and Inner Solutions</li>
	<li>7.3 Constructing Boundary Layer Solutions</li>
<ul>	<li>7.3.1 The Outer Solution</li>
	<li>7.3.2 The Distinguished Limits</li>
	<li>7.3.3 The Inner Solution</li>
	<li>7.3.4 Asymptotic Matching</li>
	<li>7.3.5 The Composite Solution</li>
</ul>
	<li>7.4 Further Examples</li>
	<li>7.5 Further Directions</li>
	<li>7.6 Exercises</li>
</ul>
	<li>8 Long-Wave Asymptotics for PDE Problems</li>
<ul>	<li>8.1 The Classic Separation of Variables Solution</li>
	<li>8.2 The Dirichlet Problem on a Slender Rectangle</li>
	<li>8.3 The Insulated Wire</li>
	<li>8.4 The Nonuniform Insulated Wire</li>
	<li>8.5 Further Directions</li>
	<li>8.6 Exercises</li>
</ul>
	<li>9 Weakly-Nonlinear Oscillators</li>
<ul>	<li>9.1 Review of Solutions of the Linear Problem</li>
	<li>9.2 The Failure of Direct Regular Expansions</li>
	<li>9.3 Poincare--Lindstedt Expansions</li>
	<li>9.4 The Method of Multiple Time-Scales</li>
	<li>9.5 Further Directions</li>
	<li>9.6 Exercises</li>
</ul>
	<li>10 Fast/slow Dynamical Systems</li>
<ul>	<li>10.1 Strongly-Nonlinear Oscillators: The van der Pol Equation</li>
	<li>10.2 Complex Chemical Reactions: The Michaelis-Menten Model</li>
	<li>10.3 Further Directions</li>
	<li>10.4 Exercises</li>
</ul>
	<li>11 Reduced Models for PDE Problems</li>
<ul>	<li>11.1 The Method of Moments</li>
	<li>11.2 Turing Instability and Pattern Formation</li>
	<li>11.3 Taylor Dispersion and Enhanced Diffusion</li>
	<li>11.4 Further Directions</li>
	<li>11.5 Exercises</li>
</ul>
	<li>Part III Case Studies&#13;</li>
	<li>12 Modelling in Applied Fluid Dynamics</li>
<ul>	<li>12.1 Lubrication Theory</li>
	<li>12.2 Dynamics of an Air Bearing Slider</li>
	<li>12.3 Rivulets in a Wedge Geometry</li>
<ul>	<li>12.3.1 Imbibition in a Vertical Wedge</li>
	<li>12.3.2 Draining in a Vertical Wedge</li>
</ul>
</ul>
	<li> Epilogue</li>
	<li>Appendix A Trigonometric Identities and Fourier Series&#13;</li>
	<li> Solutions to Selected Problems</li>
	<li> References</li>
	<li>Index</li>
</ul>
</body></html>