<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title></title>
</head>
<body><div class="page"><p/>
</div>
<div class="page"><p/>
<p>Texts in Applied Mathematics 11 
</p>
<p>Editors 
</p>
<p>JE. Marsden 
L. Sirovich 
</p>
<p>M. Golubitsky 
</p>
<p>W. J&auml;ger 
F. John (deceased) 
</p>
<p>Advisors 
</p>
<p>D. Barkley 
M. Dellnitz 
P. Holmes 
</p>
<p>G. Iooss 
P. Newton </p>
<p/>
</div>
<div class="page"><p/>
<p>Texts in Applied Mathematics 
</p>
<p>1. Sirovich: Introduction to Applied Mathematics. 
</p>
<p>2. Wiggins: Introduction to Applied Nonlinear Dynamical Systems and Chaos, 2nd ed. 
</p>
<p>3. Hale/Kor;ak: Dynamics and Bifurcations. 
</p>
<p>4. Chorin/Marsden: A Mathematical Introduction to Fluid Mechanics, 3rd ed. 
</p>
<p>5. Hubbard/West: Differential Equations: A Dynamical Systems Approach: Ordinary 
</p>
<p>Differential Equations. 
</p>
<p>6. Sontag: Mathematical Control Theory: Deterministic Finite Dimensional Systems, 
</p>
<p>2nd ed. 
</p>
<p>7. Perko: Differential Equations and Dynamical Systems, 3rd ed. 
</p>
<p>8. Seaborn: Hypergeometrie Functions and Their Applications. 
</p>
<p>9. Pipkin: A Course on Integral Equations. 
</p>
<p>I 0. Hoppensteadt/Peskin: Modeling and Simulation in Medicine and the Life Sciences, 
</p>
<p>2nd ed. 
</p>
<p>II. Braun: Differential Equations and Their Applications, 4th ed. 
</p>
<p>12. Stoer/Bulirsch: Introduction to Numerical Analysis, 3rd ed. 
</p>
<p>13. Renardy/Rogers: An Introduction to Partial Differential Equations, 2nd ed. 
</p>
<p>14. Banks: Growth and Diffusion Phenomena: Mathematical Framewerksand 
</p>
<p>Applications. 
</p>
<p>15. Brenner/Scott: The Mathematical Theory ofFinite Element Methods, 2nd ed. 
</p>
<p>16. V an de Velde: Concurrent Scientific Computing. 
</p>
<p>17. Marsden/Ratiu: Introduction to Mechanics and Syrnrnetry, 2nd ed. 
</p>
<p>18. Hubbard/West: Differential Equations: A Dynamical Systems Approach: Higher-
</p>
<p>Dimensional Systems. 
</p>
<p>19. Kaplan/Glass: Understanding Nonlinear Dynamics. 
</p>
<p>20. Holmes: Introduction to Perturbation Methods. 
</p>
<p>21. Curtain/Zwart: An Introduction to Infinite-Dimensional Linear Systems Theory. 
</p>
<p>22. Thomas: Numerical Partial Differential Equations: Finite Difference Methods. 
</p>
<p>23. Taylor: Partial Differential Equations: Basic Theory. 
</p>
<p>24. Merkin: Introduction to the Theory of Stability of Motion. 
</p>
<p>25. Naher: Topology, Geometry, and Gauge Fields: Foundations. 
</p>
<p>26. Polderman/Willems: Introduction to Mathematical Systems Theory: A Behavioral 
</p>
<p>Approach. 
</p>
<p>27. Reddy: Introductory Functional Analysis with Applications to Boundary-Value 
</p>
<p>Problems and Finite Elements. 
</p>
<p>28. Gustafson/Wilcox: Analytical and Computational Methods of Advanced 
</p>
<p>Engineering Mathematics. 
</p>
<p>29. Tveito/Winther: Introduction to Partial Differential Equations: A Computational 
</p>
<p>Approach. 
</p>
<p>30. Gasquet/Witomski: Fourier Analysis and Applications: Filtering, Numerical 
</p>
<p>Computation, Wavelets. 
</p>
<p>(continued after index) </p>
<p/>
</div>
<div class="page"><p/>
<p>Martin Braun 
</p>
<p>Differential Equations 
and Their Applications 
An Introduction to 
Applied Mathematics 
</p>
<p>F ourth Edition 
</p>
<p>With 68 Illustrations 
</p>
<p>~Springer </p>
<p/>
</div>
<div class="page"><p/>
<p>Martin Braun 
Department of Mathematics 
Queens College 
City University of New York 
Flushing, NY 11367 
USA 
</p>
<p>Series Editors 
</p>
<p>Jerrold E. Marsden 
Control and Dynamical Systems, 107-81 
California Institute of Technology 
Pasadena, CA 91125 
USA 
</p>
<p>M. Golubitsky 
Department of Mathematics 
University of Houston 
Houston, TX 77204-3476 
USA 
</p>
<p>L. Sirovich 
Division of App!ied Mathematics 
Brown University 
Providence, RI 02912 
USA 
</p>
<p>W. Jăger 
Department of Applied Mathematics 
Universităt Heidelberg 
Im Neuenheimer Feld 294 
69120 Heidelberg, Germany 
</p>
<p>Mathematics Subject Classification (1991): 34-01 
</p>
<p>Library of Congress Cata1oging-in-Pub1ication Data 
Braun, Martin, 1941-
</p>
<p>Differentia1 equations and their app1ications: an introduction to 
applied mathematics / M. Braun.-4th ed. 
</p>
<p>p. cm.-(Texts in app1ied mathematics; 11) 
Includes bibliographical references and index. 
ISBN 978-0-387-94330-5 ISBN 978-1-4612-4360-1 (eBook) 
DOI 10.1007/978-1-4612-4360-1 
1. Differential equations. 1. Title. Il. Series. 
</p>
<p>QA37l.B795 1992 
515'.35-dc20 92-24317 
</p>
<p>ISBN 978-0-387-94330-5 Printed on acid-free paper. 
</p>
<p>&copy; 1993 Springer Science+Business Media New York 
Softcover reprint of the hardcover 1 st edition 1993. 
Ali rights reserved. This work may not be translated or copied in whole or in part without the 
written permission of the publisher (Springer Science+Business Media, LLC) 
except for brief excerpts in connection with reviews or scholarly analysis. 
Use in connection with any form of information storage and retrieval, electronic 
adaptation, computer software, or by similar or dissimilar methodology now know or hereafter 
developed is forbidden. 
The use in this publication of trade names, trademarks, service marks and similar terms, even if 
the are not identified as such, is not tobe taken as an expression of opinion as to whether or not 
they are subject to proprietary rights. 
</p>
<p>9 8 
</p>
<p>springeronline.com </p>
<p/>
</div>
<div class="page"><p/>
<p>To Jour beautiful people: 
</p>
<p>Zelda Lee 
</p>
<p>Adeena Rachelle, I. Nasanayl, and Shulamit </p>
<p/>
</div>
<div class="page"><p/>
<p>Series Preface 
</p>
<p>Mathematics is playing an ever more important role in the physical and 
biological sciences, provoking a blurring of boundaries between scientific 
disciplines and a resurgence of interest in the modern as weil as the classical 
techniques of applied mathematics. This renewal of interest, both in research 
and teaching, has led to the establishment of the series: Texts in Applied 
Mathematics (TAM). 
</p>
<p>The development of new courses is a natural consequence of a high Ievel 
of excitement on the research frontier as newer techniques, such as numerical 
and symbolic computer systems, dynamical systems, and chaos, mix with and 
reinforce the traditional methods of applied mathematics. Thus, the purpose 
of this textbook series is to meet the current and future needs of these 
advances and encourage the teaching of new courses. 
</p>
<p>T AM will publish textbooks suitable for use in advanced undergraduate 
and beginning graduate courses, and will complement the Applied Mathe-
matical Seiences ( AMS) series, which will focus on advanced textbooks and 
research Ievel monographs. </p>
<p/>
</div>
<div class="page"><p/>
<p>Preface to the Fourth Edition 
</p>
<p>There are two major changes in the Fourth Edition of Differential Equations 
and Their Applications. The first concerns the computer programs in this text. 
In keeping with recent trends in computer science, we have replaced all the 
APL programs with Pascal and C programs. The Pascal programs appear in 
the text in place ofthe APL programs, where they are followed by the Fortran 
programs, while the C programs appear in Appendix C. 
</p>
<p>The second change, in response to many readers' suggestions, is the in-
clusion of a new chapter (Chapter 6) on Sturm-Liouville boundary value 
problems. Our goal in this chapter is not to present a whole lot of technical 
material. Rather it is to show that the theory of Fourier series presented in 
Chapter 5 is not an isolated theory but is part of a much more general and 
beautiful theory which encompasses many of the key ideas of linear algebra. 
</p>
<p>To accomplish this goal we have included some additional material from 
linear algebra. In particular, we have introduced the notions of inner product 
spaces and self-adjoint matrices, proven that the eigenvalues of a self-adjoint 
matrix are real, and shown that all self-adjoint matrices possess an ortho-
normal basis of eigenvectors. These results are at the heart of Sturm-Liouville 
theory. 
</p>
<p>I wish to thank Robert Giresi for writing the Pascal and C programs. 
</p>
<p>New York City 
May, 1992 
</p>
<p>Martin Braun </p>
<p/>
</div>
<div class="page"><p/>
<p>Preface to the Third Edition 
</p>
<p>There are three major changes in the Third Edition of Differential Equations 
and Their Applications. First, we have completely rewritten the section on 
singular solutions of differential equations. A new section, 2.8.1, dealing 
with Euler equations has been added, and this section is used to motivate a 
greatly expanded treatment of singular equations in sections 2.8.2 and 2.8.3. 
</p>
<p>Our second major change is the addition of a new section, 4.9, dealing 
with bifurcation theory, a subject of much current interest. We felt it 
desirable to give the reader a brief but nontrivial introduction to this 
important topic. 
</p>
<p>Our third major change is in Section 2.6, where we have switched to the 
metric system of units. This change was requested by many of our readers. 
</p>
<p>In addition to the above changes, we have updated the material on 
population models, and have revised the exercises in this section. Minor 
editorial changes have also been made throughout the text. 
</p>
<p>New York City 
November, 1982 Martin Braun </p>
<p/>
</div>
<div class="page"><p/>
<p>Preface to the First Edition 
</p>
<p>This textbook is a unique blend of the theory of differential equations&middot; and 
their exciting application to "real world" problems. First, and foremost, it 
is a rigorous study of ordinary differential equations and can be fully 
understood by anyone who has completed one year of calculus. However, 
in addition to the traditional applications, it also contains many exciting 
"real life" problems. These applications are completely self contained. 
First, the problern to be solved is outlined clearly, and one or more 
differential equations are derived as a model for this problem. These 
equations are then solved, and the results are compared with real world 
data. The following applications are covered in this text. 
</p>
<p>1. In Section 1.3 we prove that the beautiful painting "Disciples of 
Emmaus" which was bought by the Rembrandt Society of Belgium for 
$170,000 was a modern forgery. 
</p>
<p>2. In Section 1.5 we derive differential equations which govem the 
population growth of various species, and compare the results predicted by 
our models with the known values of the populations. 
</p>
<p>3. In Section 1.6 we derive differential equations which govern the rate at 
which farmers adopt new innovations. Surprisingly, these same differential 
equations govem the rate at which technological innovations are adopted in 
such diverse industries as coal, iron and steel, brewing, and railroads. 
</p>
<p>4. In Section 1.7 we try to determine whether tightly sealed drums filled 
with concentrated waste material will crack upon impact with the ocean 
floor. In this section we also describe several tricks for obtaining informa-
tion about solutions of a differential equation that cannot be solved 
explicitly. </p>
<p/>
</div>
<div class="page"><p/>
<p>Preface to the First Edition 
</p>
<p>5. In Section 2. 7 we derive a very simple model of the blood glucose 
regulatory system and obtain a fairly reliable criterion for the diagnosis of 
diabetes. 
</p>
<p>6. Section 4.5 describes two applications of differential equations to 
arms races and actual combat. In Section 4.5.1 we discuss L. F. Richard-
son's theory of the escalation of arms races and fit his model to the arms 
race which led eventually to World War I. This section also provides the 
reader with a concrete feeling for the concept of stability. In Section 4.5.2 
we derive two Lanchestrian combat models, and fit one of these models, 
with astanishing accuracy, to the battle of Iwo Jima in World War II. 
</p>
<p>7. In Section 4.10 we show why the predator portion (sharks, skates, rays, 
etc.) of all fish caught in the port of Fiume, Italy rose dramatically during 
the years of World War I. The theory we develop here also has a 
spectacular application to the spraying of insecticides. 
</p>
<p>8. In Section 4.11 we derive the "principle of competitive exclusion," 
which states, essentially, that no two species can eam their living in an 
identical manner. 
</p>
<p>9. In Section 4.12 we study a system of differential equations which 
govem the spread of epidemics in a population. This model enables us to 
prove the famous "threshold theorem of epidemiology," which states that 
an epidemic will occur only if the number of people susceptible to the 
disease exceeds a certain threshold value. We also compare the predictions 
of our model with data from an actual plague in Bombay. 
</p>
<p>10. In Section 4.13 we derive a model for the spread of gonorrhea and 
prove that either this disease dies out, or else the number of people who 
have gonorrhea will ultimately approach a fixed value. 
</p>
<p>This textbook also contains the following important, and often unique 
features. 
</p>
<p>1. In Section 1.10 we give a complete proof of the existence-uniqueness 
theorem for solutions of first-order equations. Our proof is based on the 
method of Picard iterates, and can be fully understood by anyone who has 
completed one year of calculus. 
</p>
<p>2. In Section 1.11 we show how to solve equations by iteration. This 
section has the added advantage of reinforcing the reader's understanding 
of the proof of the existence-uniqueness theorem. 
</p>
<p>3. Complete Fortran and APL programs are given for every computer 
example in the text. Computer problems appear in Sections 1.13-1.17, 
which deal with numerical approximations of solutions of differential 
equations; in Section 1.11, which deals with solving the equations x = f(x) 
and g(x)=O; andin Section 2.8, where we show how to obtain a power-
sefies solution of a differential equation even though we cannot explicitly 
solve the recurrence formula for the coefficients. 
</p>
<p>4. A self-contained introduction to the computing language APL is 
presented in Appendix C. Using this appendix we have been able to teach 
our students APL in just two lectures. </p>
<p/>
</div>
<div class="page"><p/>
<p>Preface to the First Edition 
</p>
<p>5. Modesty aside, Section 2.12 contains an absolutely super and unique 
treatment of the Dirac delta function. We are very proud of this section 
because it eliminates all the ambiguities which are inherent in the tradi-
tional exposition of this topic. 
</p>
<p>6. All the linear algebra pertinent to the study of systems of equations is 
presented in Sections 3.1-3.7. One advantage of our approachisthat the 
reader gets a concrete feeling for the very important but extremely abstract 
properties of linear independence, spanning, and dimension. Indeed, many 
linear algebra students sit in on our course to find out what's really going 
on in their course. 
</p>
<p>Differential Equations and Their Applications can be used for a one- or 
two-semester course in ordinary differential equations. It is geared to the 
student who has completed two semesters of calculus. Traditionally, most 
authors present a "suggested syllabus" for their textbook. We will not do so 
here, though, since there are already more than twenty different syllabi in 
use. Suffice it to say that this text can be used for a wide variety of courses 
in ordinary differential equations. 
</p>
<p>I greatly appreciate the help of the following people in the preparation 
of this manuscript: Douglas Reber who wrote the Fortran programs, 
Eleanor Addison who drew the original figures, and Kate MacDougall, 
Sandra Spinacci, and Miriam Green who typed portions of this manu-
script. 
</p>
<p>I am grateful to Walter Kaufmann-B&uuml;hler, the mathematics editor at 
Springer-Verlag, and Elizabeth Kaplan, the production editor, for their 
extensive assistance and courtesy during the preparation of this 
manuscript. It is a pleasure to work with these true professionals. 
</p>
<p>Finally, I am especially grateful to Joseph P. LaSalle for the encourage-
ment and help he gave me. Thanks again, Joe. 
</p>
<p>New York City 
Ju/y, 1976 
</p>
<p>Martin Braun </p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 1 
</p>
<p>First-order differential equations 
</p>
<p>1.1 Introduction 
1.2 First-order linear differential equations 
1.3 The V an Meegeren art forgeries 
1.4 Separable equations 
1.5 Population models 
1.6 The spread of technological innovations 
1.7 An atomic waste disposal problern 
1.8 The dynamics of tumor growth, mixing problems, and 
</p>
<p>orthogonal trajectories 
1.9 Exact equations, and why we cannot solve very many 
</p>
<p>differential equations 
I. 10 The existence-uniqueness theorem; Picard iteration 
1.11 Finding roots of equations by iteration 
</p>
<p>l.ll.l Newton's method 
1.12 Difference equations, and how to compute the interest 
</p>
<p>due on your student loans 
1.13 Numerical approximations; Euler's method 
</p>
<p>1.13.1 Error analysis for Euler's method 
1.14 The three term Taylor series method 
1.15 An improved Euler method 
1.16 The Runge-Kutta method 
1.17 What to do in practice 
</p>
<p>Contents 
</p>
<p>1 
</p>
<p>1 
</p>
<p>2 
11 
</p>
<p>20 
26 
39 
46 
</p>
<p>52 
</p>
<p>58 
67 
81 
87 
</p>
<p>91 
96 
</p>
<p>100 
107 
109 
112 
116 </p>
<p/>
</div>
<div class="page"><p/>
<p>Contents 
</p>
<p>Chapter 2 
</p>
<p>Second-order linear differential equations 
</p>
<p>2.1 Algebraic properties of so1utions 
2.2 Linear equations with constant coefficients 
</p>
<p>2.2.1 Comp1ex roots 
2.2.2 Equa1 roots; reduction of order 
</p>
<p>2.3 The nonhomogeneous equation 
2.4 The method of variation of parameters 
2.5 The method of judicious guessing 
2.6 Mechanical vibrations 
</p>
<p>2.6.1 The Tacoma Bridge disaster 
2.6.2 Electrical networks 
</p>
<p>2.7 A model for the detection of diabetes 
2.8 Series solutions 
</p>
<p>2.8.1 Singular points, Euler equations 
2.8.2 Regularsingular points, the method of Frobenius 
2.8.3 Equal roots, and roots differing by an integer 
</p>
<p>2.9 The method of Laplace transforms 
2.10 Some useful properties of Laplace transforms 
2.11 Differential equations with discontinuous right-hand sides 
2.12 The Dirac delta function 
2.13 The convolution integral 
2.14 The method of elimination for systems 
2.15 Higher-order equations 
</p>
<p>Chapter 3 
</p>
<p>Systems of differential equations 
</p>
<p>3.1 Algebraic properties of solutions of linear systems 
3.2 Vector spaces 
3.3 Dimension of a vector space 
3.4 App1ications of linear algebra to differential equations 
3.5 The theory of determinants 
3.6 Solutions of simultaneous linear equations 
3.7 Lineartransformations 
3.8 The eigenvalue-eigenvector method of finding solutions 
3.9 Complex roots 
3.10 Equal roots 
3.11 Fundamentalmatrix so1utions; eA1 
3.12 The nonhomogeneous equation; variation of parameters 
3.13 Solving systems by Laplace transforms 
</p>
<p>Chapter 4 
</p>
<p>Qualitative theory of differential equations 
</p>
<p>4.1 Introduction 
4.2 Stability of linear systems 
</p>
<p>127 
</p>
<p>127 
138 
141 
145 
151 
153 
157 
165 
173 
175 
178 
185 
198 
203 
219 
225 
233 
238 
243 
251 
257 
259 
</p>
<p>264 
</p>
<p>264 
273 
279 
291 
297 
310 
320 
333 
341 
345 
355 
360 
368 
</p>
<p>372 
</p>
<p>372 
378 </p>
<p/>
</div>
<div class="page"><p/>
<p>Contents 
</p>
<p>4.3 Stability of equilibrium solutions 385 
4.4 The phase-plane 394 
</p>
<p>4.5 Mathematical theories of war 398 
4.5.1 L. F. Richardson's theory of conflict 398 
4.5.2 Lanchester's combat models and the battle of I wo Jima 405 
</p>
<p>4.6 Qualitative properties of orbits 414 
4.7 Phaseportraits of linear systems 418 
4.8 Long time behavior of solutions; the Poincare-Bendixson Theorem 428 
</p>
<p>4.9 Introduction to bifurcation theory 437 
4.10 Predator-prey problems; or why 
</p>
<p>the percentage of sharks caught in the Mediterranean 
Sea rose dramatically during World War I 443 
</p>
<p>4.11 The princip1e of competitive exclusion in population biology 451 
4.12 The Threshold Theorem of epidemiology 458 
4.13 A model for the spread of gonorrhea 465 
</p>
<p>Chapter 5 
</p>
<p>Separation of variables and Fourier series 476 
</p>
<p>5.1 Two point boundary-value problems 476 
5.2 Introduction to partial differential equations 481 
</p>
<p>5.3 The heat equation; separation of variables 483 
5.4 Fourier series 487 
5.5 Even and odd functions 493 
5.6 Return to the heat equation 498 
5.7 The wave equation 503 
5.8 Laplace's equation 508 
</p>
<p>Chapter 6 
</p>
<p>Sturm-Liouville boundary value problems 514 
</p>
<p>6.1 Introduction 514 
6.2 Inner product spaces 515 
6.3 Orthogonal bases, Hermitian operators 526 
6.4 Sturm-Liouville theory 533 
</p>
<p>Appendix A 
</p>
<p>Some simple facts concerning functions 
of several variables 545 
</p>
<p>Appendix B 
</p>
<p>Sequences and series 
</p>
<p>Appendix C 
</p>
<p>C Programs 
</p>
<p>547 
</p>
<p>549 </p>
<p/>
</div>
<div class="page"><p/>
<p>Contents 
</p>
<p>Answers to odd-numbered exercises 
</p>
<p>Index 
</p>
<p>557 
</p>
<p>575 </p>
<p/>
</div>
<div class="page"><p/>
<p>First-order differential equations 
</p>
<p>1 
</p>
<p>1.1 Introduction 
</p>
<p>This book is a study of differential equations and their applications. A dif-
ferential equation is a relationship between a function of time and its de-
rivatives. The equations 
</p>
<p>dy 
dt =3y2 sin(t+y) (i) 
</p>
<p>and 
</p>
<p>(ii) 
</p>
<p>are both examples of differential equations. The order of a differential 
equation is the order of the highest derivative of the function y that ap-
pears in the equation. Thus (i) is a first-order differential equation and (ii) 
is a third-order differential equation. By a solution of a differential equa-
tion we will mean a continuous function y(t) which together with its de-
rivatives satisfies the relationship. For example, the function 
</p>
<p>y ( t) = 2 sin t - ~ cos 2 t 
</p>
<p>is a solution of the second-order differential equation 
</p>
<p>d2y 
- +y=cos2t 
dt 2 
</p>
<p>smce 
</p>
<p>d: (2sint- ~ cos2t) + (2sint- ~ cos2t) 
dt 
</p>
<p>= ( - 2 sin t + ~ cos 2 t) + 2 sin t - ~ cos 2 t = cos 2t. </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>Differential equations appear naturally in many areas of science and the 
humanities. In this book, we will present serious discussions of the applica-
tions of differential equations to such diverse and fascinating problems as 
the detection of art forgeries, the diagnosis of diabetes, the increase in the 
percentage of sharks present in the Mediterranean Sea during World War 
I, and the spread of gonorrhea. Our purpose is to show how researchers 
have used differential equations to solve, or try to solve, rea/life problems. 
And while we will discuss some of the great success stories of differential 
equations, we will also point out their limitations and document some of 
their failures. 
</p>
<p>1.2 First-order linear differential equations 
</p>
<p>Webegin by studying first-order differential equations and we will assume 
that our equation is, or can be put, in the form 
</p>
<p>dy 
dt = f(t,y). (1) 
</p>
<p>The problern before us is this: Given f(t,y) find all functions y(t) which 
satisfy the differential equation (1). We approach this problern in the 
following manner. A fundamental principle of mathematics is that the way 
to solve a new problern is to reduce it, in some manner, to a problern that 
we have already solved. In practice this usually entails successively sim-
plifying the problern until it resembles one we have already solved. Since 
we are presently in the business of solving differential equations, it is advis-
able for us to take inventory and list all the differential equations we can 
solve. If we assume that our mathematical background consists of just ele-
mentary calculus then the very sad fact is that the only first-order differen-
tial equation we can solve at present is 
</p>
<p>dy 
-=g(t) 
dt 
</p>
<p>(2) 
</p>
<p>where g is any integrable function of time. To solve Equation (2) simply 
integrate both sides with respect to t, which yields 
</p>
<p>y(t) = J g(t)dt+ c. 
</p>
<p>Here c is an arbitrary constant of integration, and by J g(t)dt we mean an 
anti-derivative of g, that is, a function whose derivative is g. Thus, to solve 
any other differential equation we must somehow reduce it to the form (2). 
As we will see in Section 1.9, this is impossible to do in most cases. Hence, 
we will not be able, without the aid of a computer, to solve most differen-
tial equations. It stands to reason, therefore, that to find those differential 
equations that we can solve, we should start with very simple equations 
</p>
<p>2 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.2 First-order linear differential equations 
</p>
<p>and not ones like 
</p>
<p>dy = e&bull;in(t-37YJYI) 
dt 
</p>
<p>(which incidentally, cannot be solved exactly). Experience has taught us 
that the "simplest" equations are those which are linear in the dependent 
variable y. 
</p>
<p>Definition. The general first-order linear differential equation is 
</p>
<p>dy 
dt +a(t)y=b(t). (3) 
</p>
<p>Unless otherwise stated, the functions a(t) and b(t) are assumed to be 
continuous functions of time. We singleout this equation and call it lin-
ear because the dependent variable y appears by itself, that is, no terms 
such as e-Y, y 3 or siny etc. appear in the equation. For example dy I dt 
= y 2 + sin t and dy I dt = cosy + t are both nonlinear equations because of 
the y 2 and cosy terms respectively. 
</p>
<p>Now it is not immediately apparent how to solve Equation (3). Thus, we 
simplify it even further by setting b( t) = 0. 
</p>
<p>Definition. The equation 
</p>
<p>dy 
- +a(t)y=O 
dt 
</p>
<p>(4) 
</p>
<p>is called the homogeneous first-order linear differential equation, and 
Equation (3) is called the nonhomogeneous first-order linear differential 
equation for b(t) not identically zero. 
</p>
<p>Fortunately, the homogeneous equation (4) can be solved quite easily. 
First, divide both sides of the equation by y and rewrite it in the form 
</p>
<p>Second, observe that 
</p>
<p>dy 
</p>
<p>dt 
- = -a(t). 
</p>
<p>y 
</p>
<p>dy 
</p>
<p>dt =!Llnly(t)l 
y dt 
</p>
<p>where by lnly{t)l we mean the naturallogarithm of ly(t)l. Hence Equation 
(4) can be written in the form 
</p>
<p>d 
dt lnly(t)l =- a(t). (5) 
</p>
<p>3 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>But this is Equation (2) "essentially" since we can integrate both sides of 
(5) to obtain that 
</p>
<p>lnly(t)l =- J a(t)dt+ c1 
</p>
<p>where c1 is an arbitrary constant of integration. Taking exponentials of 
both sides yields 
</p>
<p>ly(t)l=exp( -Ja(t)dt+c1)=cexp(- Ja(t)dt) 
</p>
<p>or 
</p>
<p>k(t)exp(J a(t)dt)i = c. (6) 
</p>
<p>Now, y(t) exp(J a( t) dt) is a continuous function of time and Equation (6) 
</p>
<p>states that its absolute value is constant. But if the absolute value of a con-
tinuous function g( t) is constant then g itself must be constant. To prove 
this observe that if g is not constant, then there exist two different times t 1 
and t2 for which g(t 1)=c and g(t2)= -c. By the intermediate value theo-
rem of calculus g must achieve all values between - c and + c which is im-
</p>
<p>possible if lg(t)l=c. Hence, we obtain theequationy(t)exp(ja(t)dt)=c 
or 
</p>
<p>y(t)=cexp(- J a(t)dt). (7) 
</p>
<p>Equation (7) is said to be the general solution of the homogeneaus equa-
tion since every solution of (4) must be of this form. Observe that an arbi-
trary constant c appears in (7). This should not be too surprising. Indeed, 
we will always expect an arbitrary constant to appear in the general solu-
tion of any first-order differential equation. To wit, if we are given dy I dt 
and we want to recover y(t), then we must perform an integration, and 
this, of necessity, yields an arbitrary constant. Observe also that Equation 
( 4) has infinitely many solutions; for each value of c we obtain a distinct 
solution y ( t). 
</p>
<p>Example 1. Find the general solution of the equation (dy I dt) + 2ty = 0. 
</p>
<p>Solution. Here a(t)=2t so thaty(t)=cexp(- J2tdt)=ce- 12 &bull; 
</p>
<p>Example 2. Determine the behavior, as t-HtJ, of all solutions of the equa-
tion (dy I dt) + ay = 0, a constant. 
</p>
<p>Solution. The general solution is y ( t) = c exp(- Ja dt) = c e- 01 &bull; Hence if 
</p>
<p>a &lt; 0, all solutions, with the exception of y = 0, approach infinity, and if a 
&gt; 0, all solutions approach zero as t ~ oo. 
</p>
<p>4 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.2 First-order linear differential equations 
</p>
<p>In applications, we are usually not interested in all solutions of (4). 
Rather, we are looking for the specific solution y(t) which at some initial 
time t0 has the value y 0&bull; Thus, we want to determine a function y(t) such 
that 
</p>
<p>dy 
dt +a(t)y=O, (8) 
</p>
<p>Equation (8) is referred to as an initial-value problern for the obvious rea-
son that of the totality of all solutions of the differential equation, we are 
looking for the one solution which initially (at time t0) has the value y 0 . To 
find this solution we integrate both sides of (5) between t0 and t. Thus 
</p>
<p>f l d fl -d lnly(s)lds=- a(s)ds 
lo S to 
</p>
<p>and, therefore 
</p>
<p>I 
y(t) I I, lnly(t)l-lnly(t0)l=ln -( -) =- a(s)ds. 
Y to to 
</p>
<p>Taking exponentials of both sides of this equation we obtain that 
</p>
<p>or 
</p>
<p>The function inside the absolute value sign is a continuous function of 
time. Thus, by the argument given previously, it is either identically + 1 or 
identically - 1. To determine which one it is, evaluate it at the point t0; 
since 
</p>
<p>y(to) (Jt0 ) -( -) exp a(s)ds = 1 
Y to to 
</p>
<p>we see that 
</p>
<p>y(t) (fl ) -( -) exp a(s)ds = 1. 
y to to 
</p>
<p>Hence 
</p>
<p>5 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>Example 3. Find the solution of the initial-value problern 
</p>
<p>dy (. ) 
dt + smt y=O, y(O)=f. 
</p>
<p>Solution. Here a(t)=sint so that 
</p>
<p>y(t)=fexp(- fo1sinsds)=fe(cost)-l. 
</p>
<p>Example 4. Find the solution of the initial-value problern 
</p>
<p>: +e 1y=O, y(l)=2. 
</p>
<p>Solution. Here a(t) = e 12 so that 
</p>
<p>y(t)=2exp(- {es 2 ds). 
</p>
<p>Now, at first glance this problern would seem to present a very serious dif-
ficulty in that we cannot integrate the function es2 directly. However, this 
solution is equally as valid and equally as useful as the solution to Example 
3. The reason for this is twofold. First, there are very simple numerical 
schemes to evaluate the above integral to any degree of accuracy with the 
aid of a computer. Second, even though the solution to Example 3 is given 
explicitly, we still cannot evaluate it at any time t without the aid of a table 
of trigonometric functions and some sort of calculating aid, such as a slide 
rule, electronic calculator or digital computer. 
</p>
<p>We return now to the nonhomogeneaus equation 
</p>
<p>dy 
dt +a(t)y=b(t). 
</p>
<p>It should be clear from our analysis of the homogeneaus equation that the 
way to solve the nonhomogeneaus equation is to express it in the form 
</p>
<p>~ ("something") = b ( t) 
</p>
<p>and then to integrate both sides to solve for "something". However, the ex-
pression (dy / dt) + a(t)y does not appear to be the derivative of some sim-
ple expression. The next logical step in our analysis therefore should be the 
following: Can we make the left hand side of the equation to be d/ dt of 
"something"? More precisely, we can multiply both sides of (3) by any 
continuous function J.L(l) to obtain the equivalent equation 
</p>
<p>dy 
J.L(t) dt + a(t) J.L(t)y = J.L(t)b(t). (9) 
</p>
<p>6 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.2 First-order linear differential equations 
</p>
<p>(By equivalent equations we mean that every solution of (9) is a solution of 
(3) and vice-versa.) Thus, can we choose 11-(t) so that 11-(t)(dy I dt) + 
a(t) 11-(t)y is the derivative of some simple expression? The answer to this 
question is yes, and is obtained by observing that 
</p>
<p>d dy d/L 
dt /L(t)y = /L(t) dt + dt y. 
</p>
<p>Hence, 11-(t)(dy I dt) + a(t) /L( t)y will be equal to the derivative of 11-(t)y if 
and only if d11-(t)l dt = a(t) 11-(t). But this is a first-order linear homoge-
neous equation for 11-(t), i.e. (d!LI dt)- a(t) 11- = 0 which we already know 
how to solve, and since we only need one such function 11-(t) we set the 
constant c in (7) equal to one and take 
</p>
<p>11-(t)=exp(J a(t)dt). 
</p>
<p>For this 11-(t), Equation (9) can be written as 
</p>
<p>d 
dt !L(t)y = !L(t)b(t). (10) 
</p>
<p>To obtain the general solution of the nonhomogeneous equation (3), that 
is, to find all solutions of the nonhomogeneous equation, we take the indef-
inite integral (anti-derivative) of both sides of (10) which yields 
</p>
<p>11-( t)y = J 11-( t)b(t)dt + c 
or 
</p>
<p>y= 11-~t)(J !L(t)b(t)dt+c)=exp(- Ja(t)dt)(J !L(t)b(t)dt+c). (11) 
</p>
<p>Alternately, if we are interested in the specific solution of (3) satisfying 
the initial condition y(t0) = y 0, that is, if we want to solve the initial-value 
problern 
</p>
<p>dy 
dt +a(t)y=b(t), 
</p>
<p>then we can take the definite integral of both sides of (10) between t0 and t 
to obtain that 
</p>
<p>or 
</p>
<p>y = 11-~t) ( 11-(t0)y0 + J: 11-(s)b(s)ds )&middot; (12) 
Remark 1. Notice how we used our knowledge of the solution of the ho-
mogeneous equation to find the function 11-(t) which enables us to solve the 
nonhomogeneous equation. This is an excellent illustration of how we use 
our knowledge of the solution of a simpler problern to solve a barder prob-
lern. 
</p>
<p>7 </p>
<p/>
</div>
<div class="page"><p/>
<p>l First-order differential equations 
</p>
<p>Remark 2. The function p.(t)=exp(J a(t)dt) is called an integratingjactor 
</p>
<p>for the nonhornogeneous equation since after rnultiplying both sides by 
p.(t) we can imrnediately integrate the equation to find all solutions. 
</p>
<p>Remark 3. The reader should not memorize formulae (11) and (12). 
Rather, we will solve all nonhornogeneous equations by first rnultiplying 
both sides by p.(t), by writing the new left-hand side as the derivative of 
p.(t)y(t), and then by integrating both sides of the equation. 
</p>
<p>Remark 4. An alternative way of solving the initial-value problern (dy I dt) 
+a(t)y=b(t),y(t0)=y0 is to find the general solution (II) of (3) and then 
use the initial condition y(t0) = y 0 to evaluate the constant c. If the function 
p.(t)b(t) cannot be integrated directly, though, then we rnust take the defi-
nite integral of (10) to obtain (12), and this equation is then approxirnated 
nurnerically. 
</p>
<p>Example 5. Find the general solution of the equation ( dy I dt)- 2ty = t. 
Solution. Here a(t) = - 2t so that 
</p>
<p>Multiplying both sides of the equation by p.(t) we obtain the equivalent 
equation 
</p>
<p>_,2(dy ) _,2 
e dt - 2ty = te or 
</p>
<p>Hence, 
</p>
<p>and 
</p>
<p>Example 6. Find the solution of the initial-value problern 
</p>
<p>: +2ty=t, y(l}=2. 
</p>
<p>Solution. Here a(t) = 2t so that 
</p>
<p>p.( t) = exp(J a( t)dt) = exp(J 2tdt) =er. 
</p>
<p>Multiplying both sides of the equation by p.(t) we obtain that 
</p>
<p>12(dy ) 2 d(2) 2 e -+2ty =te 1 or - e'y =te 1 &bull; 
dt dt 
</p>
<p>8 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.2 First-order linear differential equations 
</p>
<p>Hence, 
</p>
<p>f l d 2 fl 2 -e 5 y(s)ds= se 5 ds 
I ds I 
</p>
<p>so that 
</p>
<p>Consequently, 
</p>
<p>and 
</p>
<p>Example 7. Find the solution of the initial-value problern 
</p>
<p>dy I 
dt +y= l+t2' y(2)=3. 
</p>
<p>Solution. Here a(t)= 1, so that 
</p>
<p>t-t ( t) = exp( Ja ( t) dt) = exp( J I dt) = e 1&bull; 
</p>
<p>Multiplying both sides of the equation by t-t(t) we obtain that 
</p>
<p>or 
d 1 e 1 -ey=--. 
dt 1 + t2 
</p>
<p>Hence 
</p>
<p>11 d 11 es -d ey(s) ds = --2 ds, 
2 s 2 l+s 
</p>
<p>so that 
</p>
<p>and 
</p>
<p>EXERCISES 
</p>
<p>In each of Problems 1-7 find the general solution of the given differential 
equation. 
</p>
<p>dy 
1. dt + y cos t = 0 dy ,r 2. dt + y v t sin t = 0 
</p>
<p>9 </p>
<p/>
</div>
<div class="page"><p/>
<p>I First-order differential equations 
</p>
<p>dy 2t I 
J. dt + 1 + t 2 y = I + 12 
</p>
<p>dy 
4. dt + y = te' 
</p>
<p>dy 
5. dt + t2y =I 
</p>
<p>dy I t3 
7' dt + I+t2y=I- I+t 4 y 
</p>
<p>In each of Problems 8-14, find the solution of the given initial-value prob-
lern. 
</p>
<p>dy --
8. dt +Y1+t2 y=O, y(O)=V5 
</p>
<p>dy ,/-
9. dl + v I + 12 e _,y = 0, y(O)= I 
</p>
<p>10. ~ +YI+t2 e-y=O. y(O)=O 
dy 
</p>
<p>11. --2ty=t, 
dl 
</p>
<p>12. 
dy 
</p>
<p>y(D=O -+ty=1+t dt . 
dy I 
</p>
<p>13. dt + y = I+ 12, 
</p>
<p>14. 
dy 
</p>
<p>y(O) = 1 - -2ty= I 
dt ' 
</p>
<p>15. Find the general solution of the equation 
</p>
<p>(I+P)~ +ty=(I+12)5/2. 
</p>
<p>(Hinl: Divide both sides of the equation by I+ 12.) 
</p>
<p>16. Find the solution of the initiai-value problern 
</p>
<p>(1+1 2 )~ +41y=l, y(I)=~. 
</p>
<p>17. Find a continuous solution of the initial-value problern 
</p>
<p>where 
</p>
<p>y'+y=g(t), 
</p>
<p>g(t)= { 2, 
0, 
</p>
<p>y(O)=O 
</p>
<p>0.;; I.;; 1 
1 &gt;I . 
</p>
<p>y(O)= I 
</p>
<p>y(1)=2 
</p>
<p>18. Show that every solution of the equation (dy/dl)+ay=be-c' where a and c 
are positive constants and b is any real number approaches zero as 1 ap-
proaches infinity. 
</p>
<p>19. Given the differential equation (dy / dl) + a(t)y = j(l) with a(l) and f(l) con-
tinuous for - oo &lt;I&lt; oo, a(l) ~ c &gt; 0, and limHoo f(t) = 0, show that every 
solution tends to zero as 1 approaches infinity. 
</p>
<p>When we derived the solution of the nonhomogeneaus equation we tacitly 
assumed that the functions a(t) and b(t) were continuous so that we could 
perform the necessary integrations. If either of these functions was discon-
tinuous at a point t1, then we would expect that our solutions might be dis-
continuous at t = t 1&bull; Problems 20-23 illustrate the variety of things that 
</p>
<p>10 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.3 The V an Meergeren art forgeries 
</p>
<p>may happen. In Problems 20-22 determine the behavior of all solutions of 
the given differential equation as t~O, and in Problem 23 determine the 
behavior of all solutions as t~'Tf /2. 
</p>
<p>dy 1 1 
20. dt + (Y= t2 
</p>
<p>dy 1 sint 
22. dt + ty=cost+ - 1-
</p>
<p>21. dyd + _1_y = e VI /2 
!Vf 
</p>
<p>23. : +ytant=sintcost. 
</p>
<p>1.3 The V an Meegeren art forgeries 
</p>
<p>After the Iiberation of Belgium in World War II, the Dutch Field Security 
began its hunt for Nazi collaborators. They discovered, in the records of a 
firm which had sold numerous works of art to the Germans, the name of a 
banker who had acted as an intermediary in the sale to Goering of the 
painting "W oman Taken in Adultery" by the famed 17th century Dutch 
painter Jan Vermeer. The banker in turn revealed that he was acting on 
behalf of a third rate Dutch painter H. A. V an Meegeren, and on May 29, 
1945 V an Meegeren was arrested on the charge of collaborating with the 
enemy. On July 12, 1945 Van Meegeren startled the world by announcing 
from his prison cell that he had never sold "Woman Taken in Adultery" to 
Goering. Moreover, he stated that this painting and the very famous and 
beautiful "Disciples at Emmaus", as well as four other presumed Vermeers 
and two de Hooghs (a 17th century Dutch painter) were his own work. 
Many people, however, thought that Van Meegeren was only lying to save 
hirnself from the charge of treason. To prove his point, Van Meegeren be-
gan, while in prison, to forge the Vermeer painting "Jesus Amongst the 
Doctors" to demonstrate to the skeptics just how good a forger of Vermeer 
he was. The work was nearly completed when V an Meegeren learned that 
a charge of forgery had been substituted for that of collaboration. He, 
therefore, refused to finish and age the painting so that hopefully investiga-
tors would not uncover his secret of aging his forgeries. To settle the ques-
tion an international panel of distinguished chemists, physicists and art 
historians was appointed to investigate the matter. The panel took x-rays 
of the paintings to determine whether other paintings were underneath 
them. In addition, they analyzed the pigments (coloring materials) used in 
the paint, and examined the paintings for certain signs of old age. 
</p>
<p>Now, Van Meegeren was well aware of these methods. To avoid detec-
tion, he scraped the paint from old paintings that were not worth much, 
just to get the canvas, and he tried to use pigments that Vermeer would 
have used. Van Meegeren also knew that old paint was extremely hard, 
and impossible to dissolve. Therefore, he very cleverly mixed a chemical, 
phenoformaldehyde, into the paint, and this hardened into bakelite when 
the finished painting was heated in an oven. 
</p>
<p>11 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>However, V an Meegeren was careless with several of his forgeries, and 
the panel of experts found traces of the modern pigment cobalt blue. In 
addition, they also detected the phenoformaldehyde, which was not dis-
covered until the turn of the 19th century, in several of the paintings. On 
the basis of this evidence Van Meegeren was convicted, of forgery, on Oc-
tober 12, 1947 and sentenced to one year in prison. While in prison he 
suffered a heart attack and died on December 30, 1947. 
</p>
<p>However, even following the evidence gathered by the panel of experts, 
many people still refused to believe that the famed "Disciples at Emmaus" 
was forged by Van Meegeren. Their contention was based on the fact that 
the other alleged forgeries and Van Meegeren's nearly completed "Jesus 
Amongst the Doctors" were of a very inferior quality. Surely, they said, the 
creator of the beautiful "Disciples at Emmaus" could not produce such in-
ferior pictures. Indeed, the "Disciples at Emmaus" was certified as an 
authentic Vermeer by the noted art historian A. Bredius and was bought 
by the Rembrandt Society for $170,000. The answer of the panel to these 
skeptics was that because Van Meegeren was keenly disappointed by his 
Iack of status in the art world, he worked on the "Disciples at Emmaus" 
with the fierce determination of proving that he was better than a third 
rate painter. After producing such a masterpiece his determination was 
gone. Moreover, after seeing how easy it was to dispose of the "Disciples at 
Emmaus" he devoted less effort to his subsequent forgeries. This explana-
tion failed to satisfy the skeptics. They demanded a thoroughly scientific 
and conclusive proof that the "Disciples at Emmaus" was indeed a forgery. 
This was done recently in 1967 by scientists at Carnegie Mellon University, 
and we would now like to describe their work. 
</p>
<p>The key to the dating of paintings and other materials such as rocks and 
fossils lies in the phenomenon of radioactivity discovered at the turn of the 
century. The physicist Rutherford and his colleagues showed that the 
atoms of certain "radioactive" elements are unstable and that within a 
given time period a fixed proportion of the atoms spontaneously disin-
tegrates to form atoms of a new element. Because radioactivity is a prop-
erty of the atom, Rutherford showed that the radioactivity of a substance 
is directly proportional to the number of atoms of the substance present. 
Thus, if N (t) denotes the number of atoms present at time t, then dN / dt, 
the number of atoms that disintegrate per unit time is proportional to N, 
that is, 
</p>
<p>dN dt = -A.N. (1) 
</p>
<p>The constant )\ which is positive, is known as the decay constant of the 
substance. The larger )\ is, of course, the faster the substance decays. One 
measure of the rate of disintegration of a substance is its ha/f-/ife which is 
defined as the time required for half of a given quantity of radioactive 
atoms to decay. To compute the half-life of a substance in terms of A., 
assume that at time t0, N ( t0) = N 0&bull; Then, the solution of the initial-value 
</p>
<p>12 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.3 The Van Meergerenart forgeries 
</p>
<p>problern dN I dt= -A.N, N(t0)= N 0 is 
</p>
<p>N(t)=N0 exp( -A. J:ds)=N0e-Mt-to) 
</p>
<p>or NI N 0 = exp(- A.( t- t0 ) ). Taking logarithms of both sides we obtain that 
</p>
<p>N 
- A.( t- t0 ) =In N . (2) 
</p>
<p>0 
</p>
<p>Now, if NIN0=i then -A.(t-t0)=Ini so that 
</p>
<p>(t-to)= 1~2 = 0.6~31. (3) 
</p>
<p>Thus, the half-life of a substance is ln2 divided by the decay constant A.. 
The dimension of A., which we suppress for simplicity of writing, is recipro-
cal time. If t is measured in years then A. has the dimension of reciprocal 
years, and if t is measured in minutes, then A. has the dimension of recipro-
cal minutes. The half-lives of many substances have been determined and 
recorded. For example, the half-life of carbon-14 is 5568 years and the 
half-life of uranium-238 is 4.5 billion years. 
</p>
<p>Now the basis of "radioactive dating" is essentially the following. From 
Equation (2) we can solve for t- t0 = 1 lA. In( N ol N ). If t0 is the time the 
substance was initially formed or manufactured, then the age of the sub-
stance is liA.ln(N01 N). The decay constant A. is known or can be com-
puted, in most instances. Moreover, we can usually evaluate N quite easily. 
Thus, if we knew N 0 we could determine the age of the substance. But this 
is the real difficulty of course, since we usually do not know N 0. In some 
instances though, we can either determine N 0 indirectly, or eise determine 
certain suitable ranges for N0 , and such is the case for the forgeries of Van 
Meegeren. 
</p>
<p>We begin with the following well-known facts of elementary chemistry. 
Almost all rocks in the earth's crust contain a small quantity of uranium. 
The uranium in the rock decays to another radioactive element, and that 
one decays to another and another, and so forth (see Figure 1) in a series 
of elements that results in lead, which is not radioactive. The uranium 
(whose half-life is over four billion years) keeps feeding the elements 
following it in the series, so that as fast as they decay, they are replaced by 
the elements before them. 
</p>
<p>Now, all paintings contain a small amount of the radioactive element 
lead-210 e10Pb), and an even smaller amount of radium-226 e26Ra), since 
these elements are contained in white lead (lead oxide), which is a pigment 
that artists have used for over 2000 years. For the analysis which follows, it 
is important to note that white lead is made from lead metal, which, in 
turn, is extracted from a rock called lead ore, in a process called smelting. 
In this process, the lead-210 in the ore goes along with the lead metal. 
However, 90-95% of the radium and its descendants are removed with 
</p>
<p>13 </p>
<p/>
</div>
<div class="page"><p/>
<p>U
ra
</p>
<p>n
iu
</p>
<p>m
-2
</p>
<p>3
8
</p>
<p> 
</p>
<p>4~ 
bi
</p>
<p>ll
io
</p>
<p>n 
</p>
<p>ye
ar
</p>
<p>s T
h
</p>
<p>o
ri
</p>
<p>u
m
</p>
<p>-2
3
</p>
<p>4
 
</p>
<p>U
ra
</p>
<p>n
iu
</p>
<p>m
-2
</p>
<p>3
4
</p>
<p> 
</p>
<p>m
il
</p>
<p>li
on
</p>
<p> y
ea
</p>
<p>rs
 
</p>
<p>T
h
</p>
<p>o
ri
</p>
<p>u
m
</p>
<p>-2
3
</p>
<p>0
 
</p>
<p>8
0
</p>
<p> t
ho
</p>
<p>us
an
</p>
<p>d 
ye
</p>
<p>ar
s 
</p>
<p>R
ad
</p>
<p>iu
m
</p>
<p>-2
2
</p>
<p>6
 
</p>
<p>16
00
</p>
<p> y
ea
</p>
<p>rs
 
</p>
<p>R
ad
</p>
<p>o
n
</p>
<p>-2
2
</p>
<p>2
 
</p>
<p>3 
~ 
</p>
<p>da
ys
</p>
<p> 
</p>
<p>P
o
</p>
<p>lo
n
</p>
<p>iu
m
</p>
<p>-2
1
</p>
<p>8
 
</p>
<p>3 
m
</p>
<p>in
u
</p>
<p>te
s 
</p>
<p>L
ea
</p>
<p>d
-2
</p>
<p>1
4
</p>
<p> 
</p>
<p>P
o
</p>
<p>lo
n
</p>
<p>iu
m
</p>
<p>-2
1
</p>
<p>4
 
</p>
<p>le
ss
</p>
<p> 
th
</p>
<p>an
 
</p>
<p>on
e 
</p>
<p>se
co
</p>
<p>nd
 
</p>
<p>L
ea
</p>
<p>d
-2
</p>
<p>1
0
</p>
<p> 
</p>
<p>F
ig
</p>
<p>u
re
</p>
<p> I
. 
</p>
<p>T
h
</p>
<p>e 
U
</p>
<p>ra
n
</p>
<p>iu
m
</p>
<p> s
er
</p>
<p>ie
s.
</p>
<p> (
T
</p>
<p>h
e 
</p>
<p>ti
m
</p>
<p>es
 s
</p>
<p>h
o
</p>
<p>w
n
</p>
<p>o
n
</p>
<p> t
h
</p>
<p>e 
a
rr
</p>
<p>o
w
</p>
<p>s 
a
re
</p>
<p> t
h
</p>
<p>e 
h
</p>
<p>a
lf
</p>
<p>-l
iv
</p>
<p>es
 o
</p>
<p>f 
e
a
</p>
<p>c
h
</p>
<p> s
te
</p>
<p>p
.)
</p>
<p> 
</p>
<p>P
ol
</p>
<p>on
iu
</p>
<p>m
-2
</p>
<p>1 
0 
</p>
<p>13
8 
</p>
<p>da
ys
</p>
<p> 
</p>
<p>L
ea
</p>
<p>d
-2
</p>
<p>0
6
</p>
<p> 
</p>
<p>(N
ot
</p>
<p> R
ad
</p>
<p>io
ac
</p>
<p>ti
ve
</p>
<p>) </p>
<p/>
</div>
<div class="page"><p/>
<p>1.3 The V an Meergeren art forgeries 
</p>
<p>other waste products in a material called slag. Thus, most of the supply of 
lead-210 is cut off and it begins to decay very rapidly, with a half-life of 22 
years. This process continues until the lead-210 in the white lead is once 
more in radioactive equilibrium with the small amount of radium present, 
i.e. the disintegration of the lead-210 is exactly balanced by the disintegra-
tion of the radium. 
</p>
<p>Let us now use this information to compute the amount of lead-210 pre-
sent in a sample in terms of the amount originally present at the time of 
manufacture. Let y(t) be the amount of lead-210 per gram of white lead 
at time t, y0 the amount of lead-210 per gram of white lead present at 
the time of manufacture t0 , and r(t) the number of disintegrations of 
radium-226 per minute pergram of white Iead, at time t. If "Ais the decay 
constant for lead-210, then 
</p>
<p>dy 
dt = -l\y + r(t), (4) 
</p>
<p>Since we are only interested in a time period of at most 300 years we may 
assume that the radium-226, whose half-life is 1600 years, remains con-
stant, so that r(t) is a constant r. Multiplying both sides of the differential 
equation by the integrating factor p.( t) = eM we obtain that 
</p>
<p>Hence 
</p>
<p>or 
</p>
<p>.!}_ eA.y = reA.1 
dt 
</p>
<p>{5) 
</p>
<p>Now y(t) and r can be easily measured. Thus, if we knew y 0 we could 
use Equation (5) to compute ( t- t0) and consequently, we could determine 
the age of the painting. As we pointed out, though, we cannot measure y 0 
directly. One possible way out of this difficulty is to use the fact that the 
original quantity of lead-210 was in radioactive equilibrium with the larger 
amount of radium-226 in the ore from which the metal was extracted. Let 
us, therefore, take samples of different ores and count the number of disin-
tegrations of the radium-226 in the ores. This was done for a variety of 
ores and the results are given in Table 1 below. These numbers vary from 
0.18 to 140. Consequently, the number of disintegrations of the lead-210 
per minute per gram of white Iead at the time of manufacture will vary 
from 0.18 to 140. This implies thaty0 will also vary over a very large inter-
val, since the number of disintegrations of lead-210 is proportional to the 
amount present. Thus, we cannot use Equation (5) to obtain an accurate, 
or even a crude estimate, of the age of a painting. 
</p>
<p>15 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>Table l. Ore and ore concentrate samples. All disintegration rates 
are per gram of white lead. 
</p>
<p>Description and Source 
</p>
<p>Ore concentrate 
Crushed raw ore 
Ore concentrate 
Ore concentrate 
Ore concentrate 
Ore concentrate 
Ore concentrate 
Ore concentrate 
Ore concentrate 
Ore concentrate 
</p>
<p>(Oklahoma-Kansas) 
(S.E. Missouri) 
(S.E. Missouri) 
(ldaho) 
(ldaho) 
(Washington) 
(British Columbia) 
(British Columbia) 
(Bolivia) 
(Australia) 
</p>
<p>Disintegrations per minute of 226Ra 
</p>
<p>4.5 
2.4 
0.7 
2.2 
0.18 
</p>
<p>140.0 
1.9 
0.4 
1.6 
1.1 
</p>
<p>However, we can still use Equation (5) to distinguish between a 17th 
century painting and a modern forgery. The basis for this statement is the 
simple observation that if the paint is very old compared to the 22 year 
half-life of Iead, then the amount of radioactivity from the lead-210 in the 
paint will be nearly equal to the amount of radioactivity from the radium 
in the paint. On the other band, if the painting is modern (approximately 
20 years old, or so) then the amount of radioactivity from the lead-210 will 
be much greater than the amount of radioactivity from the radium. 
</p>
<p>We make this argument precise in the following manner. Let us assume 
that the painting in question is- either very new or about 300 years old. Set 
t- t0 = 300 years in (5). Then, after some simple algebra, we see that 
</p>
<p>\y0 = ;\y ( t)e300"- r( e300"- 1 ). (6) 
</p>
<p>If the painting is indeed a modern forgery, then ;\y0 will be absurdly 
!arge. Todetermine what is an absurdly high disintegrationrate we observe 
(see Exercise 1) that if the lead-210 decayed originally (at the time of 
manufacture) at the rate of 100 disintegrations per minute per gram of 
white Iead, then the ore from which it was extracted had a uranium con-
tent of approximately 0.014 per cent. This is a fairly high concentration of 
uranium since the average amount of uranium in rocks of the earth's crust 
is about 2.7 parts per million. On the other hand, there are some very rare 
ores in the Western Hemisphere whose uranium content is 2-3 per cent. To 
be on the safe side, we will say that a disintegration rate of lead-210 is cer-
tainly absurd if it exceeds 30,000 disintegrations per minute per gram of 
white Iead. 
</p>
<p>To eva1uate ;\y0 , we must eva1uate the present disintegration rate, ;\y(t), 
of the lead-210, the disintegrationrate r of the radium-226, and e300". Since 
the disintegrationrate of polonium-210 e10Po) equals that of lead-210 after 
several years, and since it is easier to measure the disintegration rate of 
polonium-210, we substitute these values for those of lead-210. To compute 
</p>
<p>16 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.3 The V an Meergeren art forgeries 
</p>
<p>e300\ we observe from (3) that A =(In 2 /22). Hence 
</p>
<p>e300A = e&lt;300/22)1n2 = 2(150/11&gt;. 
</p>
<p>The disintegration rates of polonium-210 and radium-226 were measured 
for the "Disciples at Emmaus" and various other alleged forgeries and are 
given in Table 2 below. 
</p>
<p>Table 2. Paintings of questioned authorship. All disintegration 
rates are per minute, pergram of white Iead. 
</p>
<p>Description 
</p>
<p>"Disciples at Emmaus" 
"Washing of Feet" 
"Woman Reading Music" 
"Woman Playing Mandolin" 
"Lace Maker" 
"Laughing Girl" 
</p>
<p>210Po disintegration 
</p>
<p>8.5 
12.6 
10.3 
8.2 
1.5 
5.2 
</p>
<p>226Ra disintegration 
</p>
<p>0.8 
0.26 
0.3 
0.17 
1.4 
6.0 
</p>
<p>If we now evaluate Xy0 from (6) for the white Iead in the painting "Disci-
ples at Emmaus" we obtain that 
</p>
<p>Xyo=( 8.5)21so;11 _ 0_8(2 1so;11 -I) 
</p>
<p>=98,050 
</p>
<p>which is unacceptably !arge. Thus, this painting must be a modern forgery. 
By a similar analysis, (see Exercises 2-4) the paintings "Washing of Feet", 
"Woman Reading Music" and "Woman Playing Mandolin" were indisput-
ably shown tobe faked Vermeers. On the other band, the paintings "Lace 
Maker" and "Laughing Girl" cannot be recently forged Vermeers, as 
claimed by some experts, since for these two paintings, the polonium-210 is 
very nearly in radioactive equilibrium with the radium-226, and no such 
equilibrium has been observed in any samples from 19th or 20th century 
paintings. 
</p>
<p>References 
</p>
<p>Coremans, P., Van Meegeren's Faked Vermeers and Oe Hooghs, Meulenhoff, 
Amsterdam, 1949. 
</p>
<p>Keisch, 8., Feiler, R. L., Levine, A. S., Edwards, P. R., Dating and Authenticating 
Works of Art by Measurement of Natural Alpha Emitters, Science (155), 
1238-1241. March 1967. 
</p>
<p>Keisch, 8., Dating Works of Art through Their Natural Radioactivity: Improve-
ments and Applications, Science, 160, 413-415, April 1968. 
</p>
<p>17 </p>
<p/>
</div>
<div class="page"><p/>
<p>First-order differential equations 
</p>
<p>EXERCISES 
</p>
<p>1. In this exercise we show how to compute the concentration of uranium in an 
ore from the dpmj(g of Pb) of the lead-210 in the ore. 
(a) The half-life of uranium-238 is 4.51 x 109 years. Since this half-life is so 
</p>
<p>large, we may assume that the amount of uranium in the ore is constant 
over a period of two to three hundred years. Let N (t) denote the number of 
atoms of 238U per gram of ordinary lead in the ore at time t. Since the 
lead-21 0 is in radioactive equilibrium with the uranium-238 in the ore, we 
know that dN j dt= -"AN= -100 dpm/g of Pb at time t0. Show that there 
are 3.42 X 1017 atoms of uranium-238 per gram of ordinary lead in the ore 
at time t0. (Hint: 1 year=525,600 minutes.) 
</p>
<p>(b) Using the fact that one mole of uranium-238 weighs 238 grams, and that 
there are 6.02 X 1023 atoms in a mole, show that the concentration of 
uranium in the ore is approximately 0.014 percent. 
</p>
<p>For each of the paintings 2, 3, and 4 use the data in Table 2 to compute 
the disintegrations per minute of the original amount of lead-210 pergram 
of white Iead, and conclude that each of these paintings is a forged 
Vermeer. 
</p>
<p>2. "W ashing of Feet" 
</p>
<p>3. "Woman Reading Music" 
</p>
<p>4. "Woman Playing Mandolin" 
</p>
<p>5. The following problern describes a very accurate derivation of the age of 
uranium. 
(a) Let N 238(t) and N 235(t) denote the number of atoms of 238U and 235 U at 
</p>
<p>time t in a given sample of uranium, and let t = 0 be the time this sample 
was created. By the radioactive decay 1aw, 
</p>
<p>d N (t)- -ln2 N (t) 
dt 238 - ( 4.5) 109 238 ' 
</p>
<p>d -ln2 
-d N235 (t)= 9 N235 (t). 
</p>
<p>t 0.707(10) 
</p>
<p>Solve these equations for N 238(t) and N 235(t) in terms of their original num-
bers N 238(0) and N 235(0). 
</p>
<p>(b) In 1946 the ratio of 238Uj235U in any sample was 137.8. Assuming that 
equal amounts of 238U and 235U appeared in any sample at the time of its 
creation, show that the age of uranium is 5.96 X 109 years. This figure is 
universally accepted as the age of uranium. 
</p>
<p>6. In a samarskite sample discovered recently, there was 3 grams of Thorium 
( 232TH). Thorium decays to lead-208 e08Pb) through the reaction 232 Th~ 208 Pb 
+6(4 4He). It was determined that 0.0376 of a gram of lead-208 was produced 
by the disintegration of the original Thorium in the sample. Given that the 
</p>
<p>18 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.3 The Van Meergerenart forgeries 
</p>
<p>half-life of Thorium is 13.9 billion years, derive the age of this samarskite sam-
ple. (Hint: 0.0376 grams of 208Pb is the product of the decay of (232/208) X 
0.0376 grams of Thorium.) 
</p>
<p>One of the most accurate ways of dating archaeological finds is the method 
of carbon-14 ct4C) dating discovered byWillard Libby around 1949. The basis 
of this method is delightfully simple: The atmosphere of the earth is continu-
ously bombarded by cosmic rays. These cosmic rays produce neutrons in the 
earth's atmosphere, and these neutrons combine with nitrogen to produce 14C, 
which is usually called radiocarbon, since it decays radioactively. Now, this ra-
diocarbon is incorporated in carbon dioxide and thus moves through the atmo-
sphere to be absorbed by plants. Animals, in turn, build radiocarbon into their 
tissues by eating the plants. In living tissue, the rate of ingestion of 14C exactly 
balances the rate of disintegration of 14C. When an organism dies, though. it 
ceases to ingest carbon-14 and thus its 14C concentration begins to decrease 
through disintegration of the 14C present. Now, it is a fundamental assumption 
of physics that the rate of bombardment of the earth's atmosphere by cosmic 
rays has always been constant. This implies that the original rate of disintegra-
tion of the 14C in a sample such as charcoal is the same as the rate measured 
today.* This assumption enables us to determine the age of a sample of char-
coal. Let N ( t) denote the amount of carbon-14 present in a sample at time t, 
and N 0 the amount present at time t = 0 when the sample was formed. If A de-
notes the decay constant of 14C (the half-life of carbon-14 is 5568 years) then 
dN (t)/ dt =-AN (t), N (0)= N 0 . Consequently, N (t)= N 0e-Jo.'. Now the present 
rate R ( t) of disintegration of the 14C in the sample is given by R (t) =AN ( t) = 
AN0e-Jo.t and the original rate of disintegration is R(O)=AN0. Thus, R(t)/ R(O) 
=e-Jo.t so that t=(l/A)ln[R(O)/ R(t)). Hence if we measure R(t), the present 
rate of disintegration of the 14C in the charcoal, and observe that R (0) must 
equal the rate of disintegration of the 14C in a comparable amount of living 
wood, then we can compute the age t of the charcoal. The following two prob-
lems are reallife illustrations of this method. 
</p>
<p>7. Charcoal from the occupation Ievel of the famous Lascaux Cave in France 
gave an average count in 1950 of 0.97 disintegrations per minute per gram. 
Living wood gave 6.68 disintegrations. Estimate the date of occupation and 
hence the probable date of the remarkable paintings in the Lascaux Cave. 
</p>
<p>8. In the 1950 excavation at Nippur, a city of Babylonia. charcoal from a roof 
beam gave a count of 4.09 disintegrations per minute per gram. Living wood 
gave 6.68 disintegrations. Assuming that this charcoal was formed during the 
time of Hammurabi's reign, find an estimate for the likely time of Hamurabi's 
succession. 
</p>
<p>*Since the mid 1950's the testing of nuclear weapons has significantly increased the amount of 
radioactive carbon in our atmosphere. Ironically this unfortunate state of affairs provides us 
with yet another extremely powerful method of detecting art forgeries. To wit, many artists' 
materials, such as linseed oil and canvas paper, come from plants and animals, and so will 
contain the same concentration of carbon-14 as the atmosphere at the time the plant or 
animal dies. Thus linseed oil (which is derived from the flax plant) that was produced during 
the last few years will contain a much greater concentration of carbon-14 than linseed oil pro-
duced before 1950. 
</p>
<p>19 </p>
<p/>
</div>
<div class="page"><p/>
<p>I First-order differential equations 
</p>
<p>1.4 Separable equations 
</p>
<p>We solved the first-order linear homogeneaus equation 
</p>
<p>dy 
dt + a(t)y =0 (1) 
</p>
<p>by dividing both sides of the equation by y(t) to obtain the equivalent 
equation 
</p>
<p>1 dy ( t) 
y(t) --;Jt =- a(t) 
</p>
<p>and observing that Equation (2) can be written in the form 
</p>
<p>d 
dtlnly(t)l= -a(t). 
</p>
<p>(2) 
</p>
<p>(3) 
</p>
<p>We then found lnly(t)l, and consequently y(t), by integrating both sides of 
(3). In an exactly analogous manner, we can solve the more general dif-
ferential equation 
</p>
<p>(4) 
</p>
<p>where fand g are continuous functions of y and t. This equation, and any 
other equation which can be put into this form, is said to be separable. To 
solve (4), we first multiply both sides by f(y) to obtain the equivalent 
equation 
</p>
<p>dy 
J(y) dt =g(t). 
</p>
<p>Then, we observe that (5) can be written in the form 
</p>
<p>d 
dt F ( y ( t)) = g ( t) 
</p>
<p>(5) 
</p>
<p>(6) 
</p>
<p>where F(y) is any anti-derivative of f(y); i.e., F(y) = J f(y)dy. Conse-
quently, 
</p>
<p>F(y(t))= J g(t)dt+c (7) 
where c is an arbitrary constant of integration, and we solve for y = y(t) 
from (7) to find the general solution of (4). 
</p>
<p>Example 1. Find the general solution of the equation dy I dt = t2 1 y 2. 
Solution. Multiplying both sides of this equation by y 2 gives 
</p>
<p>dy d y3(t) 
y2-=t2 or ---=t2. 
</p>
<p>dt ' dt 3 
</p>
<p>Hence,y3(t)=t3 +c where c is an arbitrary constant, andy(t)=(t3 +c)113&bull; 
</p>
<p>20 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.4 Separable equations 
</p>
<p>Example 2. Find the general solution of the equation 
</p>
<p>eYdr -t-t3 =0. 
</p>
<p>Solution. This equation can be written in the form 
</p>
<p>.!}__ eY(I) = t + t3 
dt 
</p>
<p>and thus eY(t) =t212+t414+c. Taking logarithms of both sides of this 
equation gives y ( t) = ln( t2 12 + t 4 I 4 + c ). 
</p>
<p>In addition to the differential equation (4), we will often impose an ini-
tial condition on y ( t) of the form y ( t0) = y 0. The differential equation ( 4) 
together with the initial conditiony(t0)=y0 is called an initial-value prob-
lern. We can solve an initial-value problern two different ways. Either we 
use the initial condition y ( t0) = y 0 to solve for the constant c in (7), or else 
we integrate both sides or (6) between t0 and t to obtain that 
</p>
<p>F(y(t))- F(y 0 )= J1 g(s)ds. 
to 
</p>
<p>(8) 
</p>
<p>If we now observe that 
</p>
<p>F(y)- F(y0 )= JY j(r)dr, 
Yo 
</p>
<p>(9) 
</p>
<p>then we can rewrite (8) in the simpler form 
</p>
<p>fy J(r)dr= r g(s)ds. 
Yo to 
</p>
<p>(10) 
</p>
<p>Example 3. Find the solution y(t) of the initial-value problern 
</p>
<p>dy 
eY- - ( t + t 3) = 0 dt , y(1)= 1. 
</p>
<p>Solution. Method (i). From Example 2, we know that the generat solution 
of this equation isy=ln(t212+t414+c). Setting t=l andy=1 gives 1= 
ln(3l4+c), or c=e-314. Hence,y(t)=1n(e-314+t 212+t414). 
Method (ii). From (10), 
</p>
<p>Consequently, 
</p>
<p>/2 t4 1 1 
eY- e= 2 + 4-2-4, and y(t)=ln(e-314+ t212+ t4l4). 
</p>
<p>Example 4. Solve the initial-value problern dy 1 dt = 1 + y 2, y(O) = 0. 
Solution. Divide both sides of the differential equation by 1 + y 2 to obtain 
</p>
<p>21 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>the equivalent equation 1 I (I + y 2)dy I dt = I. Then, from (I 0) 
</p>
<p>l y ~= (ds 
0 I+ r 2 Jo &middot; 
</p>
<p>Consequently, arctany = t, and y = tant. 
The solution y = tan t of the above problern has the disturbing property 
</p>
<p>that it goes to &plusmn; oo at t = &plusmn; '7T 12. And what's even more disturbing is the 
fact that there is nothing at all in this initial-value problern which even 
hints to us that there is any trouble at t = &plusmn; '7T 12. The sad fact of life is that 
solutions of perfectly nice differential equations can go to infinity in finite 
time. Thus, solutions will usually exist only on a finite open interval a &lt; t &lt; 
b, rather than for all time. Moreover, as the following example shows, dif-
ferent solutions of the same differential equation usually go to infinity at 
different times. 
</p>
<p>Example 5. Solve the initial-value problern dy I dt = I+ y 2, y(O) = 1. 
Solution. From (10) 
</p>
<p>--= ds f y dr 11 
1 I+ r 2 o &middot; 
</p>
<p>Consequently, arc tany- arc tan I= t, and y = tan(t + '7T 14). This solution 
exists on the open interval - 3'7T I 4 &lt; t &lt; '7T I 4. 
</p>
<p>Example 6. Find the solution y(t) of the initial-va1ue problern 
</p>
<p>dy . 
y dt +(l+y2)smt=O, y(O)=l. 
</p>
<p>Solution. Dividing both sides of the differential equation by 1 + y 2 gives 
</p>
<p>Consequently, 
</p>
<p>so that 
</p>
<p>y dy . 
---=-smt. 
1 + y 2 dt 
</p>
<p>-- = - sinsds, f y rdr 11 
1 1 + r2 o 
</p>
<p>iln(l + y 2)- iln2= cost -1. 
</p>
<p>Solving this equation for y(t) gives 
</p>
<p>y ( t) = &plusmn; (2e -4sin2t/2- 1) 1/2. 
</p>
<p>To determine whether we take the plus or minus branch of the square root, 
we note that y (0) is positive. Hence, 
</p>
<p>y(t)=(2e-4sin2t/2_1)1/2 
</p>
<p>22 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.4 Separable equations 
</p>
<p>This solution is only defined when 
</p>
<p>2e -4sin2 t/2;;;. 1 
</p>
<p>or 
</p>
<p>(li) 
</p>
<p>Since the logarithm function is monotonic increasing, we may take loga-
rithms of both sides of (II) and still preserve the inequality. Thus, 4sin2 tl2 
&lt; In2, which implies that 
</p>
<p>I I I&lt; arcsin YI~2 
Therefore, y(t) only exists on the open interval (- a,a) where 
</p>
<p>a =2arcsin[ vTn2 12]. 
Now, this appears to be a new difficulty associated with nonlinear equa-
tions, since y ( t) just "disappears" at t = &plusmn; a, without going to infinity. 
However, this apparent difficulty can be explained quite easily, and more-
over, can even be anticipated, if we rewrite the differential equation above 
in the standard form 
</p>
<p>dy (I+ y 2)sint 
dt =- y 
</p>
<p>Notice that this differential equation is not defined when y = 0. Therefore, 
if a solution y ( t) achieves the value zero at some time t = t*, then we 
cannot expect it to be defined for t &gt; t*. This is exactly what happens here, 
since y( &plusmn; a) = 0. 
</p>
<p>Example 7. Solve the initial-value problern dy I dt =(I+ y)t, y(O) =-I. 
Solution. In this case, we cannot divide both sides of the differential equa-
tion by I+ y, since y(O)= -1. However, it is easily seen that y(t)= -1 is 
one solution of this initial-value problern, and in Section 1.10 we show that 
it is the only solution. More generally, consider the initial-value problern 
dyldt=f(y)g(t), y(t0)=y0 , where f(y 0)=0. Certainly, y(t)=y0 is one 
solution of this initial-value problern, and in Section 1.10 we show that it is 
the only Solution if of I oy exists and is continuous. 
</p>
<p>Example 8. Solve the initial-value problern 
</p>
<p>( 1 + eY )dy / dt = cos t, 
</p>
<p>Solution. Frorn (10), 
</p>
<p>y(I'TI2)=3. 
</p>
<p>l Y (I+ e')dr= [ cossds 
3 '11/2 
</p>
<p>so thaty + eY = 2 + e3 + sint. This equation cannot be solved explicitly for y 
</p>
<p>23 </p>
<p/>
</div>
<div class="page"><p/>
<p>I First-order differential equations 
</p>
<p>as a function of t. Indeed, most separable equations cannot be solved ex-
plicitly for y as a function of t. Thus, when we say that 
</p>
<p>y + eY = 2 + e3 + sin t 
</p>
<p>is the solution of this initial-value problem, we really mean that it is an im-
plicit, rather than an explicit solution. This does not present us with any 
difficulties in applications, since we can always find y(t) numerically with 
the aid of a digital computer (see Section 1.11 ). 
</p>
<p>Example 9. Find all solutions of the differential equation dy I dt = - t I y. 
Solution. Multiplying both sides of the differential equation by y gives 
ydyldt= -t. Hence 
</p>
<p>(12) 
</p>
<p>Now, the curves (12) are closed, and we cannot solve for y as a single-val-
ued function of t. The reason for this difficulty, of course, is that the dif-
ferential equation is not defined wheny = 0. Nevertheless, the circles t2 + y 2 
= c2 are perfectly weil defined, even when y = 0. Thus, we will call the 
circles t2 + y 2 = c2 so/ution curves of the differential equation 
</p>
<p>dy I dt = - t 1 y. 
</p>
<p>More generally, we will say that any curve defined by (7) is a solution 
curve of (4). 
</p>
<p>EXERCISES 
</p>
<p>In each of Problems 1-5, find the general solution of the given differential 
equation. 
</p>
<p>2 dy _ 2 . &bull; _ tanx+tany 
1. (l+t )-d -l+y. Hmt. tan(x+y)- 1 t t . t - anx any 
</p>
<p>dy 
2. dt =(l+t)(l+y) 
</p>
<p>dy 2 2 
3. dt = I - t + y - ty 
</p>
<p>dy 
4. dt = e'+y+3 5 
</p>
<p>0 dy 0 
. cosysmt dt =smycost 
</p>
<p>In each of Problems 6-12, solve the given initial-value problem, and de-
termine the interval of existence of each solution. 
</p>
<p>dy 
6. t2(1+y 2)+2y dt =0, y(O)=l 
</p>
<p>7 dy = _2_t- y(2)=3 
&bull; dt y + yt2' 
</p>
<p>24 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.4 Separable equations 
</p>
<p>S. (l+t2)I/2: =ty3(l+t2)-112, y(O)=l 
</p>
<p>9 dy = 3t2+4t+2 
' dt 2(y-l) ' y(O)= -l 
</p>
<p>dy - tsiny 
10. cosy dt = 1+ 12 , y(l) = '1T 12 
</p>
<p>dy 
11. dt =k(a-y)(b-y), y(O)=O, a,b&gt;O 
</p>
<p>dy 
12. 3t dt = ycost, y(l)=O 
</p>
<p>13. Any differential equation of the form dy I dt = f(y) is separable. Thus, we can 
solve all those first-order differential equations in which time does not appear 
explicitly. Now, suppose we have a differential equation of the form dy I dt = 
f(y I t), such as, for example, the equation dy I dt = sin(y I t). Differential equa-
tions of this form are called homogeneaus equations. Since the right-hand side 
only depends on the single variable y I t, it suggests itself to make the Substitu-
tion y I t = v or y = tv. 
(a) Show that this substitution replaces the equation dy I dt = f(y I t) by the 
</p>
<p>equivalent equation t dv I dt + v = f( v), which is separable. 
(b) Find the general solution of the equation dy I dt = 2(y I t) + (y I tf, 
</p>
<p>14. Determine whether each of the following functions of t and y can be expressed 
as a function of the single variable y I t. 
</p>
<p>y2+2ty y3+ /3 
(a) (b) 
</p>
<p>y2 yt2+ y3 
</p>
<p>(e) 
et+y 
</p>
<p>. t+y 
(g) sm-
</p>
<p>t-y 
</p>
<p>t+y 
(d) lnx-lnt+ --. {- y 
</p>
<p>(f) ln\lt+Y -lnVt-y 
</p>
<p>15. Solve the initial-value problern t(dy I dt)= y + w+-? . y(l)=O. 
Find the general solution of the following differential equations. 
</p>
<p>dy 
16. 2ty dt = 3y 2 - t 2 
</p>
<p>dy t+y 
18. dt =-t-y 
</p>
<p>dy 
19. etiY(y-t)-+y(I+etiY)=Q 
</p>
<p>dt 
</p>
<p>[ Hint: J _to-l dv=ln(l+toe 11")] t:e 1/c + v2 
</p>
<p>25 </p>
<p/>
</div>
<div class="page"><p/>
<p>I First-order differential equations 
</p>
<p>20. Consider the differential equation 
</p>
<p>dy t+y+I 
dt = t- y + 3. (*) 
</p>
<p>We could solve this equation if the constants and 3 were not present. To 
eliminate these constants, we make the Substitution t = T + h, y = Y + k. 
(a) Determine h and k so that (*) can be written in the form dY I dT = 
</p>
<p>(T + Y)j(T- Y). 
(b) Find the general solution of (*). (See Exercise 18). 
</p>
<p>21. (a) Prove that the differential equation 
</p>
<p>dy at+by+ m 
</p>
<p>dt = ct+dy+ n 
</p>
<p>where a, b, c, d, m, and n are constants, can always be reduced to dy I dt = 
( at + by) / ( ct + dy) if ad- bc =!= 0. 
</p>
<p>(b) Solve the above equation in the special case that ad= bc. 
</p>
<p>Find the general solution of the following equations. 
</p>
<p>22. (l+t-2y)+(4t-3y-6)dyldt=O 
</p>
<p>23. (t+2y+3)+(2t+4y-i)dyldt=O 
</p>
<p>1.5 Population models 
</p>
<p>In this section we will study first-order differential equations which govern 
the growth of various species. At first glance it would seem impossible to 
model the growth of a species by a differential equation since the popula-
tion of any species always changes by integer amounts. Hence the popula-
tion of any species can never be a differentiable function of time. How-
ever, if a given population is very !arge and it is suddenly increased by one, 
then the change is very small compared to the given population. Thus, we 
make the approximation that !arge populations change continuously and 
even differentiably with time. 
</p>
<p>Letp(t) denote the population of a given species at timet and Iet r(t,p) 
denote the difference between its birth rate and its death rate. If this 
population is isolated, that is, there is no net immigration or emigration, 
then dp / dt, the rate of change of the population, equals rp(t). In the most 
simplistic model we assume that r is constant, that is, it does not change 
with either time or population. Then, we can write down the following dif-
ferential equation governing population growth: 
</p>
<p>dp(t) 
----;Jt = ap ( t), a = constant. 
</p>
<p>26 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.5 Population models 
</p>
<p>This is a linear equation and is known as the Malthusian law of population 
growth. If the population of the given species is p 0 at time t0, then p(t) 
satisfies the initial-value problern dp(t)/ dt = ap(t), p(t0) = p 0&bull; The solution 
of this initial-value problern is p(t) = p 0ea(t-tol. Hence any species satisfying 
the Malthusian law of population growth grows exponentially with time. 
</p>
<p>Now, we have just formulated a very simple model for population 
growth; so simple, in fact, that we have been able to solve it completely in a 
few lines. lt is important, therefore, to see if this model, with its simplicity, 
has any relationship at all with reality. Let p(t) denote the human popula-
tion of the earth at time t. lt was estimated that the earth's human 
population was increasing at an average rate of 2% per year during the 
period 1960-1970. Let us start in the middle of this decade on January 1, 
1965, at which time the U.S. Department of Commerce estimated the earth's 
population to be 3.34 billion people. Then, t 0 = 1965, p0 = 3.34X 109 and 
a = .02, so that 
</p>
<p>p(t) = (3.34)l09e.02(t-I965). 
</p>
<p>One way of checking the accuracy of this formula is to compute the time 
required for the population of the earth to double, and then compare it to 
the observed value of 35 years. Our formula predicts that the population of 
the earth will double every T years, where 
</p>
<p>e.o2r = 2. 
</p>
<p>Taking logarithms of both sides of this equation gives .02T= ln2, so that 
</p>
<p>T= 501n2 ~ 34.6 years. 
</p>
<p>This is in excellent agreement with the observed value. On the other hand, 
though, Iet us Iook into the distant future. Our equation predicts that the 
earth's populationwill be 200,000 billion in the year 2515, 1,800,000 billion 
in the year 2625, and 3,600,000 billion in the year 2660. These are astro-
nomical numbers whose significance is difficult to gauge. The total surface 
ofthisplanet is approximately 1,860,000 billion square feet. Eighty percent 
of this surface is covered by water. Assuming that we are willing to live on 
boats as well as land, it is easy to see that by the year 2515 there will be only 
9.3 square feet per person; by 2625 each person will have only one square 
foot on which to stand; and by 2660 we will be standing two deep on each 
other's shoulders. 
</p>
<p>lt would seem therefore, that this model is unreasonable and should be 
thrown out. However, we cannot ignore the fact that it offers exceptional 
agreement in the past. Moreover, wehaveadditional evidence that popula-
tions do grow exponentially. Consider the Microtus Arvallis Pali, a small 
rodent which reproduces very rapidly. We take the unit of time to be a 
month, and assume that the population is increasing at the rate of 40% per 
</p>
<p>27 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>month. If there are two rodents present initially at time t=O, thenp(t), the 
number of rodents at time t, satisfies the initial-value problern 
</p>
<p>dp(t)/ dt=0.4p, p(0)=2. 
</p>
<p>Consequently, 
</p>
<p>p ( t) = 2e0.4t. (1) 
</p>
<p>Table 1 compares the observed population with the population calculated 
from Equation (1). 
</p>
<p>Table 1. The growth of Microtus Arvallis Pall. 
</p>
<p>Months 0 2 6 10 
</p>
<p>p Observed 2 5 20 109 
p Calculated 2 4.5 22 109.1 
</p>
<p>As one can see, there is excellent agreement. 
</p>
<p>Remark. In the case of the Microtus Arvallis Pall, p observed is very ac-
curate since the pregnancy period is three weeks and the time required for 
the census taking is considerably less. If the pregnancy period were very 
short then p observed could not be accurate since many of the pregnant ro-
dents would have given birth before the census was completed. 
</p>
<p>The way out of our dilemma is to observe that linear models for popula-
tion growth are satisfactory as long as the population is not too large. 
When the population gets extremely large though, these models cannot be 
very accurate, since they do not reflect the fact that individual members 
are now competing with each other for the limited living space, natural re-
sources and food available. Thus, we must add a competition term to our 
linear differential equation. A suitable choice of a competition term is 
- bp 2, where b is a constant, since the statistical average of the number of 
encounters of two members per unit time is proportional to p 2&bull; We con-
sider, therefore, the modified equation 
</p>
<p>dp 2 
dt =ap-bp. 
</p>
<p>This equation is known as the logistic law of population growth and the 
numbers a, b are called the vital coefficients of the population. It was first 
introduced in 1837 by the Dutch mathematical-biologist Verhulst. Now, 
the constant b, in general, will be very small compared to a, so that if p is 
not too large then the term - bp 2 will be negligible compared to ap and the 
</p>
<p>28 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.5 Population models 
</p>
<p>population will grow exponentially. However, when p is very large, the 
term - bp2 is no Ionger negligible, and thus serves to slow down the rapid 
rate of increase of the population. Needless to say, the more industrialized 
a nation is, the more living space it has, and the more food it has, the 
smaller the coefficient b is. 
</p>
<p>Let us now use the logistic equation to predict the future growth of an 
isolated popula tion. If p 0 is the population at time t0, then p (t), the popula-
tion at time t, satisfies the initial-value problern 
</p>
<p>dp 2 
dt = ap- bp , p (to) =Po&middot; 
</p>
<p>This is a separable differential equation, and from Equation (10), Section 
1.4, 
</p>
<p>f P dr 2 = J'ds=t-to. 
Po ar- br t0 
</p>
<p>To integrate the function ll(ar- br2) we resort to partial fractions. Let 
</p>
<p>1 1 =A +-B-
ar-br2 r(a-br) r a-br' 
</p>
<p>To find A and B, observe that 
</p>
<p>A B A(a-br)+Br Aa+(B-bA)r 
-+--= =------
r a-br r(a-br) r(a-br) &middot; 
</p>
<p>Therefore, Aa + (B- bA)r= 1. Since this equation is true for all values of r, 
we see that Aa = 1 and B- bA = 0. Consequently, A = 1 I a, B = b I a, and 
</p>
<p>f P dr 1 fP( 1 b ) r(a-br) =-;; ~+ a-br dr 
Po Po 
</p>
<p>=- ln-+ln -- =-ln- ---. 1 [ p I a- bpo I] 1 p I a - bpo I 
a Po a-bp a Po a-bp 
</p>
<p>Thus, 
</p>
<p>p I a- bp0 I a(t- t0)=1n- --b- . 
Po a- 'P 
</p>
<p>Now, it isasimple matter to show (see Exercise I) that 
</p>
<p>is always positive. Hence, 
</p>
<p>a-bp0 
</p>
<p>a- bp(t) 
</p>
<p>p a- bp 
a( t - t0) = ln- b 0 . 
</p>
<p>Po a- 'P 
</p>
<p>(2) 
</p>
<p>29 </p>
<p/>
</div>
<div class="page"><p/>
<p>I First-order differential equations 
</p>
<p>Taking exponentials of both sides of this equation gives 
</p>
<p>P a-bp ea(t-to)=- ___ 0 
Po a- bp ' 
</p>
<p>or 
p0 (a- bp)ea(t-to)= (a- bp0 )p. 
</p>
<p>Bringing all terms involving p to the left-hand side of this equation, we see 
that 
</p>
<p>Consequently, 
</p>
<p>(3) 
</p>
<p>Let us now examine Equation (3) to see what kind of population it pre-
dicts. Observe that as t-'&gt;oo, 
</p>
<p>apo a 
p(t)-'&gt;- =- 0 
</p>
<p>bp0 b 
</p>
<p>Thus, regardless of its initial value, the population always approaches the 
limiting value al b. Next, observe that p(t) is a monotonically increasing 
function of time if 0 &lt;p0 &lt; a I b. Moreover, since 
</p>
<p>d 2p dp dp 
- =a- -2bp- =(a-2bp)p(a-bp) 
dt 2 dt dt , 
</p>
<p>we see that dp I dt is increasing if p(t) &lt; al2b, and that dp I dt is decreasing 
if p(t)&gt;al2b. Hence, if p0 &lt;al2b, the graph of p(t) must have the form 
given in Figure l. Such a curve is called a logistic, or S-shaped curve. 
From its shape we conclude that the time period before the population 
reaches half its limiting value is a period of accelerated growth. After this 
point, the rate of growth decreases and in time reaches zero. This is a 
period of diminishing growth. 
</p>
<p>These predictions are borne out by an experiment on the protozoa 
Paramecium caudatum performed by the mathematical biologist G. F. 
Gause. Five individuals of Paramecium were placed in a small test tube 
containing 0.5 cm3 of a nutritive medium, and for six days the number of 
individuals in every tube was counted daily. The Paramecium were found 
to increase at a rate of 230.9% per day when their numbers were low. The 
number of individuals increased rapidly at first, and then more slowly, un-
til towards the fourth day it attained a .maximum Ievel of 375, saturating 
the test tube. From this data we conclude that if the Paramecium cauda-
tum grow according to the logistic law dp / dt = ap- bp2, then a = 2.309 and 
</p>
<p>30 </p>
<p/>
</div>
<div class="page"><p/>
<p>0 
</p>
<p>b 
</p>
<p>_Q__ 
</p>
<p>2b 
</p>
<p>p 
</p>
<p>1.5 Population models 
</p>
<p>t 
to 
</p>
<p>Figure I. Graph of p(t) 
</p>
<p>b = 2.309/375. Consequently, the logistic law predicts that 
</p>
<p>p ( t) = (2.309)5 ( (2.309)5 ) -2.3091 
375 + 2&middot;309 - 375 e 
</p>
<p>(2.309)5 
</p>
<p>375 
(4) 
</p>
<p>1 +74e-2.309t. 
</p>
<p>(We have taken the initial time t0 to be 0.) Figure 2 compares the graph of 
p(t) predicted by Equation (4) with the actual measurements, which are de-
noted by o. As can be seen, the agreement is remarkably good. 
</p>
<p>In order to apply our results to predict the future human population of 
the earth, we must estimate the vital coefficients a and b in the logistic 
equation governing its growth. Some ecologists have estimated that the na-
tural value of a is 0.029. We also know that the humanpopulationwas in-
creasing at the rate of 2% per year when the population was (3.34) 109&bull; 
Since (ljp)(dpjdt)=a-bp, we see that 
</p>
<p>0.02 =a-b (3.34)109. 
</p>
<p>Consequently, b = 2.695 X 10- 12 &bull; Thus, according to the logistic law of 
population growth, the human population of the earth will tend to the 
limiting value of 
</p>
<p>a 
b 
</p>
<p>0&middot;029 12 = 10.76 billion people 
2.695 x w-
</p>
<p>Note that according to this prediction, we were still on the accelerated 
</p>
<p>31 </p>
<p/>
</div>
<div class="page"><p/>
<p>I First-order differential equations 
</p>
<p>400 
</p>
<p>2 
</p>
<p>Figure 2. The growth of paramecium 
</p>
<p>growth portion of the logistic curve in 1965, since we had not yet attained 
half the limiting population predicted for us. 
</p>
<p>Remark. A student of mine once suggested that we use Equation (3) to find 
the time t at which p( t) = 2, and then we can deduce how 1ong ago mankind 
appeared on earth. On the surface this seems 1ike a fantastic idea. However, 
we cannot trave1 that far backwards into the past, since our model is no 
Ionger accurate when the population is small. 
</p>
<p>As another verification of the validity of the logistic law of population 
growth, we consider the equation 
</p>
<p>197,273,000 
p(t)= 1 + e-o.o3134(t-I9I3.25) (5) 
</p>
<p>which was introduced by Pearl and Reed as a model of the population 
growth of the United States. First, using the census figures for the years 
1790, 1850, and 1910, Pearl and Reed found from (3) (see Exercise 2a) that 
a=0.03J34 and b=(l.5887)10- 10. Then (see Exercise 2b), Pearl and Reed 
calculated that the population of the United States reached half its limiting 
population of ajb= 197,273,000 in April 1913. Consequently (see Exercise 
2c), we can rewrite (3) in the simpler form (5). 
</p>
<p>Table 2 below compares Pearl and Reed's predictions with the observed 
values of the population of the United States. These results are remarkable, 
</p>
<p>32 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.5 Population models 
</p>
<p>Table 2. Population of the U.S. from 1790-1950. (The last 4 entries 
were added by the Dartmouth College Writing Group.) 
</p>
<p>Actual Predicted Error % 
</p>
<p>1790 3,929,000 3,929,000 0 0.0 
</p>
<p>1800 5,308,000 5,336,000 28,000 0.5 
</p>
<p>1810 7,240,000 7,228,000 -12,000 -0.2 
</p>
<p>1820 9,638,000 9,757,000 119,000 1.2 
</p>
<p>1830 12,866,000 13,109,000 243,000 1.9 
</p>
<p>1840 17,069,000 17,506,000 437,000 2.6 
</p>
<p>1850 23,192,000 23,192,000 0 0.0 
</p>
<p>1860 31,443,000 30,412,000 -1,031,000 -3.3 
</p>
<p>1870 38,558,000 39,372,000 814,000 2.1 
</p>
<p>1880 50,156,000 50,177,000 21,000 0.0 
</p>
<p>1890 62,948,000 62,769,000 -179,000 -0.3 
</p>
<p>1900 75,995,000 76,870,000 875,000 1.2 
</p>
<p>1910 91,972,000 91,972,000 0 0.0 
</p>
<p>1920 105,711,000 107,559,000 1,848,000 1.7 
</p>
<p>1930 122,775,000 123,124,000 349,000 0.3 
</p>
<p>1940 131,669,000 136,653,000 4,984,000 3.8 
</p>
<p>1950 150,697,000 149,053,000 -1,644,000 -1.1 
</p>
<p>especially since we have not taken into account the large waves of im-
migration into the United States, and the fact that the United States was 
involved in five wars during this period. 
</p>
<p>In 1845 Verhulst prophesied a maximum population for Belgium of 
6,600,000, and a maximum population for France of 40,000,000. Now, the 
population of Belgium in 1930 was already 8,092,000. This large dis-
crepancy would seem to indicate that the logistic law of population growth 
is very inaccurate, at least as far as the population of Belgium is con-
cerned. However, this discrepancy can be explained by the astanishing rise 
of industry in Belgium, and by the acquisition of the Congo which secured 
for the country sufficient additional wealth to support the extra popula-
tion. Thus, after the acquisition of the Congo, and the astanishing rise of 
industry in Belgium, Verhulst should have lowered the vital coefficient b. 
</p>
<p>On the other hand, the population of France in 1930 was in remarkable 
agreement with Verhulst's forecast. Indeed, we can now answer the follow-
ing tantalizing paradox: Why was the population of France increasing 
extremely slowly in 1930 while the French population of Canada was in-
creasing very rapidly? After all, they are the same people! The answer to 
</p>
<p>33 </p>
<p/>
</div>
<div class="page"><p/>
<p>I First-order differential equations 
</p>
<p>this paradox, of course, is that the population of France in 1930 was very 
near its limiting value and thus was far into the period of diminishing 
growth, while the population of Canada in 1930 was still in the period of 
accelerated growth. 
</p>
<p>Remark 1. lt is clear that technological developments, pollution considera-
tions and sociological trends have significant influence on the vital coef-
ficients a and b. Therefore, they must be re-evaluated every few years. 
</p>
<p>Remark 2. To derive more accurate models of population growth, we 
should not consider the population as made up of one homogeneous group 
of individuals. Rather, we should subdivide it into different age groups. We 
should also subdivide the population into males and females, since the re-
production rate in a population usually depends more on the number of 
females than on the number of males. 
</p>
<p>Remark 3. Perhaps the severest criticism leveled at the logistic law of 
population growth is that some populations have been observed to 
fluctuate periodically between two values, and any type of fluctuation is 
ruled out in a logistic curve. However, some of these fluctuations can be 
explained by the fact that when certain populations reach a sufficiently 
high density, they become susceptible to epidemics. The epidemic brings 
the population down to a lower value where it again begins to increase, 
until when it is large enough, the epidemic strikes again. In Exercise 10 we 
derive a mode1 to describe this phenomenon, and we apply this model in 
Exercise 11 to explain the sudden appearance and disappearance of hordes 
of small rodents. 
</p>
<p>Epilog. The following article appeared in the N ew Y ork Times on March 
26, 1978, and was authored by Nick Eberstadt. 
</p>
<p>The gist of the following article is that it is very difficult, using statistical 
methods alone, to make accurate population projections even 30 years into 
the future. In 1970, demographers at the United Nations projected the 
population of the earth to be 6.5 billion people by the year 2000. Only six 
years later, this forecastwas revised downward to 5.9 billion people. 
</p>
<p>Let us now use Equation (3) to predict the population of the earth in the 
year 2000. Setting a =.029, b = 2.695 X 10- 12, p0 = 3.34X 109, t 0 = 1965, and 
t = 2,000 gives 
</p>
<p>P(2000) = (.029)(3.34)10
9 
</p>
<p>.009 + ( .02)e-&lt;&middot;029)35 
29(3.34) 109 
</p>
<p>9+20e-'-015 
</p>
<p>= 5.96 billion people! 
</p>
<p>This is another spectacular application of the logistic equation. 
</p>
<p>34 </p>
<p/>
</div>
<div class="page"><p/>
<p>W
or
</p>
<p>ld
 P
</p>
<p>op
ul
</p>
<p>at
io
</p>
<p>n 
F
</p>
<p>ig
ur
</p>
<p>es
 A
</p>
<p>re
 M
</p>
<p>is
le
</p>
<p>ad
in
</p>
<p>g 
_
</p>
<p>_
_
</p>
<p>_
_
</p>
<p>_
_
</p>
<p>_
_
</p>
<p>_
_
</p>
<p>_
_
</p>
<p>_
_
</p>
<p>_
_
</p>
<p>_
_
</p>
<p>_
_
</p>
<p>_
_
</p>
<p> _ 
T
</p>
<p>he
 r
</p>
<p>at
e 
</p>
<p>o
f 
</p>
<p>w
or
</p>
<p>ld
 p
</p>
<p>op
ul
</p>
<p>at
io
</p>
<p>n 
gr
</p>
<p>ow
th
</p>
<p> h
as
</p>
<p> 
ri
</p>
<p>se
n 
</p>
<p>fa
ir
</p>
<p>ly
 
</p>
<p>st
ea
</p>
<p>di
ly
</p>
<p> f
or
</p>
<p> m
os
</p>
<p>t 
o
</p>
<p>f 
m
</p>
<p>an
's
</p>
<p> h
is
</p>
<p>-
to
</p>
<p>ry
, 
</p>
<p>b
u
</p>
<p>t 
w
</p>
<p>it
hi
</p>
<p>n 
th
</p>
<p>e 
la
</p>
<p>st
 d
</p>
<p>ec
ad
</p>
<p>e 
it
</p>
<p> h
as
</p>
<p> p
ea
</p>
<p>ke
d,
</p>
<p> 
an
</p>
<p>d
 n
</p>
<p>ow
 a
</p>
<p>pp
ea
</p>
<p>rs
 t
</p>
<p>o 
be
</p>
<p> d
ec
</p>
<p>li
ni
</p>
<p>ng
. 
</p>
<p>H
ow
</p>
<p> h
as
</p>
<p> 
th
</p>
<p>is
 h
</p>
<p>ap
pe
</p>
<p>ne
d,
</p>
<p> a
nd
</p>
<p> w
hy
</p>
<p>? 
T
</p>
<p>he
 "
</p>
<p>h
o
</p>
<p>w
" 
</p>
<p>is
 f
</p>
<p>ai
rl
</p>
<p>y 
ea
</p>
<p>sy
. 
It
</p>
<p> is
 n
</p>
<p>o
t 
</p>
<p>be
ca
</p>
<p>us
e 
</p>
<p>fa
rn
</p>
<p>in
es
</p>
<p> 
an
</p>
<p>d 
ec
</p>
<p>ol
og
</p>
<p>ic
al
</p>
<p> 
ca
</p>
<p>ta
st
</p>
<p>ro
ph
</p>
<p>es
 
</p>
<p>ha
ve
</p>
<p> 
el
</p>
<p>ev
at
</p>
<p>ed
 t
</p>
<p>he
 d
</p>
<p>ea
th
</p>
<p> r
at
</p>
<p>es
. 
</p>
<p>R
at
</p>
<p>he
r,
</p>
<p> a
 l
</p>
<p>ar
ge
</p>
<p> a
nd
</p>
<p> 
ge
</p>
<p>ne
ra
</p>
<p>ll
y 
</p>
<p>un
ex
</p>
<p>pe
ct
</p>
<p>ed
 d
</p>
<p>ec
re
</p>
<p>as
e 
</p>
<p>in
 f
</p>
<p>er
ti
</p>
<p>li
ty
</p>
<p> i
n 
</p>
<p>th
e 
</p>
<p>le
ss
</p>
<p> d
ev
</p>
<p>el
op
</p>
<p>ed
 c
</p>
<p>ou
nt
</p>
<p>fi
es
</p>
<p> h
as
</p>
<p> t
ak
</p>
<p>en
 p
</p>
<p>la
ce
</p>
<p>. 
F
</p>
<p>ro
m
</p>
<p> 
19
</p>
<p>70
 
</p>
<p>to
 
</p>
<p>19
77
</p>
<p> 
bi
</p>
<p>rt
h 
</p>
<p>ra
te
</p>
<p>s 
in
</p>
<p> t
he
</p>
<p> 
le
</p>
<p>ss
 
</p>
<p>de
ve
</p>
<p>lo
pe
</p>
<p>d 
w
</p>
<p>or
ld
</p>
<p> (
ex
</p>
<p>cl
ud
</p>
<p>in
g 
</p>
<p>C
hi
</p>
<p>na
) 
</p>
<p>fe
ll 
</p>
<p>fr
om
</p>
<p> 
ab
</p>
<p>o
u
</p>
<p>t 
42
</p>
<p> t
o 
</p>
<p>ne
ar
</p>
<p>ly
 3
</p>
<p>6 
pe
</p>
<p>r 
th
</p>
<p>ou
sa
</p>
<p>nd
. 
</p>
<p>T
hi
</p>
<p>s 
is
</p>
<p> 
st
</p>
<p>il
l 
</p>
<p>hi
gh
</p>
<p>er
 t
</p>
<p>ha
n 
</p>
<p>th
e 
</p>
<p>17
 p
</p>
<p>er
 t
</p>
<p>ho
us
</p>
<p>an
d 
</p>
<p>in
 d
</p>
<p>ev
el
</p>
<p>-
op
</p>
<p>ed
 c
</p>
<p>ou
nt
</p>
<p>ri
es
</p>
<p>, 
b
</p>
<p>u
t 
</p>
<p>th
e 
</p>
<p>ra
te
</p>
<p> o
f 
</p>
<p>fe
rt
</p>
<p>il
it
</p>
<p>y 
de
</p>
<p>-
cl
</p>
<p>in
e 
</p>
<p>ap
pe
</p>
<p>ar
s 
</p>
<p>to
b
</p>
<p>e
 a
</p>
<p>cc
el
</p>
<p>er
at
</p>
<p>in
g:
</p>
<p> t
he
</p>
<p> s
ix
</p>
<p>-p
oi
</p>
<p>nt
 
</p>
<p>dr
op
</p>
<p> o
f 
</p>
<p>th
e 
</p>
<p>pa
st
</p>
<p> s
ev
</p>
<p>en
 y
</p>
<p>ea
rs
</p>
<p> c
om
</p>
<p>pa
re
</p>
<p>s 
w
</p>
<p>it
h 
</p>
<p>a 
tw
</p>
<p>o-
po
</p>
<p>in
t 
</p>
<p>de
cl
</p>
<p>in
e 
</p>
<p>fo
r 
</p>
<p>th
e 
</p>
<p>pr
ev
</p>
<p>io
us
</p>
<p> t
w
</p>
<p>en
ty
</p>
<p>. 
T
</p>
<p>hi
s 
</p>
<p>fe
rt
</p>
<p>il
it
</p>
<p>y 
de
</p>
<p>cl
in
</p>
<p>e 
ha
</p>
<p>s 
be
</p>
<p>en
 a
</p>
<p> v
er
</p>
<p>y 
un
</p>
<p>-
ev
</p>
<p>en
 p
</p>
<p>ro
ce
</p>
<p>ss
. 
</p>
<p>T
he
</p>
<p> a
ve
</p>
<p>ra
ge
</p>
<p> b
ir
</p>
<p>th
-r
</p>
<p>at
e 
</p>
<p>dr
op
</p>
<p> o
f 
</p>
<p>ab
ou
</p>
<p>t 
13
</p>
<p> p
er
</p>
<p>ce
nt
</p>
<p> s
in
</p>
<p>ce
 1
</p>
<p>97
0 
</p>
<p>in
 p
</p>
<p>o
o
</p>
<p>r 
w
</p>
<p>or
ld
</p>
<p> 
b
</p>
<p>ir
th
</p>
<p> r
at
</p>
<p>es
 
</p>
<p>re
fl
</p>
<p>ec
ts
</p>
<p> 
a 
</p>
<p>ve
ry
</p>
<p> r
ap
</p>
<p>id
 
</p>
<p>de
cl
</p>
<p>in
e 
</p>
<p>in
 
</p>
<p>ce
rt
</p>
<p>ai
n 
</p>
<p>co
un
</p>
<p>tr
ie
</p>
<p>s,
 w
</p>
<p>hi
le
</p>
<p> a
 g
</p>
<p>re
at
</p>
<p> m
an
</p>
<p>y 
ot
</p>
<p>he
rs
</p>
<p> 
ha
</p>
<p>ve
 r
</p>
<p>em
ai
</p>
<p>ne
d 
</p>
<p>al
m
</p>
<p>os
t 
</p>
<p>to
ta
</p>
<p>ll
y 
</p>
<p>un
af
</p>
<p>fe
ct
</p>
<p>ed
. 
</p>
<p>W
hy
</p>
<p> f
er
</p>
<p>ti
li
</p>
<p>ty
 
</p>
<p>ha
s 
</p>
<p>dr
op
</p>
<p>pe
d 
</p>
<p>so
 r
</p>
<p>ap
id
</p>
<p>ly
 i
</p>
<p>n
 
</p>
<p>th
e 
</p>
<p>pa
st
</p>
<p> d
e
c
a
d
</p>
<p>e
-a
</p>
<p>n
d
</p>
<p> w
hy
</p>
<p> i
t 
</p>
<p>ha
s 
</p>
<p>dr
op
</p>
<p>pe
d 
</p>
<p>so
 
</p>
<p>dr
am
</p>
<p>at
ic
</p>
<p>al
ly
</p>
<p> 
in
</p>
<p> 
so
</p>
<p>m
e 
</p>
<p>pl
ac
</p>
<p>es
, 
</p>
<p>b
u
</p>
<p>t 
n
</p>
<p>o
t 
</p>
<p>in
 
</p>
<p>o
th
</p>
<p>e
rs
</p>
<p>-i
s 
</p>
<p>fa
r 
</p>
<p>m
or
</p>
<p>e 
di
</p>
<p>ff
ic
</p>
<p>ul
t 
</p>
<p>to
 e
</p>
<p>xp
la
</p>
<p>in
. 
</p>
<p>D
e-
</p>
<p>m
og
</p>
<p>ra
ph
</p>
<p>er
s 
</p>
<p>an
d 
</p>
<p>so
ci
</p>
<p>ol
og
</p>
<p>is
ts
</p>
<p> 
of
</p>
<p>fe
r 
</p>
<p>ex
pl
</p>
<p>an
a-
</p>
<p>ti
on
</p>
<p>s 
ha
</p>
<p>vi
ng
</p>
<p> t
o 
</p>
<p>d
o
</p>
<p> w
it
</p>
<p>h 
so
</p>
<p>ci
al
</p>
<p> c
ha
</p>
<p>ng
e 
</p>
<p>in
 t
</p>
<p>he
 
</p>
<p>p
o
</p>
<p>o
r 
</p>
<p>w
or
</p>
<p>ld
. 
</p>
<p>U
nf
</p>
<p>or
tu
</p>
<p>na
te
</p>
<p>ly
, 
</p>
<p>th
es
</p>
<p>e 
pa
</p>
<p>rt
ia
</p>
<p>l 
ex
</p>
<p>-
pl
</p>
<p>an
at
</p>
<p>io
ns
</p>
<p> a
re
</p>
<p> m
or
</p>
<p>e 
of
</p>
<p>te
n 
</p>
<p>th
eo
</p>
<p>ry
 t
</p>
<p>ha
n 
</p>
<p>te
st
</p>
<p>ed
 
</p>
<p>fa
ct
</p>
<p>, 
an
</p>
<p>d
 t
</p>
<p>he
re
</p>
<p> s
ee
</p>
<p>m
s 
</p>
<p>to
 b
</p>
<p>e 
an
</p>
<p> e
xc
</p>
<p>ep
ti
</p>
<p>on
 f
</p>
<p>or
 
</p>
<p>al
m
</p>
<p>os
t 
</p>
<p>ev
er
</p>
<p>y 
ru
</p>
<p>le
. 
</p>
<p>T
he
</p>
<p> d
eb
</p>
<p>at
e 
</p>
<p>ov
er
</p>
<p> f
ar
</p>
<p>ni
ly
</p>
<p> p
la
</p>
<p>nn
in
</p>
<p>g 
is
</p>
<p> c
ha
</p>
<p>r-
ac
</p>
<p>te
ri
</p>
<p>st
ic
</p>
<p>. 
S
</p>
<p>ur
ve
</p>
<p>ys
 s
</p>
<p>ho
w
</p>
<p> t
h
</p>
<p>at
 i
</p>
<p>n 
so
</p>
<p>m
e 
</p>
<p>na
ti
</p>
<p>on
s 
</p>
<p>as
 m
</p>
<p>an
y 
</p>
<p>as
 a
</p>
<p> f
if
</p>
<p>th
 o
</p>
<p>f 
th
</p>
<p>e 
ch
</p>
<p>il
dr
</p>
<p>en
 w
</p>
<p>er
e 
</p>
<p>"m
is
</p>
<p>-
ta
</p>
<p>ke
s"
</p>
<p> w
ho
</p>
<p> p
re
</p>
<p>su
m
</p>
<p>ab
ly
</p>
<p> w
ou
</p>
<p>ld
 n
</p>
<p>o
t 
</p>
<p>ha
ve
</p>
<p> b
ee
</p>
<p>n 
b
</p>
<p>o
m
</p>
<p> i
f 
</p>
<p>pa
re
</p>
<p>nt
s 
</p>
<p>ha
d 
</p>
<p>h
ad
</p>
<p> b
et
</p>
<p>te
r 
</p>
<p>co
nt
</p>
<p>ra
ce
</p>
<p>p-
tiv
</p>
<p>es
. 
</p>
<p>F
ar
</p>
<p>ni
ly
</p>
<p> p
la
</p>
<p>nn
in
</p>
<p>g 
ex
</p>
<p>pe
rt
</p>
<p>s 
su
</p>
<p>ch
 a
</p>
<p>s 
P
</p>
<p>ar
ke
</p>
<p>r 
M
</p>
<p>au
ld
</p>
<p>in
 
</p>
<p>o
f 
</p>
<p>th
e 
</p>
<p>P
op
</p>
<p>ul
at
</p>
<p>io
n 
</p>
<p>C
ou
</p>
<p>nc
il
</p>
<p> 
ha
</p>
<p>ve
 
</p>
<p>po
in
</p>
<p>te
d 
</p>
<p>ou
t 
</p>
<p>th
at
</p>
<p> n
o 
</p>
<p>po
or
</p>
<p> n
at
</p>
<p>io
n 
</p>
<p>w
it
</p>
<p>ho
ut
</p>
<p> a
n
</p>
<p> 
ac
</p>
<p>ti
ve
</p>
<p> f
ar
</p>
<p>ni
ly
</p>
<p> p
la
</p>
<p>nn
in
</p>
<p>g 
pr
</p>
<p>og
ra
</p>
<p>m
 h
</p>
<p>as
 s
</p>
<p>ig
ni
</p>
<p>fi
-
</p>
<p>ca
nt
</p>
<p>ly
 lo
</p>
<p>w
er
</p>
<p>ed
 it
</p>
<p>s 
fe
</p>
<p>rt
il
</p>
<p>it
y.
</p>
<p> O
n
</p>
<p> th
e 
</p>
<p>ot
he
</p>
<p>r 
ha
</p>
<p>nd
, 
</p>
<p>su
ch
</p>
<p> s
oc
</p>
<p>io
lo
</p>
<p>gi
st
</p>
<p>s 
as
</p>
<p> W
il
</p>
<p>li
am
</p>
<p> P
et
</p>
<p>er
se
</p>
<p>n 
o
</p>
<p>f 
O
</p>
<p>hi
o 
</p>
<p>S
ta
</p>
<p>te
 U
</p>
<p>ni
ve
</p>
<p>rs
it
</p>
<p>y 
at
</p>
<p>tr
ib
</p>
<p>ut
e 
</p>
<p>th
e 
</p>
<p>po
pu
</p>
<p>la
ti
</p>
<p>on
 d
</p>
<p>e-
cl
</p>
<p>in
e 
</p>
<p>in
 t
</p>
<p>he
se
</p>
<p> n
at
</p>
<p>io
ns
</p>
<p> t
o 
</p>
<p>so
ci
</p>
<p>al
 a
</p>
<p>nd
 e
</p>
<p>co
no
</p>
<p>m
ic
</p>
<p> 
de
</p>
<p>ve
lo
</p>
<p>pm
en
</p>
<p>t 
ra
</p>
<p>th
er
</p>
<p> 
th
</p>
<p>an
 
</p>
<p>in
cr
</p>
<p>ea
se
</p>
<p>d 
co
</p>
<p>n-
tr
</p>
<p>ac
ep
</p>
<p>ti
ve
</p>
<p> 
us
</p>
<p>e,
 
</p>
<p>ar
gu
</p>
<p>in
g 
</p>
<p>th
at
</p>
<p> 
in
</p>
<p>te
rn
</p>
<p>at
io
</p>
<p>na
l 
</p>
<p>"p
o
</p>
<p>p
u
</p>
<p>la
ti
</p>
<p>o
n
</p>
<p> c
on
</p>
<p>tr
ol
</p>
<p>" 
pr
</p>
<p>og
ra
</p>
<p>m
s 
</p>
<p>ha
ve
</p>
<p> u
su
</p>
<p>al
ly
</p>
<p> 
be
</p>
<p>en
 c
</p>
<p>lu
m
</p>
<p>sy
 a
</p>
<p>nd
 i
</p>
<p>ns
en
</p>
<p>si
ti
</p>
<p>ve
 (
</p>
<p>or
 w
</p>
<p>or
se
</p>
<p>),
 a
</p>
<p>n
d
</p>
<p> 
th
</p>
<p>at
 i
</p>
<p>n 
an
</p>
<p>y 
ev
</p>
<p>en
t 
</p>
<p>ev
en
</p>
<p> a
 w
</p>
<p>el
l-
</p>
<p>re
ce
</p>
<p>iv
ed
</p>
<p> c
ha
</p>
<p>ng
e 
</p>
<p>in
 c
</p>
<p>on
tr
</p>
<p>ac
ep
</p>
<p>ti
ve
</p>
<p> "
te
</p>
<p>ch
no
</p>
<p>lo
gy
</p>
<p>" 
do
</p>
<p>es
 n
</p>
<p>o
t 
</p>
<p>ne
c-
</p>
<p>es
sa
</p>
<p>ri
ly
</p>
<p> 
in
</p>
<p>fl
ue
</p>
<p>nc
e 
</p>
<p>pa
re
</p>
<p>nt
s 
</p>
<p>to
 
</p>
<p>w
an
</p>
<p>t 
fe
</p>
<p>w
er
</p>
<p> 
ch
</p>
<p>il
dr
</p>
<p>en
. 
</p>
<p>T
he
</p>
<p> e
ff
</p>
<p>ec
ts
</p>
<p> o
f 
</p>
<p>in
co
</p>
<p>m
e 
</p>
<p>di
st
</p>
<p>ri
bu
</p>
<p>ti
on
</p>
<p> a
re
</p>
<p> l
es
</p>
<p>s 
vo
</p>
<p>ci
fe
</p>
<p>ro
us
</p>
<p>ly
 d
</p>
<p>eb
at
</p>
<p>ed
, 
</p>
<p>b
u
</p>
<p>t 
ar
</p>
<p>e 
al
</p>
<p>m
os
</p>
<p>t 
as
</p>
<p> m
ys
</p>
<p>-
te
</p>
<p>ri
ou
</p>
<p>s.
 J
</p>
<p>am
es
</p>
<p> K
oc
</p>
<p>he
r 
</p>
<p>an
d 
</p>
<p>R
ob
</p>
<p>er
t 
</p>
<p>R
ep
</p>
<p>et
to
</p>
<p>, 
b
</p>
<p>o
th
</p>
<p> 
o
</p>
<p>f 
H
</p>
<p>ar
va
</p>
<p>rd
, 
</p>
<p>ha
ve
</p>
<p> 
ar
</p>
<p>gu
ed
</p>
<p> 
th
</p>
<p>at
 
</p>
<p>m
or
</p>
<p>e 
eq
</p>
<p>ui
ta
</p>
<p>bl
e 
</p>
<p>in
co
</p>
<p>m
e 
</p>
<p>di
st
</p>
<p>ri
bu
</p>
<p>ti
on
</p>
<p> i
n 
</p>
<p>le
ss
</p>
<p> d
ev
</p>
<p>el
-
</p>
<p>op
ed
</p>
<p> 
co
</p>
<p>un
tf
</p>
<p>ie
s 
</p>
<p>co
nt
</p>
<p>ri
bu
</p>
<p>te
s 
</p>
<p>to
 
</p>
<p>fe
rt
</p>
<p>il
it
</p>
<p>y 
de
</p>
<p>-
cl
</p>
<p>in
e.
</p>
<p> T
he
</p>
<p>y 
ha
</p>
<p>ve
 p
</p>
<p>oi
nt
</p>
<p>ed
 o
</p>
<p>ut
 t
</p>
<p>ha
t 
</p>
<p>su
ch
</p>
<p> c
ou
</p>
<p>n-
tf
</p>
<p>ie
s 
</p>
<p>as
 S
</p>
<p>ri
 L
</p>
<p>an
ka
</p>
<p>, 
S
</p>
<p>ou
th
</p>
<p> K
or
</p>
<p>ea
, 
</p>
<p>C
u
</p>
<p>b
a 
</p>
<p>an
d 
</p>
<p>C
hi
</p>
<p>na
 h
</p>
<p>av
e 
</p>
<p>se
en
</p>
<p> t
he
</p>
<p>ir
 f
</p>
<p>er
ti
</p>
<p>li
ty
</p>
<p> r
at
</p>
<p>es
 f
</p>
<p>al
l 
</p>
<p>as
 
</p>
<p>th
ei
</p>
<p>r 
in
</p>
<p>co
m
</p>
<p>e 
di
</p>
<p>st
ri
</p>
<p>bu
ti
</p>
<p>on
 b
</p>
<p>ec
am
</p>
<p>e 
m
</p>
<p>or
e 
</p>
<p>ne
ar
</p>
<p>ly
 
</p>
<p>eq
ua
</p>
<p>l. 
Im
</p>
<p>pr
ov
</p>
<p>in
g 
</p>
<p>a 
na
</p>
<p>ti
on
</p>
<p>'s
 i
</p>
<p>nc
om
</p>
<p>e 
di
</p>
<p>st
ri
</p>
<p>bu
-
</p>
<p>ti
on
</p>
<p>, 
ho
</p>
<p>w
ev
</p>
<p>er
, 
</p>
<p>ap
pe
</p>
<p>ar
s 
</p>
<p>to
b
</p>
<p>e
 n
</p>
<p>ei
th
</p>
<p>er
 a
</p>
<p> n
ec
</p>
<p>es
-
</p>
<p>sa
ry
</p>
<p> n
or
</p>
<p> a
 s
</p>
<p>uf
fi
</p>
<p>ci
en
</p>
<p>t 
co
</p>
<p>nd
it
</p>
<p>io
n 
</p>
<p>fo
r 
</p>
<p>in
du
</p>
<p>ci
ng
</p>
<p> a
 
</p>
<p>fe
rt
</p>
<p>il
it
</p>
<p>y 
dr
</p>
<p>op
. 
</p>
<p>In
co
</p>
<p>m
e 
</p>
<p>di
st
</p>
<p>ri
bu
</p>
<p>ti
on
</p>
<p> i
n
</p>
<p> B
ur
</p>
<p>m
a,
</p>
<p> 
fo
</p>
<p>r 
ex
</p>
<p>am
pl
</p>
<p>e,
 h
</p>
<p>as
 p
</p>
<p>re
su
</p>
<p>m
ab
</p>
<p>ly
 e
</p>
<p>qu
al
</p>
<p>iz
ed
</p>
<p> s
om
</p>
<p>e-
w
</p>
<p>ha
t 
</p>
<p>un
de
</p>
<p>r 
30
</p>
<p> y
ea
</p>
<p>rs
 o
</p>
<p>f 
ho
</p>
<p>m
em
</p>
<p>ad
e 
</p>
<p>so
ci
</p>
<p>al
is
</p>
<p>m
, 
</p>
<p>b
u
</p>
<p>t 
b
</p>
<p>ir
th
</p>
<p> r
at
</p>
<p>es
 h
</p>
<p>av
e 
</p>
<p>ha
rd
</p>
<p>ly
 f
</p>
<p>al
le
</p>
<p>n 
at
</p>
<p> a
ll,
</p>
<p> w
hi
</p>
<p>le
 
</p>
<p>M
ex
</p>
<p>ic
o 
</p>
<p>an
d 
</p>
<p>C
ol
</p>
<p>om
bi
</p>
<p>a,
 w
</p>
<p>it
h 
</p>
<p>hi
gh
</p>
<p>ly
 u
</p>
<p>ne
qu
</p>
<p>al
 
</p>
<p>in
co
</p>
<p>m
e 
</p>
<p>di
st
</p>
<p>ri
bu
</p>
<p>ti
on
</p>
<p>s,
 h
</p>
<p>av
e 
</p>
<p>fo
un
</p>
<p>d 
th
</p>
<p>ei
r 
</p>
<p>bi
rt
</p>
<p>h 
ra
</p>
<p>te
s 
</p>
<p>pl
um
</p>
<p>m
et
</p>
<p>in
g 
</p>
<p>in
 r
</p>
<p>ec
en
</p>
<p>t 
ye
</p>
<p>ar
s.
</p>
<p> 
O
</p>
<p>ne
 k
</p>
<p>ey
 t
</p>
<p>o 
ch
</p>
<p>an
ge
</p>
<p>s 
in
</p>
<p> f
er
</p>
<p>ti
li
</p>
<p>ty
 l
</p>
<p>ev
el
</p>
<p>s 
m
</p>
<p>ay
 
</p>
<p>be
 
</p>
<p>th
e 
</p>
<p>ec
on
</p>
<p>om
ic
</p>
<p> 
co
</p>
<p>st
s 
</p>
<p>an
d
</p>
<p> 
be
</p>
<p>ne
fi
</p>
<p>ts
 
</p>
<p>fr
om
</p>
<p> 
ch
</p>
<p>il
dr
</p>
<p>en
. 
</p>
<p>In
 p
</p>
<p>ea
sa
</p>
<p>nt
 s
</p>
<p>oc
ie
</p>
<p>tie
s,
</p>
<p> w
he
</p>
<p>re
 c
</p>
<p>hi
ld
</p>
<p>re
n 
</p>
<p>ar
e 
</p>
<p>af
fo
</p>
<p>rd
ed
</p>
<p> f
ew
</p>
<p> 
am
</p>
<p>en
it
</p>
<p>ie
s 
</p>
<p>an
d 
</p>
<p>st
ar
</p>
<p>t 
w
</p>
<p>or
k 
</p>
<p>yo
un
</p>
<p>g,
 
</p>
<p>th
ey
</p>
<p> 
m
</p>
<p>ay
 
</p>
<p>be
co
</p>
<p>m
e 
</p>
<p>ec
on
</p>
<p>om
ic
</p>
<p> 
as
</p>
<p>se
ts
</p>
<p> 
ea
</p>
<p>rl
y:
</p>
<p> A
re
</p>
<p>ce
n
</p>
<p>t 
st
</p>
<p>ud
y 
</p>
<p>in
 B
</p>
<p>an
gl
</p>
<p>ad
es
</p>
<p>h 
b
</p>
<p>y
 M
</p>
<p>ea
d 
</p>
<p>C
ai
</p>
<p>n 
o
</p>
<p>f 
th
</p>
<p>e 
P
</p>
<p>op
ul
</p>
<p>at
io
</p>
<p>n 
C
</p>
<p>ou
nc
</p>
<p>il
 p
</p>
<p>u
t 
</p>
<p>th
e 
</p>
<p>ag
e 
</p>
<p>fo
r 
</p>
<p>bo
ys
</p>
<p> 
at
</p>
<p> 
12
</p>
<p>. 
F
</p>
<p>ur
th
</p>
<p>er
m
</p>
<p>or
e,
</p>
<p> 
ch
</p>
<p>il
dr
</p>
<p>en
 
</p>
<p>(o
r 
</p>
<p>m
or
</p>
<p>e 
pr
</p>
<p>ec
is
</p>
<p>el
y,
</p>
<p> s
on
</p>
<p>s)
 m
</p>
<p>ay
 a
</p>
<p>ls
o 
</p>
<p>se
rv
</p>
<p>e 
as
</p>
<p> s
oc
</p>
<p>ia
l 
</p>
<p>se
cu
</p>
<p>ri
ty
</p>
<p> a
nd
</p>
<p> u
ne
</p>
<p>m
pl
</p>
<p>oy
m
</p>
<p>en
t 
</p>
<p>in
su
</p>
<p>ra
nc
</p>
<p>e 
w
</p>
<p>he
n 
</p>
<p>pa
re
</p>
<p>nt
s 
</p>
<p>be
co
</p>
<p>m
e 
</p>
<p>to
o 
</p>
<p>ol
d 
</p>
<p>an
d 
</p>
<p>w
ea
</p>
<p>k 
to
</p>
<p> w
or
</p>
<p>k,
 o
</p>
<p>r 
w
</p>
<p>he
n 
</p>
<p>w
or
</p>
<p>k 
is
</p>
<p> u
na
</p>
<p>va
il
</p>
<p>ab
le
</p>
<p>. 
W
</p>
<p>he
re
</p>
<p> b
ir
</p>
<p>th
 r
</p>
<p>at
es
</p>
<p> 
in
</p>
<p> p
o
</p>
<p>o
r 
</p>
<p>co
un
</p>
<p>tf
ie
</p>
<p>s 
ar
</p>
<p>e 
dr
</p>
<p>op
pi
</p>
<p>ng
, 
</p>
<p>so
ci
</p>
<p>al
 
</p>
<p>an
d 
</p>
<p>ec
on
</p>
<p>om
ic
</p>
<p> 
de
</p>
<p>ve
lo
</p>
<p>pm
en
</p>
<p>t 
m
</p>
<p>ay
 
</p>
<p>be
 
</p>
<p>m
ak
</p>
<p>in
g 
</p>
<p>ch
il
</p>
<p>dr
en
</p>
<p> l
es
</p>
<p>s 
ne
</p>
<p>ce
ss
</p>
<p>ar
y 
</p>
<p>as
 s
</p>
<p>ou
rc
</p>
<p>es
 o
</p>
<p>f 
in
</p>
<p>co
m
</p>
<p>e 
an
</p>
<p>d 
se
</p>
<p>cu
ri
</p>
<p>ty
, b
</p>
<p>u
t 
</p>
<p>so
 l
</p>
<p>it
tl
</p>
<p>e 
w
</p>
<p>or
k 
</p>
<p>ha
s 
</p>
<p>be
en
</p>
<p> d
on
</p>
<p>e 
in
</p>
<p> t
hi
</p>
<p>s 
ar
</p>
<p>ea
 t
</p>
<p>ha
t 
</p>
<p>th
is
</p>
<p> i
s 
</p>
<p>st
il
</p>
<p>l 
ju
</p>
<p>st
 a
</p>
<p> r
ea
</p>
<p>so
na
</p>
<p>bl
e 
</p>
<p>sp
ec
</p>
<p>ul
at
</p>
<p>io
n.
</p>
<p> 
S
</p>
<p>om
e 
</p>
<p>o
f 
</p>
<p>th
e 
</p>
<p>m
an
</p>
<p>y 
ot
</p>
<p>he
r 
</p>
<p>fa
ct
</p>
<p>or
s 
</p>
<p>w
ho
</p>
<p>se
 
</p>
<p>ef
fe
</p>
<p>ct
s 
</p>
<p>on
 
</p>
<p>fe
rt
</p>
<p>il
it
</p>
<p>y 
ha
</p>
<p>ve
 
</p>
<p>be
en
</p>
<p> 
st
</p>
<p>ud
ie
</p>
<p>d 
ar
</p>
<p>e 
ur
</p>
<p>ba
ni
</p>
<p>za
ti
</p>
<p>on
, 
</p>
<p>ed
uc
</p>
<p>at
io
</p>
<p>n,
 o
</p>
<p>cc
up
</p>
<p>at
io
</p>
<p>na
l 
</p>
<p>st
ru
</p>
<p>c-</p>
<p/>
</div>
<div class="page"><p/>
<p>tu
re
</p>
<p>, 
pu
</p>
<p>bl
ic
</p>
<p> h
ea
</p>
<p>lt
h 
</p>
<p>an
d 
</p>
<p>th
e 
</p>
<p>st
at
</p>
<p>us
 o
</p>
<p>f 
w
</p>
<p>om
en
</p>
<p>. 
O
</p>
<p>ne
 a
</p>
<p>re
a 
</p>
<p>w
hi
</p>
<p>ch
 p
</p>
<p>op
ul
</p>
<p>at
io
</p>
<p>n 
ex
</p>
<p>pe
rt
</p>
<p>s 
se
</p>
<p>em
 t
</p>
<p>o 
ha
</p>
<p>ve
 s
</p>
<p>hi
ed
</p>
<p> a
w
</p>
<p>ay
 f
</p>
<p>ro
m
</p>
<p>, 
ho
</p>
<p>w
ev
</p>
<p>er
, 
</p>
<p>is
 t
</p>
<p>he
 n
</p>
<p>on
-
</p>
<p>qu
an
</p>
<p>ti
fi
</p>
<p>ab
le
</p>
<p> r
ea
</p>
<p>lm
 
</p>
<p>o
f 
</p>
<p>at
ti
</p>
<p>tu
de
</p>
<p>s,
 b
</p>
<p>el
ie
</p>
<p>fs
 a
</p>
<p>nd
 
</p>
<p>va
lu
</p>
<p>es
 w
</p>
<p>hi
ch
</p>
<p> m
ay
</p>
<p> h
av
</p>
<p>e 
ha
</p>
<p>d 
m
</p>
<p>uc
h 
</p>
<p>to
 d
</p>
<p>o 
w
</p>
<p>it
h 
</p>
<p>th
e 
</p>
<p>re
ce
</p>
<p>nt
 
</p>
<p>ch
an
</p>
<p>ge
s 
</p>
<p>in
 
</p>
<p>th
e 
</p>
<p>de
ci
</p>
<p>si
on
</p>
<p>s 
of
</p>
<p> 
hu
</p>
<p>nd
re
</p>
<p>ds
 o
</p>
<p>f 
m
</p>
<p>il
li
</p>
<p>on
s 
</p>
<p>of
 c
</p>
<p>ou
pl
</p>
<p>es
. 
</p>
<p>C
ul
</p>
<p>tu
ra
</p>
<p>l 
di
</p>
<p>f-
fe
</p>
<p>re
nc
</p>
<p>es
, 
</p>
<p>et
hn
</p>
<p>ic
 c
</p>
<p>on
fl
</p>
<p>ic
ts
</p>
<p>, 
ps
</p>
<p>yc
ho
</p>
<p>lo
gi
</p>
<p>ca
l, 
</p>
<p>id
eo
</p>
<p>-
lo
</p>
<p>gi
ca
</p>
<p>l 
an
</p>
<p>d 
ev
</p>
<p>en
 
</p>
<p>po
li
</p>
<p>ti
ca
</p>
<p>l 
ch
</p>
<p>an
ge
</p>
<p>s 
co
</p>
<p>ul
d 
</p>
<p>cl
ea
</p>
<p>rl
y 
</p>
<p>ha
ve
</p>
<p> 
ef
</p>
<p>fe
ct
</p>
<p>s 
on
</p>
<p> 
fe
</p>
<p>rt
il
</p>
<p>it
y.
</p>
<p> 
A
</p>
<p>s 
M
</p>
<p>ar
is
</p>
<p> 
V
</p>
<p>on
ov
</p>
<p>sk
is
</p>
<p> o
f 
</p>
<p>th
e 
</p>
<p>H
ou
</p>
<p>se
 S
</p>
<p>el
ec
</p>
<p>t 
C
</p>
<p>om
m
</p>
<p>it
te
</p>
<p>e 
o
</p>
<p>n
 
</p>
<p>P
op
</p>
<p>ul
at
</p>
<p>io
n 
</p>
<p>ha
s 
</p>
<p>sa
id
</p>
<p>, 
ju
</p>
<p>st
 b
</p>
<p>ec
au
</p>
<p>se
 y
</p>
<p>ou
 c
</p>
<p>an
't 
</p>
<p>m
ea
</p>
<p>su
re
</p>
<p> s
om
</p>
<p>et
hi
</p>
<p>ng
 d
</p>
<p>oe
sn
</p>
<p>'t 
m
</p>
<p>ea
n 
</p>
<p>it
 i
</p>
<p>sn
't 
</p>
<p>im
-
</p>
<p>po
rt
</p>
<p>an
t.
</p>
<p> 
W
</p>
<p>ha
t 
</p>
<p>do
es
</p>
<p> 
th
</p>
<p>e 
de
</p>
<p>cl
in
</p>
<p>e 
in
</p>
<p> f
er
</p>
<p>ti
li
</p>
<p>ty
 m
</p>
<p>ea
n 
</p>
<p>ab
ou
</p>
<p>t 
fu
</p>
<p>tu
re
</p>
<p> l
ev
</p>
<p>el
s 
</p>
<p>o
f 
</p>
<p>po
pu
</p>
<p>la
ti
</p>
<p>on
? 
</p>
<p>O
bv
</p>
<p>io
us
</p>
<p>ly
, 
</p>
<p>if
 th
</p>
<p>e 
dr
</p>
<p>op
 c
</p>
<p>on
ti
</p>
<p>nu
es
</p>
<p>, 
po
</p>
<p>pu
la
</p>
<p>ti
on
</p>
<p> g
ro
</p>
<p>w
th
</p>
<p> w
ill
</p>
<p> 
be
</p>
<p> s
lo
</p>
<p>w
er
</p>
<p> 
th
</p>
<p>an
 p
</p>
<p>re
vi
</p>
<p>ou
sl
</p>
<p>y 
an
</p>
<p>ti
ci
</p>
<p>pa
te
</p>
<p>d,
 
</p>
<p>an
d 
</p>
<p>w
or
</p>
<p>ld
 p
</p>
<p>op
ul
</p>
<p>at
io
</p>
<p>n 
w
</p>
<p>ill
 e
</p>
<p>ve
nt
</p>
<p>ua
ll
</p>
<p>y 
st
</p>
<p>ab
il
</p>
<p>iz
e 
</p>
<p>at
 
</p>
<p>a 
lo
</p>
<p>w
er
</p>
<p> I
ev
</p>
<p>el
. 
</p>
<p>O
nl
</p>
<p>y 
fi
</p>
<p>ve
 y
</p>
<p>ea
rs
</p>
<p> a
go
</p>
<p> t
he
</p>
<p> U
ni
</p>
<p>te
d 
</p>
<p>N
at
</p>
<p>io
ns
</p>
<p> 
"m
</p>
<p>ed
iu
</p>
<p>m
 
</p>
<p>va
ri
</p>
<p>an
t"
</p>
<p> 
pr
</p>
<p>oj
ec
</p>
<p>ti
on
</p>
<p> 
fo
</p>
<p>r 
w
</p>
<p>or
ld
</p>
<p> p
op
</p>
<p>ul
at
</p>
<p>io
n 
</p>
<p>in
 t
</p>
<p>he
 y
</p>
<p>ea
r 
</p>
<p>20
00
</p>
<p> w
as
</p>
<p> 6
.5
</p>
<p> 
bi
</p>
<p>ll
io
</p>
<p>n;
 
</p>
<p>la
st
</p>
<p> 
ye
</p>
<p>ar
 
</p>
<p>th
is
</p>
<p> 
w
</p>
<p>as
 
</p>
<p>dr
op
</p>
<p>pe
d 
</p>
<p>m
or
</p>
<p>e 
th
</p>
<p>an
 2
</p>
<p>00
 m
</p>
<p>il
li
</p>
<p>on
, 
</p>
<p>an
d 
</p>
<p>re
ce
</p>
<p>nt
 w
</p>
<p>or
k 
</p>
<p>by
 G
</p>
<p>ar
y 
</p>
<p>L
it
</p>
<p>tm
an
</p>
<p> a
nd
</p>
<p> N
at
</p>
<p>h
an
</p>
<p> K
ey
</p>
<p>fi
tz
</p>
<p> a
t 
</p>
<p>th
e 
</p>
<p>H
ar
</p>
<p>va
rd
</p>
<p> 
C
</p>
<p>en
te
</p>
<p>r 
fo
</p>
<p>r 
P
</p>
<p>op
ul
</p>
<p>at
io
</p>
<p>n 
S
</p>
<p>tu
di
</p>
<p>es
 s
</p>
<p>ho
w
</p>
<p>s 
th
</p>
<p>at
 i
</p>
<p>n 
th
</p>
<p>e 
li
</p>
<p>gh
t 
</p>
<p>o
f 
</p>
<p>re
ce
</p>
<p>nt
 c
</p>
<p>ha
ng
</p>
<p>es
, 
</p>
<p>on
e 
</p>
<p>m
ig
</p>
<p>ht
 e
</p>
<p>as
ily
</p>
<p> 
dr
</p>
<p>op
 i
</p>
<p>t 
40
</p>
<p>0 
m
</p>
<p>il
li
</p>
<p>on
 m
</p>
<p>or
e.
</p>
<p> 
P
</p>
<p>op
ul
</p>
<p>at
io
</p>
<p>n 
pr
</p>
<p>oj
ec
</p>
<p>ti
on
</p>
<p>s,
 
</p>
<p>ho
w
</p>
<p>ev
er
</p>
<p>, 
ar
</p>
<p>e 
a 
</p>
<p>ve
ry
</p>
<p> t
ri
</p>
<p>ck
y 
</p>
<p>bu
si
</p>
<p>ne
ss
</p>
<p>. 
T
</p>
<p>o 
be
</p>
<p>gi
n 
</p>
<p>w
it
</p>
<p>h,
 t
</p>
<p>he
 f
</p>
<p>ig
-
</p>
<p>ur
es
</p>
<p> 
fo
</p>
<p>r 
to
</p>
<p>da
y'
</p>
<p>s 
po
</p>
<p>pu
la
</p>
<p>ti
on
</p>
<p>, 
up
</p>
<p>on
 
</p>
<p>w
hi
</p>
<p>ch
 
</p>
<p>to
m
</p>
<p>or
ro
</p>
<p>w
's
</p>
<p> p
ro
</p>
<p>je
ct
</p>
<p>io
ns
</p>
<p> m
us
</p>
<p>t 
be
</p>
<p> b
as
</p>
<p>ed
, 
</p>
<p>co
n-
</p>
<p>ta
in
</p>
<p> !
ar
</p>
<p>ge
 
</p>
<p>m
ar
</p>
<p>gi
ns
</p>
<p> 
of
</p>
<p> 
er
</p>
<p>ro
r.
</p>
<p> 
F
</p>
<p>o
r 
</p>
<p>ex
am
</p>
<p>pl
e,
</p>
<p> 
es
</p>
<p>ti
m
</p>
<p>at
es
</p>
<p> f
or
</p>
<p> 
C
</p>
<p>hi
na
</p>
<p>'s
 p
</p>
<p>op
ul
</p>
<p>at
io
</p>
<p>n 
ru
</p>
<p>n 
fr
</p>
<p>om
 
</p>
<p>75
0 
</p>
<p>m
il
</p>
<p>li
on
</p>
<p> 
to
</p>
<p> 
ov
</p>
<p>er
 
</p>
<p>95
0 
</p>
<p>m
ill
</p>
<p>io
n.
</p>
<p> 
B
</p>
<p>y 
th
</p>
<p>e 
ac
</p>
<p>co
un
</p>
<p>t 
of
</p>
<p> J
oh
</p>
<p>n 
D
</p>
<p>u
ra
</p>
<p>n
d
</p>
<p> o
f 
</p>
<p>th
e 
</p>
<p>U
ni
</p>
<p>ve
rs
</p>
<p>it
y 
</p>
<p>of
 
</p>
<p>P
en
</p>
<p>ns
yl
</p>
<p>va
ni
</p>
<p>a,
 t
</p>
<p>he
 m
</p>
<p>ar
gi
</p>
<p>ns
 o
</p>
<p>f 
er
</p>
<p>ro
r 
</p>
<p>fo
r 
</p>
<p>w
or
</p>
<p>ld
 
</p>
<p>po
pu
</p>
<p>la
ti
</p>
<p>on
 
</p>
<p>ad
d 
</p>
<p>up
 
</p>
<p>to
 
</p>
<p>ov
er
</p>
<p> 
20
</p>
<p>0 
m
</p>
<p>il
li
</p>
<p>on
; 
</p>
<p>hi
st
</p>
<p>or
ia
</p>
<p>n 
F
</p>
<p>em
an
</p>
<p>d
 B
</p>
<p>ra
ud
</p>
<p>ei
 p
</p>
<p>ut
s 
</p>
<p>th
e 
</p>
<p>m
ar
</p>
<p>gi
n 
</p>
<p>o
f 
</p>
<p>er
ro
</p>
<p>r 
at
</p>
<p> 
10
</p>
<p> 
pe
</p>
<p>rc
en
</p>
<p>t,
 
</p>
<p>w
hi
</p>
<p>ch
, 
</p>
<p>gi
ve
</p>
<p>n 
th
</p>
<p>e 
w
</p>
<p>or
ld
</p>
<p>'s
 
</p>
<p>ap
pr
</p>
<p>ox
im
</p>
<p>at
e 
</p>
<p>pr
es
</p>
<p>en
t 
</p>
<p>po
pu
</p>
<p>la
ti
</p>
<p>on
, 
</p>
<p>m
ea
</p>
<p>ns
 a
</p>
<p>bo
ut
</p>
<p> 4
00
</p>
<p> m
il
</p>
<p>li
on
</p>
<p> p
eo
</p>
<p>pl
e.
</p>
<p> 
P
</p>
<p>op
ul
</p>
<p>at
io
</p>
<p>n 
pr
</p>
<p>oj
ec
</p>
<p>ti
on
</p>
<p>s 
in
</p>
<p>sp
ir
</p>
<p>e 
ev
</p>
<p>en
 
</p>
<p>le
ss
</p>
<p> 
co
</p>
<p>nf
id
</p>
<p>en
ce
</p>
<p> 
th
</p>
<p>an
 
</p>
<p>po
pu
</p>
<p>la
ti
</p>
<p>on
 
</p>
<p>es
ti
</p>
<p>m
at
</p>
<p>es
, 
</p>
<p>fo
r 
</p>
<p>th
ey
</p>
<p> 
hi
</p>
<p>ng
e 
</p>
<p>on
 
</p>
<p>pr
ed
</p>
<p>ic
ti
</p>
<p>ng
 
</p>
<p>bi
rt
</p>
<p>h 
an
</p>
<p>d 
de
</p>
<p>at
h 
</p>
<p>ra
te
</p>
<p>s 
fo
</p>
<p>r 
th
</p>
<p>e 
fu
</p>
<p>tu
re
</p>
<p>. 
T
</p>
<p>he
se
</p>
<p> c
an
</p>
<p> c
ha
</p>
<p>ng
e 
</p>
<p>ra
pi
</p>
<p>dl
y 
</p>
<p>an
d
</p>
<p> u
ne
</p>
<p>xp
ec
</p>
<p>te
dl
</p>
<p>y:
 t
</p>
<p>w
o 
</p>
<p>ex
tr
</p>
<p>em
e 
</p>
<p>ex
am
</p>
<p>pl
es
</p>
<p> a
re
</p>
<p> 
S
</p>
<p>ri
 L
</p>
<p>an
ka
</p>
<p>'s
 3
</p>
<p>4 
pe
</p>
<p>rc
en
</p>
<p>t 
dr
</p>
<p>op
 i
</p>
<p>n 
th
</p>
<p>e 
de
</p>
<p>at
h 
</p>
<p>ra
te
</p>
<p> 
in
</p>
<p> j
u
</p>
<p>st
 
</p>
<p>tw
o 
</p>
<p>ye
ar
</p>
<p>s,
 
</p>
<p>an
d 
</p>
<p>Ja
pa
</p>
<p>n'
s 
</p>
<p>50
 
</p>
<p>pe
rc
</p>
<p>en
t 
</p>
<p>dr
op
</p>
<p> 
in
</p>
<p> 
th
</p>
<p>e 
bi
</p>
<p>rt
h 
</p>
<p>ra
te
</p>
<p> 
in
</p>
<p> 
10
</p>
<p>. 
"M
</p>
<p>ed
iu
</p>
<p>m
 
</p>
<p>va
ri
</p>
<p>an
t"
</p>
<p> U
.N
</p>
<p>. 
pr
</p>
<p>oj
ec
</p>
<p>ti
on
</p>
<p>s 
co
</p>
<p>m
pu
</p>
<p>te
d 
</p>
<p>ju
st
</p>
<p> 1
7 
</p>
<p>ye
ar
</p>
<p>s 
be
</p>
<p>fo
re
</p>
<p> 
19
</p>
<p>75
 
</p>
<p>ov
er
</p>
<p>es
ti
</p>
<p>m
at
</p>
<p>e 
R
</p>
<p>us
si
</p>
<p>a'
s 
</p>
<p>po
pu
</p>
<p>la
ti
</p>
<p>on
 b
</p>
<p>y 
10
</p>
<p> t
o 
</p>
<p>20
 m
</p>
<p>il
li
</p>
<p>on
, 
</p>
<p>an
d 
</p>
<p>un
de
</p>
<p>r-
es
</p>
<p>ti
m
</p>
<p>at
e 
</p>
<p>In
di
</p>
<p>a'
s 
</p>
<p>b
y
</p>
<p> 5
0 
</p>
<p>m
ill
</p>
<p>io
n.
</p>
<p> E
ve
</p>
<p>n 
pr
</p>
<p>oj
ec
</p>
<p>-
ti
</p>
<p>on
s 
</p>
<p>fo
r 
</p>
<p>th
e 
</p>
<p>U
ni
</p>
<p>te
d 
</p>
<p>S
ta
</p>
<p>te
s 
</p>
<p>do
ne
</p>
<p> 
in
</p>
<p> 
19
</p>
<p>66
 
</p>
<p>ov
er
</p>
<p>es
ti
</p>
<p>m
at
</p>
<p>e 
it
</p>
<p>s 
po
</p>
<p>pu
la
</p>
<p>ti
on
</p>
<p> o
nl
</p>
<p>y 
ni
</p>
<p>ne
 y
</p>
<p>ea
rs
</p>
<p> 
la
</p>
<p>te
r 
</p>
<p>by
 o
</p>
<p>ve
r 
</p>
<p>10
 m
</p>
<p>il
li
</p>
<p>on
. 
</p>
<p>E
no
</p>
<p>rm
ou
</p>
<p>s 
as
</p>
<p> 
th
</p>
<p>at
 
</p>
<p>ga
p 
</p>
<p>m
ay
</p>
<p> s
ou
</p>
<p>nd
, 
</p>
<p>it
 s
</p>
<p>ee
m
</p>
<p>s 
qu
</p>
<p>it
e 
</p>
<p>sm
al
</p>
<p>l 
ne
</p>
<p>xt
 t
</p>
<p>o 
th
</p>
<p>os
e 
</p>
<p>of
 t
</p>
<p>he
 1
</p>
<p>93
0'
</p>
<p>s 
es
</p>
<p>ti
m
</p>
<p>at
es
</p>
<p> w
hi
</p>
<p>ch
 e
</p>
<p>xt
ra
</p>
<p>po
-
</p>
<p>la
te
</p>
<p>d 
lo
</p>
<p>w
 D
</p>
<p>ep
re
</p>
<p>ss
io
</p>
<p>n 
er
</p>
<p>a 
bi
</p>
<p>rt
h 
</p>
<p>ra
te
</p>
<p>s 
in
</p>
<p>to
 a
</p>
<p>n 
A
</p>
<p>m
er
</p>
<p>ic
an
</p>
<p> p
op
</p>
<p>ul
at
</p>
<p>io
n 
</p>
<p>pe
ak
</p>
<p>in
g 
</p>
<p>at
 1
</p>
<p>70
 m
</p>
<p>il
li
</p>
<p>on
 
</p>
<p>in
 t
</p>
<p>he
 l
</p>
<p>at
e 
</p>
<p>19
70
</p>
<p>'s 
(t
</p>
<p>he
 p
</p>
<p>op
ul
</p>
<p>at
io
</p>
<p>n 
no
</p>
<p>w
 i
</p>
<p>so
v
</p>
<p>er
 
</p>
<p>N
ic
</p>
<p>k 
E
</p>
<p>be
rs
</p>
<p>ta
dt
</p>
<p> i
s 
</p>
<p>an
 a
</p>
<p>ff
il
</p>
<p>ia
te
</p>
<p> o
f 
</p>
<p>th
e 
</p>
<p>H
ar
</p>
<p>va
rd
</p>
<p> C
en
</p>
<p>te
r 
</p>
<p>fo
r 
</p>
<p>P
op
</p>
<p>ul
at
</p>
<p>io
n 
</p>
<p>St
ud
</p>
<p>ie
s.
</p>
<p> 
</p>
<p>22
0 
</p>
<p>m
il
</p>
<p>li
on
</p>
<p>),
 a
</p>
<p>nd
 t
</p>
<p>he
n 
</p>
<p>de
cl
</p>
<p>in
in
</p>
<p>g!
 
</p>
<p>C
ou
</p>
<p>ld
 b
</p>
<p>ir
th
</p>
<p> r
at
</p>
<p>es
 i
</p>
<p>n
 t
</p>
<p>he
 l
</p>
<p>es
s 
</p>
<p>de
ve
</p>
<p>lo
pe
</p>
<p>d 
w
</p>
<p>or
ld
</p>
<p>, 
w
</p>
<p>hi
ch
</p>
<p> n
ow
</p>
<p> a
pp
</p>
<p>ea
r 
</p>
<p>to
 b
</p>
<p>e 
de
</p>
<p>cl
in
</p>
<p>in
g 
</p>
<p>at
 
</p>
<p>an
 a
</p>
<p>cc
el
</p>
<p>er
at
</p>
<p>in
g 
</p>
<p>pa
ce
</p>
<p>, 
su
</p>
<p>dd
en
</p>
<p>ly
 s
</p>
<p>ta
bi
</p>
<p>li
ze
</p>
<p>, 
o
</p>
<p>r 
ev
</p>
<p>en
 r
</p>
<p>is
e 
</p>
<p>ag
ai
</p>
<p>n?
 T
</p>
<p>hi
s 
</p>
<p>co
ul
</p>
<p>d 
th
</p>
<p>eo
re
</p>
<p>ti
ca
</p>
<p>ll
y 
</p>
<p>ha
p-
</p>
<p>pe
n.
</p>
<p> H
er
</p>
<p>e 
ar
</p>
<p>e 
fo
</p>
<p>ur
 o
</p>
<p>f 
th
</p>
<p>e 
m
</p>
<p>an
y 
</p>
<p>re
as
</p>
<p>on
s:
</p>
<p> 
I)
</p>
<p> 
T
</p>
<p>he
 m
</p>
<p>an
y 
</p>
<p>co
un
</p>
<p>tr
ie
</p>
<p>s 
w
</p>
<p>he
re
</p>
<p> f
er
</p>
<p>ti
li
</p>
<p>ty
 h
</p>
<p>as
 a
</p>
<p>s 
ye
</p>
<p>t 
be
</p>
<p>en
 u
</p>
<p>na
ff
</p>
<p>ec
te
</p>
<p>d 
b
</p>
<p>y
 t
</p>
<p>he
 d
</p>
<p>ec
li
</p>
<p>ne
 m
</p>
<p>ig
ht
</p>
<p> s
im
</p>
<p>pl
y 
</p>
<p>co
nt
</p>
<p>in
ue
</p>
<p> t
o 
</p>
<p>be
 u
</p>
<p>na
ff
</p>
<p>ec
te
</p>
<p>d 
fa
</p>
<p>r 
in
</p>
<p>to
 t
</p>
<p>he
 f
</p>
<p>ut
ur
</p>
<p>e.
 
</p>
<p>2)
 S
</p>
<p>in
ce
</p>
<p> s
te
</p>
<p>ri
li
</p>
<p>ty
 a
</p>
<p>nd
 in
</p>
<p>fe
rt
</p>
<p>il
it
</p>
<p>y 
ar
</p>
<p>e 
w
</p>
<p>id
es
</p>
<p>pr
ea
</p>
<p>d 
in
</p>
<p> m
an
</p>
<p>y 
of
</p>
<p> t
he
</p>
<p> p
oo
</p>
<p>re
st
</p>
<p> a
nd
</p>
<p> m
os
</p>
<p>t 
di
</p>
<p>se
as
</p>
<p>e-
ri
</p>
<p>d-
de
</p>
<p>n 
ar
</p>
<p>ea
s 
</p>
<p>o
f 
</p>
<p>th
e 
</p>
<p>w
or
</p>
<p>ld
, 
</p>
<p>im
pr
</p>
<p>ov
em
</p>
<p>en
ts
</p>
<p> 
in
</p>
<p> 
he
</p>
<p>al
th
</p>
<p> a
nd
</p>
<p> n
ut
</p>
<p>ri
ti
</p>
<p>on
 t
</p>
<p>he
re
</p>
<p> c
ou
</p>
<p>ld
 r
</p>
<p>ai
se
</p>
<p> b
ir
</p>
<p>th
 
</p>
<p>ra
te
</p>
<p>s.
 
</p>
<p>3)
 
</p>
<p>T
he
</p>
<p> 
G
</p>
<p>an
dh
</p>
<p>i 
re
</p>
<p>gi
m
</p>
<p>e'
s 
</p>
<p>co
ld
</p>
<p>-h
ea
</p>
<p>rt
ed
</p>
<p> 
an
</p>
<p>d 
ar
</p>
<p>bi
tr
</p>
<p>ar
y 
</p>
<p>m
as
</p>
<p>s 
st
</p>
<p>er
il
</p>
<p>iz
at
</p>
<p>io
n 
</p>
<p>re
gi
</p>
<p>m
en
</p>
<p> m
ay
</p>
<p> 
ha
</p>
<p>ve
 h
</p>
<p>ar
de
</p>
<p>ne
d 
</p>
<p>th
at
</p>
<p> s
ix
</p>
<p>th
 o
</p>
<p>f 
th
</p>
<p>e 
w
</p>
<p>or
ld
</p>
<p> a
ga
</p>
<p>in
st
</p>
<p> 
fu
</p>
<p>tu
re
</p>
<p> f
am
</p>
<p>ily
 I
</p>
<p>im
it
</p>
<p>at
io
</p>
<p>n 
m
</p>
<p>es
sa
</p>
<p>ge
s.
</p>
<p> 4
) 
If
</p>
<p> J
o
</p>
<p>h
n
</p>
<p> 
A
</p>
<p>ir
d 
</p>
<p>o
f 
</p>
<p>th
e 
</p>
<p>D
ep
</p>
<p>ar
tm
</p>
<p>en
t 
</p>
<p>o
f 
</p>
<p>C
om
</p>
<p>m
er
</p>
<p>ce
 a
</p>
<p>nd
 
</p>
<p>ot
he
</p>
<p>rs
 a
</p>
<p>re
 c
</p>
<p>or
re
</p>
<p>ct
 t
</p>
<p>h
at
</p>
<p> C
hi
</p>
<p>na
's
</p>
<p> t
ec
</p>
<p>hn
iq
</p>
<p>ue
s 
</p>
<p>o
f 
</p>
<p>po
li
</p>
<p>ti
ca
</p>
<p>l 
m
</p>
<p>ob
il
</p>
<p>iz
at
</p>
<p>io
n 
</p>
<p>an
d 
</p>
<p>so
ci
</p>
<p>al
 p
</p>
<p>er
su
</p>
<p>as
io
</p>
<p>n 
ha
</p>
<p>ve
 
</p>
<p>in
du
</p>
<p>ce
d 
</p>
<p>m
an
</p>
<p>y 
pa
</p>
<p>re
nt
</p>
<p>s 
to
</p>
<p> 
ha
</p>
<p>ve
 
</p>
<p>fe
w
</p>
<p>er
 
</p>
<p>ch
il
</p>
<p>dr
en
</p>
<p> t
ha
</p>
<p>n 
th
</p>
<p>ey
 a
</p>
<p>ct
ua
</p>
<p>ll
y 
</p>
<p>w
an
</p>
<p>t, 
a 
</p>
<p>re
la
</p>
<p>xa
ti
</p>
<p>on
 
</p>
<p>of
 
</p>
<p>th
es
</p>
<p>e 
ru
</p>
<p>le
s 
</p>
<p>fo
r 
</p>
<p>w
ha
</p>
<p>te
ve
</p>
<p>r 
re
</p>
<p>as
on
</p>
<p>s 
m
</p>
<p>ig
ht
</p>
<p> 
m
</p>
<p>ak
e 
</p>
<p>th
e 
</p>
<p>bi
rt
</p>
<p>h 
ra
</p>
<p>te
 
</p>
<p>o
f 
</p>
<p>C
hi
</p>
<p>na
's
</p>
<p> 
en
</p>
<p>or
m
</p>
<p>ou
s 
</p>
<p>po
pu
</p>
<p>la
ti
</p>
<p>on
 r
</p>
<p>is
e.
</p>
<p> 
O
</p>
<p>ne
 o
</p>
<p>f 
th
</p>
<p>e 
on
</p>
<p>ly
 l
</p>
<p>on
g-
</p>
<p>te
rm
</p>
<p> 
ru
</p>
<p>le
s 
</p>
<p>ab
ou
</p>
<p>t 
po
</p>
<p>pu
la
</p>
<p>ti
on
</p>
<p> p
ro
</p>
<p>je
ct
</p>
<p>io
ns
</p>
<p> w
hi
</p>
<p>ch
 h
</p>
<p>as
 
</p>
<p>he
ld
</p>
<p> u
p 
</p>
<p>is
 t
</p>
<p>ha
t 
</p>
<p>w
it
</p>
<p>hi
n 
</p>
<p>th
ei
</p>
<p>r 
li
</p>
<p>m
it
</p>
<p>s 
of
</p>
<p> a
cc
</p>
<p>ur
ac
</p>
<p>y 
(a
</p>
<p>bo
ut
</p>
<p> f
iv
</p>
<p>e 
ye
</p>
<p>ar
s 
</p>
<p>in
 t
</p>
<p>he
 f
</p>
<p>ut
ur
</p>
<p>e)
 t
</p>
<p>he
y 
</p>
<p>ca
n 
</p>
<p>te
ll 
</p>
<p>no
th
</p>
<p>in
g 
</p>
<p>in
te
</p>
<p>re
st
</p>
<p>in
g,
</p>
<p> a
nd
</p>
<p> w
he
</p>
<p>n 
th
</p>
<p>ey
 s
</p>
<p>ta
rt
</p>
<p> g
iv
</p>
<p>-
in
</p>
<p>g 
in
</p>
<p>te
re
</p>
<p>st
in
</p>
<p>g 
re
</p>
<p>su
lt
</p>
<p>s,
 
</p>
<p>th
ey
</p>
<p> 
ar
</p>
<p>e 
no
</p>
<p> 
Io
</p>
<p>ng
er
</p>
<p> 
ac
</p>
<p>cu
ra
</p>
<p>te
. </p>
<p/>
</div>
<div class="page"><p/>
<p>1.5 Population models 
</p>
<p>References 
</p>
<p>1. Gause, G. F., The Struggle for Existence, Dover Publications, New York, 1964. 
</p>
<p>2. Pearl and Reed, Proceedings of the National Academy of Sciences, 1920, p. 275. 
</p>
<p>EXERCISES 
</p>
<p>1. Prove that (a- bp0)j(a- bp(t)) is positive for t0 &lt; t &lt; oo. Hint: Use Equation (2) 
to show thatp(t) can never equal ajb ifp0 =!=a/b. 
</p>
<p>2. (a) Choose 3 times t0, t 1, and t2, with t 1 - t0 = t2 - t 1&bull; Show that (3) determines a 
and b uniquely in terms of t0,p(t0), t1,p(t1), t2, andp(t2). 
</p>
<p>(b) Show that the period of accelerated growth for the United States ended in 
April, 1913. 
</p>
<p>(c) Let a populationp(t) grow according to the logistic law (3), and let t be the 
time at which half the limiting population is achieved. Show that 
</p>
<p>a/b p ( t) = _ _____:___ __ 
I+ e-a(r-1) 
</p>
<p>3. In 1879 and 1881 a number of yearling hass were seined in New Jersey, taken 
across the continent in tanks by train, and planted in San Francisco Bay. A total 
of only 435 Striped Bass survived the rigors of these two trips. Yet, in 1899, the 
commercial net catch alone was 1,234,000 pounds. Since the growth of this 
population was so fast, it is reasonable to assume that it obeyed the Malthusian 
law dp / dt = ap. Assuming that the average weight of a hass fish is three pounds, 
and that in 1899 every tenth hass fish was caught, find a lower bound for a. 
</p>
<p>4. Suppose that a population doubles its original size in 100 years, and triples it in 
200 years. Show that this population cannot satisfy the Malthusian law of 
population growth. 
</p>
<p>5. Assurne that p ( t) satisfies the Malthusian law of population growth. Show that 
the increases in p in successive time intervals of equal duration form the terms of 
a geometric progression. This is the source of Thomas Malthus' famous dieturn 
"Population wh.en unchecked increases in a geometrical ratio. Subsistence 
increases only in an arithmetic ratio. A slight acquaintance with numbers will 
show the immensity of the firstpower in comparison of the second." 
</p>
<p>6. A population grows according to the 1ogistic 1aw, with a 1imiting population of 
5 X 108 individuals. When the population is low it doubles every 40 minutes. 
What will the population be after two hours if initially it is (a) 108, (b) 109? 
</p>
<p>7. A family of salmon fish living off the Alaskan Coast obeys the Malthusian law 
of population growth dp(t)/ dt = 0.003p(t), where t is measured in minutes. At 
time t = 0 a group of sharks establishes residence in these waters and begins 
attacking the salmon. The rate at which salmon are killed by the sharks is 
0.001p 2(t), where p(t) is the population of salmon at timet. Moreover, since an 
undesirable element has moved into their neighborhood, 0.002 salmon per 
minute leave the Alaskan waters. 
(a) Modify the Malthusian law of population growth to take these two factors 
</p>
<p>into account. 
</p>
<p>37 </p>
<p/>
</div>
<div class="page"><p/>
<p>First-order differential equations 
</p>
<p>(b) Assurne that at time t=O there are one million salmon. Find the popu1ation 
</p>
<p>p(t). What happens as t~oo? 
</p>
<p>(c) Show that the above mode1 is rea11y absurd. Hint: Show, according to this 
</p>
<p>model, that the salmon population decreases from one rnillion to about one 
thousand in one rninute. 
</p>
<p>8. The population of New York City wou1d satisfy the logistic law 
</p>
<p>dp 1 1 2 
dt = 25 p- (25)1&lt;f p' 
</p>
<p>where t is measured in years, if we neglected the high emigration and homicide 
rates. 
(a) Modify this equation to take into account the fact that 9,000 people per year 
</p>
<p>move from the city, and 1,000 people per year are murdered. 
(b) Assurne that the popu1ation of New York City was 8,000,000 in 1970. Find 
</p>
<p>the popu1ation for all future time. What happens as t~oo? 
</p>
<p>9. An initial population of 50,000 inhabits a rnicrocosm with a carrying capacity of 
100,000. After five years, the popu1ation has increased to 60,000. Show that the 
</p>
<p>natural growth rate a for this popu1ation is (l/5)1n3j2. 
</p>
<p>10. W e can mode1 a population which becomes susceptible to epidemics in the 
</p>
<p>following manner. Assurne that our popu1ation is originally governed by the lo-
gistic law 
</p>
<p>38 
</p>
<p>dp 2 
-=ap-bp 
dt 
</p>
<p>(i) 
</p>
<p>and that an epidemic strikes as soon as p reaches a certain value Q, with Q less 
</p>
<p>than the limiting population a I b. At this stage the vital coefficients become 
A &lt; a, B &lt; b, and Equation (i) is replaced by 
</p>
<p>dp 2 
dt =Ap-Bp. (ii) 
</p>
<p>Suppose that Q &gt;AI B. The population then starts decreasing. A point is 
reached when the population falls below a certain value q &gt; A / B. At this mo-
ment the epidemic ceases and the popu1ation again begins to grow following 
</p>
<p>Equation (i), unti1 the incidence of a fresh epidemic. In this way there are peri-
odic fluctuations of p between q and Q. We now indicate how to calculate the 
period T of these fluctuations. 
(a) Show that the time; T1 taken by the first part of the cycle, when p increases 
</p>
<p>from q to Q is given by 
</p>
<p>1 Q(a-bq) 
T1= -1n ( Q). a q a-b 
</p>
<p>(b) Show that the time T2 taken by the second part of the cycle, when p de-
creases from Q to q is given by 
</p>
<p>1 q(QB-A) 
T2 = -A 1n ( ) . Q qB-A 
</p>
<p>Thus, the time for the entire cycle is T1 + T2&bull; </p>
<p/>
</div>
<div class="page"><p/>
<p>1.6 The spread of technological innovations 
</p>
<p>11. lt has been observed that plagues appear in mice populations whenever the 
population becomes too !arge. Further, a local increase of density attracts preda-
tors in !arge numbcrs. These two factors will succeed in destroying 97-98% of a 
population of small rodents in two or three weeks, and the density then falls to a 
Ievel at which the disease cannot spread. The population, reduced to 2% of its 
maximum, finds its refuges from the predators sufficient, and its food abundant. 
The population therefore begins to grow agairr until it reaches a Ievel favorable 
to another wave of disease and predation. Now, the speed of reproduction in 
mice is so great that we may set b = 0 in Equation (i) of Exercise 7. In the second 
part of the cycle, on the contrary, A is very small in comparison with B, and it 
may be neglected therefore in Equation (ii). 
(a) Under these assumptions, show that 
</p>
<p>l Q Q-q 
T1=-ln- and T2=--. 
</p>
<p>a q qQB 
</p>
<p>(b) Assuming that T1 is approximately four years, and Q/ q is approximately 
fifty, show that a is approximately one. This value of a, incidentally, corre-
sponds very well with the rate of multiplication of mice in natural circums-
tances. 
</p>
<p>12. There are many important classes of organisms whose birth rate is not propor-
tional to the population size. Suppose, for example, that each member of the 
population requires a partner for reproduction, and that each member relies on 
chance encounters for meeting a mate. If the expected number of encounters is 
proportional to the product of the numbers of males and females, and if these 
are equally distributed in the population, then the number of encounters, and 
hence the birthrate too, is proportional to p 2&bull; The death rate is still proportional 
top. Consequently, the population size p(t) satisfies the differential equation 
</p>
<p>dp- 2 
dt - bp - ap, a,b &gt;0. 
</p>
<p>Show that p(t) approaches 0 as t-HX:J if Po&lt; a / b. Thus, once the population size 
drops below the critical size aj b, the population tends to extinction. Thus, a 
species is classified endaugered if its current size is perilously close to its critical 
size. 
</p>
<p>1.6 The spread of technological innovations 
</p>
<p>Economists and sociologists have long been concerned with how a techno-
logical change, or innovation, spreads in an industry. Once an innovation 
is introduced by one firm, how soon do others in the industry come to 
adopt it, and what factors determine how rapidly they follow? In this sec-
tion we construct a model of the spread of innovations among farmers, 
and then show that this same model also describes the spread of innova-
tions in such diverse industries as bituminous coal, iron and steel, brewing, 
and railroads. 
</p>
<p>Assurne that a new innovation is introduced into a fixed community of 
N farmers at time t=O. Letp(t) denote the number of farmers who have 
</p>
<p>39 </p>
<p/>
</div>
<div class="page"><p/>
<p>I First-order differential equations 
</p>
<p>adopted at time t. As in the previous section, we make the approximation 
thatp(t) is a continuous function of time, even though it obviously changes 
by integer amounts. The simplest realistic assumption that we can make 
concerning the spread of this innovation is that a farmer adopts the in-
novation only after he has been told of it by a farmer who has already 
adopted. Then, the number of farmers l::ip who adopt the innovation in a 
small time interval l::it is directly proportional to the number of farmers p 
who have already adopted, and the number of farmers N-p who are as 
yet unaware. Hence, l::ip = cp(N- p)l::it or l::ip / l::it = cp(N- p) for some posi-
tive constant c. Letting l::it~O, we obtain the differential equation 
</p>
<p>dp 
dt = cp(N- p). (1) 
</p>
<p>This is the logistic equation of the previous section if we set a = cN, b = c. 
Assuming that p (0) = 1; i.e., one farmer has adopted the innovation at time 
t = 0, we see that p ( t) satisfies the initial-value problern 
</p>
<p>dp 
dt =cp(N-p), p(O)=l. (2) 
</p>
<p>The solution of (2) is 
</p>
<p>NecNt 
p{t)= N 1 cNt (3) 
</p>
<p>- +e 
</p>
<p>which is a logistic function (see Section 1.5). Hence, our model predicts 
that the adoption process accelerates up to that point at which half the 
community is aware of the innovation. After this point, the adoption pro-
cess begins to decelerate until it eventually reaches zero. 
</p>
<p>Let us compare the predictions of our model with data on the spread of 
two innovations through American farming communities in the middle 
1950's. Figure 1 represents the cumulative number of farmers in Iowa 
during 1944-1955 who adopted 2,4-D weed spray, and Figure 2 represents 
the cumulative percentage of corn acreage in hybrid corn in three Ameri-
can states during the years 1934-1958. The circles in these figures are the 
actual measurements, and the graphs were obtained by connecting these 
measurements with straight lines. As can be seen, these curves have all the 
properties of logistic curves, and on the whole, offer very good agreement 
with our model. However, there are two discrepancies. First, the actual 
point at which the adoption process ceases to aceeierate is not always when 
fifty per cent of the population has adopted the innovation. As can be seen 
from Figure 2, the adoption process for hybrid corn began to decelerate in 
Alabama only after nearly sixty per cent of the farmers had adopted the 
innovation. Second, the agreement with our model is much better in the 
later stages of the adoption process than in the earlier stages. 
</p>
<p>The source of the second discrepancy is our assumption that a farmer 
only learns of an innovation through contact with another farmer. This is 
not entirely true. Studies have shown that mass communication media such 
</p>
<p>40 </p>
<p/>
</div>
<div class="page"><p/>
<p>Cl) 
120 a: 
</p>
<p>1&amp;.1 
:::E 
a: 
~ 100 ... 
0 
</p>
<p>a: 80 1&amp;.1 
CD 
:::E 
:::) 
</p>
<p>z 60 
1&amp;.1 
&gt; 
i= 
ct 40 ...J 
:::) 
</p>
<p>:::E 
:::) 
</p>
<p>u 20 
</p>
<p>0 2 4 6 8 10 12 
TIME IN YEARS 
</p>
<p>Figure 1. Cumulative number of farmers who adopted 2,4-D weed spray in Iowa 
</p>
<p>0 
ii: 
CD 
&gt;-::r: 
~ 
</p>
<p>1&amp;.1 
c,:) 
ct 
1&amp;.1 
a:z 
</p>
<p>:&sect; 
a: 
0 
u ... 
0 
</p>
<p>~ 
</p>
<p>1&amp;.1 
~ 
</p>
<p>~ 
...J 
:::) 
</p>
<p>:::E 
:::) 
</p>
<p>u 
</p>
<p>100 
</p>
<p>10 
</p>
<p>1934 'Je '42 '46 'so '54 '58 
YEARS 
</p>
<p>Figure 2. Cumulative percentage of com acreage in hybrid com in three American 
states </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>as radio, television, newspapers and farmers' magazines play a !arge role in 
the early stages of the adoption process. Therefore, we must add a term to 
the differential equation (1) to take this into account. To compute this 
term, we assume that the number of farmers !lp who learn of the innova-
tion through the mass communication media in a short period of time !lt is 
proportional to the number of farmers who do not yet know; i.e., 
</p>
<p>!lp = c'(N-p )!lt 
for some positive constant c'. Letting !lt~O, we see that c'(N-p) farmers, 
per unit time, learn of the innovation through the mass communication 
media. Thus, if p(O)=O, thenp(t) satisfies the initial-value problern 
</p>
<p>dp 
dt =cp(N-p)+c'(N-p), p(O)=O. (4) 
</p>
<p>The solution of ( 4) is 
Ne'[ e(c'+cN)t_l] 
</p>
<p>p(t)= cN+c'e(c'+cN)t, (5) 
</p>
<p>and in Exercises 2 and 3 we indicate how to determine the shape of the 
curve (5). 
</p>
<p>The corrected curve (5) now gives remarkably good agreement with Fig-
ures 1 and 2, for suitable choices of c and c'. However, (see Exercise 3c) it 
still doesn't explain why the adoption of hybrid corn in Alabama only be-
gan to decelerate after sixty per cent of the farmers had adopted the in-
novation. This indicates, of course, that other factors, such as the time in-
terval that elapses between when a farmer first learns of an innovation and 
when he actually adopts it, may play an important role in the adoption 
process, and must be taken into account in any model. 
</p>
<p>We would now like to show that the differential equation 
</p>
<p>dp / dt = cp (N-p) 
</p>
<p>also governs the rate at which firms in such diverse industries as bi-
tuminous coal, iron and steel, brewing, and railroads adopted several 
major innovations in the first part of this century. This is rather surprising, 
since we would expect that the number of firms adopting an innovation in 
one of these industries certainly depends on the profitability of the innova-
tion and the investment required to implement it, and we haven't men-
tioned these factors in deriving Equation (1). However, as we shall see 
shortly, these two factors are incorporated in the constant c. 
</p>
<p>Let n be the total number of firms in a particular industry who have 
adopted an innovation at time t. lt is clear that the number of firms !lp 
who adopt the innovation in a short time interval !lt is proportional to the 
number of firms n-p who have not yet adopted; i.e., !lp ='A.(n-p)!lt. Let-
ting !lt ~o. we see that 
</p>
<p>dp 
dt ='A.(n-p). 
</p>
<p>42 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.6 The spread of technological innovations 
</p>
<p>The proportionality factor A. depends on the profitability '1T of installing this 
innovation relative to that of alternative investments, the investment s re-
quired to instaU this innovation as a percentage of the total assets of the 
firm, and the percentage of firms who have already adopted. Thus, 
</p>
<p>A.=j(?T,s,pjn). 
</p>
<p>Expanding f in a Taylor series, and dropping terms of degree more than 
two, gives 
</p>
<p>\ p 2 2 l\=a 1+a2?T+a3s+a4 -+a5?T +a6s +a1?Ts n 
</p>
<p>+as'IT( :)+a9s( :)+aw( :t 
In the late 1950's, Edwin Mansfield of Carnegie Mellon University in-
vestigated the spread of twelve innovations in four major industries. From 
his exhaustive studies, Mansfield concluded that a 10 = 0 and 
</p>
<p>a 1 + a2'1T + a3s + a5?T 2 + a6s2 + a1?Ts = 0. 
Thus, setting 
</p>
<p>(6) 
we see that 
</p>
<p>dp p 
-=k-(n-p). 
dt n 
</p>
<p>(This is the equation obtained previously for the spread of innovations 
among farmers, if we set kjn=c.) We assume that the innovation is first 
adopted by one firm in the year t0&bull; Then, p ( t) satisfies the initial-value 
problern 
</p>
<p>dp k 
- =- p(n-p), 
dt n 
</p>
<p>p(t0 )=I (7) 
</p>
<p>and this implies that 
</p>
<p>p(t)= n 
1 +(n-l)e-k(r-ro). 
</p>
<p>Mansfield studied how rapidly the use of twelve innovations spread 
from enterprise to enterprise in four major industries-bituminous coal, 
iron and steel, brewing, and railroads. The innovations are the shuttle car, 
trackless mobile loader, and continuous mining machine (in bituminous 
coal); the by-product coke oven, continuous wide strip mill, and continu-
ous annealing line for tin plate (in iron and steel); the pallet-loading 
machine, tin container, and high speed bottle fillcr (in brewing); and the 
diesei locomotive, centralized traffic control, and car retarders (in rail-
roads). His results are described graphically in Figure 3. For all but the 
by-product coke oven and tin container, the percentages given are for ev-
ery two years from the year of initial introduction. The length of the inter-
val for the by-product coke oven is about six years, and for the tin con-
tainer, it is six months. Notice how all these curves have the general ap-
pearance of a logistic curve. 
</p>
<p>43 </p>
<p/>
</div>
<div class="page"><p/>
<p>1/) 
100 
</p>
<p>:E I 
ct: I 
u. 80 I 
</p>
<p>ct: /-sc 
0 60 .., I I 
&lt;( I I 
</p>
<p>:E CO- I I 40 I I u. i I 0 
TC-1 1 
</p>
<p>~ 20 ,, &bull; t 
tl 
</p>
<p>0 ' 
</p>
<p>1890 1900 '10 '20 '30 '40 'so 
YEAR 
</p>
<p>(a) 
</p>
<p>100 
1/) 
</p>
<p>I I 
:E 
ct: 80 i?' iJ: I ct: I 0 60 I ..., I I 
&lt;( I 
:E 40 I 
u. I 
0 CM- 1 
~ 
</p>
<p>20 I 
</p>
<p>' ' / 
1910 '20 '30 '40 'so '60 '70 
</p>
<p>YEAR 
</p>
<p>(b) 
</p>
<p>100 
Cl) 
</p>
<p>:E 80 ct: 
i:L 
ct: 60 
0 .., 
&lt;( I 
</p>
<p>2 40 I BF 
I 
</p>
<p>u. I 
0 20 I 
</p>
<p>I 
</p>
<p>at ' 
, 
</p>
<p>/ 
</p>
<p>0 / 
</p>
<p>1910 '20 '30 '40 '50 '60 '70 
</p>
<p>YEAR 
(c) 
</p>
<p>Figure 3. Growth in the percentage of major firms that introduced twelve in-
novations; bituminous coal, iron and steel, brewing, and railroad industries, 
1890--1958; (a) By-product coke oven (CO), diesei locomotive (DL), tin container 
(TC), and shuttle car (SC); (b) Car retarder (CR), trackless mobile loader (ML), 
continuous mining machine (CM), and pallet-loading machine (PL); (c) Continu-
ous wide-strip mill (SM), centralized traffic control (CTC), continuous annealing 
(CA), and highspeed bottle filler (BF). </p>
<p/>
</div>
<div class="page"><p/>
<p>1.6 The spread of techno1ogical innovations 
</p>
<p>Table 1. 
</p>
<p>Innovation n to a4 Gg a9 'TT s 
</p>
<p>Diese11ocomotive 25 1925 -0.59 0.530 -0.027 1.59 0.015 
Centra1ized traffic 
</p>
<p>contro1 24 1926 -0.59 0.530 -0.027 1.48 0.024 
Car retarders 25 1924 -0.59 0.530 -0.027 1.25 0.785 
</p>
<p>Continuous wide 
strip mill 12 1924 -0.52 0.530 -0.027 1.87 4.908 
</p>
<p>By-product coke 
oven 12 1894 -0.52 0.530 -0.027 1.47 2.083 
</p>
<p>Continuous annealing 9 1936 -0.52 0.530 -0.027 1.25 0.554 
</p>
<p>Shuttle car 15 1937 -0.57 0.530 -0.027 1.74 0.013 
Trackless mobile 
</p>
<p>loader 15 1934 -0.57 0.530 --'0.027 1.65 0.019 
Continuous mining 
</p>
<p>machine 17 1947 -0.57 0.530 -0.027 2.00 0.301 
</p>
<p>Tin container 22 1935 -0.29 0.530 -0.027 5.07 0.267 
High speed bottle 
</p>
<p>filler 16 1951 -0.29 0.530 -0.027 1.20 0.575 
Pallet-loading 
</p>
<p>machirre 19 1948 -0.29 0.530 -0.027 1.67 0.115 
</p>
<p>Foramore detailed comparison of the predictions of our model (7) with 
these observed results, we must evaluate the constants n, k, and t0 for each 
of the twelve innovations. Table 1 gives the value of n, t0, a4, a5, a9, w, and 
s for each of the twelve innovations; the constant k can then be computed 
from Equation (6). As the answers to Exercises 5 and 6 will indicate, our 
model (7) predicts with reasonable accuracy the rate of adoption of these 
twelve innovations. 
</p>
<p>Reference 
</p>
<p>Mansfield, E., "Technical change and the rate of imitation," Econometrica, Vol. 29, 
No. 4, Oct. 1961. 
</p>
<p>EXERCISES 
</p>
<p>1. Solve the initial-value problern (2). 
</p>
<p>2. Let c=O in (5). Show thatp(t) increases monotonically from 0 to N, and has no 
points of inflection. 
</p>
<p>3. Here is a heuristic argument to determine the behavior of the curve (5). If c' = 0, 
then we have a logistic curve, and if c = 0, then we have the behavior described 
in Exercise 2. Thus, if c is !arge relative to c', then we have a logistic curve, and 
if c is small relative to c' then we have the behavior illustrated in Exercise 2. 
</p>
<p>45 </p>
<p/>
</div>
<div class="page"><p/>
<p>I First-order differential equations 
</p>
<p>(a) Letp(t) satisfy (4). Show that 
</p>
<p>d2p 
dt2 =(N-p)(cp+c')(cN-2cp-c'). 
</p>
<p>(b) Show that p ( t) has a point of inflection, at which dp I dt achieves a maxi-
mum, if, and only if, c' I c &lt; N. 
</p>
<p>(c) Assurne that p(t) has a point of inflection at t= t*. Show that p(t*),;;;; N 12. 
</p>
<p>4. Solve the initial-value problern (7). 
</p>
<p>5. lt seems reasonable to take the time span between the date when 20% of the 
firms had introduced the innovation and the date when 80% of the firms had in-
troduced the innovation, as the rate of imitation. 
(a) Show from our model that this time span is 4(ln2)1 k. 
(b) Foreach of the twelve innovations, compute this time span from the data in 
</p>
<p>Table 1, and compare with the observed value in Figure 3. 
</p>
<p>6. (a) Show from our modelthat (llk)ln(n-1) years elapse before 50% of the 
firms introduce an innovation. 
</p>
<p>(b) Compute this time span for each of the 12 innovations and compare with the 
observed values in Figure 3. 
</p>
<p>1. 7 An atomic waste disposal problern 
</p>
<p>For several years the Atomic Energy Commission (now known as the 
Nuclear Regulatory Commission) had disposed of concentrated radioac-
tive waste material by placing it in tightly sealed drums which were then 
dumped at sea in fifty fathoms (300 feet) of water. When concerned ecolo-
gists and scientists questioned this practice, they were assured by the 
A.E.C. that the drums would never develop leaks. Exhaustive tests on the 
drums proved the A.E.C. right. However, several engineers then raised the 
question of whether the drums could crack from the impact of hitting the 
ocean floor. "Never," said the A.E.C. "We'll see about that," said the en-
gineers. After performing numerous experiments, the engineers found that 
the drums could crack on impact if their velocity exceeded forty feet per 
second. The problern before us, therefore, is to compute the velocity of the 
drums upon impact with the ocean floor. Tothis end, we digress briefly to 
study elementary Newtonian mechanics. 
</p>
<p>Newtonian mechanics is the study of Newton's famous laws of motion 
and their consequences. Newton's first law of motion states that an object 
will remain at rest, or move with constant velocity, if no force is acting on 
it. A force should be thought of as a push or pull. This push or pull can be 
exerted directly by something in contact with the object, or it can be ex-
erted indirectly, as the earth's pull of gravity is. 
</p>
<p>Newton's second law of motion is concerned with describing the motion 
of an object which is acted upon by several forces. Let y(t) denote the 
position of the center of gravity of the object. (We assume that the object 
moves in only one direction.) Those forces acting on the object, which tend 
</p>
<p>46 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.7 An atomic waste disposal problern 
</p>
<p>to increase y, are considered positive, while those forces tending to de-
crease y are considered negative. The resultant force F acting on an object 
is defined to be the sum of all positive forces minus the sum of all negative 
forces. Newton's second law of motion states that the acceleration d 2y / dt2 
</p>
<p>of an object is proportional to the resultant force F acting on it; i.e., 
</p>
<p>d 2y I 
-=-F 
dt2 m . 
</p>
<p>(I) 
</p>
<p>The constant m is the mass of the object. It is related to the weight W of 
the object by the relation W = mg, where g is the acceleration of gravity. 
Unless otherwise stated, we assume that the weight of an object and the ac-
celeration of gravity are constant. We will also adopt the English system of 
units, so that t is measured in seconds, y is measured in feet, and F is 
measured in pounds. The units of m are then slugs, and the gravitational 
acceleration g equals 32.2 ftjs2. 
</p>
<p>Remark. We would prefer to use the mks system of units, where y is 
measured in meters and F is measured in newtons. The units of m are then 
kilograms, and the gravitational acceleration equals 9.8 mjs 2&bull; In the third 
edition of this text, we have changed from the English system of units to the 
mks system in Section 2.6. However, changing to the mks system in this 
section would have caused undue confusion to the users of the first and 
second editions. This is because of the truncation error involved in convert-
ing from feet &middot; to meters and pounds to newtons. 
</p>
<p>We return now to our atomic waste disposal problem. As a drum de-
scends through the water, it is acted upon by three forces W, B, and D. 
The force W is the weight of the drum pulling it down, and in magnitude, 
W = 527.436 lb. The force B is the buoyancy force of the water acting on 
the drum. This force pushes the drum up, and its magnitude is the weight 
of the water displaced by the drum. Now, the Atomic Energy Commission 
used 55 gallon drums, whose volume is 7.35 ft3. The weight of one cubic 
foot of salt water is 63.99 lb. Hence B = (63.99)(7.35) = 470.327 lb. 
</p>
<p>The force D is the drag force of the water acting on the drum; it resists 
the motion of the drum through the water. Experiments have shown that 
any medium such as water, oil, and air resists the motion of an object 
through it. This resisting force acts in the direction opposite the motion, 
and is usually directly proportional to the velocity V of the object. Thus, 
D = c V, for some positive constant c. Notice that the drag force increases 
as V increases, and decreases as V decreases. To calculate D, the engineers 
conducted numerous towing experiments. They concluded that the orienta-
tion of the drum had little effect on the drag force, and that 
</p>
<p>D =0.08 V (lb;t(s). 
</p>
<p>47 </p>
<p/>
</div>
<div class="page"><p/>
<p>I First-order differential equations 
</p>
<p>Now, sety=O at sea Ievel, and Iet the direction of increasingy be down-
wards. Then, W is a positive force, and B and D are negative forces. Con-
sequently, from (1), 
</p>
<p>d 2y l g 
- = -(W-B-cV)= -(W-B-cV). 
dt2 m W 
</p>
<p>We can rewrite this equation as a first-order linear differential equation for 
V= dy / dt; i.e., 
</p>
<p>(2) 
</p>
<p>Initially, when the drum is released in the ocean, its velocity is zero. Thus, 
V ( t), the velocity of the drum, satisfies the initial-value problern 
</p>
<p>dV + cg V= _!_(W-B) V(O)=O, (3) 
dt w w ' 
</p>
<p>and this implies that 
</p>
<p>V(t)= W-B[l-e(-cg/W)t]. 
c 
</p>
<p>(4) 
</p>
<p>Equation (4) expresses the velocity of the drum as a function of time. 
In order to determine the impact velocity of the drum, we must compute 
the time t at which the drum hits the ocean floor. Unfortunately, though, it 
is impossible to find t as an explicit function of y (see Exercise 2). There-
fore, we cannot use Equation (4) to find the velocity of the drum when it 
hits the ocean floor. However, the A.E.C. can use this equation to try and 
prove that the drums do not crack on impact. To wit, observe from (4) that 
V ( t) is a monotonic increasing function of time which approaches the 
limiting value 
</p>
<p>W-B 
V=--r c 
</p>
<p>as t approaches infinity. The quantity Vr is called the terminal velocity of 
the drum. Clearly, V(t) &lt; Vr, so that the velocity of the drum when it hits 
the ocean floor is certainly less than (W-B)jc. Now, if this terminal 
velocity is less than 40 ft/s, then the drums could not possibly break on 
impact. However, 
</p>
<p>W; B = 527.43~~:70.327 = 713 _86 ft/s, 
and this is way too large. 
</p>
<p>1t should be clear now that the only way we can resolve the dispute be-
tween the A.E.C. and the engineers is to find v(y), the velocity of the drum 
as a function of position. The function v(y) is very different from the func-
tion V(t), which is the velocity of the drum as a function of time. How-
ever, these two functions are related through the equation 
</p>
<p>V(t)=v(y(t)) 
</p>
<p>48 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.7 An atomic waste disposal problern 
</p>
<p>if we express y as a function of t. By the chain rule of differentiation, 
dV I dt = (dv I dy)(dy I dt). Hence 
</p>
<p>W dv dy 
--- = W-B- e V. 
g dy dt 
</p>
<p>But dy I dt = V(t) = v(y(t)). Thus, suppressing the dependence of y on t, we 
see that v (y) satisfies the first-order differential equation 
</p>
<p>Wdv v dv g -v-=W-B-ev, or -=-. 
g dy W-B-ev dy W 
</p>
<p>Moreover, 
</p>
<p>v(O)=v(y(O))= V(O)=O. 
Hence, 
</p>
<p>(v rdr = (Y _!!_ds= gy 
) 0 W-B-er }0 W W &middot; 
</p>
<p>Now, 
</p>
<p>iv rdr lvr-(W-B)Ie W-B iv dr --::------ = dr+ --W-B-er W-B-er e W-B-er 
0 0 0 
</p>
<p>= - _!_ ( v dr + W- B ( v dr 
eJo e ) 0 W-B-er 
</p>
<p>v (W-B) JW-B-evJ 
= - -;; - e2 In W- B . 
</p>
<p>We know already that v&lt;(W-B)Ie. Consequently, W-B-ev is always 
positive, and 
</p>
<p>gy v (W-B) W-B-cv 
W =--;;- c2 In W-B . (5) 
</p>
<p>At this point, we are ready to scream in despair since we cannot find v 
as an explicit function of y from (5). This is not an insurmountable diffi-
culty, though. As we show in Section l.ll, it is quite simple, with the aid of 
a digital computer, to find v(300) from (5). We need only supply the com-
puter with a good approximation of v(300) and this is obtained in the 
following manner. The velocity v(y) of the drum satisfies the initial-value 
problern 
</p>
<p>W dv -v-= W-B-cv 
g dy ' 
</p>
<p>v(O)=O. (6) 
</p>
<p>Let us, for the moment, set e = 0 in (6) to obtain the new initial-value prob-
lern 
</p>
<p>W du -u-=W-B 
g dy ' 
</p>
<p>u(O)=O. (6') 
</p>
<p>(We have replaced v by u to avoid confusion later.) We can integrate (6') 
immediately to obtain that 
</p>
<p>[ 
2 ]1/2 
</p>
<p>or u ( y) = : ( W- B ) y . 
</p>
<p>49 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>In particular, 
</p>
<p>- [ 2g - ]112 - [ 2(32.2)(57.109)(300) ] 112 
u(300)- W ( W B )300 - 527.436 
</p>
<p>:;;,:V2092 :;:,:45.7 ft/s. 
</p>
<p>We claim, now, that u(300) is a very good approximation of v(300). The 
proof of this is as follows. First, observe that the velocity of the drum is 
always greater if there is no drag force opposing the motion. Hence, 
</p>
<p>v(300) &lt; u(300). 
</p>
<p>Second, the velocity v increases as y increases, so that v(y) &lt; v(300) for y &lt; 
300. Consequently, the drag force D of the water acting on the drum is al-
ways less than 0.08 X u(300):;;;,: 3.7 lb. Now, the resultant force W-B pull-
ing the drum down is approximately 57 .I lb, which is very !arge compared 
to D. It stands to reason, therefore, that u(y) should be a very good ap-
proximation of v(y). And indeed, this is the case, since we find numeri-
cally (see Section 1.11) that v(300)=45.1 ft/s. Thus, the drums can break 
upon impact, and the engineers were right. 
</p>
<p>Epilog. The rules of the Atomic Energy Commission now expressly for-
bid the dumping of low Ievel atomic waste at sea. This author is uncertain 
though, as to whether Western Europe has also forbidden this practice. 
</p>
<p>Remark. The methods introduced in this section can also be used to find 
the velocity of any object which is moving through a medium that resists 
the motion. We just disregard the buoyancy force if the medium is not 
water. For example, Iet V(t) denote the velocity of a parachutist falling to 
earth under the influence of gravity. Then, 
</p>
<p>where W is the weight of the man and the parachute, and D is the drag 
force exerted by the atmosphere on the falling parachutist. The drag force 
on a bluff object in air, or in any fluid of small viscosity is usually very 
nearly proportional to V 2&bull; Proportionality to V is the exceptional case, and 
occurs only at very low speeds. The criterion as to whether the square or 
the linear law applies is the "Reynolds number" 
</p>
<p>R=pVLjp.. 
</p>
<p>L is a representative length dimension of the object, and p and p. are the 
density and viscosity of the fluid. If R &lt; 10, then D- V, and if R &gt; 103, 
D- V 2&bull; For 10&lt; R &lt; 103, neither law is accurate. 
</p>
<p>50 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.7 An atomic waste disposal problern 
</p>
<p>ExERCISES 
</p>
<p>1. Solve the initial-value problern (3). 
</p>
<p>2. Solve for y = y(t) from (4), and then show that the equation y = y(t) cannot be 
solved explicitly for t = t(y ). 
</p>
<p>3. Show that the drums of atomic waste will not crack upon impact if they are 
dropped into L feet of water with (2g(W-B)L/W) 112 &lt;40. 
</p>
<p>4. Fat Richie, an enormous underworld hoodlum weighing 400 lb, was pushed out 
of a penthouse window 2800 feet above the ground in New York City. Neglect-
ing air resistance find (a) the velocity with which Fat Richie hit the ground; (b) 
the time elapsed before Fat Richie hit the ground. 
</p>
<p>5. An object weighing 300 lb is dropped into a river 150 feet deep. The volume of 
the object is 2 ft3, and the drag force exerted by the water on it is 0.05 times its 
velocity. The drag force may be considered negligible if it does not exceed 5% 
of the resultant force pulling the drum down. Prove that the drag force is negli-
gible in this case. (Here B=2(62.4)= 124.8.) 
</p>
<p>6. A 400 lb sphere of volume 4'77 /3 and a 300 lb cylinder of volume '7T are simulta-
neously released from rest into a river. The drag force exerted by the water on 
the falling sphere and cylinder is .\Vs and .\Vc, respectively, where Vs and Vc 
are the velocities of the sphere and cylinder, and ,\ is a positive constant. De-
termine which object reaches the bottom of the river first. 
</p>
<p>7. A parachutist falls from rest toward earth. The combined weight of man and 
parachute is 161 lb. Before the parachute opens, the air resistance equals V /2. 
The parachute opens 5 seconds after the fall begins; and the air resistance is 
then V 2 /2. Find the Velocity V(t) of the parachutist after the parachute opens. 
</p>
<p>8. A man wearing a parachute jumps from a great height. The combined weight 
of man and parachute is 161 lb. Let V (t) denote his speed at time t seconds 
after the fall begins. During the first 10 seconds, the air resistance is V /2. 
Thereafter, while the parachute is open, the air resistance is 10 V. Find an ex-
plicit formula for V(t) at any timet greater than 10 seconds. 
</p>
<p>9. An object of mass m is projected vertically downward with initial velocity V0 in 
a medium offering resistance proportional to the square root of the magnitude 
of the velocity. 
(a) Find a relation between the velocity V and the time t if the drag force 
</p>
<p>equals cYV. 
(b) Find the terminal velocity of the object. Hint: You can find the terminal 
</p>
<p>velocity even though you cannot solve for V ( t). 
</p>
<p>10. A body of mass m falls from rest in a medium offering resistance proportional 
to the square of the velocity; that is, D = c V 2&bull; Find V (t) and compute the 
terminal velocity Vr-
</p>
<p>11. A body of mass m is projected upward from the earth's surface with an initial 
velocity V0. Take the y-axis to be positive upward, with the origin on the 
surface of the earth. Assuming there is no air resistance, but taking into 
</p>
<p>51 </p>
<p/>
</div>
<div class="page"><p/>
<p>First-order differential equations 
</p>
<p>account the variation of the earth's gravitational field with altitude, we obtain 
that 
</p>
<p>dV mgR2 
m- = - ------=-
</p>
<p>dt (y + R )2 
</p>
<p>where R is the radius of the earth. 
(a) Let V(t)=v(y(t)). Find a differential equation satisfied by v(y). 
(b) Find the smallest initial velocity V0 for which the body will not return to 
</p>
<p>earth. This is the so-called escape velocity. Hint: The escape velocity is 
found by requiring that v(y) remain strictly positive. 
</p>
<p>12. lt is not really necessary to find v(y) explicitly in order to prove that v(300) 
exceeds 40 ftjs. Hereis an alternate proof. Observe first that v(y) increases as 
y increases. This implies that y is a monotonic increasing function of v. There-
fore, if y is less than 300ft when v is 40 ftjs, then v must be greater than 40 
ftjs wheny is 300ft. Substitute v=40 ft/s in Equation (5), and show thaty is 
less than 300 ft. Conclude, therefore, that the drums can break upon impact. 
</p>
<p>1.8 The dynamics of tumor growth, mixing problems 
and orthogonal trajectories 
</p>
<p>In this section we present three very simple but extremely useful applica-
tions of first-order equations. The first application concerns the growth of 
solid tumors; the second application is concerned with "mixing problems" 
or "compartment analysis"; and the third application shows how to find a 
family of curves which is orthogonal to a given family of curves. 
</p>
<p>(a) The dynamics of tumor growth 
</p>
<p>It has been observed experimentally, that "frec living" dividing cells, such 
as bacteria cells, grow at a rate proportional to the volume of dividing cells 
at that moment. Let V(t) denote the volume of dividing cells at time t. 
Then, 
</p>
<p>dV =AV 
dt 
</p>
<p>for some positive constant A. The solution of (1) is 
</p>
<p>V(t)= V0eA&lt;t-to) 
</p>
<p>(1) 
</p>
<p>(2) 
</p>
<p>where V0 is the volume of dividing cells at the initial time t0&bull; Thus, free 
living dividing cells grow exponential!y with time. One important con-
sequence of (2) is that the volume of cells keeps doubling (see Exercise 1) 
every time interval of length ln2/A. 
</p>
<p>On the other hand, solid tumors do not grow exponentially with time. 
As the tumor becomes !arger, the doubling time of the total tumor volume 
continuously increases. Various researchers have shown that the data for 
many solid tumors is fitted remarkably well, over almost a 1000 fold in-
</p>
<p>52 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.8 The dynamics of tumor growth, mixing probleins, and orthogonal trajectories 
</p>
<p>crease in tumor volume, by the equation 
</p>
<p>V(t) = V0 exp( ~(I -exp(- at))) (3) 
</p>
<p>where exp(x) = eX, and A. and a are positive constants. 
Equation (3) is usually referred to as a Gompertzian relation. lt says 
</p>
<p>that the tumor grows more and more slowly with the passage of time, and 
that it ultimately approaches the limiting volume V 0 e"~". Medical re-
searchers have long been concerned with explaining this deviation from 
simple exponential growth. A great deal of insight into this problern can be 
gained by finding a differential equation satisfied by V ( t). Differentiating 
(3) gives 
</p>
<p>~ = V0 A.exp(- at) exp( ~(1-exp(- a(t)))) 
</p>
<p>(4) 
</p>
<p>Two conflicting theories have been advanced for the dynamics of tumor 
growth. They correspond to the two arrangements 
</p>
<p>dV = (A.e - at ) V 
dt 
</p>
<p>dV =A.(e-atV) 
dt 
</p>
<p>(4a) 
</p>
<p>(4b) 
</p>
<p>of the differential equation (4). According to the first theory, the retarding 
effect of tumor growth is due to an increase in the mean generation time of 
the cells, without a change in the proportion of reproducing cells. As time 
goes on, the reproducing cells mature, or age, and thus divide more slowly. 
This theory corresponds to the bracketing (a). 
</p>
<p>The bracketing (b) suggests that the mean generation time of the divid-
ing cells remains constant, and the retardation of growth is due to a loss in 
reproductive cells in the tumor. One possible explanation for this is that a 
necrotic region develops in the center of the tumor. This necrosis appears at 
a critical size for a particular type of tumor, and thereafter the necrotic 
"core" increases rapidly as the total tumor mass increases. According to 
this theory, a necrotic core develops because in many tumors the supply of 
blood, and thus of oxygen and nutrients, is almost completely confined to 
the surface of the tumor and a short distance beneath it. As the tumor 
grows, the supply of oxygen to the central core by diffusion becomes more 
and more difficult resulting in the formation of a necrotic core. 
</p>
<p>(b) Mixing problems 
</p>
<p>Many important problems in biology and engineering can be put into the 
following framework. A solution containing a fixed concentration of sub-
stance x f!ows into a tank, or compartment, containing the substance x 
and possibly other substances, at a specified rate. The mixture is stirred 
</p>
<p>53 </p>
<p/>
</div>
<div class="page"><p/>
<p>l First-order differential equations 
</p>
<p>together very rapidly, and then leaves the tank, again at a specified rate. 
Find the concentration of substance x in the tank at any time t. 
</p>
<p>Problems of this type fall under the general heading of "mixing prob-
lems," or compartment analysis. The following example illustrates how to 
solve these problems. 
</p>
<p>Example 1. A tank contains S0 lb of salt dissolved in 200 gallons of water. 
Starting at time t = 0, water containing t lb of salt per gallon enters the 
tank at the rate of 4 gal/min, and the well stirred solution leaves the tank 
at the same rate. Find the concentration of salt in the tank at any time t &gt; 
0. 
Solution. Let S (t) denote the amount of salt in the tank at time t. Then, 
S'(t), which is the rate of change of salt in the tank at time t, must equal 
the rate at which salt enters the tank minus the rate at which it leaves the 
tank. Obviously, the rate at which salt enters the tank is 
</p>
<p>t lbjgal times 4 gal/min=2lb/min. 
After a moment's reflection, it is also obvious that the rate at which salt 
leaves the tank is 
</p>
<p>Thus 
</p>
<p>and this implies that 
</p>
<p>. . S(t) 
4 galjmm ttmes 200 . 
</p>
<p>s (t) 
S'(t)=2- SO, S(O)= S0, 
</p>
<p>S (t) = Soe-0.021 + 100( 1- e-0.021). 
</p>
<p>Hence, the concentration c(t) of salt in the tank is given by 
</p>
<p>S(t) S0 
c(t)= 200 = 200e-0.021+i(l-e-o.021). 
</p>
<p>(5) 
</p>
<p>(6) 
</p>
<p>Remark. The first term on the right-hand side of (5) represents the por-
tion of the original amount of salt remaining in the tank at time t. This 
term becomes smaller and smaller with the passage of time as the original 
solution is drained from the tank. The second term on the right-hand side 
of (5) represents the amount of salt in the tank at time t due to the action 
of the flow process. Clearly, the amount of salt in the tank must ultimately 
approach the limiting value of 100 lb, and this is easily verified by letting t 
approach oo in (5). 
</p>
<p>(c) Orthogonal trajectories 
</p>
<p>In many physical applications, it is often necessary to find the orthogonal 
trajectories of a given family of curves. (A curve which intersects each 
</p>
<p>54 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.8 The dynamics of tumor growth, mixing problems, and orthogonal trajectories 
</p>
<p>member of a family of curves at right angles is called an orthogonal trajec-
tory of the given family.) For example, a charged particle moving under 
the influence of a magnetic field always travels on a curve which is per-
pendicular to each of the magnetic field lines. The problern of computing 
orthogonal trajectories of a family of curves can be solved in the following 
manner. Let the given family of curves be described by the relation 
</p>
<p>F(x,y,c)=O. 
</p>
<p>Differentiating this equation yields 
</p>
<p>Fx 
or y'=- y&middot; 
</p>
<p>y 
</p>
<p>(7) 
</p>
<p>(8) 
</p>
<p>Next, we solve for c= c(x,y) from (7) and replace every c in (8) by this 
value c(x,y). Finally, since the slopes of curves which intersect orthogo-
nally are negative reciprocals of each other, we see that the orthogonal 
trajectories of (7) are the solution curves of the equation 
</p>
<p>FY 
y'=--p&middot; 
</p>
<p>X 
</p>
<p>Example 2. Find the orthogonal trajectories of the family of parabolas 
</p>
<p>x= cy 2&bull; 
</p>
<p>(9) 
</p>
<p>Solution. Differentiating the equation x = cy 2 gives I= 2cyy'. Since c = 
x / y 2, we see that y' = y j2x. Thus, the orthogonal trajectories of the family 
</p>
<p>y 
</p>
<p>Figure I. The parabolas x = cy 2 and their orthogonal trajectories 
</p>
<p>55 </p>
<p/>
</div>
<div class="page"><p/>
<p>l First-order differential equations 
</p>
<p>of parabolas x = cy 2 are the solution curves of the equation 
</p>
<p>, 2x 
y =--. 
</p>
<p>y 
</p>
<p>This equation is separable, and its solution is 
</p>
<p>y2+2x2=k2. 
</p>
<p>(10) 
</p>
<p>(11) 
</p>
<p>Thus, the family of ellipses (11) (see Figure 1) are the orthogonal trajecto-
ries of the family of parabolas x = cy 2&bull; 
</p>
<p>Reference 
</p>
<p>Burton, Alan C., Rate of growth of solid tumors as a problern of diffusion, Growth, 
1966, vol. 30, pp. 157-176. 
</p>
<p>EXERCISES 
</p>
<p>1. A given substance satisfies the exponential growth law (!).Show that the graph 
of In V versus t is a straight line. 
</p>
<p>2. A substance x multiplies exponentially, and a given quantity of the substance 
doubles every 20 years. lf we have 3 lb of substance x at the present time, how 
many lb will we have 7 years from now? 
</p>
<p>3. A substance x decays exponentially, and only half of the given quantity of x 
remains after 2 years. How long does it take for 5 lb of x to decay to l lb? 
</p>
<p>4. The equation p' = ap a, cx &gt; l, is proposed as a model of the population growth 
of a certain species. Show that p(t)-H&gt;O in finite time. Conclude, therefore, that 
this model is not accurate over a reasonable length of time. 
</p>
<p>5. A cancerous tumor satisfies the Gompertzian relation (3). Originally, when it 
contained 104 cells, the tumor was increasing at the rate of 20% per unit time. 
The numerical value of the retarding constant cx is 0.02. What is the limiting 
number of cells in this tumor? 
</p>
<p>6. A tracer dose of radioactive iodine 1311 is injected into the blood stream at time 
t = 0. Assurne that the original amount Q0 of iodine is distributed evenly in the 
entire blood stream before any loss occurs. Let Q (t) derrote the amount of 
iodine in the blood at time t &gt; 0. Part of the iodirre leaves the blood and enters 
the urine at the rate k 1 Q. Another part of the iodine enters the thyroid gland at 
the rate k 2 Q. Find Q(t). 
</p>
<p>7. Irrdustrial waste is pumped into a tank containing 1000 gallons of waterat the 
rate of 1 galjrnin, and the well-stirred mixture leaves the tank at the same rate. 
(a) Find the concentration of waste in the tank at time t. (b) How long does it 
take for the concentration to reach 20%? 
</p>
<p>8. A tank contains 300 gallons of water and 100 gallons of pollutants. Fresh water 
is pumped into the tank at the rate of 2 gal/rnin, and the well-stirred mixture 
leaves at the same rate. How long does it take for the concentration of pollu-
tants in the tank to decrease to 1/10 of its original value? 
</p>
<p>56 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.8 The dynamics of tumor growth, mixing problems, and orthogonal trajectories 
</p>
<p>9. Consider a tank containing, at time t = 0, Q0 lb of salt dissolved in 150 gallons 
of water. Assurne that water containing t lb of salt per gallon is entering the 
tank at a rate of 3 galjmin, and that the well-stirred solution is leaving the tank 
at the same rate. Find an expression for the concentration of salt in the tank at 
timet. 
</p>
<p>10. A room containing 1000 cubic feet of air is originally free of carbon monoxide. 
Beginning at time t = 0, cigarette smoke containing 4 percent carbon monoxide 
is blown into the room at the rate of 0.1 ft3 /min, and the well-circulated mix-
ture leaves the room at the same rate. Find the time when the concentration of 
carbon monoxide in the room reaches 0.012 percent. (Extended exposure to 
this concentration of carbon monoxide is dangerous.) 
</p>
<p>11. A 500 gallon tank originally contains 100 gallons of fresh water. Beginning at 
time t = 0, water containing 50 percent pollutants flows into the tank at the rate 
of 2 galjmin, and the well-stirred mixture leaves at the rate of 1 galjmin. Find 
the concentration of pollutants in the tank at the moment it overflows. 
</p>
<p>In Exercises 12-17, find the orthogonal trajectories of the given family of 
curves. 
</p>
<p>12. y=cx2 
</p>
<p>14. y=csinx 
</p>
<p>16. y=cex 
</p>
<p>13. y 2 -x2 =c 
</p>
<p>15. x 2 + y 2 = cx (see Exercise 13 of Sec-
tion 1.4) 
</p>
<p>17. y=ecx 
</p>
<p>18. The presence of toxins in a certain medium destroys a strain of bacteria at a 
rate jointly proportional to the nurober of bacteria present and to the amount 
of toxin. Call the constant of proportionality a. If there were no toxins present, 
the bacteria would grow at a rate proportional to the amount present. Call this 
constant of proportionality b. Assurne that the amount T of toxin is increasing 
at a constant rate c, that is, dT / dt = c, and that the production of toxins begins 
at time t = 0. Let y ( t) denote the number of living bacteria present at time t. 
(a) Find a first-order differential equation satisfied by y(t). 
(b) Solve this differential equation to obtainy(t). What happens toy(t) as t ap-
</p>
<p>proaches oo? 
</p>
<p>19. Many savings banks now advertise continuous compounding of interest. This 
means that the amount of money P(1) on deposit at time 1, satisfies the dif-
ferential equation dP (1)/ dt = rP (1) where r is the annual interest rate and t is 
measured in years. Let P0 denote the original principal. 
(a) Show that P(1)=P0e'. 
(b) Let r=0.0575, 0.065, 0.0675, and 0.075. Show that e'= 1.05919, 1.06716, 
</p>
<p>1.06983, and 1.07788, respectively. Thus, the effective annual yield on inter-
es! rates of 5~, 6t, 6~, and 7t% should be 5.919, 6.716, 6.983, and 7.788%, 
respectively. Most banks, however, advertise effective annual yields of 6, 
6.81, 7 .08, and 7 .9%, respectively. The reason for this discrepancy is that 
banks calculate a daily rate of interest based on 360 days, and they pay in-
terest for each day money is on deposit. For a year, one gets five extra 
</p>
<p>57 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>days. Thus, we must multiply the annual yields of 5.919, 6.716, 6.983, and 
7.788% by 365/360, and then we obtain the advertised values. 
</p>
<p>(c) lt is interesting to note that the Old Colony Cooperative Bank in Rhode Is-
land advertises an effective annual yield of 6.72% on an annual interest rate 
of 6~% (the lower value), and an effective annual yield of 7.9% on an ann-
ual interest rate of 7~%. Thus they are inconsistent. 
</p>
<p>1.9 Exact equations, and why we cannot solve 
very many differential equations 
</p>
<p>When we began our study of differential equations, the only equation we 
could solve was dy I dt = g(t). We then enlarged our inventory to include 
all linear and separable equations. More generally, we can solve all dif-
ferential equations which are, or can be put, in the form 
</p>
<p>d 
dt cf&gt;( t ,y) = 0 ( l) 
</p>
<p>for some function cf&gt;(t,y). To wit, we can integrate both sides of (l) to ob-
tain that 
</p>
<p>cf&gt;( t ,y) = constant 
</p>
<p>and then solve for y as a function of t from (2). 
</p>
<p>(2) 
</p>
<p>Example 1. The equation l+cos(t+y)+cos(t+y)(t&Ouml;Jidt)=O can be writ-
ten in the form (dldt)(t+sin(t+y)]=O. Hence, 
</p>
<p>cf&gt;(t,y)= t+sin(t+ y)= c, and y =- t+arcsin(c- t). 
</p>
<p>Example 2. The equation cos(t+ y)+[l +cos(t+ y)]dy I dt=O can be writ-
ten in the form (dldt)(y+sin(t+y)]=O. Hence, 
</p>
<p>cf&gt;( t ,y) = y + sin( t + y) = c. 
</p>
<p>We must leave the solution in this form though, since we cannot solve for y 
explicitly as a function of time. 
</p>
<p>Equation (1) is clearly the most general first-order differential equation 
that we can solve. Thus, it is important for us to be able to recognize when 
a differential equation can be put in this form. This is not as simple as one 
might expect. For example, it is certainly not obvious that the differential 
equation 
</p>
<p>2t+y-sint+(3y2 +cosy+t) ~ =0 
</p>
<p>can be written in the form ( d I dt)(y 3 + t2 + ty + siny + cos t) = 0. To find all 
those differential equations which can be written in the form (1), observe, 
</p>
<p>58 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.9 Exact equations, and why we cannot solve very many differential equations 
</p>
<p>from the chain rule of partial differentiation, that 
</p>
<p>d acp acp dy 
dtct&gt;(t,y(t))= Tt + ay dt &middot; 
</p>
<p>Hence, the differential equation M(t,y)+N(t,y)(dyjdt)=O can be written 
in the form ( d / dt)cj&gt;( t ,y) = 0 if and only if there exists a function cj&gt;( t ,y) 
suchthat M(t,y)= acpjat and N(t,y)= acpjay. 
</p>
<p>This now leads us to the following question. Given two functions 
M ( t ,y) and N ( t ,y ), does there exist a function cj&gt;( t ,y) such that M ( t ,y) 
= acpjat and N(t,y)= acpjay? Unfortunately, the answer to this question 
is almost always no as the following theorem shows. 
</p>
<p>Theorem 1. Let M ( t ,y) and N ( t ,y) be continuous and have continuous par-
tial derivatives with respect to t and y in the reetangle R consisting of those 
points (t,y) with a &lt; t &lt; b and c &lt;y &lt; d. There exists a function cj&gt;(t,y) 
suchthat M(t,y)= acpjat and N(t,y)= acpjay if, and only if, 
</p>
<p>aMjay=aN;at 
</p>
<p>in R. 
</p>
<p>PROOF. Observe that M(t,y)= acpjat for some function cp(t,y) if, and only 
if, 
</p>
<p>cp(t,y)= f M(t,y)dt+h(y) (3) 
where h(y) is an arbitrary function of y. Taking partial derivatives of both 
sides of (3) with respect to y, we obtain that 
</p>
<p>acp J aM(t,y) 
ay = ay dt+h'(y). 
</p>
<p>Hence, acpjay will be equal to N(t,y) if, and only if, 
</p>
<p>f aM (t,y) N(t,y)= ay dt+h'(y) 
or 
</p>
<p>f aM(t,y) h'(y)=N(t,y)- ay dt. (4) 
Now h'(y) is a function of y alone, while the right-hand side of (4) appears 
to be a function of both t and y. But a function of y alone cannot be equal 
to a function of both t and y. Thus Equation (4) makes sense only if the 
right-hand side is a function of y alone, and this is the case if, and only if, 
</p>
<p>a [ J aM(t,y) ] aN aM 
31 N(t,y)- ay dt = at- ay =O. 
</p>
<p>59 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>Hence, if aN I at =!= aM I ay, then there is no function cp(t,y) such that M 
= acp I at, N = acp I ay. On the other hand, if aN I at = aM I ay then we can 
solve for 
</p>
<p>f[ f aM (t,y) ] h(y)= N(t,y)- ay dt dy. 
</p>
<p>Consequently, M= acplat, and N= acplay with 
</p>
<p>f [ aM(t,y) ] cp( t ,y) = M ( t ,y) dt + f N (t ,y) - f ay dt dy. D (5) 
</p>
<p>Definition. The differential equation 
</p>
<p>dy 
M ( t ,y) + N ( t ,y) dt = 0 (6) 
</p>
<p>is said to be exact if aM I ay = aN I at. 
</p>
<p>The reason for this definition, of course, is that the left-hand side of (6) 
is the exact derivative of a known function of t and y if aM I ay = aN I at. 
</p>
<p>Remark 1. lt is not essential, in the Statement of Theorem 1, that aM I ay 
= aN I ar in a rectangle. lt is sufficient if aM I ay = aN I ar in any region R 
which contains no "holes". That is to say, if Cis any closed curve lying en-
tirely in R, then its interior also lies entirely in R. 
</p>
<p>Remark 2. The differential equation dyldt=f(t,y) can always be written 
in the form M(t,y)+N(t,y)(dyldt)=O by setting M(t,y)=- f(t,y) and 
N(t,y)= l. 
</p>
<p>Remark 3. lt is customary to say that the solution of an exact differential 
equation is given by cp( t ,y) = constant. What we really mean is that the 
equation cp(t,y)= c is to be solved for y as a function of t and c. Unfor-
tunately, most exact differential equations cannot be solved explicitly for y 
as a function oft. While this may appear tobe very disappointing, we wish 
to point out that it is quite simple, with the aid of a computer, to compute 
y(t) to any desired accuracy (see Section 1.11). 
</p>
<p>In practice, we do not recommend memorizing Equation (5). Rather, we 
will follow one of three different methods to obtain cp(t,y). 
First Method: The equation M(t,y)= acplat determines cp(t,y) up to an ar-
bitrary function of y alone, that is, 
</p>
<p>cp(t,y)= f M(t,y)dt+h(y). 
60 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.9 Exact equations, and why we cannot solve very many differential equations 
</p>
<p>The function h (y) is then determined from the equation 
</p>
<p>3M(t,y) 
h'(y)=N(t,y)- J ay dt. 
</p>
<p>Second Method: If N (t,y) = 3cpl 3y, then, of necessity, 
</p>
<p>cp(t,y)= jN(t,y)dy+k(t) 
</p>
<p>where k( t) is an arbitrary function of t alone. Since 
</p>
<p>acp J aN (t,y) 
M(t,y)=at= at dy+k'(t) 
</p>
<p>we see that k(t) is determined from the equation 
</p>
<p>aN (t,y) 
k'(t)=M(t,y)- J 31 dy. 
</p>
<p>Note that the right-hand side of this equation (see Exercise 2) is a function 
oft alone if 3MI3y=3NI3t. 
Third M ethod: The equations 3cp I at = M ( t ,y) and 3cp I ay = N ( t ,y) imply 
that 
</p>
<p>cp( t,y) = J M ( t,y) dt + h(y) and cp( t,y) = J N ( t,y)dy + k(t). 
Usually, we can determine h(y) and k(t) just by inspection. 
</p>
<p>Example 3. Find the general solution of the differential equation 
</p>
<p>dy 
3y+e'+(3t+cosy) dt =0. 
</p>
<p>Solution. Here M(t,y)=3y+e 1 and N(t,y)=3t+cosy. This equation is 
exact since 3M I ay = 3 and aN I at = 3. Hence, there exists a function cp( t ,y) 
suchthat 
</p>
<p>a~ acp 
(i) 3y+e 1=-ft and (ii) 3t+cosy= ay&middot; 
</p>
<p>We will find cp(t,y) by each of the three methods outlined above. 
</p>
<p>First Method: From (i), cp(t,y)=e 1 +3ty+h(y). Differentiating this equa-
tion with respect to y and using (ii) we obtain that 
</p>
<p>h'(y) + 3t =3t+ cosy. 
</p>
<p>Thus, h(y) = siny and cp(t,y) = e 1 + 3ty + siny. (Strictly speaking, h(y) = 
siny + constant. However, we already incorporate this constant of integra-
tion into the solution when we write cp(t,y)=c.) The general solution of the 
differential equation must be left in the form e 1 + 3 ty + siny = c since we 
cannot find y explicitly as a function of t from this equation. 
Second Method: From (ii), cp(t,y) = 3ty + siny + k(t). Differentiating this 
</p>
<p>61 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>expression with respect to t, and using (i) we obtain that 
</p>
<p>3y+k'(t)=3y+e 1&bull; 
</p>
<p>Thus, k(t)=e 1 and &lt;P(t,y)=3ty+siny+e 1&bull; 
Third Method: Frorn (i) and (ii) 
</p>
<p>&lt;P( t,y) = e 1 + 3ty + h(y) and &lt;P(t,y) = 3ty + siny + k( t). 
Cornparing these two expressions for the same function &lt;P(t,y) it is obvious 
</p>
<p>that h(y) = siny and k(t) = e1&bull; Hence 
</p>
<p>&lt;P(t,y) = e 1 + 3ty + siny. 
</p>
<p>Example 4. Find the solution of the initial-value problern 
</p>
<p>dy 
3t2y + 8ty 2 + (t 3 + 8t2y + l2y 2) dt =0, y(2)= 1. 
</p>
<p>Solution. Here M(t,y)=3t 2y+8ty 2 and N(t,y)=t 3 +8t2y+l2y 2 . This 
equation is exact since 
</p>
<p>aM =3t2 + 16ty and aN =3t2 + 16ty. 
ay at 
</p>
<p>Hence, there exists a function &lt;/&gt;(t,y) such that 
</p>
<p>aq, aq, 
(i) 3t2y+8ty 2=- and (ii) t3 +8t2y+l2y 2=-. 
</p>
<p>at ay 
</p>
<p>Again, we will find &lt;l&gt;(t,y) by each of three rnethods. 
</p>
<p>First Method: Frorn (i), &lt;l&gt;(t,y) = t 3y + 4t2y 2 + h(y). Differentiating this 
equation with respect to y and using (ii) we obtain that 
</p>
<p>t 3 + 8t2y + h'(y)&middot;= t3 + 8t2y + 12y2&bull; 
</p>
<p>Hence, h(y)=4y 3 and the generat solution of the differential equation is 
&lt;/&gt;( t ,y) = ty + 4t2y 2 + 4y 3 = c. Setting t = 2 and y = 1 in this equation, we see 
that c = 28. Thus, the solution of our initial-value problern is defined irn-
plicitly by the equation ty + 4t2y 2 + 4y 3 = 28. 
Second Method: Frorn (ii), &lt;P(t,y)=t3y+4t2y 2 +4y3 +k(t). Differentiating 
this expression with respect to t and using (i) we obtain that 
</p>
<p>3t 2y + 8ty2 + k'( t) = 3t2y + 8ty 2&bull; 
Thus k(t)=O and q,(t,y)= t3y +4t2y 2 +4y3 &bull; 
Third Method: Frorn (i) and (ii) 
</p>
<p>&lt;P(t,y) = ty +4t2y 2 + h(y) and &lt;P(t,y)= ty+4t2y 2 +4y 3 + k(t). 
</p>
<p>Cornparing these two expressions for the sarne function &lt;P(t,y) we see that 
h(y)=4y 3 and k(t)=O. Hence, &lt;P(t,y)= t 3y +4t2y 2 +4y3&bull; 
</p>
<p>In rnost instances, as Exarnples 3 and 4 illustrate, the third rnethod is 
the sirnplest to use. However, if it is rnuch easier to integrate N with re-
</p>
<p>62 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.9 Exact equations, and why we cannot solve very many differential equations 
</p>
<p>spect to y than it is to integrate M with respect tot, we should use the sec-
ond method, and vice-versa. 
</p>
<p>Example 5. Find the solution of the initial-value problern 
</p>
<p>4t3e 1+y + t4e 1+y + 2t + (t4e 1+y + 2y) dt =0, y (0) = 1. 
Solution. This equation is exact since 
</p>
<p>j_ (4t3e1+y + tV+y + 2t) = ( t4 +4t3)e 1+y = l_( t4e 1+y + 2y ). 
ay ar 
</p>
<p>Hence, there exists a function cp(t,y) such that 
</p>
<p>and 
</p>
<p>. acp 
(1) 4t3e'+Y+t4e'+Y+2t=-
</p>
<p>at 
</p>
<p>(1.1.) 4 t+y 2 acp t e + y= ay. 
</p>
<p>Since it is much simpler to integrate t4e 1+Y+2y with respect toy than it is 
to integrate 4t 3e 1+y + t4e 1+y + 2t with respect to t, we use the second 
method. From (ii), cp( t ,y) = t 4e t+ Y + y 2 + k( t). Differentiating this expres-
sion with respect to t and using (i) we obtain 
</p>
<p>( t4 + 4t3 )e 1+y + k'( t) = 4t3e t+y + t4e 1+ Y + 2t. 
</p>
<p>Thus, k(t) = t 2 and the general solution of the differential equation is 
cp( t ,y) = t4e 1 + Y + y 2 + t2 = c. Setting t = 0 and y = 1 in this equation yields c 
= 1. Thus, the solution of our initial-value problern is defined implicitly by 
the equation t4e 1+y + t 2 + y 2 = 1. 
</p>
<p>Suppose now that we are given a differential equation 
dy 
</p>
<p>M ( t ,y) + N ( t ,y) dt = 0 (7) 
</p>
<p>which is not exact. Can we make it exact? More precisely, can we find a 
function JL(t,y) such that the equivalent differential equation 
</p>
<p>dy 
JL( t,y)M ( t,y) + JL(t,y)N (t,y) dt = 0 (8) 
</p>
<p>is exact? This question is simple, in principle, to answer. The condition that 
(8) be exact is that 
</p>
<p>a a 
ay ( JL( t,y)M ( t,y )) = at( JL(t,y )N (t,y )) 
</p>
<p>or 
</p>
<p>(9) 
</p>
<p>(For simplicity of writing, we have suppressed the dependence of JL,M and 
Non t and y in (9).) Thus, Equation (8) is exact if and only if JL(t,y) satis-
fies Equation (9). 
</p>
<p>63 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>Definition. A function JL(t,y) satisfying Equation (9) is called an integrat-
ing factor for the differential equation (7). 
</p>
<p>The teason for this definition, of course, is that if JL satisfies (9) then we 
can write (8) in the form (d/dt)cp(t,y)=O and this equation can be in-
tegrated immediately to yield the solution cp(t,y) = c. Unfortunately, 
though, there are only two special cases where we can find an explicit solu-
tion of (9). These occur when the differential equation (7) has an integrat-
ing factor which is either a function of t alone, or a function of y alone. 
Observe that if JL is a function of t alone, then Equation (9) reduces to 
</p>
<p>dJL 
( aM _aN) 
</p>
<p>ay at 
-= 
dt N JL&middot; 
</p>
<p>But this equation is meaningless unless the expression 
</p>
<p>aM aN ---
ay at 
</p>
<p>N 
</p>
<p>is a function of t alone, that is, 
</p>
<p>aM aN ---
ay at 
</p>
<p>N 
= R (t). 
</p>
<p>If this is the case then JL(t)=exp(J R(t)dt) is an integrating factor for the 
differential equation (7). 
</p>
<p>Remark. lt should be noted that the expression 
</p>
<p>aM aN ---
ay at 
</p>
<p>N 
</p>
<p>is almost always a function of both t and y. Only for very special pairs of 
functions M(t,y) and N(t,y) is it a function oft alone. A similar situation 
occurs if JL is a function of y alone (see Exercise 17). It is for this reason 
that we cannot solve very many differential equations. 
</p>
<p>Example 6. Find the general solution of the differential equation 
</p>
<p>y2 dy 
T+2yet+(y+er) dt =0. 
</p>
<p>Solution. Here M (t,y)=(y 2 /2)+ 2ye 1 and N(t,y)= y + e1&bull; This equation is 
</p>
<p>64 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.9 Exact equations, and why we cannot solve very many differential equations 
</p>
<p>not exact since oMjoy=y+2e1 and oNjot=e 1. However, 
</p>
<p>_!_( aM _aN)= y+e 1 = 1. 
N oy ot y+el 
</p>
<p>Hence, this equation has p.(t) = exp(j 1 dt) = e 1 as an integrating factor. 
</p>
<p>This means, of course, that the equivalent differential equation 
</p>
<p>y2 ~ 
-e~ +2ye21 +(yel + e21)- =0 
2 dt 
</p>
<p>is exact. Therefore, there exists a function &lt;/&gt;( t ,y) such that 
</p>
<p>y2 0&lt;/&gt; 
(i) -e1+2ye21=-
</p>
<p>2 at 
</p>
<p>and 
</p>
<p>From Equations (i) and (ii), 
</p>
<p>y2 
&lt;/&gt;(t,y) =Tel+ ye21 + h(y) 
</p>
<p>and 
</p>
<p>y2 
&lt;/&gt;(t,y) = Te 1 + ye21 + k(t). 
</p>
<p>Thus, h(y)=O, k(t)=O and the general solution of the differential equation 
is 
</p>
<p>Solving this equation for y as a function of t we see that 
</p>
<p>2 - 1/2 y(t)=-e1&plusmn;[e 1+2ce 1 ] &bull; 
</p>
<p>Example 7. Use the methods of this section to find the general solution of 
the linear equation (~/dt)+a(t)y=b(t). 
Solution. We write this equation in the form M ( t ,y) + N ( t ,y )( ~ / dt) = 0 
with M (t,y) = a(t)y- b(t) and N (t,y) = 1. This equation is not exact since 
oMjoy=a(t) and oNjot=O. However, ((oMjoy)-(oNjot))/N=a(t). 
</p>
<p>Hence, p.(t) = exp(j a( t) dt) is an integrating factor for the first-order lin-
</p>
<p>ear equation. Therefore, there exists a function &lt;f&gt;(t,y) such that 
</p>
<p>(i) p.(t)[a(t)y-b(t)]= ~~ 
</p>
<p>65 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>and 
</p>
<p>(ii) p.(t)= ~;. 
</p>
<p>Now, observe from (ii) that cp(t,y)= p.(t)y + k(t). Differentiating this equa-
tion with respect to t and using (i) we see that 
</p>
<p>p.'( t)y + k'( t) = p.( t)a( t)y- p.( t)b( t). 
</p>
<p>But, p.'(t)=a(t)p.(t). Consequently, k'(t)= -p.(t)b(t) and 
</p>
<p>cp(t,y)=p.(t)y- f p.(t)b(t)dt. 
Hence, the general solution of the first-order linear equation is 
</p>
<p>p.(t)y- f p.(t)b(t) dt = c, 
and this is the result we obtained in Section 1.2. 
</p>
<p>ExERCISES 
</p>
<p>1. Use the theorem of equality of mixed partial derivatives to show that aM I ay 
=aN I at if the equation M (t,y)+ N (t,y)(dy I dt)=O is exact. 
</p>
<p>2. Show that the expression M ( t ,y)- f (aN ( t ,y) I at) dy is a function of t alone if 
aM 1ay =aN 1at. 
</p>
<p>In each of Problems 3-6 find the general solution of the given differential 
equation. 
</p>
<p>3. 2tsiny+y3e1+(t2 cosy+3y 2e1): =0 
</p>
<p>4. 1+(1+ty)ety+(1+t2ety)dr =0 
</p>
<p>5. y sec2 t + sect tant + (2y + tant) dr = 0 
</p>
<p>y2 dy 
6. T - 2ye 1 + (y - e 1) dt = 0 
</p>
<p>In each of Problems 7-ll, solve the given initial-value problem. 
</p>
<p>7. 2ty 3 +3t2y 2 d: =0, y(l)= 1 
8. 2tcosy+3t2y+(t3 -t2 siny-y) dr =0, y(0)=2 
</p>
<p>9. 3t2 +4ty+(2y+2t2)dr =0, y(0)=1 
</p>
<p>10. y(cos2t)ety- 2(sin2t)ety + 2t +(t(cos2t)ety- 3) ~ =0, y(O) =0 
</p>
<p>66 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.10 The existence-uniqueness theorem; Picard iteration 
</p>
<p>11. 3ty+y2+(t2+ty)dt =0, y(2)=l 
</p>
<p>In each of Problems 12-14, determine the constant a so that the equation 
is exact, and then solve the resulting equation. 
</p>
<p>12. t + ye2ty + ate2ty : = 0 
</p>
<p>13. _!_ + _!__ + (at+ I) dy =0 
t2 y2 y3 dt 
</p>
<p>14. eat+y+3t2y 2 +(2yt3+eat+y): =0 
</p>
<p>15. Show that every separable equation of the form M(t)+ N(y)dy I dt=O is exact. 
</p>
<p>16. Findall functions f(t) suoh that the differential equation 
</p>
<p>y 2sint+yf(t)(dy I dt)=O 
</p>
<p>is exact. Solve the differential equation for these f(t). 
</p>
<p>17. Show that if ((aN I at)- (aM I ay))l M = Q (y), then the differential equation 
</p>
<p>M (t,y)+ N(t,y)dy I dt=O has an integrating factor p.(y)=exp(J Q (y)dy )&middot; 
</p>
<p>18. The differential equation f(t)(dy I dt)+ t2+ y =0 is known to have an integrat-
ing factor p.(t)=t. Findall possible functionsf(t). 
</p>
<p>19. The differential equation e1secy-tany+(dyldt)=O has an integrating factor 
of the forme -at cosy for some constant a. Find a, and then solve the differen-
tial equation. 
</p>
<p>20. The Bernoulli differential equation is (dyldt)+a(t)y=b(t)yn. Multiplying 
</p>
<p>through by p.(t)=exp(J a(t)dt), we can rewrite this equation in the form 
</p>
<p>dldt(p.(t)y)=b(t)p.(t)yn. Find the general solution of this equation by find-
ing an appropriate integrating factor. Hint: Divide both sides of the equation 
by an appropriate function of y. 
</p>
<p>1.10 The existence-uniqueness theorem; Picard iteration 
</p>
<p>Consider the initial-value problern 
</p>
<p>dy 
dt = f(t,y), (1) 
</p>
<p>where f is a given function of t and y. Chances are, as the rernarks in Sec-
tion 1.9 indicate, that we will be unable to solve (I) explicitly. This Ieads us 
to ask the following questions. 
</p>
<p>I. How are we to know that the initial-value problern (1) actually has a 
solution if we can't exhibit it? 
</p>
<p>67 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>2. How do we know that there is only one solution y(t) of (I)? Perhaps 
there are two, three, or even infinitely many solutions. 
</p>
<p>3. Why bother asking the first two questions? After all, what's the use of 
determining whether (I) has a unique solution if we won't be able to ex-
plicitly exhibit it? 
</p>
<p>The answer to the third question lies in the observation that it is never 
necessary, in applications, to find the solution y(t) of (1) to more than a 
finite number of decimal places. Usually, it is more than sufficient to find 
y(t) to four decimal places. As weshall see in Sections 1.13-I?, this can be 
done quite easily with the aid of a digital computer. In fact, we will be able 
to compute y(t) to eight, and even sixteen, decimal places. Thus, the 
knowledge that (I) has a unique solutiony(t) is our hunting license to go 
looking for it. 
</p>
<p>To resolve the first question, we must establish the existence of a func-
tion y(t) whose value at t = t0 is y 0 , and whose derivative at any time t 
equalsj(t,y(t)). In order to accomplish this, we must find a theorem which 
enables us to establish the existence of a function having certain proper-
ties, without our having to exhibit this function explicitly. If we search 
through the Calculus, we find that we encounter such a situation exactly 
once, and this is in connection with the theory of Iimits. As we show in Ap-
pendix B, it is often possible to prove that a sequence of functions y n (t) has 
a limity(t), without our having to exhibity(t). For example, we can prove 
that the sequence of functions 
</p>
<p>(t)= sinwt + sin2wt + + sinnwt Yn 12 22 ... n2 
</p>
<p>has a limity(t) even though we cannot exhibity(t) explicitly. This suggests 
the following algorithm for proving the existence of a solution y ( t) of (I). 
</p>
<p>(a) Construct a sequence of functions Yn(t) which come closer and closer 
to solving (I). 
</p>
<p>(b) Show that the sequence of functionsyn(t) has a limity(t) on a suitable 
interval t0 ...; t...; t0 + a. 
</p>
<p>(c) Prove thaty(t) is a solution of (I) on this interval. 
</p>
<p>We now show how to implement this algorithm. 
</p>
<p>(a) Construction of the approximating sequence Yn(t) 
</p>
<p>The problern of finding a sequence of functions that come closer and 
closer to satisfying a certain equation is one that arises quite often in 
mathematics. Experience has shown that it is often easiest to resolve this 
problern when our equation can be written in the special form 
</p>
<p>y(t)=L(t,y(t)), (2) 
</p>
<p>where L may depend explicitly on y, and on integrals of functions of y. 
</p>
<p>68 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.10 The existence-uniqueness theorem; Picard iteration 
</p>
<p>For example, we may wish to find a function y(t) satisfying 
</p>
<p>y ( t) = 1 + sin [ t + y ( t) J , 
or 
</p>
<p>y(t)=l+y 2 (t)+ fo 1y 3 (s)ds. 
In these two cases, L(t,y(t)) is an abbreviation for 
</p>
<p>1 + sin [ t + y ( t) J 
and 
</p>
<p>respectively. 
The key to understanding what is special about Equation (2) is to view 
</p>
<p>L(t,y(t)) as a "machine" that takes in one function and gives back another 
one. For example, Iet 
</p>
<p>L(t,y(t))= l+y 2 (t)+ {y 3 (s)ds. 
</p>
<p>If we plug the function y(l)= 1 into this machine, (that is, if we compute 
</p>
<p>1 + t 2 + ,i 1s 3 ds) then the machine returns to us the function 1 + 12 + 14 /4. If 
we plug ~he functiony(l)=cosl into this machine, then it returns to us the 
function 
</p>
<p>( 1 sin3 t 
1 + cos2 t + Jo cos3 sds= 1 + cos2 1+sinl- - 3-. 
</p>
<p>According to this viewpoint, we can characterize all solutions y ( t) of (2) as 
those functions y(t) which the machine L leaves unchanged. In other 
words, if we plug a function y ( t) into the machine L, and the machine re-
turns to us this same function, then y ( 1) is a solution of (2). 
</p>
<p>We can put the initial-value problern (1) into the specialform (2) by in-
tegrating both sides of the differential equationy' = f(t,y) with respect tot. 
Specifically, if y(t) satisfies (1), then 
</p>
<p>(' dy(s) Jt 
),_ ~ds= 
</p>
<p>1
/(s,y(s))ds 
</p>
<p>to 
</p>
<p>so that 
</p>
<p>(3) 
</p>
<p>Conversely, if y(t) is continuous and satisfies (3), then dy / dt = j(t,y(t)). 
Moreover, y(t0) is obviously y 0&bull; Therefore, y(t) is a solution of (1) if, and 
only if, it is a continuous solution of (3). 
</p>
<p>69 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>Equation (3) is called an integral equation, and it is in the special form 
(2) if we set 
</p>
<p>L(t,y( t)) = y 0 + Jr f(s,y (s))ds. 
to 
</p>
<p>This suggests the following scheme for constructing a sequence of "ap-
proximate solutions" Yn(t) of (3). Let us start by guessing a solutiony0(t) of 
(3). The simplest possible guess is y 0(t)= y 0&bull; To check whether y0(t) is a 
solution of (3), we compute 
</p>
<p>If y 1(t) = y 0, then y(t) = y 0 is indeed a solution of (3). If not, then we try 
y 1(t) as our next guess. To check whether y 1(t) is a solution of (3), we com-
pute 
</p>
<p>h(t)=y0 + j 1f(s,y 1(s))ds, 
to 
</p>
<p>and so on. In this manner, we define a sequence of functions y 1(t), 
Y 2( t), ... , where 
</p>
<p>(4) 
</p>
<p>These functions Yn(t) are called successive approximations, or Picard 
iterates, after the French mathematician Picard who first discovered them. 
Remarkably, these Picard iterates always converge, on a suitable interval, 
to a solution y(t) of (3). 
</p>
<p>Example 1. Compute the Picard iterates for the initial-value problern 
</p>
<p>y'=y, y(O) =I, 
</p>
<p>and show that they converge to the solution y ( t) = e 1&bull; 
Solution. The integral equation corresponding to this initial-value problern 
is 
</p>
<p>y(t)=l+ fo 1y(s)ds. 
Hence, y 0( t) = 1 
</p>
<p>y 1(t)=l+ fo 1lds=l+t 
</p>
<p>70 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.10 The existence-uniqueness theorem; Picard iteration 
</p>
<p>and, in general, 
</p>
<p>y"(t) -1 + f.'y"_' (s)ds~ I+['[ I +s+ ... + (:~-:)! l ds 
12 1n 
</p>
<p>= 1 + t + -2, + ... +I. 
. n. 
</p>
<p>Since e 1 = 1 + t + t2 /2! + ... , we see that the Picard iterates Yn(t) converge 
to the solution y(t) of this initial-value problem. 
</p>
<p>Example 2. Compute the Picard iterates y 1(t),y2(t) for the initial-value 
problern y' = 1 + y 3, y(l) = 1. 
Solution. The integral equation corresponding to this initial-value problern 
is 
</p>
<p>Hence, y 0(t) = 1 
</p>
<p>y 1(t)=l+ ~ 1 (l+l)ds=I+2(t-I) 
</p>
<p>and 
</p>
<p>h(t)=l+ ~ 1 {l+[I+2(s-I)f}ds 
</p>
<p>= I + 2( t- I)+ 3( t- 1 )2 + 4( t- I )3 + 2( t- I t 
Notice that it is already quite cumbersome to compute yit). 
</p>
<p>(b) Convergence of the Picard iterates 
</p>
<p>As was mentioned in Section 1.4, the solutions of nonlinear differential 
equations may not exist for all time t. Therefore, we cannot expect the 
Picard iterates Yn(t) of (3) to converge for all t. To provide us with a clue, 
or estimate, of where the Picard iterates converge, we try to find an inter-
val in which all the Yn(t) are uniformly bounded (that is, IYn(t)l &lt; K for 
some fixed constant K). Equivalently, we seek a reetangle R which con-
tains the graphs of all the Picard iterates Yn(t). Lemma 1 shows us how to 
find such a rectangle. 
</p>
<p>Lemma 1. Choose any two positive numbers a and b, and Iet R be the rectan-
</p>
<p>g/e: t0 &lt; t &lt; t0 + a, IY-Yol &lt; b. Compute 
</p>
<p>Then, 
</p>
<p>M= max lf(t,y)l, andset a=min(a, Mb ). 
(t,y) m R 
</p>
<p>(5) 
</p>
<p>71 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>Lemma 1 states that the graph of Yn(t) is sandwiched between the lines 
y=y0 +M(t-t0) andy=y0 -M(t-t0), for t0 ..;;t..;;t0 +a. These lines 
leave the reetangle R at t = t0 + a if a ..:; b IM, and at t = t0 + b IM if b IM 
&lt; a (see Figures la and lb). In either case, therefore, the graph of Yn(t) is 
contained in R for t0 ..:; t..:; t0 + a. 
</p>
<p>(a) (b) 
</p>
<p>Figure l. (a) a=a; (b) a= b/ M 
</p>
<p>PROOF OF LEMMA 1. We establish (5) by induction on n. Observe first that 
(5) is obviously true for n=O, sincey0(t)= y 0. Next, we must show that (5) 
is true for n = j + 1 if it is true for n = j. But this follows immediately, for if 
IY/t)-Yol..:; M(t- t0), then 
</p>
<p>iYj+ 1 (t)- Yol =I { f(s,yj(s))ds' 
..;;J1if(s,yj(s))ids..;; M(t-t0) 
</p>
<p>to 
</p>
<p>for t0 ..:; t..:; t0 + a. Consequently, (5) is true for all n, by induction. 0 
</p>
<p>We now show that the Picard iterates Yn(t) of (3) converge for each t in 
the interval to..:; t..:; to + a, if oj I oy exists and is continuous. Our first step is 
to reduce the problern of showing that the sequence of functions y n (t) con-
verges to the much simpler problern of proving that an infinite series con-
verges. This is accomplished by writing y n (t) in the form 
</p>
<p>Yn ( t) = Yo( t) + ( Yt ( t)-Yo( t)) + .. &middot; + ( Yn(t) ~ Yn-1 ( t)). 
Clearly, the sequence Yn(t) converges if, and only if, theinfinite series 
</p>
<p>[YI(t)-yo(t)]+[Yz(t)-yi(t)]+ ... +[yn(t)-yn-I(t)]+ ... (6) 
</p>
<p>converges. To prove that the infinite series (6) converges, it suffices to 
</p>
<p>72 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.10 The existence-uniqueness theorem; Picard iteration 
</p>
<p>show that 
00 
</p>
<p>~ 1Yn(t)-Yn-1(t)j&lt;oo. 
n=! 
</p>
<p>This is accomplished in the following manner. Observe that 
</p>
<p>IYn( t)-Yn-1 ( t)l =I!: [ f(s,yn-1 (s))- f(s,yn-2(s))] dsl 
..;; {if(s,yn-1 (s))-f( S,Yn-2 (s))l ds 
</p>
<p>lo rl aj(s,g(s)) I 
= ),_ ay iYn-t(s)-Yn-2(s)jds, 
</p>
<p>to 
</p>
<p>(7) 
</p>
<p>where g(s) lies between Yn- 1(s) and Yn-is). (Recall that f(x 1)- f(x2)= 
j'(g)(x1- x2), where g is some number between x 1 and x2.) lt follows im-
mediately from Lemma 1 that the points (s,g(s)) alllie in the reetangle R 
for s &lt; t0 + a. Consequently, 
</p>
<p>where 
</p>
<p>L= max . I af(t,y) I 
(t,y)inR ay 
</p>
<p>Equation (9) defines the constant L. Setting n = 2 in (8) gives 
</p>
<p>IY2(t)-y1(t)l..;; L [iYt(s)-Yoids..;; L rM(s-to)ds 
lo to 
</p>
<p>This, in turn, implies that 
</p>
<p>Proceeding inductively, we see that 
</p>
<p>(9) 
</p>
<p>M Ln- 1 ( t- lo) n 
1Yn(t)-Yn-1(t)j..;; 1 , fort0 ..;;t..;;t0 +a. (10) n. 
</p>
<p>73 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>Therefore, for t0 &lt; t &lt; t0 + a, 
[y 1 (t)- Yo(t)[ + ih(t)-Y 1 (t)[ + ... 
</p>
<p>ML(t-t0 ) 2 ML 2(t-t0 ) 3 
</p>
<p>&lt;M(t-to)+ 2! + 3! + ... 
</p>
<p>MLa 2 ML 2a 3 
&lt;Ma+-2-!-+ 3! + ... 
</p>
<p>~ ~ [ aL+ (a~)' + (a3~)' + &middot;&middot;&middot;] 
</p>
<p>= 1 (e"L-1). 
This quantity, obviously, is less than infinity. Consequently, the Pieard 
iteratesyn(t) eonverge for eaeh t in the interval t0 &lt;t&lt;t0 +a. (A similar 
argument shows that Yn(t) eonverges for eaeh t in the interval t0 - &szlig; &lt; t &lt; 
t0 , where &szlig;=min(a,b/N), and N is the maximum value of [f(t,y)[ for 
(t,y) in the reetangle t0 - a &lt; t &lt; t0, [y-y0[ &lt; b.) We will denote the Iimit of 
the sequeneeyn(t) by y(t). 0 
</p>
<p>(c) Proofthat y(t) sarisfies the initial-value problern (I) 
</p>
<p>We will show that y ( t) satisfies the integral equation 
</p>
<p>y(t)=y0 + j 1f(s,y(s))ds 
to 
</p>
<p>(11) 
</p>
<p>and that y ( t) is eontinuous. To this end, reeall that the Pieard iterates y n ( t) 
are defined reeursively through the equation 
</p>
<p>Taking Iimits of both sides of (12) gives 
</p>
<p>y(t)=y0 + lim j 1f(s,yn(s))ds. 
n-+oo to 
</p>
<p>To show that the right-hand side of (13) equals 
</p>
<p>Yo+ j 1f(s,y(s))ds, 
to 
</p>
<p>(12) 
</p>
<p>(13) 
</p>
<p>(that is, to justify passing the limit through the integral sign) we must show 
that 
</p>
<p>IJ:f(s,y(s))ds- { f(s,yn(s))dsl 
</p>
<p>approaehes zero as n approaehes infinity. This is aeeomplished in the 
following manner. Observe first that the graph of y(t) lies in the reetangle 
R for t &lt; t0 + a, sinee it is the Iimit of funetions y n ( t) whose graphs lie in R. 
74 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.10 The existence-uniqueness theorem; Picard iteration 
</p>
<p>Hence 
</p>
<p>l
{f(s,y(s))ds- J'!(s,y11 (s))dsl 
</p>
<p>to to 
</p>
<p>&lt; J'IJ(s,y(s))- f(s,yn(s))l ds &lt; L J'iy(s)-Yn(s)l ds 
~ ~ 
</p>
<p>where L is defined by Equation (9). Next, observe that 
</p>
<p>since 
</p>
<p>and 
</p>
<p>CO 
</p>
<p>y(s)-y11 (s)= ~ [y/s)-Yj-l(s)] 
j=n+l 
</p>
<p>CO 
</p>
<p>y(s)=y0 + ~ [Yj(s)-Yj-t(s)] 
j-1 
</p>
<p>II 
</p>
<p>Yn(s)=yo+ ~ "[yis)-Yj-t(s)]. 
j=l 
</p>
<p>Consequently, from (10), 
</p>
<p>and 
</p>
<p>co . (s- to)j 
ly(s)-Yn(s)I&lt;M ~ v-t .1 J. j=n+l 
</p>
<p>~ Lj-taj M ~ (aLi 
&lt;;M ~ -.-,-=-L ~ -.,-, 
</p>
<p>1&middot; J. j=n+l j=n+l 
</p>
<p>IJ.:j(s,y(s))d&gt;- J.: f(s,y.(s))d&gt;l &lt; M }. 
1 
</p>
<p>(a~)J J.: d&gt; 
</p>
<p>co (aL)j 
&lt;;Ma ~ -.1-. 
</p>
<p>j=n+l ]. 
</p>
<p>(14) 
</p>
<p>This summation approaches zero as n approaches infinity, since it is the 
tail end of the convergent Taylor series expansion of eaL. Hence, 
</p>
<p>lim J' f(s,yn(s)) ds = J' f(s,y(s )) ds, 
n-+co to to 
</p>
<p>and y(t) satisfies (11). 
To show that y(t) is continuous, we must show that for every e &gt;0 we 
</p>
<p>can find 8 &gt; 0 such that 
IY(t+h)-y(t)l&lt;e iflhl&lt;8. 
</p>
<p>Now, we cannot compare y(t+ h) withy(t) directly, since we do not know 
y(t) explicitly. To overcome this difficulty, we choose a large integer N and 
</p>
<p>75 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>observe that 
</p>
<p>y(t+ h)- y(t)= [y(t+ h)-YN(t+ h)] 
</p>
<p>+ [YN(t+h)-yN(t)] + [YN(t)-y(t)]. 
Specifically, we choose N so large that 
</p>
<p>M ~ (aL) 1 &lt;~ 
L ~ ., 3' 
</p>
<p>j=N+ I J. 
</p>
<p>Then, from (14), 
</p>
<p>ly(t+h)-yN(t+h)l&lt;f and IYN(t)-y(t)l&lt;f, 
</p>
<p>for t &lt; t0 + a, and h sufficiently small (so that t + h &lt; t0 + a.) Next, observe 
that YN(t) is continuous, since it is obtained from N repeated integrations 
of continuous functions. Therefore, we can choose 8 &gt; 0 so small that 
</p>
<p>IYN(t+h)-yN(t)l&lt;f for lhl&lt;8. 
</p>
<p>Consequently, 
</p>
<p>ly(t + h)- y(t)l&lt; ly(t+ h)-YN(t + h)l + IYN(t + h)-YN(t)l 
I ( ) ( )I E E E + YN t - y t &lt; 3 + 3 + 3 = E 
</p>
<p>for lhl &lt; 8. Therefore, y(t) is a continuous solution of the integral equation 
(11), and this completes our proof thaty(t) satisfies (1). D 
</p>
<p>In summary, we have proven the following theorem. 
</p>
<p>Theorem 2. Letfand aj I ay be continuous in the reetangle R : to.;;; t.;;; to + a, 
IY-Yol&lt; b. Compute 
</p>
<p>M= max lf(t,y)l, and set a=min(a, Mb ). 
(t,y) m R 
</p>
<p>Then, the initial-value problern y' = f(t,y), y(t0) = y 0 has at least one solu-
tion y ( t) on the interval t0 &lt; t &lt; t0 + a. A similar result is true for t &lt; t0&bull; 
</p>
<p>Remark. The number a in Theorem 2 depends specifically on our choice 
of a and b. Different choices of a and b Iead to different values of a. 
Moreover, a doesn't necessarily increase when a and b increase, since an 
increase in a or b will generally result in an increase in M. 
</p>
<p>Finally, we turn our attention to the problern of uniqueness of solutions 
of (1 ). Consider the initial-value problern 
</p>
<p>dy . 
- = (sm2tly 113 
dt I ' 
</p>
<p>y(O)=O. (15) 
</p>
<p>One solution of (15) isy(t)=O. Additional solutions can be obtained if we 
</p>
<p>76 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.10 The existence-uniqueness theorem; Picard iteration 
</p>
<p>ignore the fact that y(O) = 0 and rewrite the differential equation in the 
form 
</p>
<p>1 dy . 2 
yi/3 dt =sm t, 
</p>
<p>or 
d 3y2/3 . 
dt - 2 - =sm2t. 
</p>
<p>Then, 
</p>
<p>3y213 1 - cos 2t . 2 
- 2- = 2 = sm t 
</p>
<p>and y = &plusmn; V8j27 sin3 t are two additional solutions of (15). 
N ow, initial-value problems that have more than one solution are 
</p>
<p>clearly unacceptable in applications. Therefore, it is important for us to 
find out exactly what is "wrong" with the initial-value problern (15) that it 
has more than one solution. If we Iook carefully at the right-hand side of 
this differential equation, we see that it does not have a partial derivative 
with respect to y at y = 0. This is indeed the prob lern, as the following theo-
rem shows. 
</p>
<p>Theorem 2'. Letfand aj I ay be continuous in the reetangle R : to.;;; t .;;; to + a, 
IY- Yol &lt; b. Compute 
</p>
<p>M= max if(t,y)j, andset a=min(a,_!:_). 
(0)mR M 
</p>
<p>Then, the initial-value problern 
</p>
<p>y'=j(t,y), ( 16) 
</p>
<p>has a unique solution y( t) on the interval t0 .;;; t.;;; t0 + a. In other words, if 
y(t) and z(t) are two solutions of (16), then y(t) must equal z(t) for t0 &lt; t 
&lt; t0 + a. 
</p>
<p>PROOF. Theorem 2 guarantees the existence of at least one solution y(t) of 
(16). Suppose that z(t) is a second solution of (16). Then, 
</p>
<p>y(t) = y 0 + j 1f(s,y(s))ds and z(t) = y 0 + J1i(s,z(s))ds. 
to to 
</p>
<p>Subtracting these two equations gives 
</p>
<p>IY(t)- z(t)l = v:[f(s,y(s))- f(s,z(s))] dsl 
</p>
<p>&lt;. J1if(s,y(s))-f(s,z(s))l ds 
lo 
</p>
<p>&lt;. L J1iy(s) -z(s)ids 
to 
</p>
<p>77 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>where L is the maximum value of iofjoyi for (t,y) in R. As Lemma 2 be-
low shows, this inequality implies that y ( t) = z ( t). Hence, the initial-value 
problern (16) has a unique solutiony(t). 0 
</p>
<p>Lemma 2. Let w(t) be a nonnegative function, with 
</p>
<p>w(t) ~ L J1w(s)ds. 
to 
</p>
<p>Then, w(t) is identically zero. 
</p>
<p>FAKE PROOF. Differentiating both sides of (17) gives 
</p>
<p>dw dw dt ~ Lw(t), or dt- Lw(t) ~0. 
</p>
<p>(17) 
</p>
<p>Multiplying both sides of this inequality by the integrating factor e-L(t-to) 
gives 
</p>
<p>~ e-L(t-to)w(t) ~ 0, so that e-L(t-to)w(t) ~ w(t0 ) 
</p>
<p>for t ';;!&gt; t0&bull; But w(t0) must be zero if w(t) is nonnegative and satisfies (17). 
Consequently, e-L(t-to&gt;w(t) ~ 0, and this implies that w(t) is identically 
zero. 
</p>
<p>The error in this proof, of course, is that we cannot differentiate both 
sides of an inequality, and still expect to preserve the inequality. For exam-
ple, the function j 1 ( t) = 2t- 2 is less than fit)= t on the interval [0, 1], but 
f{(t) is greater than f2(t) on this interval. We make this proof "kosher" by 
the clever trick of setting 
</p>
<p>U(t) = {w(s)ds. 
to 
</p>
<p>Then, 
</p>
<p>dU f' -d = w(t) ~ L w(s)ds= LU(t). 
t to 
</p>
<p>Consequently, e-L(t-to)U(t)~ U(t0)=0, for t';;l&gt; t0, and thus U(t)=O. This, 
in turn, implies that w( t) = 0 since 
</p>
<p>0~ w(t) ~ L {w(s)ds= LU(t)=O. 
to 
</p>
<p>Example 3. Show that the solution y ( t) of the initial-value problern 
</p>
<p>dy = t2+ e_Y2 
dt ' 
</p>
<p>y(O)=O 
</p>
<p>exists for 0 ~ t ~ i, and in this interval, I y ( t)l ~ 1. 
</p>
<p>78 
</p>
<p>0 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.10 The existence-uniqueness theorem; Picard iteration 
</p>
<p>Solution. Let R be the reetangle 0 ~ t ~ t, IYI ~ 1. Computing 
</p>
<p>we see that y(t) exists for 
</p>
<p>0 &middot;(I I) I ~t~mm 2' 5/4 =2, 
</p>
<p>and in this interval, ly(t)l &lt; I. 
</p>
<p>Example 4. Show that the solution y(t) of the initial-value problern 
</p>
<p>: =e-r&gt;+y3, y(O)=I 
</p>
<p>exists for 0 &lt; t &lt; I /9, and in this interval, 0 ~ y ~ 2. 
Solution. Let R be the reetangle 0 ~ t ~ !-, 0 &lt; y ~ 2. Computing 
</p>
<p>M= max e- 12 +y 3 =1+23 =9, 
(t,y) in R 
</p>
<p>we see that y(t) exists for 
</p>
<p>0 &lt; t ~ min( t, t) 
and in this interval, 0 &lt; y ~ 2. 
</p>
<p>Example 5. What is the largest interval of existenee that Theorem 2 pre-
diets for the solution y ( t) of the initial-value problern y' = I + y 2, y (0) = 0? 
</p>
<p>Solution. Let R be the reetangle 0 ~ t ~ a, IYI &lt; b. Computing 
</p>
<p>M= max l+y 2 =l+b 2, 
(t,y) in R 
</p>
<p>we see that y(t) exists for 
</p>
<p>0&lt; t&lt; a=min(a,~)&middot; 
l+b 
</p>
<p>Clearly, the largest a that we ean aehieve is the maximum value of the 
funetion b/(1 +b2). This maximum value ist. Henee, Theorem 2 prediets 
</p>
<p>that y ( t) exists for 0 ~ t ~ t. The faet that y ( t) = tan t exists for 0 &lt; t ~ 7T /2 
points out the Iimitation of Theorem 2. 
</p>
<p>Example 6. Suppose that lf(t,y)l &lt;Kin the strip t0 ~ t &lt; oo,- oo &lt;y &lt; oo. 
Show that the solution y(t) of the initial-value problern y' = f(t,y), y(t0) = 
y 0 exists for all t;;;. t0. 
Solution. Let R be the reetangle t0 ~ t ~ t0 + a, IY-Yol ~ b. The quantity 
</p>
<p>M= max lf(t,y)l 
(t,y) m R 
</p>
<p>79 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>is at most K. Hence, y(t) exists for 
</p>
<p>t0 &lt; t &lt; t0 +min(a,bj K). 
</p>
<p>Now, we can make the quantity min(a,bj K) as large as desired by choos-
ing a and b sufficiently large. Therefore y(t) exists for t ~ t0. 
</p>
<p>EXERCISES 
</p>
<p>1. Construct the Picard iterates for the initial-value problern y' =2t(y + 1), y(O) = 
0 and show that they converge to the solution y (t) = e 12 - 1. 
</p>
<p>2. Cornpute the first two Picard iterates for the initial-value problern y' = t 2 + y 2, 
y(O)= 1. 
</p>
<p>3. Cornpute the first three Picard iterates for the initial-value problerny' = e 1 + y 2, 
y(O)=O. 
</p>
<p>In each of Problems 4--15, show that the solutiony(t) of the given initial-
value problern exists on the specified interval. 
</p>
<p>4.y'=y2 +cost2, y(O)=O; O.;;t.;;~ 
</p>
<p>5.y'=l+y+y2 cost, y(O)=O; O.;;t.;;} 
</p>
<p>6. y'= t + y 2 ,y(O) = 0; 0.;;: t.;;: (D213 
</p>
<p>7.y'=e- 12 +y2 , y(O)=O; O.;;t.;;! 
</p>
<p>8. y' = e- 12 + y 2, y(l) = 0; 1 .;;: t .;;: 1 + Ve /2 
</p>
<p>9.y'=e- 12 +y 2, y(O)=l; O.;;t.;; V2 
1+(1 +Yl )2 
</p>
<p>10.y'=y+e-Y+e- 1, y(O)=O; O.;;t.;;l 
</p>
<p>ll.y'=y 3 +e- 51 , y(0)=0.4; O.;;t.;;-fo 
</p>
<p>12.y'=e&lt;y- 1Jl, y(O)=l; O.;;t.;; v'32- 1e-&laquo;1+YJ)/2P 
</p>
<p>13. y' =(4y + e- 12)e2Y, y(O)=O; 0.;;: t.;;: _l_ 
8Ve 
</p>
<p>14.y'=e- 1+ln(!+y2), y(O)=O; O.;;t&lt;oo 
</p>
<p>15.y'=W+cos4t)y- 8 ~(1-cos4t)y 2 , y(O)=lOO; O.;;t.;;l 
</p>
<p>16. Consider the initial-value problern 
</p>
<p>80 
</p>
<p>y(O)=O, 
</p>
<p>and Iet R be the reetangle 0.;;: t.;;: a, - b.;;: y.;;: b. 
(a) Show that the solutiony(t) of (*) exists for 
</p>
<p>O.;; t.;;: min(a, --/!--z). 
a +b 
</p>
<p>(*) </p>
<p/>
</div>
<div class="page"><p/>
<p>1.11 Finding roots of equations by iteration 
</p>
<p>(b) Show that the maximum value of b/(a2 +b2), for a fixed, is l/2a. 
(c) Show that a=min(a,ta) is largest when a=l/v'2. 
</p>
<p>( d) Conclude that the solution y ( t) of (*) exists for 0 &lt; t &lt; l / v'2 . 
17. Prove that y(t)= -1 is the only solution of the initial-value problern 
</p>
<p>y'=t(l+y), y(O)=-l. 
</p>
<p>18. Find a nontrivial solution of the initial-value problern y' = (Y a, y (0) = 0, a &gt; l. 
Does this violate Theorem 2'? Explain. 
</p>
<p>19. Find a solution of the initial-value problern y' = t VT=7 , y(O) =I, other than 
y ( t) = l. Does this violate Theorem 2'? Explain. 
</p>
<p>20. Here is an alternate proof of Lemma 2. Let w(t) be a nonnegative function 
with 
</p>
<p>w(t).;; L {w(s)ds 
lo 
</p>
<p>(*) 
</p>
<p>on the interval t0 .;; t.;; t0 + a. Since w(t) is continuous, we can find a constant 
A such that 0.;; w( t).;; A for t0 &lt; t .;; t0 + a. 
(a) Show that w(t) &lt;LA (t- t0). 
(b) Use this estimate of w(t) in(*) to obtain 
</p>
<p>AL2 (t- t 0 ) 2 
w(t).;; 2 
</p>
<p>(c) Proceeding inductively, show that w(t)&lt;;;ALn(t-t0)n/n!, for every integer 
n. 
</p>
<p>( d) Conclude that w(t) = 0 for t0 &lt; t &lt; t0 + a. 
</p>
<p>1.11 Finding roots of equations by iteration 
</p>
<p>Suppose that we are interested in finding the roots of an equation having 
the special form 
</p>
<p>x=f(x). 
</p>
<p>For example, we might want to find the roots of the equation 
</p>
<p>x=sinx+ ~&middot; 
</p>
<p>(1) 
</p>
<p>The methods introduced in the previous section suggest the following algo-
rithm for solving this problem. 
</p>
<p>1. Try an initial guess x0, and use this number to construct a sequence of 
guesses x 1,x2,x3, &bull;&bull;&bull; , where x 1=f(x0), x2 =j(x1), x3 =f(x2), and so on. 
</p>
<p>2. Show that this sequence of iterates xn has a Iimit 11 as n approaches in-
finity. 
</p>
<p>3. Show that 11 is a root of (1); i.e., 11 = f( 11). 
</p>
<p>The following theorem teils us when this algorithm will work. 
</p>
<p>Theorem 3. Let f(x) and f'(x) be continuous in the interval a &lt; x.;;; b, with 
if'(x)l &lt; A &lt; 1 in this interval. Suppose, moreover, that the iterates xn, de-
</p>
<p>81 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>fined recursively by the equation 
</p>
<p>Xn+l = f(xn) (2) 
</p>
<p>a/1 /ie in the interval [a,b]. Then, the iterates xn converge to a unique num-
ber 11 satisfying (1). 
</p>
<p>PROOF. We convert the problern of proving that the sequence xn converges 
to the simpler problern of proving that an infinite series converges by writ-
ing xn in the form 
</p>
<p>Xn = x0 +(x1- x0) + (x2- x1) + ... + (xn- xn_ 1). 
</p>
<p>Clearly, the sequence xn converges if, and only if, the infinite series 
00 
</p>
<p>(x1-x0)+(x2-x1)+ ... +(xn-xn_ 1)+ ... = ~ (xn-xn_ 1) 
n=l 
</p>
<p>converges. To prove that this infinite series converges, it suffices to show 
that 
</p>
<p>00 
</p>
<p>lxl-xol+lx2-xll+ ... = ~ lxn-xn-ll&lt;oo. 
n-1 
</p>
<p>This is accomplished in the following manner. By definition, xn = f(xn_ 1) 
and xn-l =J(xn_ 2). Subtracting these two equations gives 
</p>
<p>where ~ is some number between xn _1 and xn _ 2&bull; In particular, ~ is in the 
interval [a,b]. Therefore, lf'(~)lt;;; X, and 
</p>
<p>lxn- Xn-11..;; XIxn-I- Xn-21&middot; 
</p>
<p>Iterating this inequality n- 1 times gives 
</p>
<p>Consequently, 
</p>
<p>lxn- Xn-11..;; XIxn-I- .(n-21 
</p>
<p>t;;;X 21Xn-2-xn-31 
</p>
<p>00 00 
</p>
<p>~ lxn-xn_J!t;;; ~ xn-llxl-xol 
n=l n=l 
</p>
<p>(3) 
</p>
<p>This quantity, obviously, is less than infinity. Therefore, the sequence of 
iterates xn has a Iimit 11 as n approaches infinity. Taking Iimits of both 
</p>
<p>82 </p>
<p/>
</div>
<div class="page"><p/>
<p>l.ll Finding roots of equations by iteration 
</p>
<p>sides of (2) gives 
</p>
<p>Hence, 11 is a root of (1). 
Finally, suppose that 11 is not unique; that is, there exist two solutions 71 1 
</p>
<p>and 712 of ( 1) in the interval [ a, b ]. Then, 
</p>
<p>where g is some number between 71 1 and 712&bull; This implies that 71 1 = 712 or j'(g) 
= 1. Butf'(g) cannot be one, since g is in the interval [a,b]. Therefore, 71 1 = 
~ D 
</p>
<p>Example 1. Show that the sequence of iterates 
</p>
<p>converge to a unique number 11 satisfying 
</p>
<p>for every initial guess x0&bull; 
Solution. Letf(x)=1+tarctanx. Computingf'(x)=ti/(l+x2), we see 
that lf'(x)l is always less than or equal to t. Hence, by Theorem 3, the 
sequence of iterates x0 , x 1, x2, &bull; &bull; &bull; converges to the unique root 11 of the 
equation x = 1 + tarc tanx, for every choice of x0 &bull; 
</p>
<p>There are many instances where we know, a priori, that the equation 
x=j(x) has a unique solution T/ in a given interva1 [a,b]. In these in-
stances, we can use Theorem 3 to obtain a very good approximation of Tl&middot; 
Indeed, life is especially simple in these instances, since we don't have to 
check that the iterates xn all lie in a specified interval. If x0 is sufficiently 
close to 71, then the iterates xn will a1ways converge to 71, as we now show. 
</p>
<p>Theorem 4. Assurne that f( Tl)= f/, and that lf'(x)l ~ A &lt; 1 in the interval 
lx- 111 ~ a. Choose a number x0 in this interval. Then, the sequence of 
iterates xn, defined recursively by the equation xn+ 1 = f(xn), will always 
converge to '11&middot; 
</p>
<p>PROOF. Denote the interval lx- Tl I~ a by /. By Theorem 3, it suffices to 
show that all the iterates xn lie in /. To this end, observe that 
</p>
<p>xi+ 1- T/ = f(xi)- f(Tt) = j'(g)(x1 - Tl) 
</p>
<p>where g is some number between x1 and Tl&middot; In particular, g is in I if x1 is in 
</p>
<p>83 </p>
<p/>
</div>
<div class="page"><p/>
<p>I First-order differential equations 
</p>
<p>I. Thus, 
</p>
<p>(4) 
</p>
<p>if JC_j is in I. This implies that x1+ 1 is in I whenever x1 is in I. By induction, 
therefore, all the iterates xn lie in I. D 
</p>
<p>Equation (4) also shows that xn+ 1 is closer to 11 than xn. Specific~lly, the 
error we make in approximating 11 by xn decreases by at least a factor of A 
each time we increase n. Thus, if A is very small, then the convergence of xn 
to 11 is very rapid, while if A is close to one, then the convergence is very 
slow. 
</p>
<p>Example 2. 
</p>
<p>(a) Show that the equation 
</p>
<p>. I 
x=smx+ 4 
</p>
<p>has a unique root 1J in the interval [ 1r I 4, 1r 12]. 
(b) Show that the sequence of numbers 
</p>
<p>&middot; I &middot; I x 1 =smx0 + 4 , x2 =smx 1 + 4 , ... 
</p>
<p>will converge to 1J if 7T I 4 &lt; x 0 &lt; 1r 12. 
</p>
<p>(5) 
</p>
<p>(c) Write a computerprogram to evaluate the first N iterates x 1,x2, ... ,xN. 
Solution. 
(a) Let g(x) = x- sin x- i, and observe that g( 1r I 4) is negative while 
g(1r 12) is positive. Moreover, g(x) is a monotonic increasing function of x 
for 1r I 4 &lt; x &lt; 7T 12, since its derivative is strictly positive in this interval. 
Therefore, Equation (5) has a unique root x = 1J in the interval 1r I 4 &lt; x &lt; 
7T 12. 
(b) Let I denote the interval 11- 1r I 4 &lt; x &lt; 1J + 1r I 4. The left endpoint of 
this interval is greater than zero, while the right endpoint is less than 37r I 4. 
Hence, there exists a number A, with O&lt;X&lt; 1, suchthat 
</p>
<p>jcosxl =I~ (sinx + nl.;;;; A 
</p>
<p>for x in I. Clearly, the interval [ 1r I 4, 1r 121 is contained in I. Therefore, by 
Theorem 4, the sequence of numbers 
</p>
<p>will converge to 1J for every x 0 in the interval [ 1r I 4, 1r 12]. 
</p>
<p>84 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.11 Finding roots of equations by iteration 
</p>
<p>(c) 
</p>
<p>Pascal Program 
</p>
<p>Program lterate (input, output); 
var 
</p>
<p>X: array[O .. 199] of real; 
k, N: integer; 
</p>
<p>begin 
readln(X[O], N); 
page; 
writeln('N':4, 'X[N]':14); 
for k := 0 to N do 
</p>
<p>end. 
</p>
<p>begin 
writel n (K:4, &middot; ':4, X [k]: 17:9); 
X[k+ 1] :=0.25+sin(X[k]); 
</p>
<p>end; 
</p>
<p>c 
</p>
<p>c 
</p>
<p>10 
</p>
<p>20 
</p>
<p>30 
40 
</p>
<p>Fortran Program 
</p>
<p>DIMENSION X(200) 
READ (5, 1 0) XO, N 
FORMAT (F15.8, 15) 
COMPUTE X(1) FIRST 
X(1) = 0.25 + SIN(XO) 
KA=O 
KB=1 
WRITE (6, 20) KA, XO, KB, X(1) 
FORMAT (1 H1, 4X, 'N', 1 OX, 'X'/ (1 H, 3X, 13, 4X, F15.9)) 
COMPUTE X(2) THRU X(N) 
DO 40 K=2,N 
X(K) = 0.25 + SIN(X(K -1 )) 
WRITE (6, 30) K, X(K) 
FORMAT (1 H, 3X, 13, 4X, F15.9) 
CONTINUE 
CALL EXIT 
END 
</p>
<p>See also C Program 1 in Appendix C for a sample C program. 
</p>
<p>85 </p>
<p/>
</div>
<div class="page"><p/>
<p>l First-order differential equations 
</p>
<p>Table 1 
</p>
<p>n Xn n Xn 
</p>
<p>0 l 8 1.17110411 
1 1.09147099 9 1.17122962 
2 1.13730626 lO 1.17122964 
3 1.15750531 ll 1.17122965 
4 1.16580403 12 1.17122965 
5 1.16910543 13 1.17122965 
6 1.17040121 14 1.17122965 
7 1.17090706 15. 1.17122965 
</p>
<p>In many instances, we want to compute a root of the equation x = f(x) 
to within a certain accuracy. The easiest, and most efficient way of accom-
</p>
<p>plishing this is to instruct the computer to terminate the program at k = j if 
xj+ 1 agrees with xj within the prescribed accuracy. 
</p>
<p>EXERCISES 
</p>
<p>1. Let 'II be the unique root of Equation (5). 
(a) Let x0= TT /4. Show that 20 iterations are required to find 'IJ to 8 significant 
</p>
<p>decimal places. 
(b) Let x0 = TT /2. Show that 20 iterations are required to find 'II to 8 decimal 
</p>
<p>places. 
(c) Let x0 =3TTj8. Show that 16 iterations are required to find 'II to 8 decima1 
</p>
<p>p1aces. 
</p>
<p>2. (a) Determine suitab1e va1ues of x0 so that the iterates xn, defined by the equa-
tion 
</p>
<p>will converge to V2 . 
(b) Choose x0 = 1.4. Show that 14 iterations are required to find V2 to 8 signifi-
</p>
<p>cant decima1 p1aces. (V2 = 1.41421356 to 8 significant decima1 p1aces.) 
</p>
<p>3. (a) Determine suitab1e values of x0 so that the iterates xn, defined by the equa-
tion 
</p>
<p>will converge to V2 . 
(b) Choose x0 = 1.4. Show that 30 iterations are required to find V2 to 6 signifi-
</p>
<p>cant decimal p1aces. 
</p>
<p>4. (a) Determine a suitab1e va1ue of a so that the iterates xn, defined by the equa-
tion 
</p>
<p>86 
</p>
<p>Xn+ I= Xn- a(xn2-3), 
</p>
<p>will converge to V3 . 
(b) Find V3 to 6 significant decimal p1aces. 
</p>
<p>x0 = 1.7 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.11 Finding roots of equations by iteration 
</p>
<p>5. Let TJ be the unique root of the equation x = 1 + t arc tanx. Find TJ to 5 signifi-
cant decimal places. 
</p>
<p>6. (a) Show that the equation 2-x=(lnx)/4 has a unique root x=TJ in the inter-
val 0&lt; x&lt; oo. 
</p>
<p>(b) Let 
</p>
<p>n =0, 1,2, ... 
</p>
<p>Show that I .;;; Xn .;;; 2 if 1 .;;; x0 .;;; 2. 
(c) Prove that Xn~TJ as n~oo if I .;;; x0 .;;; 2. 
(d) Compute TJ to 5 significant decimal places. 
</p>
<p>7. (a) Show that the equation x = cosx has a unique root x = TJ in the interval 0.;;; x 
.;;I. 
</p>
<p>(b) Let Xn+ 1=cosxm n=0,1,2, ... , with 0&lt;x0 &lt;l. Show that O&lt;xn&lt;l. Con-
clude, therefore, that xn~TJ as n~oo. 
</p>
<p>(c) Find TJ to 5 significant decimal places. 
</p>
<p>1.11.1 Newton's method 
</p>
<p>The method of iteration which we used to solve the equation x = f(x) can 
also be used to solve the equation g(x) = 0. To wit, any solution x = 71 of 
the equation g(x)=O is also a solution of the equation 
</p>
<p>x=f(x)=x-g(x), (!) 
</p>
<p>and vice-versa. Better yet, any solution x = 71 of the equation g(x) = 0 is 
also a solution of the equation 
</p>
<p>g(x) 
x=f(x)=x- --
</p>
<p>h(x) 
(2) 
</p>
<p>for any function h(x). Of course, h(x) must be unequal to zero for x near 
</p>
<p>Tl&middot; 
Equation (2) has an arbitrary function h(x) in it. Let us try and choose 
</p>
<p>h(x) so that (i) the assumptions of Theorem 4, Section 1.11 are satisfied, 
and (ii) the iterates 
</p>
<p>g(xo) g(xl) 
X I= Xo- h ( Xo) ' X2 =X I - h (X I) ' ... 
</p>
<p>converge as "rapidly as possible" to the desired root Tl&middot; To this end, we 
compute 
</p>
<p>, _ d [ g(x) l g'(x) h'(x)g(x) 
j (x)- dx x- h(x) = l- h(x) + h2 (x) 
</p>
<p>and observe that 
</p>
<p>j '( ) = 1 - g' (Tl) 
Tl h(71) . 
</p>
<p>87 </p>
<p/>
</div>
<div class="page"><p/>
<p>I First-order differential equations 
</p>
<p>This suggests that we set h(x)=g'(x), since then f'(TJ)=O. Consequently, 
the iterates xn, defined recursively by the equation 
</p>
<p>g(xn) 
Xn +I = Xn - ---;--( ) ' g Xn 
</p>
<p>n=O, 1,2, ... (3) 
</p>
<p>will converge to TJ if the initial guess x0 is sufficiently close to TJ. (If f'( TJ) = 
0, then \f'(x)\ &lt;X&lt; 1 for ix- TJ\ sufficient1y small.) Indeed, the choice of 
h(x)= f'(x) is an optimal choice of h(x), since the convergence of xn to TJ 
will be extremely rapid. This follows immediately from the fact that the 
number X in Equation 4, Section 1.11 can be taken arbitrarily small, as xn 
approaches TJ&middot; 
</p>
<p>The iteration scheme (3) is known as Newton's method for solving the 
equation g(x)=O. lt can be shown that if g(TJ)=O, and x0 is sufficiently 
close to TJ, then 
</p>
<p>ixn+ 1- TJ\ &lt; c\xn- TJ\ 2, 
for some positive constant c. In other words, the error we make in ap-
proximating TJ by xn + 1 is proportional to the square of the error we make 
in approximating TJ by xn. This type of convergence is called quadratic con-
vergence, and it implies that the iterates xn converge extremely rapidly to 
TJ&middot; In many instances, only five or six iterations are required to find TJ to 
eight or more significant decimal places. 
</p>
<p>Example 1. Use Newton's method to compute VI. 
Solution. The square root of two is a solution of the equation 
</p>
<p>g(x)=x 2 -2=0. 
</p>
<p>Hence, Newton's scheme for this problern is 
</p>
<p>(x/-2) 
</p>
<p>n=O, 1,2, .... (4) 
</p>
<p>Sampie Pascal and Fortran programs to compute the first N iterates of an 
initial guess x0 are given below. 
</p>
<p>Pascal Program 
</p>
<p>Program Newton (input, output); 
var 
</p>
<p>X: array[O .. 199] of real; 
k, N: integer; 
</p>
<p>begin 
</p>
<p>88 
</p>
<p>readln (X[O], N); 
page; </p>
<p/>
</div>
<div class="page"><p/>
<p>1.11 Finding roots of equations by iteration 
</p>
<p>writeln('N':4, 'X[N]':14); 
for k :=Oto N do 
</p>
<p>end. 
</p>
<p>begin 
writeln{K:4,' ':4, X[k]:17:9); 
X[k+ 1] :=X[k]/2+ 1/X[k]; 
</p>
<p>end; 
</p>
<p>Table 1 
</p>
<p>n Xn 
</p>
<p>0 1.4 
I 1.41428571 
2 1.41421356 
</p>
<p>n 
</p>
<p>3 
4 
5 
</p>
<p>Fortran Program 
</p>
<p>Xn 
</p>
<p>1.41421356 
1.41421356 
1.41421356 
</p>
<p>We need only replace the instructions for computing X(1) and X(K) in the 
F ortran program of Section 1.11 by 
</p>
<p>X(1)=(XOI2)+ 1 IXO 
</p>
<p>and 
</p>
<p>X(K)=(X(K -1)12)+1 IX(K -1) 
</p>
<p>We ran these programs for x0 = 1.4 and N = 5, and the results are given in 
Table 1. Notice that Newton's method requires only 2 iterations to find 
</p>
<p>v'2 to eight significant decimal places. 
See also C Program 2 in Appendix C for a sample C program. 
</p>
<p>Example 2. Use Newton's method to find the impact velocity of the drums 
in Section 1. 7. 
Solution. The impact velocity of the drums satisfies the equation 
</p>
<p>300 cg W- B l [ W- B - cv ] g(v)=v+ -- + -- n =0 
W c W-B 
</p>
<p>(5) 
</p>
<p>where 
</p>
<p>c=0.08, g=32.2, W=527.436, and B=470.327. 
</p>
<p>Setting a = ( W- B) I c and d = 300cg I W puts ( 5) in the simpler form 
</p>
<p>g(v)=v+d+aln(l-vla)=O. (6) 
</p>
<p>Newton's iteration scheme for this problern is 
</p>
<p>89 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>n=O, 1,2, .... 
</p>
<p>Sample Pascal and Fortran programs to compute the first N iterates of v0 
are given below. 
</p>
<p>Pascal Program 
</p>
<p>Program Newton (input, output); 
</p>
<p>const 
c =0.08; 
g =32.2; 
W=527.436; 
B =470.327; 
</p>
<p>var 
V: array[O .. 199] of real; 
a, d: real; 
k, N: integer; 
</p>
<p>begin 
readln(V[O], N); 
a := (W- B)/c; 
d :=300 * c &bull; g/W; 
page; 
writeln('N':4, 'V[N)':14); 
for k :=0 to N do 
</p>
<p>begin 
writeln(K:4,' ':4, V[k]:17:9); 
V[k + 1] := V[k] + ((a- V[k] )IV[k]) 
</p>
<p>end; 
end. 
</p>
<p>&bull; (V[k] + d + a &bull; ln(1- (V[k]/a))); 
</p>
<p>Fortran Program 
</p>
<p>Change every X to V, and replace the instructions for X(1) and X(K) in the 
Fortranprogram of Section 1.11 by 
</p>
<p>V{1)=VO+((A-VO)/VO)*(VO+D+A*A LOG(1----: (VO I A))) 
and 
</p>
<p>90 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.12 Difference equations 
</p>
<p>V(K)=V(K -1 )+((A-V(K -1 JliV(K -1 ))* (V(K -1)+ D 
</p>
<p>+A*A LOG (1-(V(K -1) I A))) 
</p>
<p>(Before running these programs, of course, we must instruct the computer 
to evaluate the constants a = (W-B) I c and d = 300 cg I W.) 
</p>
<p>As was shown in Section 1.7, v0 =45.7 is a very good approximation of 
v. We set v0 =45.7 in the above programs, and the iterates vn converged 
very rapidly to v = 45.1 ftl s. Thus, the drums can indeed break upon im-
pact. 
</p>
<p>In general, it is not possible to determine, a priori, how many iterations 
will be required to achieve a certain accuracy. In practice, we usually take 
N very !arge, and instruct the computer to terminate the program if one of 
the iterates agrees with its predecessor to the desired accuracy. 
</p>
<p>See also C Program 3 in Appendix C for a sample C program. 
</p>
<p>EXERCISES 
</p>
<p>1. Show that the iterates Xn defined by (4) will converge to V2 if 
</p>
<p>V273 &lt;x0 &lt;V2 +(V2- V273 ). 
</p>
<p>2. Use Newton's method to find the following numbers to 8 significant decimal 
places. (a) v'3, (b) V5, (c) V7. 
</p>
<p>3. The number '1T is a root of the equation 
X X 
</p>
<p>tan 4 -cot4 =0. 
</p>
<p>Use Newton's method to find '1T to 8 significant decimal places. 
</p>
<p>Show that each of the following equations has a unique solution in the 
given interval, and use N ewton's method to find it to 5 significant decimal 
places. 
</p>
<p>4. 2x-tanx=O; 'TT""x""3'1TI2 
</p>
<p>6. Inx+(x+ 1)3 =0; O&lt;x&lt; l ,C 'TTX 7. 2vx =cos 2 ; O""x"" l 
</p>
<p>9. x-e-x2 =1; O""x""2. 
</p>
<p>1.12 Difference equations, and how to compute 
the interest due on your student loans 
</p>
<p>In Sections 1.13-1.16 we will construct various approximations of the solu-
tion of the initial-value problern dyldt=f(t,y), y(t0),=y0&bull; In determining 
how good these approximations are, we will be confronted with the follow-
</p>
<p>91 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>ing problem: How large can the numbers E 1, ... ,EN be if 
</p>
<p>n = 0, 1, ... , N- 1 (1) 
</p>
<p>for some positive constants A and B, and E0 = 0? This is a very difficult 
problern since it deals with inequalities, rather than equalities. Fortunately, 
though, we can convert the problern of solving the inequalities (1) into the 
simpler problern of solving a system of equalities. This is the content of the 
following Iemma. 
</p>
<p>Lemma 1. Let E1, &bull;&bull;&bull; , EN satisjj; the inequa/ities 
</p>
<p>En+l &lt;AEn+B, E0 =0 
</p>
<p>for some positive constants A and B. Then, En is less than or equal to Yn' 
where 
</p>
<p>Yn+I=Ayn+B, Yo=O. (2) 
</p>
<p>PROOF. We prove Lemma 1 by induction on n. To this end, observe that 
Lemma 1 is obviously true for n = 0. Next, we assume that Lemma 1 is true 
for n=j. We must show that Lemma I is also true for n=j+ I. That is to 
say, we must prove that ~ &lt; y1 implies ~+I&lt; YJ+I&middot; But this follows im-
mediately, for if ~ &lt; y1 then 
</p>
<p>~+I &lt;AE1+B&lt;Ay1 +B=yJ+I&middot; 
</p>
<p>By induction, therefore, En &lt; Yn' n=O, l, ... ,N. D 
Our next task is to solve Equation (2), which is often referred to as a dif-
</p>
<p>ference equation. We will accomplish this in two steps. First we will solve 
the "simple" difference equation 
</p>
<p>Yo= Yo&middot; (3) 
</p>
<p>Then we will reduce the difference equation (2) to the difference equation 
(3) by a clever change of variables. 
</p>
<p>Equation (3) is trivial to solve. Observe that 
</p>
<p>Y1-Yo =Bo 
Y2-Y1 =BI 
</p>
<p>Yn-1- Yn-2 = Bn-2 
Yn- Yn-I=Bn-1&middot; 
</p>
<p>Adding these equations gives 
</p>
<p>(Yn- Yn-1) +(Yn-1-Yn-z)+ &middot;&middot;&middot; +(yi-Yo)= Bo+ BI+&middot;&middot;&middot;+ Bn-1&middot; 
</p>
<p>Hence, 
</p>
<p>92 
</p>
<p>n-1 
Yn=Yo+Bo+ &middot;&middot;&middot; +Bn-l=yo+ L Bp 
</p>
<p>}=0 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.12 Difference equations 
</p>
<p>Next, we reduce the difference equation (2) to the simpler equation (3) 
in the following clever manner. Let 
</p>
<p>n=O, l, ... ,N. 
</p>
<p>Then, zn+i=Yn+I/An+l. Butyn+I=Ayn+B. Consequently, 
</p>
<p>Therefore, 
</p>
<p>and 
</p>
<p>Yn B B 
z =-+--=z +--n+l An An+l n An+i' 
</p>
<p>B 
Yn=Anzn=Anyo+ A-1 (An-1). 
</p>
<p>Finally, returning to the inequalities (l), we see that 
</p>
<p>n=l,2, ... ,N. 
</p>
<p>(4) 
</p>
<p>(5) 
</p>
<p>While collecting material for this book, this author was approached by a 
colleague with the following problem. He had just received a bill from the 
bank for the first payment on his wife's student loan. This loan was to be 
repaid in 10 years in 120 equal monthly installments. According to his 
rough estimate, the bank was overcharging him by at least 20%. Before 
confronting the bank's officers, though, he wanted to compute exactly the 
monthly payments due on this loan. 
</p>
<p>This problern can be put in the following more generat framework. 
Suppose that P dollars are borrowed from a bank at an annual interest rate 
of R %. This loan is to be repaid in n years in equal monthly installments of 
x dollars. Find x. 
</p>
<p>Our first step in solving this problern is to compute the interest due on 
the loan. To this end observe that the interest I 1 owed when the first pay-
ment is due is I 1 =(r/12)P, where r=R/100. The principal outstanding 
during the second month of the loan is (x- I 1) less than the principal out-
standing during the first month. Hence, the interest I 2 owed during the sec-
ond month of the loan is 
</p>
<p>r 
I2=I,-Ti(x-Id. 
</p>
<p>Similarly, the interest ~+ 1 owed during the (j + l)st month is 
</p>
<p>93 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>~ + 1 = ~- (2 (X - ~) = (I + (2 )~ - (2 X, 
where ~ is the interest owed during the jth month. 
</p>
<p>Equation (6) is a difference equation for the numbers 
</p>
<p>lts solution (see Exercise 4) is 
</p>
<p>r { r )J-1 [ { r )J-1] 
~= 12 P I+ 12 +x I- I+ 12 
</p>
<p>Hence, the total amount of interest paid on the loan is 
12n 
</p>
<p>Now, 
</p>
<p>I= I 1 + I 2 + ... + I 12n = ~ ~ 
}=I 
</p>
<p>12n 12n 
= (2 p ~ (I+ (2 r-1 + I2nx- x ~ (I+ (2 r-t 
</p>
<p>j=l }=I 
</p>
<p>~{ r)J-1 I2[{ r)l2n] 
~ I+12 =-;: I+12 -I. 
J=l 
</p>
<p>Therefore, 
</p>
<p>[( r )12n ] I2x [{ r )12n ] I=P I+ 12 -1 +12nx--r- 1+12 -1 
</p>
<p>= 12nx- p + p {I + (2 ) 12n- 1;x [ { 1 + ;2 ) 12n- I]. 
</p>
<p>(6) 
</p>
<p>But, 12nx- P must equal I, since 12nx is the amount of money paid the 
bank and P was the principalloaned. Consequently, 
</p>
<p>P(1+ (2)u"_l;x[{I+ (2f2"-I]=o 
</p>
<p>and this equation implies that 
</p>
<p>r { r )12n 
12p 1+12 
</p>
<p>x= (7) 
</p>
<p>{I+ (2 (n -1 
Epilog. Using Equation (7), this author computed x for his wife's and 
</p>
<p>his colleague's wife's student loans. In both cases the bank was right-to 
the penny. 
</p>
<p>94 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.12 Difference equations 
</p>
<p>EXERCISES 
</p>
<p>1. Solve the difference equation Yn+ 1 = -7yn + 2,y0 = I. 
</p>
<p>2. Findy37 if Yn+ 1 = 3yn +I, y 0 =0, n =0, I, ... ,36. 
</p>
<p>3. Estimate the numbers E0,E1, &bull;&bull;&bull; ,EN if E0 =0 and 
(a) En+lc;;;;3En+I,n=O,l, ... ,N-I; 
(b) En +I ..;; 2En + 2, n = 0, l' ... 'N- I. 
</p>
<p>4. (a) Show that the transformation y1 = ~+ 1 transforms the difference equation 
</p>
<p>~+t={I+ ( 2 )~- [2 x, It= [2 P 
</p>
<p>into the difference equation 
</p>
<p>YJ+l =(I+ [2 )Yr [2 X, 
</p>
<p>(b) Use Equation (4) to find y1_ 1 = ~-
</p>
<p>5. Soive the difference equation Yn+ 1 = anYn + bn, y 1 = a. Hint: Set z1 = y 1 and 
Zn= Yn/ a 1 &bull;&bull; &bull; an-! for n;;. 2. Observe that 
</p>
<p>Yn+ I OnYn bn 
Zn+l=---=---+---
</p>
<p>al&bull;&bull;&bull;an al&middot;&middot;&middot;an al&middot;&middot;&middot;an 
</p>
<p>bn 
=zn+---
</p>
<p>al&middot;&middot;&middot;an 
</p>
<p>Hence, conciude that Zn =z1 + ~j: lb1/ a1 &bull;&bull;&bull; a1. 
</p>
<p>6. Solve the difference equationyn+ 1-nyn= I-n,y 1 =2. 
</p>
<p>7. FindY25 if y 1 =I and (n + I)Yn+ 1- nyn =2n, n= I, ... ,24. 
</p>
<p>8. A student borrows P dollars at an annual interest rate of R%. This loan is tobe 
repayed in n years in equal monthly installments of x dollars. Find x if 
(a) P=4250, R=3, and n=5; 
(b) P=5000, R=7, and n= 10. 
</p>
<p>9. A home buyer takes out a $30,000 mortgage at an annual interest rafe of 9%. 
This loan is to be repaid over 20 years in 240 equal monthly installments of x 
dollars. 
(a) Compute x. 
(b) Find x if the annual interest rate is 10%. 
</p>
<p>10. The quantity supplied of some commodity in a given week is obviously an in-
creasing function of its price the previous week, while the quantity demanded 
in a given week is a function of its current price. Let ~ and D1 denote, respec-
tively, the quantities supplied and demanded in the jth week, and Iet I) denote 
the price of the commodity in thejth week. We assume that there exist positive 
constants a, b, and c such that 
</p>
<p>~=aP 1 _ 1 and D1=b-clj. 
</p>
<p>(a) Show that P1 =bj(a+c)+(-ajc)i(P0 -bj(a+c)), if supply always 
equals demand. 
</p>
<p>95 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>(b) Show that IJ approaches b I ( a + c) as j approaches infinity if a I c &lt; 1. 
(c) Show that P = b l(a + c) represents an equilibrium situation. That is to say, 
</p>
<p>if supply always equals demand, and if the price ever reaches the Ievel 
bl(a+c), then it will always remain at that Ievel. 
</p>
<p>1.13 Numerical approximations; Euler's method 
</p>
<p>In Section 1.9 we showed that it is not possible, in general, to solve the ini-
tial-value problern 
</p>
<p>dy 
dt = f(t,y), (1) 
</p>
<p>Therefore, in order that differential equations have any practical value for 
us, we must devise ways of obtaining accurate approximations of the solu-
tion y ( t) of ( 1 ). In Sections 1.13-1.16 we will derive algorithms, which can 
be implemented on a digital computer, for obtaining accurate approxima-
tions of y ( t). 
</p>
<p>Now, a computer obviously cannot approximate a function on an entire 
interval t0 &lt; t &lt; t0 + a since this would require an infinite amount of infor-
mation. At best it can compute approximate values y 1, ... ,yN of y(t) at a 
finite number of points t1, t2, ... , tN. However, this is sufficient for our pur-
pose since we can use the numbers y 1, &bull;&bull;&bull; ,yN to obtain an accurate ap-
proximation of y(t) on the entire interval t0 ..;; t &lt; t0 + a. To wit, let y(t) be 
the function whose graph on each interval [0, 0+ tl is the straight line con-
necting the points (0,Y) and (0+ 1,y1+ 1) (see Figure 1). We can express y(t) 
analytically by the equation 
</p>
<p>Figure 1. Comparison of j(t) and y(t) 
</p>
<p>96 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.13 Numerical approximations; Euler's method 
</p>
<p>If y(t) is close to y(t) at t= 0; that is, if y1 is close to y(0), and if 0+ 1 is 
close to 0&bull; theny(t) is close toy(t) on the entire interval0&lt;. t&lt;. 0+I&middot; This 
follows immediately from the continuity of both y(t) and y(t). Thus, we 
need only devise schemes for obtaining accurate approximations of y(t) at 
a discrete number of points t1, ... ,tN in the interval t0 &lt;. t&lt;. t0 +a. For sim-
plicity, we will require that the points t 1, ... , tN be equally spaced. This is 
achieved by cheosing a large integer N and setting tk=t0 +k(aiN), k= 
l, ... , N. Alternately, we may write tk + 1 = tk + h where h = a IN. 
</p>
<p>Now, the only thing we know about y( t) is that it satisfies a certain dif-
ferential equation, and that its value at t= t0 is y 0&bull; We will use this infor-
mation to compute an approximate value y 1 of y at t = t 1 = t0 + h. Then, we 
will use this approximate value y 1 to compute an approximate value Y2 of y 
at t = t2 = t 1 + h, and so on. In order to accomplish this we must find a the-
orem which enables us to compute the value of y at t = tk + h from the 
knowledge of y at t = tk. This theorem, of course, is Taylor's Theorem, 
which states that 
</p>
<p>dy ( tk) h2 d 2y( tk) 
y(tk+h)=y(tk)+h-d- + -2, 2 + .... (2) 
</p>
<p>t . dt 
</p>
<p>Thus, if we know the value of y and its derivatives at t = tk, then we can 
compute the value of y at t = tk + h. Now, y(t) satisfies the initial-value 
problern (1). Hence, its derivative, when evaluated at t = tk, must equal 
f(tk,y(tk)). Moreover, by repeated use of the chain rule of partial dif-
ferentiation (see Appendix A), we can evaluate 
</p>
<p>d 2y(tk) [ af af] 
dt2 = at + f ay (tk,y(tk)) 
</p>
<p>and all other higher-order derivatives of y ( t) at t = tk. Hence, we can re-
write (2) in the form 
</p>
<p>Y ( tk+ I)= Y ( tk) + hf( tk,y ( tk)) 
</p>
<p>h2 [ af af] 
+.2! -at+fay (tk,y(tk))+ .... (3) 
</p>
<p>The simplest approximation of y ( tk + 1) is obtained by truncating the 
Taylor series (3) after the second term. This gives rise to the numerical 
scheme 
</p>
<p>and, in general, 
</p>
<p>Yo= y(to). (4) 
</p>
<p>Notice how we use the initial-value y 0 and the fact that y(t) satisfies the 
differential equation dy I dt = f(t,y) to compute an approximate value y 1 of 
y(t) at t= t1&bull; Then, we use this approximate value y 1 to compute an ap-
proximate value Y2 of y ( t) at t = t2&gt; and so on. 
</p>
<p>97 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>Equation ( 4) is known as Eu/er' s scheme. It is the simplest numerical 
scheme for obtaining approximate values y 1,. &bull;&bull; ,yN of the solution y(t) at 
times t1, &bull;&bull;&bull; ,tN. Of course, it is also the least accurate scheme, since we have 
only retained two terms in the Taylor series expansion for y(t). As weshall 
see shortly, Euler's scheme is not accurate enough to use in many prob-
lems. However, it is an excellent introduction to the more complicated 
schemes that will follow. 
</p>
<p>Example 1. Let y(t) be the solution of the initial-value problern 
</p>
<p>~I dt= 1 +(y- t)2, y(O)= ~&middot; 
</p>
<p>Use Euler's scheme to compute approximate values y 1, &bull;&bull;&bull; ,yN of y(t) at the 
points t1 = 11 N,t2 =21 N, ... ,tN= 1. 
Solution. Euler's scheme for this problern is 
</p>
<p>Yk+t=yk+h[1+(yk-tk)2 ], k=O,l, ... ,N-1, h=liN 
</p>
<p>with y0 = t. Sampie Pascal and Fortranprograms to compute y 1 , &bull;&bull;. , YN are 
given below. These programs, as well as all subsequent programs, have 
variable values for t0 , y 0, a, and N, so that they may also be used to solve 
the more general initial-value problern ~I dt = 1 + (y- ti, y(t0) = y 0 on 
any desired interval. Moreover, these same programs work even if we 
change the differential equation; if we change the functionj(t,y) then we 
need only change line 12 in the Pascal program (and line 11 in the C program) 
and the expressions for Y(1) and Y(K) in Section B ofthe Fortran program. 
</p>
<p>Pascal Program 
</p>
<p>Program Euler (input, output); 
</p>
<p>var 
T, Y: array[O .. 999] of real; 
a, h: real; 
k, N: integer; 
</p>
<p>begin 
readln(T[O], Y[O], a, N); 
h :=a/N; 
page; 
for k:=O to N-1 do 
</p>
<p>begin 
T[k+1] :=T[k]+h; 
Y[k + 1] := Y[k] + h * (1 + (Y[k]- T[k]) &bull; (Y[k]- T[k])); 
</p>
<p>end; 
writeln('T':4, 'Y':16); 
for k := 0 to N do 
</p>
<p>writeln(T[k]:10:7,' ':2, Y[k]:16:9); 
end. 
</p>
<p>98 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.13 Numerica1 approximations; Eu1er's method 
</p>
<p>Section A 
Read in data 
</p>
<p>Section 8 
Do computations 
</p>
<p>Section C 
Print out 
results 
</p>
<p>20 
</p>
<p>Fortran Program 
</p>
<p>DIMENSION T(1 000), Y(1 000) 
READ (5, 1 0) TO, YO, A, N 
FORMAT (3F20.8, 15) 
H=A/N 
</p>
<p>T(1)=TO+ H 
Y(1) = YO + H * (1 + (YO- TO) * * 2) 
DO 20 K=2,N 
T(K)=T(K-1)+ H 
Y(K)=Y(K-1)+H&bull;(1 +(Y(K-1) 
</p>
<p>1 -T(K-1))&bull; &bull;2) 
CONTINUE 
</p>
<p>WRITE (6, 30) TO, YO, (T(J), Y(J), J = 1, N) 
FORMAT (1H1,3X, 1HT,4X, 1HY,/(1H, 1X, 
F1 0. 7, 2X, F20.9 /)) 
CALL EXIT 
END 
</p>
<p>See also C Program 4 in Appendix C for a sample C program. 
Table 1 below gives the results of these computations for a= 1, N= 10, t0= 
0, and y 0 = k. All of these computations, and all subsequent computations, 
were carried out on an IBM 360 computer using 16 decimal places ac-
curacy. The results have been rounded to 8 significant decimal places. 
</p>
<p>Table 1 
</p>
<p>t y t y 
</p>
<p>0 0.5 0.6 1.29810115 
0.1 0.625 0.7 1.44683567 
0.2 0.7525625 0.8 1.60261202 
0.3 0.88309503 0.9 1.76703063 
0.4 1.01709501 1 1.94220484 
0.5 1.15517564 
</p>
<p>The exact solution of this initial-value problern (see Exercise 7) is 
</p>
<p>y(t)=t+l/(2-t). 
</p>
<p>Thus, the error we make in approximating the value of the solution at t = I 
by y 10 is approximately 0.06, since y (I)= 2. If we run this program for N = 
20 and N = 40, we obtain that Y2o = 1.96852339 and y 40 = 1.9835109. Hence, 
the error we make in approximating y(l) by y 40 is already Jess than 0.02. 
</p>
<p>99 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equatwns 
</p>
<p>EXERCISES 
</p>
<p>Using Euler's method with step size h = 0.1, determine an approximate 
value of the solution at t =I for eaeh of the initial-value problems 1-5. Re-
peat these eomputations with h = 0.025 and eompare the results with the 
given value of the solution. 
</p>
<p>1. : =l+t-y, y(O)=O; (y(t)=t) 
</p>
<p>2. : =2ty, y(0)=2; (y(t)=2e 1) 
</p>
<p>3. : =l+y2 -t2, y(O)=O; (y(t)=t) 
</p>
<p>4. dyd =te-Y+-1-2 , y(O)=O; (y(t)=ln(l+t2)) 
t I+ t 
</p>
<p>S. dyd =-1+2t+ y 2 , y(O)=l; (y(t)=l+t2) 
t (l+t2)2 
</p>
<p>6. U sing Euler's method with h = 'TT I 40, determine an approximate value of the 
solution of the initial-value problern 
</p>
<p>: =2sec2 t-(l+y2), y(O)=O 
</p>
<p>at t ="'I 4. Repeat these computations with h = 'TT I 160 and compare the results 
with the nurober one which is the value of the solutiony(t)=tant at t=TTI4. 
</p>
<p>7. (a) Show that the substitution y = t + z reduces the initial-value problern y' = 1 + 
(y- t)2, y(O) = 0.5 to the simpler initial-value problern z' = z2, z(O)=O.S. 
</p>
<p>(b) Show that z(t)= 11(2- t). Hence,y(t)= t+ 11(2- t). 
</p>
<p>1.13.1 Error analysis jor Euler's method 
</p>
<p>One of the niee features of Euler's method is that it is relatively simple to 
estimate the error we make in approximating y(tk) by Yk&middot; Unfortunately, 
though, we must make the severe restriction that t1, ... ,tN do not exceed t0 
+ a, where a is the number defined in the existenee-uniqueness theorem of 
Seetion I. 10. More preeisely, Iet a and b be two positive numbers and 
assume that the funetions j, aj I at, and aj I ay are defined and continuous 
in the reetangle t0 ..;; t.,;; t0 + a, y0- b.,;; y.,;; y0 + b. We will denote this reet-
angle by R. Let M be the maximum value of \f(t,y)\ for (t,y) in R, and set 
a=min(a,bl M). We will determine the error committed in approximating 
y(tk) by yk, for tk..;; t0+ a. 
</p>
<p>To this end observe that the numbers y0,y1, ... ,yN satisfy the difference 
equation 
</p>
<p>k = 0, I, ... , N- I 
</p>
<p>while the numbers y ( t0),y ( t 1), &bull;&bull;&bull; ,y ( t N) satisfy the difference equation 
</p>
<p>100 
</p>
<p>(I) </p>
<p/>
</div>
<div class="page"><p/>
<p>1.13 Numerical approximations; Euler's method 
</p>
<p>(2) 
</p>
<p>where ~k is some number between tk and tk + 1&bull; Equation (2) follows from 
the identity 
</p>
<p>and the fact that 
dy(t) hl d 2y(T) 
</p>
<p>y(t+h)=y(t)+h-d-+-2 2 
t dt 
</p>
<p>for some number T between t and t + h. Subtracting Equation (I) from 
Equation (2) gives 
</p>
<p>y(tk+l)-Yk+ 1 = y(tk)-Yk + h[ f(tk,y(tk))- f(tk,yk)] 
</p>
<p>hl [ of of] + 2 Tt + f ay (~k&middot;Y(~k )). 
</p>
<p>Next, observe that 
of(tk,1Jd 
</p>
<p>f(tk,y(tk))- f(tk&bull;Yk)= oy [y(tk)-yk] 
</p>
<p>where 1Jk is some number betweeny(tk) andyk. Consequently, 
</p>
<p>I of( tk, 11k) I IY(tk+l)-yk+ll.;;;ly(tk)-ykl+h oy IY(tk)-ykl 
</p>
<p>+ h221 [ ~ + f ~~ ](~k,y(~k ))I. 
In order to proceed further, we must obtain estimates of the quantities 
</p>
<p>(of(tk,1Jk))loy and [(oflot)+ f(ofloy)](~k,y(~k)). Tothis end observe that 
the points (~k&bull;Y(~k)) and (tk,yk) alllie in the reetangle R. (It was shown in 
Section 1.10 that the points (~k,y(~k)) lie in R. In addition, a simple induc-
tion argument (see Exercise 9) shows that the points (tk,yk) all lie in R.) 
Consequently, the points (tk, Tlk) must also lie in R. Let L and D be two 
positive numbers such that 
</p>
<p>max - .;;;L I of I (t,y) in R oy 
and 
</p>
<p>max I aj +Jaji.;;;D. 
(t,y) in R ot oy 
</p>
<p>Such numbers always exist if J, aj I at, and of I oy are continuous in R. 
Then, 
</p>
<p>Dh2 
IY(tk+ 1)-Yk+ d.;;; IY(tk)- Ykl + hL!y(tk) -ykl + -2-. (3) 
</p>
<p>101 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>Now, set Ek=iy(tk)-ykl, k=0,1, ... ,N. The number Ek is the error we 
make at the kth step in approximating y(tk) by Yk&middot; From (3) 
</p>
<p>Dh2 
Ek+ 1 ..;(1+hL)Ek+-2-, k=0,1, ... ,N-l. (4) 
</p>
<p>Moreover, E0 =0 since y(t0)= y 0&bull; Thus, the numbers E0, E 1, &bull;&bull;&bull; ,EN satisfy 
the set of inequa1ities 
</p>
<p>Ek+l ..;AEk+B, E0 =0 
</p>
<p>with A = 1 + hL and B = Dh2 j2. Consequently, (see Section 1.12) 
</p>
<p>B k Dh [ k J Ek..;A_ 1 (A -1)= 2L (1+hL) -1. (5) 
</p>
<p>We can also obtain an estimate for Ek that is independent of k. Observe 
that 1 + hL.;;;; ehL. This follows from the fact that 
</p>
<p>(hL) 2 (hL) 3 
ehL = 1 + hL + ll + ~ + ... 
</p>
<p>= ( 1 + hL) + "something positive". 
Therefore, 
</p>
<p>Ek,;;;; f2 [ (ehL)k -1] = f2 [ ekhL_1 ]. 
Finally, since kh .;;;; a, we see that 
</p>
<p>Ek,;;;; f2 [ eaL -1 ], k=1, ... ,N. (6) 
Equation (6) says that the error we make in approximating the solution 
</p>
<p>y(t) at timet= tk by Yk is at most a fixed constant times h. This suggests, as 
a rule of thumb, that our error shou1d decrease by approximately t if we 
decrease h by t&middot; We can verify this directly in Example 1 of the previous 
section where our error at t = 1 for h = 0.1, 0.05, and 0.025 is 0.058, 0.032, 
and 0.017 respective1y. 
</p>
<p>Example 1. Let y ( t) be the solution of the initial-value problern 
</p>
<p>y(O) =0. 
</p>
<p>(a) Show thaty(t) exists at least for 0..; t.;;;; 1, and that in this interval, -1 
..; y(t)..; I. 
(b) Let N be a large positive integer. Set up Euler's scheme to find ap-
proximate values of y at the points tk = k/ N, k =0, 1, ... ,N. 
(c) Determine a step size h = 1 j N so that the error we make in approxi-
matingy(tk) by Yk does not exceed 0.0001. 
Solution. (a) Let R be the reetangle 0..; t..; 1, -1..; y..; 1. The maximum 
value that (t2 +y2)/2 achieves for (t,y) in R is 1. Hence, by the exist-
</p>
<p>102 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.13 Numerical approximations; Euler's method 
</p>
<p>ence-uniqueness theorem of Section 1.10, y(t) exists at least for 
</p>
<p>0~ t~ a=min(I,+)= I, 
</p>
<p>and in this interval, - I ~ y ~ 1. 
</p>
<p>withy0 =0. The integer k runs from 0 to N -1. 
(c) Letf(t,y)=(t2+ y 2)/2, and compute 
</p>
<p>'df 'df 'df y 2 2 
'dy = y and at + f 'dy = t+ 2(t + Y ). 
</p>
<p>From (6), jy(tk)-Ykl ~ (Dh/2L)(eL -1) where L and D are two positive 
numbers such that 
</p>
<p>and 
</p>
<p>max IYI~L 
(t,y) in R 
</p>
<p>m~x lt+ y2 (t2+y2)1 ~ D. 
(t,y) m R 
</p>
<p>Now, the maximum values of the functions IYI and lt+(y/2)(t2+y2)1 for 
(t,y) in R are clearly I and 2 respectively. Hence, 
</p>
<p>2h 
jy(tk)-ykj ~ T(e-1)=h(e-1). 
</p>
<p>This implies that the step s-ize h should be smaller than 0.0001/(e-1). 
Equivalently, N shou1d be 1arger than ( e- 1) 104 = 17,183. Thus, we must 
iterate the equation 
</p>
<p>Yk+ 1 = Yk + 2(17\83) [ ( 17,~83 f + y~] 
17,183 times tobe sure thaty(l) is correct to four decimal places. 
</p>
<p>Example 2. Let y(t) be the solution of the initial-value problern 
</p>
<p>y(O)= 1. 
</p>
<p>(a) Show that y(t) exists at least for 0 ~ t ~ 1, and that in this interval, - 1 
~y~3. 
</p>
<p>(b) Let N be a large positive integer. Set up Euler's scheme to find ap-
proximate values of y(t) at the points tk = kj N, k =0, 1, . .. ,N. 
(c) Determine a step size h so that the error we make in approximating 
y(tk) by Yk does not exceed 0.0001. 
Solution. 
(a) Let R be the reetangle 0 ~ t ~ 1, jy -11 ~ 2. The maximum value that t 2 
+ e-y2 achieves for (t,y) in R is 2. Hence, y(t) exists at least for 0 ~ t ~ 
min(l,2/2)= 1, andin this interval, -1 ~ y ~ 3. 
</p>
<p>103 </p>
<p/>
</div>
<div class="page"><p/>
<p>l First-order differential equations 
</p>
<p>(b) Yk+i = Yk + h(t/+ e-YkJ= Yk +(1/ N)[(k/ Nl+ e-Yk2) with y0= 1. The 
integer k runs from 0 to N- 1. 
(c) Letf(t,y)= t2+ e-y2 and compute 
</p>
<p>af 2 of af 2 2 2 -=-2ye-Y and -+J-=2t-2y(t +e-Y)e-Y. 
ay ' at ay 
</p>
<p>From (6), iy(tk)-Yki.;;;; (Dh/2L)(eL-1) where L and D are two positive 
numbers suchthat 
</p>
<p>and 
</p>
<p>max l-2ye-y21.;;;; L 
(t,y) in R 
</p>
<p>max i2t-2y(t2 +e-Y2 )e-y2 io;;;; D. 
(t,y) in R 
</p>
<p>Now, it is easily seen that the maximum va1ue of l2ye-Y21 for -1.;;;; y.;;;; 3 is 
Vi; e . Thus, we take L= V2j;. Unfortunate1y, though, it is extremely 
difficult to compute the maximum value of the function 
</p>
<p>l2t-2y(t2 + e-Y2 )e-y2i 
</p>
<p>for (t,y) in R. However, we can still find an acceptable value D by observ-
ing that for (t,y) in R, 
</p>
<p>maxl2t-2v(t2 + e-Y2 )e-y2 i.;;;; maxl2tl +maxl2y(t2 + e-Y2 )e-y2i 
</p>
<p>.;;;; maxl2tl +maxl2ye-y21 Xmax(t2 + e-yl) 
</p>
<p>=2+2-vVe =2(1 + VVe ). 
Hence, we may choose D = 2(1 + V2j; ). Consequently, 
</p>
<p>2(1 + V2j; )h[ ev'Ve -I] 
iy(tk)-Yki.;;;; ... ~ &middot; 
</p>
<p>2 v2/e 
</p>
<p>This implies that the step size h must be smaller than 
</p>
<p>VVe X 0.0001 . 
1 + V2j; e&middot;h;e -1 
</p>
<p>Examples 1 and 2 show that Euler's method is not very accurate since 
approximately 20,000 iterations are required to achieve an accuracy of four 
decima1 places. One obvious disadvantage of a scheme which requires so 
many iterations is the cost. The going rate for computer usage at present is 
about $1200.00 per hour. A second, and much more serious disadvantage, 
is that Yk may be very far away from y(tk) if N is exceptionally }arge. To 
wit, a digital computer can never perform a computation exactly since it 
only retains a finite number of decimal p1aces. Consequently, every time 
we perform an arithmetic operation on the computer, we must introduce a 
</p>
<p>104 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.13 Numerical approximations; Euler's method 
</p>
<p>"round off" error. This error, of course, is small. However, if we perform 
too many operations then the accumulated round off error may become so 
large as to make our results meaningless. Exercise 8 gives an illustration of 
this for Euler's method. 
</p>
<p>EXERCISES 
</p>
<p>1. Determine an upper bound on the error we make in using Euler's rnethod with 
step size h to find an approxirnate value of the solution of the initial-value prob-
lern 
</p>
<p>y(O) = 1 
</p>
<p>at any point t in the interval [0, H Hint: Let R be the reetangle 0.;;; t.;;; 1, 0.;;; y.;;; 
2. 
</p>
<p>2. Determine an upper bound on the error we rnake in using Euler's rnethod with 
step size h to find an approxirnate value of the solution of the initial-value prob-
lern 
</p>
<p>dy 4 
dt =t-y' y(O)=O 
</p>
<p>at any point t in the interval [0, 1]. Hint: Let R be the reetangle 0.;;; t.;;; 1, -1 .;;; y 
.;;;1. 
</p>
<p>3. Determine an upper bound on the error we rnake in using Euler's rnethod with 
step size h to find an approxirnate value of the solution of the initial-value prob-
lern 
</p>
<p>dy 
-=t+eY 
dt ' 
</p>
<p>y(O)=O 
</p>
<p>at any point t in the interval [0, 1/(e+ 1)]. Hint: Let R be the reetangle 0.;;; t.;;; 1, 
-l.;;;y.;;;l. 
</p>
<p>4. Determine a suitable value of h so that the error we rnake in using Euler's 
rnethod with step size h to find an approxirnate value of the solution of the ini-
tial-value problern 
</p>
<p>dt =e 1-y2, y(O)=O 
at any point t in the interval [0, I/ e] is at rnost 0.0001. Hint: Let R be the reet-
angle 0.;;; t.;;; 1, -1.;;; y.;;; 1. 
</p>
<p>S. Determine a suitable value of h so that the error we rnake in using Euler's 
rnethod with step size h to find an approxirnate value of the solution of the ini-
tial-value problern 
</p>
<p>y(O)=O 
</p>
<p>at any point t in the interval [0, tl is at rnost 0.00001. Hint: Let R be the reetan-
gleO&lt;t&lt;&plusmn;. -vj4.;;;y.;;;vj~ 
</p>
<p>105 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>6. Determine a suitable value of h so that the error we make in using Euler's 
method with step size h to find an approximate value of the solution of the ini-
tial-value problern 
</p>
<p>dy = y(O)=O 
dt 1 + 12+ y2' 
</p>
<p>at any point t in the interval [0, 1] is at most 0.0001. Hint: Let R be the reetangle 
0.;;; t.;;; 1, -1.;;; y.;;; 1. 
</p>
<p>7. Let y(t) be the solution of the initial-value problern 
</p>
<p>dy 
dt =J(t,y), y(O)=O. 
</p>
<p>Suppose that if(t,y)j.;;; 1, jaf/ayj.;;; 1, and j(ajjat)+j(ajjay)j.;;;2 in the reetan-
gle 0.;;; t.;;; 1, - 1 .;;; y .;;; 1. When the Euler scheme 
</p>
<p>1 
Yk+l=yk+hj(tk,Yk), h= N 
</p>
<p>is used with N=IO, the value of y 5 is -0.15[(-l-!i)5 -1], and the value of y 6 is 
0.12[(-l-!i)6 -1]. Prove thaty(t) is zero at least once in the interval (t, D&middot; 
</p>
<p>8. Let y(t) be the solution of the initial-value problern 
</p>
<p>y' = f(t,y), y(to) = Yo&middot; 
</p>
<p>Euler's method for finding approximate values of y(t) is Yk+ 1 = Yk + hf(tk,Yk)&middot; 
However, the quantity Yk + hf(tk&gt;Yk) is never computed exactly: we always in-
troduce an error ek with Iek! &lt; e. That is to say, the computer computes numbers 
j ~oh .... , such that 
</p>
<p>withj0 =y0&bull; Suppose that jajjayj.;;; Land j(ajjat)+ j(ajjay)j.;;; D for all t and 
y. 
(a) Show that 
</p>
<p>Ek+l:=jy(tk+l)-h+II.;;;(I +hL)Ek+ ~ h2 +e 
</p>
<p>(b) Conclude from (a) that 
</p>
<p>Ek .;;; [ Dh + !:_ ] e"L- 1 
2 h L 
</p>
<p>for kh.;;; a. 
(c) Choose h so that the error Ek is minimized. Notice that the error Ek may be 
</p>
<p>very large if h is very small. 
</p>
<p>9. Let y 1,Y2, ... satisfy the recursion relation 
</p>
<p>Yk+ I= Yk + hf(tk,yk). 
Let R be the reetangle t0 .;;; t.;;; t0 + a,y0 - b.;;; y.;;; y0 + b, and assume that if(t,y)i 
.;;; M for (t,y) in R. Finally, Iet a = min(a,b / M). 
(a) Prove that IYJ- .Y01.;; jhM, as long asjh.;; a. Hint: Use induction. 
(b) Conclude from ( a) that the points ( ~.yj) all lie in R as long as j .;;; a / h. 
</p>
<p>106 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.14 The three term Taylor series method 
</p>
<p>1.14 The three term Taylor series method 
</p>
<p>Euler's method was derived by truncating the Taylor series 
</p>
<p>(l) 
</p>
<p>after the second term. The most obvious way of obtaining better numerical 
schemes is to retain more terms in Equation (1 ). If we truncate this Taylor 
series after three terms then we obtain the numerical scheme 
</p>
<p>h2 [ of of J 
Yk+l=yk+hf(tk,Yk)+2 a~+f 3 Y (tk.Yk), k=O, ... ,N-1 (2) 
</p>
<p>with y 0 = y(t0). 
Equation (2) is called the three term Taylor series method. lt is obviously 
</p>
<p>more accurate than Euler's method. Hence, for fixed h, we would expect 
that the numbers Yk generated by Equation (2) are better approximations 
of y(tk) than the numbers Yk generated by Euler's scheme. This is indeed 
the case, for it can be shown that iy(tk)-yki is proportional to h2 whereas 
the error we make using Euler's method is only proportional to h. The 
quantity h2 is much less than h if h is very small. Thus, the three term 
Taylor series method is a significant improvement over Euler's method. 
</p>
<p>Example 1. Let y ( t) be the solution of the initial-value problern 
</p>
<p>dy 2 1 
dt = 1 + (y - t) ' y (0) = 2 . 
</p>
<p>Use the three term Taylor series method to compute approximate values of 
y(t) at the points tk=k/N, k=1, ... ,N. 
</p>
<p>Solution. Let f ( t ,y) = 1 + (y - ti. Then, 
</p>
<p>of of [ 2] 3 3t + J oy = - 2(y- t) + 2(y- t) 1 + (Y- t) = 2(y- t) . 
</p>
<p>Hence, the three term Taylor series scheme is 
</p>
<p>with h = 1/N and y0 = !. The integer k runs from 0 to N- 1. Sampie Pascal 
and Fortran programs to compute y 1, ... ,yN are given below. Again, these 
programs have variable values for t0, y 0, a, and N. 
</p>
<p>107 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>Pascal Program 
</p>
<p>Program Taylor (input, output); 
</p>
<p>var 
T, Y: array(O .. 999] of real; 
a, h, Temp: real; 
k, N: integer; 
</p>
<p>begin 
readln(T[O], Y[O], a, N); 
h :=a/N; 
page; 
for k := 0 to N -1 do 
</p>
<p>begin 
Temp := Y[k]- T[k]; 
T[k+1]:=T(k]+h; 
Y[k + 1] := Y[k] + h * (1 + Temp * Temp) 
</p>
<p>+h * h &bull;Temp&bull;Temp * Temp; 
end; 
</p>
<p>writeln('T':4, 'Y':16); 
for k := 0 to N do 
</p>
<p>writeln(T[k]:10:7, &middot; ':2, Y[k]:16:9); 
end. 
</p>
<p>Fortran Program 
</p>
<p>Replace Section B of the Fortran program in Section 1.13 by the follow-
ing: 
</p>
<p>T(1)=TO+H 
D2Y = H * (YO- TO) * * 3 
Y(1)=YO+ H &bull;(D2Y + 1 +(YO- TO)&bull; * 2) 
0020 K=2,N 
T(K)=T(K -1)+ H 
D2Y=H&bull;(Y(K-1)-T(K-1))* &bull;3 
Y(K)= Y(K -1)+ H &bull;(D2Y + 1 +(Y(K -1)- T(K -1))* &bull;2) 
</p>
<p>20 CONTINUE 
</p>
<p>See also C Program 5 in Appendix C for a sample C program. 
Table 1 below shows the results of these computations for a = 1, N = 10, 
</p>
<p>t0 =0, andy0 =0.5. 
</p>
<p>Now Euler's method with N= 10 predicted a value of 1.9422 for y(1). No-
tice how much closer the number 1.9957 is to the correct value 2. lf we run 
this program for N = 20 and N = 40, we obtain that y 20 = 1.99884247 and 
</p>
<p>108 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.15 An improved Euler method 
</p>
<p>Table I 
</p>
<p>t y t y 
0 0.5 0.6 1.31331931 
</p>
<p>0.1 0.62625 0.7 1.4678313 
0.2 0.7554013 0.8 1.63131465 
0.3 0.88796161 0.9 1.80616814 
0.4 1.02456407 1 1.99572313 
0.5 1.1660084 
</p>
<p>y 40 = 1.99969915. Thesenumbersare also much more accurate than the val-
ues 1.96852339 and 1.9835109 predicted by Euler's method. 
</p>
<p>ExERCISES 
</p>
<p>Using the three term Taylor series method with h=0.1, determine an ap-
proximate value of the solution at t = 1 for each of the initial-value prob-
lems 1-5. Repeat these computations with h = 0.025 and compare the re-
sults with the given value of the solution. 
</p>
<p>1. dyldt=l+t-y, y(O)=O; (y(t)=t) 
</p>
<p>2. dyldt=2ty, y(0)=2; (y(t)=2e 1) 
</p>
<p>3. dyldt=l+y 2-t2, y(O)=O; (y(t)=t) 
</p>
<p>4. dy I dt= te-y + tl(l + t 2), y(O)=O; (y{t)=ln(l + t 2)) 
</p>
<p>s. dy I dt= -1 +2t+ y 2 1(1 + t2) 2, y(O)= 1; (y(t)= 1+ t2) 
6. U sing the three term Taylor series method with h = '1T I 40, determine an ap-
</p>
<p>proximate value of the solution of the initial-value problern 
</p>
<p>~ =2sec2 t-(l+y2), y(O)=O 
</p>
<p>at t = '1T I 4. Repeat these computations with h = '1T I 160 and compare the results 
with the number one which is the value of the solutiony(t)=tant at t='ITI4. 
</p>
<p>1.15 An improved Euler method 
</p>
<p>The three term Taylor series method is a significant improvement over 
Euler's method. However, it has the serious disadvantage of requiring us to 
compute partial derivatives of f(t,y), and this can be quite difficult if the 
function f(t,y) is fairly complicated. For this reason we would like to de-
rive numerical schemes which do not require us to compute partial deriva-
tives of f(t,y). One approach to this problern is to integrate both sides of 
the differential equation y' = f(t,y) between tk and tk + h to obtain that 
</p>
<p>f tk+h ( ) y(tk+l)=y(tk)+ f t,y(t) dt. 
tk 
</p>
<p>(1) 
</p>
<p>109 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>This reduces the problern of finding an approximate value of y ( tk + 1) to the 
much simpler problern of approximating the area under the curve f(t,y(t)) 
between tk and tk + h. A crude approximation of this area is hf(tk,y(tk)), 
which is the area of the reetangle R in Figure 1a. This gives rise to the 
numerical scheme 
</p>
<p>Yk+ I= Yk + hf( tk,yk) 
which, of course, is Euler's method. 
</p>
<p>A much better approximation of this area is 
</p>
<p>~ [f(tk,y(tk))+ J(tk+l&bull;y(tk+l))] 
which is the area of the trapezoid T in Figure 1 b. This gives rise to the 
numerical scheme 
</p>
<p>h 
Yk+ I= Yk + 2 [ f(tk,yk) + f(tk+ I&bull;Yk+ I)]. (2) 
</p>
<p>However, we cannot use this scheme to determine Yk+ 1 from Yk since Yk+l 
also appears on the right-hand side of (2). A very clever way of overcoming 
this difficulty is to replace Yk+ 1 in the right-hand side of (2) by the value 
Yk + hf(tk,yk) predicted for it by Euler's method. This gives rise to the 
numerical scheme 
</p>
<p>Yk+ 1 = Yk + ~ [ f(tk,Yk) + f(tk + h,Yk + hf(tk&bull;Yk)) ], Yo= y(to). (3) 
Equation (3) is known as the improved Eu/er method. lt can be shown 
</p>
<p>that ly(tk)-Ykl is at most a fixed constant times h2&bull; Hence, the improved 
Euler method gives us the same accuracy as the three term Taylor series 
method without requiring us to compute partial derivatives. 
</p>
<p>~ ,--- ----j 
I I T 
I R I I 
I I I 
</p>
<p>(a) 
</p>
<p>t I t 
tk 
</p>
<p>(b) 
tk+h 
</p>
<p>I 
</p>
<p>Figure 1 
</p>
<p>Example 1. Let y(t) be the solution of the initial-value problern 
</p>
<p>dy 2 1 
dt =1+(y-t), y(0)=2. 
</p>
<p>110 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.15 An improved Euler method 
</p>
<p>Use the improved Euler method to compute approximate values of y(t) at 
the points tk = k/ N, k= l, .. . ,N. 
Solution. The improved Euler scheme for this problern is 
</p>
<p>Yk + 1 = Yk + ~ { 1 + (yk- tk)2 + 1 + [ Yk + h ( 1 + (yk- tk/)- tk + 1 r} 
with h = 1/N and y0 = 0.5. The integer k runs from 0 to N- 1. Sample Pascal 
and Fortran programs to compute y 1, ... ,yN are given below. Again, these 
programs have variable values for t0, y 0, a, and N. 
</p>
<p>Pascal Program 
</p>
<p>Program lmproved (input, output); 
</p>
<p>var 
T, Y: array[O .. 999] of real; 
a, h, R: real; 
k, N: integer; 
</p>
<p>begin 
readln (T[O], Y(O], a, N); 
h :=a/N; 
page; 
for k:=O to N-1 do 
</p>
<p>begin 
R := 1 + (Y[k]- T[k]) &bull; (Y[k]- T[k]); 
T[k+1]:=T[k]+h; 
Y[k+ 1] := Y[k] + (h/2) &bull; (R+ 1 
</p>
<p>+(Y[k] +h &bull; R- T[k+ 1]) &bull; (Y[k] +h &bull; R- T[k+1])); 
end; 
</p>
<p>writeln('T':4, 'Y':16); 
for k := 0 to N do 
</p>
<p>writeln(T[k]:10:7,' ':2, Y[k]:16:9); 
end. 
</p>
<p>Fortran Program 
</p>
<p>Replace Section B of the Fortranprogram in Example 1 of Section 1.13 by 
the following: 
</p>
<p>T(1)=TO+ H 
R = 1 + (YO- TO) * * 2 
Y(1) = YO + (H/2) * (R + 1 + (YO+ (H * R)- T(1 )) * * 2) 
0020 K=2,N 
T(K)=T(K -1)+ H 
R = 1 + (Y(K -1)- T(K- 1 )) * * 2 
Y(K)= Y(K-1)+(H/2)&bull;(R + 1 + (Y(K -1)+(H * R)- T(K))&bull; * 2) 
</p>
<p>20 CONTINUE 
</p>
<p>111 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>See also C Program 6 in Appendix C for a sample C program. 
Table 1 below shows the results of these computations for a = 1, N = 10, 
</p>
<p>t0 =0, andy0 =0.5. If we run this program for N=20 and N=40 we obtain 
that Y2o = 1.99939944 and y 40 = 1.99984675. Hence the values y 10, J20, and 
y 40 computed by the improved Euler method are even closer to the correct 
va1ue 2 than the corresponding values 1.99572313, 1.99884246, and 
1.99969915 computed by the three term Tay1or series method. 
</p>
<p>Table 1 
t y t y 
0 0.5 0.6 1.31377361 
</p>
<p>0.1 0.62628125 0.7 1.46848715 
0.2 0.75547445 0.8 1.63225727 
0.3 0.88809117 0.9 1.80752701 
0.4 1.02477002 1 1.99770114 
0.5 1.16631867 
</p>
<p>EXERCISES 
</p>
<p>Using the improved Euler method with h=0.1, determine an approximate 
value of the solution at t = 1 for each of the initia1-va1ue problems 1-5. Re-
peat these computations with h = 0.025 and compare the results with the 
given value of the solution. 
</p>
<p>1. dyldt=l+t-y, y(O)=O; (y(t)=t) 
</p>
<p>2. dyldt=2ty, y(0)=2; (y(t)=2e 1) 
</p>
<p>3. dy I dt= I+ y 2 - t 2, y(O)=O; (y(t)= t) 
</p>
<p>4. dyldt=te-Y+tl(l+t2), y(O)=O; (y(t)=In(I+t2)) 
</p>
<p>5. dy I dt= -l+2t+ y 2 I(I + t2)2, y(O)= I; (y(t)= I+ t 2) 
</p>
<p>6. Using the improved Euier method with h = w I 40, determine an approximate 
value of the solution of the initiai-value problern 
</p>
<p>y(O)=O 
</p>
<p>at t = w I 4. Repeat these computations with h = w I I60 and compare the results 
with the number one which is the value of the solution y(t) = tan t at t = w I 4. 
</p>
<p>1.16 The Runge-Kutta method 
</p>
<p>We now present, without proof, a very powerful scheme which was devel-
oped around 1900 by the mathematicians Runge and Kutta. Because of its 
simplicity and great accuracy, the Runge-Kutta method is still one of the 
most widely used numerical schemes for solving differential equations. It is 
defined by the equation 
</p>
<p>112 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.16 The Runge-Kutta method 
</p>
<p>h 
Yk+ 1 = Yk + 6 [ Lk,l +2Lk,2+2Lk,3+ Lk,4], k = 0, 1, ... , N- 1 
</p>
<p>where y 0 = y(t0) and 
</p>
<p>This formula involves a weighted average of values of f(t,y) taken at diffe-
rent points. Hence the sum i[Lk, 1 + 2Lk, 2 + 2Lk, 3 + Lk,4] can be interpreted 
as an average slope It can be shown that the error iy(tk)-Yki is at most a 
fixed constant times h4&bull; Thus, the Runge-Kutta method is much more ac-
curate than Euler's method, the three term Taylor series method and the 
improved Euler method. 
</p>
<p>Example 1. Let y(t) be the solution of the initial-value problern 
</p>
<p>dy 2 
dt = 1 + (y- t) ' y(O)= i&middot; 
</p>
<p>Use the Runge-Kutta method to find approximate values y 1, ... ,yN of y at 
the points tk = k/ N, k = 1, .. . ,N. 
Solution. Sampie Pascal and Fortranprograms to compute y1, ... ,yN by the 
Runge-Kutta method are given below. These programs differ from our 
previous programs in that they do not compute y 1 separately. Rather, they 
compute y 1 in the same "loop" as they compute Y2&middot; ... ,yN. This is accom-
plished by relabeling the numbers t0 andy0 as 11 andy 1 respectively. 
</p>
<p>Pascal Program 
</p>
<p>Program Runge_Kutta (input, output); 
</p>
<p>var 
T, Y: array[0 .. 999] of real; 
a, h, LK1, LK2, LK3, LK4: real; 
k, N: integer; 
</p>
<p>begin 
readln(T[O], Y[O], a, N); 
h :=a/N; 
page; 
for k:=O to N-1 do 
</p>
<p>begin 
T[k+1]:=T[k]+h; 
LK1 := 1 + (Y[k]- T[k]) &bull; (Y[k]- T[k]); 
LK2 := 1 + ((Y[k] + (h/2) &bull; LK1)- (T[k] + h/2)) 
</p>
<p>&bull; ((Y[k] +(h/2) &bull; LK1)-(T[k] +h/2)); 
</p>
<p>113 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>LK3 := 1 + ((Y[k] + (h/2) &bull; LK2)- (T[k] + h/2)) 
&bull; ((Y[k] + (h/2) &bull; LK2)- (T[k] + h/2)); 
</p>
<p>LK4 := 1 + ((Y[k] + h &bull; LK3)- (T[k] + h)) 
&bull; ((Y[k] + h &bull; LK3)- (T[k] + h)); 
</p>
<p>Y[k + 1] := Y[k] + (h/6) &bull; (LK1 + LK4+2 &bull; (LK2 + LK3)); 
end; 
</p>
<p>writeln('T':4, 'Y':16); 
for k :=0 to N do 
</p>
<p>writeln(T[k]:10:7,' ':2, Y[k]:16:9); 
end. 
</p>
<p>Fortran Program 
</p>
<p>DIMENSION T(1 000), Y(1 000) 
READ (5, 1 0) T(1 ), Y(1 ), A, N 
</p>
<p>1 0 FORMAT (3F20.8, 15) 
H=A/N 
0020 K=1,N 
T(K+1)=T(K)+H 
REAL LK1, LK2, LK3, LK4 
LK1 = 1 +(Y(K)- T(K))* *2 
LK2 = 1 + ((Y(K) + (H/2) * LK1)- (T(K) + H/2)) * * 2 
LK3=1 +((Y(K)+(H/2)*LK2)-(T(K)+H/2))* *2 
LK4 = 1 + ((Y(K) + H * LK3)- (T(K) + H)) * * 2 
Y(K + 1 )=Y(K)+(H/6)*(LK1 + LK4+ 2 *(LK2+ LK3)) 
</p>
<p>20 CONTINUE 
NA=N+1 
WAlTE (6, 30) (T(J), Y(J), J = 1, NA) 
</p>
<p>30 FORMAT (1 H1 ,3X, 1 HT,4X, 1 HY,/(1 H, 1 X, F1 0.7,2X, F20.9/)) 
CALL EXIT 
END 
</p>
<p>See also C Program 7 in Appendix C for a sample C program. 
Table I beiow shows the results of these computations for a = I, N = 10, 
</p>
<p>t0 =0, andy0 =0.5. 
</p>
<p>Table 1 
</p>
<p>t y t y 
</p>
<p>0 0.5 0.6 1.31428555 
</p>
<p>0.1 0.62631578 0.7 1.4692305 
</p>
<p>0.2 0.75555536 0.8 1.6333329 
0.3 0.88823526 0.9 1.8090902 
0.4 1.02499993 I 1.9999988 
0.5 1.16666656 
</p>
<p>114 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.16 The Runge-Kutta method 
</p>
<p>Notice how much closer the number y 10 = 1.9999988 computed by the 
Runge-Kutta method is to the correct value 2 than the numbers y 10 = 
1.94220484, y 10 = 1.99572312, and y 10 = 1.99770114 computed by the Euler, 
three term Taylor series and improved Euler methods, respectively. lf we 
run this program for N = 20 and N = 40, we obtain that Yzo = 1.99999992 
andy40 = 2. Thus, our approximation of y(l) is already correct to eight dec-
imal places when h = 0.025. Equivalently, we need only choose N &gt; 40 to 
achieve eight decimal places accuracy. 
</p>
<p>To put the accuracy of the various schemes into proper perspective, Iet 
us say that we have three different schemes for numerically solving the ini-
tial-value problern dy / dt = f( t ,y ), y (0) = 0 on the interval 0 &lt; t &lt; I, and that 
the error we make in using these schemes is 3h, llh2, and 42h4, respec-
tively. If our problern is such that we require eight decimal places ac-
curacy, then the step sizes h1, h2, and h3 of these three schemes must satisfy 
the inequalities 3h 1 &lt; 10- 8, llhi &lt; 10- 8, and 42hj &lt; 10- 8&bull; Hence, the num-
ber of iterations N 1, N 2, and N 3 of these three schemes must satisfy the in-
equalities 
</p>
<p>and 
N 3 &gt;(42) 114 x 10 2 ~260. 
</p>
<p>This is a striking example of the difference between the Runge-Kutta 
method and the Euler, improved Euler and three term Taylor series 
methods. 
</p>
<p>Remark. It should be noted that we perform four functional evaluations at 
each step in the Runge-Kutta method, whereas we only perform one func-
tional evaluation at each step in Euler's method. N evertheless, the 
Runge-Kutta method still beats the heck out of Euler's method, the three 
term Taylor series method, and the improved Euler method. 
</p>
<p>EXERCISES 
</p>
<p>U sing the Runge-Kutta method with h = 0.1, determine an approximate 
value of the solution at t= 1 for each of the initial-value problems 1-5. Re-
peat these computations with h = 0.025 and compare the results with the 
given value of the solution. 
</p>
<p>1. dyjdi=I+I-y, y(O)=O; (y(l)=l) 
</p>
<p>2. dyjdl=2ty, y(0)=2; (y(1)=2e 1) 
</p>
<p>3. dyjdi=I+y2 -12, y(O)=O; (y(l)=l) 
</p>
<p>4. dy / dl= le-Y +I /(I+ 12), y(O) =0; (y(l) =In( I+ 12)) 
</p>
<p>5. dy I dl= -1 +21+ y 2 /((1 + 12i). y(O)= 1; (y(l)= 1 + 12) 
</p>
<p>115 </p>
<p/>
</div>
<div class="page"><p/>
<p>l First-order differential equations 
</p>
<p>6. Using the Runge-Kutta method with h ="'I 40, determine an approximate value 
of the solution of the initial-value problern 
</p>
<p>y(O)=O 
</p>
<p>at t ="'I 4. Repeat these computations with h ="'I 160 and compare the results 
with the number one which is the value of the solutiony(t)=tant at t='TTI4. 
</p>
<p>1.17 What to do in practice 
</p>
<p>In this section we discuss some of the practical problems which arise when 
we attempt to solve differential equations on the computer. First, and fore-
most, is the problern of estimating the error that we make. lt is not too dif-
ficult to show that the error we make using Euler's method, the three term 
Taylor series method, the improved Euler method and the Runge-Kutta 
method with step size h is at most c1h, c2h2, c3h2, and c4h4, respectively. 
With one exception, though, it is practically impossible to find the con-
stants c1, c2, c3, and c4&bull; The one exception is Euler's method where we can 
explicitly estimate (see Section l.l3.1) the error we make in approximating 
y(tk) by Yk&middot; However, this estimate is not very useful, since it is only valid 
for tk sufficiently close to t0, and we are usually interested in the values of 
y at times t much larger than t0&bull; Thus, we usually do not know, a priori, 
how small to choose the step size h so as to achieve a desired accuracy. We 
only know that the approximate values Yk that we compute get closer and 
closer to y(tk) as h gets smaller and smaller. 
</p>
<p>One way of resolving this difficulty is as follows. Using one of the 
schemes presented in the previous section, we choose a step size h and 
compute numbers y 1, ... ,yN. We then repeat the computations with a step 
size h /2 and compare the results. If the changes are greater than we are 
willing to accept, then it is necessary to use a smaller step size. We keep 
repeating this process until we achieve a desired accuracy. For example, 
suppose that we require the solution of the initial-value problemy' = f(t,y), 
y(O)=y0 at t= I to four decimal places accuracy. We choose a step size h 
= l/100, say, and computeyi' ... ,y 100&bull; We then repeat these computations 
with h= l/200 and obtain new approximations z1, ... ,z200&bull; If y 100 and z200 
agree in their first four decimal places then we take z200 as our approxima-
tion of y(l)." If y 100 and z200 do not agree in their first four decimal places, 
then we repeat our computations with step size h = 1/400. 
</p>
<p>Example 1. Find the solution of the initial-value problern 
</p>
<p>*This does not guarantee that z200 agrees with y(l) to four decimal places. As an added pre-
caution, we might halve the step size again. If the first four decimal places still remain un-
changed, then we can be reasonably certain that z200 agrees withy(l) to four decimal places. 
</p>
<p>116 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.17 What to do in practice 
</p>
<p>y(O)=O 
</p>
<p>at t = I to four decimal places accuracy. 
Solution. We illustrate how to try and solve this problern using Euler's 
method, the three term Taylor series method, the improved Euler method, 
and the Runge-Kutta method. 
</p>
<p>(i) Euter' s method: 
Pascal Program 
</p>
<p>Program Euler (input, output); 
</p>
<p>var 
T, Y: array[O .. 999] of real; 
a, h: real; 
k, N: integer; 
</p>
<p>begin 
readln{T[O], Y[O], a, N); 
h :=a/N; 
page; 
for k := 0 to N -1 do 
</p>
<p>begin 
T[k+1]:=T[k]+h; 
Y[k + 1] := Y[k] + h * (Y[k] * (1 + exp(- Y[k])) + exp(T[k])); 
</p>
<p>end; 
writeln{'N':4, 'h':10, 'Y[N]':20); 
writeln{N:4,' ':2, h:10:7,' ':2, Y[N]:18:10); 
</p>
<p>end. 
</p>
<p>Section A 
Read in data {10 
</p>
<p>Fortran Program 
</p>
<p>DIMENSION T(1 000), Y(1 000) 
READ (5, 1 0) T(1 ), Y(1 ), A, N, 
FORMAT (3F20.8, 15) 
H=A/N 
</p>
<p>D020 K= 1, N 
T(K + 1)=T(K)+ H Section B { 
</p>
<p>Do computations Y(K + 1) = Y(K) + H * (Y(K) * (1 + EXP(- Y(K))) 
</p>
<p>Section C 
Print out 
results 
</p>
<p>20 
+ EXP(T(K))) 
</p>
<p>CONTINUE 
</p>
<p>WAlTE (6, 30) N, H, Y(N + 1) 
FORMAT (1 H, 1 X, 15, 2X, F1 0. 7, 4X, F20.9) 
CALL EXIT 
END 
</p>
<p>117 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>See also C Program 8 in Appendix C for a sample C program. 
We set A= 1, T[O] =0, Y[O] =O(T(l)= Y(l)=Oin the Fortran program) and 
ran these programs for N = 10, 20, 40, 80, 160, 320, and 640. The results of 
these computations are given in Table I. Notice that even with a step size h 
</p>
<p>Table 1 
</p>
<p>N h YN 
</p>
<p>10 0.1 2.76183168 
20 0.05 2.93832741 
40 0.025 3.03202759 
80 0.0125 3.08034440 
</p>
<p>160 0.00625 3.10488352 
320 0.003125 3.11725009 
640 0.0015625 3.12345786 
</p>
<p>as small as I/ 640, we can only guarantee an accuracy of one decimal 
place. This points out the Iimitation of Euler's method. Since N is so large 
already, it is wiser to use a more accurate scheme than to keep choosing 
smaller and smaller step sizes h for Euler's method. 
</p>
<p>(ii) The three term Taylor series method 
</p>
<p>Pascal Program 
</p>
<p>Program Taylor (input, output); 
</p>
<p>var 
T, Y: array[O .. 999] of real; 
a, h, DY1, DY2: real; 
k, N: integer; 
</p>
<p>begin 
readln(T[O], Y[O], a, N); 
h :=a/N; 
page; 
for k:=O to N-1 do 
</p>
<p>begin 
T[k+1] :=T[k]+h; 
DY1 := 1 + (1- Y[k]) * exp(- Y[k]); 
DY2 := Y[k] * (1 + exp(- Y[k])) + exp(T[k]); 
Y[k + 1] := Y[k] + h &bull; DY2+ (h * h/2) &bull; (exp(T[k]) + DY1 * DY2); 
</p>
<p>end; 
writeln('N':4, 'h':10, 'Y[N]':20); 
writeln(N:4,' ':2, h:10:7,' ':2, Y[N]:18:10); 
</p>
<p>end. 
</p>
<p>118 </p>
<p/>
</div>
<div class="page"><p/>
<p>l.l7 What to do in practice 
</p>
<p>Fortran Program 
</p>
<p>Replace Section B of the previous F ortran program by 
</p>
<p>0020 K= 1, N 
T(K+1)=T(K)+H 
DY1 = 1 + (1 - Y(K)) * EXP(- Y(K)) 
DY2 = Y(K) * (1 + EXP(- Y(K))) + EXP(T(K)) 
Y(K + 1)= Y(K)+ H * DY2 +(H * H/2)*(EXP(T(K))+ DY1 * DY2) 
</p>
<p>20 CONTINUE 
</p>
<p>See also C Program 9 in Appendix C for a sample C program. 
We set A=l, T[O]=O, and Y[O]=O (T(l)=O, and Y(l)=O in the Fortran 
program) and ran these programs for N = 10, 20, 40, 60, 80, 160, and 320. 
The results of these computations are given in Table 2. Observe that y 160 
</p>
<p>Table 2 
</p>
<p>N h YN 
</p>
<p>10 0.1 3.11727674 
20 0.05 3.12645293 
40 0.025 3.12885845 
80 0.0125 3.12947408 
</p>
<p>160 0.00625 3.12962979 
320 0.003125 3.12966689 
</p>
<p>and y 320 agree in their first four decimal places. Hence the approximation 
y(l) = 3.12966689 is correct to four decimal places. 
</p>
<p>(iii) The improved Eu/er method 
</p>
<p>Pascal Program 
</p>
<p>Program lmproved (input, output); 
</p>
<p>var 
T, Y: array[0 .. 999] of real; 
a, h, R1, R2: real; 
k, N: integer; 
</p>
<p>begin 
readln(T[O], Y[O], a, N); 
h :=a/N; 
page; 
for k:=O to N-1 do 
</p>
<p>begin 
T[k+1]:=T[k]+h; 
</p>
<p>119 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>R1 := Y[k] * (1 + exp(- Y[k])) + exp(T[k]); 
R2 := (Y[k] + h &bull; R1) * (1 + exp(- (Y[k] + h * R1))) + exp(T[k + 1]); 
Y[k + 1] := Y[k] + (h/2) &bull; (R1 + R2); 
</p>
<p>end; 
writeln{'N':4, 'h':10, 'Y[N]':20); 
writeln(N:4,' ':2, h:10:7,' ':2, Y[N]:18:10); 
</p>
<p>end. 
</p>
<p>Fortran Program 
</p>
<p>Replace Section B of the first Fortran program in this section by 
</p>
<p>0020 K= 1, N 
T(K + 1)=T(K)+ H 
R1 = Y(K) * (1 + EXP(- Y(K))) + EXP(T(K)) 
R2 =(Y(K)+ H * R1)&bull; (1 + EXP(- (Y(K)+ H * R1)))+ EXP(T(K + 1)) 
Y(K + 1) = Y(K) + (H/2) * (R1 + R2) 
</p>
<p>20 CONTINUE 
</p>
<p>See also C Program 10 in Appendix C for a sample C program. 
WesetA = 1, T[O] =0 and Y[O] =0 (T(1)=0 and Y(1)=0 in the Fortran pro-
gram) and ran these programs for N = 10, 20, 40, 80, 160, and 320. The re-
sults of these computations are given in Table 3. Observe that y 160 and 1320 
</p>
<p>Table 3 
</p>
<p>N h YN 
10 0.1 3.11450908 
20 0.05 3.12560685 
40 0.025 3.1286243 
80 0.0125 3.12941247 
</p>
<p>160 0.00625 3.12961399 
320 0.003125 3.12964943 
</p>
<p>agree in their first four decimal places. Hence the approximation y(1)= 
3.12964943 is correct to four decimal places. 
</p>
<p>(iv) The method oj Runge-Kutta 
</p>
<p>Pascal Program 
</p>
<p>Program Runge_Kutta (input, output); 
</p>
<p>var 
T, Y: array[O .. 999] of real; 
a, h, LK1, LK2, LK3, LK4: real; 
k, N: integer; 
</p>
<p>120 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.17 What to do in practice 
</p>
<p>begin 
readln(T[O], Y[O], a, N); 
h :=a/N; 
page; 
tor k:=O to N-1 do 
</p>
<p>begin 
T[k + 1] := T[k]+ h; 
LK1 := (Y[k] * (1 + exp(- Y[k])) + exp(T[k]); 
LK2 := (Y[k] + (h/2) * LK1) * (1 + exp(- (Y[k] + (h/2) * LK1))) 
</p>
<p>+ exp(T[k] + (h/2)); 
LK3 := (Y(k] + (h/2) * LK2) * (1 + exp(- (Y[k] + (h/2) * LK2))) 
</p>
<p>+ exp(T[k] + (h/2)); 
LK4 := (Y(k] + h * LK3) * (1 + exp(- (Y[k] + h * LK3))) 
</p>
<p>+exp(T[k+ 1]); 
Y[k + 1] := Y[k] + (h/6) * (LK1 +2 * LK2+ 2 * LK3 + LK4); 
</p>
<p>end; 
writeln('N':4, 'h':10, 'Y[N]':20); 
writeln(N:4,' ':2, h:10:7,' ':2, Y[N]:18:10); 
</p>
<p>0 0 1 10 
</p>
<p>Fortran Program 
</p>
<p>Replace Section B of the first Fortran program in this section by 
</p>
<p>0020 K=1, N 
T(K + 1)= T(K)+ H 
LK1 = Y(K) * (1 + EXP(- Y(K)) + EXP(T(K)) 
LK2 = (Y(K) + (H/2) * LK1) * (1 + EXP(- (Y(K) + (H/2) * LK1 ))) 
</p>
<p>1 + EXP(T(K) + (H/2)) 
LK3 = (Y(K) + (H/2) * LK2) * (1 + EXP(- (Y(K) + (H/2) * LK2))) 
+ EXP(T(K) + (H/2)) 
LK4 = (Y(K) + H * LK3) * (1 + EXP(- (Y(K) + H * LK3))) 
+ EXP(T(K + 1 )) 
</p>
<p>20 Y(K + 1)= Y(K)+(H/6) *(LK1 + 2 * LK2 +2 * LK3+ LK4) 
CONTINUE 
</p>
<p>See also C Program 11 in Appendix C for a sample C program. 
We set A= 1, T[O] =0 and Y[O] =0(T(1)=0 and Y(1)=0in the Fortran pro-
gram) and ran these programs for N = 10, 20, 40, 80, 160, and 320. The re-
sults of these computations are given in Table 4. Notice that our approxi-
mation of y(l) is already correct to four decimal places with h =0.1, and 
that it is already correct to eight decimal places with h=0.00625(N= 160). 
This example again illustrates the power of the Runge-Kutta method. 
</p>
<p>We conclude this section with two examples which pointout some addi-
tional difficulties which may arise when we solve initial-value problems on 
a digital computer. 
</p>
<p>121 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>Table 4 
</p>
<p>N h YN 
</p>
<p>10 0.1 3.1296517 
20 0.05 3.12967998 
40 0.025 3.1296819 
80 0.0125 3.12968203 
</p>
<p>160 0.00625 3.12968204 
320 0.003125 3.12968204 
</p>
<p>Example 2. Use the Runge-Kutta method to find approximate values of 
the solution of the initial-value problern 
</p>
<p>~ =t2+y2, y(O)= 1 
</p>
<p>at the points tk=kjN, k=1, ... ,N. 
Solution. 
</p>
<p>Pascal Program 
</p>
<p>Program Runge_Kutta (input, output); 
</p>
<p>var 
T, Y: array[0 .. 999] of real; 
a, h, LK1, LK2, LK3, LK4: real; 
k, N: integer; 
</p>
<p>begin 
readln(T[O], Y[O], a, N); 
h :=a/N; 
page; 
for k:=O to N-1 do 
</p>
<p>begin 
T[k+1]:=T[k]+h; 
LK1 :=T[k] &bull; T[k] + Y[k]&bull; Y[k]; 
LK2 := (T[k] + h/2) &bull; (T[k] + h/2) 
</p>
<p>+ (Y[k] + (h/2) &bull; LK1) &bull; (Y[k] + (h/2) &bull; LK1 ); 
LK3 := (T[k] + h/2) &bull; (T[k] + h/2) 
</p>
<p>+ (Y[k] + (h/2) &bull; LK2) &bull; (Y[k] + (h/2) &bull; LK2); 
LK4 := (T[k] + h) &bull; (T[k] + h) 
</p>
<p>+ (Y[k] + h &bull; LK3) &bull; (Y[k] + h &bull; LK3); 
Y[k+ 1] :=Y[k] + (h/6) &bull; (LK1 +2 &bull; LK2+2&bull; LK3+LK4); 
</p>
<p>end; 
writeln('T':4, 'Y':15); 
for k := 0 to N do 
</p>
<p>writeln(T[k]:10:7,' ':2, Y[k]:16:9); 
end. 
</p>
<p>122 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.17 What to do in practice 
</p>
<p>Fortran Program 
</p>
<p>Replace Sections B and C of the first Fortran program in this section by 
</p>
<p>0020 K=1,N 
</p>
<p>Section B 
Do computa-
</p>
<p>tions 
</p>
<p>Section C 
Print out 
results 
</p>
<p>20 
</p>
<p>T(K + 1) =T(K)+ H 
LK1 =T(K)* *2+Y(K)* *2 
LK2=(T(K)+(HI2))* *2+(Y(K)+(HI2)*LK1)* *2 
LK3=(T(K)+(HI2))* *2+(Y(K)+(HI2)*LK2)* *2 
LK4=(T(K)+ H) * *2 + (Y(K)+ H * LK3)* * 2 
Y(K + 1) =Y(K)+(HI6)* (LK1 +2 * LK2 +2 * LK3 +LK4) 
CONTINUE 
</p>
<p>NA=N+1 
WRITE (6, 30) (T(J), Y(J), J = 1, NA) 
</p>
<p>30 FORMAT (1 H1 ,3X, 1 HT,4X, 1 HY 1(1 H, 1X, F9.7, 
1 2X, F20.9l)) 
</p>
<p>CALL EXIT 
END 
</p>
<p>See also C Program 12 in Appendix C for a sample C program. 
We attempted to run these programs with A = 1, T[O] =0, Y[O] = 1 (T(1) = 0, 
and Y (1) = 1 in the Fortran program) and N = 10, but we received an error 
message that the numbers being computed exceeded the domain of the 
computer. That is to say, they were !arger than 1038 . This indicates that the 
solutiony(t) goes to infinity somewhere in the interval [0, 1). We can prove 
this analytically, and even obtain an estimate of wherey(t) goes to infinity, 
by the following clever argument. Observe that for 0 &lt; t &lt; 1, y(t) is never 
less than the solution &lt;/&gt;i(t)= 11(1- t) of the initial-value problern 
</p>
<p>: = y2, y (0) = 1. 
</p>
<p>In addition, y ( t) never exceeds the solution &lt;/&gt;z{ t) = tan( t + 7T I 4) of the ini-
tial-value problern dy I dt = 1 + y 2, y(O) = 1. Hence, for 0 &lt; t &lt; 1, 
</p>
<p>-1
1- &lt; y(t) &lt; tan(t + 7T 14). 
-t 
</p>
<p>This situation is described graphically in Figure 1. Since &lt;t&gt; 1(t) and &lt;Pz{t) be-
come infinite at t = 1 and t = 7T I 4 respectively, we conclude that y ( t) be-
comes infinite somewhere between 7T I 4 and 1. 
</p>
<p>The solutions of most initial-value problems which arise in physical and 
biological applications exist for all future time. Thus, we need not be 
overly concerned with the problern of solutions going to infinity in finite 
time or the problern of solutions becoming exceedingly large. On the other 
hand, though, there are several instances in economics where this problern 
is of paramount importance. In these instances, we are often interested in 
</p>
<p>123 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>y 
</p>
<p>~(t )=tan(t+ ~) 
y(t) 
</p>
<p>~------------~~--------~~t 
</p>
<p>t=l t=l 
</p>
<p>Figure 1 
</p>
<p>deterrnining whether certain differential equations can accurately rnodel a 
given econornic phenornenon. lt is often possible to elirninate several of 
these equations by showing that they allow solutions which are unrealisti-
cally large. 
</p>
<p>Example 3. Use Euler's rnethod to deterrnine approxirnate values of the 
solution of the initial-value problern 
</p>
<p>~ =y[y[- 3 1 4 +tsin~, y(O)=O (I) 
</p>
<p>at the points l / N, 2/ N, ... , 2. 
Solution. The prograrnrning for this problern is sirnplified irnrnensely by 
observing that 
</p>
<p>y[y[- 314 =(sgny)[y[ 114, where sgny= 0, y=O { 
I, y &gt;0 
</p>
<p>Pascal Program 
</p>
<p>Program Euler (input, output); 
</p>
<p>const 
</p>
<p>PI = 3.141592654; 
</p>
<p>var 
</p>
<p>T, Y: array[O .. 999] of real; 
</p>
<p>h: real; 
</p>
<p>k, N: integer; 
</p>
<p>124 
</p>
<p>-1, y &lt;0 </p>
<p/>
</div>
<div class="page"><p/>
<p>1.17 What to do in practice 
</p>
<p>begin 
readln(N); 
page; 
h :=2/N; 
T[1]:=h; 
Y[1] :=0; 
for k:=1 to N-1 do 
</p>
<p>begin 
T[k+1]:=T[k]+h; 
if Y[k]=O then Y[k+1] :=h &bull;T[k] &bull;sin(PI/T[k]) else 
Y[k+ 1] := Y[k] + h * (Y[k] * exp(( -3/4) * ln(abs(Y[k]))) 
</p>
<p>+ T[k] * sin(PI/T[k])); 
end; 
</p>
<p>writeln('T':4, 'Y':15); 
for k := 1 to N do 
</p>
<p>writeln(T[k]:10:7,' ':2, Y[k]:16:9); 
end. 
</p>
<p>Fortran Program 
</p>
<p>DIMENSION T(1 000), Y(1 000) 
READ (5, 1 0) N 
</p>
<p>1 0 FORMAT (15) 
H=2/N 
T(1)=H 
Y(1)=0 
D020 K=2,N 
T(K)=T(K -1)+ H 
Y(K) =Y(K-1) +H * (SIGN(Y(K-1)) * ABS(Y(K-1)) * &bull;0.25 
</p>
<p>1 + T(K -1) * SIN(3.141592654/T(K-1))) 
20 CONTINUE 
</p>
<p>WRITE(6,30) 0, 0, (T(J), Y(J), J = 1, N) 
30 FORMAT (1 H1,3X, 1 HT,4X, 1 HY /(1 H, 1 X, F10.7,2X, F20.9/)) 
</p>
<p>CALL EXIT 
END 
</p>
<p>See also C Program 13 in Appendix C for a sample C program. 
When we set N =25 we obtained the value 2.4844172 for y(2), but when we 
set N = 27, we obtained the va1ue - 0.50244575 for y (2). Moreover, all the 
Yk were positive for N = 25 and negative for N = 27. We repeated these 
computations with N = 89 and N = 91 and obtained the va1ues 2.64286349 
and -0.6318074 respective1y. In addition, all theYk were again positive for 
N = 89 and negative for N = 91. Indeed, it is possib1e, but rather difficult, 
to prove that all the Yk will be positive if N = 1, 5, 9, 13, 17, ... and negative 
</p>
<p>125 </p>
<p/>
</div>
<div class="page"><p/>
<p>1 First-order differential equations 
</p>
<p>if N = 3, 7, 11, 15, .... This suggests that the so1ution of the initial-value 
problern (1) is not unique. We cannot prove this analytically, since we 
cannot solve the differential equation explicitly. lt should be noted though, 
that the existence-uniqueness theorem of Section 1.10 does not apply here, 
since the partial derivative with respect to y of the function IYI- 3/')&gt; + 
t sin 7r / t does not exist at y = 0. 
</p>
<p>Most of the initial-value problems that arise in applications have unique 
solutions. Thus, we need not be overly concerned with the problern of non-
uniqueness of solutions. However, we should always bear in mind that ini-
tial-value problems which do not obey the hypotheses of the existence-
uniqueness theorem of Section 1.10 might possess more than one solution, 
for the consequences of picking the wrong solution in these rare instances 
can often be catastrophic. 
</p>
<p>EXERCISES 
</p>
<p>In each of Problems 1-5, find the solution of the given initial-value prob-
lern at t = 1 to four decimal places accuracy. 
</p>
<p>1. ~ =y+e-Y+2t, y(O)=O 2. ~ =1-t+y2, y(O)=O 
</p>
<p>dy t2+ y2 
3. dt = 2, y(O)=O 
</p>
<p>l+t+y 
</p>
<p>dy 3 
5. dt = ty - y' y (0) = 1 
</p>
<p>126 </p>
<p/>
</div>
<div class="page"><p/>
<p>Second -order linear 
differential equations 
</p>
<p>2.1 Algebraic properties of solutions 
</p>
<p>A second-order differential equation is an equation of the form 
</p>
<p>d2y ( dy) 
dt2 = f t ,y' dt . 
</p>
<p>For example, the equation 
</p>
<p>d
2
y =sint+3y+(dy)2 
</p>
<p>dt2 dt 
</p>
<p>2 
</p>
<p>(1) 
</p>
<p>is a second-order differential equation. A function y = y( t) is a solution of 
(1) if y(t) satisfies the differential equation; that is 
</p>
<p>d 2y(t) ( dy(t)) 
~=! t,y(t),----;Jt. 
</p>
<p>Thus, the function y(t)=cost is a solution of the second-order equation 
d 2yjdt2= -y since d 2(cost)/dt2 = -cost. 
</p>
<p>Second-order differential equations arise quite often in applications. 
The most famous second-order differential equation is Newton's second 
law of motion (see Section 1.7) 
</p>
<p>d2y ( dy) 
m dt2 = F t ,y, dt 
</p>
<p>which governs the motion of a particle of mass m moving under the in-
fluence of a force F. In this equation, m is the mass of the particle, y = y ( t) 
is its position at time t, dy / dt is its velocity, and Fis the total force acting 
on the particle. As the notation suggests, the force F may depend on the 
position and velocity of the particle, as well as on time. 
</p>
<p>127 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>In addition to the differential equation (I), we will often impose initial 
conditions on y(t) of the form 
</p>
<p>y(to)=yo, y'(to)=y~. (1') 
</p>
<p>The differential equation (I) together with the initial conditions (1') is re-
ferred to as an initial-value problem. For example, Iet y(t)* denote the 
position at timet of a particle moving under the influence of gravity. Then, 
y(t) satisfies the initial-value problern 
</p>
<p>d2y 
dt2 = -g; y(to)=yo, y'(to)=y~, 
</p>
<p>where y 0 is the initial position of the particle and y0 is the initial velocity of 
the particle. 
</p>
<p>Second-order differential equations are extremely difficult to solve. This 
should not come as a great surprise to us after our experience with first-
order equations. We will only succeed in solving the special differential 
equation 
</p>
<p>d2y dy 
-2 +p(t)-d +q(t)y=g(t). 
dt t 
</p>
<p>(2) 
</p>
<p>Fortunately, though, many of the second-order equations that arise in ap-
plications are of this form. 
</p>
<p>The differential equation (2) is called a second-order linear differential 
equation. We singleout this equation and call it linear because bothy and 
dy I dt appear by themselves. For example, the differential equations 
</p>
<p>d2y dy 
- 2 +3t-d +(sint)y=e 1 dt t 
</p>
<p>and 
d2y dy 
-+e'-+2y=l 
dt2 dt 
</p>
<p>are linear, while the differential equations 
</p>
<p>d2y dy 
- +3- +siny=t3 
dt2 dt 
</p>
<p>and 
</p>
<p>d2y + ( dy )2 = I 
dt 2 dt 
</p>
<p>are both nonlinear, due to the presence of the siny and (dy I dti terms, re-
spectively. 
</p>
<p>We consider first the second-order linear homogeneous equation 
</p>
<p>d2y dy 
- 2 +p(t)-d +q(t)y=O (3) dt t 
</p>
<p>*The positive direction of y is taken upwards. 
</p>
<p>128 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.1 Algebraic properties of solutions 
</p>
<p>which is obtained from (2) by setting g(t) = 0. lt is certainly not obvious at 
this point how to find all the solutions of (3), or how to solve the initial-
value problern 
</p>
<p>d2y dy 
dP +p(t) dt +q(t)y=O; y(to)=yo, y'(to)=yb. (4) 
</p>
<p>Therefore, before trying to develop any elaborate procedures for solving 
( 4), we should first determine whether it actually has a solution. This infor-
mation is contained in the following theorem, whose proof will be indi-
cated in Chapter 4. 
</p>
<p>Theorem 1. (Existence-uniqueness Theorem). Let the functions p ( t) and 
q( t) be continuous in the open interval a &lt; t &lt; &szlig;. Then, there exists one, 
and only one function y ( t) satisfying the differential equation (3) on the en-
tire interval a &lt; t &lt; &szlig;, and the prescribed initial conditions y(t0) = y 0, y'(t0) 
= Yb&middot; In particular, any solution y = y(t) oj (3) which satisfies y(t0) = 0 and 
y'(t0) = 0 at some time t = t0 must be identically zero. 
</p>
<p>Theorem 1 is an extremely important theorem for us. On the one hand, 
it is our hunting license to find the unique solutiony(t) of (4). And, on the 
other hand, we will actually use Theorem 1 to help us find all the solutions 
of (3). 
</p>
<p>We begin our analysis of Equation (3) with the important observation 
that the left-hand side 
</p>
<p>y" + p(t)y' + q(t)y 
</p>
<p>of the differential equation can be viewed as defining a "function of a 
function": with each function y having two derivatives, we associate 
another function, which we'll call L [y ], by the relation 
</p>
<p>L[y ](t)= y"(t) + p(t)y'(t)+ q(t)y(t). 
</p>
<p>In mathematical terminology, L is an operator which operates on func-
tions; that is, there is a prescribed recipe for associating with each function 
y a new function L[y ]. 
</p>
<p>Example 1. Letp(t)=O and q(t)= t. Then, 
</p>
<p>L[y ](t)= y"(t) + ty(t). 
If y(t)=cost, then 
</p>
<p>L [ y J ( t) = ( cos t )" + t cos t = ( t - 1 )cos t, 
</p>
<p>and if y (t) = t3, then 
</p>
<p>L[y ](t)=(t3)" + t(t3)= t4 +6t. 
</p>
<p>129 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>Thus, the operator L assigns the function ( t- 1 )cos t to the function cos t, 
and the function 6t + t 4 to the function t 3&bull; 
</p>
<p>The concept of an operator acting on functions, or a "function of a 
function" is analogaus to that of a function of a single variable t. Recall 
the definition of a functionj on an interval /: with each number t in I we 
associate a new number called f(t). In an exactly analogaus manner, we 
associate with each function y having two derivatives a new function called 
L[y]. This is an extremely sophisticated mathematical concept, because in 
a certain sense, we are treating a function exactly as we do a point. 
Admittedly, this is quite difficult to grasp. It's not surprising, therefore, 
that the concept of a '~function of a function" was not developed till the 
beginning of this century, and that many of the "high powered" theorems 
of mathematical analysis were proved only after this concept was 
mastered. 
</p>
<p>We now derive several important properties of the operator L, which we 
will use to great advantage shortly. 
</p>
<p>Property 1. L[cy)=cL[y),jor any constant c. 
</p>
<p>PROOF. L[ cy )( t) = ( cy )"(t) + p( t)( cy )'( t) + q( t)( cy )( t) 
</p>
<p>= cy"(t)+ cp(t)y'(t) + cq(t)y(t) 
</p>
<p>= c[y"(t) + p(t)y'(t) + q(t)y(t) J 
</p>
<p>=cL[y](t). 0 
The meaning of Property 1 is that the operator L assigns to the function 
</p>
<p>(cy) c times the function it assigns toy. For example, Iet 
</p>
<p>L[ y ](t) = y"(t) + 6y'(t)- 2y(t). 
This operator L assigns the function 
</p>
<p>( t 2)" + 6( t 2)'- 2( t2 ) = 2 + 12t- 2t 2 
</p>
<p>to the function t2&bull; Hence, L must assign the function 5(2 + 12t- 2t2) to the 
function 5t2&bull; 
</p>
<p>Property 2. L[y 1 + Y2l = L[ytJ + L[J2). 
</p>
<p>PROOF. 
</p>
<p>L[ Yt + Y2]( t) = (Yt + Y2)"( t) + p( t)(Yt + J2)'(t) + q( t)( Yt + h)( t) 
= y;' (t) + y; (t) + p(t)y; (t) + p(t)y2(t) + q(t)y1 (t) + q(t)h(l) 
</p>
<p>= [ y ;' ( t) + p ( t) y; ( t) + q ( t) y 1 ( t) J + [ y; ( t) + p ( t) Y2 ( t) + q ( t) Y2 ( t) J 
</p>
<p>=L[yt](t)+L[h](t). 0 
</p>
<p>The meaning of Property 2 is that the operator L assigns to the function 
y 1 + Y2 the sum of the functions it assigns to y 1 and h&middot; For example, Iet 
</p>
<p>L[y ](t) = y"(t) +2y'(t)- y(t). 
</p>
<p>130 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.1 Algebraic properties of solutions 
</p>
<p>This operator L assigns the function 
</p>
<p>(cost)" + 2(cost)'- cost =-2cost- 2sint 
to the function cos t, and the function 
</p>
<p>(sin t)" + 2(sin t)'- sin t = 2 cos t- 2 sin t 
to the function sin t. Hence, L assigns the function 
</p>
<p>( - 2 cos t - 2 sin t) + 2 cos t - 2 sin t = - 4 sin t 
to the function sin t + cos t. 
</p>
<p>Definition. An operator L which assigns functions to functions and which 
satisfies Properties l and 2 is called a linear operator. All other opera-
tors are nonlinear. An example of a nonlinear operator is 
</p>
<p>L[y](t)=y"(t)-2t[y(t)f, 
</p>
<p>This operator assigns the function 
</p>
<p>(l)" -2t(l)4 = 1_ _1_ =0 
I I 13 13 
</p>
<p>to the function l I t, and the function 
</p>
<p>(E._)" -21(E._)4= 2c- 2c4 = 2c(l-c3) 
I t 13 13 13 
</p>
<p>to the function c I I. Hence, for C7'~'o, I, and y(t) =I I I, we see that L[cy] 
~cL[y]. 
</p>
<p>The usefulness of Properties I and 2 lies in the observation that the 
solutions y ( t) of the differential equation (3) are exactly those functions y 
for which 
</p>
<p>L[ y ](1) = y"( 1) + p(1)y'(1) + q(l)y(t) = 0. 
</p>
<p>In other words, the solutions y(t) of (3) are exactly those functions y to 
which the operator L assigns the zero function."' Hence, if y(l) is a solution 
of (3) then so is cy(t), since 
</p>
<p>L[ cy ](1) = cL[y ](t) =0. 
</p>
<p>If y 1(t) and yit) are solutions of (3), then y 1(t) + yit) is also a solution of 
(3), since 
</p>
<p>L[y1 + h](t)= L[yi](t) + L[h](t)=O+O=O. 
</p>
<p>Combining Properties l and 2, we see that alllinear combinations 
</p>
<p>CIYI (t) + C2h(t) 
of solutions of (3) are again solutions of (3). 
</p>
<p>"The zero function is the function whose value at any timet is zero. 
</p>
<p>131 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>The preceding argument shows that we can use our knowledge of two 
solutions y 1(t) and J2(t) of (3) to generate infinitely many other solutions. 
This statement has some very interesting implications. Consider, for exam-
ple, the differential equation 
</p>
<p>d2y 
-+y=O. 
dt2 
</p>
<p>Two solutions of (5) arey 1(t)=cost andyz{t)=sint. Hence, 
</p>
<p>y(t) = c1 cost + c2 sint 
</p>
<p>(5) 
</p>
<p>(6) 
</p>
<p>is also a solution of (5), for every choice of constants c1 and c2&bull; Now, 
Equation (6) contains two arbitrary constants. It is natural to suspect, 
therefore, that this expression represents the general solution of (5); that is, 
every solution y(t) of (5) must be of the form (6). This is indeed the case, 
as we now show. Let y ( t) be any solution of (5). By the existence-unique-
ness theorem, y(t) exists for all t. Let y(O) = y 0, y'(O) = yb, and consider the 
function 
</p>
<p>&lt;/&gt;( t) = y 0 cos t + ybsin t. 
</p>
<p>This function is a solution of (5) since it is a linear combination of solu-
tions of (5). Moreover, cj&gt;(O)=y0 and cj&gt;'(O)=yb. Thus,y(t) and cj&gt;(t) satisfy 
the same second-order linear homogeneaus equation and the same initial 
conditions. Therefore, by the uniqueness part of Theorem 1, y(t) must be 
identically equal to &lt;j&gt;{t), so that 
</p>
<p>Y( t) = y0 cos t + ybsint. 
</p>
<p>Thus, Equation (6) is indeed the general solution of (5). 
Let us return now to the generallinear equation (3). Suppose, in some 
</p>
<p>manner, that we manage to find two solutions y 1(t) and yz(t) of (3). Then, 
every function 
</p>
<p>(7) 
</p>
<p>is again a solution of (3). Does the expression (7) represent the general 
solution of (3)? That is to say, does every solutiony(t) of (3) have the form 
(7)? The following theorem answers this question. 
</p>
<p>Theorem 2. Let y 1(t) and Y2(t) be two solutions of (3) on the interval a &lt; t &lt; 
&szlig;, with 
</p>
<p>Y1 (t)y2(t)- y; (t)Y2(t) 
</p>
<p>unequal to zero in this interval. Then, 
</p>
<p>y(t)= c1y 1 (t)+ CzJ2(t) 
</p>
<p>is the generat solution of (3). 
</p>
<p>PROOF. Let y(t) be any solution of (3). We must find constants c1 and c2 
such thaty(t)=c1y 1(t)+c2yz{t). Tothis end, pick a time t0 in the interval 
</p>
<p>132 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.1 Algebraic properties of solutions 
</p>
<p>(a,&szlig;) and lety0 andy0 denote the values of y andy' at t = t0&bull; The constants 
c1 and c2, if they exist, must satisfy the two equations 
</p>
<p>ciyi (to) + C2Y2(to) = Yo 
Cl Y~ ( to) + C2Yl ( to) = Yo&middot; 
</p>
<p>Multiplying the first equation by y2(t0), the second equation by Y2(t0) and 
subtracting gives 
</p>
<p>cl [ Y 1 (to) Y2 (to)- Y~ (to) Y2 (to)] = YoY2 (to)-Yoh (to)&middot; 
</p>
<p>Similarly, multiplying the first equation by y;(to), the second equation by 
y 1(t0) and subtracting gives 
</p>
<p>c2[Y~ (to)h(to)- Y1 (to)Y2(to)] = YoY; (to)-YoY1 (to)&middot; 
</p>
<p>Hence, 
</p>
<p>and 
</p>
<p>YoY1 ( to)-YoY; ( to) 
</p>
<p>c2 = Y1 (to)Y2(to)- Y~ (to)Y2(to) 
</p>
<p>if Yi(t0)y2(t0)-y;(t0)Y2(t0)*0. Now, let 
</p>
<p>cf&gt;(t)= C1Y1 (t)+ C2Y2(t) 
</p>
<p>for this choice of constants cpc2&bull; We know that cp(t) satisfies (3), since it is 
a linear combination of solutions of (3). Moreover, by construction, cf&gt;(t0) = 
y 0 and cf&gt;'(t0) = y0. Thus, y(t) and cf&gt;(t) satisfy the same second-order linear 
homogeneaus equation and the same initial conditions. Therefore, by the 
uniqueness part of Theorem 1, y(t) must be identically equal to cf&gt;{t); that 
is, 
</p>
<p>a&lt;t&lt;&szlig;. D 
Theorem 2 is an extremely useful theorem since it reduces the problern 
</p>
<p>of finding all solutions of (3), of which there are infinitely many, to the 
much simpler problern of finding just two solutions y 1(t),yit). The only 
condition imposed on the solutions y 1(t) and yit) is that the quantity 
y 1(t)y2(t)- y~(t)yit) be unequal to zero for a &lt; t &lt; &szlig;. When this is the 
case, we say that y 1(t) and Y2(t) are a fundamental set of solutions of (3), 
since all other solutions of (3) can be obtained by taking linear combina-
tions of y 1(t) and Y2(t). 
</p>
<p>Definition. The quantity y 1(t)y2(t)-y((t)yit) is called the Wronskian of 
y 1 andh, and is denoted by W(t)= W[y 1,y2](t). 
</p>
<p>Theorem 2 requires that W[y 1,Y2](t) be unequal to zero at all points in 
the interval ( a, &szlig;). In actual fact, the Wronskian of any two solutions 
</p>
<p>133 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>y 1(t),yit) of (3) is either identically zero, or is never zero, as we now 
show. 
</p>
<p>Theorem 3. Let p(t) and q(t) be continuous in the interval a &lt; t &lt; &szlig;, and Iet 
y 1(t) and Yit) be two solutions of (3). Then, W[y 1,Y2](t) is either identi-
ca/ly zero, or is never zero, on the interval a &lt; t &lt; &szlig;. 
</p>
<p>We prove Theorem 3 with the aid of the following Iemma. 
</p>
<p>Lemma 1. Let y 1(t) and y 2(t) be two solutions of the linear differential equa-
tiony"+p(t)y'+q(t)y=O. Then, their Wronskian 
</p>
<p>satisfies the first-order differential equation 
</p>
<p>W'+p(t)W=O. 
</p>
<p>PROOF. Observe that 
</p>
<p>W'(t) = ~ (YIY;- Yih) 
</p>
<p>= Y1Y; + y;y;- y;y;- y;'Y2 
= Y1Y;- Y~h&middot; 
</p>
<p>Since y 1 and Y2 are solutions of y" + p(t)y' + q(t)y = 0, we know that 
</p>
<p>and 
</p>
<p>Hence, 
</p>
<p>y~= -p(t)yi-q(t)y1. 
</p>
<p>W'(t) = Y1 [-p(t)y;- q(t)h]-h[-p(t)y;- q(t)y 1] 
</p>
<p>= -p(t)[y1y;-y;Y2] 
</p>
<p>= -p(t)W(t). 0 
</p>
<p>We can now give a very simple proof of Theorem 3. 
</p>
<p>PRooF OF THEOREM 3. Pick any t0 in the interval (a,&szlig;). From Lemma 1, 
</p>
<p>W[yi,h](t)= W[y 1,Y2](t0)exp(- f&gt;(s)ds). 
</p>
<p>Now, exp(- !,
0
</p>
<p>1 p(s)ds) is unequal to zero for a &lt; t &lt; &szlig;. Therefore, 
W[y 1,Y2](t) is either identically zero, or is never zero. 0 
</p>
<p>134 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.1 Algebraic properties of solutions 
</p>
<p>The simplest situation where the Wronskian of two functions y 1(t),yit) 
vanishes identically is when one of the functions is identically zero. More 
generally, the Wronskian of two functions y 1(t),yit) vanishes identically if 
one of the functions is a constant multiple of the other. If Y2 = cyp say, 
then 
</p>
<p>W[ y 1,Y2]( t) = y 1 ( cy 1)'- y~ ( cy 1) = 0. 
</p>
<p>Conversely, suppose that the Wronskian of two solutions y 1(t),yit) of (3) 
vanishes identically. Then, one of these solutions must be a constant multi-
ple of the other, as we now show. 
</p>
<p>Theorem 4. Let y 1(t) and Y2(1) be two solutions of (3) on the interval a &lt; t &lt; 
&szlig;, and suppose that W[y 1,Y2](t0) = 0 for some t0 in this interval. Then, one 
of these solutions is a constant multiple of the other. 
</p>
<p>PROOF # 1. Suppose that W[y 1,Y2](t0)=0. Then, the equations 
</p>
<p>clyl Uo) + C2Y2Uo) = 0 
</p>
<p>cly~ Uo) + c2y;(to) = 0 
</p>
<p>have a nontrivial solution c1,c2; that is, a solution c1,c2 with ic11 + jc21 *0. 
Lety(t)= c1y 1(t)+ c2Y2(t), for this choice of constants c1,c2. We know that 
y(t) is a solution of (3), since it is a linear combination of y 1(t) and Y2(t). 
Moreover, by construction,y(t0)=0 andy'(t0)=0. Therefore, by Theorem 
1, y (t) is identically zero, so that 
</p>
<p>a&lt; t&lt;&szlig;, 
</p>
<p>If c 1 * 0, then y 1(t) = - (c 2 / c 1)Y2(t), and if c2 * 0, then y 2(t) = 
-(c1/c2)y 1(t). In either case, one of these solutions is a constant multiple 
of the other. 0 
</p>
<p>PROOF # 2. Suppose that W [Yph](t0) = 0. Then, by Theorem 3, 
W[y 10 y2](t) is identically zero. Assurne that y 1(t)yit)*O for a &lt; t &lt; &szlig;. 
Then, dividing both sides of the equation 
</p>
<p>Y1 (t)y;(t)- y~ (t)y2(t) =0 
</p>
<p>y;(t) y~(t) 
-----=0 
Y2(t) Y1 (t) . 
</p>
<p>This equation implies that y 1(t)= cyit) for some constant c. 
Next, suppose that y 1(t)yit) is zero at some point t = t* in the interval 
</p>
<p>a &lt; t &lt; &szlig;. Without loss of generality, we may assume that y 1(t*)=O, since 
otherwise we can relabely 1 andh. In this case it is simple to show (see Ex-
ercise 19) that either y 1(t)=:O, or yit)=[y;(t*)/yi(t*)]y 1(t). This com-
pletes the proof of Theorem 4. 0 
</p>
<p>135 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>Definition. The functions y 1(t) and yit) are said to be linearly dependent 
on an interval I if one of these functions is a constant multiple of the 
</p>
<p>other on I. The functions y 1(t) and Yit) are said to be linearly indepen-
dent on an interval I if they are not linearly dependent on I. 
</p>
<p>Corollary to Theorem 4. Two solutions y 1(t) and Yz(l) of (3) are linearly in-
dependent on the interval o: &lt; t &lt; &szlig; if, and only if, their Wronskian is un-
equal to zero on this interval. Thus, two solutions y 1(t) and Yz(t) form a 
fundamental set of solutions of (3) on the interval o: &lt; t &lt; &szlig; if, and only ij, 
they are linearly independent on this interval. 
</p>
<p>EXERCISES 
</p>
<p>1. Let L[y](t)=y"(t)-3ty'(t)+3y(t). Compute 
(a} L[e 1], (b) L[cosv'3 t], (c) L[2e 1+4cosv'3 t], 
(d) L[t2], (e) L[5t2], (f) L[t], (g) L[t2 +3t]. 
</p>
<p>2. Let L[y](t)=y"(t)-6y'(t)+5y(t). Compute 
(a) L[e 1], (b) L{e21 ], (c) L[e31 ], 
(e) L[t], (f) L[t2], (g) L[t2 +2t]. 
</p>
<p>3. Show that the operator L defined by 
</p>
<p>L(y](t)= {s 2y(s)ds 
</p>
<p>is linear; that is, L[cy]=cL[y] and L[y1+Y2]=L[yd+L[Y21&middot; 
</p>
<p>4. Let L[y](t) = y"(t) + p(t)y'(t) + q(t)y(t), and suppose that L[t2] = t + l and 
L(t] = 2t + 2. Show that y(t) = t- 2t2 is a solution of y" + p(t)y' + q(t)y =0. 
</p>
<p>5. (a) Show that y 1(t) = Yt and Y2(1)= 1/ t are solutions of the differential equa-
tion 
</p>
<p>136 
</p>
<p>2t2y"+3ty'-y=O (*) 
</p>
<p>on the interval 0 &lt; t &lt; oo. 
(b) Compute W[y 1,y2](t). What happens as t approaches zero? 
(c) Show thaty1(t) andy2(t) form a fundamental set of solutions of (*) on the 
</p>
<p>interval 0 &lt; t &lt; oo. 
(d) Solve the initial-value problern 2t2y" + 3ty'-y =0; y(l) =2, y'(l)= I. 
</p>
<p>y"+ty'+y=O 
</p>
<p>on the interval - oo &lt; t &lt; oo. 
(b) Compute W[y 1,y2](t). 
</p>
<p>(*) 
</p>
<p>(c) Show thaty 1 andy2 form a fundamental set of solutions of (*) on the inter-
val - oo &lt; t &lt; oo. 
</p>
<p>(d) Solve the initial-value problern y" + ty' + y = 0; y(O) =0, y'(O) =I. </p>
<p/>
</div>
<div class="page"><p/>
<p>2.1 Algebraic properties of solutions 
</p>
<p>7. Compute the Wronskian of the following pairs of functions. 
(a) sinat,cosbt (b) sin2 t, 1-cos2t 
(c) eat,ebt (d) ea',teat 
(e) t,t!nt (f) ea1 sinbt,ea1 cosbt 
</p>
<p>8. Let y 1(t) and Y2(t) be solutions of (3) on the interval - oo &lt; t &lt; oo with y 1(0) = 
3, Y!(O) = 1, Y2(0) = 1, andy2(0) = t. Show thaty 1(t) andyit) are 1inearly depen-
dent on the interval - oo &lt; t &lt; oo. 
</p>
<p>9. (a) Lety 1(t) andY2(t) be solutions of (3) on the interval a &lt; t &lt; &szlig;, withy 1(t0)= 
I, y!(t0) = 0, Y2Uo) = 0, and y2(t0) =I. Show that y 1(t) and yit) form a 
fundamental set of solutions of (3) on the interva1 a &lt; t &lt; &szlig;. 
</p>
<p>(b) Show thaty(t)=y0 y 1(t)+YoY2U) is the solution of (3) satisfyingy(t0)=Yo 
and y' ( t0) = y0. 
</p>
<p>10. Show that y(t)= t2 can never be a solution of (3) if the functions p(t) and q(t) 
are continuous at t = 0. 
</p>
<p>11. Lety 1(t)= t2 andyit)= tltl. 
(a) Show that y 1 and y 2 are linearly dependent on the interval 0.;; t.;; I. 
(b) Show that y 1 and y 2 are linearly independent on the interva1 - 1 .;; t .;; I. 
(c) Show that W[y 1,Y2](t) is identically zero. 
(d) Show thaty1 andY2 can never be two so1utions of (3) on the interval - l &lt; t 
</p>
<p>&lt; I if both p and q are continuous in this interval. 
</p>
<p>12. Suppose thaty 1 andY2 are linearly independent on an interval /. Prove that z 1 
= y 1 + Y2 and z2 = y 1 - Y2 arealso linearly independent on I. 
</p>
<p>13. Let y 1 and y 2 be solutions of Bessel's equation 
</p>
<p>t2y" + ty' + (t 2 - n2 )y =0 
</p>
<p>on the interval 0 &lt; t &lt; oo, with y 1(l)= l, y!(l)=O, yil)=O, and y2(l)= I. Com-
pute W[y 1,y2](t). 
</p>
<p>14. Suppose that the Wronskian of any two solutions of (3) is constant in time. 
Prove that p ( t) = 0. 
</p>
<p>In Problems 15-18, assume thatp and q are continuous, and that the func-
tions y 1 and h are solutions of the differential equation 
</p>
<p>y" + p(t)y' + q(t)y =0 
</p>
<p>on the interval a &lt; t &lt; &szlig;. 
15. Prove that if y 1 and Y2 vanish at the same point in the interval a &lt; t &lt; &szlig;, then 
</p>
<p>they cannot form a fundamental set of solutions on this interval. 
</p>
<p>16. Prove that if y 1 and Y2 achieve a maximum or minimum at the same point in 
the interval a &lt; t &lt; &szlig;, then they cannot form a fundamental set of solutions on 
this interval. 
</p>
<p>17. Prove that if y 1 and y 2 are a fundamental set of solutions, then they cannot 
have a common point of inflection in a &lt; t &lt; &szlig; un1ess p and q vanish simulta-
neously there. 
</p>
<p>137 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>18. Suppose that y 1 and y 2 are a fundamental set of solutions on the interval - oo 
&lt; t &lt; oo. Show that there is one and only one zero of y 1 between consecutive 
zeros of y 2&bull; Hint: Differentiate the quantity y2fy 1 and use Rolle's Theorem. 
</p>
<p>19. Suppose that W[y 1,y2](t*) = 0, and, in addition, y 1(t*) = 0. Prove that either 
y 1(t):=O or yz(t)=[y2(t*)/y!(t*)]y 1(t). Hint: If W[y 1,Yz](t*)=O andy 1(t*)=O, 
then Yz(t*)y!(t*) =0. 
</p>
<p>2.2 Linear equations with constant coefficients 
</p>
<p>W e consider now the homogeneous linear second-order equation with con-
stant coefficients 
</p>
<p>d2y dy 
L[y] =a- +b- +cy=O 
</p>
<p>dt2 dt 
(I) 
</p>
<p>where a, b, and c are constants, with a * 0. Theorem 2 of Section 2.1 teils 
us that we need only find two independent solutions y 1 and Yz of (I); all 
other solutions of (I) are then obtained by taking linear combinations of y 1 
and Yz&middot; U nfortunately, Theorem 2 doesn't teil us how to find two solutions 
of (1). Therefore, we will try an educated guess. Tothis end, observe that a 
function y(t) is a solution of (I) if a constant times its second derivative, 
plus another constant times its first derivative, plus a third constant times 
itself is identicaily zero. In other words, the three terms ay", by', and cy 
must cancel each other. In general, this can only occur if the three func-
tions y(t), y'(t), and y"(t) are of the "same type". For example, the func-
tion y(t)= t5 can never be a solution of (1) since the three terms 20at3, 
5bt4, and ct 5 are polynomials in t of different degree, and therefore cannot 
cancel each other. On the other hand, the function y(t) = ert, r constant, 
has the property that both y'(t) and y"(t) are multiples of y(t). This sug-
gests that we try y(t) = e'1 as a solution of (1). Computing 
</p>
<p>L [ e rt J = a ( e'1 )" + b ( e rt )' + c( e ' 1 ) 
= ( ar2 + br + c)e'1, 
</p>
<p>we see thaty(t)=e'1 is a solution of (I) if, and only if 
</p>
<p>ar2 + br + c = 0. (2) 
</p>
<p>Equation (2) is cailed the characteristic equation of (1). It has two roots 
rpr2 given by the quadratic formula 
</p>
<p>- b+ Yb 2 -4ac 
rl = 2a 2a 
</p>
<p>If b2 -4ac is positive, then r1 and r2 arereal and distinct. In this case,y 1(t) 
= e'&bull;1 and Yz(t)= e''1 are two distinct solutions of (1). These solutions are 
clearly linearly independent (on any interval /), since e''1 is obviously not 
a constant multiple of e''1 for r2*r1&bull; (If the reader is unconvinced of this 
</p>
<p>138 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.2 Linear equations with constant coefficients 
</p>
<p>he can compute 
</p>
<p>W[ e''l,er21] =(r2-rl)e&lt;r,+r2)t, 
</p>
<p>and observe that W is never zero. Hence, e' 11 and e'21 are linearly indep:m-
dent on any interval /.) 
</p>
<p>Example 1. Find the generat solution of the equation 
</p>
<p>d2y dy 
-+5-+4y=O. 
dt2 dt 
</p>
<p>(3) 
</p>
<p>Solution. The characteristic equation r2+5r+4=(r+4)(r+ 1)=0 has two 
distinct roots r1 = -4 and r2 = - l. Thus, y 1(t) = e - 41 and Yz(t) = e -I form a 
fundamental set of solutions of (3), and every solution y(t) of (3) is of the 
form 
</p>
<p>y(t) = c1e- 41 + c2e- 1 
</p>
<p>for some choice of constants cp c2. 
</p>
<p>Example 2. Find the solution y(t) of the initial-value problern 
</p>
<p>d2y dy 
-+4--2y=O&middot; 
dt2 dt ' 
</p>
<p>y(O)= 1, y'(0)=2. 
</p>
<p>Solution. The characteristic equation r2 + 4r- 2 = 0 has 2 roots 
</p>
<p>-4+ v'T6+8 = -2+ v'6 
2 
</p>
<p>and 
</p>
<p>r2= -4- ~16+8 = -2- v'6. 
</p>
<p>Hence, y 1(t) = e''1 and Yz(t) = e'21 are a fundamental set of solutions of 
y" +4y'- 2y =0, so that 
</p>
<p>y( t) = c1e&lt; -2+ V6)t + c2e&lt; - 2 - V6)t 
</p>
<p>for some choice of constants c1,c2 &bull; The constants c1 and c2 are determined 
from the initial conditions 
</p>
<p>c1 +c2 =1 and (-2+v'6)c 1 +(-2-v'6)c2 =2. 
</p>
<p>From the first equation, c2 = 1 - c 1&bull; Substituting this value of c2 into the 
second equation gives 
</p>
<p>(-2+Y6)c 1-(2+Y6)(1-c1)=2, or 2v'6 c1 =4+v'6. 
</p>
<p>Therefore, c1 =2/v'6 + ~, c2 = 1- c1 = ~- 2/v'6, and 
</p>
<p>Y ( t) = ( _!_ + 2_ )e&lt; -2+ V6)t + ( _!_ __ 2_ )e -(2+ v6 )1&bull; 
2 V6 2 v'6 
</p>
<p>139 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>EXERCISES 
</p>
<p>Find the general solution of each of the following equations. 
</p>
<p>d 2y d 2y dy 
1 --y=O 2. 6--7-+y=O 
. dt2 dt2 dt 
</p>
<p>d 2y dy d 2y dy 
3. dt2 - 3 dt + y = 0 4. 3 dt2 + 6 dt + 2y = 0 
</p>
<p>Solve each of the following initial-value problems. 
</p>
<p>d 2y dy 
5. dt2 -3 dt -4y=O; y(0)=1, y'(O)=O 
</p>
<p>d 2y dy 
6 2-+- -!Oy=O&middot; y(1)=5, y'(1)=2 
</p>
<p>. dt2 dt ' 
</p>
<p>d2y dy 
7. 5-2 +5-d -y=O; y(O)=O, y'(O)= I dt t 
</p>
<p>d2y dy 
8. dt2 -6 dt + y =0; y(2)= 1, y'(2)= 1 
</p>
<p>Remark. In doing Problems 6 and 8, observe that e'&lt;r-ro) is also a solution 
of the differential equation ay" + by' + cy = 0 if ar2 + br + c = 0. Thus, to 
find the solutiony(t) of the initial-value problern ay" + by' + cy =0; y(t0)= 
y 0,y'(t0)= y0, we would write y(t)= c1e'&bull;&lt;r-ro&gt;+ c2e'2(r-ro) and solve for c1 
and c2 from the initial conditions. 
</p>
<p>9. Lety(t) be the solution of the initial-value problern 
</p>
<p>d 2y dy 
-+5-+6y=O&middot; 
dt2 dt ' 
</p>
<p>y(O)=l, y'(O)=V. 
</p>
<p>For what values of V does y(t) remain nonnegative for all t;;. 0? 
</p>
<p>10. The differential equation 
</p>
<p>L[y]= t 2y" +aty' + &szlig;y=O (*) 
</p>
<p>is known as Euler's equation. Observe that t 2 y ", ty', and y are all multiples of 
t' if y = t'. This suggests that we try y = t' as a solution of (*).Show thaty = t' 
is a solution of ('1') if r2+(a -l)r+ &szlig; = 0. 
</p>
<p>11. Find the general solution of the equation 
</p>
<p>t 2y" +5ty' -5y =0, t &gt;0 
</p>
<p>12. Solve the initial-value problern 
</p>
<p>t 2y"- ty'- 2y =0; y(l)=O, y'(l)= 1 
</p>
<p>on the interval 0 &lt; t &lt; oo. 
</p>
<p>140 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.2 Linear equations with constant coefficients 
</p>
<p>2.2.1 Complex roots 
</p>
<p>If b2 - 4ac is negative, tben tbe cbaracteristic equation ar2 + br + c = 0 bas 
complex roots 
</p>
<p>- b+ rV 4ac- b2 
rt= 
</p>
<p>- b- iV 4ac- b2 
and r2 = 2a . 2a 
</p>
<p>We would like to say tbat e''1 and e'21 are solutions of tbe differential 
equation 
</p>
<p>(I) 
</p>
<p>However, tbis presents us witb two serious difficulties. On tbe one band, 
tbe function e'1 is not defined, as yet, for r complex. And on tbe otber 
band, even if we succeed in defining e''1 and e'21 as complex-valued solu-
tions of (1), we are still faced witb tbe problern of finding two real-valued 
solutions of (1). 
</p>
<p>We begin by resolving tbe second difficulty, since otberwise tbere's no 
sense tackling tbe first problem. Assurne tbaty(t)=u(t)+iv(t) is a com-
plex-valued solution of (1). Tbis means, of course, tbat 
</p>
<p>a[ u"(t) + iv"(t) J + b[ u'(t) + iv'(t) J + c[ u(t) + iv(t) J =0. (2) 
Tbis complex-valued solution of (I) gives rise to two real-valued solutions, 
as we now sbow. 
</p>
<p>Lemma 1. Let y(t) = u(t) + iv(t) be a complex-valued solution of (1), with a, 
b, and c real. Then,y 1(t)=u(t) andYl(t)=v(t) are two real-valued solu-
</p>
<p>tions of (1). In other words, both the real and imaginary parts of a com-
</p>
<p>plex-valued solution of (1) are solutions of (1). (The imaginary part of the 
</p>
<p>complex number a + i&szlig; is &szlig;. Similarly, the imaginary part of the function 
u(t)+ iv(t) is v(t).) 
</p>
<p>PROOF. From Equation (2), 
</p>
<p>[ au"(t) + bu'(t) + cu( t) J + i[ av"(t) + bv'(t) + cv(t) J =0. (3) 
Now, if a complex nurober is zero, then bothitsreal and imaginary parts 
must be zero. Consequently, 
</p>
<p>au"(t)+bu'(t)+cu(t)=O and av"(t)+bv'(t)+cv(t)=O, 
</p>
<p>and tbis proves Lemma 1. 0 
</p>
<p>Tbe problern of defining e'1 for r complex can also be resolved quite 
easily. Let r = a + i&szlig;. By tbe law of exponents, 
</p>
<p>(4) 
</p>
<p>Tbus, we need only define the quantity ei&szlig;t, for &szlig; real. To tbis end, recall 
</p>
<p>141 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>that 
</p>
<p>x2 x3 
ex= 1+x+ 2! + 3! + .... (5) 
</p>
<p>Equation (5) makes sense, formally, even for x complex. This suggests that 
</p>
<p>we set 
</p>
<p>. (i&szlig;t)2 (i&szlig;t)3 
e&bull;&szlig;t = 1 +i&szlig;t+~+ 3! + .... 
</p>
<p>Next, observe that 
</p>
<p>. (i&szlig;t)2 . &szlig;2t2 i&szlig;3t3 &szlig;4t4 i&szlig;sts 
I+ z&szlig;t + ~ + ... = 1 + z&szlig;t- 2! - 3! + 4! + ----s! + &middot;. &middot; 
</p>
<p>[ 
&szlig;2t2 &szlig;4t4 ] &middot;[ &szlig;3t3 &szlig;sts ] 
</p>
<p>= 1- 2! + 4! + . . . + l &szlig;t- 3! + 5! + ... 
</p>
<p>=cos&szlig;t+ isin&szlig;t. 
</p>
<p>Hence, 
</p>
<p>e&lt;a+i&szlig;)t = eatei&szlig;t = eat (cos&szlig;t + i sin&szlig;t). 
</p>
<p>Returning to the differential equation (1), we see that 
</p>
<p>y ( t) = e[- b+ ;\/ 4ac- b2 ]t/2a 
</p>
<p>= e-bt/la[ cos V 4ac- b2 t j2a + i sin V 4ac- b2 t j2a] 
</p>
<p>(6) 
</p>
<p>is a complex-valued solution of (1) if b2 - 4ac is negative. Therefore, by 
Lemma 1, 
</p>
<p>&szlig;= V4ac-b 2 
2a 
</p>
<p>are two real-valued solutions of (1). These two functions are linearly inde-
</p>
<p>pendent on any interval /, since their Wronskian (see Exercise 10) is never 
</p>
<p>zero. Consequently, the genera1 solution of (1) for b2 - 4ac &lt; 0 is 
</p>
<p>&szlig;= V4ac-b 2 
2a 
</p>
<p>Remark 1. Strictly speaking, we must verify that the formula 
</p>
<p>.!i.e'1 = re'1 
dt 
</p>
<p>is true even for r complex, before we can assert that e'&bull;1 and e'21 are com-
</p>
<p>p1ex-valued solutions of (1). To this end, we compute 
</p>
<p>.!i.e&lt;a+ i&szlig;)t = .!i.ea1[ cos&szlig;t + i sin&szlig;t] 
dt dt 
</p>
<p>= ea&bull;[ (a cos&szlig;t- &szlig;sin&szlig;t) + i(a sin&szlig;t + &szlig;cos&szlig;t)] 
</p>
<p>142 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.2 Linear equations with constant coefficients 
</p>
<p>and this equals (a + i&szlig;)e&lt;a+i&szlig;&gt;1, since 
</p>
<p>( a + i&szlig; )e&lt;a+i&szlig;)l = ( a + i&szlig; )ea1[ cos&szlig;t + isin&szlig;t] 
</p>
<p>= ea1[ ( a cos&szlig;t- &szlig;sin&szlig;t) + i( a sin&szlig;t + &szlig;cos&szlig;t) ]. 
Thus, (d/ dt)e'1 = re'1, even for r complex. 
</p>
<p>Remark 2. At first glance, one might think that e'21 would give rise to two 
additional solutions of (1 ). This is not the case, though, since 
</p>
<p>e'21=e-(b/2a)le-i&szlig;l, &szlig;=Y4ac-b2 /2a 
</p>
<p>= e-bi/Za[ cos(- &szlig;t)+ isin(- &szlig;t) J = e-bi/Za[ cos&szlig;t- isin&szlig;t]. 
</p>
<p>Hence, 
</p>
<p>and 
Im{ e'21 } =- e-hi/Zasin&szlig;t=-Y2(t). 
</p>
<p>Example 1. Find two linearly independent real-valued solutions of the dif-
ferential equation 
</p>
<p>d2y dy 
4- +4- +5y=O. 
</p>
<p>dt2 dt 
(7) 
</p>
<p>Solution. The characteristic equation 4r2 + 4r + 5 = 0 has complex roots r1 
=- i + i and r2=- i- i. Consequently, 
</p>
<p>e'11 = e&lt;-I/Z+i)l = e- 112 cost + ie -l/2sint 
</p>
<p>is a complex-valued solution of (7). Therefore, by Lemma 1, 
</p>
<p>Re{ e''1 } = e-112cost and Im{ e''1 } = e-112sint 
are two linearly independent real-valued solutions of (7). 
</p>
<p>Example 2. Find the solution y(t) of the initial-value problern 
</p>
<p>d2y dy 
dtz +2 dt +4y=O; y(O)=I, y'(O)=I. 
</p>
<p>Solution. The characteristic equation r2 + 2r + 4 = 0 has complex roots r 1 = 
- 1 + V3 i and r2 = - 1- V3 i. Hence, 
</p>
<p>e''1 = e&lt; -I+ V3 i)l = e-1 cos V3 t + ie- 1 sin V3 t 
is a complex-valued solution of y" + 2y' + 4y = 0. Therefore, by Lemma 1, 
both 
</p>
<p>Re{ e''1 } = e- 1 cos V3 t and Im{ e'11 } = e- 1 sin V3 t 
</p>
<p>are real-valued solutions. Consequently, 
</p>
<p>y(t)=e- 1[c 1cosV3 t+c2 sinV3 t] 
</p>
<p>143 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>for some choice of constants c1,c2&bull; The constants c1 and c2 are determined 
from the initial conditions 
</p>
<p>l=y(O)=c 1 
and 
</p>
<p>1 = y'(O) = - c1 + v'3 c2. 
This implies that 
</p>
<p>c1=l,c2 = ...)J and y(t)=e-'[cosv'3t+ ...)J sinv'3tl 
</p>
<p>ExERCISEs 
</p>
<p>Find the general solution of each of the following equations. 
</p>
<p>d2y dy d2y dy 
1. dt2 + dt +y=O 2. 2 dt2 +3 dt +4y=O 
</p>
<p>d2y dy 
4. 4---+y=O 
</p>
<p>dt2 dt 
</p>
<p>Solve each of the following initial-value problems. 
</p>
<p>d2y dy 
5. dt2 + dt +2y=O; y(O)=l, y'(O)= -2 
</p>
<p>d2y dy 
6. - +2- +5y=O&middot; y(O)=O, y'(0)=2 
</p>
<p>dt2 dt ' 
</p>
<p>7. Assurne that b2 - 4ac &lt; 0. Show that 
Yt (t) = e&lt;- b/2a)(t-to) cos &szlig; (t- to) 
</p>
<p>and 
</p>
<p>Y2 (t) = e&lt;- bf2a)(t-to) sin&szlig; ( t- lo), 
</p>
<p>are solutions of (1), for any number t0&bull; 
</p>
<p>&szlig;= Y4ac-b 2 
2a 
</p>
<p>Solve each of the following initial-value problems. 
</p>
<p>d2y dy 
8. 2 dt2 - dt +3y=O; y(l)=l, y'(l)=l 
</p>
<p>d2y dy 
9. 3 dt2 -2 dt +4y=O; y(2)=1, y'(2)= -1 
</p>
<p>10. Verify that W[ea'cos&szlig;t, ea'sin&szlig;t]=&szlig;e2a1&bull; 
</p>
<p>11. Show that e;.,, is a complex-valued solution of the differential equation y" + 
w2y = 0. Find two real-valued solutions. 
</p>
<p>12. Show that (cost+isint)'=cosrt+isinrt. Use this result to obtain the double 
angle formulas sin2t=2sintcost and cos2t=cos2 t-sin2 t. 
</p>
<p>144 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.2 Linear equations with constant coefficients 
</p>
<p>13. Show that 
</p>
<p>( cos t 1 + i sin t 1 )( cos t2 + i sin t2) = cos( t 1 + t2) + i sin( t 1 + t2). 
</p>
<p>Use this result to obtain the trigonometric identities 
</p>
<p>cos(t1 + t2 ) = cost1 cost2 - sint1 sint2, 
</p>
<p>sin(t1 + t2) = sin t1 cost2 +cost 1 sint2&bull; 
</p>
<p>14. Show that any complex nurober a + ib can be written in the form Ae;9, where 
</p>
<p>A = V a2 + b2 and tan (} = b / a. 
15. Defining the two possible square roots of a complex nurober Ae;9 as 
</p>
<p>::!:: VA ei9f 2, compute the square roots of i, I+ i, - i, VI. 
</p>
<p>16. Use Problem 14 to find the three cube roots of i. 
</p>
<p>17. (a) Let r 1 =A. + ip. be a complex root of r2+(a -l)r+ &szlig;=O. Show that 
</p>
<p>t&gt;-+ip. = t&gt;-t;~' = t&gt;-e(ln r)ip. = t&gt;-[cos p. In t + i sin p. In t] 
</p>
<p>is a complex-valued solution of Euler's equation 
</p>
<p>d2y dy 
t2- +at- +&szlig;y=O. 
</p>
<p>dt2 dt 
</p>
<p>(b) Show that t&gt;-cosp.lnt and t&gt;-sinp.Int are real-valued solutions of (*). 
</p>
<p>Find the general solution of each of the following equations. 
</p>
<p>d2y dy 
18. P-2 +t-d +y=O, t&gt;O 
</p>
<p>dt t 
</p>
<p>d2y dy 
19. t2- 2 +2t-d +2y=O, t&gt;O 
</p>
<p>dt t 
</p>
<p>2.2.2 Equal roots; reduction of order 
</p>
<p>(*) 
</p>
<p>If b2 = 4ac, then the characteristic equation ar2 + br + c = 0 has real equal 
roots r 1 = r2 = - b j2a. In this case, we obtain only one solution 
</p>
<p>y,(t)=e-bt/Za 
</p>
<p>of the differential equation 
</p>
<p>dzy dy 
a- +b- +cy=O. 
</p>
<p>dt2 dt 
(!) 
</p>
<p>Our problern is to find a second solution which is independent of y 1&bull; One 
approach to this problern is to try sorne additional guesses. A second, and 
rnuch rnore clever approach is to try and use our knowledge of y 1{t) to help 
us find a second independent solution. More generally, suppose that we 
know one solution y = y 1{t) of the second-order linear equation 
</p>
<p>d2y dy 
L[y]= dtz +p(t) dt +q(t)y=O. (2) 
</p>
<p>Can we use this solution to help us find a second independent solution? 
</p>
<p>145 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>The answer to this question is yes. Once we find one solution y = y 1(1) of 
(2), we can reduce the problern of finding all solutions of (2) to that of 
solving a first-order linear homogeneaus equation. This is accomplished by 
defining a new dependent variable v through the substitution 
</p>
<p>y (I) = y 1 (I )v (I). 
</p>
<p>Then 
</p>
<p>and 
</p>
<p>since y 1(t) is a solution of L[y]=O. Hence, y(t)= y 1(t)v(t) is a solution of 
(2) if v satisfies the differential equation 
</p>
<p>d 2v [ dyl ] dv 
YI dt2 + 2dt +p(t)yl dt =0. (3) 
</p>
<p>Now, observe that Equation (3) is really a first-order linear equation for 
dv / dt. Its solution is 
</p>
<p>: ~cexp[- J[ 2 ~:i:~ +p(t) H 
= c exp ( - J p ( t) dt) exp [ - 2 J ~: ~ ~ ~ dt ] 
</p>
<p>cexp(- J p(t)dt) 
yi(t) 
</p>
<p>(4) 
</p>
<p>Since we only need one solution v(l) of (3), we set c =I in (4). Integrating 
this equation with respect tot, and setting the constant of integration equal 
</p>
<p>146 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.2 Linear equations with constant coefficients 
</p>
<p>to zero, we obtain that v(t)= J u(t)dt, where 
</p>
<p>Hence, 
</p>
<p>exp(- J p(t)dt) 
u(t)=-----
</p>
<p>Yi(t) 
</p>
<p>Y2(t)=v(t)y 1(t)=y 1(t) J u(t)dt 
</p>
<p>(5) 
</p>
<p>(6) 
</p>
<p>is a second solution of (2). This solution is independent of y" for if J2(1) 
were a constant multiple of y 1(t) then v(t) would be constant, and conse-
quently, its derivative would vanish identically. However, from (4) 
</p>
<p>dv exp(- J p(t)dt) 
dt = Yi(t) 
</p>
<p>and this quantity is never zero. 
</p>
<p>Remark 1. In writing v(t)= J u(t)dt, we set the constant of integration 
equal to zero. Choosing a nonzero constant of integration would only add 
a constant multiple of y 1(t) to y 2(t). Similarly, the effect of choosing a con-
stant c other than one in Equation (4) would be to multiply yit) by c. 
</p>
<p>Remark 2. The method we have just presented for solving Equation (2) is 
known as the method of reduction of order, since the Substitution y(t) = 
y 1(t)v(t) reduces the problern of solving the second-order equation (2) to 
that of solving a first-order equation. 
</p>
<p>Application to the case of equal roots: In the case of equal roots, we found 
y 1(t)=e-bt/Za as one solution of the equation 
</p>
<p>d2y dy 
a- +b- +cy=O. (7) 
</p>
<p>dt2 dt 
</p>
<p>We can find a second solution from Equations (5) and (6). lt is important 
to realize though, that Equations (5) and (6) were derived under the 
assumption that our differential equation was written in the form 
</p>
<p>d2y dy 
dt2 + p(t) dt + q(t)y =0; 
</p>
<p>that is, the coefficient of y" was one. In our equation, the coefficient of y" 
is a. Hence, we must divide Equation (7) by a to obtain the equivalent 
equation 
</p>
<p>d2y b dy c 
-+--+-y=O. 
dt2 a dt a 
</p>
<p>147 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>Now, we can insertp(t)=b/a into (5) to obtain that 
</p>
<p>exp(- J ~ dt) e-bt/a 
u(t)= =--=I. 
</p>
<p>[ e -bt/2a t e -bt/a 
Hence, 
</p>
<p>J2(1) = y 1 (t) f dt = ty 1 (t) 
is a second solution of (7). The functionsy 1(t) andyit) are clearly linearly 
independent on the interval - oo &lt; t &lt; oo. Therefore, the general solution 
of (7) in the case of equal roots is 
</p>
<p>y ( t) = c,e -bt/2a + c2te -bt/2a = [ c, + c2t Je -bt/2a 
</p>
<p>Example 1. Find the solution y(t) of the initial-value problern 
</p>
<p>d2y dy 
dt2 +4 dt +4y=O; y(O)= 1, y'(0)=3. 
</p>
<p>Solution. The characteristic equation r2 + 4r + 4 = (r + 2? = 0 has two equal 
roots r1 = r2 =- 2. Hence, 
</p>
<p>y(t) = c,e- 21 + c2te- 21 
</p>
<p>for sorne choice of constants c1, c2. The constants c1 and c2 are deterrnined 
frorn the initial conditions 
</p>
<p>1 = y(O)= c1 
and 
</p>
<p>3 = y'(O) = - 2c 1 + c2&bull; 
This irnplies that c1 = 1 and c2 = 5, so that y(t) = (1 + 5t)e- 21&bull; 
</p>
<p>Example 2. Find the solution y(t) of the initial-value problern 
</p>
<p>d2y dy 
(1-t2)-+2t--2y=O&middot; y(0)=3, y'(0)=-4 
</p>
<p>dt2 dt ' 
</p>
<p>on the interval - I &lt; t &lt; I. 
Solution. Clearly, y 1(t) = t is one solution of the differential equation 
</p>
<p>d2y dy 
(I-t2)-+2t--2y=O. (8) 
</p>
<p>dt2 dt 
</p>
<p>We will use the rnethod of reduction of order to find a second solution 
Yit) of (8). To this end, divide both sides of (8) by 1- t2 to obtain the 
equivalent equation 
</p>
<p>148 
</p>
<p>d 2y 2t dy 2 
-+------y=O 
dt2 I - 12 dt 1 - 12 . </p>
<p/>
</div>
<div class="page"><p/>
<p>2.2 Linear equations with constant coefficients 
</p>
<p>Then, from (5) 
</p>
<p>and 
</p>
<p>exp(- J 1 :tt2 dt) 
u(t)= ------
</p>
<p>yf(t) 
</p>
<p>y2(t)=tf 1 ~/ 2 dt=-t(++t)=-(l+t2) 
</p>
<p>js a second solution of (8). Therefore, 
</p>
<p>y(t)= c1t- c2 (1 + t 2) 
for some choice of constants c1, c2&bull; (Notice that all solutions of (9) are con-
tinuous at t = &plusmn; 1 even though the differential equation is not defined at 
these points. Thus, it does not necessarily follow that the so1utions of a dif-
ferential equation are discontinuous at a point where the differential equa-
tion is not defined-but this is often the case.) The constants c1 and c2 are 
determined from the initial conditions 
</p>
<p>3=y(O)= -c2 and -4=y'(O)=c1&bull; 
</p>
<p>Hence, y(t) = - 4t + 3(1 + t 2). 
</p>
<p>EXERCISES 
</p>
<p>Find the general solution of each of the following equations 
</p>
<p>d2y dy d2y dy 
1. dt2 -6 dt +9y=O 2. 4 dt2 -I2 dt +9y=O 
</p>
<p>Solve each of the following initial-value problems. 
</p>
<p>d2y dy 
3. 9-2 +6-d +y=O; y(O)=I, y'(O)=O 
</p>
<p>dt t 
</p>
<p>d2y dy 
4. 4 dt2 -4 dt +y=O; y(O)=O, y'(0)=3 
</p>
<p>5. Suppose b2 =4ac. Show that 
</p>
<p>Yl (t) = e-b(t-to)/2a and Y2(t) = (t- to)e-b(t-to)/2a 
</p>
<p>are soiutions of (I) for every choice of t0. 
</p>
<p>So1ve the following initia1-va1ue prob1ems. 
</p>
<p>d2y dy 
6. - 2 +2-d +y=O; y(2)= I, y'(2)= -I dt t 
</p>
<p>d2y dy 
7. 9 dP -I2 dt +4y=O; y(w)=O, y'(w)=2 
</p>
<p>8. Let a, b and c be positive numbers. Prove that every solution of the differential 
equation ay" + by' + cy =0 approaches zero as t approaches infinity. 
</p>
<p>149 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>9. Here is an alternate and very elegant way of finding a second solution Y2( t) of 
(I). 
(a) Assurne that b2 =4ac. Show that 
</p>
<p>L[ e''] = a( e'' )" + b( e'1 )' + ce'1 = a(r- r1) 2ert 
for r1 = - b l2a. 
</p>
<p>(b) Show that 
</p>
<p>(a I ar)L[ e'1 ] = L[ ( a I ar)e''] = L[te'1 ] = 2a(r- r,)ert + at(r- r,)2ert. 
</p>
<p>(c) Conclude from (a) and (b) that L[te'11]=0. Hence,yit)=te' 11 is a second 
solution of (1). 
</p>
<p>Use the method of reduction of order to find the general solution of the 
following differential equations. 
</p>
<p>2(t+ I) dy 2 
----"-----+ y=O (y1(1)=1+1) 
(12 +21-1) dl (12 +21-1) 
</p>
<p>d2y dy 
11. --41- +(412 -2)y=O (y 1(1)=e 12) 
</p>
<p>dl2 dl 
</p>
<p>d2y dy 
12. (1- 12) dl2 -21 dl + 2y =0 (y,(l) =I) 
</p>
<p>d2y dy 
13. (1+12)--21-+2y=O (y1(t)=l) 
</p>
<p>dl2 dl 
</p>
<p>d2y dy 
14. (1- 12)-2 -21-d +6y=O (y 1(1)=312 -l) 
</p>
<p>dl I 
</p>
<p>d2 dy 
15. (21+1)~ 2 -4(t+I)-d +4y=O (y1(1)=1+l) 
</p>
<p>dl t 
</p>
<p>d2 dy ( ) 16. 12 dt; +I dl +(12-i~=O y,(t)= ~~ 
</p>
<p>17. Given that the equation 
</p>
<p>d2y dy 
t dt2 -(1+31) dl +3y=O 
</p>
<p>has a solution of the form ect, for some constant c, find the generat solution. 
</p>
<p>18. (a) Show that t' is a solution of Euler's equation 
</p>
<p>Py"+ary'+&szlig;y=O, t&gt;O 
</p>
<p>if r 2+(a-l)r+ &szlig;=O. 
(b) Suppose that (a-li=4&szlig;. Using the method of reduction of order, show 
</p>
<p>that (In 1)1(1- a)/2 is a second solution of Euler's equation. 
</p>
<p>Find the general solution of each of the following equations. 
</p>
<p>d2y dy d2y dy 
19. t 2 - 2 +3t-d +y=O 20. 12--1- +y=O dt t dl2 dl 
</p>
<p>150 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.3 The nonhomogeneous equation 
</p>
<p>2.3 The nonhomogeneous equation 
</p>
<p>W e turn our attention now to the nonhomogeneaus equation 
</p>
<p>d2y dy 
L[y]= dtz +p(t) dt +q(t)y=g(t) (I) 
</p>
<p>where the functions p(t), q(t) and g(t) are continuous on an open interval 
a &lt; t &lt; &szlig;. An important clue as to the nature of all solutions of (I) is pro-
vided by the first-order linear equation 
</p>
<p>dy 
dt -2ty= -t. (2) 
</p>
<p>The general solution of this equation is 
</p>
<p>y ( t) = ce t2 + t . 
Now, observe that this solution is the sum of two terms: the first term, ce 12, 
is the general solution of the homogeneaus equation 
</p>
<p>: -2ty=O (3) 
</p>
<p>while the second term, t, is a solution of the nonhomogeneaus equation 
(2). In other words, every solution y ( t) of (2) is the sum of a particular 
solution, 1/;(t) = t, with a solution ce 12 of the homogeneaus equation. A sim-
ilar situation prevails in the case of second-order equations, as we now 
show. 
</p>
<p>Theorem 5. Let y 1(t) and Y2(t) be two linearly independent solutions of the 
homogeneaus equation 
</p>
<p>d2y dy 
L[y] = - 2 +p(t)-d +q(t)y=O 
</p>
<p>dt t 
(4) 
</p>
<p>and Iet IJ;(t) be any particular solution of the nonhomogeneaus equation (1). 
Then, every so/ution y(t) of (I) must be of the form 
</p>
<p>y(t) = C1y 1 (t) + CzYz(t) + 1/J(t) 
for some choice of constants c1, c2&bull; 
</p>
<p>The proof of Theorem 5 relies heavily on the following Iemma. 
</p>
<p>Lemma 1. The difference of any two so/utions of the nonhomogeneaus equa-
tion (1) is a solution of the homogeneaus equation (4). 
</p>
<p>PROOF. Let l/;1(t) and 1/;2(1) be two solutions of (1). By the linearity of L, 
</p>
<p>L[ 1/11 - 1/12 ]( t) = L[ 1/11 J ( t)- L[ 1/12 ] ( t) = g( t)- g( t) = 0. 
Hence, 1/;1 ( t)- IJ;z( t) is a solution of the homogeneaus equation ( 4). 0 
</p>
<p>151 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>We can now give a very simple proof of Theorem 5. 
</p>
<p>PROOF OF THEOREM 5. Let y(t) be any solution of (1). By Lemma l, the 
function &lt;j&gt;(t)=y(t)-l[;(t) is a solution of the homogeneous equation (4). 
But every solution &lt;j&gt;(t) of the homogeneous equation (4) is of the form 
&lt;t&gt;(t) = c1y 1(t) + c2yit), for some choice of constants c1, c2&bull; Therefore, 
</p>
<p>y( t) =&lt;t&gt;( t) + 1/;(t) = c1 y 1 ( t) + c2y 2 ( t) + 1/;( t). 0 
</p>
<p>Remark. Theorem 5 is an extremely useful theorem since it reduces the 
problern of finding all solutions of (1) to the much simpler problern of find-
ing just two solutions of the homogeneous equation (4), and one solution 
of the nonhomogeneous equation (1). 
</p>
<p>Example 1. Find the general solution of the equation 
</p>
<p>d2y 
-+y=t. 
dt2 
</p>
<p>(5) 
</p>
<p>Solution. The functionsy 1(t)=cost andYz(t)=sint are two linearly inde-
pendent solutions of the homogeneous equation y" + y = 0. Moreover, 1/;(t) 
= t is obviously a particular solution of (5). Therefore, by Theorem 5, 
every solution y(t) of (5) must be of the form 
</p>
<p>y ( t) = c1 cos t + c2 sin t + t. 
</p>
<p>Example 2. Three solutions of a certain second-order nonhomogeneous 
linear equation are 
</p>
<p>t/;2 ( t) = t + e 1, and 1[;3 ( t) = 1 + t + e 1&bull; 
Find the general solution of this equation. 
Solution. By Lemma I, the functions 
</p>
<p>t/;2(t)-tf;1(t)=e 1 and t/;3(t)-t/;2(t)= 1 
</p>
<p>are solutions of the corresponding homogeneous equation. Moreover, these 
functions are obviously linearly independent. Therefore, by Theorem 5. 
every solution y(t) of this equation must be of the form 
</p>
<p>y(t) = c1e 1 + c2 + t. 
</p>
<p>ExERCISES 
</p>
<p>1. Three solutions of a certain second-order nonhomogeneaus linear equation an: 
</p>
<p>1/;, (t) = t2, t/;2 (t) = t2 + e2t 
and 
</p>
<p>tf;3 (t)= I+ t2+2e21 &bull; 
</p>
<p>Find the general solution of this equalic:1. 
</p>
<p>152 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.4 The method of variation of parameters 
</p>
<p>2. Three solutions of a certain second-order linear nonhomogeneaus equation are 
</p>
<p>1); 1 (t) = l + e 12, 1);2(t) = l + te 12 
</p>
<p>and 
</p>
<p>1);3 ( t) = ( t + I)e 12 + l 
Find the general solution of this equaHon. 
</p>
<p>3. Three solutions of a second-order linear equation L[y] = g(t) are 
</p>
<p>1); 1 (t) = 3e1 + e 12, 1);2(t) =7e1 + e 12 
</p>
<p>and 
</p>
<p>1);3(t) =Se,+ e-t' + et2. 
</p>
<p>Find the solution of the initial-value problern 
</p>
<p>L[y]=g; y(O)= l, y'(0)=2. 
</p>
<p>4. Let a, b and c be positive constants. Show that the difference of any two solu-
tions of the equation 
</p>
<p>ay" + by' + cy = g(t) 
</p>
<p>approaches zero as t approaches infinity. 
</p>
<p>5. Let l);(t) be a solution of the nonhomogeneaus equation (!), and Iet q,(t) be a 
solution of the homogeneaus equation (4). Show that l);(t)+&lt;/&gt;(t) is again a solu-
tion of (!). 
</p>
<p>2.4 The method of variation of parameters 
</p>
<p>In this section we describe a very general method for finding a particular 
solution 1/;(t) of the nonhomogeneaus equation 
</p>
<p>d 2y dy 
L[y]= dt1 +p(t) dt +q(t)y=g(t), (I) 
</p>
<p>once the solutions of the homogeneaus equation 
</p>
<p>d1y dy 
L[y] =- +p(t)-d +q(t)y=O 
</p>
<p>dt 2 t 
(2) 
</p>
<p>are known. The basic principle of this method is to use our knowledge of 
the solutions of the homogeneaus equation to help us find a solution of the 
nonhomogeneaus equation. 
</p>
<p>Lety1(t) andyit) be two linearly independent solutions of the homoge-
neaus equation (2). We will try to find a particular solution lf;(t) of the 
nonhomogeneaus equation (I) of the form 
</p>
<p>1/;(t) = u1(t)y 1(t) + u2(t)yit); (3) 
that is, we will try to find functions u1(t) and uit) so that the linear combi-
nation u1(t)y 1(t) + uit)yit) is a solution of (1). At first glance, this 
</p>
<p>153 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>would appear to be a dumb thing to do, since we are replacing the problern 
of finding one unknown function 1/;(t) by the seemingly barder problern of 
finding two unknown functions u1(t) and u2(t). However, by playing our 
cards right, we will be able to find u1(t) and uit) as the solutions of two 
very simple first-order equations. We accomplish this in the following 
manner. Observe that the differential equation (1) imposes only one condi-
tion on the two unknown functions u1(t) and uit). Therefore, we have a 
certain "freedom" in choosing u1(t) and u2(t). Our goal is to impose an 
additional condition on u1(t) and uit) which will make the expression 
L[u1y 1 + u2h] as simple as possible. Computing 
</p>
<p>d d 
dt!J;(t)= dt [utYt+u2h] 
</p>
<p>= [ UtYi + U2Y2] + [ u;yl + u2h] 
we see that d21/; j dt2, and consequently L[ 1/;], will contain no second-order 
derivatives of u 1 and u2 if 
</p>
<p>Y1 (t)u; (t)+ h(t)u2(t) =0. (4) 
</p>
<p>This suggests that we impose the condition (4) on the functions u1(t) and 
ui t). In this case, then, 
</p>
<p>L[ 1/1] = [ UtYi + u2y2J' + p(t)[ UtYi + u2y2] + q( t)[ UtYt + U2Y2J 
= u;y; + u2y2 + u1 [ y;' + p(t)y; + q(t)y 1 ] + u2 [ y{ + p(t)y2+ q(t)h] 
</p>
<p>= u;y; + u2y2 
</p>
<p>since both y 1(t) and yit) are solutions of the homogeneous equation L[y] 
=0. Consequently, 1/;(t)= u1y 1 + u2 y 2 is a solution of the nonhomogeneous 
equation (1) if u1(t) and u2(t) satisfy the two equations 
</p>
<p>Y1 (t)u; (t) + Y2 ( t)u2 ( t) = 0 
y; (t)u; (t) + Y2(t)u2(t) = g(t). 
</p>
<p>Multiplying the first equation by y2(t), the second equation by h(t), and 
subtracting gives 
</p>
<p>[y 1 (t)y2(t)- y; (t)y2(t) ]u; (t)=- g(t)y2(t), 
</p>
<p>while multiplying the first equation by y;(t), the second equation by y 1(t), 
and subtracting gives 
</p>
<p>Hence, 
</p>
<p>[ Y1 ( t)y2( t)-Yi (t)h( t) ]u2 (t) = g( t)y 1 ( t). 
</p>
<p>g(t)y2(t) 
u;(t)=-----
</p>
<p>W[yt,h](t) 
d '() g(t)yl(t) an u2 t = -=-----
</p>
<p>W[Yt&middot;h](t) 
(5) 
</p>
<p>Finally, we obtain u1(t) and uit) by integrating the right-hand sides of (5). 
</p>
<p>154 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.4 The method of variation of parameters 
</p>
<p>Remark. The general solution of the homogeneous equation (2) is 
</p>
<p>y(t)= c1y 1 (t)+ c2Y2(t). 
</p>
<p>By letting c1 and c2 vary with time, we obtain a solution of the nonhomo-
geneous equation. Hence, this method is known as the method of variation 
of parameters. 
</p>
<p>Example 1. 
</p>
<p>(a) Find a particular solution 1/;( t) of the equation 
</p>
<p>d2y 
-+y=tant 
dt2 
</p>
<p>{6) 
</p>
<p>on the interval - 1r /2 &lt; t &lt; 1r /2. 
(b) Find the solutiony(t) of (6) which satisfies the initial conditionsy(O)= 
l,y'(O)=l. 
Solution. 
(a) The functions y 1(t) = cos t and yit) = sin t are two linearly independent 
solutions of the homogeneous equation y" + y = 0 with 
</p>
<p>W[ YPY2] ( t) = y 1A- y; h = ( cost)cos t- (- sin t)sint = l. 
Thus, from (5), 
</p>
<p>u; ( t) = - tan t sin t and u; ( t) = tan t cos t. 
Integrating the first equation of (7) gives 
</p>
<p>f . J sin2 t u1(t)=- tantsmtdt=- --dt cost 
= J cos2 1- 1 dt = sint -lnlsect + tantl. 
</p>
<p>cost 
</p>
<p>=sint -ln(sect+tant), -I&lt; t &lt;I 
while integrating the second equation of (7) gives 
</p>
<p>u2 (t)= Jtantcostdt= Jsintdt= -cost. 
</p>
<p>Consequently, 
</p>
<p>1/; ( t) = cos t [ sin t - ln (sec t + tan t) J + sin t ( - cos t) 
= -costln(sect+tant) 
</p>
<p>is a particular solution of (6) on the interval - 1r /2 &lt; t &lt; 1r /2. 
(b) By Theorem 5 of Section 2.3, 
</p>
<p>y ( t) = c 1 cos t + c 2 sin t- cos t ln( sec t + tan t) 
</p>
<p>(7) 
</p>
<p>for some choice of constants c1, c2 &bull; The constants c1 and c2 are determined 
from the initial conditions 
</p>
<p>l=y(O)=c1 and l=y'(O)=c2 -l. 
</p>
<p>155 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>Hence, c1 = 1, c2 =2 and 
</p>
<p>y(t) = cos t + 2sint- cost ln(sect + tant). 
</p>
<p>Remark. Equation (5) determines u1(t) and u2(t) up to two constants of in-
tegration. We usually take these constants to be zero, since the effect of 
choosing nonzero constants is to add a solution of the homogeneaus equa-
tion to 1/;(t). 
</p>
<p>EXERCISES 
</p>
<p>Find the general solution of each of the following equations. 
</p>
<p>d2y 
1. -+y=sect -"!...&lt;t&lt;"!... 
</p>
<p>dt2 ' 2 2 
</p>
<p>d2y dy 21 
2. - - 4- + 4y = te 
</p>
<p>dt2 dt 
</p>
<p>d 2y dy 
3. 2-2 -3-d +y=(t2+1)e 1 dt t 
</p>
<p>d2y dy 3t 
4. - - 3- + 2y = te + 1 
</p>
<p>dt2 dt 
</p>
<p>Salve each of the following initial-value problems. 
</p>
<p>5. 3y"+4y'+y=(sint)e- 1; y(O)=l, y'(O)=O 
</p>
<p>6. y"+4y'+4y=t512e- 21 ; y(O)=y'(O)=O 
</p>
<p>7. y" -3y' +2y = v'f+T; y(O)= y'(O)=O 
</p>
<p>8. y"-y=j(t); y(O)=y'(O)=O 
</p>
<p>Warning. lt must be remembered, while doing Problems 3 and 5, that 
Equation (5) was derived under the assumption that the coefficient of y" 
was one. 
</p>
<p>9. Find two linearly independent solutions of t2y"- 2y = 0 of the form y(t) = t'. 
Using these solutions, find the general solution of t2y"- 2y = t2&bull; 
</p>
<p>10. One solution of the equation 
</p>
<p>y" + p(t)y' + q(t)y =0 
</p>
<p>is (1 + t)2, and the Wronskian of any two solutions of (*) is constant. Find the 
general solution of 
</p>
<p>y" +p(t)y' + q(t)y = 1+ t. 
</p>
<p>11. Find the general solution ofy"+(lj4t2)y=fcost, t&gt;O, given thaty 1(t)=Yt 
is a solution of the homogeneous equation. 
</p>
<p>156 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.5 The method of judicious guessing 
</p>
<p>12. Find the general solution of the equation 
</p>
<p>d 2y 21 dy 2 2 
-----+--y=l+l. 
d12 I + 12 dl I + 12 
</p>
<p>13. Show that sec I+ tanl is positive for - 'lT /2 &lt;I&lt; 'lT /2. 
</p>
<p>2.5 The method of judicious guessing 
</p>
<p>A serious disadvantage of the method of variation of parametersisthat the 
integrations required are often quite difficult. In certain cases, it is usually 
much simpler to guess a particular solution. In this section we will establish 
a systematic method for guessing solutions of the equation 
</p>
<p>d2y dy 
a...::- +b- +cy=g(t) 
</p>
<p>dt2 dt 
(I) 
</p>
<p>where a, b and c are constants, and g( t) has one of several special forms. 
Consider first the differential equation 
</p>
<p>d2y dy n 
L[y] =a dt2 +b dt +cy=a0 +a1t+ ... +ant . (2) 
</p>
<p>We seek a function l[;(t) suchthat the three functions al[;", bl[;' and cl[; add 
up to a given polynomial of degree n. The obvious choice for l[;(t) is a 
polynomial of degree n. Thus, we set 
</p>
<p>and compute 
</p>
<p>L[ l[; ]( t) = al[;"( t) + bl[;'( t) + cl[;( t) 
= a[2A2 + ... + n(n-l)Antn-2] + b[ A 1 + ... + nAntn-l] 
</p>
<p>+c[A 0 +A 1t+ ... +Antn] 
</p>
<p>= cAntn + ( cAn-1 + nbAn)tn-l + ... + ( cAo + bA I+ 2aA2). 
</p>
<p>Equating coefficients of like powers of t in the equation 
</p>
<p>L [ l[;] ( t) = a0 + a 1 t + ... + an t n 
gives 
</p>
<p>(3) 
</p>
<p>cAn =an, cAn-l + nbAn =an- I" .. ,cA 0 + bA 1 + 2aA 2 = a0 . (4) 
</p>
<p>The first equation determines An= an/ c, for c=FO, and the remaining equa-
tions then determine An-I&gt; ... ,A0 successively. Thus, Equation (I) has a 
particular solution l[;( t) of the form (3), for c =F 0. 
</p>
<p>We run into trouble when c = 0, since then the first equation of ( 4) has 
no solution An. This difficulty is to be expected though, for if c = 0, then 
L[ l[;] = al[;" + bl[;' is a polynomial of degree n- I, while the right hand side 
</p>
<p>157 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>of (2) is a polynomial of degree n. To guarantee that alf;" + blf;' is a poly-
nomial of degree n, we must take 1/; as a polynomial of degree n + 1. Thus, 
we set 
</p>
<p>(5) 
</p>
<p>Wehave omitted the constant term in (5) since y = constant is a solution of 
the homogeneous equation ay n + by' = 0, and thus can be subtracted from 
1/;( t). The coefficients A 0, A 1, ... ,An are determined uniquely (see Exercise 
19) from the equation 
</p>
<p>if b=FO. 
Finally, the case b = c = 0 is trivial to handle since the differential equa-
</p>
<p>tion (2) can then be integrated immediately to yield a particular solution 
1/;( t) of the form 
</p>
<p>1 [ a 12 a 13 a 1 n + 2 l 
1/1( 1)= a 1~2 + 21&middot;3 + ... + (n+ ;)(n+2) . 
</p>
<p>Summary. The differential equation (2) has a solution 1/;(t) of the form 
</p>
<p>{
</p>
<p>Ao+A 1t+ ... +Antn, 
</p>
<p>1/;(t)= t(A 0 +A 1t+ ... +Antn), 
</p>
<p>12 (A 0 +A 1t+ ... +Antn), 
</p>
<p>c=FO 
</p>
<p>c=O, b=FO. 
</p>
<p>c=b=O 
</p>
<p>Example 1. Find a particular solution lf;(t) of the equation 
</p>
<p>d2 y dy 2 
L [ y J = dt 2 + dt + y = t . 
</p>
<p>Solution. We set lf;(t)=A 0 +A 1t+A 2t2 and compute 
</p>
<p>L[ lf; ](t)=lf;"(t)+lf;'(t)+lf;(t) 
</p>
<p>=2A 2 + (A 1 + 2A 2t) + A 0 + A 1t + A 2t2 
</p>
<p>= (A 0 + A 1 + 2A 2 ) + (A 1 + 2A 2 )t + A 2 t2 . 
</p>
<p>(6) 
</p>
<p>Equating coefficients of like powers of t in the equation L[ lf; ]( t) = t2 gives 
</p>
<p>A 2 = 1, A 1 +2A 2 =0 
</p>
<p>and 
</p>
<p>A 0 + A 1 +2A 2 =0. 
</p>
<p>The first equation tells us that A 2 = I, the second equation then tells us that 
A 1 = -2, and the third equation then tells us that A 0 = 0. Hence, 
</p>
<p>lf;(t)=-2t+t 2 
</p>
<p>is a particular solution of (6). 
</p>
<p>158 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.5 The method of judicious guessing 
</p>
<p>Let us now re-do this problern using the rnethod of variation of pararne-
ters. lt is easily verified that 
</p>
<p>y 1(t)=e- 112 cosV3 t/2 and Y2(t)=e- 112 sinV3 t/2 
</p>
<p>are two solutions of the hornogeneous equation L[y] = 0. Hence, 
</p>
<p>1[;( t) = u1 ( t)e -t12cos V3 t /2 + u2 ( t)e -t/2 sin V3 t /2 
</p>
<p>is a particular solution of (6), where 
</p>
<p>- t2e- 112 sin V3 t/2 -2 
u1 (t) = J dt= -- Jt 2e 112 sin V3 t/2dt 
</p>
<p>W[y 1,h](t) V3 
</p>
<p>and 
</p>
<p>These integrations are extrernely difficult to perforrn. Thus, the rnethod of 
guessing is certainly preferrable, in this problern at least, to the rnethod of 
variation of pararneters. 
</p>
<p>Consider now the differential equation 
</p>
<p>L[ ] d
2y b dy ( n) at Y =a-2 + -d +cy= a0 +a1t+ ... +ant e . dt t 
</p>
<p>(7) 
</p>
<p>We would like to rernove the factor ea1 frorn the right-hand side of (7), so 
as to reduce this equation to Equation (2). This is accornplished by setting 
y(t)= ea1v(t). Then, 
</p>
<p>y'= eat (v' + av) and y" = eat (v" +2av' + a2v) 
</p>
<p>so that 
</p>
<p>L[y J = eaT av" + (2aa + b)v' +(aa 2 + ba+ c)v]. 
</p>
<p>Consequently, y(t) = ea1v(t) is a solution of (7) if, and only if, 
</p>
<p>d 2v dv 2 
a dt2 +(2aa+b) dt +(aa +ba+c)v=a0 +a1t+ ... +antn. (8) 
</p>
<p>In finding a particular solution v(t) of (8), we rnust distinguish as to 
whether (i) aa2 +ba+c*O; (ii) aa 2 +ba+c=O, but 2aa+b*O; and (iii) 
both aa 2 + ba + c and 2aa + b = 0. The first case rneans that a is not a root 
of the characteristic equation 
</p>
<p>ar2 + br + c = 0. (9) 
In other words, ea1 is not a solution of the hornogeneous equation L[y] = 0. 
The second condition rneans that a is a single root of the characteristic 
equation (9). This irnplies that ea1 is a solution of the hornogeneous equa-
tion, but teat is not. Finally, the third condition rneans that a is a double 
</p>
<p>159 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>root of the characteristic equation (9), so that both ea1 and 1ea1 are solu-
</p>
<p>tions of the homogeneous equation. Hence, Equation (7) has a particular 
</p>
<p>solution 1/;(t) of the form (i) l/;(t)=(A0+ ... +Anln)ea1, if ea1 is not a solu-
tion of the homogeneous equation; (ii) I/;(1)=1(A 0 + ... +Anln)ea1, if ea1 is 
</p>
<p>a solution of the homogeneous equation but le at is not; and (iii) 1/;( t) = 
</p>
<p>12(A 0 + ... +Anln)ea1 if both ea1 and lea1 are solutions of the homogeneous 
</p>
<p>equation. 
</p>
<p>Remark. There are two ways of computing a particular solution 1/;(t) of (7). 
</p>
<p>Either we make the substitutiony = ea'v and find v(l) from (8), or we guess 
</p>
<p>a solution 1/;(t) of the form ea' times a suitable polynomial in 1. If a is a 
</p>
<p>double root of the characteristic equation (9), or if n &gt; 2, then it is advis-
able to set y = ea1v and then find v(l) from (8). Otherwise, we guess 1/;(t) 
</p>
<p>directly. 
</p>
<p>Example 2. Find the general solution of the equation 
</p>
<p>d2 dy 
; -4-d +4y=(l+t+ ... +t27)e21. 
</p>
<p>dt t 
(10) 
</p>
<p>Solution. The characteristic equation r2 -4r+4=0 has equal roots r1=r2 
= 2. Hence, y 1 ( t) = e21 and Y2( I)= te21 are solutions of the homogeneous 
equationy" -4y' +4y =0. To find a particular solution 1/;(1) of (10), we set 
</p>
<p>y = e21v. Then, of necessity, 
</p>
<p>d2~ = 1 + t + 12 + ... + (27. 
dl 
</p>
<p>Integrating this equation twice, and setting the constants of integration 
</p>
<p>equa1 to zero gives 
12 (3 129 
</p>
<p>v(t)= 1&middot;2 + 2&middot;3 + ... + 28&middot;29 &middot; 
</p>
<p>Hence, the general solution of (10) is 
</p>
<p>21 21 21[ 12 129 ] y(t)=c 1e +c2te +e N+ ... + 28 .29 
</p>
<p>[ 
t2 129 ] 
</p>
<p>= e2' Ct + c2t + N + ... + 28.29 . 
</p>
<p>lt would be sheer madness (and a terrible waste of paper) to plug the ex-
</p>
<p>pression 
l/;(t)=t2(Ao+Att+ ... +A27t27)e2' 
</p>
<p>into (10) and then solve for the coefficients A0, A 1, ... ,A21&bull; 
</p>
<p>Example 3. Find a particular solution 1/;(t) of the equation 
</p>
<p>d2y dy 
L[y]= dt2 -3 dt +2y=(l+t)e3'. 
</p>
<p>160 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.5 The method of judicious guessing 
</p>
<p>Solution. In this case, e31 is not a solution of the homogeneous equation 
y"- 3y' + 2y =0. Thus, we set tJ;(t)=(A 0 + A 1t)e 31&bull; Computing 
</p>
<p>L[t/J](t)=tJ;"-31/;'+21/; 
</p>
<p>= e3'[ (9A 0 +6A 1 +9A 1t)- 3(3A 0 + A 1 +3A 1t) + 2(A 0 + A 1t) J 
= e3'[ (2A 0 +3Ad + 2A 1t] 
</p>
<p>and cancelling off the factor e31 from both sides of the equation 
</p>
<p>L[ tJ; ](t)= (I+ t)e 31 , 
</p>
<p>gives 
</p>
<p>2A 1t + (2A 0 + 3A 1) = 1 + t. 
This implies that 2A 1 =1 and 2A 0 +3A 1=1. Hence, A 1=i, A 0 =-~ and 
</p>
<p>1/;(t)=(- i + t/2)e 31 &bull; 
Finally, we consider the differential equation 
</p>
<p>[ ] _ d
2y bdy -( n) { coswt L y -a-2 + -d +cy- a0 +a1t+ ... +an! X . . 
</p>
<p>~ t ~~ 
(I I) 
</p>
<p>We can reduce the problern of finding a particular solution 1/;(t) of (11) to 
the simpler problern of finding a particular solution of (7) with the aid of 
the following simple but extremely useful Iemma. 
</p>
<p>Lemma 1. Let y(t)=u(t)+iv(t) be a complex-valued solution of the equa-
tion 
</p>
<p>d2y dy 
L[y]=a dt2 +b dt +cy=g(t)=g1(t)+ig2 (t) (12) 
</p>
<p>where a, band c are real. This means, of course, that 
</p>
<p>a[ u"(t) + iv"(t) J + b[ u'(t) + iv'(t) J + c[ u(t) + iv(t) J = g1 (t) + ig2(t). 
(13) 
</p>
<p>Then, L[u](t)=g1(t) and L[v](t)=git). 
</p>
<p>PRooF. Equating real and imaginary parts in (13) gives 
</p>
<p>au"(t) + bu'(t) + cu(t) = g1 (t) 
and 
</p>
<p>av"(t) + bv'(t) + cv(t) = g2 (t). 
</p>
<p>Now, Iet cp(t)=u(t)+iv(t) be a particular solution of the equation 
</p>
<p>d2 dy 
a~ +b-d +cy=(ao+ ... +antn)eiwt. 
</p>
<p>dt t 
</p>
<p>D 
</p>
<p>(14) 
</p>
<p>The real part of the right-hand side of (14) is (a0 + ... + antn)coswt, while 
</p>
<p>161 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>the imaginary part is (a0 + ... +antn)sinwt. Hence, by Lemma I 
</p>
<p>u(t)=Re{cj&gt;(t)} 
</p>
<p>is a solution of 
</p>
<p>while 
</p>
<p>v(t)=lm{cj&gt;(t)} 
</p>
<p>is a solution of 
</p>
<p>Example 4. Find a particular solution l{;(t) of the equation 
</p>
<p>d2y 
L[y] = - 2 +4y=sin2t. 
</p>
<p>dt 
(15) 
</p>
<p>Solution. We will find l{;(t) as the imaginary part of a complex-valued solu-
tion cj&gt;( t) of the equation 
</p>
<p>d2y 
L [ y J = - + 4y = e2u. ( 16) 
</p>
<p>dt2 
</p>
<p>Tothis end, observe that the characteristic equation r 2 +4=0 has complex 
roots r= &plusmn;2i. Therefore, Equation (16) has a particular solution cj&gt;(t) of the 
form cj&gt;(t) = A 0te2u. Computing 
</p>
<p>cj&gt;'(t)=A 0 (1+2it)e2;1 and cj&gt;"(t)=A 0 (4i-4t)e2;1 
</p>
<p>we see that 
</p>
<p>L[ cj&gt; J(t) = cj&gt;"( t) + 4cj&gt;( t) =4iA 0e2;1&bull; 
</p>
<p>Hence, A0 = 1/4i= -i/4 and 
</p>
<p>cj&gt;(t) =- *e2;1 =- *(cos2t + isin2t) = &plusmn; sin2t- i&plusmn; cos2t. 
Therefore, I{;( t) =Im { cj&gt;( t)} = - (t / 4) cos 2t is a particular solution of ( 15). 
</p>
<p>Example 5. Find a particular solution l{;(t) of the equation 
</p>
<p>d2y 
- +4y=cos2t. 
dt2 
</p>
<p>(17) 
</p>
<p>Solution. From Example 4, cj&gt;(t)=(t/4)sin2t-i(t/4)cos2t is a complex-
valued solution of (16). Therefore, 
</p>
<p>l{;(t) =Re{ cj&gt;(t)} = &plusmn; sin2t 
is a particular solution of (17). 
</p>
<p>162 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.5 The method of judicious guessing 
</p>
<p>Example 6. Find a particular solution "'(t) of the equation 
</p>
<p>d 2y dy 
L[y] =-+2- +y=te 1cost. 
</p>
<p>dt2 dt 
(18) 
</p>
<p>Solution. Observe that te 1 cost is the real part of te&lt;l+i)t. Therefore, we can 
find l[;(t) as the real part of a complex-valued solution cp(t) of the equation 
</p>
<p>d2y dy 
L[y]=-+2-+y=te&lt;l+i)t. (19) 
</p>
<p>dt2 dt 
</p>
<p>To this end, observe that 1 + i is not a root of the characteristic equation 
r2 + 2r + 1 = 0. Therefore, Equation (19) has a particular solution cp(t) of the 
form cp(t)=(A0 +A 1t)e(l+i)t. Computing L[cp]=cp"+2cp'+cp, and using the 
identity 
</p>
<p>( 1 + i)2 + 2( 1 + i) + 1 = [ ( 1 + i) + 1 t = (2 + i)2 
we see that 
</p>
<p>[ (2+ i)2 A 1t + (2+ i)2 A 0 + 2(2+ i)A 1 J = t. 
Equating coefficients of 1ike powers of t in this equation gives 
</p>
<p>and 
</p>
<p>(2 + i)A0 + 2A 1 =0. 
</p>
<p>This imp1ies that A 1 = 1 /(2 + i)2 and A 0=- 2/(2 + i)3, so that 
</p>
<p>cp(t)= [ -2 + t ]eo+nt. 
(2+i)3 (2+i)2 
</p>
<p>After a 1itt1e a1gebra, we find that 
</p>
<p>et J cp(t)= 125 {[(15t-4)cost+(20t-22)sint 
</p>
<p>+ i[ (22- 20t)cost + (15t- 4)sint J}. 
</p>
<p>Hence, 
</p>
<p>et 
"'(t)=Re{ cp(t)} = 125 [ (15t-4)cost+ (20t-22)sint]. 
</p>
<p>Remark. The method of judicious guessing also applies to the equation 
</p>
<p>d2y dy n 
L[y]=adt2 +b dt +cy= ~ Pj(t)eaJt 
</p>
<p>j=l 
</p>
<p>(20) 
</p>
<p>where the Pit),j= I, ... ,n are po1ynomia1s in t. Let tf;/t) be a particu1ar 
</p>
<p>163 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>solution of the equation 
</p>
<p>j= l, ... ,n. 
</p>
<p>Then, ~{t) = ~J= 1 ~/t) is a solution of (20) since 
</p>
<p>L[ ~ J = L[ 1 ~ 1 ~J l = 1 ~ 1 L[ ~ 1 ] = 1 ~ 1 PJ(t)eaJr. 
Thus, to find a particular solution of the equation 
</p>
<p>y" + y' + y = e 1 + t sin t 
</p>
<p>we find particular solutions ~ 1 (t) and ~it) of the equations 
</p>
<p>y"+y'+y=e 1 and y"+y'+y=tsint 
</p>
<p>respectively, and then add these two solutions together. 
</p>
<p>EXERCISES 
</p>
<p>Find a particular solution of each of the following equations. 
</p>
<p>1. y"+3y=t3-l 2. y"+4y'+4y=tea1 
</p>
<p>5. y"+2y'+y=e- 1 
</p>
<p>7. y"+4y=tsin2t 
</p>
<p>4. y" + y' + y = 1 + t + t2 
</p>
<p>6. y"+5y'+4y=t2e71 
</p>
<p>8. y"- 6y' + 9y = (3t 7 - 5t4)e31 
</p>
<p>10. y"-2y'+5y=2(cos 2t)e 1 9. y"-2y'+5y=2cos2 t 
</p>
<p>11. y"+y'-6y=sint+te21 
</p>
<p>13. y"-3y'+2y=e 1+e21 
</p>
<p>12. y" + y' +4y = t 2 +(2t+ 3)(1 +cost) 
</p>
<p>14. y"+2y'=1+t2+e- 21 
</p>
<p>15. y" + y = cos t cos2t 16. y" + y = cos t cos2t cos3t. 
</p>
<p>17. (a) Show that cos3wt = iRe{ e3iwr + 3e;"'1}. 
</p>
<p>Hint: coswt=(e;"'1+e-;"'1)j2. 
(b) Find a particular solution of the equation 
</p>
<p>10y" +0.2y' + 1000y =5 + 20cos3 10t 
</p>
<p>18. (a) Let L[y]=y"-2r1y'+r12y. Show that 
</p>
<p>L[ e' 11v(t)] = e' 11v"(t). 
(b) Find the general solution of the equation 
</p>
<p>y" _ 6y' + 9y = t3f2e3r. 
</p>
<p>19. Let 1/;(t) = t(A 0 + ... + Antn), and assume that b o;60. Show that the equation 
al/;" + blf;' = a0 + ... + antn determines A 0, &bull;&bull;&bull; ,An uniquely. 
</p>
<p>164 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.6 Mechanical vibrations 
</p>
<p>2.6 Mechanical vibrations 
</p>
<p>Consider the case where a small object of mass m is attached to an elastic 
spring of length /, which is suspended from a rigid horizontal support (see 
Figure 1). (An elastic spring has the property that if it is stretched or com-
pressed a distance M which is small compared to its naturallength /, then 
it will exert a restering force of magnitude kM. The constant k is called 
the spring-constant, and is a measure of the stiffness of the spring.) In 
addition, the mass and spring may be immersed in a medium, such as oil, 
which impedes the motion of an object through it. Engineers usually refer 
to such systems as spring-mass-dashpot systems, or as seismic instruments, 
since they are similar, in principle, to a seismograph which is used to detect 
motions of the earth's surface. 
</p>
<p>Figure I 
</p>
<p>Spring-mass-dashpot systems have many diverse applications. For ex-
ample, the shock absorbers in our automobiles are simple spring-mass-
dashpot systems. Also, most heavy gun emplacements are attached to such 
systems so as to minimize the "recoil" effect of the gun. The usefulness of 
these devices will become apparent after we set up and solve the differen-
tial equation of motion of the mass m. 
</p>
<p>In calculating the motion of the mass m, it will be convenient for us to 
measure distances from the equilibrium position of the mass, rather than 
the horizontal support. The equilibrium position of the mass is that point 
where the mass will hang at rest if no external forces act upon it. In 
equilibrium, the weight mg of the mass is exactly balanced by the restoring 
force of the spring. Thus, in its equilibrium position, the spring has been 
stretched a distance !:l/, where kM= mg. We let y = 0 denote this equi-
librium position, and we take the downward direction as positive. Let y(t) 
denote the position of the mass at time t. To find y(t), we must compute 
the total force acting on the mass m. This force is the sum of four separate 
forces W, R, D and F. 
</p>
<p>165 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>(i) The force W = mg is the weight of the mass pulling it down ward. 
This force is positive, since the downward direction is the positive y direc-
tion. 
</p>
<p>(ii) The force R is the restoring force of the spring, and it is proportional 
to the elongation, or compression, t::.l + y of the spring. lt always acts to re-
store the spring to its natural length. If t::./ + y &gt; 0, then R is negative, so 
that R = - k(t::./ + y), and if t::./ + y &lt; 0, then R is positive, so that R = 
- k(t::.l+ y). In either case, 
</p>
<p>R= -k(t::.l+y). 
</p>
<p>(iii) The force D is the damping, or drag force, which the medium exerts 
on the mass m. (Most media, such as oil and air, tend to resist the motion 
of an object through it.) This force always acts in the direction opposite the 
direction of motion, and is usually directly proportional to the magnitude 
of the velocity dy I dt. If the velocity is positive; that is, the mass is moving 
in the downward direction, then D =- cdy I dt, and if the velocity is nega-
tive, then D =- cdy I dt. In either case, 
</p>
<p>D= -cdyldt. 
</p>
<p>(iv) The force F is the external force applied to the mass. This force is 
directed upward or downward, depending as to whether F is positive or 
negative. In general, this external force will depend explicitly on time. 
</p>
<p>From Newton's second law of motion (see Section 1.7) 
</p>
<p>d2y 
m dt2 = W+R+D+F 
</p>
<p>=mg-k(t::.l+y)-c~ +F(t) 
dy 
</p>
<p>= -ky-c dt +F(t), 
</p>
<p>since mg= k t::.l. Hence, the position y(t) of the mass satisfies the second-
order linear differential equation 
</p>
<p>d2y dy 
m- +c- +ky=F(t) 
</p>
<p>dt2 dt 
(1) 
</p>
<p>where m, c and karenonnegative constants. We adopt here the mks system 
of units so that F is measured in newtons, y is measured in meters, and t is 
measured in seconds. In this case, the units of k are N jm, the units of c are 
N &middot; sjm, and the units of m are kilograms (N &middot; s2jm) 
</p>
<p>(a) Free vibrations: 
</p>
<p>We consider first the simplest case of free undamped motion. In this case, 
Equation (1) reduces to 
</p>
<p>166 
</p>
<p>d2y 
m-+ky=O or 
</p>
<p>dt2 
(2) </p>
<p/>
</div>
<div class="page"><p/>
<p>2.6 Mechanical vibrations 
</p>
<p>where w~ = k Im. The general solution of (2) is 
y(t) = a cosw0 t + b sinw0t. (3) 
</p>
<p>In order to analyze the solution (3), it is convenient to rewrite it as a single 
cosine function. This is accomplished by means of the following Iemma. 
</p>
<p>Lemma 1. Any function y(t) of the form (3) can be written in the simpler 
form 
</p>
<p>y(t) = R cos(w0t- 8) 
</p>
<p>where R = Ya2 + b2 and 8=tan- 1 bl a. 
(4) 
</p>
<p>PROOF. We will verify that the two expressions (3) and (4) are equal. To 
this end, compute 
</p>
<p>R cos(w0t- 8) = R cosw0t cos8 + R sinw0 t sin8 
and observe from Figure 2 that R cos8 = a and R sin8 = b. Hence, 
</p>
<p>R cos(w0t- 8) = a cos w0t + b sin w0 t. 0 
</p>
<p>0 
</p>
<p>Figure 2 
</p>
<p>b 
</p>
<p>In Figure 3 we have graphed the functiony = R cos(w0t- 8). Notice that 
y(t) always lies between - R and + R, and that the motion of the mass is 
periodic-it repeats itself over every time interval of length 27T I w0&bull; This 
type of motion is called simple harmonic motion; R is called the amplitude 
of the motion, 8 the phase angle of the motion, T0 = 27T I w0 the natural 
period of the motion, and w0 = ~ the natural frequency of the sys-
tem. 
</p>
<p>(b) Damped free vibrations: 
</p>
<p>If we now include the effect of damping, then the differential equation 
governing the motion of the mass is 
</p>
<p>d2y dy 
m- +c- +ky=O. 
</p>
<p>dP dt 
(5) 
</p>
<p>The roots of the characteristic equation mr2 + er+ k = 0 are 
</p>
<p>167 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>Figure 3. Graph ofy(t)=Rcos(w0t-&lt;'l) 
</p>
<p>Thus, there are three cases to consider, depending as to whether c2 - 4km 
is positive, negative or zero. 
</p>
<p>(i) c2 - 4km &gt; 0. In this case both r1 and r2 are negative, and every solu-
tion y(t) of (5) has the form 
</p>
<p>y (t) = ae' 11 + be'21 &bull; 
(ii) c2 - 4km = 0. In this case, every solution y (t) of (5) is of the form 
</p>
<p>y ( t) = ( a + bt )e- cl 12m. 
(iii) c2 - 4km &lt; 0. In this case, every solution y(t) of (5) is of the form 
</p>
<p>Y4km-c 2 
p.= y ( t) = e- cl 12m [ a cos p.t + b sin p.t J, 
</p>
<p>2m 
</p>
<p>The first two cases are referred to as overdainped and critically damped, 
respectively. They represent motions in which the originally displaced mass 
creeps back to its equilibrium position. Depending on the initial condi-
tions, it may be possible to overshoot the equilibrium position once, but no 
more than once (see Exercises 2-3). The third case, which is referred to as 
an underdamped motion, occurs quite often in mechanical systems and 
represents a damped vibration. To see this, we use Lemma 1 to rewrite the 
function 
</p>
<p>y ( t) = e -ct/2m[ a cosp.t + b sinp.t J 
</p>
<p>in the form 
</p>
<p>y(t)= Re-c112mcos( p.t- 8). 
</p>
<p>The displacement y oscillates between the curves y =&plusmn;Re-et/2m, and thus 
represents a cosine curve with decreasing amplitude, as shown in Figure 4. 
</p>
<p>Now, observe that the motion of the mass always dies out eventually if 
there is damping in the system. In other words, any initial disturbance of 
</p>
<p>168 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.6 Mechanical vibrations 
</p>
<p>y 
</p>
<p>Figure 4. Graph of Re- ct /Zm cos( Jl.l- 8) 
</p>
<p>the system is dissipated by the damping present in the system. This is one 
reason why spring-mass-dashpot systems are so useful in mechanical sys-
tems: they can be used to damp out any undesirable disturbances. For ex-
ample, the shock transmitted to an automobile by a bump in the road is 
dissipated by the shock absorbers in the car, and the momentum from the 
recoil of a gun barre! is dissipated by a spring-mass-dashpot system 
attached to the gun. 
</p>
<p>(c) Damped forced vibrations: 
</p>
<p>If we now introduce an external force F ( t) = F0 cos wt, then the differential 
equation governing the motion of the mass is 
</p>
<p>d2y dy 
m-2 +c-d +ky=F0 coswt. 
</p>
<p>dt t 
(6) 
</p>
<p>Using the method of judicious guessing, we can find a particular solution 
l[;(t) of (6) of the form 
</p>
<p>F 0 cos( wt - &szlig; ) 
(7) 
</p>
<p>where tan&szlig;=cw/(k-mw2). Hence, every solutiony(t) of (6) must be of 
</p>
<p>169 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>the form 
</p>
<p>y(t) =&lt;j&gt;(t) + lf;(t) =&lt;J&gt;(t) + [ 2 ]1/2 
(k-mw1) +c2w2 
</p>
<p>F0 cos(wt- 8) 
(8) 
</p>
<p>where &lt;j&gt;(t) is a solution of the homogeneous equation 
</p>
<p>d1y dy 
m- +c- +ky=O. 
</p>
<p>dt1 dt 
(9) 
</p>
<p>Wehave already seen though, that every solutiony =&lt;j&gt;(t) of (9) approaches 
zero as t approaches infinity. Thus, for large t, the equation y(t) = 1/;(t) de-
scribes very accurately the position of the mass m, regardless of its initial 
position and velocity. Forthis reason, 1/;(t) is called the steady state part of 
the solution (8), while &lt;j&gt;(t) is called the transient part of the solution. 
</p>
<p>(d) Forced free vibrations: 
</p>
<p>W e now remove the damping from our system and consider the case of 
forced free vibrations where the forcing term is periodic and has the form 
F(t)= F0 coswt. In this case, the differential equation governing the motion 
of the mass m is 
</p>
<p>d1y Fo 
- 2 +w5y=- coswt, dt m 
</p>
<p>w5=kjm. (10) 
</p>
<p>The case w~w 0 is uninteresting; every solution y(t) of (10) has the form 
</p>
<p>. Fo 
y(t)=c1cosw0t+c1smw0t+ ( 2 2) coswt, 
</p>
<p>m w0 -w 
</p>
<p>and thus is the sum of two periodic functions of different periods. The in-
teresting case is when w = w0 ; that is, when the frequency w of the external 
force equals the natural frequency of the system. This case is called the res-
onance case, and the differential equation of motion for the mass m is 
</p>
<p>d1y 2 Fo 
- 2 +w0 y =- COSw0t. 
dt m 
</p>
<p>( ll) 
</p>
<p>We will find a particular solution 1/;(t) of (11) as the real part of a 
complex-valued solution &lt;j&gt;(t) of the equation 
</p>
<p>d 1y Fo . 
- +w2y= -e'wot. 
dt2 o m 
</p>
<p>{12) 
</p>
<p>Since eiwot is a solution of the homogeneaus equation y" + w5y = 0, we 
know that (12) has a particular solution &lt;j&gt;(t)=Ateiwot, for some constant A. 
Computing 
</p>
<p>170 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.6 Mechanical vibrations 
</p>
<p>we sec that 
</p>
<p>Hence, 
</p>
<p>1 Fa - iFo 
A=--=--
</p>
<p>2iw0 m 2mw0 &middot; 
</p>
<p>-iF t 
cj&gt;(t) = -2 &deg; (cosw0t + isinw0 t) mw0 
</p>
<p>F0 t . . F0 t 
= -2-- Stn w0t- t-2-- COS w0 t mw0 mw0 
</p>
<p>is a particular solution of (12), and 
</p>
<p>F0t 
~ ( t) = Re { cj&gt;( t)} = -2 - sin w0t mw0 
</p>
<p>is a particular solution of (11). Consequently, every solution y(t) of (11) is 
of the form 
</p>
<p>(13) 
</p>
<p>for some choice of constants c1,c2&bull; 
Now, the sum of the first two terms in (13) is a periodic function of 
</p>
<p>time. The third term, though, represents an oscillation with increasing am-
plitude, as shown in Figure 5. Thus, the forcing term F0 coswt, if it is in res-
onance with the natural frequency of the system, will always cause un-
bounded oscillations. Such a phenomenon was responsible for the collapse 
of the Tacoma Bridge, (see Section 2.6.1) and many other mechanical 
catastrophes. 
</p>
<p>y 
</p>
<p>Figure 5. Graph of f(t)=Atsinw0t 
</p>
<p>171 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>ExERCISES 
</p>
<p>l. lt is found experimentally that a l kg mass stretches a spring 49/320 m. If the 
mass is pulled down an additional 1/4 m and released, find the amplitude, 
period and frequency of the resulting motion, neglecting air resistance (use 
</p>
<p>g = 9.8 mjs2 ). 
</p>
<p>2. Let y(t)=Ae'11 + Be'21 , with lA I+ IBI ""'0. 
(a) Show thaty(t) is zero at most once. 
(b) Show that y'(t) is zero at most once. 
</p>
<p>3. Let y(t) = (A + Bt)e'', with lA I+ IB I ""'0. 
(a) Show that y(t) is zero at most once. 
(b) Show thaty'(t) is zero at most once. 
</p>
<p>4. A small object of mass l kg is attached to aspring with spring constant 2Njm. 
This spring-mass system is immersed in a viscous medium with damping 
</p>
<p>constant 3 N&middot;sjm. At time t=O, the mass is lowered l/2 m below its 
equilibrium position, and released. Show that the mass will creep back to its 
equilibrium position as t approaches infinity. 
</p>
<p>5. A small object of mass l kg is attached to aspring with spring-constant l Njm 
and is immersed in a viscous medium with damping constant 2 N &middot; sjm. At time 
t = 0, the mass is lowered 1/4 m and given an initial velocity of 1 mjs in the 
upward direction. Show that the mass will overshoot its equilibrium position 
once, and then creep back to equilibrium. 
</p>
<p>6. A small object of mass 4 kg is attached to an elastic spring with spring-constant 
64 Njm, and is acted upon by an extemal force F(t) = A cos3wt. Findall values 
of w at which resonance occurs. 
</p>
<p>7. The gun of a U.S. M60 tank is attached to a spring-mass-dashpot system with 
spring-constant 100a2 and damping constant 200a, in their appropriate units. 
The mass of the gun is 100 kg. Assurne that the displacement y(t) of the gun 
from its rest position after being fired at time t = 0 satisfies the initial-value 
problern 
</p>
<p>lOOy" +100ay' + 100a2y = 0; y(O) = 0, y'(O) = 100 mjs. 
lt is desired that one second later, the quantity y 2 +(y') 2 be less than .01. How 
large must a be to guarantee that this is so? (The spring-mass-dashpot 
mechanism in the M60 tanks supplied by the U.S. to Israel are critically 
damped, for this situation is preferable in desert warfare where one has to fire 
again as quickly as possible). 
</p>
<p>8. A spring-mass-dashpot system has the property that the spring constant k is 9 
times its mass m, and the damping constant c is 6 times its mass. At time t = 0, 
</p>
<p>the mass, which is banging at rest, is acted upon by an extemal force F(t) = 
(3 sin3t) N. The spring will break if it is stretched an additional 5 m from its 
equilibrium position. Show that the spring will not break if m ;;.} /5 kg. 
</p>
<p>9. A spring-mass-dashpot system with m = 1, k = 2 and c = 2 (in their respective 
units) hangs in equilibrium. At timet= 0, an extemal force F(t) = 7T- t N acts 
foratime interval 7T. Find the position of the mass at anytime t &gt; 7T. 
</p>
<p>172 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.6 Mechanica1 vibrations 
</p>
<p>10. A 1 kg mass is attached to aspring with spring constant k = 64 Njm. With the 
mass on the spring at rest in the equilibrium position at time t = 0, an external 
force F(t) = (!t) N is applied unti1 time t1 = 1-IT/16 seconds, at which time it is 
removed. Assurning no damping, find the frequency and amplitude of the 
resulting oscillation. 
</p>
<p>11. A 1 kg mass is attached to aspring with spring constant k = 4 Njm, and hangs 
in equilibrium. An external force F(t) = (1 + t +sin2t) N is applied to the mass 
beginning at time t = 0. lf the spring is stretched a length ( 1/2 + 'IT / 4) m or 
more from its equilibrium position, then it will break. Assurning no damping 
present, find the time at which the spring breaks. 
</p>
<p>12. A small object of mass I kg is attached to a spring with spring constant k =I 
Njm. This spring-mass system is then immersed in a viscous medium with 
damping constant c. An external force F(t) = (3 -cos t) N is applied to the 
system. Determine the minimum positive value of c so that the magnitude of the 
steady state solution does not exceed 5 m. 
</p>
<p>13. Determine a particular solution 1/J(t) of my" + cy' + ky = F0 coswt, of the form 
1/J(t)=A cos(wt-q,). Show that the amplitude A is a maximum when w2 =wJ 
- t( c Im )2&bull; This value of w is called the resonant jrequency of the system. What 
happens when wJ &lt; t( c Im )2? 
</p>
<p>2.6.1 The Tacoma Bridgedisaster 
</p>
<p>On July I, 1940, the Tacoma Narrows Bridge at Puget Sound in the state 
of Washington was completed and opened to traffic. From the day of its 
opening the bridge began undergoing vertical oscillations, and it soon was 
nicknamed "Galloping Gertie." Strange as it may seem, traffic on the 
bridge increased tremendously as a result of its novel behavior. People 
came from hundreds of miles in their cars to enjoy the curious thrill of 
riding over a galloping, rolling bridge. For four months, the bridge did a 
thriving business. As each day passed, the authorities in charge became 
more and more confident of the safety of the bridge-so much so, in fact, 
that they were planning to cancel the insurance policy on the bridge. 
</p>
<p>Starting at about 7:00 on the morning of November 7, 1940, the bridge 
began undulating persistently for three hours. Segments of the span were 
heaving periodically up and down as much as three feet. At about 10:00 
a.m., something seemed to snap and the bridge began oscillating wildly. At 
one moment, one edge of the roadway was twenty-eight feet higher than 
the other; the next moment it was twenty-eight feet lower than the other 
edge. At 10:30 a.m. the bridge began cracking, and finally, at 11:10 a.m. 
the entire bridge came crashing down. Fortunately, only one car was on 
the bridge at the time of its failure. lt belonged to a newspaper reporter 
who had to abandon the car and its sole remaining occupant, a pet dog, 
when the bridge began its violent twisting motion. The reporter reached 
safety, torn and bleeding, by crawling on hands and knees, desperately 
</p>
<p>173 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>clutching the curb of the bridge. His dog went down with the car and the 
span-the only life lost in the disaster. 
</p>
<p>There were many humorous and ironic incidents associated with the col-
lapse of the Tacoma Bridge. When the bridge began heaving violently, the 
authorities notified Professor F. B. Farquharson of the University of 
Washington. Professor Farquharson had conducted numerous tests on a 
simulated model of the bridge and had assured everyone of its stability. 
The professor was the last man on the bridge. Even when the span was tilt-
ing more than twenty-eight feet up and down, he was making scientific Ob-
servations with little or no anticipation of the imminent collapse of the 
bridge. When the motion increased in violence, he made his way to safety 
by scientifically following the yellow line in the middle of the roadway. 
The professor was one of the most surprised men when the span crashed 
into the water. 
</p>
<p>One of the insurance policies covering the bridge had been written by a 
local travel agent who had pocketed the premium and had neglected to re-
port the policy, in the amount of $800,000, to his company. When he later 
received his prison sentence, he ironically pointed out that his embezzle-
ment would never have been discovered if the bridge had only remairred 
up for another week, at which time the bridge officials had planned to 
cancel all of the policies. 
</p>
<p>A large sign near the bridge approach advertised a local bank with the 
slogan "as safe as the Tacoma Bridge." Immediately following the collapse 
of the bridge, several representatives of the bank rushed out to remove the 
billboard. 
</p>
<p>After the collapse of the Tacoma Bridge, the governor of the state of 
Washington made an emotional speech, in which he declared "We are 
going to build the exact same bridge, exactly as before." Upon hearing 
this, the noted engineer Von Karman sent a telegram to the governor stat-
ing "lf you build the exact same bridge exactly as before, it will fall into 
the exact same river exactly as before." 
</p>
<p>The collapse of the Tacoma Bridge was due to an aerodynamical phe-
nomenon known as stall jlutter. This can be explained very briefly in the 
following manner. lf there is an obstacle in a stream of air, or liquid, then 
a "vortex street" is formed behind the obstacle, with the vortices flowing 
off at adefinite periodicity, which depends on the shape and dimension of 
the structure as well as on the velocity of the stream (see Figure 1). As a 
result of the vortices separating alternately from either side of the obstacle, 
it is acted upon by a periodic force perpendicular to the direction of the 
stream, and of magnitude F0 coswt. The coefficient F0 depends on the 
shape of the structure. The poorer the streamlining of the structure; the 
larger the coefficient F0, and hence the amplitude of the force. For exam-
ple, flow around an airplane wing at small angles of attack is very smooth, 
so that the vortex street is not weil defined and the coefficient F0 is very 
small. The poorly streamlined structure of a suspension bridge is another 
</p>
<p>174 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.6 Mechanical vibrations 
</p>
<p>Figure I 
</p>
<p>matter, and it is natural to expect that a force of large amplitudewill be set 
up. Thus, a structure suspended in an air stream experiences the effect of 
this force and hence goes into a state of forced vibrations. The amount of 
danger from this type of motion depends on how close the natural 
frequency of the structure (remember that bridges are made of steel, a 
highly elastic material) is to the frequency of the driving force. If the two 
frequencies are the same, resonance occurs, and the oscillations will be de-
structive if the system does not have a sufficient amount of damping. It has 
now been established that oscillations of this type were responsible for the 
collapse of the Tacoma Bridge. In addition, resonances produced by the 
separation of vortices have been observed in steel factory chimneys, and in 
the periscopes of submarines. 
</p>
<p>The phenomenon of resonance was also responsible for the collapse of 
the Broughton suspension bridge near Manchester, England in 1831. This 
occurred when a column of soldiers marched in cadence over the bridge, 
thereby setting up a periodic force of rather large amplitude. The 
frequency of this force was equal to the natural frequency of the bridge. 
Thus, very large oscillations were induced, and the bridge collapsed. lt is 
for this reason that soldiers are ordered to break cadence when crossing a 
bridge. 
</p>
<p>Epilog. The father of one of my students is an engineer who worked on the 
construction of the Bronx Whitestone Bridge in New York City. He 
informed me that the original plans for this bridge were very similar to those 
of the Tacoma Bridge. These plans were hastily redrawn following the 
collapse of the Tacoma Bridge. 
</p>
<p>2.6.2 Electrical networks 
</p>
<p>We now briefly study a simple series circuit, as shown in Figure I below. 
The symbol E represents a source of electromotive force. This may be a 
battery or a generator which produces a potential difference (or voltage), 
that causes a current I to flow through the circuit when the switch S is 
closed. The symbol R represents a resistance to the flow of current such as 
that produced by a lightbulb or toaster. When current flows through a coil 
of wire L, a magnetic field is produced which opposes any change in the 
current through the coil. The change in valtage produced by the coil is pro-
portional to the rate of change of the current, and the constant of propor-
</p>
<p>175 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>R 
</p>
<p>L 
+ 
</p>
<p>+ 
</p>
<p>c 
Figure I. A simple series circuit 
</p>
<p>tionality is called the inductance L of the coil. A capacitor, or condenser, 
indicated by C, usually consists of two metal plates separated by a material 
through which very little current can flow. A capacitor has the effect of re-
versing the flow of current as one plate or the other becomes charged. 
</p>
<p>Let Q (t) be the charge on the capacitor at time t. To derive a differen-
tial equation which is satisfied by Q (t) we use the following. 
</p>
<p>Kirchoffs second law: In a closed circuit, the impressed voltage equals the 
sum of the valtage drops in the rest of the circuit. 
</p>
<p>Now, 
</p>
<p>(i) The valtage drop across a resistance of R ohms equals RI (Ohm's 
law). 
</p>
<p>(ii) The valtage drop across an inductance of L henrys equals L( dl / dt). 
(iii) The valtage drop across a capacitance of C farads equals Q/ C. 
</p>
<p>Hence, 
</p>
<p>E (t) = L dl + RI + Q 
dt c' 
</p>
<p>and since I (t) = dQ (t)/ dt, we see that 
d 2Q dQ Q 
</p>
<p>L dt2 +Rdt + C =E(t). (1) 
</p>
<p>Notice the resemblance of Equation (1) to the equation of a vibrating 
mass. Among the similarities with mechanical vibrations, electrical circuits 
also have the property of resonance. Unlike mechanical systems, though, 
resonance is put to good use in electrical systems. For example, the tuning 
knob of a radio is used to vary the capacitance in the tuning circuit. In this 
manner, the resonant frequency (see Exercise 13, Section 2.6) is changed 
until it agrees with the frequency of one of the incoming radio signals. The 
amplitude of the current produced by this signal will be much greater than 
</p>
<p>176 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.6 Mechanical vibrations 
</p>
<p>that of all other signals. In this way, the tuning circuit picksout the desired 
station. 
</p>
<p>EXERCISES 
</p>
<p>1. Suppose that a simple series circuit has no resistance and no impressed voltage. 
Show that the charge Q on the capacitor is periodic in time, with frequency 
</p>
<p>w0 = V I I LC . The quantity V I I LC is called the natural frequency of the 
circuit. 
</p>
<p>2. Suppose that a simple series circuit consisting of an inductor, a resistor and a 
capacitor is open, and that there is an initial charge Q0 = w-s coulombs on the 
capacitor. Find the charge on the capacitor and the current flowing in the circuit 
after the switch is closed for each of the following cases. 
(a) L=0.5 henrys, C= w-s farads, R= !000 ohms 
(b) L= I henry, C= w- 4 farads, R=200 ohms 
(c) L=2 henrys, C= w- 6 farads, R=2000 ohms 
</p>
<p>3. A simple series circuit has an inductor of I henry, a capacitor of w- 6 farads, 
and a resistor of 1000 ohms. The initial charge on the capacitor is zero. If a 12 
volt battery is connected to the circuit, and the circuit is closed at t = 0, find the 
charge on the capacitor I second later, and the steady state charge. 
</p>
<p>4. A capacitor of w- 3 farads is in series with an electromotive force of 12 volts 
and an inductor of I henry. At t = 0, both Q and I are zero. 
(a) Find the natural frequency and period of the electrical oscillations. 
(b) Find the maximum charge on the capacitor, and the maximum current flow-
</p>
<p>ing in the circui t. 
</p>
<p>5. Show that if there is no resistance in a circuit, and the impressed voltage is of 
the form E0 sinwt, then the charge on the capacitor will become unbounded as 
</p>
<p>t-&gt; oo if w = V I I LC . This is the phenomenon of resonance. 
</p>
<p>6. Consider the differential equation 
</p>
<p>.. . Q 
LQ + RQ + C = E0 coswt. (i) 
</p>
<p>We find a particular solution !f;(t) of (i) as the real part of a particular solution 
</p>
<p>&lt;/&gt;( t) of 
(ii) 
</p>
<p>(a) Show that 
Eo . 
</p>
<p>iw&lt;j&gt;(t) = 1 e'"'1&bull; 
R + i(wL- wC) 
</p>
<p>(b) The quantity Z = R + i(wL -I I wC) is known as the complex impedance of 
the circuit. The reciprocal of Z is called the admittance, and the real and im-
aginary parts of I I Z are called the conductance and susceptance. De-
termine the admittance, conductance and susceptance. 
</p>
<p>7. Consider a simple series circuit with given values of L, R and C, and an im-
pressed voltage E0 sinwt. For which value of w will the steady state current be a 
maximum? 
</p>
<p>177 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>2.7 A model for the detection of diabetes 
</p>
<p>Diabetes mellitus is a disease of metabolism which is characterized by too 
much sugar in the blood and urine. In diabetes, the body is unable to burn 
off all its sugars, starches, and carbohydrates because of an insufficient 
supply of insulin. Diabetes is usually diagnosed by means of a glucose 
tolerance test (GTT). In this test the patient comes to the hospital after an 
overnight fast and is given a large dose of glucose (sugar in the form in 
which it usually appears in the bloodstream). During the next three to five 
hours several measurements are made of the concentration of glucose in 
the patient's blood, and these measurements are used in the diagnosis of 
diabetes. A very serious difficulty associated with this method of diagnosis 
is that there is no universally accepted criterion for interpreting the results 
of a glucose tolerance test. Three physicians interpreting the results of a 
GTT may come up with three different diagnoses. In one case recently, in 
Rhode Island, one physician, after reviewing the results of a GTT, came 
up with a diagnosis of diabetes. A second physician declared the patient to 
be normal. To settle the question, the results of the GTT were sent to a 
specialist in Boston. After examining these results, the specialist concluded 
that the patient was suffering from a pituitary tumor. 
</p>
<p>In the mid 1960's Drs. Rosevear and Molnar of the Mayo Clinic and 
Ackerman and Gatewood of the University of Minnesota discovered a 
fairly reliable criterion for interpreting the results of a glucose tolerance 
test. Their discovery arose from a very simple model they developed for 
the blood glucose regulatory system. Their model is based on the following 
simple and fairly well known facts of elementary biology. 
</p>
<p>1. Glucose plays an important role in the metabolism of any vertebrate 
since it is a source of energy for all tissues and organs. Foreach individual 
there is an optimal blood glucose concentration, and any excessive devia-
tion from this optimal concentration leads to severe pathological condi-
tions and potentially death. 
</p>
<p>2. While blood glucose levels tend to be autoregulatory, they are also in-
fluenced and controlled by a wide variety of hormones and other metabo-
lites. Among these are the following. 
</p>
<p>(i) Insulin, a hormone secreted by the &szlig; cells of the pancreas. After we 
eat any carbohydrates, our G.l. tract sends a signal to the pancreas to 
secrete more insulin. In addition, the glucose in our blood directly stimu-
lates the &szlig; cells of the pancreas to secrete insulin. lt is generally believed 
that insulin facilitates tissue uptake of glucose by attaching itself to the im-
permeable membrane walls, thus allowing glucose to pass through the 
membranes to the center of the cells, where most of the biological and 
chemical activity takes place. Without sufficient insulin, the body cannot 
avail itself of all the energy it needs. 
</p>
<p>178 </p>
<p/>
</div>
<div class="page"><p/>
<p>2. 7 A model for the detection of diabetes 
</p>
<p>(ii) Glucagon, a hormone secreted by the a cells of the pancreas. Any ex-
cess glucose is stored in the liver in the form of glycogen. In times of need 
this glycogen is converted back into glucose. The hormone glucagon in-
creases the rate of breakdown of glycogen into glucose. Evidence collected 
thus far clearly indicates that hypoglycemia (low blood sugar) and fasting 
promote the secretion of glucagon while increased blood glucose Ievels 
suppress its secretion. 
</p>
<p>(iii) Epinephrine (adrenalin), a hormone secreted by the adrenal medulla. 
Epinephrine is part of an emergency mechanism to quickly increase the 
concentration of glucose in the blood in times of extreme hypoglycemia. 
Like glucagon, epinephrine increases the rate of breakdown of glycogen 
into glucose. In addition, it directly inhibits glucose uptake by muscle 
tissue; it acts directly on the pancreas to inhibit insulin secretion; and it 
aids in the conversion of Iactate to glucose in the liver. 
</p>
<p>(iv) G/ucocorticoids, hormones such as cortisol which are secreted by the 
adrenal cortex. Glucocorticoids play an important role in the metabolism 
of carbohydrates. 
</p>
<p>(v) Thyroxin, a hormone secreted by the thyroid gland. This hormone 
aids the liver in forming glucose from non-carbohydrate sources such as 
glycerol, Iactate and amino acids. 
</p>
<p>(vi) Growth hormone (somatotropin), a hormone secreted by the anterior 
pituitary gland. Not only does growth hormone affect glucose Ievels in a 
direct manner, but it also tends to "block" insulin. lt is believed that 
growth hormone decreases the sensitivity of muscle and adipose membrane 
to insulin, thereby reducing the effectiveness of insulin in promoting 
glucose uptake. 
</p>
<p>The aim of Ackerman et al was to construct a model which would ac-
curately describe the blood glucose regulatory system during a glucose 
tolerance test, and in which one or two parameters would yield criteria for 
distinguishing normal individuals from mild diabetics and pre-diabetics. 
Their model is a very simplified one, requiring only a limited number of 
blood samples during a GTT. lt centers attention on two concentrations, 
that of glucose in the blood, Iabelied G, and that of the net hormonal con-
centration, Iabelied H. The latter is interpreted to represent the cumulative 
effect of all the pertinent hormones. Those hormones such as insulin which 
decrease blood glucose concentrations are considered to increase H, while 
those hormones such as cortisol which increase blood glucose concentra-
tions are considered to decrease f/. Now there are two reasons why such a 
simplified model can still provide an accurate description of the blood 
glucose regulatory system. First, studies have shown that under normal, or 
close to normal conditions, the interaction of one hormone, namely in-
sulin, with blood glucose so predominates that a simple "lumped parame-
ter model" is quite adequate. Second, evidence indicates that normogly-
cemia does not depend, necessarily, on the normalcy of each kinetic 
</p>
<p>179 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>mechanism of the blood glucose regulatory system. Rather, it depends on 
the overall performance of the blood glucose regulatory system, and this 
system is dominated by insulin-glucose interactions. 
</p>
<p>The basic model is described analytically by the equations 
</p>
<p>dG 
dt=F1 (G,H)+J(t) (1) 
</p>
<p>(2) 
</p>
<p>The dependence of F 1 and F2 on G and H signify that changes in G and H 
are determined by the values of both G and H. The function J (t) is the ex-
ternal rate at which the blood glucose concentration is being increased. 
Now, we assume that G and H have achieved optimal values G0 and H0 by 
the time the fasting patient has arrived at the hospital. This implies that 
F1( G0, H0) = 0 and F2( G0, H0) = 0. Since we are interested here in the devia-
tions of G and H from their optimal values, we make the substitution 
</p>
<p>g= G- G0, h= H-H0&bull; 
</p>
<p>Then, 
</p>
<p>dg 
dt =F1 (G0 +g,H0 +h)+J(t), 
</p>
<p>dh 
dt =F2(Go+g,Ho+h). 
</p>
<p>Now, observe that 
</p>
<p>3F1 (G0,H0 ) 3F1 (G0,H0 ) 
F1 (G0 +g,H0 +h)=F1(G0,H0 )+ aG g+ aH h+e1 
</p>
<p>and 
</p>
<p>3F2 (G0,H0 ) 3F2 (G0,H0 ) 
F2(G0 +g,H0 +h)=F2(G0,H0 )+ aG g+ aH h+e2 
</p>
<p>where e1 and e2 are very small compared to g and h. Hence, assuming that 
G and H deviate only slightly from G0 and H0, and therefore neglecting 
the terms e1 and e2, we see that 
</p>
<p>dg 3F1 (G0,H0 ) aF, (G0,H0 ) 
dt = aG g+ aH h+J(t) (3) 
</p>
<p>dh 3F2 (G0,H0 ) 3F2 (G0,H0 ) 
dt = aG g+ aH h. (4) 
</p>
<p>Now, there are no means, a priori, of determining the numbers 
</p>
<p>3F1 (G0,H0 ) 3F1 (G0,H0 ) 3F2 (G0,H0 ) 
</p>
<p>aG aH aG 
and 
</p>
<p>However, we can determine their signs. Referring to Figure 1, we see that 
dg / dt is negative for g &gt; 0 and h = 0, since the blood glucose concentration 
</p>
<p>180 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.7 A model for the detection of diabetes 
</p>
<p>I G.l. Tract I 
fl 
</p>
<p>Glucose Pool Tissuc 
Li ver 
</p>
<p>0 
G Uptake 
</p>
<p>' 
, 
</p>
<p>"' , 
/'---------"' 
</p>
<p>' /, ,. .. ' ', / Endocrines // Hormone Pool Hormone 
0 H 
</p>
<p>Metabolism 
</p>
<p>Figure 1. Simplified model of the blood glucose regulatory system 
</p>
<p>will be decreasing through tissue uptake of glucose and the storing 
of excess glucose in the liver in the form of glycogen. Consequently 
aF1(G0 ,H0)jaG must be negative. Similarly, aF1(G0,H0)jaH is negative 
since a positive value of h tends to decrease blood glucose levels by facili-
tating tissue uptake of glucose and by increasing the rate at which glucose 
is converted to glycogen. The number aFi G0, H0)/ aG must be positive 
since a positive value of g causes the endocrine glands to secrete those 
hormones which tend to increase H. Finally, aFl Go, Ho) I aH must be 
negative, since the concentration of hormones in the blood decreases 
through hormone metabolism. 
</p>
<p>Thus, we can write Equations (3) and (4) in the form 
</p>
<p>dg 
dt = -m1g-m2h+J(t) (5) 
</p>
<p>dh 
-=-mh+m g dt 3 4 (6) 
</p>
<p>where mp m2, m3, and m4 are positive constants. Equations (5) and (6) are 
two first-order equations for g and h. However, since we only measure the 
concentration of glucose in the blood, we would like to remove the vari-
able h. This can be accomplished as follows: Differentiating (5) with re-
spect to t gives 
</p>
<p>d2g dg dh dJ 
dt2 = - m1 dt - mz dt + dt &middot; 
</p>
<p>Substituting for dhj dt from (6) we obtain that 
</p>
<p>d 2g dg dJ 
dtz = -mi dt +mzm3h-mzm4g+ Tt&middot; (7) 
</p>
<p>Next, observe from (5) that m2h =(- dgj dt)- m 1 g+J(t). Consequently, 
</p>
<p>181 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>g(t) satisfies the second-order linear differential equation 
</p>
<p>d 2g dg dJ 
-2 +(ml+m3)-d +(mlm3+m2m4)g=m3J+-d . 
dt t t 
</p>
<p>We rewrite this equation in the form 
</p>
<p>d2g dg 2 
- +2a-d +w0 g=S(t) 
dt2 t 
</p>
<p>(8) 
</p>
<p>where a=(m 1 + m3)j2, w6= m 1m3+ m2m4, and S(t)= m3J + dJ / dt. 
Notice that the right-hand side of (8) is identically zero except for the 
</p>
<p>very short time interval in which the glucose Ioad is being ingested. We will 
learn to deal with such functions in Section 2.12. For our purposes here, Iet 
t = 0 be the time at which the glucose Ioad has been completely ingested. 
Then, for t &gt; 0, g(t) satisfies the second-order linear homogeneaus equa-
tion 
</p>
<p>(9) 
</p>
<p>This equation has positive coefficients. Hence, by the analysis in Section 
2.6, (see also Exercise 8, Section 2.2.2) g(t) approaches zero as t ap-
proaches infinity. Thus our model certainly conforms to reality in pre-
dicting that the blood glucose concentration tends to return eventually to 
its optimal concentration. 
</p>
<p>The solutions g(t) of (9) are of three different types, depending as to 
whether a 2 - w5 is positive, negative, or zero. These three types, of course, 
correspond to the overdamped, critically damped and underdamped cases 
discussed in Section 2.6. We will assume that a 2 - w6 is negative; the other 
two cases are treated in a similar manner. If a 2 - w6 &lt; 0, then the character-
istic equation of Equation (9) has complex roots. lt is easily verified in this 
case (see Exercise 1) that every solution g(t) of (9) is of the form 
</p>
<p>g(t)=Ae-a1 cos(wt-8), w2=w6-a2. (10) 
</p>
<p>Consequently, 
</p>
<p>G ( t) = G0 + Ae -at cos( wt- 8 ). (11) 
Now there are five unknowns G0, A, a, w0, and 8 in (11). One way of de-
termining them is as follows. The patient's blood glucose concentration be-
fore the glucose Ioad is ingested is G0. Hence, we can determine G0 by 
measuring the patient's blood glucose concentration immediately upon his 
arrival at the hospital. Next, if we take four additional measurements G1, 
G2, G3, and G4 of the patient's blood glucose concentration at times t1, t2, 
t3, and t4, then we can determine A, a, w0, and 8 from the four equations 
</p>
<p>G1 = G 0 +Ae-a~cos(w1- 8 ), j= 1,2,3,4. 
</p>
<p>A second, and better method of determining G0, A, a, w0, and 8 is to take n 
measurements G1, G2, &bull;&bull;&bull; , Gn of the patient's blood glucose concentration at 
</p>
<p>182 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.7 A model for the detection of diabetes 
</p>
<p>times t1,t2, ... ,tn. Typically n is 6 or 7. We then find optimal values for GO'&gt; 
A, a, w0, and 8 such that the least square error 
</p>
<p>n 
</p>
<p>E= ~ [ G1 - G0 - Ae-a~cos(wt 1 - 8) t 
)=! 
</p>
<p>is minimized. The problern of minimizing E can be solved on a digital 
computer, and Ackerman et al (see reference at end of section) provide a 
complete Fortranprogram for determining optimal values for G0, A, a, w0, 
and 8. This method is preferrable to the first method since Equation (ll) is 
only an approximate formula for G (t). Consequently, it is possible to find 
values G0, A, a, w0 , and 8 so that Equation (ll) is satisfied exactly at four 
points t 1, t2, t3, and t4 but yields a poor fit to the data at other times. The 
second method usually offers a better fit to the data on the entire time in-
terval since it involves more measurements. 
</p>
<p>In numerous experiments, Ackerman et al observed that a slight error in 
measuring G could produce a very large error in the value of a. Hence, any 
criterion for diagnosing diabetes that involves the parameter a is unreli-
able. However, the parameter w0, the natural frequency of the system, was 
relatively irrsensitive to experimental errors in measuring G. Thus, we may 
regard a value of w0 as the basic descriptor of the response to a glucose 
tolerance test. For discussion purposes, it is more convenient to use the 
corresponding natural period T0 = 27T / w0&bull; The remarkable fact is that data 
from a variety of sources indicated that a value oJ /ess than Jour hours Jor 
T0 indicated normalcy, while appreciably more than Jour hours implied mild 
diabetes. 
</p>
<p>Remark 1. The usual period between meals in our culture is about 4 hours. 
This suggests the interesting possibility that sociological factors may also 
play a role in the blood glucose regulatory system. 
</p>
<p>Remark 2. W e wish to emphasize that the model described above can only 
be used to diagnose mild diabetes or pre-diabetes, since we have assumed 
throughout that the deviation g of G from its optimal value G0 is small. 
Very large deviations of G from G0 usually indicate severe diabetes or di-
abetes insipidus, which is a disorder of the posterior lobe of the pituitary 
gland. 
</p>
<p>A serious shortcoming of this simplified model is that it sometimes 
yields a poor fit to the data in the time period three to five hours after in-
gestion of the glucose Ioad. This indicates, of course, that variables such as 
epinephrine and glucagon play an important role in this time period. Thus 
these variables should be included as separate variables in our model, 
rather than being lumped together with insulin. In fact, evidence indicates 
that Ievels of epinephrine may rise dramatically during the recovery phase 
of the GTT response, when glucose Ievels have been lowered below fasting 
</p>
<p>183 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>g(t) 
</p>
<p>Figure 2. Graph of g(t) if a2 -w5&gt;0 
</p>
<p>levels. This can also be seen directly from Equation (9). If a2 - w5 &gt; 0, then 
g(t) may have the form described in Figure 2. Note that g(t) drops very 
rapidly from a fairly high value to a negative one. It is quite conceivable, 
therefore, that the body will interpret this as an extreme emergency and 
thereby secrete a large amount of epinephrine. 
</p>
<p>Medical researchers have long recognized the need of including epi-
nephrine as a separate variable in any model of the blood glucose regula-
tory system. However, they were stymied by the fact that there wa&amp; no reli-
able method of measuring the concentration of epinephrine in the blood. 
Thus, they bad to assume, for all practical purposes, the the level of epi-
nephrine remained constant during the course of a glucose tolerance test. 
This author has just been informed that researchers at Rhode Island 
Hospital have devised an accurate method of measuring the concentration 
of epinephrine in the blood. Thus we will be able to develop and test more 
accurate models of the blood glucose regulatory system. Hopefully, this 
will lead to more reliable criteria for the diagnosis of diabetes. 
</p>
<p>Rejerence 
E. Ackerman, L. Gatewood, J. Rosevear, and G. Molnar, Blood glucose regulation 
</p>
<p>and diabetes, Chapter 4 in Concepts and Models of Biomathematics, F. Heinmets, 
ed., Marcel Dekker, 1969, 131-156. 
</p>
<p>EXERCISES 
</p>
<p>1. Derive Equation (10). 
</p>
<p>2. A patient arrives at the hospital after an overnight fast with a blood g1ucose con-
centration of 70 mg glucose/100 ml b1ood (mg glucose/100 ml blood= 
milligrams of glucose per 100 milliliters of blood). His blood glucose concentra-
tion 1 hour, 2 hours, and 3 hours after fully absorbing a large amount of glucose 
is 95, 65, and 75 mg glucose/100 ml blood, respectively. Show that this patient is 
normal. Hint: In the underdamped case, the time interval between two succes-
sive zeros of G- G0 exceeds one half the natural period. 
</p>
<p>184 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.8 Series solutions 
</p>
<p>According to a famous diabetologist, the blood glucose concentration of a 
nondiabetic who has just absorbed a large amount of glucose will be at or 
below the fasting Ievel in 2 hours or less. Exercises 3 and 4 compare the 
diagnoses of this diabetologist with those of Ackerman et al. 
</p>
<p>3. The deviation g(t) of a patient's blood glucose concentration from its optimal 
concentration satisfies the differential equation (d 2gjdt2)+2a(dg/dt)+a2g=O 
immediately after he fully absorbs a !arge amount of glucose. The time t is 
measured in minutes, so that the units of a are reciprocal minutes. Show that 
this patient is normal according to Ackerman et al, if a &gt; 'TT /120 (min), and that 
this patient is normal according to the famous diabetologist if 
</p>
<p>g'(O) &lt; - ( 1 ~ 0 + a) g(O). 
</p>
<p>4. A patient's blood glucose concentration G ( t) satisfies the initial-value problern 
</p>
<p>d 2G + I dG + I G 
dt2 20 (min) dt 2500 (min)2 
</p>
<p>1 
2 75 mg glucose/100 ml blood; 
</p>
<p>2500 (min) 
</p>
<p>G (0) = 150 mg glucose/ 100 ml blood, 
</p>
<p>G'(O)=- aG(O)/(min); 
I 1-4e1815 
</p>
<p>a;;;. 200 1-eiS/5 
</p>
<p>immediately after he fully absorbs a !arge amount of glucose. This patient's opti-
mal blood glucose concentration is 75 mg glucose/100 ml blood. Show that this 
patient is a diabetic according to Ackerman et al, but is normal according to the 
famous diabetologist. 
</p>
<p>2.8 Series solutions 
</p>
<p>We return now to the general homogeneaus linear second-order equation 
</p>
<p>d2y dy 
L[y]=P(t)-2 +Q(t)-d +R(t)y=O 
</p>
<p>dt t 
(I) 
</p>
<p>with P (t) unequal to zero in the interval a &lt; t &lt; &szlig;. lt was shown in Section 
2.1 that every solutiony(t) of (1) can be written in the formy(t)=c 1y 1(t) 
+ c2 Y2( t), where y 1 ( t) and Y2( t) are any two linearly independent solutions 
of (1). Thus, the problern of finding all solutions of (1) is reduced to the 
simpler problern of finding just two solutions. In Section 2.2 we handled 
the special case where P, Q, and R are constants. The next simplest case is 
when P ( t), Q ( t), and R ( t) are polynomials in t. In this case, the form of 
the differential equation suggests that we guess a polynomial solution y(t) 
of (1). If y(t) is a polynomial in t, then the three functions P(t)y"(t), 
Q (t)y'(t), and R (t)y(t) are again polynomials in t. Thus, in principle, we 
can determine a polynomial solution y ( t) of (1) by setting the sums of the 
</p>
<p>185 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>coefficients of like powersoft in the expression L[y](t) equal to zero. We 
illustrate this method with the following example. 
</p>
<p>Example 1. Find two linearly independent solutions of the equation 
</p>
<p>d2y dy 
L[y]= dt2 -2td1 -2y=O. (2) 
</p>
<p>Solution. We will try to find 2 polynomial solutions of (2). Now, it is not 
obvious, a priori, what the degree of any polynomial solution of (2) should 
be. Nor is it evident that we will be able to get away with a polynomial of 
finite degree. Therefore, we set 
</p>
<p>Computing 
</p>
<p>and 
</p>
<p>00 
</p>
<p>y(t)=a0 +a1t+a2t2 + ... = L antn. 
n=O 
</p>
<p>d2y 00 
- 2 =2a2 +6a3t+ ... = L n(n-I)antn- 2, 
dt n=O 
</p>
<p>we see that y(t) is a solution of (2) if 
00 00 00 
</p>
<p>L[y](t)= L n(n-l)antn- 2 -2t L nantn-!_2 L antn 
n=O n=O n=O 
</p>
<p>00 00 00 
</p>
<p>= L n(n-l)antn- 2 -2 L nantn-2 L antn=O. (3) 
n=O n=O n=O 
</p>
<p>Our next step is to rewrite the first summation in (3) so that the expo-
nent of the general term is n, instead of n- 2. This is accomplished by in-
creasing every n underneath the summation sign by 2, and decreasing the 
lower Iimit by 2, that is, 
</p>
<p>00 00 
</p>
<p>L n(n-l)antn- 2= L (n+2)(n+l)an+ 2tn. 
n=O n= -2 
</p>
<p>(If you don't believe this, you can verify it by writing out the first few 
terms in both summations. If you still don't believe this and want a formal 
proof, set m = n- 2. When n is zero, m is -2 and when n is infinity, m is 
infinity. Therefore 
</p>
<p>00 00 
</p>
<p>L n(n -l)antn- 2= L (m +2)(m+ l)am+ 2tm, 
n=U m=-2 
</p>
<p>and since m is a dummy variable, we may replace it by n.) Moreover, ob-
serve that the contribution to this sum from n = -2 and n = - 1 is zero 
</p>
<p>186 </p>
<p/>
</div>
<div class="page"><p/>
<p>208 Series solutions 
</p>
<p>since the factor (n + 2)(n + 1) vanishes in both these instanceso Hence, 
00 00 
</p>
<p>L n(n-1)antn- 2 = L (n+2)(n+ 1)an+ 2tn 
n=O n=O 
</p>
<p>and we can rewrite (3) in the form 
00 00 00 
</p>
<p>L (n+2)(n+1)an+Ztn-2 L nantn-2 L antn=Oo (4) 
n=O n=O n=O 
</p>
<p>Setting the sum of the coefficients of 1ike powers of t in (4) equal to zero 
gives 
</p>
<p>so that 
2( n + l )an 2an 
</p>
<p>an+z= (n+2)(n+ l) = n+2 &deg; (5) 
</p>
<p>Equation (5) is a recurrence formula for the coefficients a0,a1,a2,a3, o 0 o o 
The coefficient an determines the coefficient an+ 2 0 Thus, a0 determines a2 
through the relation a2 = 2a0 /2 = a0 ; a2, in turn, determines a4 through the 
relation a4 = 2a2/(2 + 2) = a0 j2; and so ono Similarly, a 1 determines a3 
through the relation a3 = 2a1/(2 + 1) = 2a 1j3; a3, in turn, determines a5 
through the relation a5 =2a3/(3+2)=4a 1j3o5; and so ono Consequently, 
all the coefficients are determined uniquely once a0 and a 1 are prescribedo 
The values of a0 and a 1 are completely arbitraryo This is to be expected, 
though, for if 
</p>
<p>y(t)=a0 +a1t+a2t 2 + 000 
</p>
<p>then the values of y and y' at t = 0 are a0 and a 1 respectivelyo Thus, the 
coefficients a0 and a 1 must be arbitrary until specific initial conditions are 
imposed on y 0 
</p>
<p>To find two solutions of (2), we choose two different sets of values of a0 
and a 1o The simplest possible choices are (i) a0 = 1,a1 =0; (ii) a0 =0, a 1 = 1. 
</p>
<p>(i) a0 =1, a 1 =0o 
</p>
<p>In this case, all the odd coefficients apa3,a5,ooo are zero since a3 =2a 1/3= 
0, a5 = 2a3 j 5 = 0, and so ono The even coefficients are determined from the 
relations 
</p>
<p>and so ono Proceeding inductively, we find that 
</p>
<p>1 1 
az = =-n 2o3ooon n! 0 
</p>
<p>Hence, 
</p>
<p>187 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>is one solution of (2). 
</p>
<p>(ii) a0 =0, a1=1. 
</p>
<p>In this case, all the even coefficients are zero, and the odd coefficients are 
determined from the relations 
</p>
<p>2al 2 
a3=3=3, 
</p>
<p>and so on. Proceeding inductively, we find that 
</p>
<p>2n 
a2n+l= 3 . &middot;5&middot; .. (2n + 1) 
</p>
<p>Thus, 
00 
</p>
<p>2!3 22!5 ~ 2nt2n+ I 
y 2(t)=t+3+ 3&middot;5 + ... = ~3&middot;5 .. &middot;(2n+l) 
</p>
<p>is a second solution of (2). 
</p>
<p>Now, observe that y 1(t) and y 2(t) are polynomials of infinite degree, 
even though the coefficients P(t)= 1, Q(t)= -2t, and R(t)= -2 are poly-
nomials of finite degree. Such polynomials are called power series. Before 
proceeding further, we will briefly review some of the important properties 
of power series. 
</p>
<p>1. An infinite series 
</p>
<p>(6) 
</p>
<p>is called apower series about t = t0 &bull; 
2. All power series have an interval of convergence. This means that there 
</p>
<p>exists a nonnegative number p such that the infinite series (6) converges 
for I t- t0 I &lt; p, and diverges for I t- t0 I &gt; p. The number p is called the 
radius of convergence of the power series. 
</p>
<p>3. The power series (6) can be differentiated and integrated term by term, 
and the resultant series have the same interval of convergence. 
</p>
<p>4. The simplest method (if it works) for determining the interval of conver-
gence of the power series (6) is the Cauchy ratio test. Suppose that the 
absolute value of an+ 1/ an approaches a Iimit X as n approaches infinity. 
Then, the power series (6) converges for lt- t0l &lt; 1/'A, and diverges for 
lt- t01 &gt; 1/X. 
</p>
<p>5. The product of two power series ~ :_ 0an(t- t0)n and ~ :_0bn(t- t0Y 
is again a power series of the form ~ :_ 0cn(t- t0Y, with cn = a0bn + 
a1bn-l + ... + anb0&bull; The quotient 
</p>
<p>a0 + a1t + a2t2+ .. . 
b0 +b1t+b2t2+ .. . 
</p>
<p>of two power series is again apower series, provided that b0 =1=0. 
</p>
<p>188 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.8 Series solutions 
</p>
<p>6. Many of the functions j ( t) that arise in applications can be expanded in 
power series; that is, we can find coefficients a0, a ~&gt; a2, &bull;&bull;&bull; so that 
</p>
<p>00 
</p>
<p>f(t)=ao+al(t-to)+az(t-to) 2 + ... = ~ an(t-to( (7) 
n=O 
</p>
<p>Such functions are said to be analytic at t = t0, and the series (7) is called 
the Taylor series of f about t = t0 &bull; It can easily be shown that if j admits 
such an expansion, then, of necessity, an= j&lt;nl(t0)/ n!, where j&lt;nl(t) = 
d"j(t)j dtn. 
</p>
<p>7. The interval of convergence of the Tayior series of a functionj(t), about 
t 0 , can be determined directly through the Cauchy ratio test and other 
simiiar methods, or indirectly, through the following theorem of complex 
analysis. 
</p>
<p>Theorem 6. Let the variable t assume complex values, and Iet z0 be the point 
closest to t0 at which f or one of its derivatives fails to exist. Compute the 
distance p, in the complex plane, between t0 and z0 . Then, the Taylor series 
of f about t0 converges for I t- t0 I &lt; p, and diverges for I t- t0 I &gt; p. 
</p>
<p>As an illustration of Theorem 6, consider the function j( t) =I j(I + t 2 ). 
The Taylor series of f about t = 0 is 
</p>
<p>1 - 2 4 6 
--2 -I-t +t -t + ... , 
I+ t 
</p>
<p>and this series has radius of convergence one. Although the function 
(I+ t 2 )- 1 is perfectly weil behaved fort real, it goes to infinity when t = &plusmn; i, 
and the distance of each of these points from the origin is one. 
</p>
<p>A second application of Theorem 6 is that the radius of convergence of 
the Taylor series about t = 0 of the quotient of two poiynomiais a( t) and 
b( t ), is the magnitude of the smallest zero of b( t ). 
</p>
<p>At this point we make the important observation that it really wasn't 
necessary to assume that the functions P ( t), Q ( t), and R ( t) in (I) are poly-
nomials. The method used to solve Example I should also be applicable to 
the more general differential equation 
</p>
<p>d2y dy 
L[y]=P(t) dt 2 +Q(t) dt +R(t)y=O 
</p>
<p>where P(t), Q(t), and R(t) arepower series about t0 &bull; (Of course, we would 
expect the aigebra tobe much more cumbersome in this case.) If 
</p>
<p>P ( t) =Po+ P 1 ( t- to) + &middot; &middot; &middot; , 
R(t)=r0 +r1(t-t0)+ ... 
</p>
<p>andy(t) = a0 + a1(t- t0 )+ ... , then L[y](t) will be the sum of three power 
series about t = t0 &bull; Consequently, we should be able to find a recurrence 
formula for the coefficients an by setting the sum of the coefficients of Iike 
</p>
<p>189 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>powers of t in the expression L[y](t) equal to zero. This is the content of 
the following theorem, which we quote without proof. 
</p>
<p>Theorem 7. Let the functions Q(t)IP(t) and R(t)IP(t) have convergent 
Taylor series expansions about t = t0, for I t- t0l &lt; p. Then, every solution 
y(t) of the differential equation 
</p>
<p>d2y dy 
P(t) dt2 +Q(t) dt +R(t)y=O (8) 
</p>
<p>is analytic at t = t0, and the radius of convergence of its Taylor series ex-
pansion about t = t0 is at least p. The coefficients a2, a3, &bull;&bull;&bull; , in the Taylor 
series expansion 
</p>
<p>(9) 
</p>
<p>are determined by plugging the series (9) into the differential equation (8) 
and setting the sum of the coefficients of like powers of t in this expression 
equal to zero. 
</p>
<p>Remark. The interval of convergence of the Taylor series expansion of any 
solutiony(t) of (8) is determined, usually, by the interval of convergence of 
the power series Q (t) I P ( t) and R ( t) I P ( t), rather than by the interval of 
convergence of the power series P ( t), Q ( t), and R ( t). This is because the 
differential equation (8) must be put in the standard form 
</p>
<p>d2y dy 
- 2 +p(t)-d +q(t)y=O 
dt t 
</p>
<p>whenever we examine questions of existence and uniqueness. 
</p>
<p>Example 2. 
(a) Find two linearly independent solutions of 
</p>
<p>d 2Y 3t dy I 
L [ y J = dt2 + I + t2 dt + I + t2 y = O. (10) 
</p>
<p>(b) Find the solution y(t) of (10) which satisfies the initial conditions y(O) 
= 2, y'(O) = 3. 
Solution. 
(a) The wrong way to do this problern is to expand the functions 3tl(l + t2) 
and 1/(l+ t2) in power series about t=O. The right way to do this problern 
is to multiply both sides of (10) by 1 + t2 to obtain the equivalent equation 
</p>
<p>d2y dy 
L[y] =(1+t2)-+3t- +y=O. 
</p>
<p>dt2 dt 
</p>
<p>We do the problern this way because the algebra is much less cumbersome 
when the coefficients of the differential equation (8) are polynomials than 
</p>
<p>190 </p>
<p/>
</div>
<div class="page"><p/>
<p>208 Series solutions 
</p>
<p>when they arepower serieso Setting y(t)= ~ :=oantn, we compute 
</p>
<p>00 00 00 
</p>
<p>L[y](t)=(I+t2) ~ n(n-1)antn- 2 +3t ~ nantn-l+ ~ antn 
n=O n=O n=O 
</p>
<p>00 00 
</p>
<p>= ~ n ( n - 1) an t n- 2 + ~ [ n ( n - 1) + 3 n + 1 ] an t n 
n=O n=O 
</p>
<p>00 00 
</p>
<p>= ~ (n+2)(n+ 1)an+ 2t"+ ~ (n+ I)2antno 
n=O n=O 
</p>
<p>Setting the sum of the coefficients of Iike powers of t equal to zero gives 
(n+2)(n+ I)an+ 2 +(n+ 1ian=Oo Hence, 
</p>
<p>(n + 1)2an (n + I)an 
an+ 2 =- (n+2)(n+ I)=- n+2 
</p>
<p>(11) 
</p>
<p>Equation (11) is a recurrence formula for the coefficients a2, a3, 0 0 0 in terms 
of a0 and a 10 To find two linearly independent solutions of (10), we choose 
the two simplest cases (i) a0 = l, a 1 =0; and (ii) a0 =0, a 1 = l. 
</p>
<p>(i) a0 = l, a 1 =00 
</p>
<p>In this case, all the odd coefficients are zero since a3 = - 2a1/3 = 0, a5 = 
- 4a3/ 5 = 0, and so ono The even coefficients are determined from the rela-
tions 
</p>
<p>ao I 5a4 Io3 &deg; 5 
a =--=--
</p>
<p>2 2 2' 
a =--=---
</p>
<p>6 6 2&deg;4&deg;6 
</p>
<p>and so ono Proceeding inductively, we find that 
</p>
<p>n I 0 3 0 0 0 (2n- I) n 1 0 3 0 0 0 (2n- l) 
a2n = ( - I) 2 4 2 = (- I) 2n ' 0 0 0 0 o n no 
</p>
<p>Thus, 
</p>
<p>I 0 4 _ n 2n 2 I 3 Loo I 0 3 0 0 0 (2n- I) 
y 1(t)=I-2+ 204 1 +000- (-I) 2nn! t (12) 
</p>
<p>n=O 
</p>
<p>is one solution of (IO)o The ratio of the (n + I)st term to the nth term of 
y 1(t) is 
</p>
<p>Io3ooo(2n-I)(2n+1)t2n+ 2 2nn! 
-------------------x---~~-----
</p>
<p>2n+'(n+I)! Io3ooo(2n-I)t 2n 
</p>
<p>-(2n+ l)t2 
</p>
<p>2(n +I) 
</p>
<p>and the absolute value of this quantity approaches t 2 as n approaches in-
finityo Hence, by the Cauchy ratio test, theinfinite series (12) converges for 
Jtl &lt; l, and diverges for ltl &gt;I. 
</p>
<p>(ii) a0 =0, a 1 = l. 
</p>
<p>191 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>In this case, all the even coefficients are zero, and the odd coefficients are 
determined from the relations 
</p>
<p>2al 2 4a3 2&middot;4 6a5 2&middot;4&middot;6 
a3 = - -3- = - 3' a5 = - -5- = 3 &middot; 5 ' a1 = - 7 = - 3 &middot; 5 &middot; 7 ' 
</p>
<p>and so on. Proceeding inductively, we find that 
</p>
<p>Thus, 
</p>
<p>n 2&middot;4&middot; &middot; &middot; 2n 
a2n + I = ( - } ) -3 -=. 5:_&middot; ....:...., &middot;--,-( 2__;n::..:.+;__l_) 3 &middot; 5 .. &middot; (2n + 1) &middot; 
</p>
<p>&middot; _ 2 3 2&middot;4 5 _ 2:00 ( - 1Y2nn! 2n+l 
Y2(t)-t--3 t +-3 5 t + ... - ( )t &middot; 3 &middot; 5 .. &middot; 2n + 1 n-0 
</p>
<p>(13) 
</p>
<p>is a second solution of (10), and it is easily verified that this solution, too, 
converges for ltl &lt; 1, and diverges for ltl &gt; 1. This, of course, is not very 
surprising, since the Taylor series expansions about t = 0 of the functions 
3 t I (1 + t2) and 1 I (1 + t2) only converge for I tl &lt; 1. 
(b) The solutiony 1(t) satisfies the initial conditionsy(O)= l,y'(O)=O, while 
Yit) satisfies the initial conditions y(O) = 0, y'(O) = 1. Hence y(t) = 2y 1(t) + 
3ylt). 
</p>
<p>Example 3. Solve the initial-value problern 
</p>
<p>d2y dy 
L[y]=-+t2 -+2ry=O&middot; y(O)=l, y'(O)=O. 
</p>
<p>dt2 dt ' 
</p>
<p>Solution. Settingy(t)= L :.oantn, we compute 
00 00 00 
</p>
<p>L[y](t)= L n(n-l)antn- 2+t2 ~ nantn- 1+2t ~ antn 
n-0 n&bull;O n-0 
</p>
<p>00 00 00 
</p>
<p>= ~ n(n -l)antn- 2 + L nantn+ I+ 2 ~ antn+ I 
n&bull;O n=O n-0 
</p>
<p>00 00 
</p>
<p>= L n(n-l)antn- 2 + L (n+2)antn+l. 
n-o n=O 
</p>
<p>Our next step is to rewrite the first summation so that the exponent of the 
general term is n + 1 instead of n - 2. This is accomplished by increasing 
every n underneath the summation sign by 3, and decreasing the lower 
Iimit by 3; that is, 
</p>
<p>00 00 
</p>
<p>L n(n-l)antn- 2 = ~ (n+3)(n+2)an+ 3tn+l 
n&bull;O n&bull; -3 
</p>
<p>00 
</p>
<p>= L (n+3)(n+2)an+ 3tn+l. 
n&bull; -I 
</p>
<p>192 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.8 Series solutions 
</p>
<p>Therefore, 
00 00 
</p>
<p>L[y](l)= ~ (n+3)(n+2)an+Jin+l+ ~ (n+2)anln+l 
n=-1 n=O 
</p>
<p>00 00 
</p>
<p>=2a2+ ~ (n+3)(n+2)an+Jin+l+ ~ (n+2)anln+l. 
n=O n=O 
</p>
<p>Setting the sums of the coefficients of like powers of I equal to zero gives 
</p>
<p>2a2=0, and (n+3)(n+2)an+ 3 +(n+2)an=O; n=O, 1,2, ... 
</p>
<p>Consequently, 
</p>
<p>a2 =0, and n;) 0. (14) 
</p>
<p>The recurrence formula (14) determines a3 in terms of a0, a4 in terms of 
a1, a5 in terms of a2, and so on. Since a2 = 0, we see that a5,a8,a 11 , &bull;&bull;&bull; are all 
zero, regardless of the values of a0 and a1&bull; To satify the initial conditions, 
we set a0 = 1 and a1 =0. Then, from (14), a4,a1,a10, &bull;&bull;&bull; are all zero, while 
</p>
<p>0 o 1 &deg;3 1 &deg;6 1 
03 = - 3 = - 3' 06 = - 6 = 3 &middot; 6 ' 09 = - 9 = - 3 &middot; 6 &middot; 9 
</p>
<p>and so on. Proceeding inductively, we find that 
</p>
<p>(-lf (-l)n (-1( 
03n= 3&middot;6&middot;&middot;&middot;3n = 3nl&middot;2&middot;&middot;&middot;n = 3nn! &middot; 
</p>
<p>Hence, 
00 ( l)n 3n 
</p>
<p>13 16 19 ~ - I 
</p>
<p>Y ( t) = l - 3 + 3 &middot; 6 - 3 &middot; 6 &middot; 9 + &middot; &middot; &middot; = ~ 3nn! 
n=O 
</p>
<p>By Theorem 7, this series converges for all t, since the power series t2 and 
2t obviously converge for all t. (We could also verify this directly using the 
Cauchy ratio test.) 
</p>
<p>Example 4. Solve the initial-value problern 
</p>
<p>d2y dy 
L[y] =(12-2t)- +5(1-l)- +3y=O&middot; 
</p>
<p>dl2 dl ' 
y(l)=7, y'(1)=3. (15) 
</p>
<p>Solution. Since the initial conditions are given at t = 1, we will express the 
coefficients of the differential equation (15) as polynomials in ( t- l ), and 
then we will find y(t) as a power series centered about t = 1. To this end, 
observe that 
</p>
<p>t2-2t= t(l-2)= [(t-1)+ 1 ][(t-1)-1] =(t-1)2 -l. 
</p>
<p>Hence, the differential equation (15) can be written in the form 
</p>
<p>d2y dy 
L[yJ=[(t-1i-t] dl2 +5(t-1) dt +3y=O. 
</p>
<p>193 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>00 
</p>
<p>L[y](t)=[{t-1)2 -1] L n(n-1)an{t-1r- 2 
n=O 
</p>
<p>00 00 
</p>
<p>+ 5( t - 1) L nan ( t - 1 r- I + 3 L an (t - 1 f 
n=O n=O 
</p>
<p>00 
</p>
<p>=- L n(n-1)an{t-1r- 2 
n=O 
</p>
<p>00 00 
</p>
<p>+ L n(n -1)an(t -1f + L (Sn+ 3)an(t -1)n 
n=O n=O 
</p>
<p>00 00 
</p>
<p>=- L (n+2)(n+ 1)an+2 (t-1)n + L (n 2+4n+3)an(t-1( 
n=O n=O 
</p>
<p>Setting the sums of the coefficients of like powers of t equal to zero gives 
- (n + 2)(n + l)an+ 2 + (n 2 + 4n + 3)an = 0, so that 
</p>
<p>n2+4n+3 n+3 
an+2= (n+2)(n+l)an= n+2an, n ~0. (16) 
</p>
<p>To satisfy the initia1 conditions, we set a0 =7 and a 1 =3. Then, from (16), 
</p>
<p>and so on. Proceeding inductive1y, we find that 
</p>
<p>3&middot;5&middot; &middot; &middot; (2n+ I) 
a2 = &middot;7 and 
</p>
<p>n 2&middot;4 .. &middot; (2n) 
</p>
<p>4&middot;6&middot; &middot; &middot; (2n+2) 
a2n+l = &middot;3 
</p>
<p>3&middot;5&middot; &middot; &middot; (2n+ I) 
(for n ~I). 
</p>
<p>Hence, 
</p>
<p>3 ( 2 4 3 y(t)=7+3(t-1)+ 2'7 t-1) + 3&middot;3(t-1) + ... 
</p>
<p>_ ~ 00 3&middot;5 .. &middot;(2n+l)(t-1)2n _ ~ 00 2n(n+l)!(t-1)2n+l 
-7+7 2n 1 +3(1 1)+3 ( ) n. 3&middot;5&middot; &middot; &middot; 2n+ 1 
</p>
<p>n-1 n=l 
</p>
<p>Examp1e 5. Solve the initial-va1ue problern 
</p>
<p>d2y dy 
L[y]=(I-t) dt2 + dt +(I-t)y=O; y(0)=1, y'(O)=I. 
</p>
<p>Solution. Settingy(t)= L :=oantn, we compute 
</p>
<p>194 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.8 Series solutions 
</p>
<p>00 
</p>
<p>L ( y ] ( t) = ( 1 - t) ~ n ( n - 1) an t n- 2 
n=O 
</p>
<p>00 00 
</p>
<p>+ ~ nan t n- 1 + ( 1 - t) ~ an t n 
n=O n=O 
</p>
<p>00 00 
</p>
<p>= ~ n(n-I)antn- 2- ~ n(n-I)antn-l 
n=O n=O 
</p>
<p>00 00 00 
</p>
<p>+ ~ nan t n- I + ~ an t n- ~ an t n + I 
n=O n=O n=O 
</p>
<p>00 00 
</p>
<p>= ~ (n+2)(n+I)a"+ 2tn- ~ n(n-2)a"tn-l 
n=O n=O 
</p>
<p>00 00 
</p>
<p>+ ~ an t n- ~ an t n + I 
n=O n=O 
</p>
<p>00 00 
</p>
<p>= ~ (n+2)(n+ I)an+ 2tn- ~ (n+ I)(n-I)an+ltn 
n=O n=O 
</p>
<p>00 00 
</p>
<p>+ ~ an t n- ~ an- I t n 
n=O n=l 
</p>
<p>=2a2+a1+a0 
00 
</p>
<p>+ ~ { (n +2)(n + I)an+ 2-(n + I)(n -l)an+l +an- an- I }tn. 
n=l 
</p>
<p>Setting the coefficients of each power of t equal to zero gives 
</p>
<p>a1+a0 (n+I)(n-l)an+l-an+an-l 
a2=- -2- and an+2= (n+2)(n+ I) ' n ~ 1. 
</p>
<p>(17) 
</p>
<p>To satisfy the initial conditions, we set a0 = I and a1 = 1. Then, from (17), 
</p>
<p>I 
60' 
</p>
<p>I5a5 -a4 +a3 1 
a6 = 30 = 360 
</p>
<p>6' 
</p>
<p>and so on. Unfortunately, though, we cannot discern a general pattern for 
the coefficients an as we did in the previous examples. (This is because the 
coefficient an+ 2 depends on the values of an+ 1, a", and a"_ 1, while in our 
previous examples, the coefficient an+ 2 depended on only one of its prede-
cessors.) This is not a serious problem, though, for we can find the 
coefficients an quite easily with the aid of a digital computer. Sampie Pascal 
and Fortranprograms to compute the coefficients a2, ... ,an in terms of a0 
and a1, and to evaluate the "approximate" solution 
</p>
<p>Y ( f) ~ ao + a I t + ... + an t n 
195 </p>
<p/>
</div>
<div class="page"><p/>
<p>196 
</p>
<p>2 Second-order linear differential equations 
</p>
<p>at any point t are given below. These programs have variable values for a0 
and ap so they can also be used to solve the more general initial-value 
problern 
</p>
<p>d2y dy 
(1-t)-+-+(1-t)y=O&middot; y(O)=a0, y'(O)=a1&bull; 
</p>
<p>dt2 dt ' 
</p>
<p>Pascal Program 
</p>
<p>Program Series (input, output); 
</p>
<p>var 
A: array[O .. 199] of real; 
T, sum: real; 
k, N: integer; 
</p>
<p>begin 
readln(A[O], A[1], T, N); 
page; 
A[2] := -0.5 &bull; (A[1] + A[O]); 
sum :=A[O]+A[1] &bull; T +A[2] &bull; T &bull; T; 
for k : = 1 to N -2 do 
</p>
<p>begin 
A[k+2] := ((k + 1) &bull; (k-1) &bull; A[k + 1] -A[k] + A[k-1]) 
</p>
<p>/((k+ 1). (k+2)); 
sum :=sum+A[k+2] &bull; exp((k+2) &bull;ln(T)); 
</p>
<p>end; 
writeln ('For N =' , N:3, ' and T =' , T:6:4); 
writeln ('the sum is: ', sum:11 :9); 
</p>
<p>end. 
</p>
<p>10 
</p>
<p>20 
</p>
<p>30 
</p>
<p>Fortran Program 
</p>
<p>DIMENSION A(200) 
READ (5, 1 0) AO, A(1 ), T, N 
FORMAT (3F15.8, 15) 
A(2) = - 0.5 * (A(1) + AO) 
A(3) = (AO- A(1))/2. * 3. 
SUM =AO+ A(1)&bull; T + A(2)&bull; T * &bull;2 + A(3)&bull; T * * 3 
NA=N-2 
D020 K=2,NA 
A(K + 2) = (A(K -1)- A(K) + (K + 1 .) * (K -1 .) * 
A(K + 1}}/(K + 1.)* (K +2.) 
SUM=SUM +A(K+2)&bull;T&bull; &bull;(K+2) 
CONTINUE 
WRITE (6, 30) N, T, SUM 
FORMAT (1 H1, 'FOR N = ', 13, ', AND T= ', F10.4/1 H, 'THE 
SUM IS', F20.9) 
CALL EXIT 
END </p>
<p/>
</div>
<div class="page"><p/>
<p>2.8 Series solutions 
</p>
<p>See also C Program 14 in Appendix C for a sample C program. 
Setting A[O]=l, A[l]=l, (A(l)=l for the Fortran program), T=0.5, and 
N = 20 in these programs gives 
</p>
<p>This result is correct to eight significant decimal places, since any larger 
value of N yields the same result. 
</p>
<p>EXERCISES 
</p>
<p>Find the general solution of each of the following equations. 
</p>
<p>1. y"+ty'+y=O 
</p>
<p>3. (2+t 2)y"-ty'-3y=O 
</p>
<p>2.y"-ty=O 
</p>
<p>4. y"-t3y=O 
</p>
<p>Solve each of the following initial-value problems. 
</p>
<p>5. t(2-t)y"-6(t-I)y'-4y=O; y(l)=l, y'(l)=O 
</p>
<p>6.y"+t 2y=O; y(0)=2,y'(O)=-I 
</p>
<p>7. y"- t3y=O; y(O)=O, y'(O)= -2 
</p>
<p>8. y" +(t2 +2t+ I)y'-(4+4t)y =0; y( -1)=0, y'( -1)= I 
</p>
<p>9. The equation y" - 2ty' + ~ = 0, ,\ constant, is known as the Hermite differential 
equation, and it appears in many areas of mathematics and physics. 
(a) Find 2 linearly independent solutions of the Hermite equation. 
(b) Show that the Hermite equation has a polynomial solution of degree n if 
</p>
<p>,\ = 2n. This polynomial, when properly normalized; that is, when multi-
plied by a suitable constant, is known as the Hermite polynomial Hn(t). 
</p>
<p>10. The equation (1- t 2)y"- 2ty' + a(a + l)y = 0, a constant, is known as the 
Legendre differential equation, and it appears in many areas of mathematics 
and physics. 
(a) Find 2 linearly independent solutions of the Legendre equation. 
(b) Show that the Legendre differential equation has a polynomial solution of 
</p>
<p>degree n if a = n. 
(c) The Legendre polynomial Pn(t) is defined as the polynomial solution of the 
</p>
<p>Legendre equation with a = n which satisfies the condition Pn(l) = 1. Find 
P0(t), P 1(t), Pz(t), and P3(t). 
</p>
<p>11. The equation (I- t 2)y"- ty' + a2y =0, a constant, is known as the Tchebycheff 
differential equation, and it appears in many areas of mathematics and physics. 
(a) Find 2 linearly independent solutions of the Tchebycheff equation. 
(b) Show that the Tchebycheff equation has a polynomial solution of degree n 
</p>
<p>if a = n. These polynomials, when properly normalized, are called the 
Tchebycheff polynomials. 
</p>
<p>197 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>12. (a) Find 2 linearly independent solutions of 
</p>
<p>y" + t 3y' +3Py =0. 
</p>
<p>(b) Find the first 5 terms in the Taylor series expansion about t = 0 of the solu-
tion y(t) of the initial-value problern 
</p>
<p>y(O)=O, y'(O)=O. 
</p>
<p>In each of Problems 13-17, (a) Find the first 5 terms in the Taylor series 
expansion ~ :=oantn of the solution y(t) of the given initial-value prob-
lern. (b) Write a computer program to find the first N + 1 coefficients 
a0,a1, ... ,aN, and to evaluate the polynornial a0+a1t+ ... +aNtN. Then, 
</p>
<p>obtain an approximation of y(i) by evaluating ~ ~~oanC~r. 
</p>
<p>13. (I-t)y"+ty'+y=O; y(0)=1, y'(O)=O 
</p>
<p>14. y"+y'+ty=O; y(O)= -1, y'(0)=2 
</p>
<p>15.y"+ty'+e1y=O; y(0)=1,y'(0)=0 
</p>
<p>16. y"+y'+e 1y=O; y(O)=O, y'(O)= -1 
</p>
<p>17. y"+y'+e- 1y=O; y(0)=3, y'(0)=5 
</p>
<p>2.8.1 Singular points, Eu/er equations 
</p>
<p>The differential equation 
</p>
<p>d 2 d 
L[y) = P(t)----f + Q(t) dy + R(t)y = 0 
</p>
<p>dt t 
(1) 
</p>
<p>is said to be singular at t = t0 if P(t0 ) = 0. Solutions of (I) frequently 
become very large, or oscillate very rapidly, in a neighborhood of the 
singular point t 0 &bull; Thus, solutions of (1) may not even be continuous, Iet 
along analytic at t0 , and the method of power series solution will fail to 
work, in general. 
</p>
<p>Our goal is to find a dass of singular equations which we can solve for t 
near t 0 &bull; To this end we will first study a very simple equation, known as 
Euler's equation, which is singular, but easily solvable. We will then use the 
Euler equation to motivate a more general dass of singular equations which 
are also solvable in the vicinity of the singular point. 
</p>
<p>Definition. The differential equation 
</p>
<p>d 2 d 
L[y] = t 2 ____1_ + at1 + &szlig;y = 0. 
</p>
<p>dt2 dt 
(2) 
</p>
<p>where a and &szlig; are constants is known as Euler's equation. 
</p>
<p>198 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.8 Series solutions 
</p>
<p>We will assume at first, for simplicity, that t &gt; 0. Observe that t 2y" and 
ty' are both multiples of tr if y = tr. This suggests that we try y = tr as a 
</p>
<p>solution of (2). Computing 
</p>
<p>we see that 
</p>
<p>where 
</p>
<p>d 
- f r = rt r- I and 
dt 
</p>
<p>L[tr] = r(r -l)tr + artr + &szlig;tr 
</p>
<p>= [r(r -1)+ ar + &szlig;]tr 
</p>
<p>= F(r )tr 
</p>
<p>F( r) = r ( r - 1) + ar + &szlig; 
</p>
<p>=r 2 +(a-l)r+&szlig;. 
</p>
<p>(3) 
</p>
<p>(4) 
</p>
<p>Hence, y = t r is a solution of (2) if, and only if, r is a solution of the 
quadratic equation 
</p>
<p>r 2 +(a-l)r+&szlig;=O. (5) 
</p>
<p>The solutions r 1, r2 of (5) are 
</p>
<p>r 1 = - -! [ ( a - 1) + V ( a - 1) 2 - 4&szlig; ] 
</p>
<p>r2 = --! [ ( a- 1)- V ( a- 1 )2 - 4&szlig;). 
Just as in the case of constant coefficients, we must examine separately the 
cases where (a.-1) 2 -4&szlig; is positive, negative, and zero. 
</p>
<p>Case 1. ( a- I )2 - 4&szlig; &gt; 0. In this case Equation (5) has two real, unequal 
roots, and thus (2) has two solutions of the form y 1(t) = tr'. y2(t) = tr'. 
Clearly, tr' and tr' are independent if r 1 =I= r2 . Thus the general solution of 
(2) is (for t &gt; 0) 
</p>
<p>Example 1. Find the general solution of 
</p>
<p>L[y]=t 2 d 2y +4tdy +2y=O 
dt 2 dt ' 
</p>
<p>Solution. Substituting y = tr in (6) gives 
</p>
<p>L[tr] = r(r -J)tr +4rtr +2tr 
</p>
<p>=[r(r-1)+4r+2]tr 
</p>
<p>= (r 2 +3r +2)tr 
</p>
<p>=(r+l)(r+2)tr 
</p>
<p>t &gt;0. (6) 
</p>
<p>199 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>Hence r1 = -1, r2 = -2 and 
c c 
</p>
<p>y(t) = c1t- 1 + c2 t- 2 = ___!_ + _2 
t !2 
</p>
<p>is the genera1 solution of (6). 
</p>
<p>Case 2. (a-1)2 -4&szlig;=O. In this case 
</p>
<p>1-a 
rl=rz=-2-
</p>
<p>and we have only one solution y = t'&bull; of (2). A second solution (see Exercise 
11) can be found by the method of reduction of order. However, we would 
like to present here an altemate method of obtainingy2 which will generalize 
very nicely in Section 2.8.3. Observe that F(r) = (r- r1) 2 in the case of 
equal roots. Hence 
</p>
<p>(7) 
</p>
<p>Taking partial derivatives of both sides of (7) with respect to r gives 
</p>
<p>_!L[t'] = L[i_t'] = _! [(r- r )2 t']. 
ar ar ar I 
</p>
<p>Since a(t')jar = t'ln t, we see that 
</p>
<p>L[t'lnt] = (r- r1) 2 t'lnt +2(r- r1)t'. (8) 
</p>
<p>The right hand side of (8) vanishes when r = r1&bull; Hence, 
</p>
<p>L[t'&bull;lnt] =0 
</p>
<p>which implies that y2(t) = t'&bull;ln t is a second solution of (2). Since t'' and 
t'&bull;ln t are obviously linearly independent, the general solution of (2) in the 
case of equal roots is 
</p>
<p>Example 2. Find the general solution of 
</p>
<p>L[y] =t 2 d 2y -5tdy +9y=O 
dt 2 dt ' 
</p>
<p>Solution. Substituting y = t' in (9) gives 
</p>
<p>200 
</p>
<p>L[t']=r(r-1)t'-5rt'+9t' 
</p>
<p>= [r(r -1)-Sr +9]t' 
</p>
<p>= (r 2 -6r +9)t' 
</p>
<p>=(r-3)2 t'. 
</p>
<p>t&gt;O. (9) </p>
<p/>
</div>
<div class="page"><p/>
<p>2.8 Series solutions 
</p>
<p>The equation (r- 3)2 = 0 has r = 3 as a double root. Hence, 
y 1 ( t ) = t 3 , y2 ( t ) = t 31n t 
</p>
<p>and the general solution of (9) is 
</p>
<p>y(t}=(c1 +c2lnt}t3 , t&gt;O. 
</p>
<p>Case 3. ( a - I )2 - 4&szlig; &lt; 0. In this case. 
</p>
<p>r1 = A + iJ.t and r2 = A - iJ.t 
with 
</p>
<p>are complex roots. Hence, 
</p>
<p>cJ&gt;( t) = tA+ip. = t)\tip. 
</p>
<p>= ti\[ cos(J.tln t} + i sin(J.tln t }] 
is a complex-valued solution of (2). But then (see Section 2.2.1) 
</p>
<p>and 
</p>
<p>(10} 
</p>
<p>are two real-valued independent solutions of (2). Hence, the general solution 
of (2), in the case of complex roots, is 
</p>
<p>y( t} = ti\[ c1cos(J.tln t} + c2 sin(J.tln t}] 
with A and J.l. given by (10). 
</p>
<p>Example 3. Find the general solution of the equation 
</p>
<p>L[y] =t 2y"-5ty'+25y=O, t&gt;O. 
</p>
<p>Solution. Substituting y = t' in (II) gives 
</p>
<p>L[t'] = r(r -I}t' -5rt' +25t' 
</p>
<p>= [r(r -l}-5r +25] t' 
</p>
<p>= [r 2 -6r +25]t' 
</p>
<p>The roots of the equation r 2 -6r +25 = 0 are 
</p>
<p>6&plusmn;V36-wo 
---=---- = 3 &plusmn;4i 
</p>
<p>2 
</p>
<p>(11) 
</p>
<p>201 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>so that 
</p>
<p>&lt;!&gt;( t) = t3+4i = t3t4i 
= t3e(lnt)4i = t3ei(41nt) 
= t 3 [cos(4ln t) + isin(41n t )] 
</p>
<p>is a complex-valued solution of (11 ). Consequently, 
</p>
<p>y 1(t)=Re{&lt;t&gt;(t)}=t 3cos(41nt) 
</p>
<p>and 
</p>
<p>Y2( t) =Im { &lt;t&gt;( t)} = t 3sin( 4ln t) 
</p>
<p>are two independent solutions of (11), and the general solution is 
</p>
<p>y( t) = t 3[ c1cos(4ln t) + c2sin(4ln t )], t &gt; 0. 
Let us now return to the case t &lt; 0. One difficulty is that tr may not be 
</p>
<p>defined if t is negative. For example, ( -1YI 2 equals i, which is imaginary. A 
second difficulty isthat 1n t is not defined for negative t. We overcome both 
of these difficulties with the following clever change of variable. Set 
</p>
<p>t=-x, x&gt;O, 
</p>
<p>and 1et y = u( x ), x &gt; 0. Observe, from the chain ru1e, that 
</p>
<p>dy_dudx_ du 
</p>
<p>dt dx dt dx 
</p>
<p>and 
</p>
<p>Thus, we can rewrite (2) in the form 
</p>
<p>( z d 2 u ( du) -x) -+a(-x) -- +&szlig;u=O 
dx 2 dx 
</p>
<p>or 
</p>
<p>2 d 2 u du _ 
x --2 +ax-d +&szlig;u-0, 
</p>
<p>dx x 
x&gt;O (12) 
</p>
<p>But Equation (12) is exactly the same as (2) with t rep1aced by x and y 
replaced by u. Hence, Equation (12) has so1utions of the form 
</p>
<p>202 
</p>
<p>{
</p>
<p>C1Xr 1 + CzXr2 
u(x)= (c1 +c21nx)xr' 
</p>
<p>[ c1cos(ttln x) + c2 sin(ttln x)] x" 
(13) </p>
<p/>
</div>
<div class="page"><p/>
<p>2.8 Series solutions 
</p>
<p>depending on whether ( a- 1 )2 - 4&szlig; is positive, zero, or negative. Observe 
now that 
</p>
<p>x=-t=ltl 
</p>
<p>for negative t. Thus, for negative t, the solutions of (2) have one of the forms 
</p>
<p>{
cdti''+czltl'2 
</p>
<p>[c 1+c2 lnltl]ltl'' 
</p>
<p>[ c1cos(p.ln I tl) + c2sin(p.ln lt I)] lt I~ 
</p>
<p>Remark. The equation 
</p>
<p>(14) 
</p>
<p>is also an Euler equation, with a singularity at t = t0 instead oft= 0. In this 
case we look for solutions of the form (t- t 0 )'. Alternately, we can reduce 
(14) to (2) by the change of variable x = t- t 0 &bull; 
</p>
<p>EXERCISES 
</p>
<p>In Problems 1-8, find the general solution of the given equation. 
</p>
<p>1. t 2y"+5ty'-5y=O 
</p>
<p>3. ( t - 1) 2 y"- 2( f - 1) y I+ 2 y = 0 
</p>
<p>5. t 2y"-ty'+y=O 
</p>
<p>7. t 2y" + ty' + y = 0 
</p>
<p>9. Solve the initial-value problern 
</p>
<p>2. 2t 2y" + 3ty'- y = 0 
</p>
<p>4. t 2y"+3ty'+ y=O 
</p>
<p>6. (t-2) 2y"+5(t-2)y'+4y=O 
</p>
<p>8. t 2y"+3ty'+2y=O 
</p>
<p>t 2y"-ty'-2y=O; y(l)=O, y'(l)=l 
</p>
<p>on the interval 0 &lt; t &lt; oo. 
</p>
<p>10. Solve the initial-value problern 
</p>
<p>t 2y"-3ty'+4y=O; y(l)=l, y'(l)=O 
</p>
<p>on the interval 0 &lt; t &lt; oo. 
</p>
<p>11. Use the rnethod of reduction of order to show that y2(t) = t''ln t in the case of 
equal roots. 
</p>
<p>2.8.2 Regularsingular points, the method of Frobenius 
</p>
<p>Our goal now is to find a class of singular differential equations which is 
more general than the Euler equation 
</p>
<p>d 2y dlJ 
t 2 - + at..L + &szlig;y = 0 (1) 
</p>
<p>dt 2 dt 
</p>
<p>203 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>but which is also solvable by analytical techniques. To this end we rewrite 
(I) in the form 
</p>
<p>d2y +~ dy +_ly=O. 
dt2 t dt 12 
</p>
<p>(2) 
</p>
<p>A very natural generalization of (2) is the equation 
</p>
<p>L[y]=d2; +p(t)ddy +q(t)y=O 
dt t 
</p>
<p>(3) 
</p>
<p>where p( t) and q( t) can be expanded in series of the form 
</p>
<p>p(t)=Po+p,+p2t+p3t2+ ... 
t 
</p>
<p>( ) qo q, 2 q t = ii + t + q2 + q3t + q4t + ... (4) 
</p>
<p>Definition. The equation (3) is said to have a regular singular point at t = 0 
if p(t) and q(t) have series expansions of the form (4). Equivalently, t = 0 
is a regular singular point of (3) if the functions tp ( t) and t 2q( t) are 
analytic at t = 0. Equation (3) is said to have a regular singular point at 
t = t0 if the functions (t- t0 )p(t) and (t- t0 ) 2q(t) are analytic at t = t0 . 
A singular point of (3) which is not regular is called irregular. 
</p>
<p>Example 1. Classify the singular points of Bessel's equation of order 11 
</p>
<p>d 2y dy 
t 2-+t-+(t2 -11 2)y=O (5) 
</p>
<p>dt2 dt ' 
</p>
<p>where 11 is a constant. 
Solution. Here P( t) = t 2 vanishes at t = 0. Hence, t = 0 is the only singular 
point of (5). Dividing both sides of (5) by t 2 gives 
</p>
<p>d2y +_!.. dy +(1-~)y=O. 
dt2 t dt t2 
</p>
<p>Observe that 
</p>
<p>are both analytic at t = 0. Hence Bessel's equation of order 11 has a regular 
singular point at t = 0. 
</p>
<p>Example 2. Classify the singular points of the Legendre equation 
</p>
<p>2 d 2y dy 
(1-t )--2t-+a(a+1)y=O 
</p>
<p>dt 2 dt 
(6) 
</p>
<p>where a is a constant. 
Solution. Since 1- t 2 vanishes when t = 1 and -1, we see that (6) IS 
</p>
<p>204 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.8 Series solutions 
</p>
<p>singular at t = &plusmn; 1. Dividing both sides of (6) by 1- t 2 gives 
</p>
<p>d 2y _ _l!_ dy +a (a+l) y=O. 
dt 2 1- t 2 dt 1- t 2 
</p>
<p>Observe that 
</p>
<p>2t 2t 
(t -l)p(t) = -(t -1)--=-
</p>
<p>1- t2 1 + t 
and 
</p>
<p>2 ( t -I )2 1- t 
(t-1) q(t)=a(a+l) 1_ 12 =a(a+l) l+t 
</p>
<p>are analytic at t = 1. Similarly, both (t + l)p(t) and (t + 1)2q(t) are analytic 
at t = -1. Hence, t = 1 and t = -1 are regular singular points of (6). 
</p>
<p>Example 3. Show that t = 0 is an irregular singular point of the equation 
</p>
<p>d 2y dy 
t 2-+3-+ty=O. (7) 
</p>
<p>dt 2 dt 
</p>
<p>Solution. Dividing through by t 2 gives 
</p>
<p>d2y +1_ dy +.!_y=O. 
dt 2 t 2 dt t 
</p>
<p>In this case, the function 
</p>
<p>tp(t) = t( :2) = ~ 
is not analytic at t = 0. Hence t = 0 is an irregular singular point of (7). 
</p>
<p>W e return now to the equation 
</p>
<p>d 2y dy 
L[y] = - 2 + p(t)-d + q(t)y = 0 
</p>
<p>dt t 
(8) 
</p>
<p>where t = 0 is a regular singular point. For simplicity, we will restriet 
ourselves to the interval t &gt; 0. Multiplying (8) through by t 2 gives the 
equivalent equation 
</p>
<p>d 2 d 
L[y] = t 2__1_ + t(tp(t))2 + t 2q(t)y = 0. 
</p>
<p>dt 2 dt 
(9) 
</p>
<p>We can view Equation (9) as being obtained from (I) by adding higher 
powersoft to the coefficients a and &szlig;. This suggests that we might be able 
to obtain solutions of (9) by adding terms of the form tr+ 1, tr+ 2 , &bull;&bull;&bull; to the 
solutions tr of (1). Specifically, we will try to obtain solutions of (9) of the 
form 
</p>
<p>00 00 
</p>
<p>y( t) = ~ antn+r = tr ~ antn. 
n=O n=O 
</p>
<p>205 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>Example 4. Find two linearly independent solutions of the equation 
</p>
<p>d 2 d 
L[y] = 2t____l + 2 + ty = 0 
</p>
<p>dt2 dt ' 
O&lt;t&lt;oo. 
</p>
<p>Solution. Let 
00 
</p>
<p>y( t) = ~ antn+r, 
n=O 
</p>
<p>Computing 
00 
</p>
<p>y'(t)= ~ (n+r)antn+r-I 
n=O 
</p>
<p>and 
00 
</p>
<p>y"(t)= ~ (n+r)(n+r-l)antn+r- 2 
n=O 
</p>
<p>we see that 
</p>
<p>00 
</p>
<p>+ ~ [2(n + r )(n + r -l)an +(n + r )an+ an_ 2]tn+r-I 
n=2 
</p>
<p>Setting the coefficients of each power of t equal to zero gives 
</p>
<p>(i) 2r(r -l)a0 + ra0 = r(2r -l)a0 = 0, 
(ii) 2(r + l)ra1 +(r + l)a 1 = (r + 1)(2r + l)a 1 = 0, 
and 
</p>
<p>(10) 
</p>
<p>(iii) 2(n + r)(n + r -l)an +(n + r)an = (n + r)[2(n + r)-l]an =- an_ 2 , 
n;;;.2. 
</p>
<p>The first equation determines r; it implies that r = 0 or r = 1. The second 
equation then forces a1 tobe zero, and the third equation determines an for 
n;;;.2. 
</p>
<p>206 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.8 Series solutions 
</p>
<p>(i) r = 0. In this case, the recurrence formula (iii) is 
</p>
<p>-an-2 
an=n(2n-I)' 
</p>
<p>n-;;;.2. 
</p>
<p>Since a1 = 0, we see that all of the odd coefficients are zero. The even 
coefficients are determined from the relations 
</p>
<p>and so on. Setting a0 = 1, we see that 
</p>
<p>(2 (4 oo (-lft2n 
YJ(t)=l- 2&middot;3 + 2&middot;4&middot;3&middot;7 + ... =I+ n~l 2nn!3&middot;7&middot;&middot;&middot;(4n-l) 
</p>
<p>is one solution of (10). lt is easily verified, using the Cauchy ratio test, that 
this series converges for all t. 
</p>
<p>(ii) r =!. In this case, the recurrence formula (iii) is 
</p>
<p>- an-2 - an-2 
a = = n-;;;.2. 
</p>
<p>n (n+!)[2(n+!)-l] n(2n+l)' 
</p>
<p>Again, all of the odd coefficients are zero. The even coefficients are 
determined from the relations 
</p>
<p>- -ao -a2 ao - -a4- -ao 
a2- ~&middot; a4 = 4-9 = 2&middot;4&middot;5&middot;9' a6 - 6&middot;13- 2&middot;4&middot;6&middot;5&middot;9&middot;13 
</p>
<p>and so on. Setting a0 = 1, we see that 
</p>
<p>Y2(t)=t112[I- ;.25 + 2&middot;;&middot;45&middot;9 + ... ] 
</p>
<p>= tl/2 t + L - t [ oo ( l)n 1n l 
n=! 2nn!5&middot;9&middot;&middot;&middot;(4n+l) 
</p>
<p>is a second solution of (10) on the interval 0 &lt; t &lt; oo. 
</p>
<p>Remark. Multiplying both sides of (1 0) by t gives 
</p>
<p>2t1d1y +tdy +t2y=O. 
dt2 dt 
</p>
<p>This equation can be viewed as a generalization of the Euler equation 
</p>
<p>2t2d2y +tdy =0. 
dt 2 dt 
</p>
<p>Equation (11) has solutions of the formt', where 
</p>
<p>2r(r -1)+ r= 0. 
</p>
<p>( 11) 
</p>
<p>This equation is equivalent to Equation (i) which determined r for the 
solutions of (1 0). 
</p>
<p>207 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>Let us now see whether our technique, which is known as the method of 
Frobenius, works in general for Equation (9). (We will assume throughout 
this section that t &gt; 0.) By assumption, this equation can be written in the 
form 
</p>
<p>Set 
00 
</p>
<p>y( t) = ~ antn+r, With Go=/= 0. 
n=O 
</p>
<p>Computing 
00 
</p>
<p>y'(t)= ~ (n+r)antn+r- 1 
n=O 
</p>
<p>and 
00 
</p>
<p>y"( t) = ~ ( n + r )( n + r- 1 )antn+r-Z 
n=O 
</p>
<p>we see that 
</p>
<p>Multip1ying through and collecting terms gives 
</p>
<p>L[y] = [r(r -1)+ p0 r + q0]a 0 t' 
</p>
<p>+ { [ (1 + r )r + p0(l + r) + q0 ] a1 + ( rp 1 + q1 )a0 }t'+ 1 
</p>
<p>+ { [ ( n + r )( n + r -1) + p0 ( n + r) + q0] an 
</p>
<p>+ :~:[(k+r)Pn-k+qn-k]ak}tn+r 
</p>
<p>+ .... 
</p>
<p>This expression can be simp1ified if we set 
</p>
<p>F(r) = r(r -1)+ p0 r + q0 . 
</p>
<p>208 
</p>
<p>(12) </p>
<p/>
</div>
<div class="page"><p/>
<p>2.8 Series solutions 
</p>
<p>Then, 
</p>
<p>L [y) = a0 F( r )t' + [ a1 F( I+ r) + ( rp 1 + q 1 )a0] t 1 +r + 0 0 0 
</p>
<p>+ anF(n + r )tn+r + c~: [(k + r )Pn-k + qn-d ak}tn+r 
</p>
<p>+ 0000 
Setting the coefficient of each power of t equal to zero gives 
</p>
<p>F(r) = r(r -1)+ p0 r + q0 = 0 (13) 
and 
</p>
<p>n-1 
</p>
<p>F(n+r)an=- ~ [(k+r)Pn-k+qn-k]ak, n;;;a.l. (14) 
k=O 
</p>
<p>Equation (13) is called the indicial equation of (9)0 It is a quadratic 
equation in r, and its roots determine the two possible values r1 and r2 of r 
for which there may be solutions of (9) of the form 
</p>
<p>00 
</p>
<p>~ a tn+r 
~ n . 
</p>
<p>n=O 
</p>
<p>Note that the indicial equation (13) is exactly the equation we would obtain 
in looking for solutions t' of the Euler equation 
</p>
<p>2d2y dy -
t dt2 +Pot dt + qoy- 00 
</p>
<p>Equation (14) shows that, in general, an depends on r and all the preceding 
coefficients a0 , a 1,oo.,an-Io We can solve it recursively for an provided that 
F( I + r ), F(2 + r ), 0 0 0, F( n + r) are not zeroo Observe though that if F( n + r) 
= 0 for some positive integer n, then n + r is a root of the indicial equation 
(13)0 Consequently, if (13) has two real roots r1, r2 with r1 &gt; r2 and r1- r2 not 
an integer, then Equation (9) has two solutions of the form 
</p>
<p>00 00 
</p>
<p>YI(t)=t'' ~ an(r1)tn,yit)=t'2 ~ an(r2 )tn, 
n=O n=O 
</p>
<p>and these solutions can be shown to converge wherever tp(t) and t 2q(t) 
both convergeo 
</p>
<p>Remarko Wehave introduced the notation an(r1) and an(r2 ) to emphasize 
that an is determined after we choose r = r1 or r2 0 
</p>
<p>Example 5o Find the general solution of the equation 
</p>
<p>d 2y dy 
L[y] =4t-2 +3-d +3y=Oo 
</p>
<p>dt t 
(15) 
</p>
<p>209 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>Solution. Equation (15) has a regular singular point at t = 0 since 
</p>
<p>tp(t)=i and t 2q(t)=it 
</p>
<p>are both analytic at t = 0. Set 
00 
</p>
<p>y( t) = ~ antn+r, a0 =I= 0. 
n=O 
</p>
<p>Computing 
00 
</p>
<p>y'(t)= ~ (n+r)antn+r- 1 
n=O 
</p>
<p>and 
00 
</p>
<p>y"(t)= ~ (n+r)(n+r-1)antn+r- 2 
n=O 
</p>
<p>we see that 
</p>
<p>00 
</p>
<p>L[y] = 4 ~ (n + r )(n + r -1)antn+r- 1 
n=O 
</p>
<p>00 00 
</p>
<p>+3 ~ (n+r)antn+r- 1+3 ~ antn+r 
n=O n=O 
</p>
<p>00 00 
</p>
<p>= ~ [4(n+r)(n+r-1)+3(n+r)]antn+r- 1+ ~ 3an_ 1tn+r- 1. 
n=O n=l 
</p>
<p>Setting the sum of coefficients of 1ike powers of t equal to zero gives 
</p>
<p>4r(r -1)+3r = 4r 2 - r =r(4r -1) = 0 (16) 
and 
</p>
<p>[4(n + r)(n + r -1)+3(n + r)]an =(n + r)[4(n + r)-1]an = -3an-l&bull; 
</p>
<p>n ;;;.}. {17) 
</p>
<p>Equation (16) is the indicial equation, and it implies that r = 0 or r = i. 
Since these roots do not differ by an integer, we can find two solutions of 
(15) of the form 
</p>
<p>with an determined from (17). 
</p>
<p>r = 0. In this case the recurrence relation (17) reduces to 
</p>
<p>a = -3 an-1 
n 4n(n -1)+3n 
</p>
<p>-3an-1 
n(4n-1) &middot; 
</p>
<p>210 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.8 Series solutions 
</p>
<p>Setting a0 = 1 gives 
</p>
<p>- -3az- 2 
a 3 - 3-lT-- 3 -2-&middot; 3-.-7.-1-1 ' 
</p>
<p>_ -3a 3 _ 3 1 
a4 -4-15- 3 2&middot;3&middot;4&middot;7&middot;11&middot;15' 
</p>
<p>and, in general, 
</p>
<p>- (-1r3n-l 
an- ( ) &middot; n !7 &middot;11&middot;15 &middot; &middot; &middot; 4n -1 
</p>
<p>Hence, 
</p>
<p>oo ( 1)n3n-l 
Y (t)- ~ - tn 
</p>
<p>1 -n= 0 n!7&middot;11&middot;15&middot;&middot;&middot;(4n-1) 
(18) 
</p>
<p>is one solution of (15). lt is easily seen, using the Cauchy ratio test, that 
y 1(t) converges for all t. Hencey/t) is an analytic solution of (15). 
</p>
<p>r = t. In this case the recurrence relation ( 17) reduces to 
</p>
<p>-3an-I -3an-l 
a = = n;;;;.1 
</p>
<p>n (n +t)[4(n -t)+3] n(4n + 1)' &middot; 
</p>
<p>Setting a0 = 1 gives 
</p>
<p>-3 -33 
a~=-5-, a =-----
</p>
<p>3 2&middot;3&middot;5&middot;9&middot;13' 
</p>
<p>a = ... 
4 2&middot;3&middot;4&middot;5&middot;9&middot;13&middot;17' . 
</p>
<p>Proceeding inductively, we see that 
</p>
<p>_ ( -1f3n 
an- ( ) &middot; n!5&middot;9&middot;13&middot;&middot;&middot; 4n+1 
</p>
<p>Hence, 
</p>
<p>is a second solution of (15). It can easily be shown, using the Cauchy ratio 
test, that this Solution converges for allpositive t. Note, however, that rz(t) 
is not differentiab1e at t = 0. 
</p>
<p>The method of Frobenius hits a snag in two separate instances. The first 
instance occurs when the indicial equation (13) has equal roots r1 = r2 . In 
</p>
<p>211 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>this case we can only find one solution of (9) of the form 
</p>
<p>00 
</p>
<p>y,(t)=t'1 }: Gn(n. 
n=O 
</p>
<p>In the next section we will prove that (9) has a second solution Yi t) of the 
form 
</p>
<p>00 
</p>
<p>J2(t)= y 1(t)lnt+t' 1 }: bntn 
n=O 
</p>
<p>and show how to compute the coefficients bn. The computation of the bn is 
usually a very formidable problem. We wish to pointout here, though, that 
in many physical applications the solution yit) is rejected on the grounds 
that it is singular. Thus, it often suffices to find y 1(t) alone. It is also 
possible to find a second solution y2( t) by the method of reduction of order, 
but this too is usually very cumbersome. 
</p>
<p>The second snag in the method of Frobenius occurs when the roots r1, r2 
of the indicial equation differ by a positive integer. Suppose that r1 = r2 + N, 
where N is a positive integer. In this case, we can find one solution of the 
form 
</p>
<p>00 
</p>
<p>y,(t)=t'1 }: Gn(n. 
n=O 
</p>
<p>However, it may not be possible to find a second solution y2(t) of the form 
</p>
<p>00 
</p>
<p>y2(t)=t' 2 }: bntn. 
n=O 
</p>
<p>This is because F( r2 + n) = 0 when n = N. Thus, the left hand side of (14) 
becomes 
</p>
<p>N-1 
</p>
<p>O&middot;aN=- }: [(k+rz)PN-k+qN-k]ak 
k=O 
</p>
<p>when n = N. This equation cannot be satisfied for any choice of a N&bull; if 
</p>
<p>N-1 
</p>
<p>}: [(k+rz)PN-k+qN-k]ak~O. 
k=O 
</p>
<p>(19) 
</p>
<p>In this case (see Section 2.8.3), Equation (9) has a second solution of the 
form 
</p>
<p>00 
</p>
<p>J2(t)=y1(t)lnt+t' 2 }: bntn 
n=O 
</p>
<p>where again, the computation of the bn is a formidable problem. 
</p>
<p>212 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.8 Series solutions 
</p>
<p>On the other hand, if the sum on the right hand side of (19) vanishes, 
then aN is arbitrary, and we can obtain a second solution of the form 
</p>
<p>00 
</p>
<p>Y2(t)=t'2 ~ b"t". 
n=O 
</p>
<p>W e illustrate this situation with the following example. 
</p>
<p>Example 6. Find two solutions of Bessel's equation of order 1, 
d 2y dy 
</p>
<p>t 2-+t-+(t2-1j4)y=O O&lt;t&lt;oo. 
dt2 dt ' 
</p>
<p>Solution. This equation has a regular singular point at t = 0 since 
</p>
<p>tp(t)=1 and t 2q(t)=t2-t 
</p>
<p>are both analytic at t = 0. Set 
00 
</p>
<p>y(t)= ~ a"tn+r, a0 *0. 
n=O 
</p>
<p>Computing 
00 
</p>
<p>y'(t)= ~ (n+r)a"tn+r-l 
n=O 
</p>
<p>and 
00 
</p>
<p>y"(t)= ~ (n+r)(n+r-1)a"tn+r-Z 
n=O 
</p>
<p>we see that 
00 00 
</p>
<p>n=O n=O 
</p>
<p>00 00 
</p>
<p>+ "" a tn+r+2 -l "" a tn+r 
~ n 4 ~ n 
</p>
<p>n=O n=O 
</p>
<p>00 00 
</p>
<p>(20) 
</p>
<p>= ~ [(n+r)(n+r-I)+(n+r)-t]a"t"+'+ ~ a"_ 2tn+r. 
n=O n=2 
</p>
<p>Setting the sum of coefficients of like powers of t equal to zero gives 
</p>
<p>F(r )a0 = [r(r -1)+ r -t] a0 = (r 2 -i)a0 = 0 (i) 
</p>
<p>F( I + r ) a 1 = [ (I + r) r + ( 1 + r) - t] a 1 = [ (I + r ) 2 - t] a 1 = 0 ( ii) 
and 
</p>
<p>F( n + r )a" = [ ( n + r )2 - t] a" =- a"_ 2 , n ~ 2 (iii) 
Equation (i) is the indicial equation, and it implies that r1 = t, r2 =- t. 
r1 = t: Set a0 =I. Equation (ii) forces a 1 to be zero, and the recurrence 
</p>
<p>213 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>relation (iii) implies that 
</p>
<p>- an-2 - an-2 a - - n~2. 
n- F(n+!)- n(n+l)' 
</p>
<p>This, in turn, implies that all the odd coefficients a 3 , a 5 , &bull;&bull;&bull; , are zero, and 
the even coefficients are given by 
</p>
<p>-a0 -1 
a 2 =~-2&middot;3- 3! 
</p>
<p>_ - a2 _ 1 1 
a4 - 4-5- 2&middot;3&middot;4&middot;5 5! 
</p>
<p>-a -1 
a6 = 6 &middot; / = -2-&middot; 3-.-4-.-5-. 6-&middot;-7 7! 
</p>
<p>and so on. Proceeding inductively, we see that 
</p>
<p>Hence 
</p>
<p>_ (-1r 
a 2n- (2n)!{2n+l) 
</p>
<p>Y ( t)=t 1 1 2 (1-.c+~-~+ ... ) 
I 3! 5! 7! 
</p>
<p>is one solution of (20). This solution can be rewritten in the form 
</p>
<p>tl/2( t3 t5 11 ) 
Yl(t)=-~- t-3f+Sf-7! + ... 
</p>
<p>1 . 
= {t smt. 
</p>
<p>r2 = -1: Set a0 = 1. Since 1 + r2 = 1 is also a root of the indicial equation, 
we could, conceivably, run into trouble when trying to solve for a 1&bull; 
However, Equation (ii) is automatically satisfied, regardless of the value of 
a 1&bull; We will set a 1 = 0. (A nonzero value of a 1 will just reproduce a multiple 
of y 1(t)). The recurrence relation (iii) becomes 
</p>
<p>n~2. 
</p>
<p>All the odd coefficients are again zero, and the even coefficients are 
</p>
<p>214 
</p>
<p>_ -a0 _ 1 
a2-2T--2T 
</p>
<p>_ - a2 _ 1 
a4-o-- 4! 
</p>
<p>_ -a4 _ 1 
a6- "6-"5-- 6! </p>
<p/>
</div>
<div class="page"><p/>
<p>2.8 Series solutions 
</p>
<p>and so on. Proceeding inductively, we see that 
</p>
<p>(-1r 
a =--
</p>
<p>2n (2n)! 
</p>
<p>Hence, 
</p>
<p>is a second solution of (20). 
</p>
<p>Remark 1. If r is a complex root of the indicial equation, then 
00 
</p>
<p>y( t) = t' ~ antn 
n=O 
</p>
<p>is a complex-valued solution of (9). lt is easily verified in this case that both 
the real and imaginary parts of y( t) are real-valued solutions of (9). 
</p>
<p>Remark 2. W e must set 
00 
</p>
<p>y(t)=lti' ~ antn 
n=O 
</p>
<p>if we want to solve (9) on an interval where t is negative. The proof is 
exactly analogous to the proof for the Euler equation in Section 2.8.1, and is 
left as an exercise for the reader. 
</p>
<p>W e summarize the results of this section in the following theorem. 
</p>
<p>Theorem 8. Consider the differential equation (9) where t = 0 is a regular 
singular point. Then, the functions tp(t) and t 2q(t) are analytic at t = 0 
with power series expansions 
</p>
<p>which converge for I t I &lt; p. Let r1 and r2 be the two roots of the indicial 
equation 
</p>
<p>r( r - 1) + p0 r + q0 = 0 
</p>
<p>with r 1 ;;;;;. r2 if they are real. Then, Equation (9) has two linearly independent 
solutions y 1(t) and yz(t) on the interval 0 &lt; t &lt; p of the following form: 
(a) If r1 - r2 is notapositive integer, then 
</p>
<p>00 00 
</p>
<p>n=O n=O 
</p>
<p>215 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>(b) If r1 = r2 , then 
00 00 
</p>
<p>y 1(t)=t' 1 ~ ant\ Y2(t)=y,(t)lnt+t'1 ~ bntn. 
n=O n=O 
</p>
<p>(c) If r1 - r2 = N, a positive integer, then 
00 00 
</p>
<p>Y1(t)=t' 1 ~ ant\ y2(t)=ay1(t)Int+t'2 ~ bntn 
n=O n=O 
</p>
<p>where the constant a may turn out to be zero. 
</p>
<p>EXERCISES 
</p>
<p>In each of Problems 1-6, determine whether the specified value of t is a 
regular singular point of the given differential equation. 
</p>
<p>1. t(t-2) 2y"+ty'+ y=O; t=O 2. t(t-2) 2y"+ty'+ y=O; t=2 
</p>
<p>3. (sint)y"+(cost)y'+_!_y=O; t=O 4. (e 1 -l)y"+e 1y'+ y=O; t=O 
t 
</p>
<p>1 
5. (1- t 2 )y" + . y' + y = 0; t =-I 
</p>
<p>sm(t +I) -
</p>
<p>6. t 3y"+(sint 2 )y'+ty=O; t=O 
</p>
<p>Find the generat solution of each of the following equations. 
</p>
<p>7. 2t 2y"+3ty'-(l+t)y=O 8. 2ty"+(1-2t)y'- y=O 
</p>
<p>9. 2ty"+(l + t)y'-2y = 0 
11. 4ty"+3y'-3y = 0 
</p>
<p>10. 2t 2y"- ty' +(1 + t)y = 0 
</p>
<p>12. 2t2y"+(t 2 -t)y'+ y=O 
</p>
<p>In each of Problems 13-18, find two independent solutions of the given 
equation. In each problem, the roots of the indicial equation differ by a 
positive integer, but two solutionsexist of the form t'"i.'::=oantn. 
</p>
<p>13. t 2 y"-ty'-(t 2 +~)y=O 14. t 2y"+(t-t 2 )y'-y=O 
</p>
<p>15. ty"-(t 2 +2)y'+ty=O 16. t 2y"+(3t-t 2 )y'-ty=O 
</p>
<p>17. t 2y"+t(t+1)y'- y=O 18. ty"-(4+t)y'+2y=O 
</p>
<p>19. Consider the equation 
</p>
<p>(a) Show that r = 1 and r = 3 are the two roots of the indicial equation of ( * )-
(b) Find a power series solution of ( *) of the form 
</p>
<p>00 
</p>
<p>y 1(t)=t 3 ~ antn, a 0 =1. 
n=O 
</p>
<p>216 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.8 Series solutions 
</p>
<p>(c) Showthaty1(t)=t3e-1&bull; 
( d) Show that ( *) has no solution of the form 
</p>
<p>(e) Find a second solution of ( *) using the method of reduction of order. Leave 
your answer in integral form. 
</p>
<p>20. Consider the equation 
</p>
<p>t 2y" + ty'-(1+ t )y = 0. 
</p>
<p>(a) Show that r = -1 and r = 1 are the two roots of the indicial equation. 
(b) Find one solution of the form 
</p>
<p>00 
</p>
<p>Yi(t) = t ~ antn. 
n=O 
</p>
<p>(c) Find a second solution using the method of reduction of order. 
</p>
<p>21. Consider the equation 
</p>
<p>ty"+ty'+2y=O. 
</p>
<p>(a) Show that r = 0 and r = 1 are the two roots of the indicial equation. 
(b) Find one solution of the form 
</p>
<p>00 
</p>
<p>Yi(t) = t ~ antn. 
n=O 
</p>
<p>(c) Find a second solution using the method of reduction of order. 
</p>
<p>22. Consider the equation 
</p>
<p>ty"+(l- t 2 )y'+4ty = 0. 
</p>
<p>(a) Show that r = 0 is a double root of the indicial equation. 
(b) Find one solution of the form y 1( t) = ~~=o antn. 
(c) Find a second solution using the method of reduction of order. 
</p>
<p>23. Consider the Bessel equation of order zero 
</p>
<p>t 2y" + ty' + t 2y = 0. 
(a) Show that r = 0 is a double root of the indicial equation. 
(b) Find one solution of the form 
</p>
<p>12 t4 t6 
</p>
<p>Yi(t) = 1- 22 + 22&middot;42- 22&middot;42-62 + .... 
</p>
<p>This solution is known as J0(t). 
(c) Find a second solution using the method of reduction of order. 
</p>
<p>217 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>24. Consider the Bessel equation of order " 
</p>
<p>t2y" + ty' + ( (2- "2 )y = 0 
</p>
<p>where " is real and positive. 
(a) Find apower series solution 
</p>
<p>This function Jv( t) is called the Bessel function of order ". 
(b) Find a second solution if 2" is not an integer. 
</p>
<p>25. The differential equation 
</p>
<p>ty"+(l- t)y'+ ;\y = 0, ;\ constant, 
</p>
<p>is called the Laguerre differential equation. 
(a) Show that the indicial equation is r2 = 0. 
(b) Find a solutiony(t) of the Laguerre equation of the form ~;:"=oantn. 
( c) Show that this solution reduces to a polynomial if ;\ = n. 
</p>
<p>26. The differential equation 
</p>
<p>t ( 1 - t) y" + [ y - ( 1 + a. + &szlig;) t] y'- a&szlig; y = 0 
</p>
<p>where a., &szlig;, and y are constants, is known as the hypergeometric equation. 
(a) Show that t = 0 is a regular singu1ar point and that the roots of the indicial 
</p>
<p>equa tion are 0 and 1- y. 
(b) Show that t = 1 is also a regular singular point, and that the roots of the 
</p>
<p>indicial equation are now 0 and y - a.- &szlig;. 
(c) Assurne that y is not an integer. Find two solutions y 1(t) and y2(t) of the 
</p>
<p>hypergeometric equation of the form 
00 00 
</p>
<p>n=O n=O 
</p>
<p>27. (a) Show that the equation 
</p>
<p>2(sin t)y" +(I- t)y'-2y = 0 
</p>
<p>has two solutions of the form 
</p>
<p>00 00 
</p>
<p>n=O n=O 
</p>
<p>(b) Find the first 5 terms in these series expansions assuming that a 0 = b0 =I. 
</p>
<p>28. Lety(t)=u(t)+iv(t) be a complex-valued solution of (3) withp(t) and q(t) 
real. Show that both u(t) and v(t) are real-valued solutions of (3). 
</p>
<p>29. (a) Show that the indicial equation of 
</p>
<p>218 
</p>
<p>t 2y"+ty'+(1+t)y=O 
</p>
<p>has complex roots r = &plusmn; i. </p>
<p/>
</div>
<div class="page"><p/>
<p>2.8 Series solutions 
</p>
<p>(b) Show that ( *) has 2 linearly independent solutions y( t) of the form 
00 00 
</p>
<p>y(t)=sin(lnt) ~ antn+cos(lnt) ~ bntn. 
n=O n=O 
</p>
<p>2.8.3 Equal roots, and roots differing by an integer 
</p>
<p>Equal roots. 
We run into trouble if the indicial equation has equal roots r1 = r2 because 
then the differential equation 
</p>
<p>d 2y dy 
P(t)-2 + Q(t)-d + R(t)y = 0 (1) dt t 
</p>
<p>has only one solution of the form 
</p>
<p>(2) 
n=O 
</p>
<p>The method of finding a second solution is very similar to the method used 
in finding a second solution of Euler's equation, in the case of equal roots. 
Let us rewrite (2) in the form 
</p>
<p>00 
</p>
<p>y(t)=y(t,r)=t'}: an(r)tn 
n=O 
</p>
<p>to emphasize that the solution y(t) depends on our choice of r. Then (see 
Section 2.8.2) 
</p>
<p>L[y ](t, r) = a0 F(r )t' 
</p>
<p>+ n~l {an(r)F(n+r)+ :~~[(k+r)Pn-k+qn-k]ak}tn+r. 
</p>
<p>We now think of ras a continuous variable and determine an as a function 
of r by requiring that the coefficient of tn+r be zero for n ;;;.I. Thus 
</p>
<p>n-1 
</p>
<p>-}: [(k+r)Pn-k+qn-k]ak 
an( r) = ___:k.::..._=_:O:.....__-:----:-----
</p>
<p>F(n + r) 
With this choice of an( r ), we see that 
</p>
<p>L[y ](t, r) = a0 F(r )t'. (3) 
</p>
<p>In the case of equal roots, F(r) = (r- r1) 2 , so that (3) can be written in the 
form 
</p>
<p>L[y ](t, r) = a0(r- r1) 2t'. 
</p>
<p>Since L[y](t, r 1) = 0, we obtain one solution 
</p>
<p>y1(t)=t''[ao+ n~l an(rl)t+ 
</p>
<p>219 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>Observe now, that 
</p>
<p>;,L[y ](t, r) = L[ ~~ ](t, r) 
- a ( )2 r - a,ao r- rl t 
</p>
<p>= 2a0( r- r1 )t' + a0( r- r1 ) 2(ln t )t' 
</p>
<p>also vanishes when r = r 1&bull; Thus 
a 
</p>
<p>Y2(t)= arYJ(t,r)i,=r, 
</p>
<p>= ;, [n~O an(r)tn+l=r, 
00 00 
</p>
<p>= ~ [an(rl)tn+r,]lnt+ ~ a~(r 1 )tn+r, 
n=O n=O 
</p>
<p>00 
</p>
<p>=y1(t)lnt+ ~ a~(r 1 )tn+r, 
n=O 
</p>
<p>is a second solution of (I). 
</p>
<p>Example 1. Find two solutions of Bessel's equation of order zero 
</p>
<p>L[y]=t2d 2y +tdy +t2y=O t&gt;O. 
dt2 dt ' 
</p>
<p>Solution. Set 
00 
</p>
<p>y( t) = ~ antn+r. 
n=O 
</p>
<p>Computing 
00 
</p>
<p>y'(t)= ~ (n+r)antn+r-J 
n=O 
</p>
<p>and 
00 
</p>
<p>y"(t)= ~ (n+r)(n+r-l)antn+r- 2 
n=O 
</p>
<p>we see that 
</p>
<p>00 00 00 
</p>
<p>(4) 
</p>
<p>L[y]= ~ (n+r)(n+r-I)antn+r+ ~ (n+r)antn+r+ ~ antn+r+2 
n=O n=O n=O 
</p>
<p>00 00 
</p>
<p>= ~ ( n + r )2 antn+r + ~ an-2tn+r. 
n=O n=2 
</p>
<p>220 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.8 Series solutions 
</p>
<p>Setting the sums of like powers of t equal to zero gives 
</p>
<p>(i) r 2a0 =F(r)a0 =0 
(ii) (1 + r)2a 1 = F(l + r)a 1 = 0 
</p>
<p>and 
(iii) (n + r)2an = F(n + r)an =- an_ 2 , n;;;. 2. 
</p>
<p>Equation (i) is the indicial equation, and it has equal roots r1 = r2 = 0. 
Equation (ii) forces a 1 tobe zero, and the recurrence relation (iii) says that 
</p>
<p>-an-2 
an= 2. 
</p>
<p>(n +r) 
</p>
<p>Clearly, a3 = a5 = a 7 = &middot; &middot; &middot; = 0. The even coefficients are given by 
</p>
<p>-a -1 
a2(r)= (2+ro)2 = (2+r)2 
</p>
<p>- a 2 1 a 4 ( r) = = --....,--------,-
(4+ r )2 (2+ r )2(4+ r f 
</p>
<p>and so on. Proceeding inductively, we see that 
</p>
<p>_ (-1r 
a2n( r)- 2 2 2 &bull; 
</p>
<p>(2+r) (4+r) &middot; &middot; &middot; (2n+r) 
</p>
<p>Todetermine y 1(t), we set r = 0. Then 
</p>
<p>and in general 
</p>
<p>Hence, 
</p>
<p>-1 
a2(0)=-2 
</p>
<p>2 
1 I 1 
</p>
<p>a4(0) = 22-42 = 24 (2!)2 
</p>
<p>-1 -1 
a (o)----
</p>
<p>6 - 22-42-62 26(3!)2 
</p>
<p>t2 t4 
</p>
<p>YI(t)=l- 22 + 4 ( )2 
2. 2! 
</p>
<p>oo (-lft2n 
~ 2 
</p>
<p>n=O 22n(n!) 
</p>
<p>is one solution of ( 4). This solution is often referred to as the Bessel function 
of the first kind of order zero, and is denoted by J0( t ). 
</p>
<p>221 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>To obtain a second solution of (4) we set 
00 
</p>
<p>Y2(t)=yl(t)Int+ ~ a;n(O)t 2n. 
n=O 
</p>
<p>To compute a;n(O), observe that 
</p>
<p>a;n(r) d d -2 ( )-2 
--( -) = -d Inla 2n(r )I= -d ln(2+ r) .. &middot; 2n + r 
a2n r r r 
</p>
<p>d 
= -2 dr [In(2+ r )+ ln(4+ r )+ .. &middot; + ln(2n + r )] 
</p>
<p>=-2(-I-+_I_+ ... +-I-). 
2+r 4+r 2n+r 
</p>
<p>Hence, 
</p>
<p>a' (0) = - 2 ( _!_ + _!_ + .. &middot; + _I ) a (0) 2n 2 4 2n 2n 
</p>
<p>Setting 
</p>
<p>I I I 
H =I+-+-+ ... +-
</p>
<p>n 2 3 n 
</p>
<p>we see that 
</p>
<p>a I (0) - _-_H...::._n ('------,I ):.._n 
2n - 2 ( )2 2 n n! 
</p>
<p>and thus 
</p>
<p>(-Ir+ IHn 
</p>
<p>22n(n!)2 
</p>
<p>is a second soiution of (4) with Hn given by (5). 
</p>
<p>(5) 
</p>
<p>Roots differing by a positive integer. Suppose that r2 and r1 = r2 + N, N a 
positive integer, are the roots of the indicial equation. Then we can certainly 
find one solution of (I) of the form 
</p>
<p>00 
</p>
<p>YI(t) = 1'1 L an(r1)tn. 
n~O 
</p>
<p>As we mentioned previousiy, it may not be possible to find a second 
solution of the form 
</p>
<p>222 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.8 Series solutions 
</p>
<p>In this case, Equation (1) will have a second solution of the form 
</p>
<p>Y2 ( t) = :r Y ( t' r) Ir~ '2 
00 
</p>
<p>=ay1(t)lnt+ L a~(r 2 )tn+r2 
n~O 
</p>
<p>where a is a constant, and 
00 
</p>
<p>y(t, r) = t' ~ an(r )tn 
n=O 
</p>
<p>with 
a0 = a0( r) = r- r2 &bull; 
</p>
<p>The proof of this result can be found in more advanced books on differen-
tial equations. In Exercise 5, we develop a simple proof, using the method of 
reduction of order, to show why a logarithm term will be present. 
</p>
<p>Remark. It is usually very difficult, and quite cumbersome, to obtain the 
second solution J2{t) when a logarithm term is present. Beginning and 
intermediate students are not expected, usually, to perform such calcula-
tions. Wehave included several exercises for the more industrious students. 
In these problems, andin similar problems which occur in applications, it is 
often more than sufficient to find just the first few terms in the series 
expansion of y2 ( t ), and this can usually be accomplished using the method 
of reduction of order. 
</p>
<p>EXERCISES 
</p>
<p>In Problems 1 and 2, show that the roots of the indicial equation are equal, 
and find two independent solutions of the given equation. 
</p>
<p>1. ty"+y'-4y=O 
</p>
<p>2. t 2y"-t(l+t)y'+ y=O 
</p>
<p>3. (a) Show that r =-I and r =I are the roots of the indicial equation for Bessel's 
equation of order one 
</p>
<p>(b) Find a solution: 
00 
</p>
<p>J1(t)=tt ~ antn,a 0 =l. 
n=O 
</p>
<p>J1(t) is called the Bessel function of order one. 
(c) Find a second solution: 
</p>
<p>( t)=-J(t)lnt+.![l- ~ (-lr(Hn+Hn-I) 1zn]. 
Yz I 1 .(", z2n !( -J)! n=] n. n . 
</p>
<p>223 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>4. Consider the equation 
</p>
<p>ty"+3y'-3y=O, t&gt;O. 
</p>
<p>( a) Show that r = 0 and r = -2 are the roots of the indicial equation. 
(b) Find a solution 
</p>
<p>00 
</p>
<p>Yt(t) = ~ antn. 
n=O 
</p>
<p>(c) Find a second solution 
</p>
<p>_ I 1 I II 31 2 
Y2(t)-yl(t)Int+~-t+4+ 36 1+ 576 1 + ... &middot; 
</p>
<p>5. This exercise gives an alternate proof of some of the results of this section, using 
the method of reduction of order. 
(a) Let t = 0 be a regular singular point of the equation 
</p>
<p>t2y"+ tp(t)y'+ q(t)y= 0 (i) 
</p>
<p>Show that the Substitution y = trz reduces (i) to the equation 
</p>
<p>t 2z"+[2r+ p(t)]tz'+[r(r-1)+ rp(t)+ q(t)]z = 0. (ii) 
</p>
<p>(b) Let r be a root of the indicial equation. Show that (ii) has an analytic 
solution z1(t) = ~~=oant". 
</p>
<p>(c) Set z2(t) = z1(t)v(t). Show that 
</p>
<p>v(t)= ju(t)dt, 
e- f[2r+p(t)]/tdt 
</p>
<p>where u( t) = ---2---
z1 (t) 
</p>
<p>( d) Suppose that r = r0 is a double root of the indicial equation. Show that 
2r0 +Po= I, and conclude therefore that 
</p>
<p>(e) Use the result in (d) to show that Y2(t) has an In t term in the case of equal 
roots. 
</p>
<p>(f) Suppose the roots of the indicial equation are r0 and r0 - N, N a positive 
integer. Show that 2r0 + p 0 = 1 + N, and conclude therefore, that 
</p>
<p>u(t) = 1 ~Nu(t) 
t 
</p>
<p>where il(t) is analytic at t = 0. 
(g) Use the result in (f) to show that y2(t) has an In t term if the coefficient of tN 
</p>
<p>in the expansion of il(t) is nonzero. Show, in addition, that if this coefficient 
is zero, then 
</p>
<p>( ) V_N V_l 2 v t =7+ ... +-t-+vtt+v2t + ... 
</p>
<p>and Y2( t) has no In t term. 
</p>
<p>224 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.9 The method of Laplace transforms 
</p>
<p>2.9 The method of Laplace transforms 
</p>
<p>In this section we describe a very different and extremely clever way of 
solving the initial-value problern 
</p>
<p>d2y dy 
a dt2 +b dt +cy=j(t); y(O)=yo, y'(O)=y~ (!) 
</p>
<p>where a, b and c are constants. This method, which is known as the 
method of Laplace transforms, is especially useful in two cases which arise 
quite often in applications. The first case is when f(t) is a discontinuous 
function of time. The second case is when f(t) is zero except for a very 
short time interval in which it is very !arge. 
</p>
<p>To put the method of Laplace transforms into proper perspective, we 
consider the following hypothetical situation. Suppose that we want to 
multiply the numbers 3.163 and 16.38 together, but that we have forgotten 
completely how to multiply. We only remernher how to add. Being good 
mathematicians, we ask ourselves the following question. 
</p>
<p>Question: Is it possible to reduce the problern of multiplying the two num-
bers 3.163 and 16.38 together to the simpler problern of adding two num-
bers together? 
</p>
<p>The answer to this question, of course, is yes, and is obtained as follows. 
First, we consult our logarithm tables and find that In 3.163 = 1.15152094, 
and ln 16.38 = 2.79606108. Then, we add these two numbers together to 
yield 3.94758202. Finally, we consult our anti-logarithm tables and find 
that 3.94758202 = ln 51.80994. Hence, we conclude that 3.163 x 16.38 = 
51.80994. 
</p>
<p>The key point in this analysis is that the operation of multiplication is 
replaced by the simpler operation of addition when we work with the loga-
rithms of numbers, rather than with the numbers themselves. We represent 
this schematically in Table 1. In the method to be discussed below, the un-
known functiony(t) will be replaced by a new function Y(s), known as the 
Laplace transform of y(t). This association will have the property thaty'(t) 
will be replaced by sY(s)-y(O). Thus, the operation of differentiation with 
respect to t will be replaced, essentially, by the operation of multiplication 
with respect to s. In this manner, we will replace the initial-value problern 
(l) by an algebraic equation which can be solved explicitly for Y(s). Once 
we know Y (s), we can consult our "anti-Laplace transform" tables and re-
cover y(t). 
</p>
<p>Table I 
</p>
<p>a 
</p>
<p>b 
</p>
<p>a&middot;b 
</p>
<p>ina 
inb 
Ina+inb 
</p>
<p>225 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>We begin with the definition of the Laplace transform. 
</p>
<p>Definition. Let f(t) be defined for 0 ~ t &lt; oo. The Laplace transform of 
f(t), which is denoted by F(s), or e{j(t)}, is given by the formula 
</p>
<p>F(s) = e {J( t)} = {") e -srf( t) dt (2) 
where 
</p>
<p>(
00 e-stj(t)dt = }im (A e-stj(t)dt. 
</p>
<p>Jo A---+oo Jo 
</p>
<p>Example 1. Compute the Laplace transform of the function f(t) = 1. 
Solution. From (2), 
</p>
<p>e {f ( t) } = }im r A e - s/ dt = }im 
A---+oo ) 0 A---+oo 
</p>
<p>={~' s&gt;O 
oo, s ~ 0 
</p>
<p>I- e-sA 
</p>
<p>s 
</p>
<p>Example 2. Compute the Lapiace transform of the function ea1&bull; 
Solution. From (2), 
</p>
<p>l 
I 
</p>
<p>= s-a' 
oo, 
</p>
<p>s&gt;a 
</p>
<p>s~a 
</p>
<p>Example 3. Compute the Laplace transform of the functions cos wt and 
sinwt. 
Solution. From (2), 
</p>
<p>q coswt} = fo 00 e-s/ coswt dt and ef sinwt} = fooo e-s/ sinwtdt. 
</p>
<p>Now, observe that 
</p>
<p>e { COS Wt} + ie { sinwt} = ( 00 e -steiwt dt = lim (A e(iw-s)t dt 
Jo A---+oo Jo 
</p>
<p>. e(iw-s)A- I 
= hm .::.._ __ --~ 
</p>
<p>A---+oo zw-s 
</p>
<p>{ 
I s+ iw 
</p>
<p>= s - iw = s2 + w2 ' 
undefined, 
</p>
<p>s&gt;O 
</p>
<p>s~O 
</p>
<p>226 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.9 The method of Laplace transforms 
</p>
<p>Equating real and imaginary parts in this equation gives 
</p>
<p>E{coswt}= ~ and E{sinwt}= A, s&gt;O. 
s +w s +w 
</p>
<p>Equation (2) associates with every function f(t) a new function, which 
we call F(s). As the notation E{!(t)} suggests, the Laplace transform is an 
operator acting on functions. lt is also a linear operator, since 
</p>
<p>e{ ctfl (t) + c2f2 (t)} = foooe-st[ ctfl (t) + cd2 (t)] dt 
</p>
<p>=Cl fo 00 e -stjl (t) dt + C2 fooo e -stj2 ( t) dt 
</p>
<p>= cle{fl (t)} + c2e{f2 (t) }. 
</p>
<p>lt is to be noted, though, that whereas f(t) is defined for 0..;; t &lt; oo, its 
Laplace transform is usually defined in a different interval. For example, 
the Laplace transform of e21 is only defined for 2 &lt; s &lt; oo, and the Laplace 
transform of e81 is only defined for 8 &lt; s &lt; oo. This is because the integral 
(2) will only exist, in general, if s is sufficiently large. 
</p>
<p>One very serious difficulty with the definition (2) is that this integral 
may fail to exist for every value of s. This is the case, for example, if f(t) = 
e 12 (see Exercise 13). To guarantee that the Laplace transform of f(t) exists 
at least in some interval s &gt; s0, we impose the following conditions on f(t). 
(i) The function f(t) is piecewise continuous. This means that f(t) has at 
</p>
<p>most a finite number of discontinuities on any interval 0..;; t..;; A, and 
both the limit from the right and the limit from the left of fexist at ev-
ery point of discontinuity. In other words,f(t) has only a finite number 
of ')ump discontinuities" in any finite interval. The graph of a typical 
piecewise continuous functionf(t) is described in Figure 1. 
</p>
<p>y 
</p>
<p>Figure I. Graph of a typical piecewise continuous function 
</p>
<p>227 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>(ii) The function f(t) is of exponential order, that is, there exist constants 
M and c such that 
</p>
<p>jj(t)j&lt; Mect, O&lt;t&lt;oo. 
</p>
<p>Lemma 1. lf f(t) is piecewise continuous and of exponential order, then its 
Laplace transform exists for all s sufficiently !arge. Specifically, if f(t) is 
</p>
<p>piecewise continuous, and if(t)j&lt; Mec1, then F(s) exists for s &gt; c. 
</p>
<p>We prove Lemma 1 with the aid of the following Iemma from integral 
calculus, which we quote without proof. 
</p>
<p>Lemma 2. Let g(t) be piecewise continuous. Then, the improper integral 
</p>
<p>Jooo g(t)dt exists if foooi g(t)j dt exists. To prove that this latter integral ex-
ists, it suffices to show that there exists a constant K such that 
</p>
<p>foAig(t)jdt&lt; K 
</p>
<p>for all A. 
</p>
<p>Remark. Notice the similarity of Lemma 2 with the theorem of infinite 
</p>
<p>series (see Appendix B) which states that theinfinite series ~an converges 
</p>
<p>if ~ ianl converges, and that ~ lanl converges if there exists a constant K 
suchthat jad + ... + ianl &lt; K for all n. 
</p>
<p>We are now in a position to prove Lemma 1. 
</p>
<p>PROOF OF LEMMA 1. Since f(t) is piecewise continuous, the integral 
</p>
<p>JoA e-s1f(t)dt exists for all A. To prove that this integral has a Iimit for all s 
</p>
<p>sufficiently large, observe that 
</p>
<p>foAie-s'f(t)j dt.;;; M foA e -stect dt 
</p>
<p>= _M_ [ e&lt;c-s)A _ 1 J.;;; _M_ 
e-s s-c 
</p>
<p>for s &gt; c. Consequently, by Lemma 2, the Laplace transform of f(t) exists 
for s &gt; c. Thus, from here on, we tacitly assume that jj(t)j.;;; Mec1, and 
s&gt;c. D 
</p>
<p>The real usefulness of the Laplace transform in solving differential 
equations lies in the fact that the Laplace transform of f'(t) is very closely 
related to the Laplace transform of f(t). This is the content of the follow-
ing important Iemma. 
</p>
<p>228 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.9 The method of Laplace transforms 
</p>
<p>Lemma 3. Let F(s)= E{f(t)}. Then 
</p>
<p>E{J'(t)} = sE{J(t)}-1(0) = sF(s)-1(0). 
</p>
<p>PROOF. The proof of Lemma 3 is very elementary; we just write down the 
formula for the Laplace transform of f'(t) and integrate by parts. To wit, 
</p>
<p>E{J'(t)} = lim (A e- 51j'(t)dt 
A~oo Jo 
</p>
<p>A lA = lim e -st1( t)J + lim s e -st1( t) dt 
A~oo 0 A~oo 0 
</p>
<p>= - 1(0) + s lim (A e -st1( t), dt 
A~oo Jo 
</p>
<p>=-1(0) + sF(s). D 
</p>
<p>Our next step is to relate the Laplace transform of j"(t) to the Laplace 
transform of 1(t). This is the content of Lemma 4. 
</p>
<p>Lemma 4. Let F(s)= E{f(t)}. Then, 
</p>
<p>E{J"(t)} = s2F(s)- s1(0)- j'(O). 
</p>
<p>PRooF. Using Lemma 3 twice, we see that 
</p>
<p>E{J"(t)} =sE{J'(t)}- j'(O) 
</p>
<p>=s[ sF(s)-1(0)]-j'(O) 
</p>
<p>=s2F(s) -s1(0)-j'(O). D 
</p>
<p>Wehave now developed all the machinery necessary to reduce the prob-
lern of solving the initial-value problern 
</p>
<p>d2y dy 
a dt2 + b dt + cy = 1 ( t); Y (0) = Yo&bull; y'(O) = Yb (3) 
</p>
<p>tothat of solving an algebraic equation. Let Y(s) and F(s) be the Laplace 
transforms of y(t) andf(t) respectively. Taking Laplace transforms of both 
sides of the differential equation gives 
</p>
<p>E{ ay"( t) + by'(t) + cy( t)} = F(s). 
</p>
<p>By the linearity of the Laplace transform operator, 
</p>
<p>e{ ay"(t) + by'(t) + cy(t)} = aE{ y"( t)} + be{y'(t)} + cE{y(t) }, 
</p>
<p>229 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>and from Lemmas 3 and 4 
</p>
<p>e{y'(t)} =sY(s)-y0, 
</p>
<p>Hence, 
</p>
<p>and this algebraic equation implies that 
</p>
<p>(as+ b)y0 ay0 F(s) 
Y(s)= + + . (4) 
</p>
<p>as2 + bs + c as2 + bs + c as2 + bs + c 
</p>
<p>Equation (4) tells us the Laplace transform of the solutiony(t) of (3). To 
find y(t), we must consult our anti, or inverse, Laplace transform tables. 
Now, just as Y(s) is expressed explicitly in terms of y(t); that is, Y(s) 
</p>
<p>= Jo 00e-'1y(t)dt, we can write down an explicit formula for y(t). However, 
this formula, which is written symbolically as y(t)= e- 1{ Y(s)}, involves 
an integration with respect to a complex variable, and this is beyond the 
scope of this book. Therefore, instead of using this formula, we will derive 
several elegant properties of the Laplace transform operator in the next 
section. These properties will enable us to invert many Laplace transforms 
by inspection; that is, by recognizing "which functions they are the 
Laplace transform of". 
</p>
<p>Example 4. Solve the initial-value problern 
</p>
<p>d2y dy 
--3- +2y=e31 &bull; y(O)= 1, y'(O)=O. 
dt2 dt ' 
</p>
<p>Solution. Let Y(s)= C{y(t)}. Taking Laplace transforms of both sides of 
the differential equation gives 
</p>
<p>s2Y(s)-s-3[sY(s)-1]+2Y(s)= s~ 3 
and this implies that 
</p>
<p>Y(s)= 1 + s-3 
(s-3)(s 2 -3s+2) s2 -3s+2 
</p>
<p>1 s-3 
( + . s-l)(s-2)(s-3) (s-l)(s-2) (5) 
</p>
<p>To find y(t), we expand each term on the right-hand side of (5) in partial 
fractions. Thus, we write 
</p>
<p>1 = ~ + __!!__ + __.f._ 
(s-1)(s-2)(s-3) s-1 s-2 s-3 &middot; 
</p>
<p>230 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.9 The method of Laplace transforms 
</p>
<p>This implies that 
</p>
<p>A(s-2)(s-3)+ B(s-I)(s-3)+ C(s-I)(s-2)= I. (6) 
</p>
<p>Setting s = I in (6) gives A = i; setting s = 2 gives B = - I; and setting s = 3 
gives C = i. Hence, 
</p>
<p>I = .!. _I ___ I_ + .!. _I_ 
(s-I)(s-2)(s-3) 2 s-l s-2 2 s-3 &middot; 
</p>
<p>I 
</p>
<p>Similarly, we write 
</p>
<p>s-3 = _!2_ + __&sect;__ 
(s-I)(s-2) s-l s-2 
</p>
<p>and this implies that 
</p>
<p>D (s- 2) + E(s -l) = s- 3. (7) 
Setting s = I in (7) gives D = 2, while setting s = 2 gives E = - I. Hence, 
</p>
<p>II I II 2 I 
Y(s)=2 s-I- s-2 +2 s-3 + s-l- s-2 
</p>
<p>= 1_I ___ 2_ +.!._I_ 
2s-I s-2 2s-3' 
</p>
<p>Now, we recognize the first term as being the Laplace transform of ie'. 
Similarly, we recognize the second and third terms as being the Laplace 
transforms of - 2e21 and i e31 , respectively. Therefore, 
</p>
<p>Y(s) = e{ ~e 1 -2e 21 + ie3'} 
so that 
</p>
<p>Remark. Wehave cheated a little bit in this problern because there are ac-
tually infinitely many functions whose Laplace transform is a given func-
tion. For example, the Laplace transform of the function 
</p>
<p>{ 
~e 1 - 2e21 + le3' t=l= I, 2, and 3 
</p>
<p>z(t)= 2 2 ' 
0, t= 1,2,3 
</p>
<p>is also Y(s), since z(t) differs from y(t) at only three points.* However, 
there is only one continuous function y(t) whose Laplace transform is a 
given function Y(s), and it is in this sensethat we writey(t)= e- 1 { Y(s)}. 
</p>
<p>We wish to emphasize that Example 4 is just by way of illustrating the 
method of Laplace transforms for solving initial-value problems. The best 
way of solving this particular initial-value problern is by the method of 
</p>
<p>*If f(t)=g(t) except at a finite number of points, then J)&lt;t)dt= ibg(t)dt 
</p>
<p>231 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>judicious guessing. However, even though it is Ionger to solve this particu-
lar initial-value problern by the method of Laplace transforms, there is still 
something "nice and satisfying" about this method. If we had done this 
problern by the method of judicious guessing, we would have first com-
puted a particular solution ~( t) = t e3'. Then, we would have found two in-
dependent solutions e' and e2' of the homogeneaus equation, and we 
would have written 
</p>
<p>y (t) = cle' + c2e2' + te3' 
</p>
<p>as the general solution of the differential equation. Finally, we would have 
computed c1 =% and c2 = -2 from the initial conditions. What is unsatisfy-
ing about this method is that we first had to find all the solutions of the 
differential equation before we could find the specific solution y(t) which 
we were interested in. The method of Laplace transforms, on the other 
hand, enables us to find y(t) directly, without first finding all solutions of 
the differential equation. 
</p>
<p>EXERCISES 
</p>
<p>Determine the Laplace transform of each of the following functions. 
</p>
<p>1. t 
</p>
<p>3. e 01 cosbt 
</p>
<p>5. cos2at 
</p>
<p>7. sinatcosbt 
</p>
<p>4. e01 sinbt 
</p>
<p>6. sin2at 
</p>
<p>8. t2 sint 
</p>
<p>9. Given that foooe-x 2 dx = v.ii j2, find e{t- 112 ). Hint: Make the change of vari-
able u = Vt in (2). 
</p>
<p>Show that each of the following functions are of exponential order. 
</p>
<p>11. sinat 12. eYi 
</p>
<p>13. Show that e 12 does not possess a Laplace transform. Hint: Show that e 12 - 31 &gt; e1 
for t&gt;s+l. 
</p>
<p>14. Suppose thatj(t) is of exponential order. Show that F(s)= E{j(t)} approaches 
0 as s~oo. 
</p>
<p>Solve each of the following initial-value problems. 
</p>
<p>15. y" -5y'+4y=e2'; y(O)= 1, y'(O)= -1 
</p>
<p>16. 2y"+y'-y=e3'; y(0)=2,y'(O)=O 
</p>
<p>Find the Laplace transform of the solution of each of the following initial-
value problems. 
</p>
<p>17. y"+2y'+y=e- 1; y(O)=l,y'(0)=3 
</p>
<p>232 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.10 Some useful properties of Laplace transforms 
</p>
<p>18. y"+y=t2 sint; y(O)=y'(O)=O 
</p>
<p>19. y"+3y'+7y=cost; y(O)=O,y'(0)=2 
</p>
<p>20. y"+y'+y=t3 ; y(0)=2,y'(O)=O 
</p>
<p>21. Prove that all solutions y(t) of ay" + by' + cy = f(t) are of exponential order if 
f(t) is of exponential order. Hint: Show that all solutions of the homogeneaus 
equation are of exponential order. Obtain a particular solution using the 
method of variation of parameters, and show that it, too, is of exponential 
order. 
</p>
<p>22. Let F(s)=e{f(t)}. Prove that 
</p>
<p>{
d"j(t)}- n n-l dj&lt;&bull;-l&gt;(O) e -d n -s F(s)-s 'f(O)- ... - I . 
</p>
<p>t dt&bull;-
</p>
<p>Hint: Try induction. 
</p>
<p>23. Solve the initial-value problern 
</p>
<p>y'"-6y" + lly' -6y = e41 ; y(O) = y'(O)= y"(O)=O 
</p>
<p>24. Solve the initial-value problern 
</p>
<p>y"-3y'+2y=e- 1 ; y(t0 )= I, y'(t0 )=0 
</p>
<p>by the method of Laplace transforms. Hint: Let .p(t)=y(t+t0). 
</p>
<p>2.10 Some useful properties of Laplace transforms 
</p>
<p>In this section we derive several important properties of Laplace trans-
forms. Using these properties, we will be able to compute the Laplace 
transform of most functions without performing tedious integrations, and 
to invert many Laplace transforms by inspection. 
</p>
<p>Property 1. If e {j(t)} = F(s), then 
d E{ -tf(t)}= dsF(s). 
</p>
<p>PRooF. By definition, F(s)= j 000e-s1f(t)dt. Differentiating both sides of 
this equation with respect to s gives 
</p>
<p>.!!._ F(s) = .!!._ (oo e-stf(t)dt 
ds ds Jo 
</p>
<p>= roo l_(e-s1 )f(t)dt= roo -te-s1j(t)dt 
~ as k 
</p>
<p>=E{ -if(t)}. 0 
</p>
<p>233 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>Property 1 states that the Laplace transform of the function - tf(t) is 
the derivative of the Laplace transform of f(t). Thus, if we know the 
Laplace transform F(s) of f(t), then, we don't have to perform a tedious 
integration to find the Lap1ace transform of tf(t); we need only differenti-
ate F(s) and multiply by - 1. 
</p>
<p>Example 1. Compute the Laplace transform of te 1&bull; 
Solution. The Laplace transform of e 1 is 1 j(s- 1). Hence, by Property 1, 
the Lap1ace transform of te 1 is 
</p>
<p>E{tet} =- !]__ _1_ = 1 
ds s - 1 ( s _ 1 )2 &middot; 
</p>
<p>Example 2. Compute the Laplace transform of t 13&bull; 
Solution. Using Property 1 thirteen times gives 
</p>
<p>d 13 d13 1 (13)! 
E{t 13 } =( -1) 13 -E{1} =( -1) 13--=-. 
</p>
<p>dsl3 ds13 s s14 
</p>
<p>The main usefulness of Property 1 is in inverting Laplace transforms, as 
the following examp1es illustrate. 
</p>
<p>Example 3. What function has Laplace transform -1/(s-2)2? 
Solution. Observe that 
</p>
<p>1 d 
(s-2)2 = ds s-2 
</p>
<p>Hence, by Property 1, 
</p>
<p>e-1{- 1 2 }=-te2t. 
(s-2) 
</p>
<p>Example 4. What function has Lap1ace transform -4s/(s2 +4i? 
Solution. Observe that 
</p>
<p>4s d 2 
(s2+4)2 = ds s2+4 
</p>
<p>and --f- =E{sin2t}. 
s +4 
</p>
<p>Hence, by Property 1, 
</p>
<p>e- 1 {- 4s } =- tsin2t. 
(s2+4)2 
</p>
<p>Example 5. What function has Lap1ace transform 1 j (s- 4)3? 
</p>
<p>234 </p>
<p/>
</div>
<div class="page"><p/>
<p>2. 10 Some useful properties of Laplace transforms 
</p>
<p>Solution. We recognize that 
</p>
<p>1 d 2 1 1 
(s-4)3 = ds2 2 s-4 &middot; 
</p>
<p>Hence, using Property 1 twice, we see that 
</p>
<p>1 = e { .!. t2e4t } . 
(s-4)3 2 
</p>
<p>Property 2. If F(s)=E{f{t)}, then 
</p>
<p>e{ ea1j(t)} = F(s- a). 
</p>
<p>PROOF. By definition, 
</p>
<p>e{ ealf(t)} = Iaoo e-stealf(t)dt= fooo e&lt;a-s)lj(t)dt 
</p>
<p>= fooo e-&lt;s-a)tj(t)dt=.F(s-a). 0 
</p>
<p>Property 2 states that the Laplace transform of ea1f(t) evaluated at the 
point s equals the Laplace transform of f(t) evaluated at the point (s- a). 
Thus, if we know the Laplace transform F(s) ofj(t), then we don't have to 
perform an integration to find the Laplace transform of ea1j(t); we need 
only replace every s in F(s) by s- a. 
</p>
<p>Example 6. Compute the Laplace transform of e31 sin t. 
Solution. The Laplace transform of sint is l/(s2 + 1). Therefore, to com-
pute the Laplace transform of e31 sin t, we need only replace every s by 
s- 3; that is, 
</p>
<p>e { e31 sin t} = 1 2 
(s-3) + 1 
</p>
<p>The real usefulness of Property 2 is in inverting Laplace transforms, as 
the following examples illustrate. 
</p>
<p>Example 7. What function g( t) has Laplace transform 
</p>
<p>Solution. Observe that 
</p>
<p>G(s)= s-7 ? 
25 +(s-7)2 &bull; 
</p>
<p>F ( s) = ~ = e { cos 5 t} 
s +5 
</p>
<p>and that G (s) is obtained from F(s) by replacing every s by s -7. Hence, 
</p>
<p>235 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>by Property 2, 
</p>
<p>s-7 
-~--:-2'------- = e{ e71 cos5t}. 
(s-7) +25 
</p>
<p>Example 8. What function has Laplace transform l/(s2 -4s+9)? 
Solution. One way of solving this problern is to expand l/(s2 -4s+9) in 
partial fractions. A much better way is to complete the square of s2 - 4s + 
9. Thus, we write 
</p>
<p>2 &bull; 
(s-2) +5 
</p>
<p>Now, 
</p>
<p>- 1- = e { - 1- sin V5 t}. 
s2 +5 V5 
</p>
<p>Hence, by Property 2, 
</p>
<p>1 = 1 = e { - 1- e21 sin V5 t} . 
s2 -4s+9 (s-2)2 +5 V5 
</p>
<p>Examp1e 9. What function has Laplace transform s/(s2 -4s+9)? 
Solution. Observe that 
</p>
<p>s s-2 2 
---2--+ 2 . 
(s-2) +5 (s-2) +5 
</p>
<p>The function s /(s2 + 5) is the Laplace transform of cosv'5 t. Therefore, by 
Property 2, 
</p>
<p>s-2 2 ,rr 
---2 -=e{e 1cosv5 t}, 
(s-2) +5 
</p>
<p>and 
</p>
<p>s = e { e21 cos V5 t + - 2- e21 sin V5 t}. 
s2 -4s+9 V5 
</p>
<p>In the previous section we showed that the Laplace transform is a linear 
operator; that is 
</p>
<p>e{ elf! (t) + cd2 (t)} = cle{fl (t)} + c2e{f2 (t) }. 
Thus, if we know the Laplace transforms F 1(s) and Fis), of j 1(t) andfit), 
then we don't have to perform any integrations to find the Laplace trans-
form of a linear combination of f 1(t) and f2(t); we need only take the same 
linear combination of F 1(s) and F2(s). For example, two functions which 
appear quite often in the study of differential equations are the hyperbolic 
cosine and hyperbolic sine functions. These functions are defined by the 
equations 
</p>
<p>eat + e-at 
coshat= 2 , 
</p>
<p>. eat- e-at 
smhat= 2 . 
</p>
<p>236 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.10 Some useful properties of Laplace transforms 
</p>
<p>Therefore, by the linearity of the Laplace transform, 
</p>
<p>e{ coshat} = t e{ e01 } + t e{ e-at} 
= t [ s 2 a + s 1 a ] = s2 ~ a2 
</p>
<p>and 
</p>
<p>e { sinh at} = t e { e a/ } - t e { e - at } 
= t [ s 2 a - s 1 a ] = s2 ~ a2 &middot; 
</p>
<p>EXERCISES 
</p>
<p>Use Properties I and 2 to find the Laplace transform of each of the follow-
ing functions. 
</p>
<p>3. tsinat 
</p>
<p>5. t512 (see Exercise 9, Section 2.9) 
</p>
<p>6. Let F(s)=E{f(t)}, and suppose thatf(t)/t has a Iimit as t approaches zero. 
Prove that 
</p>
<p>E{f(t)/t} = J00F(u)du. 
s 
</p>
<p>(*) 
</p>
<p>(The assumption thatf(t)/t has a Iimit as t~O guarantees that the integral on 
the right-hand side of (*) exists.) 
</p>
<p>7. Use Equation (*) of Problem 6 to find the Laplace transform of each of the 
following functions: 
(a) sint (b) cosat- 1 
</p>
<p>t t 
</p>
<p>Find the inverse Laplace transform of each of the following functions. In 
several of these problems, it will be helpful to write the functions 
</p>
<p>aJs3+&szlig;Js2+yJs+&szlig;J als2+&szlig;ls+y 
p 1(s)= and p 2 (s)= ------,----
</p>
<p>( as2 + bs + c )( ds2 +es+ f) ( as + b )( cs2 + ds + e) 
</p>
<p>in the simpler form 
</p>
<p>( ) _ As + B + Cs + D PJ s -
as2 + bs + c ds 2 + es+ f 
</p>
<p>8. 
s 
</p>
<p>(s+a)2+b2 
</p>
<p>10. 
1 
</p>
<p>s(s2+4) 
</p>
<p>12. 
I 
</p>
<p>(s2 + a2)(s2 + b2) 
</p>
<p>A Cs+D 
and p 2 (s) = --b + 2 &bull; as+ es +ds+ e 
</p>
<p>11. s 
s2 -3s-12 
</p>
<p>3s 
13. 4 
</p>
<p>(s+ 1) 
</p>
<p>237 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>14. 2 
s(s+4) 
</p>
<p>s 
15. 2 
</p>
<p>(s+1) (s2 +1) 
</p>
<p>1 
16. 2 
</p>
<p>(s 2 + 1) 
17. Let F(s)= e{j(t)}. Show that 
</p>
<p>f(t)=- +e- 1{F'(s)}. 
Thus, if we know how to invert F'(s), then we can also invert F(s). 
</p>
<p>18. Use the result of Problem 17 to invert each of the following Lap1ace transforms 
</p>
<p>(a) 1n(s+a) (b) arctan~ (c) 1n(1- a:) 
s-a s s 
</p>
<p>Solve each of the following initial-value problems by the method of 
Laplace transforms. 
</p>
<p>19. y" + y =sint; y(O)= 1, y'(0)=2 
</p>
<p>20. y"+y=tsint; y(0)=1,y'(0)=2 
</p>
<p>21. y"-2y'+y=te 1; y(O)=O,y'(O)=O 
</p>
<p>22. y"- 2y' + 7y =sint; y(O)=O, y'(O)=O 
</p>
<p>23. y" +y'+y= 1+e- 1; y(0)=3,y'(O)= -5 
</p>
<p>24.y"+y={~~-?, ~~~~~; y(O)=O,y'(O)=O 
</p>
<p>2.11 Differential equations with discontinuous 
right-hand sides 
</p>
<p>In many applications, the right-hand side of the differential equation ay" + 
by' + cy = f(t) has a jump discontinuity at one or more points. For exam-
ple, a particle may be moving under the influence of a force j 1(t), and 
suddenly, at time t1, an additional forcefit) is applied to the particle. Such 
equations are often quite tedious and cumbersome to solve, using the 
methods developed in Se9tions 2.4 and 2.5. In this section we show h~w to 
handle such problems by the method of Laplace transforms. We begm by 
computing the Laplace transform of several simple discontinuous func-
tions. 
</p>
<p>The simplest example of a function with a single jump discontinuity is 
the function 
</p>
<p>O~t&lt;c 
</p>
<p>~~ c 
</p>
<p>This function, whose graph is given in Figure I, is often called the unit step 
</p>
<p>238 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.11 Differential equations with discontinuous right-hand sides 
</p>
<p>~~--------~------------~--t 
c 
</p>
<p>Figure l. Graph of Hc(t) 
</p>
<p>function, or the Heaviside function. lts Laplace transform is 
</p>
<p>s 
</p>
<p>Next, Iet j be any function defined on the interval 0..;; t &lt; oo, and Iet g 
be the function obtained from j by moving the graph of j over c units to 
the right, as shown in Figure 2. More precisely, g(t) = 0 for 0..;; t &lt; c, and 
g(t) = f(t- c) for t ~ c. For example, if c = 2 then the value of g at t =7 is 
the value of j at t = 5. A convenient analytical expression for g(t) is 
</p>
<p>g(t)=Hc(t)f(t-c). 
</p>
<p>The factor Hc(t) makes g zero for 0..;; t &lt; c, and replacing the argument t 
of j by t- c moves j over c units to the right. Since g(t) is obtained in a 
simple manner from f(t), we would expect that its Laplace transform can 
also be obtained in a simple manner from the Laplace transform of j(t). 
This is indeed the case, as we now show. 
</p>
<p>Figure 2 
</p>
<p>239 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>Property 3. Let F(s)=E{f(t)}. Then, 
</p>
<p>E{ Hc(t)f(t- c)} = e-csF(s). 
</p>
<p>PROOF. By definition, 
</p>
<p>e{ Hc(t)J(t- c)} = fo 00e-s1Hc(t)f(t- c)dt 
</p>
<p>= j 00e-s1j(t-c)dt. 
c 
</p>
<p>This integral suggests the Substitution 
</p>
<p>~=t-c. 
</p>
<p>Then, 
</p>
<p>loo e-stf(t- c )dt= fo 00 e-s(~+c) J(~)d~ 
</p>
<p>= e -es fooo e-s~J(~)d~ 
=e-csF(s). 
</p>
<p>Hence, E{Hc(t)J(t-c)}=e-cse{j(t)}. 
</p>
<p>Example 1. What function has Laplace transform e-s;s 2? 
</p>
<p>0 
</p>
<p>Solution. We know that 1js 2 is the Laplace transform of the function t. 
Hence, by Property 3 
</p>
<p>e~s =e{H1 (t)(t-1)}. 
s 
</p>
<p>The graph of H 1(t)(t- 1) is given in Figure 3. 
</p>
<p>Figure 3. Graph of H 1(t) (t-1) 
</p>
<p>240 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.11 Differential equations with discontinuous right-hand sides 
</p>
<p>Example 2. What function has Laplace transform e- 3"j(s 2 -2s-3)? 
Solution. Observe that 
</p>
<p>s2 - 2s - 3 s2 - 2s + 1 - 4 ( s - I )2 - 22 &bull; 
</p>
<p>Since I/(s2-22)=eUsinh2t}, we conclude from Property 2 that 
</p>
<p>I =e{-2Ie 1sinh2t}. 
(s-I)2 -22 
</p>
<p>Consequently, from Property 3, 
</p>
<p>-3s { I } 
2 e =e -2 H 3 (t)e 1 - 3 sinh2(1-3). s -2s-3 
</p>
<p>Example 3. Letf(t) be the function which is 1 for 0..; 1 &lt;I, and 0 for 1;;. I. 
Find the Lapiace transform of f without performing any integrations. 
Solution. Observe that f(t) can be written in the form 
</p>
<p>f( 1) = t[ H0 ( t)- H 1 ( t)] = t- tH1 ( t). 
</p>
<p>Hence, from Property I, 
</p>
<p>e{J(t)} = e{ t}- e{ tH1 (t)} 
I d e-&bull; I e-&bull; e-&bull; 
</p>
<p>=-+--=-----
s2 ds s s2 s s2 . 
</p>
<p>Example 4. Solve the initial-value problern 
</p>
<p>dzy dy { I, 0..; t &lt; I; 
- 2 -3 dt +2y=f(t)= I, 2..; t&lt;3; 
dt I, 4..; t&lt; 5; 
</p>
<p>0, I..; 1&lt;2; 
0, 3..; I &lt;4; 
0, 5..; I&lt; 00. 
</p>
<p>y(O)=O, y'(O)=O 
</p>
<p>Solution. Let Y(s)= e{y(l)} and F(s)= e{f(t)}. Taking Laplace trans-
forms of both sides of the differential equation gives (s2- 3s + 2) Y (s) = 
F(s), so that 
</p>
<p>F(s) 
Y(s)----
</p>
<p>s2-3s+2 
</p>
<p>F(s) 
</p>
<p>(s-I)(s-2) &middot; 
</p>
<p>One way of computing F(s) is to writef(t) in the form 
</p>
<p>Hence, by the linearity of the Laplace transform 
</p>
<p>I e-&bull; e-2&bull; e-3s e-4s e-ss 
F(s)=---+---+---. 
</p>
<p>s s s s s s 
</p>
<p>241 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>A second way of computing F(s) is to evaluate the integral 
</p>
<p>fo 00e-s'f(t)dt= fo 1e-s1dt+ ~ 3 e-s 1 dt+ 15e-s1dt 
I-e-s e-2s-e-3s e- 43 -e-ss -=---=-- + + ..::___...::___ 
</p>
<p>s s s 
</p>
<p>Consequently, 
</p>
<p>1- e-s+ e-2s- e-3s + e-4s- e-ss 
Y(s)= s(s-l)(s-2) &middot; 
</p>
<p>Our next step is to expand 1/ s(s- 1 )(s- 2) in partial fractions; i.e., we 
write 
</p>
<p>1 =A+_l!_+_f_ 
s(s-l)(s-2) s s-1 s-2 &middot; 
</p>
<p>This implies that 
</p>
<p>A (s-l)(s-2) + Bs(s-2) + Cs(s-1) = 1. (1) 
</p>
<p>Setting s=O in (I) gives A = 1; setting s= 1 gives B= -1; and setting s=2 
gives C = 4. Thus, 
</p>
<p>I = .!. .!. __ 1_ + .!. _1_ 
s{s-l){s-2) 2 s s-1 2 s-2 
</p>
<p>=e{ -!-e'+-!e2'}&middot; 
Consequently, from Property 3, 
</p>
<p>y(t) = [ 4- e' + 4e2']- Hl (t)[ 4- e&lt;t-1&gt;+ ie2&lt;t-t)] 
+ H2 (t)[ 4- e&lt;t-2) + ie2&lt;t-2)]- H3 (t)[ 4- e&lt;t-3) + ie2&lt;t-3)] 
+ H4 (t)[ 4- e&lt;t-4) + ie2&lt;t-4)]- Hs (t)[ 4- e&lt;t-s) + ie2&lt;t-5) ]. 
</p>
<p>Remark. lt is easily verified that the function 
</p>
<p>and its derivative are both zero at t=n. Hence, bothy(t) andy'(t) are con-
tinuous functions of time, even thoughf(t) is discontinuous at t= I, 2, 3, 4, 
and 5. More generally, both the solution y(t) of the initial-value problern 
</p>
<p>d2y dy 
a dt2 +b dt +cy=J(t); y(to)=YO&gt; y'(to)=yo 
</p>
<p>242 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.12 The Dirac delta function 
</p>
<p>and its derivative y'(t) are always continuous functions of time, if f(t) is 
piecewise continuous. We will indicate the proof of this result in Section 
2.12. 
</p>
<p>EXERCISES 
</p>
<p>Find the solution of each of the following initial-value problems. 
</p>
<p>1. y"+2y'+y=2(t-3)H3(t); y(0)=2,y'(0)=1 
</p>
<p>2. y"+y'+y=H"'(t)-H2.,(t); y(O)=I,y'(O)=O 
</p>
<p>3.y"+4y={b: ?;~&lt; 4 ; y(0)=3,y'(0)=-2 
</p>
<p>4. y"+y= { sint, 
cost, 
</p>
<p>5 "+ -{cost, .y y-
0, 
</p>
<p>~~~~:; y(0)=1,y'(0)=0 
</p>
<p>0 ,;;;; t &lt; 7r 12 . (0) = 3 '(0) = - 1 
7r /2 ,;;;; t &lt; 00 ' y 'y 
</p>
<p>6. "+ 2 '+ ={sin2t, O&lt;:.t&lt;w/2. (O)=l '(O)=O 
y y y 0, 7r /2 ,;;;; t &lt; 00 ' y ' y 
</p>
<p>7. y"+y'+1y= { 6, ~~ :~~; y(O)=O,y'(O)=O 
8. y"+y= { t2, 0&lt;:. t&lt; I ; y(O)=O,y'(O)=O 
</p>
<p>0, I,;;;; t &lt; oo 
</p>
<p>{ 
0, 
</p>
<p>9. y"-2y'+y= t, 
0, 
</p>
<p>O&lt;:.t&lt;I 
1,;;;; t&lt;2 ; y(O)=O,y'(O)= I 
2&lt;:.t&lt;oo 
</p>
<p>10. Find the Laplace transform of lsin tl. Hint: Observe that 
00 
</p>
<p>lsintl=sint+2 ~ Hm,(t)sin(t-nw). 
n=l 
</p>
<p>11. Solve the initial-value problern of Example 4 by the method of judicious guess-
ing. Hint: Find the general solution of the differential equation in each of the 
intervals 0 &lt; t &lt;I, I&lt; t &lt; 2, 2 &lt; t &lt; 3, 3 &lt; t &lt; 4, 4 &lt; t &lt; 5, 5 &lt; t &lt; oo, and 
choose the arbitrary constants so that y(t) and y'(t) are continuous at the 
points t= I, 2, 3, 4, and 5. 
</p>
<p>2.12 The Dirac delta function 
</p>
<p>In many physical and biological applications we are often confronted with 
an initial-value problern 
</p>
<p>d2y dy 
a-2 + b-d + cy = f(t); 
</p>
<p>dt t 
y(O) = Yo&bull; y'(O) = Yo (1) 
</p>
<p>243 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>Figure 1. The graph of a typical impulsive function f(t) 
</p>
<p>where we do not know f(t) explicitly. Suchproblems usually arise when we 
are dealing with phenomena of an impulsive nature. In these situations, the 
only information we have about f(t) is that it is identically zero except for 
a very short time interval t0 ~ t ~ t 1, and that its integral over this time in-
terval is a given number 10 =!=0. If / 0 is not very small, then f(t) will be 
quite large in the interval t0 ~ t ~ t 1&bull; Such functions are called impulsive 
functions, and the graph of a typicalf(t) is given in Figure I. 
</p>
<p>In the early 1930's the Nobel Prize winning physicist P. A. M. Dirac de-
veloped a very controversial method for dealing with impulsive functions. 
His method is based on the following argument. Let t 1 get closer and closer 
to t0 . Then the functionf(t)/ / 0 approaches the function which is 0 for t=fo 
t0, and oo for t = t0, and whose integral over any interval containing t0 is I. 
We will denote this function, which is known as the Dirac delta function, 
by 8 ( t- t0). Of course, 8 ( t- t0) is not an ordinary function. However, says 
Dirac, Iet us formally operate with 8 (t- t0) as if it really were an ordinary 
function. Then, if we setf(t)=/08(t-t0) in (I) and impose the condition 
</p>
<p>(ab g(t)8 (t- to)dt= { g(Oto) if a ~ fo &lt; b (2) 
) - otherwise 
</p>
<p>for any continuous function g(t), we will always obtain the correct solution 
y(t). 
</p>
<p>Remark. Equation (2) is certainly a very reasonable condition to impose 
on 8 ( t- t0). To see this, suppose that f ( t) is an impulsive function which is 
positive for t0 &lt; t &lt; t1, zero otherwise, and whose integral over the interval 
[t&lt;Pt1] is I. For any continuous function g(t), 
</p>
<p>[ min g(t)]f(t) &lt; g(t)f(t) &lt;[ max g(t)]f(t). 
t0 &lt;t&lt;t1 to&lt;t"t&bull; 
</p>
<p>Consequently, 
</p>
<p>('&bull;[ min g(t)]f(t)dt~J 11 g(t)f(t)dt&lt;j'&bull;[ max g(t)]f(t)dt, 
) 10 to &lt; t &lt; t1 to 10 to &lt; t &lt; t1 
</p>
<p>244 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.12 The Dirac delta function 
</p>
<p>or 
</p>
<p>Now, most mathematicians, of course, usually ridiculed this method. 
"How can you make believe that ~ ( t- t0) is an ordinary function if it is 
obviously not," they asked. However, they never laughed too loud since 
Dirac and his followers always obtained the right answer. In the late 
1940's, in one of the great success stories of mathematics, the French 
mathematician Laurent Schwartz succeeded in placing the delta function 
on a firm mathematical foundation. He accomplished this by enlarging the 
dass of all functions so as to include the delta function. In this section we 
will first present a physical justification of the method of Dirac. Then we 
will illustrate how to solve the initial-value problern (1) by the method of 
Laplace transforms. Finally, we will indicate very briefly the "germ" of 
Laurent Schwartz's brilliant idea. 
</p>
<p>Physical justification of the method of Dirac. Newton's second law of mo-
tion is usually written in the form 
</p>
<p>d 
dt mv(t) = f(t) (3) 
</p>
<p>where m is the mass of the particle, v is its velocity, and f(t) is the total 
force acting on the particle. The quantity mv is called the momentum of 
the particle. Integrating Equation (3) between t0 and t 1 gives 
</p>
<p>mv(t1)-mv(t0 )= J1'j(t)dt. 
to 
</p>
<p>This equation says that the change in momentum of the particle from time 
</p>
<p>t0 to time t 1 equals ['f(t)dt. Thus, the physically important quantity is 
the integral of the force, which is known as the impulse imparted by the 
force, rather than the force itself. Now, we may assume that a&gt;O in Equa-
tion (1), for otherwise we can multiply both sides of the equation by -1 to 
obtain a &gt; 0. In this case (see Section 2.6) we can view y(t), fort.;;;; t0, as the 
position at time t of a particle of mass a moving under the influence of the 
force -b(dyjdt)-cy. At time t0 a forcef(t) is applied to the particle, and 
this force acts over an extremely short time interval t0 .;;;; t.;;;; t 1&bull; Since the 
time interval is extremely small, we may assume that the position of the 
particle does not change while the force f(t) acts. Thus the sum result of 
the impulsive force f(t) is that the velocity of the particle jumps by an 
amount 10 / a at time t0&bull; In other words, y(t) satisfies the initial-value prob-
lern 
</p>
<p>d2y dy 
a- +b- +cy=O&middot; 
</p>
<p>dt2 dt ' 
y(O) = y 0, y'(O) = y~ 
</p>
<p>245 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>for 0 ~ t &lt; t0, and 
</p>
<p>d2y dy 
a- +b- +cy=O&middot; 
</p>
<p>dt2 dt ' 
(4) 
</p>
<p>for t;;;. t0, where z0 and z~ are the position and velocity of the particle just 
before the impulsive force acts. It is clear, therefore, that any method 
which correctly takes into account the momentum / 0 transferred to the 
particle at time t0 by the impulsive force f(t) must yield the correct answer. 
It is also clear that we always keep track of the momentum / 0 transferred 
to the particle by f(t) if we replace f(t) by / 0 ~ (t- t0) and obey Equation 
(2). Hence the method of Dirac will always yield the correct answer. 
</p>
<p>Remark. We can now understand why any solutiony(t) of the differential 
equation 
</p>
<p>d2y dy 
a-+b-+cy=f(t) 
</p>
<p>dt2 dt ' 
f(t) a piecewise continuous function, 
</p>
<p>is a continuous function of time even thoughf(t) is discontinuous. To wit, 
since the integral of a piecewise continuous function is continuous, we see 
that y'(t), must vary continuously with time. Consequently, y(t) must also 
vary continuously with time. 
</p>
<p>Solution of Equation (I) by the method of Laplace transforms. In order to 
solve the initial-value problern (I) by the method of Laplace transforms, 
we need oniy know the Laplace transform of ~ ( t- t0). This is obtained di-
rectly from the definition of the Laplace transform and Equation (2), for 
</p>
<p>e { ~ ( t- to)} = fo 00 e -st~ ( t- to) dt = e -sto (for t0 ;;;. 0). 
</p>
<p>Exampie 1. Find the solution of the initial-value problern 
</p>
<p>d 2y dy 
dt2 -4 dt +4y=3~(t-I)+~(t-2); y(O)= I, y'(O)= I. 
</p>
<p>Solution. Let Y(s)=e{y(t)}. Taking Laplace transforms of both sides of 
the differential equation gives 
</p>
<p>s2Y- s -I-4(sY -I) +4 Y =3e-s + e-2s 
</p>
<p>or 
</p>
<p>(s2 -4s +4) Y (s) = s- 3 + 3e-s + e-2s. 
Consequently, 
</p>
<p>Y( )= s-3 + 3e-s + e-2s 
s 2 2 2. 
</p>
<p>(s-2) (s-2) (s-2) 
</p>
<p>246 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.12 The Dirac delta function 
</p>
<p>Now, Ij(s-2?= e{te2'}. Hence, 
</p>
<p>3e-s + e-2s = e{3H (t)(t-I)e2&lt;t-l)+ H (t)(t-2)e2&lt;t-2&gt;}. 
(s-2)2 (s-2)2 I 2 
</p>
<p>To invert the first term of Y(s), observe that 
</p>
<p>s- 3 s- 2 I = e{ e2'} _ e{ te2'}. 
(s-2)2 (s-2)2 (s-2)2 
</p>
<p>Thus, y(t) = (1- t)e2' + 3H1{t){t -l)e2&lt;t-l)+ H2(t)(t- 2)e2&lt;'-2&gt;. 
</p>
<p>It is instructive to do this problern the lang way, that is, to findy(t) sep-
arately in each of the intervals 0( t&lt; I, I&lt; t &lt;2 and 2 &lt; t&lt; oo. For 0 &lt; t &lt; 
I, y(t) satisfies the initial-value problern 
</p>
<p>d2y dy 
dt2 -4 dt +4y=O; y(O)=I, y'(O)=I. 
</p>
<p>The characteristic equation of this differential equation is r2 - 4r + 4 = 0, 
whose roots are r1 = r2 =2. Hence, any solution y(t) must be of the form 
y(t)=(a1 +a2t)e21 &bull; The constants a 1 and a2 are determined from the initial 
conditions 
</p>
<p>I=y(O)=a1 and l=y'(0)=2a1+a2&bull; 
</p>
<p>Hence, a 1 =I, a2 = -1 and y{t)=(l- t)e21 for 0 ( t&lt; I. Now y(I)=O and 
y'(I)=- e2&bull; At timet= I the derivative of y(t) is suddenly increased by 3. 
Consequently, for I &lt; t &lt; 2, y ( t) satisfies the initial-value problern 
</p>
<p>d2y dy 
dt2 -4 dt +4y=O; y(I)=O, y'(I)=3-e2&bull; 
</p>
<p>Since the initial conditions are given at t= I, we write this solution in the 
formy(t)=[b 1 +b2(t-l)]e2&lt;1 - 1&gt; (see Exercise 1). The constants b1 and b2 
are determined from the initial conditions 
</p>
<p>0= y(I) = b1 and 3- e2= y'(I) =2b1 + b2&bull; 
</p>
<p>Thus, b1 = 0, b2 = 3- e2 and y(t) = (3- e2)(t- I)e2&lt;r-l), I &lt; t &lt; 2. Now, 
y(2)={3- e2)e2 and y'(2)=3(3- e2)e2&bull; At time t =2 the derivative of y(t) 
is suddenly increased by I. Cop.sequently, for 2 ( t &lt; oo, y(t) satisfies the 
initial-value problern 
</p>
<p>d2y dy 
--4-+4y=O&middot; y(2)=e2(3-e2), y'(2)=I+3e2(3-e2). 
dt2 dt ' 
</p>
<p>Hencey(t)=[c1+c2(t-2)]e2&lt;'- 2&gt;. The constants c1 and c2 are determined 
from the equations 
</p>
<p>e2(3-e2)=c1 and 1+3e2(3-e2)=2c1+c2&bull; 
</p>
<p>247 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>Thus, 
</p>
<p>and y ( t) = [ e 2(3- e2) +(I + e2(3- e2))( t- 2)]e2&lt;1 - 2&gt;, t ~ 20 The reader should 
verify that this expression agrees with the expression obtained for y(t) by 
the method of Laplace transformso 
</p>
<p>Example 2. A particle of mass I is attached to a spring dashpot mechanismo 
The stiffness constant of the spring is 1 Njft and the drag force exerted by 
the dashpot mechanism on the particle is twice its velocityo At time t = 0, 
when the particle is at rest, an externai force e -t is applied to the systemo At 
time t = I, an additional force /( t) of very shor: duration is applied to the 
particle. This force imparts an im pulse of 3 N &deg; s to the particleo Find the 
position of the particle at any time t greater than I. 
Solution. Let y(t) be the distance of the particle from its equilibrium 
positiono Then, y( t) satisfies the initial-value problern 
</p>
<p>y(O)=O, y'(O)=Oo 
</p>
<p>Let Y(s)=e{y(t)}o Taking Laplace transforms of both sides of the dif-
ferential equation gives 
</p>
<p>(s 2 +2s+ J)Y(s)= - 1-1 +3e-s, or s+ 
</p>
<p>Since 
</p>
<p>I - e { t2e- I } and 
(s+ 1)3 - 2 
</p>
<p>we see that 
</p>
<p>Y(s)= I + 3e-s 0 
(s+I)3 (s+l)2 
</p>
<p>2 -t 
</p>
<p>y(t)= T +3H1 (t)(t-I)e-&lt;t-l)o 
Consequently, y(t) = ~ t 2e -t + 3(t- l)e -(t-l) for t &gt;I. 
</p>
<p>We conclude this section with a very brief description of Laurent 
Schwartz's method for placing the delta function on a rigorous mathemati-
cal foundationo The main step in his method is to rethink our notion of 
"functiono" In Calculus, we are taught to recognize a function by its value 
at each time lo A much more subtle (and much more difficult) way of re-
cognizing a function is by what it does to other functionso More precisely, 
Iet f be a piecewise continuous function defined for - oo &lt; t &lt; ooo To each 
function &lt;P which is infinitely often differentiable and which vanishes for I tl 
</p>
<p>248 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.12 The Dirac delta function 
</p>
<p>sufficiently large, we assign a nurober K[q,] according to the formula 
</p>
<p>K[ q,] = L: q&gt;(t)f(t)dt. (5) 
As the notation suggests, K is an operator acting on functions. However, it 
</p>
<p>differs from the operators introduced previously in that it associates a 
</p>
<p>number, rather than a function, with &lt;f&gt;. Forthis reason, we say that K[&lt;/&gt;] is 
</p>
<p>a functional, rather than a function. Now, observe that the association q,~ 
</p>
<p>K[&lt;/&gt;] is a linear association, since 
</p>
<p>K[c1q&gt; 1+c2q&gt;2]= 1: (c11/&gt; 1+c2&lt;/&gt;2)(t)f(t)dt 
=c1f_: &lt;P 1(t)f(t)dt+c2f_: &lt;P2(t)f(t)dt 
= c1K[ &lt;/&gt; 1 ] + c2K[ 1/&gt;2 ]. 
</p>
<p>Hence every piecewise continuous function defines, through (5), a linear 
</p>
<p>functional on the space of all infinitely often differentiahte functions which 
</p>
<p>vanish for I tl sufficiently large. 
Now consider the functional K[&lt;/&gt;] defined by the relation K[q&gt;]=&lt;f&gt;(t0). 
</p>
<p>K is a linear functional since 
</p>
<p>K[ c1q&gt; 1 + c2q&gt;2 ] = c1&lt;P 1 (t0) + c2q&gt;2 (t0) = c1K[ &lt;/&gt; 1] + c2K[ 1/&gt;2 ]. 
</p>
<p>To mirnie (5), we write K symbolically in the form 
</p>
<p>K['f&gt;]= L: &lt;P(t)8(t-t0)dt. (6) 
In this sense, 8 (t- t0) is a "generalized function." It is important to realize 
</p>
<p>though, that we cannot speak of the value of 8 (t- t0) at any time t. The 
</p>
<p>only meaningful quantity is the expression L: q&gt;(t)8(t- t0)dt, and we 
must always assign the value &lt;f&gt;(t0) to this expression. 
</p>
<p>Admittedly, it is very difficult to think of a function in terms of the lin-
</p>
<p>ear functional (5) that it induces. The advantage to this way of thinking, 
</p>
<p>though, is that it is now possible to assign a derivative to every piecewise 
</p>
<p>continuous function and to every "generalized function." To wit, suppose 
</p>
<p>that f(t) is a differentiahte function. Then f'(t) induces the linear func-
tional 
</p>
<p>K'[ &lt;P] = L: &lt;P(t)f'(t)dt. (7) 
Integrating by parts and using the fact that &lt;/&gt;( t) vanishes for I tl sufficiently 
large, we see that 
</p>
<p>K'[&lt;P]= L: [ -&lt;P'(t)]f(t)dt=K[ -q,']. (8) 
249 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>Now, notice that the formula K'[cp]=K[-cp'] makes sense even if f(t) is 
not differentiable. This motivates the following definition. 
</p>
<p>Definition. To every linear functional K[cp] we assign the new linear func-
tional K'[cp] by the formula K'[cp]= K[ -cp']. The linear functional K'[cp] 
is called the derivative of K[cp] since if K[cp] is induced by a differentia-
ble function f(t) then K'[cp] is induced by j'(t). 
</p>
<p>Finally, we observe from (8) that the derivative of the delta function 
8 (t- t0) is the linear functional which assigns to each function cp the num-
ber -cp'(t0), for if Klcp]=cp(t0) then K'[cp]=K[ -cp']= -cp'(t0). Thus, 
</p>
<p>loo cp(t)8'(t- t0 )dt= -cp'(t0) -oo 
for all differentiable functions cp(t). 
</p>
<p>EXERCISES 
</p>
<p>1. Let a be a fixed constant. Show that every solution of the differential equation 
(d 2yldt2)+2a(dyldt)+a2y=O can be written in the form 
</p>
<p>y(t) = [ c1 + c2(t- a)Je-a(t-aJ. 
</p>
<p>2. Solve the initial-value problern (d 2y I dt 2)+4(dy I dt)+Sy = f(t); y(O)= l,y'(O)= 
0, where f( t) is an impulsive force which acts on the extremely short time inter-
</p>
<p>f i+T vall&lt;;;t&lt;;;l+T,and 1 f(t)dt=2. 
3. (a) Solve the initial-value problern (d 2y 1 dt 2)- 3(dy 1 dt) + 2y = f(t); y(O) = 1, 
</p>
<p>y'(O) = 0, where f( t) is an impulsive function which acts on the extremely 
h &bull; &bull; 2 f2+T s ort time mterval 2.;; t.;; + 'T, and 2 f(t)di =- 1. 
</p>
<p>(b) Solve the initial-value problern (d 2y I dt 2)- 3(dy I dt) + 2y =0; y(O)= I, y'(O) 
=0, on the interval 0.;; t.;; 2. Compute z0 = y(2) and z0= y'(2). Then solve 
the initial-value problern 
</p>
<p>y(2)=z0, y'(2)=z0-l, 
</p>
<p>Compare this solution with the solution of part (a). 
</p>
<p>4. A particle of mass I is attached to a spring dashpot mechanism. The stiffness 
constant of the spring is 3 Njm and the drag force exerted on the particle by the 
dashpot mechanism is 4 times its velocity. At time t = 0, the particle is stretched &plusmn; 
m from its equilibrium position. At timet= 3 seconds, an impulsive force of very 
short duration is applied to the system. This force imparts an im pulse of 2 N &middot; s to 
the particle. Find the displacement of the particle from its equilibrium position. 
</p>
<p>250 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.13 The convolution integral 
</p>
<p>In Exercises 5-7 solve the given initial-value problem. 
</p>
<p>d2y 
5. dt2 +y=sint+8(t-w); y(O)=O,y'(O)=O 
</p>
<p>d2y dy 
6. dt2 + dt +y=28(t-l)-8(t-2); y(O)=l,y'(O)=O 
</p>
<p>d2 dy 
7. ~ 2 +2-d +y=e- 1 +38(t-3); y(O)=O,y'(0)=3 
</p>
<p>dt t 
</p>
<p>8. (a) Solve the initial-value problern 
</p>
<p>d2y 00 
- 2 +y= ~ 8(t-jw), y(O)=y'(O)=O, 
dt j-0 
</p>
<p>and show that 
</p>
<p>y(t)= { sint, 
0, 
</p>
<p>in the interval nw &lt; t &lt; (n + l)w. 
(b) Solve the initial-value problern 
</p>
<p>n even 
n odd 
</p>
<p>d2y 00 
- 2 +y= ~ 8(t-2jw), y(O)=y'(O)=O, 
dt j-0 
</p>
<p>and show that y(t) =(n + l)sint in the interval 2nw &lt; t &lt;2(n + l)w. 
This example indicates why soldiers are instructed to break cadence when 
marehing across a bridge. To wit, if the soldiers are in step with the natural 
frequency of the steel in the bridge, then a resonance situation of the type (b) 
may be set up. 
</p>
<p>9. Letj(t) be the function which ist for t&gt;t0, 0 for t=t0, and -t for t&lt;t0. Let 
K[q&gt;] be the linear functional 
</p>
<p>K[q&gt;]= L: q&gt;(t)f(t)dt. 
Show that K'[q&gt;J=K[-q&gt;']=q&gt;(t0). Thus, 8(t-t0) may be viewed as the deriva-
tive of f(t). 
</p>
<p>2.13 The convolution integral 
</p>
<p>Consider the initial-value problern 
</p>
<p>d 2y dy 
a dt2 + b dt + cy = f ( t); y (0) = Yo&bull; y'(O) = Yo&middot; (I) 
</p>
<p>Let Y(s)= e{y(t)} and F(s)= e{f(t)}. Taking Laplace transforms of 
both sides of the differential equation gives 
</p>
<p>a[ s2Y(s)- sy0 - y0 J + b[ sY(s)- y 0 ] + cY (s) = F(s) 
</p>
<p>251 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>and this implies that 
</p>
<p>Y( ) - as+ b + a , + s- Yo Yo ----. 
as2 + bs + c as2 + bs + c as2 + bs + c 
</p>
<p>F(s) 
</p>
<p>Now, let 
</p>
<p>y,(t)=e-'{ as+b } 
as2 + bs+ c 
</p>
<p>and 
</p>
<p>h(t)=e-'{ 2 a }&middot; 
as + bs+c 
</p>
<p>Settingf(t)=O,y0 = 1 andy~=O, we see thaty 1(t) is the solution of the ho-
mogeneous equation which satisfies the initial conditions y 1(0) =I, Yi(O) = 
0. Similarly, by setting f(t)=O, y0 =0 and y~= I, we see that y2(t) is the 
solution of the homogeneaus equation which satisfies the initial conditions 
yiO) = 0, Y2(0) =I. This implies that 
</p>
<p>1/;(t)=e-'{ F(s) } 
as2 + bs+ c 
</p>
<p>is the particular solution of the nonhomogeneaus equation which satisfies 
the initial conditions 1[;(0) = 0, t[/(0) = 0. Thus, the problern of finding a par-
ticular solution l[;(t) of the nonhomogeneaus equation is now reduced to 
the problern of finding the inverse Laplace transform of the function 
F(s)j(as 2 + bs + c). If we look carefully at this function, we see that it is 
the product of two Laplace transforms; that is 
</p>
<p>F(s) =e{J(t)}xe{ Y2(t) }&middot; 
as2 +bs+c a 
</p>
<p>It is natural to ask whether there is any simple relationship between l[;(t) 
and the functions f ( t) and h( t) / a. It would be nice, of course, if 1[;( t) were 
the product of f(t) withh(t)/ a, but this is obviously false. However, there 
is an extremely interesting way of combining two functions f and g 
together to form a new function f * g, which resembles multiplication, and 
for which 
</p>
<p>e{ U*g)(t)} = e{f(t)} x q g(t) }. 
</p>
<p>This combination of f and g appears quite often in applications, and is 
known as the convolution of f with g. 
</p>
<p>Definition. The convolution (f * g)( t) of f with g is defined by the equation 
</p>
<p>(f*g)(t)= Iot f(t- u) g(u)du. (2) 
</p>
<p>252 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.13 The convolution integral 
</p>
<p>For example, ifj(t)=sin2t andg(t)=e 12, then 
</p>
<p>(I 2 
U*g)(t)= Jo sin2(t- u)e" du. 
</p>
<p>The convolution operator * clearly bears some resemblance to the mul-
tiplication operator since we multiply the value of f at the point t- u by 
the value of g at the point u, and then integrate this product with respect to 
u. Therefore, it should not be too surprising to us that the convolution op-
erator satisfies the following properties. 
</p>
<p>Property 1. The convolution operator obeys the commutative law of multi-
plication; that is, (f * g)( t) = ( g * f)( t). 
</p>
<p>PROOF. By definition, 
</p>
<p>Let us make the substitution t- u = s in this integral. Then, 
</p>
<p>U*g)(t)=- j 0 f(s)g(t-s)ds 
I 
</p>
<p>= fo 1 g(t-s)f(s)ds=:(g*f)(t). 0 
</p>
<p>Property 2. The convolution operator satisfies the distributive law of mul-
tiplication; that is, 
</p>
<p>PRooF. See Exercise 19. 0 
</p>
<p>Property 3. The convolution operator satisfies the associative law of multi-
plication; that is, U*g)*h=f*(g*h). 
</p>
<p>PROOF. See Exercise 20. 0 
</p>
<p>Property 4. The convolution of any function f with the zero function is 
zero. 
</p>
<p>PROOF. Obvious. 0 
</p>
<p>On the other hand, the convolution operator differs from the multiplica-
tion operator in that f *I =I= f and f * f=l= f 2&bull; Indeed, the convolution of a 
function f with itself may even be negative. 
</p>
<p>Example 1. Compute the convolution of f ( t) = t 2 with g( t) = I. 
</p>
<p>253 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>Solution. From Property 1, 
</p>
<p>Example 2. Compute the convolution of f(t)=cost with itself, and show 
that it is not always positive. 
Solution. By definition, 
</p>
<p>(j * j)(t) = fot cos( t-u) cosudu 
</p>
<p>= fot (costcos2 u + sintsinucosu)du 
</p>
<p>i t 1 +cos2u . t . =cost 2 du+smt J~ smucosudu 
0 0 
</p>
<p>_ t[ t + sin2t J + sin3 t -cos 2 -4- --2-
</p>
<p>t cos t + sin t cos2 t + sin 3 t 
2 
</p>
<p>t cos t + sin t ( cos2 t + sin2 t) 
</p>
<p>2 
tcost+sint 
</p>
<p>2 
</p>
<p>This function, clearly, is negative for 
</p>
<p>(2n+ 1)'77' &lt; t &lt;(2n+ 1)'77'+ ~'77', n =0, 1,2, .... 
</p>
<p>We now show that the Laplace transform of f * g is the product of the 
Laplace transform of f with the Laplace transform of g. 
</p>
<p>Theorem 9. e{(f&bull;g)(t)} = e{j(t)} Xe{ g(t)}. 
</p>
<p>PROOF. By definition, 
</p>
<p>er (f&bull;g)(t)}- J.~ .-&middot;[ !,' f(t- u)g(u)du ]"'&middot; 
This iterated integral equals the double integral 
</p>
<p>J J e-stf(t-u)g(u)dudt 
R 
</p>
<p>where R is the triangular region described in Figure 1. Integrating first 
</p>
<p>254 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.13 The convolution integral 
</p>
<p>u 
</p>
<p>t 
</p>
<p>Figure I 
</p>
<p>with respect to t, instead of u, gives 
</p>
<p>Setting t - u = g, we see tha t 
</p>
<p>Hence, 
</p>
<p>e{ U*g)(t)} = [oo g(u)[ fo 00 e-s"e-s~f(g)dg ]du 
</p>
<p>= [ fooo g(u)e-s"du] [ fooo e-s~j(g)dg] 
</p>
<p>=e{J(t)}xe{g(t)}. o 
</p>
<p>Example 3. Find the inverse Laplace transform of the function 
a 
</p>
<p>Solution. Observe that 
</p>
<p>J... = e{ t} and ~ = e{ sinat}. 
s 2 s +a 
</p>
<p>Hence, by Theorem 9 
</p>
<p>e-I{ 2 2a 2 } = ('(t-u)sinaudu 
s (s +a ) lo 
</p>
<p>at- sinat 
a2 
</p>
<p>255 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>Example 4. Find the inverse Laplace transform of the function 
</p>
<p>I 
</p>
<p>Solution. Observe that 
</p>
<p>_!_ = E{l} and 
s s2 +2s+2 
</p>
<p>I 2 = e { e -I sin t} . 
(s+1) +1 
</p>
<p>Hence, by Theorem 9, 
</p>
<p>e- 1 { 1 } = te-usinudu 
s(s2 +2s+2) Jo 
</p>
<p>= -&sect;: [ 1 - e - 1 ( cos t + sin t) ]. 
</p>
<p>Remark. Let Y2(t) be the solution of the homogeneaus equation ay" + by' 
+ cy = 0 which satisfies the initial conditions y 2(0) = 0, A(O) =I. Then, 
</p>
<p>Y2(t) 
![;(t)=f(t)* -a- (3) 
</p>
<p>is the particular solution of the nonhomogeneaus equation ay" + by' + cy = 
f(t) which satisfies the initial conditions 1[;(0) = 1[;'(0) = 0. Equation (3) is 
often much simpler to use than the variation of parameters formula de-
rived in Section 2.4. 
</p>
<p>EXERCISES 
</p>
<p>Compute the convolution of each of the following pairs of functions. 
</p>
<p>3. cosat, cosbt 4. sinat, sinbt, a=!=b 
</p>
<p>5. sin at, sin at 6. t, sint 
</p>
<p>Use Theorem 9 to invert each of the following Laplace transforms. 
</p>
<p>7. 1 8. s 9. s 
s2(s2+ 1) (s+ l)(s2 +4) (s2+ 1)2 
</p>
<p>1 
12. 2 
</p>
<p>(s2 + 1) 
</p>
<p>Use Theorem 9 to find the solution y(t) of each of the following integro-
differential equations. 
</p>
<p>13. y(t)=4t- 3 {y(u)sin(t- u)du 
</p>
<p>14. y(t)=4t-3 {y(t- u)sinudu 
</p>
<p>256 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.14 The method of elirnination for systems 
</p>
<p>15. y'(t)=sint+ {y(t- u)cosudu, y(O)=O 
</p>
<p>16. y(t)=4t2 - {y(u)e-(t-u)du 
</p>
<p>17. y'(t)+2y + {y(u)du=sint, y(O)= 1 
</p>
<p>18. y(t)= t-e' {y(u)e-udu 
</p>
<p>19. Prove thatf&bull;(g+ h)= f&bull;g+ f&bull;h. 
</p>
<p>20. Prove that (f&bull;g)&bull;h=f&bull;(g&bull;h). 
</p>
<p>2.14 The method of elimination for systems 
</p>
<p>The theory of second-order linear differential equations can also oe used 
to find the solutions of two simultaneaus first-order equations of the form 
</p>
<p>x'= ~~ =a(t)x+b(t)y+f(t) 
</p>
<p>dy 
y'= dt =c(t)x+d(t)y+g(t). 
</p>
<p>(1) 
</p>
<p>The key idea is to eliminate one of the variables, say y, and then find x as 
the solution of a second-order linear differential equation. This technique 
is known as the method of elimination, and we illustrate it with the follow-
ing two examples. 
</p>
<p>Example 1. Find all solutions of the simultaneaus equations 
</p>
<p>x'=2x+y+ t 
</p>
<p>y'=x+3y+l. 
</p>
<p>Solution. First, we solve for 
</p>
<p>(2) 
</p>
<p>y = x'- 2x- t (3) 
</p>
<p>from the first equation of (2). Differentiating this equation gives 
</p>
<p>y'= x" -2x' -1 =x +3y + 1. 
Then, substituting for y from (3) gives 
</p>
<p>x" -2x' -1 = x+3(x' -2x- t)+ 1 
so that 
</p>
<p>x"-5x'+5x=2-3t. (4) 
</p>
<p>Equation (4) is a second-order linear equation and its solution is 
</p>
<p>. (1 +3t) 
x(t)=e5t/2[ cieVS t/2+c2e-Vs t/2]- 5 
</p>
<p>257 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>for some constants c1 and c2&bull; Finally, plugging this expression into (3) gives 
</p>
<p>(/) - 5tf2[ l+YS v'5t/2+ 1-v'S -v'St/2]+ t-I y - e 2 cle 2 c2e 5 . 
</p>
<p>Example 2. Find the solution of the initial-value problern 
</p>
<p>x'=3x-y, 
</p>
<p>y'=x+y, 
</p>
<p>x(0)=3 
</p>
<p>y(O)=O. 
</p>
<p>Solution. From the first equation of (5), 
</p>
<p>y=3x-x'. 
</p>
<p>Differentiating this equation gives 
</p>
<p>y'=3x'- x" =x + y. 
</p>
<p>Then, substituting for y from (6) gives 
</p>
<p>3x'- x" = x+3x- x' 
so that 
</p>
<p>x"-4x'+4x=O. 
</p>
<p>This implies that 
</p>
<p>x(t) =(c1 +c2t)e21 
</p>
<p>for some constants c1, c2, and plugging this expression into (6) gives 
</p>
<p>y(t)=(c1- c2 + c 2t)e21 &bull; 
</p>
<p>The constants c1 and c2 are determined from the initial conditions 
</p>
<p>Hence c1 =3, c2 =3 and 
</p>
<p>x(O) =3 = c1 
</p>
<p>y(O)=O= c1 - c2&bull; 
</p>
<p>x( t) = 3(1 + t) e21, y( t) = 3te21 
</p>
<p>is the solution of (5). 
</p>
<p>(5) 
</p>
<p>(6) 
</p>
<p>Remark. The simultaneous equations (1) are usually referred to as a first-
order system of equations. Systems of equations are treated fully in 
Chapters 3 and 4. 
</p>
<p>EXERCISES 
</p>
<p>Find all solutions of each of the following systems of equations. 
</p>
<p>1. x'=6x-3y 
y'=2x+y 
</p>
<p>258 
</p>
<p>2. x'= -2x+y+t 
y'= -4x+3y-l </p>
<p/>
</div>
<div class="page"><p/>
<p>2.15 Higher-order equations 
</p>
<p>3. x'= -3x+2y 
y'= -x-y 
</p>
<p>4. x'=x+y+e 1 
</p>
<p>y'=x-y-e 1 
</p>
<p>Find the solution of each of the following initial-value problems. 
</p>
<p>5. x'=x+y, x(0)=2 
y'=4x+y, y(0)=3 
</p>
<p>7. x'=x-y, x(0)=1 
y'=5x-3y, y(0)=2 
</p>
<p>9. x'=4x+5y+4e 1 cost, x(O)=O 
y'= -2x-2y, y(O)=O 
</p>
<p>ll. x'=2x-5y+sint, x(O)=O 
y'=x-2y+tant, y(O)=O 
</p>
<p>2.15 Higher-order equations 
</p>
<p>6. x'=x-3y, x(O)=O 
y'= -2x+2y, y(0)=5 
</p>
<p>8. x'=3x-2y, x(O)= 1 
y'=4x-y, y(0)=5 
</p>
<p>10. x'=3x-4y+e 1, x(0)=1 
y'=x-y+e1, y(O)= 1 
</p>
<p>12. x'=y+fi(t), x(O)=O 
y'= -x+h(t), y(O)=O 
</p>
<p>In this section we briefly discuss higher-order linear differential equations. 
</p>
<p>Definition. The equation 
</p>
<p>dny dn-y 
L[y] = an(t) d n + an-l (t)--1 + ... +a0(t)y =0, an(t):;,!,O (1) t dtn-
</p>
<p>is called the general nth order homogeneous linear equation. The dif-
ferential equation (1) together with the initial conditions 
</p>
<p>(t ) - '(t )- t (n-l)(t )- (n-1) Y o -yo, Y o -yo, ... ,y o -Yo (1') 
</p>
<p>is called an initial-value problem. The theory for Equation (1) is com-
pletely analogous to the theory for the second-order linear homoge-
neous equation which we studied in Sections 2.1 and 2.2. Therefore, we 
will state the relevant theorems without proof. Complete proofs can be 
obtained by generalizing the methods used in Sections 2.1 and 2.2, or by 
using the methods to be developed in Chapter 3. 
</p>
<p>Theorem 10. Let y 1(t), ... ,yn(t) be n independent solutions of (1); that is, no 
solution Y/t) is a linear combination of the other solutions. Then, every 
solution y(t) of (1) is of the form 
</p>
<p>(2) 
</p>
<p>for some choice of constants c1, ... , cn- For this reason, we say that (2) is 
the generat solution of ( 1 ). 
</p>
<p>To find n independent solutions of (1) when the coefficients a0, a1, ... ,an 
do not depend on t, we compute 
</p>
<p>(3) 
</p>
<p>259 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>This implies that err is a solution of (1) if, and only if, r is a root of the 
characteristic equation 
</p>
<p>(4) 
</p>
<p>Thus, if Equation (4) has n distinct roots r1, ... ,rn, then the general solution 
of (1) isy(t)=c1e''1 + ... +cne'&bull;1&bull; If 'j=a1 +i&szlig;1 is a complex root of (4), 
then 
</p>
<p>and 
v(t) =Im{ e'i1 } = ea,r sin&szlig;_/ 
</p>
<p>are two real-valued solutions of (1). Finally, if r 1 is a root of multiplicity k; 
that is, if 
</p>
<p>anrn + ... + a0= (r- r1)kq(r) 
</p>
<p>where q(r1)*0, then e''1, te''1, ... ,tk-le''1 arekindependent solutions of 
(1). We prove this last assertion in the following manner. Observe from (3) 
that 
</p>
<p>L[ e'1 ] = (r- r1)kq(r)e'1 
</p>
<p>if r 1 is a root of multiplicity k. Therefore, 
</p>
<p>= ~(r- r1)kq(r)e'1l ar1 r- r, 
=0, for 1 &lt;.j&lt;k. 
</p>
<p>Example 1. Find the general solution of the equation 
</p>
<p>d4y 
-+y=O. 
dt4 
</p>
<p>(5) 
</p>
<p>Solution. The characteristic equation of (5) is r4 + 1 =0. We find the roots 
of this equation by noting that 
</p>
<p>Hence, 
</p>
<p>r 1 = ei"'/4 = cos:!.. + isin:!.. = - 1-(1 + i) 
4 4 V2 ' 
</p>
<p>3wi/4 3'17 &middot; &middot; 3'17 1 (1 ') r2 = e = cos 4 + 1 sm 4 = - V2 - 1 , 
</p>
<p>Swi/4 5'17 &middot; &middot; 5'17 1 (1 ') r3 = e = cos 4 + 1 sm 4 =- V2 + 1 , 
</p>
<p>260 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.15 Higher-order equations 
</p>
<p>and 
</p>
<p>7wi/4 7 1r &bull; &bull; 7 1r 1 ( 1 .) r4 =e =cos- +1sm- = -- -1 
4 4 V2 
</p>
<p>are 4 roots of the equation r4 + I =0. The roots r3 and r4 are the complex 
conjugates of r2 and r 1, respectively. Thus, 
</p>
<p>e''1 = e 11Y'i [ cos ~ + isin ~ ] 
</p>
<p>and 
</p>
<p>are 2 complex-valued solutions of (5), and this implies that 
</p>
<p>are 4 real-valued solutions of (5). These solutions are clearly independent. 
Hence, the general solution of (5) is 
</p>
<p>y(t)= e 11Y'i [a 1cos - 1- +b 1sin - 1-] 
V2 V2 
</p>
<p>+ e-t/Y'i [a cos - 1- + b sin - 1- ]&middot; 2\12 2\12 
</p>
<p>Example 2. Find the general solution of the equation 
</p>
<p>d4y d3y d2y dy 
--3-+3---=0. 
dt4 dt3 dt2 dt 
</p>
<p>Solution. The characteristic equation of (6) is 
</p>
<p>0= r4 -3r3 +3r2 - r= r(r3 -3r2 +3r-I) 
</p>
<p>= r(r-1)3. 
</p>
<p>(6) 
</p>
<p>Its roots are r 1 = 0 and r 2 = I, with r 2 = I a root of multiplicity three. Hence, 
the generat solution of (6) is 
</p>
<p>Y( t) = c1 + ( c2 + c3t + c4t2)e 1&bull; 
</p>
<p>The theory for the nonhomogeneaus equation 
</p>
<p>dny 
L[y] = an(t) dtn + ... + ao(t)y = f(t), an(t)~O (7) 
</p>
<p>261 </p>
<p/>
</div>
<div class="page"><p/>
<p>2 Second-order linear differential equations 
</p>
<p>is also completely analogous to the theory for the second-order nonhomo-
geneous equation. The following results are the analogs of Lemma 1 and 
Theorem 5 of Section 2.3. 
</p>
<p>Lemma 1. The difference of any two solutions of the nonhomogeneous equa-
</p>
<p>tion (7) is a so/ution of the homogeneous equation (1). 
</p>
<p>Theorem 11. Let 1/;(t) be a particular solution of the nonhomogeneous equa-
</p>
<p>tion (7), and Iet y 1(t), ... ,yn(t) be n independent solutions of the homoge-
neous equation (1). Then, every so/ution y(t) of (7) is of the form 
</p>
<p>for some choice of constants c1, c2, &bull;&bull;. ,cn. 
</p>
<p>The method of judicious guessing also applies to the nth-order equation 
</p>
<p>(8) 
</p>
<p>1t is easily verified that Equation (8) has a particular solution 1/;(t) of the 
form 
</p>
<p>if ea1 is not a solution of the homogeneous equation, and 
</p>
<p>t/;(t)=t1[ c0 +c1t+ ... +cktk]ea1 
</p>
<p>if ti-iea1 is a solution of. the homogeneous equation, but tiea1 is not. 
</p>
<p>Example 3. Find a particular solution !f(t) of the equation 
</p>
<p>dy d 2y dy 
L[y] =-+3- +3- +y=e 1&bull; 
</p>
<p>dt 3 dt 2 dt 
(9) 
</p>
<p>Solution. The characteristic equation 
</p>
<p>r3 +3r2 +3r+ 1 =(r+ 1)3 
</p>
<p>has r = - 1 as a triple root. Hence, e 1 is not a solution of the homogeneous 
equation, and Equation (9) has a particular solution !f(t) of the form 
</p>
<p>!f(t)=Ae1&bull; 
</p>
<p>Computing L[t/;](t)=8Ae 1, we see that A =k. Consequently, !f(t)=ie' is a 
particular solution of (9). 
</p>
<p>There is also a variation of parameters formula for the nonhomoge-
neous equation (7). Let v(t) be the solution of the homogeneous equation 
</p>
<p>262 </p>
<p/>
</div>
<div class="page"><p/>
<p>2.15 Higher-order equations 
</p>
<p>(I) which satisfies the initial conditions v(t0)=0, v'(t0)=0, ... ,v&lt;n-2l(t0)=0, 
v&lt;n-ll(t0) =I. Then, 
</p>
<p>( v(t-s) 
1/;(t)= }._ an(s) f(s)ds 
</p>
<p>to 
</p>
<p>is a particular solution of the nonhomogeneaus equation (7). We will prove 
this assertion in Section 3.12. (This can also be proven using the method of 
Laplace transforms; see Section 2.13.) 
</p>
<p>EXERCISES 
</p>
<p>Find the general solution of each of the following equations. 
</p>
<p>1. y"' -2y"-y' +2y =0 2. y"' -6y" +5y' + 12y =0 
</p>
<p>3. y(iv)_ 5y"' +6y" +4y'- Sy =0 4. y"'-y"+y'-y=O 
</p>
<p>Solve each of the following initial-value problems. 
</p>
<p>5. y(iv&gt;+4y"' + l4y"- 20y' +25y =0; y(O)= y'(O)= y"(O)=O, y"'(O)=O 
</p>
<p>6. y&lt;iv)_ y =0; y(O)= 1, y'(O)= y"(O)=O, y"'(O)= -1 
</p>
<p>7. y&lt;v&gt;- 2y(ivJ + y"' =0; y(O)= y'(O)= y"(O) = y"'(O) =0, y&lt;ivl(O) = -1 
</p>
<p>8. Given that y 1(t) = e1 cost is a solution of 
</p>
<p>y(iv)_2y"' + y" +2y' -2y=O, (*) 
</p>
<p>find the general solution of (*). Hint: Use this information to find the roots of 
the characteristic equation of (*). 
</p>
<p>Find a particular solution of each of the following equations. 
</p>
<p>9. y"'+y'=tant 10. y(iv)_y=g(t) 
</p>
<p>11. y(iv) + Y = g(t) 
</p>
<p>13. y'" -4y'= t+cost+2e- 2' 
</p>
<p>15. y&lt;iv) + 2y" + y = t2 sint 
</p>
<p>17. y"'+y"+y'+y=t+e- 1 
</p>
<p>12. y"'+y'=2t2 +4sint 
</p>
<p>14. y&lt;iv)_y=t+sint 
</p>
<p>16. y(vi)+ y" = 12 
</p>
<p>18. y&lt;iv)+4y"' +6y" +4y' + y = t3e- 1 
</p>
<p>Hint for (18): Make the substitution y = e _,v and so1ve for v. Otherwise, it will 
take an awfully long time to do this problem. 
</p>
<p>263 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 
Systems of differential equations 
</p>
<p>3.1 Algebraic properties of solutions of linear systems 
</p>
<p>In this chapter we will consider simultaneaus first-order differential equa-
tions in several variables, that is, equations of the form 
</p>
<p>dx 1 
dt =j1 (t,x 1, &bull;&bull;&bull; ,xn), 
</p>
<p>dx2 
dt = J2 (t,xl, ... ,xn), (I) 
</p>
<p>dxn 
dt =Jn(t,xl, ... ,xn). 
</p>
<p>A solution of (I) is n functions x 1 ( t), .. "xn (t) such that dx/ t) j dt = 
.fj(t,x1(t), ... ,xn(t)),j=I,2, ... ,n. For example, x 1(t)=t and xit)=t2 is a 
solution of the simultaneaus first-order differential equations 
</p>
<p>dx 1 dx2 
dt =I and dt =2x1 
</p>
<p>since dx 1(t)/ dt =I and dxit)/ dt =2t =2x1(t). 
In addition to Equation (I), we will often impose initial conditions on 
</p>
<p>the functions x 1(t), .. . ,xn(t). These will be of the form 
</p>
<p>x 1(t0 )=x?, x 2 (t 0 )=x~, ... ,xn(t 0 )=x~. (I') 
Equation (1), together with the initial conditions (I)', is referred to as an 
initial-value problem. A solution of this initial-value problern is n functions 
x 1(t), ... ,xn(t) which satisfy (I) and the initial conditions 
</p>
<p>x 1 (t0 ) = x?, ... ,xn(t0 ) = x~. 
</p>
<p>For example, x 1(t)=e 1 and xit)=I+e21 j2 is a solution of the initial-
</p>
<p>264 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.1 Algebraic properties of solutions of linear systems 
</p>
<p>value problern 
dx 1 
dt =Xp 
</p>
<p>dx2 2 
dt =xi, 
</p>
<p>x 1(0)=1, 
</p>
<p>3 
x2 (0)= 2, 
</p>
<p>since dx 1(t)l dt = e 1 = x 1(t), dxit)l dt = e21 = xf(t), x 1(0) = 1 and x2(0) = ~&middot; 
Equation (1) is usually referred to as a system of n first-order differen-
</p>
<p>tial equations. Equations of this type arise quite often in biological and 
physical applications and frequently describe very complicated systems 
since the rate of change of the variable xj depends not only on t and Xp but 
on the value of all the other variables as well. One particular example is the 
blood glucose model we studied in Section 2.7. In this model, the rates of 
change of g and h (respectively, the deviations of the blood glucose and net 
hormonal concentrations from their optimal values) are given by the equa-
tions 
</p>
<p>dg 
- = -m g-m h+J(t) 
dt I 2 ' 
</p>
<p>This is a system of two first-order equations for the functions g(t) and h(t). 
First-ordersystems of differential equations also arise from higher-order 
</p>
<p>equations for a single variable y(t). Every nth-order differential equation 
for the single variable y can be converted into a system of n first-order 
equations for the variables 
</p>
<p>dy dn-y 
xl(t)=y, x2(t)= dt , ... ,xn(t)= dtn-1 . 
</p>
<p>Examples 1 and 2 illustrate how this works. 
</p>
<p>Example 1. Convert the differential equation 
</p>
<p>dny dn-y 
an(t) d n +an-l(t)--1 + ... +aoy=O 
</p>
<p>t dtn-
</p>
<p>into a system of n first-order equations. 
Solution. Let x 1(t)=y, x2(t)=dyldt, ... , and xn(t)=dn-yldtn-I. Then, 
</p>
<p>dx 1 
dt =x2, 
</p>
<p>and 
</p>
<p>Example 2. Convert the initial-value problern 
</p>
<p>d3y ( dy )2 -+ - +3y=e1&middot; 
dt3 dt ' 
</p>
<p>y(O)= l, y'(O)=O, y"(O)=O 
</p>
<p>into an initial-value problern for the variables y, dy I dt, and d 2y I dt2. 
</p>
<p>265 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>Solution. Set x 1(t)=y, x2(t)=dyjdt, and x3(t)=d2yjdt2. Then, 
</p>
<p>dx 1 dx2 dx3 
dt =x2, dt =x3, dt =et-xi-3xl. 
</p>
<p>Moreover, the functions x 1, x2, and x3 satisfy the initial conditions x 1(0)= 
1, xiO)=O, and xiO)=O. 
</p>
<p>lf each of the functions j 1, ... .!n in (1) is a linear function of the depen-
dent variables x1, ... ,xn, then the system of equations is said to be linear. 
The most general system of n first-order linear equations has the form 
</p>
<p>dx 1 
dt = a11 (t)x 1 + ... + a1n(t)xn + g 1 (t) 
</p>
<p>(2) 
</p>
<p>dxn 
dt =an I (t)xl + .. &middot; + ann(t)xn + gn(t). 
</p>
<p>lf each of the functions g1, ... ,gn is identically zero, then the system (2) is 
said to be homogeneous; otherwise it is nonhomogeneous. In this chapter, 
we only consider the case where the coefficients aij do not depend on t. 
</p>
<p>Now, even the homogeneaus linear system with constant coefficients 
</p>
<p>dx 1 
dt = allxl + ... + alnxn 
</p>
<p>(3) 
</p>
<p>dxn 
dt =anlxl + &middot;&middot;&middot; +annxn 
</p>
<p>is quite cumbersome to handle. This is especially true if n is large. There-
fore, we seek to write these equations in as concise a manner as possible. 
To this end we introduce the concepts of vectors and matrices. 
</p>
<p>Definition. A vector 
</p>
<p>x= 
</p>
<p>is a shorthand notation for the sequence of numbers x 1, &bull;&bull;&bull; , xn. The 
numbers x 1, ... ,xn are called the components of x. If x 1=x1(t), ... , and 
Xn = Xn ( t), then 
</p>
<p>is called a vector-valued function. Its derivative dx(t)/ dt is the vector-
</p>
<p>266 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.1 Algebraic properties of solutions of linear systems 
</p>
<p>vaiued function 
</p>
<p>dx 1(t) 
</p>
<p>dt 
</p>
<p>dxn(t) 
</p>
<p>dt 
</p>
<p>Definition. A matrix 
a11 a12 0 1n 
0 21 a22 02n 
</p>
<p>A= 
</p>
<p>0ml am2 0mn 
</p>
<p>is a shorthand notation for the array of numbers aiJ arranged in m rows 
and n coiumns. The eiement lying in the ith row and jth column is de-
noted by aiJ, the first subscript identifying its row and the second sub-
script identifying its column. A is said to be a square matrix if m = n. 
</p>
<p>Next, we define the product of a matrix A with a vector x. 
</p>
<p>Definition. Let A be an n X n matrix with elements aiJ and Iet x be a vector 
with components x 1, &bull;&bull;&bull; ,xn. We define the product of A with x, denoted 
by Ax, as the vector whose ith component is 
</p>
<p>i= 1,2, ... ,n. 
</p>
<p>In other words, the ith component of Ax is the sum of the product of 
corresponding terms of the ith row of A with the vector x. Thus, 
</p>
<p>a11 a12 aln XI 
a21 a22 a2n x2 
</p>
<p>Ax= 
</p>
<p>an I an2 ann Xn 
</p>
<p>a11xl +a12x2+ &middot;&middot;&middot; +alnxn 
a21X1 +a22x2+ &middot;&middot;&middot; +a2nxn 
</p>
<p>an lXI + an2X2 + &middot; &middot; &middot; + annXn 
</p>
<p>For example, 
</p>
<p>H 2 4WJ r 3+4+4J n 0 6 2 = -3+0+6 = 3 . I I I 3+2+1 6 
267 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>Finally, we observe that the left-hand sides of (3) are the components of 
the vector dxj dt, while the right-hand sides of (3) are the components 
of the vector Ax. Hence, we can write (3) in the concise form 
</p>
<p>x{:J 
au a12 
</p>
<p>:i= dx =Ax 
a21 a22 
</p>
<p>where and A= 
dt ' 
</p>
<p>an I an2 
</p>
<p>Moreover, if x 1(t), ... ,xn(t) satisfy the initial conditions 
</p>
<p>x 1 (t0 ) = x?, ... ,xn(t0 ) = x~, 
</p>
<p>then x(t) satisfies the initial-value problern 
</p>
<p>:i=Ax, 
</p>
<p>For example, the system of equations 
</p>
<p>dx 1 
dt =3x1-7x2+9x3 
</p>
<p>dx2 
dt = 15x1 +x2-x3 
</p>
<p>dx3 
dt =7xl +6x3 
</p>
<p>can be written in the concise form 
</p>
<p>&middot;~ H -r -!]~ 
and the initial-value problern 
</p>
<p>dx 1 
dt =xl-x2+x3, 
</p>
<p>dx2 
dt =3x2-x3, 
</p>
<p>dx3 
dt=xl+7x3, 
</p>
<p>can be written in the concise form 
</p>
<p>268 
</p>
<p>xlO)=O 
</p>
<p>xiO)= -1 
</p>
<p>{4) 
</p>
<p>{5) </p>
<p/>
</div>
<div class="page"><p/>
<p>3.1 Algebraic properties of solutions of linear systems 
</p>
<p>Now that we have succeeded in writing (3) in the more manageable 
form (4), we can tackle the problern of finding all of its solutions. Since 
these equations are linear, we will try and play the same game that we 
played, with so much success, with the second-order linear homogeneous 
equation. To wit, we will show that a constant times a solution and the 
sum of two solutions are again solutions of (4). Then, we will try and show 
that we can find every solution of (4) by taking alllinear combinations of a 
finite number of solutions. Of course, we must first define what we mean 
by a constant times x and the sum of x and y if x and y are vectors with n 
components. 
</p>
<p>Definition. Let c be a number and x a vector with n components x 1, &bull;&bull;&bull; ,xn. 
We define cx tobe the vector whose components are cx1, &bull;&bull;&bull; ,cxn, that is 
</p>
<p>cx=c 
</p>
<p>For example, if 
</p>
<p>c~2 and x~ [H then 2x~2[!] ~ UJ 
This process of multiplying a vector x by a number c is called scalar 
multiplication. 
</p>
<p>Definition. Let x and y be vectors with components x 1, &bull;&bull;&bull; ,xn andy 1, &bull;&bull;&bull; ,yn 
respectively. We define x + y to be the vector whose components are 
x 1 + y 1, &bull;&bull;&bull; ,Xn + Yn&bull; that is 
</p>
<p>For example, if 
</p>
<p>then 
</p>
<p>xl 
</p>
<p>x2 
</p>
<p>x+y= + 
</p>
<p>Y1 
Y2 
</p>
<p>and y= -1] -6 
7 ' 
9 
</p>
<p>x+y~ iH =~ ~ :~ 
This process of adding two vectors together is called vector addition. 
</p>
<p>269 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>Having defined the processes of scalar multiplication and vector addi-
tion, we can now state the following theorem. 
</p>
<p>Theorem 1. Let x(t) and y(t) be two solutions of (4). Then (a) cx(t) is a solu-
tion,jor any constant c, and (b) x(t)+y(t) is again a solution. 
</p>
<p>Theorem 1 can be proven quite easily with the aid of the following 
Iemma. 
</p>
<p>Lemma. Let A be an n X n matrix. For any vectors x and y and constant c, 
(a) A(cx)=cAx and (b) A(x+y)=Ax+Ay. 
</p>
<p>PROOF OF LEMMA. 
</p>
<p>(a) We prove that two vectors are equal by showing that they have the 
same components. Tothis end, observe that the ith component of the vec-
tor cAx is 
</p>
<p>and the ith component of the vector A( cx) is 
</p>
<p>an(cx 1)+a;2(cx2)+ ... +a;n(cxn)=c(a;1x 1+ ... +a;nxn). 
</p>
<p>Hence A( cx) = cAx. 
(b) The ith component of the vector A(x + y) is 
ail (xl + Yl) + ... + a;n(xn + Yn) = (a;IXI + ... + a;nxn) + (ailyl + ... + a;nYn). 
</p>
<p>But this is also the ith component of the vector Ax + Ay since the ith com-
ponent of Ax is an x 1 + ... + a;nxn and the ith component of Ay is an y 1 
+ ... +a;nYn&middot; Hence A(x+y)=Ax+Ay. 0 
</p>
<p>PROOF OF THEOREM 1. 
(a). If x(t) is a solution of (4), then 
</p>
<p>d dx(t) 
dt cx(t) = c----;]1 = cAx(t) =A( cx(t)). 
</p>
<p>Hence, cx( t) is also a solution of ( 4). 
(b). If x(t) and y(t) are solutions of (4) then 
</p>
<p>d dx(t) dy(t) 
dt (x(t) +y(t)) =----;]{ +----;]{ = Ax(t) + Ay(t) = A(x(t) + y(t)). 
</p>
<p>Hence, x(t)+y(t) is also a solution of (4). 0 
</p>
<p>An immediate corollary of Theorem 1 is that any linear combination of 
solutions of (4) is again a solution of (4). That is to say, if x1(t), ... ,xl(t) are 
j solutions of (4), then c1x1(t)+ ... + c1xi(t) is again a solution for any 
</p>
<p>270 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.1 Algebraic properties of solutions of linear systems 
</p>
<p>choice of constants c1,c2, &bull;&bull;&bull; ,c1. For example, consider the system of equa-
tions 
</p>
<p>dx ( 0 
dt = -4 b )x, x = ( ~~). (6) 
</p>
<p>This system of equations was derived from the second-order scalar equa-
tion (d 2y I dt2)+4y =0 by setting x 1 = y and x 2 = dy I dt. Since y 1(t)=cos2t 
and yit) = sin2t are two solutions of the scalar equation, we know that 
</p>
<p>x(t) = ( x 1 (t)) = c1 ( cos2t) + c2 ( sin2t) 
x 2 (t) -2sin2t 2cos2t 
</p>
<p>( 
c1cos2t+c2sin2t) 
</p>
<p>= - 2c1 sin2t + 2c2 cos2t 
</p>
<p>is a solution of (6) for any choice of constants c1 and c2&bull; 
The next step in our gameplan is to show that every solution of (4) can 
</p>
<p>be expressed as a linear combination of finitely many solutions. Equiv-
alently, we seek to determine how many solutions we must find before we 
can generate all the solutions of (4). There is a branch of mathematics 
known as linear algebra, which addresses itself to exactly this question, and 
it is to this area that we now turn our attention. 
</p>
<p>EXERCISES 
</p>
<p>In each of Exercises 1-3 convert the given differential equation for the sin-
gle variable y into a system of first-order equations. 
</p>
<p>1. d3y+(dy)2=0 2. d3y+cosy=e' 3. d4y+d2y=l 
dt3 dt dt3 dt4 dt2 
</p>
<p>4. Convert the pair of second-order equations 
</p>
<p>d 2y dz d 2 dy 
3 2 0 ~ + 3- + 2z = 0 dt2 + dt + y = ' dt2 dt 
</p>
<p>into a system of 4 first-order equations for the variables 
</p>
<p>xl=y, 
</p>
<p>5. (a) Lety(t) be a solution of the equationy"+y'+y=O. Show that 
</p>
<p>x(t)=(y(t)) 
y'(t) 
</p>
<p>is a solution of the system of equations 
</p>
<p>x=( -~ -Dx. 
271 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>(b) Let 
</p>
<p>be a solution of the system of equations 
</p>
<p>i= ( 0 l )x 
-l -1 . 
</p>
<p>Show that y = x 1 ( t) is a solution of the equation y" + y' + y = 0. 
</p>
<p>In each of Exercises 6-9, write the given system of differential equations 
and initial values in the form x = Ax, x(t0) = x0. 
6 . .X 1=3x1-7x2, x 1(0)=1 
</p>
<p>x2=4x1, xiO)= 1 
</p>
<p>8 . .X1 =x1 +x2-x3, 
x2=3x 1-x2+4x3, 
x3 = -xl-x2, 
</p>
<p>10. Let 
</p>
<p>x 1(0)=0 
xiO)= 1 
x 3(0)= -1 
</p>
<p>7. x 1 =5x1 +5x2, 
x2=-xl+7x2, 
</p>
<p>Xt(3)=0 
x 2(3)=6 
</p>
<p>9. x1=-x3, x 1(-1)=2 
x2= x 1, xi -1)=3 
x3=-x2, x3(-1)=4 
</p>
<p>x=(D and y=( -~)&middot; 
Compute x+y and 3x-2y. 
</p>
<p>11. Let 
</p>
<p>A=( ~ 
-1 
</p>
<p>Compute Ax if 
</p>
<p>(a) x=U)&middot; (b)x=(O&middot; (c)x=(n&middot; 
</p>
<p>12. Let A be any n X n matrix and Iet ei be the vector whose jth component is 1 
and whose remaining components are zero. Verify that the vector Aei is thejth 
column of A. 
</p>
<p>13. Let 
</p>
<p>( -1 
,j n. A= 2 l -1 0 
</p>
<p>Compute Ax if 
</p>
<p>(a) x= 0)&middot; (b)x=( =D&middot; (c)x=O)&middot; (d)x=(?)&middot; 
14. Let A be a 3 X 3 matrix with the property that 
</p>
<p>272 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.2 Vector spaces 
</p>
<p>Compute 
</p>
<p>Hint: Write 
</p>
<p>as a linear combination of 
</p>
<p>15. Let A be a 2 X 2 matrix with the property that 
</p>
<p>Find A. Hint: The easy way is to use Exercise 12. 
</p>
<p>3.2 V ector spaces 
</p>
<p>In the previous section we defined, in a natural manner, a process of 
adding two vectors x and y together to form a new vector z=x+y, and a 
process of multiplying a vector x by a scalar c to form a new vector u = cx. 
The former process was called vector addition and the latter process was 
called scalar multiplication. Our study of linear algebra begins with the 
more general premise that we have a set V of elements x,y,z, ... and that 
we have one process that combines two elements x and y of V to form a 
third element z in V and a second process that combines a number c and 
an element x in V to form a new element u in V. We will denote the first 
process by addition; that is, we will write z = x + y, and the second process 
by scalar multiplication; that is, we will write u = cx, if they satisfy the us-
ual axioms of addition and multiplication. These axioms are: 
</p>
<p>(i) x+y=y+x (commutative law) 
(ii) x+(y+z)=(x+y)+z (associative law) 
</p>
<p>(iii) There is a unique element in V, called the zero element, and denoted 
by 0, having the property that x+O=x for all x in V. 
</p>
<p>(iv) For each element x in V there is a unique element, denoted by - x 
and called minus x, suchthat x+( -x)=O. 
</p>
<p>(v) l&middot;x=x for all x in V. 
(vi) (ab)x=a(bx) for any numbers a,b and any element x in V. 
</p>
<p>(vii) a(x+y)=ax+ay 
(viii) (a+b)x=ax+bx. 
</p>
<p>A set V, together with processes addition and multiplication satisfying 
(i)-(viii) is said tobe a vector space and its elements are called vectors. The 
</p>
<p>273 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>numbers a, b will usually be real numbers, except in certain special cases 
where they will be complex numbers. 
</p>
<p>Remark 1. Implicit in axioms (i)-(viii) is the fact that if x and y are in V, 
then the linear combination ax + by is again in V for any choice of con-
stants a and b. 
</p>
<p>Remark 2. In the previous section we defined a vector x as a sequence of n 
numbers. In the more general context of this section, a quantity x is a vec-
tor by dint of its being in a vector space. That is to say, a quantity x is a 
vector if it belongs to a set of elements V which is equipped with two 
processes (addition and scalar multiplication) which satisfy (i)-(viii). As we 
shall see in Example 3 below, the set of all sequences 
</p>
<p>x= 
</p>
<p>of n real numbers is a vector space (with the usual Operations of vector 
addition and scalar multiplication defined in Section 3.1). Thus, our two 
definitions are consistent. 
</p>
<p>Example 1. Let V be the set of all functions x(t) which satisfy the differen-
tial equation 
</p>
<p>d 2x --x=O 
dt2 
</p>
<p>(1) 
</p>
<p>with the sum of two functions and the product of a function by a number 
being defined in the usual manner. That is to say, 
</p>
<p>and 
</p>
<p>{cf)(t)= cf(t). 
</p>
<p>lt is trivial to verify that V is a vector space. Observe first that if x 1 and x 2 
are in V, then every linear combination c1x 1 + c2x2 is in V, since the dif-
ferential equation (1) is linear. Moreover, axioms (i), (ii), and (v)-(viii) are 
automatically satisfied since all we are doing at any time t in function 
addition and multiplication of a function by a number is adding or multi-
plying two numbers together. The zero vector in V is the function whose 
value at any timet is zero; this function is in V since x(t):=O is a solution 
of (1). Finally, the negative of any function in V is again in V, since the 
negative of any solution of (1) is again a solution of (1). 
</p>
<p>274 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.2 Vector spaces 
</p>
<p>Example 2. Let V be the set of all solutions x(t) of the differential equa-
tion ( d 2x I dt 2)- 6x 2 = 0, with the sum of two functions and the product of 
a function by a number being defined in the usual manner. V is not a vec-
tor space since the sum of any two solutions, while being defined, is not 
necessarily in V. Similarly, the product of a solution by a constant is not 
necessarily in V. For example, the function x(t) = 1 I t2 is in V since it 
satisfies the differential equation, but the function 2x(t)=2lt2 is not in V 
since it does not satisfy the differential equation. 
</p>
<p>Example 3. Let V be the set of all sequences 
</p>
<p>of n real numbers. Define x + y and cx as the vector addition and scalar 
multiplication defined in Section 3.1. It is trivial to verify that V is a vector 
space under these operations. The zero vector is the sequence 
</p>
<p>and the vector - x is the vector 
</p>
<p>0 
0 
</p>
<p>0 
</p>
<p>This space is usually called n dimensional Euclidean space and is denoted 
by Rn. 
</p>
<p>Example 4. Let V bt the set of all sequences 
</p>
<p>of n complex numbers x 1, &bull;&bull;&bull; ,xn. Define x+y and cx, for any complex 
number c, as the vector addition and scalar multiplication defined in Sec-
tion 3.1. Again, it is trivial to verify that V is a vector space under these 
Operations. This space is usually called complex n dimensional space and is 
denoted by cn. 
</p>
<p>275 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>Example 5. Let V be the set of all n X n matrices A. Define the sum of two 
matrices A and B to be the matrix obtained by adding together corre-
sponding elements of A and B, and define the matrix cA tobe the matrix 
obtained by multiplying every element of A by c. In other words, 
</p>
<p>au ai2 ain bu b12 bin 
</p>
<p>a2i a22 a2n b2i b22 b2n 
+ 
</p>
<p>ani an2 ann bni bn2 bnn 
</p>
<p>au + bu a12 + bi2 ain +bin 
a2i + b2i a22+ b22 a2n + b2n 
</p>
<p>= 
</p>
<p>ani + bni an2 + bn2 ann + bnn 
</p>
<p>and 
</p>
<p>au a12 ain cau ca 12 cain 
a2i a22 azn cazi cazz ca2n 
</p>
<p>c 
</p>
<p>ani an2 ann cani can2 cann 
</p>
<p>Axioms (i), (ii), and (v)--{viii) are automatically satisfied since all we are 
doing in adding two matrices together or multiplying a matrix by a number 
is adding or multiplying two numbers together. The zero vector, or the 
matrix 0, is the matrix whose every element is the number zero, and the 
negative of any matrix A is the matrix 
</p>
<p>Hence V is a vector space under these operations of matrix addition and 
scalar multiplication. 
</p>
<p>Example 6. We now present an example of a set of elements which comes 
close to being a vector space, but which doesn't quite make it. The purpose 
of this example is to show that the elements of V can be just about any-
thing, and the operation of addition can be a rather strange process. Let V 
be the set consisting of three animals, a cat, a dog, and a mouse. Whenever 
any two of these animals meet, one eats up the other and changes into a 
different animal. The rules of eating are as follows. 
</p>
<p>276 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.2 Vector spaces 
</p>
<p>(I) If a dog meets a cat, then the dog eats up the cat and changes into a 
mouse. 
</p>
<p>(2) If a dog meets another dog, then one dog eats up the other and 
changes into a cat. 
</p>
<p>(3) If a dog meets a mouse, then the dog eats up the mouse and remains 
unchanged. 
</p>
<p>(4) If a cat meets another cat, then one cat eats up the other and changes 
into a dog. 
</p>
<p>(5) If a cat meets a mouse, then the cat eats up the mouse and remains un-
changed. 
</p>
<p>(6) If a mouse meets another mouse, then one mouse eats up the other and 
remains unchanged. 
</p>
<p>Clearly, "eating" is a process which combines two elements of V to form a 
third element in V. If we call this eating process addition, and denote it by 
+, then rules 1-6 can be written concisely in the form 
</p>
<p>I. D+C=M 
4. C+C=D 
</p>
<p>2. D+D=C 
5. C+M=C 
</p>
<p>3. D+M=D 
6. M+M=M. 
</p>
<p>This operation of eating satisfies all the axioms of addition. To see this, 
note that axiom (i) is satisfied since the eating formulae do not depend on 
the order of the two animals involved. This is to say, D + C = C + D, etc. 
Moreover, the result of any addition is again an animal in V. This would 
not be the case, for example, if a dog ate up a cat and changed into a 
hippopotamus. The associative law (ii) is also satisfied, but it has to be 
verified explicitly. For example, suppose that we have an encounter be-
tween two cats and a dog. It is not obvious, a priori, that it does not make 
a difference whether the two cats meet first and their resultant meets the 
dog or whether one cat meets the dog and their resultant meets the other 
cat. To check that this is so we compute 
</p>
<p>(C+ C)+D=D+D= C 
</p>
<p>and 
</p>
<p>(C+D)+C=M+C=C. 
</p>
<p>In a similar manner we can show that the result of any encounter between 
three animals is independent of the order in which they meet. Next, ob-
serve that the zero element in V is the mouse, since every animal is un-
changed after eating a mouse. Finally, "minus a dog" is a cat (since D + C 
= M), "minus a cat" is a dog and "minus a mouse" is a mouse. However, 
V is not a vector space since there is no operation of scalar multiplication 
defined. Moreover, it is clearly impossible to define the quantities aC and 
aD, for all real numbers a, so as to satisfy axioms (v)-(viii). 
</p>
<p>277 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>Example 7. Let V be the set of all vector-valued solutions 
</p>
<p>x(t)= 
</p>
<p>of the vector differential equation 
</p>
<p>x=Ax, (2) 
</p>
<p>V is a vector space under the usual Operations of vector addition and 
scalar multiplication. To wit, observe that axioms (i), (ii), and (v)-(viii) are 
automatically satisfied. Hence, we need only verify that 
</p>
<p>(a) The sum of any two solutions of (2) is again a solution. 
(b) A constant times a solution of (2) is again a solution. 
(c) The vector-valued function 
</p>
<p>x(t)= x 1 ~t) =[~] 
xn(t) 0 
</p>
<p>is a solution of (2) (axiom (iii)). 
(d) The negative of any solution of (2) is again a solution (axiom (iv)). 
</p>
<p>Now (a) and (b) are exactly Theorem I of the previous section, while (d) is 
a special case of (b). To verify (c) we observe that 
</p>
<p>Hence the vector-valued function x(t)=:O is always a solution of the dif-
ferential equation (2). 
</p>
<p>ExERCISEs 
</p>
<p>In each of Problems 1-6, determine whether the given set of elements 
</p>
<p>form a vector space under the properties of vector addition and scalar mul-
tiplication defined in Section 3.1. 
</p>
<p>278 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.3 Dimension of a vector space 
</p>
<p>1. The set of all elements x= ( ~~) where 3x1-2x2 =0 
</p>
<p>2. The set of all elements x = ( :~ ) where x 1 + x 2 + x 3 = 0 
</p>
<p>3. The set of all elements x = ( :~ ) where xf + xi + xj = 1 
</p>
<p>4. The set of all elements x = ( ~~) where x 1 + x 2 + x 3 = 1 
</p>
<p>5. The set of elements x = ( %) for all real numbers a and b 
</p>
<p>6. The set of all elements x = ( :i) where 
x 1 +x2 +x3 =0, x 1-x2 +2x3 =0, 3x1-x2 +5x3 =0 
</p>
<p>In each of Problems 7-11 determine whether the given set of functions 
form a vector space under the usual operations of function addition and 
multiplication of a function by a constant. 
</p>
<p>7. The set of all polynomials of degree .;;; 4 
</p>
<p>8. The set of all differentiable functions 
</p>
<p>9. The set of all differentiable functions whose derivative at t = 1 is three 
</p>
<p>10. The set of all solutions of the differential equationy"+y=cost 
</p>
<p>11. The set of all functionsy(t) which have period 2'll', that isy(t+2'll')=y(t) 
</p>
<p>12. Show that the set of all vector-valued solutions 
</p>
<p>x(t)=(x 1(t)) 
x 2 (t) 
</p>
<p>of the system of differential equations 
dx 1 
- =x2 + 1 
dt ' 
</p>
<p>is not a vector space. 
</p>
<p>3.3 Dimension of a vector space 
</p>
<p>Let V be the set of all solutions y(t) of the second-order linear homoge-
neous equation (d 2y I dt2) + p(t)(dy I dt) + q(t)y =0. Recall that every solu-
tiony(t) can be expressedas a linear combination of any two linearly inde-
pendent solutions. Thus, if we knew two "independent" functions y 1( t) and 
</p>
<p>279 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>y 2(t) in V, then we could find every function in V by taking alllinear com-
binations c1y 1(t)+c2y 2(t) ofy 1 andy 2&bull; We would like to derive a similar 
property for solutions of the equation x = Ax. To this end, we define the 
notion of a finite set of vectors generating the whole space, and the notion 
of independence of vectors in an arbitrary vector space V. 
</p>
<p>Definition. A set of vectors xl, x2, ... , xn is said to span V if the set of all 
linear combinations c1x1 + c2x2 + ... + cnxn exhausts V. That is to say, 
the vectors x 1, x2, &bull;&bull;&bull; , xn span V if every element of V can be expressed as 
a linear combination of x1, x2, ... , xn. 
</p>
<p>Example 1. Let V be the set of all solutions of the differential equation 
(d 2xjdt2)-x=O. Let x 1 be the function whose value at any timet is e' 
and let x 2 be the function whose value at any timet is e- 1&bull; The functions 
x 1 and x 2 are in V since they satisfy the differential equation. Moreover, 
these functions also span V since every solution x(t) of the differential 
equation can be written in the form 
</p>
<p>x(t)=c 1e1+c2e- 1 
</p>
<p>so that 
</p>
<p>Example 2. Let V= Rn and let ei denote the vector with a 1 in the jth place 
and zeros everywhere else, that is, 
</p>
<p>1 0 0 
0 I 0 
</p>
<p>el= 0 e2= 0 , ... ,en= 
</p>
<p>0 
0 0 I 
</p>
<p>The set of vectors e1 ,e2, ... ,en span Rn since any vector 
</p>
<p>x= 
</p>
<p>can be written in the form 
</p>
<p>XI 0 0 
0 X2 0 
</p>
<p>x= + + ... + 
</p>
<p>0 0 
</p>
<p>280 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.3 Dimension of a vector space 
</p>
<p>Definition. A set of vectors x I, x2, &bull;&bull;. , xn in V is said to be linearly dependent 
if one of these vectors is a linear combination of the others. A very pre-
cise mathematical way of saying this is as follows. A set of vectors 
x1, x2, &bull;.&bull; , xn is said to be linearly dependent if there exist constants 
c1,c2, ... ,cn, not allzerosuch that 
</p>
<p>c1x1+c2x2 + ... +cnxn=O. 
</p>
<p>These two definitions are equivalent, for if xj is a linear combination of 
x1, &bull;&bull;&bull; ,xi- 1,xj+ 1, &bull;&bull;&bull; ,xn, that is 
</p>
<p>then the linear combination 
</p>
<p>equals zero and not all the constants are zero. Conversely, if c1x1 + c2x2 
+ ... + cnxn = 0 and cj *0 for some }, then we can divide by cj and solve for 
xj as a linear combination of x1, &bull;&bull;&bull; ,xi- 1 ,xi+ 1, &bull;&bull;&bull; ,xn. For example, if c1 *0 
then we can divide by c1 to obtain that 
</p>
<p>Definition. If the vectors x1, x2, &bull;&bull;&bull; , xn are not linearly dependent, that is, 
none of these vectors can be expressed as a linear combination of the 
others, then they are said to be linearly independent. The precise 
mathematical way of saying this isthat the vectors x1,x2, &bull;&bull;&bull; ,xn are lin-
early independent if the equation 
</p>
<p>implies, of necessity, that all the constants c1, c2, ... , cn are zero. 
</p>
<p>In order to determine whether a set of vectors x 1, x2, &bull;&bull;&bull; , xn is linearly de-
pendent or linearly independent, we write down the equation c1x1 + c2x2 
+ ... + cnxn = 0 and see what this implies about the constants c 1, c2, ... , cn. 
If all these constants must be zero, then x1, x2, ... , xn are linearly indepen-
dent. On the other hand, if not all the constants c1,c2, ... ,cn must be zero, 
then x1,x2, &bull;&bull;&bull; ,xn are linearly dependent. 
</p>
<p>Example 3. Let V=R3 and Iet x1, x2, and x3 be the vectors 
</p>
<p>281 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>To determine whether these vectors are linearly dependent or linearly inde-
pendent, we write down the equation c1x1+c2x2 +c3x3 =0, that is 
</p>
<p>c,[ -l]+c,[~]+c,m~[g] 
The 1eft-hand side of this equation is the vector 
</p>
<p>[ 
c1 +c2 +3c3 ] 
-c1+2c2 &bull; 
</p>
<p>c1 +3c2 +5c3 
</p>
<p>Hence the constants c1, c2, and c3 must satisfy the equations 
</p>
<p>c1+c2 +3c3 =0, (i) 
</p>
<p>- c1 +2c2 =0, (ii) 
</p>
<p>c1 +3c2 +5c3 =0. (iii) 
</p>
<p>Equation (ii) says that c1 = 2c2. Substituting this into Equations (i) and (iii) 
gives 
</p>
<p>3c2+3c3 =0 and 5c2 +5c3 =0. 
</p>
<p>These equations have infinitely many solutions c2,c3 since they both reduce 
to the sing1e equation c2 + c3 =0. One solution, in particular, is c2 = -1, 
c3 =I. Then, from Equation (ii), c1 = -2. Hence, 
</p>
<p>-z[ -lH~H~H~l 
and xl, x2 and x3 are 1inearly dependent vectors in R3. 
</p>
<p>Example 4. Let V=Rn and Iet e 1,e2, ... ,en be the vectors 
</p>
<p>1 0 0 
0 1 0 
</p>
<p>el= 0 e2= 0 , ... ,en= 
</p>
<p>0 
0 0 1 
</p>
<p>To determine whether e1, e2, ... , en are linearly dependent or linearly inde-
pendent, we write down the equation cle1 + ... + cnen = 0, that is 
</p>
<p>1 0 0 0 
0 1 0 0 
</p>
<p>Cl 0 +c2 0 + ... +cn 0 
</p>
<p>0 
0 0 1 0 
</p>
<p>282 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.3 Dimension of a vector space 
</p>
<p>The left-hand side of this equation is the vector 
</p>
<p>Hence c1 = 0, c2 = 0, ... , and cn = 0. Consequently, e 1, e2, ... , en are linearly 
independent vectors in Rn. 
</p>
<p>Definition. The dimension of a vector space V, denoted by dim V, is the 
fewest nurober of linearly independent vectors which span V. V is said 
to be a finite dimensional space if its dimension is finite. On the other 
hand, V is said to be an infinite dimensional space if no set of finitely 
many elements span V. 
</p>
<p>The dimension of a space V can be characterized as the fewest number 
of elements that we have to find in order to know all the elements of V. In 
this sense, the definition of dimension captures our intuitive feeling. How-
ever, it is extremely difficult to compute the dimension of a space V from 
this definition alone. For example, Iet V=Rn. Wehave shown in Examples 
2 and 4 that the vectors e1,e2, ... ,en are linearly independent and span V. 
Moreover, it seems intuitively obvious to us that we cannot generate Rn 
from fewer than n vectors. Thus, the dimension of Rn should be n. But how 
can we prove this rigorously? To wit, how can we prove that it is impossi-
ble to find a set of (n -1) linearly independent vectors that span Rn? Thus, 
our definition of dimension is not, as yet, a very useful one. However, it 
will become extremely useful after we prove the following theorem. 
</p>
<p>Theorem 2. Ij n linearly independent vectors span V, then dim V= n. 
</p>
<p>W e will need two Iemmas to prove Theorem 2. The first Iemma con-
cerns itself with the solutions of simultaneaus linear equations and can be 
motivated as follows. Suppose that we are interested in determining n un-
known numbers x 1,x2, ... ,xn uniquely. lt seems pretty reasonable that we 
should be given n equations satisfied by these unknowns. If we are given 
too few equations then there may be many different solutions, that is, 
many different sets of values for x 1,x2, ... ,xn which satisfy the given equa-
tions. Lemma 1 proves this in the special case that we have m homoge-
neaus linear equations for n &gt; m unknowns. 
</p>
<p>Lemma l. A set oj m homogeneaus linear equations for n unknowns 
x 1, x 2, ... , xn always admits a nontrivial solution if m &lt; n. That is to say, 
</p>
<p>283 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>the set of m equations in n unknowns 
</p>
<p>a 11 x 1 + a12x2+ ... + a1nxn=O 
</p>
<p>a21X1 + a22X2+ &middot;&middot;&middot; + a2nxn=O 
(I) 
</p>
<p>always has a solution x 1, x2, ... , xn, other than x 1 = ... = xn = 0, if m &lt; n. 
</p>
<p>Remark. Notice that x 1 = 0, x2 = 0, ... , xn = 0 is certainly one solution of the 
system of equations (1). Thus, Lemma 1 is telling us that these equations 
have more than one solution. 
</p>
<p>PRooF OF LEMMA 1. We will prove Lemma 1 by induction on m. To this 
end, observe that the Iemma is certainly true if m = 1, for in this case we 
have a single equation of the form a 11x1 + a12x2 + ... + a1nxn =0, with 
n ::&gt; 2. We can find a nontrivial solution of this equation, if a 11 = 0, by 
taking x 1 = 1, x2 = 0, ... , xn = 0. W e can find a nontrivial solution of this 
equation, if a 11 ~0, by taking x2 = 1, ... , xn = 1 and x 1 =- (a 12 + ... + 
aln)/ all. 
</p>
<p>For the next step in our induction proof, we assume that Lemma 1 is 
true for some integer m = k and show that this implies that Lemma 1 is 
true for m = k +I, and k + 1 &lt; n. To this end, consider the k + 1 equations 
for the n unknowns x 1,x2, ... ,xn 
</p>
<p>(2) 
</p>
<p>with k + 1 &lt; n. If a 11 ,a21 , ... ,ak+ 1 1 are all zero, then x 1 = 1,x2 = 0, ... ,xn =0 
is clearly a non-trivial solution. Hence, we may assume that at least one of 
these coefficients is not zero. Without any loss of generality, we may 
assume that a 11 ~0, for otherwise we can take the equation with the non-
zero coefficient of x1 and relabel it as the first equation. Then 
</p>
<p>al2 a13 aln 
XI=- -x2- -x3- ... - -xn. 
</p>
<p>all all all 
</p>
<p>Substituting this va1ue of x 1 in the second through the ( k + 1 )st equations, 
</p>
<p>284 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.3 Dimension of a vector space 
</p>
<p>we obtain the equivalent equations 
</p>
<p>(3) 
</p>
<p>where biJ=aiJ-a;1avfa11 &bull; Now, the last k equations of (3) are k homoge-
neous linear equations for the (n-1) unknowns x2, .&bull;&bull; ,xn. Moreover, k is 
less than n- 1 since k + 1 is less than n. Hence, by the induction hypothe-
sis, these equations have a nontrivial solution x2, ..&bull; ,xn. Once x 2, &bull;&bull;&bull; ,xn are 
known, we have as before x 1 = -(a12x 2 + ... +a1nxn)/a 11 from the first 
equation of (3). This establishes Lemma 1 for m = k +I, and therefore for 
all m, by induction. D 
</p>
<p>If a vector space V has dimension m, then it has m linearly independent 
vectors x 1, &bull;&bull;&bull; , xm and every vector in the space can be written as a linear 
combination of the m vectors xl,x2, ..&bull; ,xm. It seems intuitively obvious to 
us in this case that there cannot be more than m linear independent vectors 
in V. This is the content of Lemma 2. 
</p>
<p>Lemma 2. In an m dimensional space, any set of n &gt; m vectors must be lin-
early dependent. In other words, the maximum number of linearly indepen-
dent vectors in a finite dimensional space is the dimension of the space. 
</p>
<p>PROOF. Since V has dimension m, there exist m linearly independent vec-
tors xl,x2, &bull;&bull;&bull; ,xm which span V. Let y1,y2, ... ,y" be a set of n vectors in V, 
with n&gt;m. Since x1,x2, &bull;&bull;&bull; ,xm span V, all the yi can be written as linear 
combinations of these vectors. That is to say, there exist constants aiJ, 1 &lt; i 
&lt; n, I &lt; j &lt; m such that 
</p>
<p>(4) 
</p>
<p>285 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>To determine whether yl, y2, ... , yn are linearly dependent or linearly inde-
pendent, we consider the equation 
</p>
<p>clyl + C2Y2 + ... + CnYn =0. 
</p>
<p>Using (4) we can rewrite (5) in the form 
</p>
<p>0=clyl+c2y2+ ... +cnyn 
</p>
<p>= ( clall + ... + cnanl)xl + ( clal2 + ... + cnanz)X2 
</p>
<p>+ ... +(clalm+ ... +cnanm)xm. 
</p>
<p>(5) 
</p>
<p>This equation states that a linear combination of x1, x2, &bull;&bull;&bull; , xm is zero. Since 
x1, x2, ... , xm are linearly independent, all these coefficients must be zero. 
Hence, 
</p>
<p>(6) 
</p>
<p>Now, observe that the system of Equations (6) is a set of m homogeneous 
linear equations for n unknowns c1, c2, ... , cn, with n &gt; m. By Lemma l, 
these equations have a nontrivial solution. Thus, there exist constants 
c1,c2, &bull;.. ,cn, not all zero, such that c1y1 + c2y2 + ... + cnyn =0. Consequently, 
y1, y2, ... , yn are linearly dependent. D 
</p>
<p>We are now in a position to prove Theorem 2. 
</p>
<p>PRooF OF THEOREM 2. If n linearly independent vectors span V, then, by 
the definition of dimension, dim V &lt; n. By Lemma 2, n &lt; dim V. Hence, 
dimV=n. D 
</p>
<p>Example 5. The dimension of Rn is n since e 1, e2, ... , en are n linearly inde-
pendent vectors which span Rn. 
</p>
<p>Example 6. Let V be the set of all 3 X 3 matrices 
</p>
<p>A= [:~: :~~ :~~]' 
a31 a32 a33 
</p>
<p>and Iet Eu denote the matrix with a one in the ith row, jth column and 
zeros everywhere eise. For example, 
</p>
<p>286 
</p>
<p>0 
0 
0 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.3 Dimension of a vector space 
</p>
<p>To determine whether these matrices are linearly dependent or linearly in-
dependent, we consider the equation 
</p>
<p>&plusmn; c!iE!i=O= [~ ~ ~0 ]. i,j=l 0 0 
Now, observe that the left-hand side of (7) is the matrix 
</p>
<p>0 
0 
0 
</p>
<p>1 
0 
0 
</p>
<p>0 
0 
0 
</p>
<p>(7) 
</p>
<p>Equating this matrix to the zero matrix gives c11 = 0, c12 = 0, ... , c33 = 0. 
Hence the 9 matrices E!i are linearly independent. Moreover, these 9 
matrices also span V since any matrix 
</p>
<p>can obviously be written in the form A= L ~.J=Ia!iE!i. Hence dimV=9. 
</p>
<p>Definition. If a set of linearly independent vectors span a vector space V, 
then this set of vectors is said to be a basis for V. A basis may also be 
called a coordinate system. For example, the vectors 
</p>
<p>ei= b] 
0 ' 
0 
</p>
<p>are a basis for R4. If 
</p>
<p>then x = x 1e1 + x2e2 + x 3e3 + x4e4, and relative to this basis the xi are 
called "components" or "coordinates." 
</p>
<p>Corollary. In a finite dimensional vector space, each basis has the same num-
ber of vectors, and this number is the dimension of the space. 
</p>
<p>The following theorem is extremely useful in determining whether a set 
of vectors is a basis for V. 
</p>
<p>287 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>Theorem 3. Any n linearly independent vectors in an n dimensional space V 
must also span V. That is to say, any n linearly independent vectors in an n 
dimensional space V are a basis for V. 
</p>
<p>PROOF. Let x 1, x2, ... , xn be n linearly independent vectors in an n dimen-
sional space V. To show that they span V, we must show that every x in V 
can be written as a linear combination of x1,x2, ... ,xn. Tothis end, pick 
any x in V and consider the set of vectors x,x1,x2, ... ,xn. This is a set of 
( n + 1) vectors in the n dimensional space V; by Lemma 2, they must be 
linearly dependent. Consequently, there exist constants c,c1,c2, ... ,cn, not 
all zero, such that 
</p>
<p>(8) 
</p>
<p>Now ci'O, for otherwise the set of vectors x1,x2, ... ,xn would be linearly 
dependent. Therefore, we can divide both sides of (8) by c to obtain that 
</p>
<p>cl I c2 2 
x=--x --x-
</p>
<p>c c 
</p>
<p>Hence, any n linearly independent vectors in an n dimensional space V 
must also span V. D 
</p>
<p>Example 7. Prove that the vectors 
</p>
<p>form a basis for R2&bull; 
Solution. To determine whether x1 and x2 are linearly dependent or lin-
early independent, we consider the equation 
</p>
<p>(9) 
</p>
<p>Equation (9) implies that c 1 + c2 = 0 and c 1- c2 = 0. Adding these two equa-
tions gives c1 = 0 while subtracting these two equations gives c2 = 0. Conse-
quently, x1 and x2 are two linearly independent vectors in the two dimen-
sional space R2&bull; Hence, by Theorem 3, they must also span V. 
</p>
<p>EXERCISES 
</p>
<p>In each of Exercises 1-4, determine whether the given set of vectors is lin-
early dependent or linearly independent. 
</p>
<p>2. ( D&middot; ( n and ( ~) 
288 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.3 Dimension of a vector space 
</p>
<p>4. (i ), ( -10, ( -~) and 
</p>
<p>(=D 
5. Let V be the set of all 2 X 2 matrices. Determine whether the following sets of 
</p>
<p>matrices are linearly dependent or linearly independent in V. 
</p>
<p>(a) ( ~ g), (6 n, (~ 6) and (g D 
(b)n g), (6 n, (~ 6) and (- ~ -2) 1 . 
</p>
<p>6. Let V be the space of all polynomials in t of degree &lt; 2. 
(a) Show that dimV=3. 
(b) Let Pt, p 2 and p 3 be the three polynomials whose values at any time t are 
</p>
<p>(t-1f, (t-2)2, and (t-1) (t-2) respectively. Show thatpt&gt;pz, andp3 are 
linearly independent. Hence, conclude from Theorem 3 that Pt, p 2, and p 3 
form a basis for V. 
</p>
<p>7. Let V be the set of all solutions of the differential equation d 2y / dt2 - y = 0. 
(a) Show that V is a vector space. 
(b) Find a basis for V. 
</p>
<p>8. Let V be the set of all solutions of the differential equation (dyjdt 3)+y=O 
which satisfy y(O) = 0. Show that V is a vector space and find a basis for it. 
</p>
<p>9. Let V be the set of all polynomialsp(t)=a0 +att+a2t2 which satisfy 
</p>
<p>p(O) +2p'(O) + 3p"(O) =0. 
</p>
<p>Show that V is a vector space and find a basis for it. 
</p>
<p>10. Let V be the set of all solutions 
</p>
<p>of the differential equation 
</p>
<p>x=(~ 6 &deg;61 )x. -11 
Show that 
</p>
<p>form a basis for V. 
</p>
<p>289 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>11. Let V be a vector space. We say that W is a subspace of Vif W is a subset of V 
which is itself a vector space. Let W be the subset of R3 which consists of all 
vectors 
</p>
<p>which satisfy the equations 
</p>
<p>x= (~~) 
</p>
<p>x 1 +x2+2x3=0 
2x 1- x2 + x3=0 
6x 1 +6x3 =0. 
</p>
<p>Show that W is a subspace of R3 and find a basis for it. 
</p>
<p>12. Prove that any n vectors which span an n dimensional vector space V must be 
linearly independent. Hint: Show that any set of linearly dependent vectors 
contains a linearly independent subset which also spans V. 
</p>
<p>13. Let v1, v2, &bull;&bull;&bull; , v" be n vectors in a vector space V. Let W be the subset of V 
which consists of alllinear combinations c1v1+c2r+ ... +cnv" of v1,r, ... ,v". 
Show that W is a subspace of V, and that dim W..; n. 
</p>
<p>14. Let V be the set of all functions f(t) which are analytic for JtJ &lt;I, that is, f(t) 
has a power series expansion j( t) = a0 + a1 t + a2t2 + ... which converges for J tJ 
&lt; I. Show that V is a vector space, and that its dimension is infinite. Hint: V 
contains all polynomials. 
</p>
<p>15. Let v1, v2, &bull;&bull;&bull; , v"' be m linearly independent vectors in an n dimensional vector 
space V, with n &gt; m. Show that we can find vectors vm+ 1, &bull;&bull;&bull; , vn so that 
v1, v2, &bull;&bull;&bull; , v"', yn+ 1, &bull;&bull;&bull; , v" form a basis for V. That is to say, any set of m linearly 
independent vectors in an n &gt; m dimensional space V can be completed to 
form a basis for V. 
</p>
<p>16. Find a basis for R3 which includes the vectors 
</p>
<p>(l) and (&Uuml;&middot; 
17. (a) Show that 
</p>
<p>290 
</p>
<p>are linearly independent in R3. 
(b) Let </p>
<p/>
</div>
<div class="page"><p/>
<p>3.4 Applications of linear algebra to differential equations 
</p>
<p>Since v1,v2, and v3 are linearly independent they are a basis and x=y 1v1+ 
y 2v2 + y 3v3&bull; What is the relationship between the original coordinates X; and 
the new coordinates y1? 
</p>
<p>(c) Express the relations between coordinates in the form x=By. Show that the 
columns of 8 are v1, v2, and v3&bull; 
</p>
<p>3.4 Applications of linear algebra 
to differential equations 
</p>
<p>Recall that an important tool in solving the second-order linear homoge-
neous equation (d 2y I dt 2) + p(t)(dy I dt) + q(t)y = 0 was the existence-
uniqueness theorem stated in Section 2.1. In a similar manner, we will 
make extensive use of Theorem 4 below in solving the homogeneous linear 
system of differential equations 
</p>
<p>dx =Ax 
dt , 
</p>
<p>A= ~~II 
an I 
</p>
<p>The proof of this theorem will be indicated in Section 4.6. 
</p>
<p>{1) 
</p>
<p>Theorem 4 (Existence-uniqueness theorem). There exists one, and only 
one, solution of the initial-value problern 
</p>
<p>dx =Ax 
dt , 
</p>
<p>x? 
X~ 
</p>
<p>x{t0)=x0 = 
</p>
<p>Moreover, this solution exists for - oo &lt; t &lt; oo. 
</p>
<p>{2) 
</p>
<p>Theorem 4 is an extremely powerful theorem, and has many implica-
tions. In particular, if x(t) is a nontrivial solution, then x(t)*O for any t. 
(If x(t*)=O for some t*, then x(t) must be identically zero, since it, and the 
trivial solution, satisfy the same differential equation and have the same 
value at t = t* .) 
</p>
<p>Wehave already shown (see Example 7, Section 3.2) that the space V of 
all solutions of (1) is a vector space. Our next step is to determine the di-
mension of V. 
</p>
<p>Theorem 5. The dimension of the space V of all solutions of the homogeneaus 
linear system of differential equations (I) is n. 
</p>
<p>PROOF. We will exhibit a basis for V which contains n elements. To this 
</p>
<p>291 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>end, let .pl(t),j= l, ... ,n be the solution of the initial-value problern 
</p>
<p>dx =Ax 
dt ' 
</p>
<p>0 
</p>
<p>0 
x(O) = el = 1 - jth row. 
</p>
<p>0 
</p>
<p>0 
</p>
<p>(3) 
</p>
<p>For example, .p1(t) is the solution of the differential equation (1) which 
satisfies the initial condition 
</p>
<p>0 
</p>
<p>Note from Theorem 4 that .pJ (t) exists for all t and is unique. To de-
termine whether .pl,.p2, &bull;&bull;. ,.pn are linearly dependent or linearly indepen-
dent vectors in V, we consider the equation 
</p>
<p>(4) 
</p>
<p>where the zero on the right-hand side of (4) stands for the zero vector in V 
(that is, the vector whose every component is the zero function). We want 
to show that (4) implies c1 = c2 = ... = cn =0. Evaluating both sides of (4) at 
t=O gives 
</p>
<p>or 
</p>
<p>0 
0 
</p>
<p>c1-f&gt; 1 (0) + c2-f&gt;2 (0) + ... + cn.Pn (0) = =0 
</p>
<p>0 
</p>
<p>Since we know that e 1,e2, &bull;&bull;. ,en are linearly independent in Rn, c1 =c2 
= ... =cn=O. We conclude, therefore, that .p 1,.p2, &bull;&bull;&bull; ,.pn are linearly inde-
pendent vectors in V. 
</p>
<p>Next, we claim that .p1,.p2, &bull;&bull;&bull; ,.pn also span V. To prove this, we must 
show that any vector x in V (that is, any solution x(t) of (1)) can be written 
as a linear combination of .p 1,.p2, &bull;&bull;&bull; ,.pn. Tothis end, pick any x in V, and 
</p>
<p>292 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.4 Applications of linear algebra to differential equations 
</p>
<p>Iet 
</p>
<p>c= 
</p>
<p>be the value of x at t=O (x(O)=c). With these constants c1,c2, &bull;&bull;&bull; ,cn, con-
struct the vector-valued function 
</p>
<p>f/&gt;(t)=c 1f/&gt; 1(t)+c2f/&gt;2 (t)+ ... +cnq,n(t). 
</p>
<p>We know that f/&gt;(t) satisfies (1) since it isalinear combination of solutions. 
Moreover, 
</p>
<p>f/&gt;{0) = c1f/&gt; 1 {0) + c2f/&gt;2(0) + ... + cnq,n (0) 
</p>
<p>1 0 0 Cl 
0 1 0 Cz 
</p>
<p>=cl +c2 + ... +cn =x{O). 
</p>
<p>0 0 Cn 
</p>
<p>Now, observe that x(t) and f/&gt;(t) satisfy the samehomogeneaus linear sys-
tem of differential equations, and that x(t) and f/&gt;(t) have the same value at 
t=O. Consequently, by Theorem 4, x(t) and f/&gt;(t) must be identical, that is 
</p>
<p>x(t)=f/&gt;(t) = c1f/&gt; 1 (t) + c2f/&gt;2{t) + ... + cnq,n (t). 
</p>
<p>Thus, q,l,q,2, &bull;&bull;&bull; ,q,n also span V. Therefore, by Theorem 2 of Section 3.3, 
dimV=n. 0 
</p>
<p>Theorem 5 states that the space V of all solutions of (1) has dimension 
n. Hence, we need only guess, or by some means find, n linearly indepen-
dent solutions of (1). Theorem 6 below establishes a test for linear indepen-
dence of solutions. It reduces the problern of determining whether n solu-
tions xl, x2, ... , xn are linearly independent to the much simpler problern of 
determining whether their values x 1( t0), x2( t0), &bull;&bull;&bull; , xn (10) at an appropriate 
time t0 are linearly independent vectors in Rn. 
</p>
<p>1beorem 6 (Test for linear independence). Let xl,x2, &bull;&bull;&bull; ,xk be k so/utions 
of x = Ax. Select a convenient t0&bull; Then, x I, ... , xk are linear independent 
solutions if, and only if, x1(t0),x2(t0), &bull;.. ,xk(t0) are linearly independent 
vectors in Rn. 
</p>
<p>PROOF. Suppose that x 1,x2, ... ,xk are linearly dependent solutions. Then, 
there exist constants c1, c2, ... , ck, not all zero, such that 
</p>
<p>c1x 1+c2x2 + ... +ckxk=O. 
</p>
<p>293 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>Evaluating this equation at t = t0 gives 
</p>
<p>0 
0 
</p>
<p>c1x1(t0)+c2x2(t0)+ ... +ckxk(t0)= 
</p>
<p>0 
</p>
<p>Hence x1(t0),x2(t0), ... ,xk(t0) are linearly dependent vectors in Rn. 
Conversely, suppose that the values of x\ x2, ... , xk at some time t0 are 
</p>
<p>linearly dependent vectors in Rn. Then, there exist constants c1,c2, ... ,ck, 
not all zero, such that 
</p>
<p>0 
0 
</p>
<p>c1x1(t0) + c2x2(t0) + ... + ckxk(t0 ) = =0. 
</p>
<p>0 
</p>
<p>With this choice of constants c1,c2, ... ,ck, construct the vector-valued func-
tion 
</p>
<p>This function satisfies (I) since it is a linear combination of solutions. 
Moreover, &lt;[&gt;(10)=0. Hence, by Theorem 4, &lt;[&gt;(t)=O for all t. This implies 
that x1, x2, ... , xk are linearly dependent solutions. D 
</p>
<p>Example 1. Consider the system of differential equations 
</p>
<p>dx 1 
dt =x2 
</p>
<p>dx ( 0 
or dt = -1 (5) dx2 
</p>
<p>-=-x -2x dt I 2 
</p>
<p>This system of equations arose from the single second-order equation 
</p>
<p>d2y dy 
-+2-+y=O 
dt2 dt 
</p>
<p>(6) 
</p>
<p>by setting x 1 = y and x2 = dy / dt. Since y 1(t)= e- 1 and yit)= te- 1 are two 
solutions of (6), we see that 
</p>
<p>and 
</p>
<p>294 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.4 Applications of linear algebra to differential equations 
</p>
<p>are two solutions of (5). To determine whether x1 and x2 are linearly de-
pendent or linearly independent, we check whether their initial values 
</p>
<p>and 
</p>
<p>are linearly dependent or linearly independent vectors in R2. Thus, we con-
sider the equation 
</p>
<p>c1x1(0) + c2x2(0) = ( _ c~~ Cz) = ( ~ ). 
This equation implies that both c1 and c2 are zero. Hence, x1(0) and x2(0) 
are linearly independent vectors in R2. Consequently, by Theorem 6, x1(t) 
and x2(t) are linearly independent solutions of (5), and every solution x(t) 
of (5) can be written in the form 
</p>
<p>(7) 
</p>
<p>Example 2. Solve the initial-value problern 
</p>
<p>~; =( _ ~ _;)x, x(O)=( D&middot; 
Solution. From Example I, every solution x(t) must be of the form (7). The 
constants c1 and c2 are determined from the initial conditions 
</p>
<p>Therefore, c1 =I and c2 = I +c 1 =2. Hence 
</p>
<p>x(t) = ( x 1 (t)) = ( (1 + 2t)e- 1 )&middot; 
x 2 (t) (I-2t)e- 1 
</p>
<p>Up to this point in studying (I) we have found the concepts of linear al-
gebra such as vector space, dependence, dimension, basis, etc., and vector-
matrix notation useful, but we might weil ask is all this other than simply 
an appropriate and convenient language. If it were nothing eise it would be 
worth introducing. Good notations are important in expressing mathemati-
cal ideas. However, it is more. lt is a body of theory with many applica-
tions. 
</p>
<p>295 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>In Sections 3.8-3.10 we will reduce the problern of finding all solutions 
of (1) to the much simpler algebraic problern of solving simultaneous linear 
equations of the form 
</p>
<p>allxl + a12X2 + &middot; &middot; &middot; + alnxn = bl 
a21X1 +a22x2+ &middot;&middot;&middot; +a2nxn=b2 
</p>
<p>Therefore, we will now digress to study the theory of simultaneous linear 
equations. Here too we will see the role played by linear algebra. 
</p>
<p>EXERCISES 
</p>
<p>In each of Exercises 1-4 find a basis for the set of solutions of the given 
differential equation. 
</p>
<p>1. x = ( _ ~ _ ~ )x (Hint: Find a second-order differential equation satis-
fied by x1(t).) 
</p>
<p>2. x=G -~ r)x (Hint: Find a third-order differential equation satis-
fied by x1(t).) 
</p>
<p>3. x=(i nx 4. x=O 0 0) 1 0 X 
1 1 
</p>
<p>For each of the differential equations 5-9 determine whether the given 
solutions are a basis for the set of all solutions. 
</p>
<p>6. x=( -1 
</p>
<p>( 
-3 
</p>
<p>7. x= ~ 
</p>
<p>( 
-5 
</p>
<p>s. x= 1 
-1 
</p>
<p>296 
</p>
<p>-2 
0 
</p>
<p>-2 
-~)x; 
-1 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.5 The theory of determinants 
</p>
<p>2) [ -31] =~ x; x1(t)= :~31 , 
</p>
<p>10. Determine the solutions q, 1,q,2, &bull;&bull;&bull; ,q,n (see proof of Theorem 5) for the system 
of differential equations in (a) Problem 5; (b) Problem 6; (c) Problem 7. 
</p>
<p>11. Let V be the vector space of all continuous functions on (- oo, oo) to Rn (the 
values of x(t) lie in Rn). Let x1,x2, &bull;&bull;&bull; ,xn be functions in V. 
(a) Show that x1(t0), &bull;&bull;&bull; ,xn(t0) linearly independent vectors in Rn for some t0 
</p>
<p>implies x 1,x2, ..&bull; ,xn are linearly independent functions in V. 
(b) Is it true that x 1(t0), &bull;&bull;&bull; ,xn(t0) linearly dependent in Rn for some t0 implies 
</p>
<p>x1, x2, &bull;&bull;&bull; , xn are linearly dependent functions in V? Justify your ans wer. 
</p>
<p>IZ. Let u be a vector in Rn(u~O). 
(a) Is x(t)= tu a solution of a linear homogeneous differential equation i=Ax? 
(b) Is x(t)=e;vu? (c) Is x(t)=(e 1-e- 1)u? 
(d) Is x(t)=(e 1 +e- 1)u? (e) Is x(t)=(eA&bull;1 +eA21)u? 
(f) For what functions q&gt;(t) can x(t)=q,(t)u be a solution of some i=Ax? 
</p>
<p>3.5 The theory of determinants 
</p>
<p>In this section we will study simultaneaus equations of the form 
</p>
<p>a 11 x 1 + a 12x 2 + ... + a 1nxn = b 1 
a21X 1 + a22X2 + &middot; &middot; &middot; + a2nxn = b2 
</p>
<p>an lXI + an2x2 + ... + annxn = bn. 
</p>
<p>(I) 
</p>
<p>Our goal is to determine a necessary and sufficient condition for the sys-
tem of equations (I) to have a unique solution x 1,x2, &bull;&bull;&bull; ,xn. 
</p>
<p>To gain some insight into this problem, we begin with the simplest case 
n = 2. If we multiply the first equation a11x 1 + a12x2 = b1 by aw the second 
equation a 21 x 1 + a22x 2 = b 2 by a 11 , and then subtract the former from the 
latter, we obtain that 
</p>
<p>(a 11a 22 - a12a21 )x2 = a 11 b 2 - a 21 b 1. 
Similarly, if we multiply the first equation by a22, the second equation by 
a12, and then subtract the latter from the former, we obtain that 
</p>
<p>( aua22- a,2a2,)x, = a22bl- a,2b2. 
</p>
<p>Consequently, the system of equations (I) has a unique solution 
</p>
<p>297 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>if the number aua22 -a12a 21 is unequal to zero. If this number equals zero, 
then we may, or may not, have a solution. For example, the system of 
equations 
</p>
<p>obviously has no solutions, while the system of equations 
</p>
<p>x 1-x2 =0, 2x1-2x2 =0 
</p>
<p>has an infinity of solutions x 1 = c,x2 = c for any number c. For both these 
systems of equations, 
</p>
<p>aua22- al2a21 = 1( -2)- ( -1)2=0. 
</p>
<p>The case of three equations 
</p>
<p>aux1 + a 12x2 + a 13x 3 = b 1 
</p>
<p>a2Ixl + a22X2 + a23X3 = b2 (2) 
a31X1 + a32x2 + a33X3 = b3 
</p>
<p>in three unknowns x 1,x2,x3 can also be handled quite easily. By eliminat-
ing one of the variables from two of the equations (2), and thus reducing 
ourselves to the case n = 2, it is possible to show (see Exercise 1) that the 
system of equations (2) has a unique solution xpx2,x3 if, and only if, the 
number 
</p>
<p>is unequal to zero. 
We now suspect that the system of equations (1), which we abbreviate 
</p>
<p>in the form 
</p>
<p>(4) 
</p>
<p>has a unique solution x if, and only if, a certain number, which depends on 
the elements aiJ of the matrix A, is unequa1 to zero. We can determine this 
number for n = 4 by eliminating one of the variables from two of the equa-
tions (1). However, the a1gebra is so comp1ex that the resulting number is 
unintelligib1e. Instead, we will genera1ize the number (3) so as to associate 
with each system of equations Ax = b a sing1e number called determinant A 
(detA for short), which depends on the elements of the matrix A. We will 
estab1ish several usefu1 properties of this association, and then use these 
properties to show that the system of equations (4) has a unique solution x 
if, and only if, detki'O. 
</p>
<p>If we carefully analyze the number (3), we see that it can be described in 
the following interesting manner. Fi.-st, we pick an e1ement alj, from the 
</p>
<p>298 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.5 The theory of determinants 
</p>
<p>first row of the matrix 
</p>
<p>This element can be either a 11 ,a12, or a 13&bull; Then, we multiply aiJ, by an ele-
ment a2h from the second row of A. However,h must not equalj1&bull; For ex-
ample, if we choose a12 from the first row of A, then we must choose either 
a21 or a23 from the second row of A. Next, we multiply these two numbers 
by the element in the third row of A in the remaining column. We do this 
for all possible choices of picking one element from each row of A, never 
picking from the same column twice. In this manner, we obtain 6 different 
products of three elements of A, since there are three ways of choosing an 
element from the first row of A, then two ways of picking an element from 
the second row of A, and then only one way of choosing an element from 
the third row of A. Each of these products a1J,a21,a3h is multiplied by &plusmn; 1, 
depending on the specific order ) 1h)3&bull; The products a 1ha21,a3h with 
(Jd2) 3)=(123), (231), and (312) are multiplied by + 1, while the products 
aiJ,a21,a3h with (j1) 21J)=(321), (213), and (132) are multiplied by -1. Fi-
nally, the resulting numbers are added together. 
</p>
<p>The six sets of numbers (123), (231), (312), (321), (213), and (132) are 
calledpermutations, or scramblings, of the integers I, 2, and 3. Observe that 
each of the three permutations corresponding to the plus terms requires an 
even number of interchanges of adjacent integers to unscramble the per-
mutation, that is, to bring the integers back to their natural order. Sirni-
larly, each of the three permutations corresponding to the minus terms re-
quires an odd number of interchanges of adjacent integers to unscramble 
the permutation. To verify this, observe that 
</p>
<p>231~213~123 (2 interchanges) 
</p>
<p>312~ 132~ 123 (2 interchanges) 
</p>
<p>321~312~132~123 (3 interchanges) 
</p>
<p>213~123 and 132~123 (I interchange each). 
</p>
<p>This motivates the following definition of the determinant of an n X n 
matrix A. 
</p>
<p>Definition. 
</p>
<p>detA= ~ EJ,jz ... J"aiJ,alh ... anJ. (5) 
Jh&middot;&middot;&middot;,Jn 
</p>
<p>where f_j,J, .. .J" =I if the permutation (J1h&middot;&middot; .Jn) is even, that is, if we can 
bring the integersj1 &bull;&bull; &bull; Jn back to their natural order by an even number 
of interchanges of adjacent integers, and EJ,jz ... J" =- 1 if the permutation 
(Jd2 ... Jn) is odd. In other words, pick an element aiJ, from the first row 
</p>
<p>299 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>of the matrix A. Then, multiply it by an element a2h from the second 
row of A, withj2'1' }1&bull; Continue this process, going from row to row, and 
always picking from a new column. Finally, multiply the product 
av,a2h ... anj" by + 1 if the permutation (} 112 ... Jn) is even and by -1 if 
the permutation is odd. Do this for all possib1e choices of picking one 
element from each row of A, never picking from the same column twice. 
Then, add up all these contributions and denote the resulting number 
by detA. 
</p>
<p>Remark. There are many different ways of bringing a permutation of the 
integers 1, 2, ... , n back to their natural order by successive interchanges of 
adjacent integers. For example, 
</p>
<p>4312~4132~1432~1423~1243~1234 
</p>
<p>and 
4312~3412~3142~3124~1324~1234. 
</p>
<p>However, it can be shown that the number of interchanges of adjacent in-
tegers necessary to unscramble the permuationj1 &bull; .. Jn is always odd oral-
ways even. Hence ej, .. Jn is perfectly well defined. 
</p>
<p>Example 1. Let 
</p>
<p>A=(au at2). 
a21 a22 
</p>
<p>In this case, there are only two products a 11 a 22 and a 12a 21 that enter into 
the definition of detA. Since the permutation (12) is even, and the per-
mutation (21) is odd, the term a 11 a 22 is multiplied by + 1 and the term 
a 12a21 is multiplied by -1. Hence, detA=a 11 a22 -a12a21 &bull; 
</p>
<p>Example 2. Compute 
</p>
<p>detu j n 
Solution. A shorthand method for computing the determinant of a 3 X 3 
matrix is to write the first two co1umns after the matrix and then take 
products along the diagonals as shown below. 
</p>
<p>det[ ~ 
-1 
</p>
<p>1 
2 
</p>
<p>-1 
</p>
<p>If Ais an n X n matrix, then detA will contain, in general, n! products of 
n elements. The determinant of a 4 X 4 matrix contains, in general, 24 
terms, while the determinant of a 10 X 10 matrix contains the unacceptably 
</p>
<p>300 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.5 The theory of determinants 
</p>
<p>large figure of 3,628,800 terms. Thus, it is practically impossible to com-
pute the determinant of a large matrix A using the definition (5) alone. The 
smart way, and the only way, to compute determinants is to (i) find special 
matrices whose determinants are easy to compute, and (ii) reduce the prob-
lern of finding any determinant to the much simpler problern of computing 
the determinant of one of these special matrices. To this end, observe that 
there are three special classes of matrices whose determinants are trivial to 
compute. 
</p>
<p>I. Diagonal matrices: A matrix 
</p>
<p>all 0 0 0 
</p>
<p>0 
A= 
</p>
<p>a22 0 0 
</p>
<p>0 0 0 ann 
</p>
<p>whose nondiagonal elements are all zero, is called a diagonal matrix. lts 
determinant is the product of the diagonal elements all&bull; a22&bull; &bull;&bull;&bull; 'ann&bull; This 
follows immediately from the observation that the only way we can choose 
a nonzero element from the first row of Ais to pick all. Similarly, the only 
way we can choose a nonzero element from the jth row of A is to pick ajj. 
Thus the only nonzero product entering into the definition of det A is 
alla22 ... ann' and this term is multiplied by +I since the permutation 
(12 ... n) is even. 
</p>
<p>2. Lower diagonal matrices: A matrix 
</p>
<p>all 0 0 
</p>
<p>a2I a22 0 
A= 
</p>
<p>anl an2 ann 
</p>
<p>whose elements above the main diagonal are all zero, is called a lower di-
agonal matrix, and its determinant too is the product of the diagonal ele-
ments all, ... ,ann&middot; To prove this, observe that the only way we can choose a 
nonzero element from the first row of Ais to pick all. The second row of A 
has two nonzero elements, but since we have already chosen from the first 
column, we are forced to pick a22 from the second row. Similarly, we are 
forced to pick ajj from thejth row of A. Thus, detA=alla22 ... ann&middot; 
</p>
<p>3. Upper diagonal matrices: A matrix 
</p>
<p>all al2 aln 
0 a22 a2n 
</p>
<p>A= 
</p>
<p>0 0 ann 
</p>
<p>301 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>whose elements below the main diagonal are all zero is called an upper di-
agonal matrix and its determinant too is the product of the diagonal ele-
ments a11 , ... ,ann&middot; To prove this, we proceed backwards. The only way we 
can choose a nonzero element from the last row of A is to pick ann&middot; This 
then forces us to pick an-I,n-I from the (n -l)st row of A. Similarly, we 
are forced to pick ajj from thejth row of A. Hence detA=ann ... a22a 11 &bull; 
</p>
<p>W e now derive some simple but extremely useful properties of determi-
nants. 
</p>
<p>Property 1. If we interchange two adjacent rows of A, then we change the 
sign of its determinant. 
</p>
<p>PRooF. Let B be the matrix obtained from A by interchanging the kth and 
(k+ l)st rows. Observe that all of the products entering into the definition 
of detB are exactly the same as the products entering into the definition of 
detA. The only difference is that the order in which we choose from the 
columns of A and B is changed. For example, let 
</p>
<p>A~ [l 3 Jl -1 2 
and 
</p>
<p>B- [l 3 -n 2 -1 
The product 4 X 2 X 2 appears in detA by choosing first from the first row, 
third column; then from the second row, first column; and finally from the 
third row, second column. This same product appears in detB by choosing 
first from the first row, third column; then from the second row, second 
column; and finally from the third row, first column. More generally, the 
term 
</p>
<p>in detA corresponds to the term 
</p>
<p>in det B. The sign of the first term is determined by the permutation 
()1 .. &middot;Alk+ I&middot; .. Jn) while the sign of the second term is determined by the 
permutation ()1 &bull;&bull; &middot;ik+ 1A .. . Jn). Since the second permutation is obtained 
from the first by interchanging the kth and (k + l)st elements, we see that 
these two terms have opposite signs. Hence detB= -detA. 0 
</p>
<p>Property 2. If we interchange any two rows of A, then we change the sign 
of its determinant. 
</p>
<p>302 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.5 The theory of determinants 
</p>
<p>PRooF. We will show that the nurober of interchanges of adjacent rows re-
quired to interchange the ith and jth rows of A is odd. Property 2 will then 
follow immediately from Property I. Tothis end, assume thatj is greater 
than i. We needj- i successive interchanges of adjacent rows to get thejth 
row into the ith place, and thenj- i- I successive interchanges of adjacent 
rows to get the original ith row into the jth place. Thus the total nurober of 
interchanges required is 2U- i)- I, and this nurober is always odd. 0 
</p>
<p>Property 3. If any two rows of Aare equal, then detA=O. 
</p>
<p>PROOF. Let the ith andjth rows of A be equal, and Iet B be the matrix ob-
tained from A by interchanging its ith andjth rows. Obviously, B=A. But 
Property 2 states that detB= -detA. Hence, detA= -detA if two rows of 
Aare equal, and this is possible only if detA=O. 0 
</p>
<p>Property 4. det cA = c n det A. 
</p>
<p>PROOF. Obvious. 0 
</p>
<p>Property 5. Let B be the matrix obtained from A by multiplying its ith row 
by a constant c. Then, detB=cdetA. 
</p>
<p>PROOF. Obvious. 0 
</p>
<p>Property 6. Let AT be the matrix obtained from A by switching rows and 
columns. The matrix AT is called the transpose of A. For example, if 
</p>
<p>A= [ ~ 
-1 
</p>
<p>3 
9 
2 
</p>
<p>A concise way of saying this is (AT)!i= aji' Then, 
</p>
<p>detAT =detA. 
</p>
<p>6 
9 
4 
</p>
<p>-I] 2 . 
7 
</p>
<p>PROOF. lt is clear that all the products entering into the definition of detA 
and detAT are equal, since we always choose an element from each row 
and each column. The proof that these products have the same sign, 
though, is rather difficult, and will not be included here. (Frankly, 
whenever this author teaches determinants to his students he wishes that 
he were king, so that he could declare Property 6 true by edict.) 0 
</p>
<p>Remark. 1t follows immediately from Properties 2, 3, and 6 that we change 
the sign of the determinant when we interchange two columns of A, and 
that detA = 0 if two columns of A are equal. 
</p>
<p>Property 7. If we add a multiple of one row of A to another row of A, then 
we do not change the value of its determinant. 
</p>
<p>303 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>PROOF. We first make the crucial observation that detA is a linear func-
tion of each row of A separately. By this we mean the following. Write the 
matrix A in the form 
</p>
<p>where 
</p>
<p>Then 
</p>
<p>and 
</p>
<p>For example, 
</p>
<p>A= 
</p>
<p>a1 = ( a11 , a12, &bull;&bull;&bull; , a1n) 
</p>
<p>a2 = ( a2t&bull; a22&bull; &bull; &bull; &bull; 'a2n) 
</p>
<p>det cak = c det ak 
</p>
<p>an an 
</p>
<p>a" 
</p>
<p>det ak + b = det ak + det b 
</p>
<p>an an a" 
</p>
<p>5 
2 
</p>
<p>-1 
</p>
<p>(i) 
</p>
<p>(ii) 
</p>
<p>since (4, 1, 9) + (4,2,- 2) = (8, 3, 7). Now Equation (i) is Property 5. To de-
</p>
<p>304 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.5 The theory of determinants 
</p>
<p>rive Equation (ii), we compute 
</p>
<p>det ak+b = L ej, ... j.aiJ,&middot;&middot;&middot;(akJ. +bj.) ... a'!i. 
j,, ... ,j. 
</p>
<p>JJ,&middot;&middot;&middot;,Jn )b&middot;&middot;&middot;,Jn 
</p>
<p>a' a' 
</p>
<p>=det ak +det b 
</p>
<p>an an 
</p>
<p>Property 7 now follows immediately from Equation (ii), for if B is the 
matrix obtained from A by adding a multiple c of the kth row of A to the 
jth row of A, then 
</p>
<p>aj + cak aj cak 
</p>
<p>detB=det =det +det =detA+cdet 
</p>
<p>ak ak ak 
</p>
<p>an an an 
</p>
<p>But 
</p>
<p>a' 
</p>
<p>ak 
</p>
<p>det =0 
</p>
<p>ak 
</p>
<p>an 
</p>
<p>since this matrix has two equal rows. Hence, detB=detA. 
</p>
<p>ak 
</p>
<p>ak 
</p>
<p>an 
</p>
<p>0 
</p>
<p>305 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>Remark 1. Everything we say about rows applies to columns, since detAT 
=detA. Thus, we do not change the value of the determinant when we add 
a multiple of one column of A to another column of A. 
</p>
<p>Remark 2. The determinant is a linear function of each row of A sep-
arately. It is not a linear function of A itself, since, in general, 
</p>
<p>detcA~cdetA and det(A+B)~detA+detB. 
</p>
<p>For example, if 
</p>
<p>A=(~ -;) 
</p>
<p>and 
</p>
<p>B= ( -1 
0 
</p>
<p>then 
</p>
<p>det(A+B)=det(g 1 ~)=o, 
</p>
<p>while detA+detB=3-9= -6. 
</p>
<p>Property 7 is extremely important because it enables us to reduce the 
problern of computing any determinant to the much simpler problern of 
computing the determinant of an upper diagonal matrix. To wit, if 
</p>
<p>au a12 aln 
</p>
<p>a21 a22 a2n 
</p>
<p>A= 
</p>
<p>an! 0 n2 0 nn 
</p>
<p>and a11 ~ 0, then we can add suitable multiples of the first row of A to the 
remairring rows of A so as to make the resulting values of a 21 , ... ,an1 all 
zero. Similarly, we can add multiples of the resulting second row of A to 
the rows beneath it so as to make the resulting values of a 32, ... , an2 all zero, 
and so on. We illustrate this method with the following example. 
</p>
<p>Example 3. Compute 
</p>
<p>306 
</p>
<p>-1 
2 
1 
2 
</p>
<p>2 3 
0 2 
</p>
<p>-1 -1 
3 0 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.5 The theory of determinants 
</p>
<p>Solution. Subtracting twice the first row from the second row; four times 
the first row from the third row; and the first row from the last row gives 
</p>
<p>detl~ 
-1 2 
</p>
<p>_ !J ~det 
1 -1 2 3 
</p>
<p>2 0 0 4 -4 -4 
1 -1 0 5 -9 -13 
2 3 0 3 1 -3 
</p>
<p>~4det[~ 
-1 2 
</p>
<p>3] 1 -1 -1 
5 -9 -13 . 
3 1 -3 
</p>
<p>Next, we subtract five times the second row of this latter matrix from the 
third row, and three times the second row from the fourth row. Then 
</p>
<p>1 -1 2 
</p>
<p>-!J ~4det 
1 -1 2 3 
</p>
<p>det 2 2 0 0 1 -1 -1 
4 1 -1 0 0 -4 -8 
1 2 3 0 0 4 0 
</p>
<p>Finally, adding the third row of this matrix to the fourth row gives 
</p>
<p>-1 
2 
1 
2 
</p>
<p>2 
0 
</p>
<p>-1 
3 
</p>
<p>~1 =4det[~ - ~ -; 
-1 0 0 -4 
</p>
<p>0 0 0 0 
</p>
<p>-~J -8 
-8 
</p>
<p>=4( -4)( -8) = 128. 
</p>
<p>(Alternately, we could have interchanged the third and fourth columns of 
the matrix 
</p>
<p>to yie1d the same result.) 
</p>
<p>-1 
1 
</p>
<p>0 
0 
</p>
<p>2 
-1 
</p>
<p>-4 
4 
</p>
<p>-ij 
-8 
</p>
<p>0 
</p>
<p>Remark 1. If a 11 =0 and aj1 *0 for some j, then we can interchange the 
first and jth rows of A so as to make a 11 *0. (We must remember, of 
course, to multiply the determinant by - 1.) If the entire first column of A 
is zero, that is, if a 11 = a21 = ... = an 1 = 0 then we need proceed no further 
for detA=O. 
</p>
<p>307 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>Remark 2. In exactly the same manner as we reduced the matrix A to an 
upper diagonal matrix, we can reduce the system of equations 
</p>
<p>auxi + a12x2 + ... + ainXn = bi 
a2Ixi +a22x2+ &middot;&middot;&middot; +a2nxn=b2 
</p>
<p>to an equivalent system of the form 
</p>
<p>CuXI +c12x2 + ... +cinxn=di 
C22X2+ &middot;&middot;&middot; +c2nxn=d2 
</p>
<p>We can then solve (if cnn'FO) for xn from the last equation, for Xn-I from 
the (n -1)st equation, and so on. 
</p>
<p>Example 4. Find all solutions of the system of equations 
</p>
<p>xi+x2+x3 = 1 
</p>
<p>- xi + x2 + x 3 =2 
2xi-x2+x3 =3. 
</p>
<p>Solution. Adding the first equation to the second equation and subtracting 
twice the first equation from the third equation gives 
</p>
<p>xi +x2+x3 = 1 
</p>
<p>2x2+2x3 =3 &middot; 
</p>
<p>-3x2- x 3 = I. 
</p>
<p>Next, adding f the second equation to the third equation gives 
xi +x2+x3 = 1 
</p>
<p>2x2+2x3 =3 
</p>
<p>2x =!! 3 2 . 
</p>
<p>Consequently, x3 = .!j-, x2 =(3 -.!j-)/2 =- ~. and xi = 1 + ~- .!j- =- i&middot; 
</p>
<p>EXERCISES 
</p>
<p>1. Show that the system of equations 
</p>
<p>308 
</p>
<p>aiixi + a 12x2 + a13x3 = b1 
a2Ixi + a22x2 + a23x3 = b2 
a31x1 + a32X2 + a33X3 = b3 </p>
<p/>
</div>
<div class="page"><p/>
<p>305 The theory of determinants 
</p>
<p>has a unique solution x 1,x2,x3 if, and only if, 
</p>
<p>Hint: Solve for x 1 in tenns of x2 and x3 from one of these equationso 
</p>
<p>2. (a) Show that the total nurober of pennutations of the integers 1, 2, o 0 0, n is 
eveno 
</p>
<p>(b) Prove that exactly half of these pennutations are even, and half are oddo 
</p>
<p>In each of Problems 3-8 compute the determinant of the given matrixo 
</p>
<p>[ -~ 5. -b 
0 
</p>
<p>2 
8 
</p>
<p>-1 
2 
</p>
<p>3 
-1 
</p>
<p>0 
6 
</p>
<p>- ~] 
-1 
</p>
<p>1 
</p>
<p>&bull;. l:, ,, n 
~ [1 
</p>
<p>-1 6 
0 1 
3 0 
</p>
<p>-1 1 
</p>
<p>1 1 1 1 1 
1 0 0 0 2 
</p>
<p>8.01003 
0 0 1 0 4 
0 0 0 1 5 
</p>
<p>9. Without doing any computations, show that 
</p>
<p>In each of Problems 10-15, find all solutions of the given system of equa-
tions 
</p>
<p>10. x 1+x2-x3=0 
2x1 + x3 = 14 
</p>
<p>x2 +x3 = 13 
</p>
<p>12. x 1 +x2 +x3 =0 
x 1-x2 -x3 =0 
</p>
<p>x2 +x3 =0 
</p>
<p>14. x 1 +x2 +2x3 -x4 = 1 
x 1-x2 +2x3 +x4 =2 
x 1 +x2+2x3 -x4 = 1 
</p>
<p>-x1-x2 -2x3 +x4 =0 
</p>
<p>11. x 1 +x2 +x3 =6 
x 1-x2-x3= -4 
</p>
<p>x2 +x3 = -I 
</p>
<p>13. x 1+ x2 + x3 -x4 =1 
x 1 +2x2 -2x3 +x4 = 1 
x 1 +3x2 -3x3 -x4 = 1 
x 1 +4x2 -4x3 -x4 = I 
</p>
<p>15. x 1- x2 +x3 + x4 =0 
x 1 +2x2 -x3 +3x4 =0 
</p>
<p>3x1 +3x2 -x3+7x4 =0 
-x1+2x2 +x3 - x4 =0 
</p>
<p>309 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>3.6 Solutions of simultaneous linear equations 
</p>
<p>In this section we will prove that the system of equations 
</p>
<p>Ax=b, {I) 
</p>
<p>has a unique solution x if detA1'0. Tothis end, we define the product of 
two n X n matrices and then derive some additional properties of determi-
nants. 
</p>
<p>Definition. Let A and B be n X n matrices with elements aiJ and biJ respec-
tively. We define their product AB as the n X n matrix C whose ij ele-
ment ciJ is the product of the ith row of A with the jth column of B. 
That is to say, 
</p>
<p>n 
</p>
<p>ciJ = L a;kbkJ" 
k=l 
</p>
<p>Alternately, if we write B in the form B = (b\ b2, ... , bn), where bi is the 
jth column of B, then we can express the product C =AB in the form 
C = (Ab1, Ab2, &bull; &bull;&bull; , Ahn), since the ith component of the vector Abi is 
</p>
<p>L:=IaikbkJ&middot; 
</p>
<p>Exampie 1. Let 
</p>
<p>A=[~ 
1 -:] 2 
I 
</p>
<p>and 
</p>
<p>B= [ ~ 
-1 n -1 -1 0 
</p>
<p>Compute AB. 
Solution. 
</p>
<p>[~ 
I -:][ ~ -1 0] [3+2+1 -3-1+0 0+ I +0] 2 -1 I = 0+4-1 0-2+0 0+2+0 
I 1 -1 0 0 I +2-1 -1-1+0 0+1+0 
</p>
<p>= [~ 
-4 
</p>
<p>~] -2 -2 
</p>
<p>310 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.6 Solutions of simultaneous linear equations 
</p>
<p>Example 2. Let A and B be the matrices in Example 1. Compute BA. 
Solution. 
</p>
<p>u -1 rm 1 -1] [ 3+0+0 1-2+0 -1-1 +0] -1 2 1 = 6+0+ 1 2-2+1 -2-1+1 0 1 1 -3+0+0 -1+0+0 1+0+0 
~[ i -1 -2] 1 -2 
</p>
<p>-3 -1 1 
</p>
<p>Remark 1. As Examples 1 and 2 indicate, it is generallynot true that AB= 
BA. lt can be shown, though, that 
</p>
<p>A(BC) = (AB)C (2) 
</p>
<p>for any three n X n matrices A, B, and C. We will give an extremely simple 
proof of (2) in the next section. 
</p>
<p>Remark 2. Let I denote the diagonal matrix 
</p>
<p>1 0 0 
0 1 0 
</p>
<p>0 0 
</p>
<p>I is called the identity matrix since IA=AI=A (see Exercise 5) for any 
n X n matrix A. 
</p>
<p>The following two properties of determinants are extreme1y usefu1 in 
many applications. 
</p>
<p>Property 8. 
</p>
<p>detAB=detAXdetB. 
</p>
<p>That is to say, the determinant of the product is the product of the de-
terminants. 
</p>
<p>Property 9. Let A(iiJ) denote the (n- 1) X (n -1) matrix obtained from A 
by deleting the ith row andjth column of A. For example, if 
</p>
<p>A=[ ~ 
-4 
</p>
<p>2 
-1 
-5 
</p>
<p>Let cu=( -ly+i detA(iiJ). Then 
n 
</p>
<p>detA= ~ aucu 
i= I 
</p>
<p>311 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>for any choice of j between 1 and n. This process of computing deterrni-
nants is known as "expansion by the elements of columns," and Prop-
erty 9 states that it does not matter which column we choose to expand 
about. For example, let 
</p>
<p>A~[ ~ 
3 2 
</p>
<p>n -1 0 1 3 -1 6 3 
Expanding about the first, second, third, and fourth columns of A, re-
spectively, gives 
</p>
<p>[-I 0 ~]-9det[! 2 1] detA=det ! 3 3 3 3 
+2detH 2 ~] +det[-! 
</p>
<p>2 
</p>
<p>!] 0 0 3 3 
~ -Jdet[ ~ 0 ~]-d&bull;t[ ~ 
</p>
<p>2 
</p>
<p>1] 3 3 -1 3 5 -1 3 
-det[ ~ 2 ~] +6det[~ 
</p>
<p>2 
</p>
<p>!] 0 0 -1 3 3 
~2det[ ~ 
</p>
<p>-1 
~] +3det[ ~ 3 ~] 1 -1 -1 6 5 -1 6 
</p>
<p>-3det[~ 
3 
</p>
<p>!] -1 1 
--6det[ ~ -1 ~] +7det[ ~ 3 ~] 1 1 -1 6 3 -1 6 
</p>
<p>-4det[ ~ 3 ~] +5det[~ 
3 H -1 -1 -1 6 1 
</p>
<p>We will derive Properlies 8 and 9 with the aid of the following Iemma. 
</p>
<p>Lemma 1. Let D = D (A) be a function that assigns to each n X n matrix A 
a number D (A). Suppose, moreover, that D is a linear function of each 
</p>
<p>312 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.6 Solutions of simultaneous linear equations 
</p>
<p>column (row) of A separately, i.e. 
</p>
<p>D ( l j + b) n) _ D { I j n) + D { I 1..) n) a , ... ,a c , ... ,a - a , ... ,a , ... ,a c a , ... ,., , ... ,a , 
and D (B) = - D (A) if B is obtained from A by interchanging two col-
umns (rows) of A. Then 
</p>
<p>D (A) =detAX D {I). 
</p>
<p>A function D that assigns to each n X n matrix a nurober is called alter-
nating if D (B) = - D (A) whenever B is obtained from A by interchanging 
two columns (rows) of A. Lemma 1 shows that the properties of being 
alternating and linear in the columns (rows) of A serve almost completely 
to characterize the determinant function detA. More precisely, any func-
tion D (A) which is alternating and linear in the columns (rows) of A must 
be a constant multiple of detA. lf, in addition, D(I)= 1, then D(A)=detA 
for all n X n matrices A. lt also follows immediately from Lemma 1 that if 
D (A) is alternating and linear in the columns of A, then it is also alternat-
ing and linear in the rows of A. 
</p>
<p>PR.ooF OF LEMMA 1. We first write A in the form A=(a1,a2, ... ,an) where 
</p>
<p>an al2 aln 
a21 
</p>
<p>a2= 
a22 a2n 
</p>
<p>al= 
' 
</p>
<p>, ... ,an= 
</p>
<p>an! an2j ann 
</p>
<p>Then, writing a1 in the form a1 = a 11e1 + ... + an 1en we see that 
</p>
<p>D(A)=D(a 11e1+ ... +an1en,a2, ... ,an) 
</p>
<p>= a11 D (e\a2, ... , an)+ ... + an1D (en,a2, ... ,an) 
</p>
<p>= Lav,D(e1&bull;,a2, ... ,an). 
j, 
</p>
<p>Similarly, writing a2 in the form a2=a12e1+ ... +an2en we see that 
</p>
<p>D(A)= L av,a2hD(e1&bull;,eh,a3, &bull;&bull;&bull; ,an). 
j,Jz 
</p>
<p>Proceeding inductively, we see that 
</p>
<p>D(A)= L av,a2),&middot;&middot;&middot;anJnD(e1&bull;,eh, ... ,eJn). 
j., ... Jn 
</p>
<p>Now, we need only sum over those integers }1,}2, ... ,Jn with }; =I= A since 
D (A) is zero if A has two equal columns. Moreover, 
</p>
<p>D (ei&bull;,eh, ... ,ein)= fy,J, ... JnD (e1,e2, ... ,en) = eJ.. .. JnD (I). 
</p>
<p>313 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>Consequently, 
</p>
<p>D(A)= L e1, ... J.a1J,&middot;&middot;&middot;a'li&szlig;(I)=detAXD(I). D 
Jt, ... ,Jn 
</p>
<p>We are now in a position to derive Properties 8 and 9. 
</p>
<p>PROOF OF PROPERTY 8. Let A be a fixed n X n matrix, and define the func-
tion D (B) by the formula 
</p>
<p>D (B) = detAB. 
</p>
<p>Observe that D (B) is alternating and linear in the columns b1, &bull;.&bull; , bn of B. 
This follows immediately from the fact that the columns of AB are 
Ab1, &bull;&bull;&bull; ,Abn. Hence, by Lemma 1. 
</p>
<p>D (B)=detBX D (I)=detBXdetAI=detAXdetB. 0 
</p>
<p>PROOF OF PROPERTY 9. Pick any integer j between 1 and n and Iet 
n 
</p>
<p>D(A)= L aiJcii' 
i= I 
</p>
<p>where ciJ = (- Iy+i detA(ilj). It is trivial to verify that D is alternating and 
linear in the columns of A. Hence, by Lemma 1, 
</p>
<p>D (A) =detA x D (I) =detA. D 
</p>
<p>The key to solving the system of equations (I) is the crucial observation 
that 
</p>
<p>n 
</p>
<p>L a;kciJ=O for k=!=j 
i= I 
</p>
<p>(3) 
</p>
<p>where ciJ = ( -IY+J detA(ilj). The proof of (3) is very simple: Let B denote 
the matrix obtained from A by replacing thejth column of A by its kth col-
umn, leaving everything eise unchanged. For example, if 
</p>
<p>A~[ ~ 
5 1} 2 j=2, and k=3, 
</p>
<p>-1 0 -1 
</p>
<p>then 
</p>
<p>B~ [ ~ 
6 1] 1 
</p>
<p>-1 -1 -1 
</p>
<p>Now, the determinant of B is zero, since B has two equal columns. On the 
other band, expanding about the jth column of B gives 
</p>
<p>n n 
</p>
<p>detB= L bucu= L a;kciJ 
i= I i= I 
</p>
<p>314 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.6 Solutions of simultaneous linear equations 
</p>
<p>where 
</p>
<p>ciJ = (- l)i+J detB(iiJ) = ( -l)i+J detA(iiJ) = ciJ. 
</p>
<p>Hence, L;=,a;kciJ=O if k is unequal toj. 
Now, whenever we see a sum from 1 to n involving the product of terms 
</p>
<p>with two fixed indicesj and k (as in (3)), we try and write it as thejk ele-
ment of the product of two matrices. If we let C denote the matrix whose ij 
element is ciJ and set 
</p>
<p>adjA:::::cr, 
</p>
<p>then 
n n 
</p>
<p>L a;kciJ= L (adjA)1;a;k=(adjAXA)1k. 
i= I i= I 
</p>
<p>Hence, from (3), 
</p>
<p>(adjAXA)1k=O for j=l=k. 
</p>
<p>Combining this result with the identity 
</p>
<p>we see that 
</p>
<p>n 
</p>
<p>detA= L aiJciJ=(adjAxA)ii, 
i= I 
</p>
<p>detA 0 0 
</p>
<p>0 detA 0 
adjAXA= 
</p>
<p>0 0 detA 
</p>
<p>=(detA)I. (4) 
</p>
<p>Similarly, by working with Ar instead of A (see Exercise 8) we see that 
</p>
<p>detA 0 0 
0 detA 0 
</p>
<p>AXadjA= =(detA)I. 
</p>
<p>0 0 detA 
</p>
<p>Example 3. Let 
</p>
<p>A~ [: 
0 -I] 1 -1 . 
2 1 
</p>
<p>Compute adj A and verify directly the identities ( 4) and (5). 
Solution. 
</p>
<p>T 
</p>
<p>-2 1] [ 3 --2~ 01
1
</p>
<p>] 
~ -i = -i 
</p>
<p>(5) 
</p>
<p>315 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>so that 
</p>
<p>adjAxA~ [ -! -2 m: 0 -1] [2 0 ~] ~21 2 I - ~ = ~ 2 -2 2 0 
and 
</p>
<p>AxadjA~ [: 
0 -I][ 3 -2 
</p>
<p>~H~ 
0 
</p>
<p>~] ~21 I - ~ -i 2 2 
2 -2 0 
</p>
<p>Now, detA= I-2+ I +2=2. Hence, 
</p>
<p>adjAXA=AX adjA= (detA)I. 
</p>
<p>We return now to the system of equations 
</p>
<p>[ a_" a,'" l x{J bl Ax=b, A= . . ' b= (6) 
anl ann bn 
</p>
<p>If A were a nonzero number instead of a matrix, we wouid divide both 
sides of (6) by A to obtain that x= b/ A. This expression, of course, does 
not make sense if A is a matrix. However, there is a way of deriving the 
solution x = b/ A which does generalize to the case where A is an n X n 
matrix. To wit, if the number A were unequal to zero, then we can multiply 
both sides of (6) by the number A-I to obtain that 
</p>
<p>A - 1Ax=x=A - 1b. 
</p>
<p>Now, if we can define A-I as an n X n matrix when A is an n x n matrix, 
then the expression A -Ib would make perfectly good sense. This Ieads us 
to ask the following two questions. 
</p>
<p>Question I: Given an n X n matrix A, does there exist another n X n matrix, 
which we will call A- 1, with the property that 
</p>
<p>A - 1A=AA- 1 =I? 
</p>
<p>Question 2: If A-I exists, is it unique? That is to say, can there exist two 
distinct matrices B and C with the property that 
</p>
<p>BA=AB=I and CA=AC=I? 
</p>
<p>The answers to these two questions are supplied in Theorems 7 and 8. 
</p>
<p>Theorem 7. An n X n matrix A has at most one inverse. 
</p>
<p>PROOF. Suppose that A has two distinct inverses. Then, there exist two dis-
tinct matrices B and C with the property that 
</p>
<p>AB=BA=I and AC=CA=I. 
</p>
<p>316 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.6 Solutions of simultaneous linear equations 
</p>
<p>If we multiply both sides of the equation AC= I by B we obtain that 
</p>
<p>BI=B(AC) =(BA)C=IC. 
</p>
<p>Hence, B = C, which is a contradiction. 
</p>
<p>Theorem 8. A-I exists if, and only if, detA*O, andin this case 
</p>
<p>A-1 1 d"A 
= detA a ~ &middot; 
</p>
<p>D 
</p>
<p>(7) 
</p>
<p>PROOF. Suppose that detA*O. Then, we can divide both sides of the iden-
tities (4) and (5) by detA to obtain that 
</p>
<p>adjA 1 adjA 
detA XA=I= detA AXadjA=AX detA. 
</p>
<p>Hence, A- 1=adjA/detA. 
Conversely, suppose that A-I exists. Taking determinants of both sides 
</p>
<p>of the equation A -JA= I, and using Property 8 gives 
</p>
<p>(detA - 1)detA=deti= 1. 
</p>
<p>Butthis equation implies that detA cannot equal zero. D 
</p>
<p>Finally, suppose that detA*O. Then, A-I exists, and multiplying both 
sides of (6) by this matrix gives 
</p>
<p>A - 1Ax=Ix=x=A - 1b. 
</p>
<p>Hence, if a solution exists, it must be A - 1b. Moreover, this vector is a solu-
tion of (6) since 
</p>
<p>A(A - 1b)=AA - 1b=Ib=b. 
</p>
<p>Thus, Equation (6) has a unique solution x=A -lb if detA*O. 
</p>
<p>Example 4. Find all solutions of the equation 
</p>
<p>[~ 
1 
</p>
<p>JJ&middot;~ln x~ [~:] -2 (8) 3 
Solution. 
</p>
<p>det[~ 
I 
</p>
<p>~] ~det[ ~ 
I 
</p>
<p>~ l ~24 -2 -4 
3 -3 0 0 -6 
</p>
<p>Hence, Equation (8) has a unique solution x. But 
</p>
<p>x~ [ ~~ 
317 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>is obviously one solution. Therefore, 
</p>
<p>is the unique solution of (8). 
</p>
<p>Remark. It is often quite cumbersome and time consuming to compute the 
inverse of an n X n matrix A from (7). This is especially true for n ~ 4. An 
alternate, and much more efficient way of computing A-I, is by means of 
"elementary row operations." 
</p>
<p>Definition. An elementary row operation on a matrix A is either 
(i) an interchange of two rows, 
(ii) the multiplication of one row by a nonzero number, 
or 
(iii) the addition of a multiple of one row to another row. 
</p>
<p>It can be shown that every matrix A, with detAoFO, can be transformed 
into the identity I by a systematic sequence of these operations. Moreover, 
if the same sequence of operations is then performed upon I, it is trans-
formed into A- 1&bull; We illustrate this method with the following example. 
</p>
<p>Example 5. Find the inverse of the matrix 
</p>
<p>0 
I 
2 
</p>
<p>-1] -1 . 
1 
</p>
<p>Solution. The matrix A can be transformed into I by the following 
sequence of elementary row operations. The result of each step appears be-
low the operation performed. 
</p>
<p>(a) We obtain zeros in the off-diagonal positions in the first column by 
subtracting the first row from both the second and third rows. 
</p>
<p>[~ 
0 
1 
2 
</p>
<p>(b) We obtain zeros in the off-diagonal positions in the second column by 
adding (- 2) times the second row to the third row. 
</p>
<p>[~ 
318 
</p>
<p>0 
1 
0 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.6 Solutions of simultaneous linear equations 
</p>
<p>(c) We obtain a one in the diagonal position in the third column by multi-
plying the third row by 4. 
</p>
<p>[~ 
0 
I 
0 
</p>
<p>(d) Finally, we obtain zeros in the off-diagonal positions in the third col-
umn by adding the third row to the first row. 
</p>
<p>If we perform the same sequence of elementary row operations upon I, we 
obtain the following sequence of matrices: 
</p>
<p>[~ 
0 
</p>
<p>~].[-: 
0 HH 0 n 1 1 1 0 1 -1 0 -2 
</p>
<p>H 
0 n 
</p>
<p>3 -1 I 2 2 
1 -1 0 
</p>
<p>-1 I -1 I 2 2 
</p>
<p>The last of these matrices is A- 1&bull; 
</p>
<p>EXERCISES 
</p>
<p>In each of Problems 1-4, compute AB and BA for the given matrices A 
and B. 
</p>
<p>1. A= (! 2 ~), ( -1 
0 -!) 2. A=U ~), B=(i n I B= ~ I 6 6 
</p>
<p>3. A=(l 
0 
</p>
<p>i), B= 0 1 i) 1 1 1 0 
4. A~ [! n B~ [l 
</p>
<p>1 1 
</p>
<p>ll 2 2 3 3 4 4 
5. Show that lA =AI= A for all matrices A. 
6. Show that any two diagonal matrices A and B commute, that is AB= BA, if A 
</p>
<p>and B are diagonal matrices. 
</p>
<p>319 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>7. Suppose that AD =DA for all matrices A. Prove that D is a multiple of the 
identity matrix. 
</p>
<p>8. Prove that AxadjA=detAxl. 
</p>
<p>In each of Problems 9-14, find the inverse, if it exists, of the given matrix. 
</p>
<p>9. ( -~ ~ ;) 10. (co~9 ~ -shn9) 
4 1 -1 sin9 0 cos9 
</p>
<p>11. ( -i -D 12. u 2 -~) i 1 1 3 -1 
13. (l l+i 1f) 14. (- ~ 1 l) 0 0 1 -1 -1 
15. Let 
</p>
<p>Show that 
</p>
<p>if detA""'O. 
</p>
<p>16. Show that (AB)- 1=B- 1A- 1 if detAXdetB""'O. 
</p>
<p>In each of Problems 17-20 show that x = 0 is the unique solution of the 
given system of equations. 
</p>
<p>17. x 1 - x2 - x3 =0 
3x1- x2 +2x3=0 
2x1 +2x2 +3x3=0 
</p>
<p>19. x1+ 2x2 - x3 
2x1+ 3x2+ x3-
</p>
<p>=0 
x4 =0 
</p>
<p>-x1 +2x3+2x4 =0 
3x1- x2+ x3+3x4 =0 
</p>
<p>3.7 Lineartransformations 
</p>
<p>18. x1 +2x2+4x3=0 
x2+ x3=0 
</p>
<p>x 1+ x2 + x 3 =0 
20. x 1 + 2x2- x3+3x4 =0 
</p>
<p>2x1 + 3x2 - x4 =0 
-x1+ x2+2x3+ x4 =0 
</p>
<p>-x2+2x3+3x4 =0 
</p>
<p>In the previous section we approached the problern of solving the equation 
</p>
<p>[
an 
</p>
<p>Ax=b, A= : 
</p>
<p>an1 
</p>
<p>(1) 
</p>
<p>by asking whether the matrix A - 1 exists. This approach led us to the con-
clusion that Equation (1) has a unique solution x=A- 1b if detA~O. In 
</p>
<p>320 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.7 Linear transformations 
</p>
<p>order to determine what happens when det A = 0, we will approach the 
problern of solving (I) in an entirely different manner. To wit, we willlook 
at the set V of all vectors obtained by multiplying every vector in Rn by A 
and see if b is in this set. Obviously, Equation (I) has at least one solution 
x if, and only if, b is in V. We begin with the following simple but ex-
tremely useful Iemma. 
</p>
<p>Lemma 1. Let A be an n X n matrix with elements a;p and Iet x be a vector 
with components x 1,xb&middot;&middot;&middot;,xn. Let 
</p>
<p>denote the jth column of A. Then 
</p>
<p>Ax=x1a1 +x2a2 + ... +xnan. 
</p>
<p>PROOF. We will show that the vectors Ax and x1a1 + ... + xnan have the 
same components. To this end, observe that (Ax)p the jth component of 
Ax, is a11 x 1 + ... + a1nxm while thejth component of the vector x 1a1 + ... + 
xnan is 
</p>
<p>x1a) + ... +xna}=x1a11 + ... + xnaJn =(Ax)p 
</p>
<p>Hence, Ax=x1a1 +x2a2 + ... +xnan. D 
</p>
<p>Now, Jet V be the set of vectors obtained by multiplying every vector x 
in Rn by the matrix A. It follows immediately from Lemma I that V is the 
set of all linear combinations of the vectors al, a2, &bull;&bull;. , an, that is, V is 
spanned by the columns of A. Hence the equation Ax = b has a solution if, 
and only if, b is a linear combination of the columns of A. With the aid of 
this observation, we can now prove the following theorem. 
</p>
<p>Theorem 9. (a) The equation Ax=b has a unique solution if the columns of 
A are linearly independent. 
</p>
<p>(b) The equation Ax = b has either no solution, or infinitely many solu-
tions, if the columns of Aare linearly dependent. 
</p>
<p>PRooF. (a) Suppose that the columns of A are linearly independent. Then, 
a1,a2, .&bull;&bull; ,an form a basis for Rn. In particular, every vector b can be written 
as a linear combination of al,a2, .&bull;&bull; ,an. Consequently, Equation (I) has at 
least one solution. To prove that (I) has exactly one solution, we show that 
any two solutions 
</p>
<p>321 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>and 
</p>
<p>must be equal. Tothis end, observe that if x and y are two solutions of (1), 
then 
</p>
<p>A{x -y) =Ax- Ay= b-b=O. 
</p>
<p>By Lemma l, therefore, 
</p>
<p>{xi-YI)a1 + (x2-Y2)a2 + ... + (xn-Yn)an =0. {2) 
</p>
<p>Butthis implies that x1 =y 1, x2 =y2, ... , and xn=Yn&bull; since a1,a2, ... ,an are 
linearly independent. Consequently, x = y. 
</p>
<p>(b) If the columns of Aare linearly dependent, then we can extract from 
a1,a2, ... ,an a smaller set of independent vectors which also span V (see Ex-
ercise 12, Section 3.3). Consequently, the space V has dimension at most 
n- I. In other words, the space V is distinctly smaller than Rn. Hence, 
there are vectors in Rn which are not in V. If b is one of these vectors, then 
the equation Ax = b obviously has no solutions. On the other hand, if b is 
in V, that is, there exists at least one vector x* such that Ax* = b, then 
Equation (I) has infinitely many solutions. To prove this, observe first that 
x=x* is certainly one solution of (1). Second, observe that if A~= 0 for 
some vector ~in Rn, then x =x* +~ is also a solution of (1), since 
</p>
<p>A(x* +~) = Ax* + A~= b+O = b. 
</p>
<p>Finally, observe that there exist numbers c1,c2, ... ,cn not all zero, suchthat 
c1a1+c2a2+ ... +cnan=O. By Lemma 1, therefore, A~=O, where 
</p>
<p>But if A~ equals zero, then A( a~ also equals zero, for any constant a. 
Thus, there are infinitely many vectors ~ with the property that A~ = 0. 
Consequently, the equation Ax = b has infinitely many solutions. 0 
</p>
<p>Example 1. (a) For which vectors 
</p>
<p>can we solve the equation 
</p>
<p>Ax- [i ~ !]x=b1 
322 </p>
<p/>
</div>
<div class="page"><p/>
<p>(b) Find all solutions of the equation 
</p>
<p>[l ~ !]&middot;- [g] 
(c) Find all solutions of the equation 
</p>
<p>1 
0 
1 
</p>
<p>Solution. (a) The columns of the matrix A are 
</p>
<p>3.7 Lineartransformations 
</p>
<p>a'~[i]. a'~[f] and a'~[H 
Notice that a1 and a2 are linearly independent while a3 is the sum of a1 and 
a2&bull; Hence, we can solve the equation Ax = b if, and only if, 
</p>
<p>for some constants c1 and c2&bull; Equivalently, (see Exercise 25) b3 = b1 + b2&bull; 
(b) Consider the three equations 
</p>
<p>x 1+x2 +2x3 =0 
x 1 + x3 =0 
</p>
<p>2x1+x2 +3x3 =0. 
</p>
<p>Notice that the third equation is the sum of the first two equations. Hence, 
we need only consider the first two equations. The second equation says 
that x 1 = - x3&bull; Substituting this value of x 1 into the first equation gives 
x2 = - x3&bull; Hence, all solutions of the equation Ax = 0 are of the form 
</p>
<p>(c) Observe first that 
</p>
<p>is clearly one solution of this equation. Next, let x2 be any other solution of 
this equation. It follows immediately that x2 =x1 +&euro;, where &euro; is a solution 
of the homogeneous equation Ax = 0. Moreover, the sum of any solution of 
</p>
<p>323 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>the nonhomogeneaus equation 
</p>
<p>with a solution of the homogeneaus equation is again a solution of the 
nonhomogeneaus equation. Hence, any solution of the equation 
</p>
<p>Ax- [ ~] 
is of the form 
</p>
<p>Theorem 9 is an extremely useful theorem since it establishes necessary 
and sufficient conditions for the equation Ax = b to have a unique solution. 
However, it is often very difficult to apply Theorem 9 since it is usually 
quite difficult to determine whether n vectors are linearly dependent or lin-
early independent. Fortunately, we can relate the question of whether the 
columns of A are linearly dependent or linearly independent to the much 
simpler problern of determining whether the determinant of A is zero or 
nonzero. There are several different ways of accomplishing this. In this sec-
tion, we will present a very elegant method which utilizes the important 
concept of a linear transformation. 
</p>
<p>Definition. A linear transformation ~ taking Rn into Rn is a function 
which assigns to each vector x in Rn a new vector which we call ~(x) = 
~(x 1 , ... ,xn). Moreover, this association obeys the following rules. 
</p>
<p>~( cx) = c~(x) 
</p>
<p>and 
</p>
<p>~(x +y) = ~(x) + ~(y). 
</p>
<p>Example 2. The transformation 
</p>
<p>is obviously a linear transformation of Rn into Rn since 
</p>
<p>~( cx) = cx = c~(x) 
</p>
<p>and 
</p>
<p>~(x+y)=x+y= ~(x)+~(y). 
</p>
<p>324 
</p>
<p>(i) 
</p>
<p>(ii) </p>
<p/>
</div>
<div class="page"><p/>
<p>3.7 Lineartransformations 
</p>
<p>Example 3. The transformation 
</p>
<p>x~ [ ;:] ~~(x)- [ ;: ~;:~~:] 
is a linear transformation taking R3 into R3 since 
</p>
<p>and 
</p>
<p>[
(xl + Y1) +(x2+ Y2) +(x3 + Y3) l 
</p>
<p>li(x+y)= (xl +y1)+(x2+y2)-(x3+y3) 
x1+Y1 
</p>
<p>Example 4. Let li(x1,x2) be the point obtained from x=(x1,x2) by rotating 
x 30&deg; in a counterclockwise direction. lt is intuitively obvious that any 
rotation is a linear transformation. If the reader is not convinced of this, 
though, he can compute 
</p>
<p>li(x1,x2)= [ 
4 YJ XI- 4x2] 
4xl+4 V3 X2 
</p>
<p>and then verify directly that (i isalinear transformation taking R2 into R2. 
</p>
<p>Example 5. The transformation 
</p>
<p>X= ( ~~)~(X~! X~) 
takes R2 into R2 but is not linear, since 
</p>
<p>li{2x)=li{2x1,2x2)=( 4 2
1
</p>
<p>4 2 )~2li(x). 
XI+ X2 
</p>
<p>Now, every n X n matrix A defines, in a very natural manner, a linear 
transformation li taking Rn~Rn. To wit, consider the transformation of 
Rn~Rn defined by 
</p>
<p>x~li(x)=Ax. 
</p>
<p>In Section 3.1, we showed that A(cx)= cAx and A(x+y)=Ax+Ay. Hence, 
</p>
<p>325 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>the association x~t!(x)=Ax is linear. Conversely, any linear transforma-
tion EE taking R"~R" must be of the form t!(x)=Ax for some matrix A. 
This is the content of the following theorem. 
</p>
<p>1beorem 10. Any linear Iransformation x~Et(x) taking R" into R" must be 
of the form l!(x) = Ax. In other words, given any linear Iransformation Et 
taking R" into R", we can find an n X n matrix A such that 
</p>
<p>t!(x)=Ax 
</p>
<p>for a/1 x. 
</p>
<p>PR.ooF. Let e1 denote the vector whose jth component is one, and whose 
remaining components are zero, and Iet 
</p>
<p>al=Et(el). 
</p>
<p>We claim that 
</p>
<p>(3) 
</p>
<p>for every 
</p>
<p>in R". To prove this, observe that any vector x can be written in the form 
x = x 1e1 + ... + x"e". Hence, by the linearity of t!, 
</p>
<p>Et(x) = Et( x1e1 + ... + x"e") = x 1l!(e1) + ... + x"Et(e") 
</p>
<p>0 
</p>
<p>Remark 1. The simplest way of evaluating a linear transformation Et is to 
compute a1=l!(e1), &bull;&bull;&bull; ,a"=El(e") and then observe from Theorem 10 and 
Lemma I that l!(x)=Ax, where A=(a1,a2, &bull;&bull;&bull; ,a"). Thus, to evaluate the 
linear transformation in Example 4 above, we observe that under a rota-
tion of 30&deg; in a counterclockwise direction, the point (1,0) goes into the 
point &Uuml; V3, t&gt; and the point (0, 1) goes into the point (- t. t V3 ). Hence, 
any point x=(x1,x2) goes into the point 
</p>
<p>Remark 2. If EE and ~ arelinear transformations taking R" into R", then 
the composition transformation Et o ~ defined by the relation 
</p>
<p>l!o~(x)=Et{~(x)) 
</p>
<p>326 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.7 Linear transforrnations 
</p>
<p>is again a linear transformation taking Rn~Rn. To prove this, observe that 
</p>
<p>and 
</p>
<p>(:E o 'E&szlig; ( cx) = !!E( 'E&szlig; ( cx)) = l:E( d&szlig; (x)) = cl:E( &euro;&szlig; (x)) 
</p>
<p>= cl:E o 'E&szlig; (x) 
</p>
<p>(:E o &euro;&szlig; (x + y) = l:E( 'E&szlig; (x + y)) = l:E( 'E&szlig; (x) + &euro;&szlig; (y)) 
</p>
<p>= l:E( 'E&szlig; (x)) + l:E( &euro;&szlig; (y)) = (:E o &euro;&szlig; (x) + (:E o 'E&szlig; (y). 
</p>
<p>Moreover, it isasimple matter to show (see Exercise 15) that if !!E(x)=Ax 
and &euro;&szlig; (x) = Bx, then 
</p>
<p>l:E o ';i (x) = ABx. (4) 
</p>
<p>Similarly, if l:E, &euro;&szlig;, and e are 3 linear transformations taking Rn into Rn, 
with !!E(x) = Ax, &euro;&szlig; (x) = Bx, and e(x) = Cx then 
</p>
<p>(l:Eo&euro;&szlig;)oe(x)=(AB)Cx (5) 
</p>
<p>and 
</p>
<p>(:E o ('E&szlig; o e)(x) =A(BC)x. 
</p>
<p>Now, clearly, (!!E o ';i) o e(x) = (:E o ('E&szlig; o e)(x). Hence, 
</p>
<p>(AB)Cx = A(BC)x 
</p>
<p>for all vectors x in Rn. This implies (see Exercise 14) that 
</p>
<p>(AB)C=A(BC) 
</p>
<p>for any three n X n matrices A, B, and C. 
</p>
<p>(6) 
</p>
<p>In most applications, it is usually desirable, and often absolutely essen-
tial, that the inverse of a linear transformation exists. Heuristically, the in-
verse of a transformation l:E undoes the effect of l:E. That is to say, if !!E(x) 
= y, then the inverse transformation applied to y must yield x. More pre-
cisely, we define l:E- 1 (y) as the unique element x in Rn for which !!E(x) = y. 
Of course, the transformation l:E- 1 may not exist. There may be some vec-
tors y with the property that y=l= !!E(x) for all x in Rn. Or, there may be 
some vectors y which come from more than one x, that is, l:E(x1) = y and 
!!E(x2) = y. In both these cases, the transformation l:E does not possess an 
inverse. In fact, it is clear that l:E possesses an inverse, which we will call 
l:E- 1 if, and only if, the equation !!E(x) = y has a unique solution x for every 
y in Rn. In addition, it is clear that if l:E is a linear transformation and l:E- 1 
exists, then l:E- 1 must also be linear. To prove this, observe first that 
l:E- 1(cy)=cl:E- 1(y) since l:E(cx)=cy if !!E(x)=y. Second, observe that 
l:E- 1(y1 +f)=l:E- 1(y1)+l:E- 1(f) since !!E(x1 +x2)=y1+f if !!E(x1)=y1 and 
!!E(x2) = y2&bull; Thus (:E- 1, if it exists, must be linear. 
</p>
<p>At this point the reader should feel that there is an intimate connection 
between the linear transformation (:E- 1 and the matrix A-I. This is the 
content of the following Iemma. 
</p>
<p>327 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>Lemma 2. Let A be an n X n matrix and Iet Ii be the linear transformation 
defined by the equation ci(x)=Ax. Then, Ii has an inverse if, and on/y if, 
the matrix Ahasan inverse. Moreover, if A-I exists, then ci- 1(x)= A - 1x. 
</p>
<p>PROOF. Suppose that ci- 1 exists. Clearly, 
</p>
<p>Ii o ci- 1(x) = ci- 1 o ci(x) = x (7) 
</p>
<p>and &laquo;- 1 is linear. Moreover, there exists a matrix B with the property that 
ci- 1(x)=Bx. Therefore, from (4) and (7) 
</p>
<p>ABx=BAx=x 
</p>
<p>for all x in Rn. But this immediately implies (see Exercise 14) that 
</p>
<p>AB= BA= I. 
</p>
<p>Hence B=A -I. 
Conversely, suppose that A- 1 exists. Then, the equation 
</p>
<p>ci(x)=Ax=y 
</p>
<p>has a unique solution x = A- 1y for all y in Rn. Thus, A- 1 also exists, and 
</p>
<p>0 
We are now ready to relate the problern of determining whether the col-
</p>
<p>umns of an n x n matrix A are linearly dependent or linearly independent 
to the much simpler problern of determining whether the deterrninant of A 
is zero or nonzero. 
</p>
<p>Lemma 3. The co/umns of an n X n matrix Aare linear/y independent if, and 
only if, det A * 0. 
</p>
<p>PROOF. We prove Lemma 3 by the following complex, but very clever 
argument. 
</p>
<p>(I) The columns of Aare linearly independent if, and only if, the equation 
Ax = b has a unique solution x for every b in Rn. This Statement is just 
a reformulation of Theorem 9. 
</p>
<p>(2) From the remarks preceding Lemma 2, we conclude that the equation 
Ax = b has a unique solution x for every b if, and only if, the linear 
transformation li(x)=Ax has an inverse. 
</p>
<p>(3) From Lemma 2, the linear transformation Ii has an inverse if, and 
only if, the matrix A- 1 exists. 
</p>
<p>(4) Finally, the matrix A-I exists if, and only if, detA*O. This is the con-
tent of Theorem 8, Section 3.6. Therefore, we conclude that the col-
umns of Aare linearly independent if, and only if, detA*O. 0 
</p>
<p>We summarize the results of this section by the following theorem. 
</p>
<p>328 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.7 Linear transformations 
</p>
<p>Theorem 11. The equation Ax=b has a unique solution x=A -Ib if detA* 
0. The equation Ax = b has eilher no solutions, or infinite/y many solutions 
if detA=O. 
</p>
<p>PRooF. Theorem 11 follows immediately from Theorem 9 and Lemma 3. 
0 
</p>
<p>Corollary. The equation Ax=O has a nontrivial solution (that is, a solution 
</p>
<p>&middot;{J 
with not all the X; equal to zero) if, and on/y if, detA=O. 
</p>
<p>PROOF. Observe that 
</p>
<p>is always one solution of the equation Ax = 0. Hence, it is the only solution 
if detA#O. On the other band, there exist infinitely many solutions if detA 
= 0, and all but one of these are non trivial. 0 
</p>
<p>Example 6. For which values of).. does the equation 
</p>
<p>have a nontrivial solution? 
Solution. 
</p>
<p>[l ~ 1]x~o 
</p>
<p>det[l ~ 1]-HH-~~~-1. 
Hence, the equation 
</p>
<p>[l ~ 1l&middot;=O 
has a nontrivial solution if, and only if, ).. = 1. 
</p>
<p>Remark 1. Everything we've said about the equation Ax = b applies equally 
weil when the elements of A and the components of x and b are complex 
numbers. In this case, we interpret x and b as vectors in cn, and the matrix 
A as inducing a linear transformation of cn into itself. 
</p>
<p>Remark 2. Suppose that we seek to determine n numbers x 1,x2, &bull;&bull;&bull; ,xn. Our 
intuitive feeling is that we must be given n equations which are satisfied by 
</p>
<p>329 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>these unknowns. This is certainly the case if we are given n linear equa-
tions of the form 
</p>
<p>a11 x 1 + a12x 2 + ... + a1nxn = bi' }= 1,2, ... ,n 
and detk;60, where 
</p>
<p>(9) 
</p>
<p>On the other hand, our intuition would seem tobe wrong when detA=O. 
This is not the case, though. To wit, if detA=O, then the columns of Aare 
linearly dependent. But then the columns of Ar, which are the rows of A, 
arealso linearly dependent, since detAT =detA. Consequently, one of the 
rows of A is a linear combination of the other rows. Now, this implies that 
the left-hand side of one of the equations (9), say the kth equation, is a lin-
ear combination of the other left-hand sides. Obviously, the equation Ax = 
b has no solution if bk is not the exact same linear combination of 
b1, ... ,bk-t&bull;bk+l&bull;"&middot;&bull;bn. For example, the system of equations 
</p>
<p>x 1-x2 + x3 = 1 
x 1 +x2 + x3 = 1 
</p>
<p>2x1 +2x3 =3 
</p>
<p>obviously has no solution. On the other hand, if bk is the same linear com-
bination of b1, ... ,bk-l&bull;bk+l&bull;"''bn, then the kth equation is redundant. In 
this case, therefore, we really have only n- 1 equations for the n unknowns 
xl,x2, ... ,xn. 
</p>
<p>Remark 3. Once we introduce the concept of a linear transformation we 
no Ionger need to view an n X n matrix as just a square array of numbers. 
Rather, we can now view an n X n matrix A as inducing a linear transfor-
mation ~(x) = Ax on Rn. The benefit of this approach is that we can derive 
properties of A by deriving the equivalent properties of the linear transfor-
mation ~. For example, we showed that (AB)C=A(BC) for any 3 n X n 
matrices A, B, and C by showing that the induced linear transformations 
~. ti, and (3 satisfy the relation (~ o li) o (3 = ~ o (li o &lt;3). Now, this re-
sult can be proven directly, but it requires a great deal more work (see Ex-
ercise 24). 
</p>
<p>EXERCISES 
</p>
<p>In each of Problems 1-3 find all vectors b for which the given system of 
equations has a solution. 
</p>
<p>~]x=b 
12 
</p>
<p>330 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.7 Linear transforrnations 
</p>
<p>(
ll 
</p>
<p>3. ~ 
</p>
<p>In each of Problems 4-9, find all solutions of the given system of equa-
tions. 
</p>
<p>4. u 2 -3) 5. ( -i 2 l)x=U) 3 -1 x=O -2 3 10 8 
[ ! 
</p>
<p>1 1 
</p>
<p>!]&middot;-&middot; 7. ( _; -1 -1) (-1) 6. -1 1 3 1 x= 2 1 -1 
1 1 -1 
</p>
<p>-1 1 -1 3 
</p>
<p>.. [~ 
2 3 
</p>
<p>!]&middot;~&middot; 9. 0 1 -Dx=( D 1 -1 0 0 -1 
4 6 1 
</p>
<p>In each of Problems 10-12, determine all values of X for which the given 
system of equations has a nontrivial solution. 
</p>
<p>10. ( ~ 
-1 
</p>
<p>12. 0 
</p>
<p>1 
i\ 
3 
</p>
<p>-1 
-1 
</p>
<p>i\ 
</p>
<p>-1) 
~ x=O. 
</p>
<p>11. [ l 
-1 
</p>
<p>1 
-1 
</p>
<p>1 
0 
</p>
<p>13. (a) For which va1ue of i\ does the system of equations 
</p>
<p>-4 
-1 
</p>
<p>2 
</p>
<p>have a solution? 
(b) Find all solutions for this value of i\. 
</p>
<p>14. Suppose that Ax = Bx for all vectors 
</p>
<p>Prove that A=B. 
</p>
<p>i\ 
i\ 
0 
</p>
<p>-1 
</p>
<p>15. Let tl and t!&szlig; be two linear transformations taking Rn into Rn. Then, there exist 
n X n matrices A and B such that tl(x) = Ax and t!&szlig; (x) = Bx. Show that tl o t!&szlig; (x) 
=A&szlig;x. Hint: tl o C!&szlig; isalinear transformation taking Rn into Rn. Hence, there 
exists an n X n matrix C such that tl o C!&szlig; (x) = Cx. The jth column of C is 
tl o t!&szlig; (ej). Thus show that tl o t!&szlig; (e j) is the jth column of the matrix AB. 
</p>
<p>331 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>16. Let tt be a linear transformation taking Rn~Rn. Show that lt(O)=O. 
</p>
<p>17. Let ~(8) be the linear transformation which rotates each point in the plane by 
an angle 8 in the counterclockwise direction. Show that 
</p>
<p>-sinB)(x&bull; )&middot; 
cosB X2 
</p>
<p>18. Let ~ and ~ 2 be the linear transformations which rotate each point in the 
plane by angles n. and 82 respectively. Then the linear transformation ~ = 
~ o ~ rotates each point in the plane by an angle 81 + 82 (in the counterclock-
wise direction). Using Exercise (15), show that 
</p>
<p>( cos(81 +82 ) -sin(81 +82 ) )=(cos81 
-sin81 )(cos82 
</p>
<p>sin(81+82 ) cos(81+82 ) sin81 cos81 sin82 
</p>
<p>Thus, derive the trigonometric identities 
</p>
<p>sin(81 + 82 ) = sin81 cos82 + cos81 sin82 
</p>
<p>cos( 81 + 82 ) = cos81 cos82 - sin81 sin82&bull; 
</p>
<p>19. Let 
</p>
<p>lt(x1, x2) = ( ;; ~ ;~ )&middot; 
</p>
<p>(a) Verify that tt is linear. 
(b) Show that every point (x.,x2) on the unit circle xr+ xi= 1 goes into a point 
</p>
<p>on the circle, xr + xi = 2. 
</p>
<p>20. Let V be the space of all polynomials p(t) of degree less than or equal to 3 and 
Iet (Dp)(t)=dp(t)/dt. 
(a) Show that D is a linear transformation taking V into V. 
(b) Show that D does not possess an inverse. 
</p>
<p>21. Let V be the space of all continuous functionsf(t),- oo &lt; t &lt; oo and Iet (Kf)(t) 
</p>
<p>= Jo' f(s)ds. 
(a) Show that K is a linear transformation taking V into V. 
(b) Show that (DK)j= f where Dj= f'. 
(c) Let f(t) be differentiable. Show that 
</p>
<p>[(KD)f](t)= f(t)- j(O). 
</p>
<p>22. A linear transformation tt is said tobe 1-1 if lt(x)*lt(y) whenever X*Y&middot; In 
other words, no two vectors go into the same vector under lt. Show that (t is 
1-l if, and only if, lt(x)= 0 implies that x=O. 
</p>
<p>23. A linear transformation tt is said to be onto if the equation lt(x) = y has at least 
one solution for every y in Rn. Prove that (t is onto if, and only if, (t is 1-l. 
Hint: Showfirst that tt is onto if, and only if, the vectors lt(e1), ... ,lt(en) are 
linearly independent. Then, use Lemma 1 to show that we can find a nonzero 
solution of the equation lt(x) =0 if lt(e1), ... , lt(en) are linearly dependent. Fi-
nally, show that lt(e1), ... , lt(en) are linearly dependent if the equation lt(x)=O 
has a nonzero solution. 
</p>
<p>332 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.8 The eigenvalue-eigenvector method 
</p>
<p>24. Prove directly that (AB)C=A(Bq. Hint: Show that these matrices have the 
same elements. 
</p>
<p>25. Show that 
</p>
<p>if, and only if, b3 = b1 + b2&bull; 
</p>
<p>3.8 The eigenvalue-eigenvector method 
of finding solutions 
</p>
<p>We return now to the first-order linear homogeneous differential equation 
</p>
<p>(I) 
</p>
<p>Our goal is to find n linearly independent solutions x1(t), ... ,xn(t). Now, 
recall that both the first-order and second-order linear homogeneous scalar 
equations have exponential functions as solutions. This suggests that we try 
x(t) = e&gt;..tv, where v is a constant vector, as a solution of (1). To this end, 
observe that 
</p>
<p>and 
</p>
<p>A(e&gt;..tv) = e"1Av. 
</p>
<p>Hence, x(t)= e&gt;..tv is a solution of (I) if, and only if, A.e"1v= e&gt;..tAv. Dividing 
both sides of this equation by e&gt;..t gives 
</p>
<p>~=~ w 
Thus, x(t)=eMv is a solution of (I) if, and only if, A. and v satisfy (2). 
</p>
<p>Definition. A nonzero vector v satisfying (2) is called an eigenvector of A 
with eigenvalue A.. 
</p>
<p>Remark. The vector v = 0 is excluded because it is uninteresting. Obvi-
ously, AO=l\&middot;0 for any number A.. 
</p>
<p>An eigenvector of a matrix A is a rather special vector: under the linear 
transformation x~Ax, it goes into a multiple A of itself. Vectors which are 
transformed into multiples of themselves play an important role in many 
applications. To find such vectors, we rewrite Equation (2) in the form 
</p>
<p>O=Av-A.v= (A -A.I)v. (3) 
</p>
<p>333 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>But, Equation (3) has a nonzero solution v only if det(A- Al)= 0. Hence 
the eigenvalues A of A are the roots of the equation 
</p>
<p>au-A al2 aln 
</p>
<p>0 = det(A- Al)= det 
a2I a22-A a2n 
</p>
<p>an I an2 ann-A 
</p>
<p>and the eigenvectors of A are then the nonzero solutions of the equations 
(A- Al)v = 0, for these values of A. 
</p>
<p>The determinant of the matrix A-Al is clearly a polynomial in A of de-
gree n, with leading term (- l)nA n. lt is customary to call this polynomial 
the characteristic polynomial of A and to denote it by p(A). For each root 
A; of p(A), that is, for each number A; such that p(A) = 0, there exists at least 
one nonzero vector vi such that Avi = &gt;yvi. Now, every polynomial of de-
gree n ~ 1 has at least one (possibly complex) root. Therefore, every matrix 
has at least one eigenvalue, and consequently, at least one eigenvector. On 
the other band, p(A) has at most n distinct roots. Therefore, every n X n 
matrix has at most n eigenvalues. Finally, observe that every n X n matrix 
has at most n linearly independent eigenvectors, since the space of all vec-
tors 
</p>
<p>has dimension n. 
</p>
<p>Remark. Let v be an eigenvector of A with eigenvalue A. Observe that 
</p>
<p>A(cv)= cAv= CAV=A( cv) 
</p>
<p>for any constant c. Hence, any constant multiple ( c ~ 0) of an eigenvector 
of A is again an eigenvector of A, with the same eigenvalue. 
</p>
<p>For _each eigenvector vi of A with eigenvalue Ai' we have a solution xi (t) 
= e"''1V1 of (1). If A has n linearly independent eigenvectors vl, ... , yn with 
eigenvalues A1, ... ,An respectively (A1, ... ,An need not be distinct), then xi(t) 
=e"'}v1,j= l, ... ,n are n linearly independent solutions of (1). This follows 
immediately from Theorem 6 of Section 3.4 and the fact that x! (0) = vi. In 
this case, then, every solution x(t) of (1) is of the form 
</p>
<p>(4) 
</p>
<p>This is sometimes called the "general solution" of (1). 
The situation is simplest when A has n distinct real eigenvalues 
</p>
<p>A1, A2, ... , An with eigenvectors v1, v2, ... , vn respectively, for in this case we 
</p>
<p>334 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.8 The eigenvalue-eigenvector method 
</p>
<p>are guaranteed that v1, v2, &bull;&bull;&bull; , v" are linearly independent. This is the con-
tent of Theorem 12. 
</p>
<p>Theorem 12. Any k eigenvectors v1, ... , vk of A with distinct eigenvalues 
A1, ... , Ak respectively, are linear/y independent. 
</p>
<p>PROOF. We will prove Theorem 12 by induction on k, the number of ei-
genvectors. Observe that this theorem is certainly true for k = l. Next, we 
assume that Theorem 12 is true for k = j. That is to say, we assume that 
any set of j eigenvectors of A with distinct eigenvalues is linearly indepen-
dent. We must show that any set of j + 1 eigenvectors of A with distinct ei-
genvalues is also linearly independent. To this end, let v1, ... , vi+ 1 be j + 1 
eigenvectors of A with distinct eigenvalues A1, ... ,A1+ 1 respectively. To de-
termine whether these vectors are linearly dependent or linearly indepen-
dent, we consider the equation 
</p>
<p>{5) 
</p>
<p>Applying A to both sides of (5) gives 
</p>
<p>(6) 
</p>
<p>Thus, if we multiply both sides of (5) by A1 and subtract the resulting equa-
tion from (6), we obtain that 
</p>
<p>(7) 
</p>
<p>But v2, ... ,vi+I arej eigenvectors of A with distinct eigenvalues A2, ... ,AJ+I 
respectively. By the induction hypothesis, they are linearly independent. 
Consequently, 
</p>
<p>Since A1,A2, ... ,\+I are distinct, we conclude that c2,c3, ... ,c1+1 are all zero. 
Equation (5) now forces c1 to be zero. Hence, v1, v2, ... , vi+ 1 are linearly in-
dependent. By induction, therefore, every set of k eigenvectors of A with 
distinct eigenvalues is linearly independent. D 
</p>
<p>Example 1. Find all solutions of the equation 
</p>
<p>i- [~ -~ -i]x. 
1 -1 
</p>
<p>Solution. The characteri.stic polynomial of the matrix 
</p>
<p>-~ -i] 
1 -1 
</p>
<p>335 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>is 
</p>
<p>p (A) = det( A - Al) = det [ 1 ; A 2-=_ ~ ~ 1 ] 
2 1 -1-A 
</p>
<p>=- (1 +A)(1-A)(2-A) + 2+ 12- 8(2-A) + (1-A)- 3(1 +A) 
</p>
<p>= (1- A)(A- 3)(A + 2). 
</p>
<p>Thus the eigenva1ues of A are A1 = 1, A2 = 3, and A3 = -2. 
(i) A1 = 1: We seek a nonzero vector v such that 
</p>
<p>(A- l)v- [~ 
-1 
</p>
<p>1 
1 
</p>
<p>This implies that 
</p>
<p>- v2 +4v3 =0, 3v1 + v2 - v3 =0, and 2v 1 + v2 - 2v3 =0. 
</p>
<p>Solving for v1 and v2 in terms of v3 from the first two equations gives v1 = 
- v3 and v2 = 4v3. Hence, each vector 
</p>
<p>is an eigenvector of A with eigenvalue one. Consequently, 
</p>
<p>is a solution of the differential equation for any constant c. For simplicity, 
we take 
</p>
<p>x'(t)-&bull;'[ -n 
(ii) A2 = 3: W e seek a nonzero vector v such that 
</p>
<p>(A-JI)v- [ -~ 
-1 
-1 
</p>
<p>1 
</p>
<p>This implies that 
</p>
<p>- 2v1 - v2 +4v3 =0, 3v1 - v2 - v3 = 0, and 2v 1 + v2 -4v3 =0. 
</p>
<p>Solving for v1 and v2 in terms of v3 from the first two equations gives v1 = 
v3 and v2 = 2v3&bull; Consequently, each vector 
</p>
<p>336 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.8 The eigenvalue-eigenvector rnethod 
</p>
<p>is an eigenvector of A with eigenvalue 3. Therefore, 
</p>
<p>x 2 (t)~e''[~] 
is a second solution of the differential equation. 
</p>
<p>(iii) &gt;.3 = -2: We seek a nonzero vector v such that 
</p>
<p>(A+ll)&middot;~[i -~ -:m:Hn 
This implies that 
</p>
<p>Solving for v1 and v2 in terms of v3 gives v1 = - v3 and v2 = v3&bull; Hence, each 
vector 
</p>
<p>is an eigenvector of A with eigenvalue -2. Consequently, 
</p>
<p>x'(t)~e- 2 ' [ -:l 
is a third solution of the differential equation. These solutions must be lin-
early independent, since A has distinct eigenvalues. Therefore, every solu-
tion x(t) must be of the form 
</p>
<p>x(the' [- ~] +c2e3' [ ~] +,,,-u [ -:j 
- c e 1 + c e31 - c e- 21 I 2 3 
4c 1e1 + 2c2e31 + c3e- 21 
</p>
<p>c e1+ c e31 +c e- 21 I 2 3 
</p>
<p>Remark. If &gt;. is an eigenvalue of A, then the n equations 
</p>
<p>j= l, ... ,n 
</p>
<p>are not independent; at least one of them is a linear combination of the 
others. Consequently, we have at most n- I independent equations for the 
n unknowns v1, &bull;&bull;&bull; , vn. This implies that at least one of the unknowns 
v1, &bull;&bull;&bull; , vn can be chosen arbitrarily. 
</p>
<p>337 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>Example 2. Solve the initial-value problern 
</p>
<p>x=U 1nx. x(O)=(~)&middot; 
Solution. The characteristic polynomial of the matrix 
</p>
<p>is 
</p>
<p>p(A) = det( 1 ~A I~.\)= (1-A)2 -36=(A -7)(A+ 5). 
</p>
<p>Thus, the eigenvalues of A are A1 = 7 and A2 = - 5. 
(i) A1 = 7: We seek a nonzero vector v such that 
</p>
<p>(A-7I)v=( -~ ~~)(~~)=(~)&middot; 
</p>
<p>This implies that v1 = 2v2&bull; Consequently, every vector 
</p>
<p>v=c(n 
is an eigenvector of A with eigenvalue 7. Therefore, 
</p>
<p>is a solution of the differential equation. 
(ii) A2 = - 5: W e seek a nonzero vector v such that 
</p>
<p>(A+51)v=(~ 1 ~){~~)=(~)&middot; 
</p>
<p>This implies that v1 = - 2v2&bull; Consequently, 
</p>
<p>is an eigenvector of A with eigenvalue -5, and 
</p>
<p>is a second solution of the differential equation. These solutions are lin-
early independent since A has distinct eigenvalues. Hence, x(t)=c1x1(t)+ 
c2x2(t). The constants c1 and c2 are determined from the initial condition 
</p>
<p>338 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.8 The eigenva1ue-eigenvector method 
</p>
<p>Thus, 2c1 - 2c2 =0 and c1 + c2 = 1. The solution of these two equations is 
c1 = t and c2 = t. Consequently, 
</p>
<p>Example 3. Find all solutions of the equation 
</p>
<p>1 1 l 1 1 
2 2 2 2 2 
</p>
<p>x=Ax= 3 3 3 3 3 X. 
4 4 4 4 4 
5 5 5 5 5 
</p>
<p>Solution. lt is not necessary to compute the characteristic polynomial of A 
in order to find the eigenvalues and eigenvectors of A. To wit, observe that 
</p>
<p>XI 1 
x2 2 
</p>
<p>Ax=A x3 = (xl + x2+ x3+x4+ xs) 3 
x4 4 
Xs 5 
</p>
<p>Hence, any vector x whose components add up to zero is an eigenvector of 
A with eigenvalue 0. In particular 
</p>
<p>1 0 0 0 
0 l 0 0 
</p>
<p>vl= 0, r= 0 ' v3= l ' 
and v4= 0 
</p>
<p>0 0 0 l 
-1 -I -I -1 
</p>
<p>are four independent eigenvectors of A with eigenvalue zero. Moreover, 
observe that 
</p>
<p>l 
2 
</p>
<p>v5 = 3 
4 
5 
</p>
<p>is an eigenvector of A with eigenvalue 15 since 
</p>
<p>l 
2 
</p>
<p>A 3 
4 
5 
</p>
<p>l 
2 
</p>
<p>=(1+2+3+4+5) 3 
4 
5 
</p>
<p>l 
2 
</p>
<p>= 15 3 
4 
5 
</p>
<p>339 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>The five vectors vl, v2, v3, v4, and v5 are easily seen to be linearly indepen-
dent. Hence, every solution x(t) is of the form 
</p>
<p>1 0 0 0 1 
0 1 0 0 2 
</p>
<p>x(t)=c1 0 +cz 0 +c3 1 +c4 0 +c et5t 5 3 
0 0 0 1 4 
</p>
<p>-1 -1 -1 -1 5 
</p>
<p>EXERCISES 
</p>
<p>In each of Problems 1-6 find all solutions of the given differential equa-
tion. 
</p>
<p>1. x=(~ -3) 1 X 2 . ( -2 . x= -4 j)x 
</p>
<p>3. x=(! 
2 
</p>
<p>i)x 4. x= ( -1b -1 -I~)x 0 4 2 -2 I -I 
( -7 0 ~)x u-[~ 
</p>
<p>2 3 
'~]&middot; s. x= ~ 5 6 9 0 10 I5 30 I4 2I 42 
</p>
<p>In each of Problems 7-12, solve the given initial-value problem. 
</p>
<p>7. x=(! Dx, x(O)=n) s. x=( -i -nx, x(O)=(~) 
</p>
<p>9. x={! 
1 -I) x(O)=( =D 3 -I x, 
3 -I 
</p>
<p>10. x=O 
-I 
</p>
<p>r)x, x(O)= ( ~;) 2 
10 
</p>
<p>u.x=(~ 
-3 
</p>
<p>~)x, x(O)= ( -~) -I -I -2 
</p>
<p>12. x=(-! 
I -qx, x(O)=( ! ) 2 I -3 -7 
</p>
<p>13. (a) Show that e"A&lt;r-ro&gt;v,t0 constant, is a solution of x=Ax if Av=A.v. 
(b) Solve the initial-value problern 
</p>
<p>x=( -! ~ =Dx, x(I)=(_D 
(see Exercise 12). 
</p>
<p>340 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.9 Complex roots 
</p>
<p>14. Three solutions of the equation x = Ax are 
</p>
<p>Find the eigenvalues and eigenvectors of A. 
</p>
<p>15. Show that the eigenvalues of A- 1 are the reciprocals of the eigenvalues of A. 
</p>
<p>16. Show that the eigenvalues of An are the nth power of the eigenvalues of A. 
</p>
<p>17. Show that ;\.=0 is an eigenvalue of A if detA=O. 
</p>
<p>18. Show, by example, that the eigenvalues of A + B are not necessarily the sum of 
an eigenvalue of A and an eigenvalue of B. 
</p>
<p>19. Show, by example, that the eigenvalues of AB are not necessarily the product 
of an eigenvalue of A with an eigenvalue of B. 
</p>
<p>20. Show that the matrices A and T- 1AT have the same characteristic polynomial. 
</p>
<p>21. Suppose that either B-I or A-I exists. Prove that AB and BA have the same 
eigenvalues. Hint: Use Exercise 20. (This result is true even if neither B- 1 or 
A-I exist; however, it is more difficult to prove then.) 
</p>
<p>3.9 Complex roots 
</p>
<p>If X= a + i&szlig; is a complex eigenvalue of A with eigenvector v=v1 + iv2, then 
x( t) = eMv is a complex-valued solution of the differential equation 
</p>
<p>x=Ax. (I) 
This complex-valued solution gives rise to two real-valued solutions, as we 
now show. 
</p>
<p>Lemma 1. Let x(t)=y(t)+ iz(t) be a complex-valued so/ution of (1). Then, 
both y(t) and z(t) are rea/-valued so/utions of (1). 
</p>
<p>PROOF. If x(t)=y(t)+ iz(t) is a complex-valued solution of (1), then 
</p>
<p>y( t) + iz( t) = A(y( t) + iz( t)) = Ay( t) + iAz( t). (2) 
</p>
<p>Equating real and imaginary parts of (2) gives y( t) = Ay( t) and i:( t) = Az( t). 
Consequently, both y(t)=Re{x(t)} and z(t)=Im{x(t)} are real-va1ued 
</p>
<p>solutions of (1). 0 
</p>
<p>The complex-valued function x( t) = e&lt;a + i&szlig;)t (v1 + iv2) can be written in 
the form 
</p>
<p>x(t) = ea1 (cos&szlig;t+ isin&szlig;t)(v1 + iv2) 
</p>
<p>= ea1 [ (v1 cos&szlig;t- v2 sin&szlig;t) + i(v1 sin&szlig;t +v2 cos&szlig;t)]. 
</p>
<p>341 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>Hence, if A = a + i&szlig; is an eigenvalue of A with eigenvector v = v1 + iv2, then 
</p>
<p>y(t) = ea1 (v1 cos&szlig;t -v2 sin&szlig;t) 
</p>
<p>and 
</p>
<p>z( t) = ea1 (v1 sin&szlig;t + v2 cos &szlig;t) 
</p>
<p>are two real-valued solutions of (1). Moreover, these two solutions must be 
linearly independent (see Exercise 10). 
</p>
<p>Example 1. Solve the initial-value problern 
</p>
<p>0 
I 
I 
</p>
<p>x(O)- m 
Solution. The characteristic polynomial of the matrix 
</p>
<p>IS 
</p>
<p>0 
1 
1 
</p>
<p>p(A.)=det(A-A.I)=det[ 
1 ;A 1 ~A ~1 l 
</p>
<p>0 1 1-A. 
</p>
<p>= (1- A.)3 + (1-A.) = (1-A.)(A.2 - 2A.+2). 
</p>
<p>Hence the eigenva1ues of A are 
</p>
<p>A. = 1 and A. = 2 &plusmn; V4=8 = 1 &plusmn; i. 
2 
</p>
<p>(i) A. = I: Clearly, 
</p>
<p>is an eigenvector of A with eigenvalue 1. Hence 
</p>
<p>x'(t)-e' [g] 
is one solution of the differential equation :X= Ax. 
</p>
<p>(ii) A.= 1 + i: We seek a nonzero vector v suchthat 
</p>
<p>[A-(l+i)l]v- [ -~ 
</p>
<p>342 
</p>
<p>0 
-i 
</p>
<p>1 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.9 Complex roots 
</p>
<p>This implies that - iv1 = 0, - iv2 - v3 = 0, and v 2 - iv3 = 0. The first equa-
tion says that v1 = 0 and the second and third equations both say that v2 = 
iv3&bull; Consequently, each vector 
</p>
<p>is an eigenvector of A with eigenvalue 1 + i. Thus, 
</p>
<p>x(t)- &bull;'' &bull;&bull;&gt;&bull; [1] 
is a complex-valued solution of the differential equation x = Ax. Now, 
</p>
<p>e0 &bull;''' [! ]- e' (cost+ isint)[ [ ?] + i [! l] 
-e'[ COSI m -sinl m + isinl m +icost m l 
</p>
<p>[ 
0 
</p>
<p>I . =e -smt 
cost l + ie 1 [ c;s t]. smt 
</p>
<p>Consequently, by Lemma 1, 
</p>
<p>are real-valued solutions. The three solutions x1(t), x2(t), and x3(t) are lin-
early independent since their initial values 
</p>
<p>x'(o)- [H 
are linearly independent vectors in R3&bull; Therefore, the solution x(t) of our 
initial-value problern must have the form 
</p>
<p>Setting t = 0, we see that 
</p>
<p>[ :J- c. [ ~ J + c, m + c, m -[ ~: J&middot; 
343 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>Consequently c1 = c2 = c3 = I and 
</p>
<p>x(t)= e' [6] + e' [- s~nt ] +e' [c~st] 
0 cost smt 
</p>
<p>= e 1 [ cos t ~ s~n t ]&middot; 
cost+smt 
</p>
<p>Remark. If v is an eigenvector of A with eigenvalue A,_!hen v, the complex 
conjugate of v, is an eigenvector of A with eigenvalue A. (Each component 
of v is the complex conjugate of the corresponding component of v.) To 
prove this, we take complex conjugates of both sides of the equation Av = 
Av and observe that the complex conjugate of the vector Av is Av if A is 
real. f!ence, Av=~v, which shows that v is an eigenvector of A with eigen-
vatue A. 
</p>
<p>EXERCISES 
</p>
<p>In each of Problems 1-4 find the general solution of the given system of 
differential equations. 
</p>
<p>1. x=(=:~ 2)x 2. x=(i 
-5 
</p>
<p>~)x -3 -1 0 
</p>
<p>3. x={i 
0 
</p>
<p>-nx 4. x= ( 6 
0 -qx 1 1 2 -2 0 -1 
</p>
<p>In each of Problems 5-8, solve the given initial-value problem. 
</p>
<p>s. x=U -1) -3 X, x(o)=U) 6. x=(! =:i)x, x(O)= { ~) 
</p>
<p>( -3 0 g )x, x(O)= ( =D 7. x= 1 -1 -2 -1 
8 +~ 
</p>
<p>2 0 
-~]~ ~0)- [1] 0 0 &bull; X 0 0 0 
</p>
<p>0 0 3 
</p>
<p>9. Determine all vectors x0 such that the solution of the initia1-value problern 
</p>
<p>x=(~ ~ -~)x, 
-1 -1 
</p>
<p>x(O)=x0 
</p>
<p>is a periodic function of time. 
</p>
<p>344 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.10 Equal roots 
</p>
<p>10. Let x(t)=eAiv be a solution of x=Ax. Prove that y(t)=Re{x(t)} and z(t)= 
lm{x(t)} are linearly independent. Hint: Observe that v and v are linearly inde-
pendent in cn since they are eigenvectors of A with distinct eigenvalues. 
</p>
<p>3.10 Equal roots 
</p>
<p>If the characteristic polynomial of A does not have n distinct roots, then A 
may not have n linearly independent eigenvectors. For example, the matrix 
</p>
<p>has only two distinct eigenvalues ;\1 = I and ;\2 = 2 and two linearly inde-
pendent eigenvectors, which we take to be 
</p>
<p>Consequently, the differential equation x = Ax has only 9"0 linearly inde-
pendent solutions 
</p>
<p>e' [~] and e" [~] 
of the form eAiv. Our problem, in this case, is to find a third linearly inde-
pendent solution. More generally, suppose that the n X n matrix A has only 
k &lt; n linearly independent eigenvectors. Then, the differential equation 
x = Ax has only k linearly independent solutions of the form eAiv. Our 
problern is to find an additional n- k linearly independent solutions. 
</p>
<p>We approach this problern in the following ingenious manner. Recall 
that x( t) = e 01c is a solution of the scalar differential equation .X= ax, for 
every constant c. Analogously, we would like to say that x{t) = eA1v is a 
solution of the vector differential equation 
</p>
<p>x=Ax (I) 
</p>
<p>for every constant vector v. However, eA1 is not defined if A is an n X n 
matrix. This is not a serious difficulty, though. There is a very natural way 
of defining eA1 so that it resembles the scalar exponential e01 ; simply set 
</p>
<p>(2) 
</p>
<p>It can be shown that the infinite series (2) converges for all t, and can be 
</p>
<p>345 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>differentiated term by term. In particular 
</p>
<p>d At 2 An+l n 
-de =A+At+ ... +-1-t + ... t n. 
</p>
<p>[ Antn ] =A l+At+ ... +----;;! + ... =AeA1&bull; 
</p>
<p>This implies that eA1v is a solution of (1) for every constant vector v, since 
</p>
<p>; eAtv = AeAtv = A( eArv). 
</p>
<p>Remark. The matrix exponential eA1 and the sca1ar exponentia1 ea1 satisfy 
many similar properties. For examp1e, 
</p>
<p>(eAtfi=e-At and eA(t+s&gt;=eAteAs. (3) 
</p>
<p>Indeed, the same proofs which show that (ea1)- 1=e-a1 and ea(t+s&gt;=eateas 
can be used to estab1ish the identities (3): we need on1y rep1ace every a by 
A and every 1 by I. However, eAt+Bt equa1s eA1e81 only if AB= BA (see Ex-
ercise 15, Section 3.11). 
</p>
<p>There are severa1 classes of matrices A (see Problems 9-11) for which 
the infinite series (2) can be summed exactly. In genera1, though, it does 
not seem possible to express eA1 in closed form. Yet, the remarkable fact is 
that we can always find n linearly independent vectors v for which the in-
finite series eA1v can be summed exactly. Moreover, once we know n lin-
early independent solutions of (1), we can even compute eA1 exactly. (This 
latter property will be proven in the next section.) 
</p>
<p>We now show how to find n linearly independent vectors v for which 
the infinite series eA1v can be summed exactly. Observe that 
</p>
<p>for any constant ;&gt;.., since (A- ;\1)(;\I) = (;\I)(A- M). Moreover, 
</p>
<p>Hence, eA1v= e;ve&lt;A-~l) 1 v. 
Next, we make the crucial observation that if v satisfies (A- ;\I)mv = 0 
</p>
<p>for some integer m, then the infinite series e&lt;A-~I&gt;tv terminates after m 
terms. If (A-AI)mv=O, then (A-;\Ir+ 1v is also zero, for every positive in-
teger I, since 
</p>
<p>346 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.10 Equal roots 
</p>
<p>Consequently, 
m-1 
</p>
<p>e&lt;A-AI)tv=v+t{A-;\I)v+ ... + t {A-;\I)m- 1v 
(m-1)! 
</p>
<p>and 
</p>
<p>[ 
tm-1 ] 
</p>
<p>=e&gt;.t v+t{A-;\I)v+ ... + ( )' {A-;\I)m- 1v . 
m~l. 
</p>
<p>This suggests the following algorithm for finding n linearly independent 
solutions of (1). 
</p>
<p>(I) Findall the eigenvalues and eigenvectors of A. If A has n linearly in-
dependent eigenvectors, then the differential equation x = Ax has n linearly 
independent solutions of the form e&gt;.tv. (Observe that the infinite series 
e&lt;A-;&gt;..I)tv terminates after one term if v is an eigenvector of A with eigen-
vatue ;\.) 
</p>
<p>(2) Suppose that A has only k &lt; n linearly independent eigenvectors. 
Then, we have only k linearly independent solutions of the form e&gt;.tv. To 
find additional solutions we pick an eigenvalue ;\ of A and find all vectors 
v for which (A-;\Ifv=O, but (A-;\I)V7~'o. Foreach such vector v 
</p>
<p>eA1v= e;&gt;.,1e&lt;A-M)tv= e;&gt;.,1[ v + t(A- ;\l)v] 
</p>
<p>is an additional solution of x = Ax. We do this for all the eigenvalues ;\ of 
A. 
</p>
<p>(3) If we still do not have enough solutions, then we find all vectors v 
for which (A-;\1)3v=O, but (A-;\1)2v*O. Foreach such vector v, 
</p>
<p>eA1v = e;&gt;.,1[ v + t(A- ;\l)v+ ~~ (A- ;\1)2v J 
</p>
<p>is an additional solution of x = Ax. 
(4) We keep proceeding in this manner until, hopefully, we obtain n lin-
</p>
<p>early independent solutions. 
The following Iemma from linear algebra, which we accept without 
</p>
<p>proof, guarantees that this algorithm always works. Moreover, it puts an 
upper bound on the number of steps we have to perform in this algorithm. 
</p>
<p>Lemma 1. Let the characteristic polynomial of A have k distinct roots 
;\1, &bull;&bull;&bull; ,;\k with multiplicities n 1, &bull;&bull;&bull; ,nk respectively. (This means that p(;\) 
can be factared into the form (;\1 -At' ... (;\k- ;\)"".) Suppose that A has 
only P_j &lt;f1:i linearly independent eigenvectors with eigenvalue \&middot; Then the 
equation (A-\Ifv=O has at least v1+ I independent solutions. More 
generally, if the equation (A- ;\}rv = 0 has only m1 &lt; n1 independent 
solutions, then the equation (A-;\})m+tv=O has at least m1+I indepen-
dent solutions. 
</p>
<p>347 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>Lemma I clearly implies that there exists an integer ~ with ~ &lt; np such 
that the equation (A- X})'~v = 0 has at least n1 linearly independent solu-
tions. Thus, for each eigenvalue X1 of A, we can compute n1 linearly inde-
pendent solutions of x = Ax. All these solutions have the form 
</p>
<p>[ 
t4-l d 1 l x(t)=e&gt;..Jr v+t(A-X})v+ ... + ( (A-X}r- v . 
~-I)! 
</p>
<p>In addition, it can be shown that the set of n1 + ... + nk = n solutions thus 
obtained must be linearly independent. 
</p>
<p>Exampie 1. Find three linearly independent solutions of the differential 
equation 
</p>
<p>&bull;=[g i ~]&middot; 
Solution. The characteristic polynomial of the matrix 
</p>
<p>A= [g 
I 
1 
0 ~] 
</p>
<p>is ( 1 - Xi(2- X). Hence X= 1 is an eigenvalue of A with multiplicity two, 
and X= 2 is an eigenvalue of A with multiplicity one. 
</p>
<p>(i) X= I: We seek all nonzero vectors v such that &middot; 
</p>
<p>(A-I)v= [~ 
1 
0 
0 
</p>
<p>This implies that v2 = v3 = 0, and v 1 is arbitrary. Consequently, 
</p>
<p>x'(t)=e' [g] 
is one solution of x = Ax. Since A has only one linearly independent eigen-
vector with eigenvalue 1, we Iook for all solutions of the equation 
</p>
<p>2 [0 (A-1) v= ~ I 0 
0 
</p>
<p>I 
0 
0 
</p>
<p>0 
0 
0 
</p>
<p>This implies that v3 = 0 and both v 1 and v2 are arbitrary. N ow, the vector 
</p>
<p>&bull;= [!] 
348 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.10 Equal roots 
</p>
<p>satisfies (A- Iiv = 0, but (A- I)v * 0. (We could just as weil choose any 
</p>
<p>for which v2*0.) Hence, 
</p>
<p>x2(1) ~ e" [!] ~ e 'e'A-0' [ r l 
~e'[I+t(A-1)][!] ~e'[ [!] +t[~ g mm 
</p>
<p>is a second linearly independent solution. 
(ii) f-=2: We seek a nonzero vector v suchthat 
</p>
<p>[
-1 
</p>
<p>(A-2I)v= ~ 
</p>
<p>This implies that v1 = v2 = 0 and v3 is arbitrary. Hence 
</p>
<p>x 3 (t)~e" [~] 
is a third linearly independent solution. 
</p>
<p>Example 2. Solve the initial-value problern 
</p>
<p>1 
2 
0 -!]&middot;&middot; 
</p>
<p>Solution. The characteristic polynomial of the matrix 
</p>
<p>1 
</p>
<p>2 
0 
-!] 
</p>
<p>is (2- f-)3. Hence A = 2 is an eigenvalue of A with multiplicity three. The ei-
genvectors of A satisfy the equation 
</p>
<p>(A-2I)v~ [~ 
1 
0 
0 
</p>
<p>349 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>This implies that v2 = v3 = 0 and v1 is arbitrary. Hence 
</p>
<p>is one solution of x = Ax. 
Since A has only one linearly independent eigenvector we look for all 
</p>
<p>solutions of the equation 
</p>
<p>(A-21)2v- [~ 
1 
0 
0 
</p>
<p>1 
0 
0 -!]&middot;- [~ 
</p>
<p>0 
0 
0 
</p>
<p>-1] [VI] [0] 0 V2 = 0 . 
0 V3 0 
</p>
<p>This implies that v3 =0 and both v1 and v2 are arbitrary. Now, the vector 
</p>
<p>v= [!] 
satisfies (A- 2Iiv = 0, but (A- 2I)v ~ 0. Hence 
</p>
<p>x2(1)- e" [! ]- e"e&lt;&bull;-m&bull; [!] 
= e"[l+ I(A-21)] [!] =e"[ I+ I[~ 
</p>
<p>= &bull;"[ [! l + 1 [ ~ l] = e'' [ i j 
is a second solution of x = Ax. 
</p>
<p>I 
0 
0 -!]][!] 
</p>
<p>Since the equation (A- 21)2v = 0 has only two linearly independent solu-
tions, we look for all solutions of the equation 
</p>
<p>(A- 2I)'v= [ ~ 
1 
0 
0 
</p>
<p>Obviously, every vector v is a solution of this equation. The vector 
</p>
<p>350 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.10 Equal roots 
</p>
<p>does not satisfy (A- 2Iiv=O. Hence 
</p>
<p>x'( t) ~ e" [ ~ ]- ,u,&lt;&gt;-n&gt;&bull; m 
~e"[I+I(A-21)+ 1; (A-2I)'l[~] 
</p>
<p>is a third linearly independent solution. Therefore, 
</p>
<p>The constants c1, c2, and c3 are determined from the initial conditions 
</p>
<p>l ~ 1 ~ , . m + ,, l! 1 + ,, m &middot; 
This implies that c1 =I, c2 =2, and c3 = 1. Hence 
</p>
<p>x(t) ~ e" [I+~~~ jt']&middot; 
</p>
<p>For the matrix A in Exampie 2,p(;\)=(2-;\)3 and (21-A)3 =0. This is 
not an accident. Every matrix A satisfies its own characteristic equation. 
This is the content of the following theorem. 
</p>
<p>Theorem 13 (Cayley-Harnilton). Let p (;\)=Po+ p 1;\ + ... + (- I t;\ n be the 
characteristic polynomial of A. Then, 
</p>
<p>p(A)=p01+p1A+ ... +( -I)nAn=O. 
</p>
<p>FAKE PROOF. Setting ;\=A in the equationp(;\)=det(A-M) givesp(A)= 
det(A-AI)=detO=O. The fallacy in this proof isthat we cannot set ;\=A 
in the expression det(A- M) since we cannot subtract a matrix from the di-
agonal elements of A. However, there is a very clever way to make this 
proof kosher. Let C(;\) be the classical adjoint (see Section 3.6) of the 
matrix (A-M). Then, 
</p>
<p>(A- ;\I)C(;\) = p(;\)1. (4) 
</p>
<p>351 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>Each element of the matrix C(A) is a polynomial in A of degree at most 
(n -1). Therefore, we can write C(A) in the form 
</p>
<p>C(A)=C0 +C1A+ ... +Cn_ 1An-l 
</p>
<p>where C0, &bull;&bull;&bull; , Cn-l are n X n matrices. For example, 
</p>
<p>(A+A2 
A2 
</p>
<p>2A ) (0 
1-A = 0 ~)+(~ 2A )+(A
</p>
<p>2 
-A A2 ~) 
</p>
<p>=(~ ~)+A(b 2)+A2{I -1 l ~). 
Thus, Equation (4) can be written in the form 
</p>
<p>(A-Al)[ Co+C1A+ ... +Cn-IAn-l) =pJ+p1AI+ ... +( -1)nAnl. (5) 
</p>
<p>Observe that both sides of (5) are polynomials in A, whose coefficients are 
n X n matrices. Since these two polynomials are equal for all values of A, 
their coefficients must agree. But if the coefficients of like powers of A 
agree, then we can put in anything we want for A and still have equality. In 
particular, set A = A. Then, 
</p>
<p>p(A)=p0l+p 1A+ ... +( -l)nAn 
</p>
<p>=(A-AI)[Co+CIA+ ... +Cn-IAn-l) =0. 0 
</p>
<p>EXERCISES 
</p>
<p>In each of Problems 1-4 find the generat solution of the given system of 
differential equations. 
</p>
<p>1. x=O 
-1 
-3 
-1 
</p>
<p>(
-I 
</p>
<p>3. x= g 
-1 
-1 
</p>
<p>0 
</p>
<p>[
2 0 
</p>
<p>. 0 2 
4. x= 0 0 
</p>
<p>0 0 
</p>
<p>~ )x 
-1 
</p>
<p>( 
I 1 
</p>
<p>2. x= 2 1 
-3 2 
</p>
<p>g )x Hint: Look at Example I of text. 
-2 
</p>
<p>In each of Problems 5-8, solve the given initial-value problern 
</p>
<p>5. x=( :::~ i)x, x(0)=(6) 6. x=( lci -~ ?)x, x(O)=( i) 
-2 3 1 -4 -3 1 -1 
</p>
<p>'&middot; &bull;=(! J -D~ x(O)=(g) ax= [~ ~ ~ ~]&middot;&middot; &bull;&lt;Ol= [!] 
352 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.10 Equal roots 
</p>
<p>9. Let 
</p>
<p>AI 0 0 
0 A2 0 
</p>
<p>A= 
</p>
<p>0 0 An 
</p>
<p>Show that 
</p>
<p>r~&middot;&middot; 
0 
</p>
<p>Jl e&gt;..2t eAt= &bull; 0 0 
10. Let 
</p>
<p>A=(g 
I 
</p>
<p>rl&middot; A 0 
Prove that 
</p>
<p>eN~,&middot; [~ jt'] I t . 
0 I 
</p>
<p>Hint: Write A in the form 
</p>
<p>A=AI+(g 
I 
</p>
<p>!) 0 0 
and observe that 
</p>
<p>,~ ~ ."oxp[ ( g I !)~] 0 
0 
</p>
<p>11. Let A be the n X n matrix 
</p>
<p>A I 0 0 
0 A I 0 
</p>
<p>0 0 0 I 
0 0 0 A 
</p>
<p>and Iet P be the n X n matrix 
</p>
<p>0 I 0 0 
0 0 I 0 
</p>
<p>0 0 0 I 
0 0 0 0 
</p>
<p>353 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>(a) Show that pn=O. 
(c) Show that 
</p>
<p>(b) Show that (;\I)P=P(;\1). 
</p>
<p>eAt=e&gt;..t[l+tP+ pp2 + +~pn-1] 
2! ... (n-1)! &middot; 
</p>
<p>12. Compute eA1 if 
</p>
<p>[2 I 0 n (a) A= 0 2 I 0 0 2 0 0 0 
~) A~ [~ 
</p>
<p>I 0 
</p>
<p>n 2 I 0 2 0 0 
13. (a) Show that er'AT =T- 1eAT. 
</p>
<p>(b) Given that 
</p>
<p>with 
</p>
<p>T=U 
</p>
<p>compute eA1&bull; 
</p>
<p>(o) A~ [~ 
I 0 
</p>
<p>n 2 0 0 2 0 0 
</p>
<p>= ~ - ~ )&middot; 
2 3 
</p>
<p>14. Suppose thatp(A)=det(A-Al) has n distinct roots A1, ... ,An. Prove directly that 
p(A):=(-It(A-;\11) ... (A-;\ni)=O. Hint: Write any vector x in the form x= 
x 1 v1 + ... + xn v" where v1, ... , vn are n independent eigenvectors of A with eigen-
values ;\1, ... ,A" respectively, and conclude thatp(A)x=O for all vectors x. 
</p>
<p>15. Suppose that A2 = aA. Find eA1&bull; 
</p>
<p>16. Let 
</p>
<p>A= 
</p>
<p>(a) Show that A(A-51)=0. 
(b) Find eA1&bull; 
</p>
<p>17. Let 
</p>
<p>(a) Show that A2 = -I. 
</p>
<p>354 
</p>
<p>A=(-~ 6)&middot; </p>
<p/>
</div>
<div class="page"><p/>
<p>3.11 Fundamental matrix so1utions; eA1 
</p>
<p>(b) Show that 
</p>
<p>eAI=( C?SI sint). 
-smt cost 
</p>
<p>In each of Problems 18-20 verify directly the Cayley-Hamilton Theorem 
for the given matrix A. 
</p>
<p>18. A=( ~ 
-1 
</p>
<p>-1 
1 
</p>
<p>-1 
</p>
<p>-1) (2 3 -1 19. A= 2 3 
I 2 3 
</p>
<p>1) (-1 0 1) 1 20. A= -I 3 0 
1 2 4 6 
</p>
<p>3.11 Fundamental matrix solutions; eA1 
</p>
<p>If x 1( t), . .. , xn ( t) are n linearly independent solutions of the differential 
equation 
</p>
<p>x=Ax, 
</p>
<p>then every solution x(t) can be written in the form 
</p>
<p>x(t)= c1x1(t)+ c2x2(t)+ ... + cnxn(t). 
</p>
<p>(1) 
</p>
<p>(2) 
</p>
<p>Let X(t) be the matrix whose columns are x1(t), ... ,xn(t). Then, Equation 
(2) can be written in the concise form x(t)=X(t)c, where 
</p>
<p>Definition. A matrix X(t) is called afundamental matrix solution of (1) if its 
columns form a set of n linearly independent solutions of (1). 
</p>
<p>Example 1. Find a fundamental matrix solution of the system of differen-
tial equations 
</p>
<p>-~ -1]x. 
I -1 
</p>
<p>Solution. We showed in Section 3.8 (see Example I) that 
</p>
<p>e''[~] and ,-fll 
are three linearly independent solutions of (3). Hence 
</p>
<p>is a fundamental matrix solution of (3). 
</p>
<p>-e -21] 
e -21 
e-21 
</p>
<p>(3) 
</p>
<p>355 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>In this section we will show that the matrix eA1 can be computed di-
rectly from any fundamental matrix solution of (1). This is rather remark-
able since it does not appear possib1e to sum the infinite series [I+ At+ 
(At)2 /2! + ... ] exactly, for an arbitrary matrix A. Specifically, we have the 
following theorem. 
</p>
<p>Theorem 14. Let X(t) be a fundamental matrix solution of the differential 
equation x = Ax. Then, 
</p>
<p>(4) 
</p>
<p>In other words, the product of any fundamental matrix solution of (1) with 
its inverse at t = 0 must yield eA1&bull; 
</p>
<p>We prove Theorem 14 in three steps. First, we establish a simple test to 
determine whether a matrix-valued function is a fundamental matrix solu-
tion of (1). Then, we use this test to show that eA1 is a fundamental matrix 
solution of (1). Finally, we establish a connection between any two funda-
mental matrix solutions of (1). 
</p>
<p>Lemma 1. A matrix X(t) isafundamental matrix solution of (1) if, and only 
if, X(t)=AX(t) and detX(O)~O. (The derivative of a matrix-valuedfunc-
tion X(t) is the matrix whose components are the derivatives of the corre-
sponding components of X(t).) 
</p>
<p>PROOF. Let x 1(t), ... ,xn(t) denote the n columns of X(t). Observe that 
</p>
<p>X( t) = (x1(t), ... ,xn(t)) 
</p>
<p>and 
</p>
<p>AX(t) = (Ax1(t), ... ,Axn(t)). 
</p>
<p>Hence, the n vector equations x 1( t) = Ax \ t), ... , xn ( t) = Axn ( t) are equiv-
alent to the single matrix equation X(t) = AX(t). Moreover, n solutions 
x1(t), ... ,xn(t) of (1) are linearly independent if, and only if, x\O), ... ,xn(O) 
are linearly independent vectors of Rn. These vectors, in turn, are linearly 
independent if, and only if, detX(O)~O. Consequently, X(t) is a fundamen-
tal matrix solution of (1) if, and only if, X(t)=AX(t) and detX(O)~O. 0 
</p>
<p>Lemma 2. The matrix-valued func:ion eA1 =I+ At+ A2t 2 /2! + ... is a 
fundamental matrix solution of ( 1 ). 
</p>
<p>PROOF. We showed in Section 3.10 that (d/dt)eA1 =AeA1&bull; Hence eA1 is a 
solution of the matrixdifferential equation X(t)=AX(t). Moreover, its de-
terminant, evaluated at t=O, is one since eA0 =1. Therefore, by Lemma 1, 
eA1 isafundamental matrix solution of (1). 0 
</p>
<p>Lemma 3. Let X(t) and Y(t) be two fundamental matrix solutions of (1). 
Then, there exists a constant matrix C such that Y(t) = X(t)C. 
</p>
<p>356 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.11 Fundamentalmatrix solutions; eA' 
</p>
<p>PROOF. By definition, the columns x 1(t}, ... ,xn(t) of X(t) and y1(t}, ... , 
yn(t) of Y(t) are linearly independent sets of solutions of (1). In particular, 
therefore, each column of Y(t) can be written as a linear combination of 
the columns of X(t); i.e., there exist constants c{, ... ,c~ suchthat 
</p>
<p>yj(t)=c{x 1 (t)+c~x 2 (t)+ ... +c~xn(t), j=l, ... ,n. (5) 
</p>
<p>Let C be the matrix (cl,c2, &bull;&bull;&bull; ,c") where 
</p>
<p>Then, the n equations (5) are equivalent to the single matrix equation Y(t) 
=X(t)C. 0 
</p>
<p>We are now in a position to prove Theorem 14. 
</p>
<p>PRooF OF THEOREM 14. Let X(t) be a fundamental matrix solution of (1). 
Then, by Lemmas 2 and 3 there exists a constant matrix C such that 
</p>
<p>eA' =X( t)C. (6) 
</p>
<p>Setting t=O in (6) gives I=X(O}C, which implies that C=X- 1(0). Hence, 
eA'=X(t)X- 1(0). 0 
</p>
<p>Example 1. Find eA' if 
</p>
<p>1 
3 
0 
</p>
<p>Solution. Our first step is to find 3 linearly independent solutions of the 
differential equation 
</p>
<p>To this end we compute 
</p>
<p>[ 
1-X 
</p>
<p>p(X)= det(A -XI) =det ~ 
1 
</p>
<p>3-X 
0 
</p>
<p>i l =(l-X)(3-X)(5-X). 
5-X 
</p>
<p>Thus, A has 3 distinct eigenvalues X= 1, X= 3, and X= 5. 
(i) X= 1: Clearly, 
</p>
<p>357 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>is an eigenvector of A with eigenvalue one. Hence 
</p>
<p>x'(t)-e' [~] 
is one solution of x = Ax. 
</p>
<p>(ii) ).. = 3: We seek a nonzero solution of the equation 
</p>
<p>[
-2 
</p>
<p>(A-3I)v= ~ 
</p>
<p>This implies that v3 =0 and v2 =2v 1&bull; Hence, 
</p>
<p>is an eigenvector of A with eigenvalue 3. Consequently, 
</p>
<p>x1(t)-e3' [i] 
is a second solution of x = Ax. 
</p>
<p>(iii) &gt;-.=5: We seek a nonzero solution of the equation 
</p>
<p>[ 
-4 
</p>
<p>(A-5I)v= ~ 
</p>
<p>This implies that v2 = v3 and v 1 = v3/2. Hence, 
</p>
<p>is an eigenvector of A with eigenvalue 5. Consequently, 
</p>
<p>x3(1)-e" m 
is a third solution of x = Ax. These solutions are clearly linearly indepen-
dent. Therefore, 
</p>
<p>[
e 1 
</p>
<p>X(t)= ~ 
</p>
<p>is a fundamental matrix solution. Using the methods of Section 3.6, we 
</p>
<p>358 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.11 Fundamental matrix solutions; eA1 
</p>
<p>compute 
</p>
<p>I I 0 
</p>
<p>x-'(O)~[~ 
I 
</p>
<p>~r 
-2 
</p>
<p>2 = 0 I I 2 -2 
0 
</p>
<p>0 0 I 2 
</p>
<p>Therefore, 
</p>
<p>''W 
</p>
<p>I 0 
</p>
<p>exp[ [~ 
I 
</p>
<p>~ll[~ 
e3' 
</p>
<p>2:51 0 
</p>
<p>-2 
</p>
<p>3 2e3' 
I I 
2 -2 
</p>
<p>0 0 2e5' 0 0 I 2 
</p>
<p>e' _ .!e' + .!e3' 
- '&bull;'' + '&bull;"] 2 2 2 2 
</p>
<p>0 e3' _ e3' +es' . 
</p>
<p>0 0 es' 
</p>
<p>EXERCISES 
</p>
<p>Compute eA1 for A equal 
</p>
<p>1. ( ~ 
-I -q 2. u l -]) 3. 0 0 D 3 3 -4 0 -3 I -I I -4 -2 
</p>
<p>4. 0 0 -n 5. (-r 2 - ~) 6. 0 I -D I -3 I 2 1 -1 -1 
7. Find A if 
</p>
<p>[ 2e"-e' e2t_ e' e'-e''] eA'= e2t_ e' 2e21 - e 1 e'-e2t . 
3e2'-3e' 3e21 - 3e' 3e'- 2e21 
</p>
<p>In each of Problems 8-11, determine whether the given matrix is a funda-
mental matrix solution of x=Ax, for some A; if yes, find A. 
</p>
<p>[ 
e' 
</p>
<p>8. e 1 
</p>
<p>2e 1 
</p>
<p>[ 
-5cos2t 
</p>
<p>9. -2(cos2t+sin2t) 
</p>
<p>cos2t 
</p>
<p>-5sin2t 
2( cos 2t- sin2t) 
</p>
<p>sin2t 
</p>
<p>359 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>10. e' [: 
t+ I 
</p>
<p>2(t+ l) 
t+2 
</p>
<p>11. [;:: 
</p>
<p>3e 1 
</p>
<p>12. Let q,i(t) be the solution of the initial-value problern i=Ax, x(O)=ei. Show 
that eAt =(&lt;PI ,cp2, ... ,q,n). 
</p>
<p>13. Suppose that Y(t)=X(t)C, where X(t) and Y(t) are fundamental matrix solu-
tions of i=Ax, and Cis a constant matrix. Prove that detC;=O. 
</p>
<p>14. Let X(t) be a fundamental matrix solution of (1), and Ca constant rnatrix with 
detC7=0. Show that Y(t)=X(t)C is again a fundamental matrix solution of (1). 
</p>
<p>15. Let X(t) be a fundamental matrix solution of i=Ax. Prove that the solution 
x(t) of the initial-value problern i=Ax, x(t0)=x0 is x(t)=X(t)X- 1(t0)x0&bull; 
</p>
<p>16. Let X( t) be a fundamental matrix solution of i = Ax. Prove that X( t)X- 1( t0) = 
eA&lt;t-to'J. 
</p>
<p>17. Hereis an elegant proof of the identity eAt+Bt = eA1e81 if AB=BA. 
(a) Show that X(t) = eAt+Bt satisfies the initial-value problern X= (A + B)X, 
</p>
<p>X(O)=I. 
(b) Show that eA1B=BeA1 if AB=BA. (Hint: AiB=BAi if AB=BA). Then, 
</p>
<p>conclude that ( d / dt)eA1e81 = (A + B)eA1e81 &bull; 
(c) lt follows immediately from Theorem 4, Section 3.4 that the solution X(t) 
</p>
<p>of the initial-value problern X= (A + B)X, X(O) =I, is unique. Conclude, 
therefore, that eAt+Bt = eA1e81&bull; 
</p>
<p>3.12 The nonhomogeneous equation; 
variation of parameters 
</p>
<p>Consider now the nonhomogeneaus equation i = Ax + f( t). In this case, we 
can use our knowledge of the solutions of the homogeneaus equation 
</p>
<p>x=Ax (1) 
</p>
<p>to help us find the solution of the initial-value problern 
</p>
<p>x=Ax+f(t), (2) 
</p>
<p>Let x 1(t), ... ,xn(t) be n linearly independent solutions of the homogeneaus 
equation (1). Since the general solution of (1) is c1x1(t)+ ... + cnxn(t), it is 
natural to seek a solution of (2) of the form 
</p>
<p>(3) 
</p>
<p>This equation can be written concisely in the form x( t) =X( t)u( t) where 
</p>
<p>360 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.12 The nonhomogeneous equation; variation of parameters 
</p>
<p>X(t)=(x1(t), ... ,xn(t)) and 
</p>
<p>u(t)= 
</p>
<p>u,.( t) 
</p>
<p>Plugging this expression into the differential equation x = Ax + f( t) gives 
</p>
<p>X( t)u( t) +X( t)ti( t) = AX( t)u( t) + f( t). (4) 
</p>
<p>The matrix X(t) is a fundamental matrix solution of (1). Hence, X(t)= 
AX(t), and Equation (4) reduces to 
</p>
<p>X( t)ti( t) = f( t). (5) 
</p>
<p>Recall that the columns of X(t) are linearly independent vectors of Rn at 
every timet. Hence x- 1(t) exists, and 
</p>
<p>ti( t) =X - 1( t)f(t). (6) 
</p>
<p>Integrating this expression between t0 and t gives 
</p>
<p>u( t) = u(t0) + j 1X- 1(s)f(s)ds 
to 
</p>
<p>=X- 1(t0)x0 + {x- 1(s)f(s)ds. 
to 
</p>
<p>Consequently, 
</p>
<p>x( t) =X( t)X- 1( t0)x0 + X(t) j 1X- 1(s)f(s)ds. 
to 
</p>
<p>(7) 
</p>
<p>If X(t) is the fundamental matrix solution eA1, then Equation (7) sim-
plifies considerably. To wit, if X(t) = eA1, then x- 1(s) = e -As. Hence 
</p>
<p>x(t) = eAte-Atoxo + eAt Jte-Asf(s)ds 
to 
</p>
<p>= eA(t-to)xO+ JteA(t-s)f(s)ds. 
to 
</p>
<p>Example 1. Solve the initial-value problern 
</p>
<p>0 
1 
2 
</p>
<p>0] [ 0 l -2 x+ 0 , 
1 e 1 cos2t 
</p>
<p>x(O)- [:J. 
</p>
<p>(8) 
</p>
<p>361 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>Solution. We firstfind eA1, where 
</p>
<p>To this end compute 
</p>
<p>[ 
1-A. 
</p>
<p>det(A- A.I) = det ; 
</p>
<p>Thus the eigenvalues of A are 
</p>
<p>0 
1-A. 
</p>
<p>2 
</p>
<p>0 
1 
2 -n 
</p>
<p>~2] =(1-A.)(A.2 -2A.+5). 
1-A. 
</p>
<p>A.=1 and A.= 2 &plusmn;V4"=20 =1&plusmn;2i. 
2 
</p>
<p>(i) A. = 1: We seek a nonzero vector v such that 
</p>
<p>(A-l)v~ [~ 
0 
0 
2 
</p>
<p>This implies that v1 = v3 and v2 = - 3v 1/2. Hence 
</p>
<p>is an eigenvector of A with eigenvalue 1. Consequently, 
</p>
<p>is a solution of the homogeneaus equation x = Ax. 
(ii) A.= 1 +2i: We seek a nonzero vector v suchthat 
</p>
<p>[ 
-2i 
</p>
<p>[A-(1+2i)I]v= ~ 
0 
</p>
<p>-2i 
2 
</p>
<p>This implies that v1 = 0 and v3 = - iv2 &bull; Hence, 
</p>
<p>is an eigenvector of A with eigenvalue 1 + 2i. Therefore, 
</p>
<p>362 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.12 The nonhornogeneous equation; variation of pararneters 
</p>
<p>is a complex-valued Solution of x=Ax. Now, 
</p>
<p>[ ~ ~ ]eo+&gt;&bull;&gt;&bull; ~ e' (cos2t+ isin2t)[ [!] ~ i [ ~ l] 
</p>
<p>- &middot;&middot;[ cos2t [! l + sin2t m l 
+ ie'[ sin2t [! l ~cos2t m l 
</p>
<p>Consequently, 
</p>
<p>and x\t)=e 1 [ s~n2tl 
-cos2t 
</p>
<p>are real-valued solutions of x = Ax. The solutions x 1, x2, and x3 are linearly 
independent since their values at t = 0 are clearly linearly independent vec-
tors of R3&bull; Therefore, 
</p>
<p>0 
e 1 cos2t 
</p>
<p>e 1 sin2t 
</p>
<p>is a fundamental matrix solution of x = Ax. Computing 
</p>
<p>we see that 
</p>
<p>[ 2e' eAt= -3et 
</p>
<p>2e1 
</p>
<p>0 
</p>
<p>0 
1 
0 
</p>
<p>e 1cos2t 
e1 sin2t 
</p>
<p>Jl 
-I I 
</p>
<p>2 
3 
2 
</p>
<p>0 
</p>
<p>0 
</p>
<p>ow e1 sin2t t 
- e1 cos2t 1 
</p>
<p>= et [ - t + ico!2t +sin2t 
1 + isin2t- cos2t 
</p>
<p>0 
cos2t 
</p>
<p>sin2t 
</p>
<p>0 
</p>
<p>1 
</p>
<p>0 
</p>
<p>0 
</p>
<p>0 
</p>
<p>-1 
</p>
<p>0 
</p>
<p>0 
</p>
<p>-1 
</p>
<p>-s~n2t]. 
cos2t 
</p>
<p>363 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>Consequently, 
</p>
<p>- 1 + 1 cos 2s- sin 2s 2 2 
</p>
<p>1-lsin2s- cos2s 2 
</p>
<p>0 
cos2s 
</p>
<p>-sin2s 
</p>
<p>0 
</p>
<p>sin2s [ 0 ] ds 
</p>
<p>cos2s es c~s2s 
</p>
<p>=e 1 [cos2t~S~n2tl +eAt ( 1 [sin2s~OS2s] ds 
cos2t+sm2t Jo cos2 2s 
</p>
<p>=e 1 [cos2t~s~n2t]+eA 1 [ (1-co~4t)/8] 
cos2t + sm2t t /2 + (sin4t)/8 
</p>
<p>= e1 [ cos2t ~ sin2tl 
cos2t+sin2t 
</p>
<p>0 
_ tsin2t + cos2t-cos4tcos2t-sin4tsin2t 
</p>
<p>2 8 
tcos2t + sin4tcos2t-sin2tcos4t+ sin2t 
</p>
<p>2 8 
</p>
<p>0 
</p>
<p>=et cos2t-(l+ft)sin2t 
</p>
<p>(I + 4 t )cos 2 t + ~ sin 2 t 
</p>
<p>As Example 1 indicates, the method of variation of parameters is often 
quite tedious and laborious. One way of avoiding many of these calcula-
tions is to "guess" a particular solution l[;(t) of the nonhomogeneous equa-
tion and then to observe (see Exercise 9) that every solution x(t) of the 
nonhomogeneous equation must be of the form cp( t) +I[;( t) where cp( t) is a 
solution of the homogeneous equation. 
</p>
<p>Example 2. Find all solutions of the differential equation 
</p>
<p>364 
</p>
<p>0 
I 
2 
</p>
<p>(9) </p>
<p/>
</div>
<div class="page"><p/>
<p>Solution. Let 
</p>
<p>3.12 The nonhomogeneous equation; variation of parameters 
</p>
<p>0 
I 
2 -n 
</p>
<p>We "guess" a particular solution 1/J(t) of the form 1/J(t) = bec1&bull; Plugging this 
expression into (9) gives 
</p>
<p>or 
</p>
<p>This implies that 
</p>
<p>(A-cl)b~ [-H 
1 
</p>
<p>2( c- 4) 
</p>
<p>b=--=-!_ 4+(1-c/ 
1-c 
</p>
<p>1 +3c 
</p>
<p>4+ (1- c)2 
</p>
<p>Hence, every solution x(t) of (9) is of the form 
</p>
<p>1-c 
</p>
<p>1 
</p>
<p>2(c-4) 
</p>
<p>4+ (1- c)2 
</p>
<p>1 +3c 
</p>
<p>4+ (1- c)2 
</p>
<p>365 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>Remark. We run into trouble when c= 1 because one is an eigenvalue of 
the matrix 
</p>
<p>[~ 
0 
1 
2 -n 
</p>
<p>More generally, the differential equation x = Ax + vec1 may not have a 
solution of the form bec1 if c is an eigenvalue of A. In this case we have to 
guess a particular solution of the form 
</p>
<p>~(t)=ec'(b 0 +b 1 t+ ... +bk_ 1tk-!] 
</p>
<p>for some appropriate integer k. (See Exercises 10-18). 
</p>
<p>EXERCISES 
</p>
<p>In each of Problems 1-6 use the method of variation of parameters to 
solve the given initial-value problem. 
</p>
<p>t. x={ -~ 
</p>
<p>2. x={i 
</p>
<p>3. x={i 
</p>
<p>=1)x+{De', x(O)={D 
</p>
<p>=Dx+{~~). x(O)={g) 
</p>
<p>4. x={ 0 1)x+(ft(t))&bull; x(O)={O) 
-1 0 !2(1) 0 
</p>
<p>S. x=(g ~ ~)x+(f)e 21 , x(O)=(D 
</p>
<p>( 
-1 
</p>
<p>6. i= ~ 
-1 
</p>
<p>1 
1 
</p>
<p>7. Consider the nth-order scalar differential equation 
</p>
<p>(*) 
</p>
<p>Let v(t) be the solution of L[y]=O which satisfies the initial conditions 
y(O)= ... = y&lt;n-2&gt;(0)=0,y&lt;n-l)(O)= 1. Show that 
</p>
<p>y(t)= {v(t-s)f(s)ds 
</p>
<p>is the solution of (*) which satisfies the initial conditionsy(O)= ... = y&lt;n-t&gt;(O) = 
0. Hint: Convert (*) to a system of n first-order equations of the form i=Ax, 
</p>
<p>366 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.12 The nonhomogeneous equation; variation of parameters 
</p>
<p>and show that 
</p>
<p>is the nth column of eA1&bull; 
</p>
<p>v(t) 
</p>
<p>v'(t) 
</p>
<p>8. Find the solution of the initial-value problern 
</p>
<p>d} dy 
- +- =secltanl y(O)= y'(O)=y"(O)=O. 
dl3 dl . ' 
</p>
<p>9. (a) Let 1{1(1) be a solution of the nonhomogeneous equation x=Ax+f(l) and 
Iet f/1(1) be a solution of the homogeneous equation x=Ax. Show that f/1(1) 
+ 1{1(1) is a solution of the nonhomogeneous equation. 
</p>
<p>(b) Let 1{11(1) and l{lil) be two solutions of the nonhomogeneous equation. 
Show that 1{11(t)-l{lil) is a solution of the homogeneous equation. 
</p>
<p>(c) Let l{l(t) be a particular solution of the nonhomogeneous equation. Show 
that any other solution y( t) must be of the form y( 1) = f/1( t) + 1{1( t) where 
f/l(t) is a solution of the homogeneous equation. 
</p>
<p>In each of Problems 10-14 use the method of judicious guessing to find a 
particular solution of the given differential equation. 
</p>
<p>10. x=(i -~)x+( De3t 11. x=U - j)x+ ( -;:2) 
</p>
<p>12. x= (-i 3 2) ( sinl) 2 1 x+ 0 
-1 -1 0 
</p>
<p>13. x=O 
2 
</p>
<p>-ox+(_~)e 1 1 
-1 
</p>
<p>( -1 -1 
</p>
<p>-Dx+(JJ 14. x= ~ -4 
5 
</p>
<p>15. Consider the differential equation 
</p>
<p>i=Ax+ve)..1 (*) 
</p>
<p>where v is an eigenvector of A with eigenvalue 71.. Suppose moreover, that A has 
n linearly independent eigenvectors vl, v2, &bull;&bull;&bull; , vn, with distinct eigenvalues 
71. 1, ... ,71.n respectively. 
(a) Show that (*) has no solution l{l(t) of the form l{l(t)=ae&gt;.1&bull; Hinl: Write a= 
</p>
<p>alvl+ ... +anvn. 
(b) Show that (*) has a solution 1{1(1) of the form 
</p>
<p>l{l(t) = ae&gt;.1 + bte&gt;.1&bull; 
</p>
<p>367 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>Hint: Show that bis an eigenvector of A with eigenvalue A and choose it so 
that we can solve the equation 
</p>
<p>(A-A.I)a=b-v. 
</p>
<p>In each of Problems 16-18, find a particular solution l[l(t) of the given dif-
ferential equation of the form l[l(t)= eM(a+bt). 
</p>
<p>( 
1 1 
</p>
<p>16. x= 2 3 
4 1 
</p>
<p>17. x= ( ~ 
-3 
</p>
<p>-1 
3 
1 
</p>
<p>- ~ )x + ( _ ~ ) e3t 
-1 -1 
</p>
<p>3.13 Solving systems by Laplace transforms 
</p>
<p>The method of Laplace transforms introduced in Chapter 2 can also be 
used to solve the initial-value problern 
</p>
<p>x=Ax+f(t), x(O)=x0&bull; (1) 
</p>
<p>Let 
</p>
<p>X 1 (s) 
foc&gt;:J e-s1X 1 (t)dt 
</p>
<p>X(s)= = e{x(t)} = 
</p>
<p>xn (s) fo c&gt;:J e -stxn( t)dt 
</p>
<p>and 
</p>
<p>F1 (s) 
foc&gt;:J e -stjl ( t) dt 
</p>
<p>F(s)= =e{r(t)}= 
</p>
<p>Fn(s) fo c&gt;:J e -stfn ( t) dt 
</p>
<p>Taking Laplace transforms ofboth sides of (1) gives 
</p>
<p>e{ x(t)} = e{ Ax(t) +f(t)} =Ae{ x(t)} + e{f(t)} 
</p>
<p>=AX(s) + F(s), 
</p>
<p>368 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.13 Solving systems by Laplace transforms 
</p>
<p>and from Lemma 3 of Section 2.9, 
</p>
<p>e{ x(t)} = 
</p>
<p>=sX(s)-x0. 
</p>
<p>Hence, 
</p>
<p>sX(s) -x0 =AX(s) + F(s) 
or 
</p>
<p>I 0 
</p>
<p>(sl -A)X(s) =x0 + F(s), 
0 I 
</p>
<p>I= 
</p>
<p>0 0 
</p>
<p>0 
0 
</p>
<p>(2) 
</p>
<p>Equation (2) is a system of n simultaneous equations for X 1(s), ... ,Xn(s), 
and it can be solved in a variety of ways. (One way, in particular, is to mul-
tiply both sides of (2) by (si-A)- 1.) Once we know X 1(s), ... ,Xn(s) we can 
find x 1(t), ... ,xn(t) by inverting these Laplace transforms. 
</p>
<p>Example 1. Solve the initial-value problern 
</p>
<p>. (I x= 
1 
</p>
<p>x(O)=(i). (3) 
</p>
<p>Solution. Taking Laplace transforms of both sides of the differential equa-
tion gives 
</p>
<p>or 
</p>
<p>sX(s)-{i)={! i)x(s)+ s~I {D 
</p>
<p>I 
(s-I)X1 (s)-4X2 (s)=2+ s-l -
</p>
<p>I 
X1 (s)+(s-I)X2 (s)=l+ s-l. 
</p>
<p>The solution of these equations is 
</p>
<p>X 1 (s)= s-=3 + sz~ 1' Xz (s)= s~3 + (s-l)(s; I)(s-3) 
Now, 
</p>
<p>369 </p>
<p/>
</div>
<div class="page"><p/>
<p>3 Systems of differential equations 
</p>
<p>Hence, 
</p>
<p>e1-e- 1 
xl(t)=2e31+ 2 . 
</p>
<p>To invert X2(s), we use partial fractions. Let 
</p>
<p>s = ___4_ + __1!_ + _f__ 
(s-1)(s+ 1)(s-3) s-1 s+ 1 s-3 &middot; 
</p>
<p>This implies that 
</p>
<p>A(s+ 1)(s-3)+B(s-1)(s-3)+ C(s-1)(s+ I)=s. (4) 
</p>
<p>Setting s =I, -1, and 3 respectively in (4) gives A =- ~. B =- i. and 
C= t. Consequently, 
</p>
<p>x (t)= e-1{ _1__1 __ 1__1_ + .!_!__1_} 
2 4 s-1 8 s+ 1 8 s-3 
</p>
<p>_ 1 -1 1 1 + 11 31 
--Se -4e Se. 
</p>
<p>EXERCISES 
</p>
<p>Find the solution of each of the following initial-value problems. 
</p>
<p>1. x=( -~ -ux. x(O)=(~J 
</p>
<p>2. x=O =nx. x(O)=(D 
</p>
<p>3. x=n =Dx+( 3: 1 ), x(O)=(i) 
</p>
<p>4. x=(! Dx+( _ ~)e 1 , x(O)=(g) 
</p>
<p>s. x=U =~ )x+( De 1, x(O)=( D 
6. x=(i - 5 )x + ( sin t ) x(O) = ( - 1 ) -2 tant ' 0 
7. x=( -i -Dx+( 4e 1 ~0st ). x(O)=( D 
s. x=( _ ~ 1 )x + ( !1 ( t) ). x(O) = ( 0 ) 
</p>
<p>0 f2 (t) 0 
</p>
<p>9. x=(~ =~)x+(6(t~17)). x(O)=(~) 
</p>
<p>10. x=(~ =nx+ e- ~"(t) ). x(O)= (~) 
370 </p>
<p/>
</div>
<div class="page"><p/>
<p>3.13 So1ving systems by Lap1ace transforms 
</p>
<p>11. i=O 
2 -ox, x(O)= (g) 1 
</p>
<p>-1 
</p>
<p>12. x={g ~ nx+ ( ~ )e21 , x(O)= ( D 
( -1 
</p>
<p>13. i= ~ -~ !)x+{g)e', x(O)=(g) 
</p>
<p>14. x=O 0 0) ( 0 ) x(O)=(r) 1 -2 x+ 0 , 
2 1 e1cos2t 
</p>
<p>15.i&middot;[~ 
0 0 
</p>
<p>~]~ &middot;~&gt;- [!] 3 0 0 3 
0 2 
</p>
<p>371 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 
Qualitative theory of 
</p>
<p>differential equations 
</p>
<p>4.1 Introduction 
In this chapter we consider the differential equation 
</p>
<p>x=f(t,x) 
</p>
<p>where 
</p>
<p>and 
</p>
<p>f(t,x)= 
</p>
<p>fn(t,Xp ... ,xn) 
</p>
<p>(1) 
</p>
<p>is a nonlinear function of x 1, ... , xn. Unfortunately, there are no known 
methods of solving Equation (1). This, of course, is very disappointing. 
However, it is not necessary, in most applications, to find the solutions of 
(1) explicitly. For example, let x 1(t) and xit) denote the populations, at 
time t, of two species competing amongst themselves for the limited food 
and living space in their microcosm. Suppose, moreover, that the rates of 
growth of x 1(t) and xit) are governed by the differential equation (1). In 
this case, we arenot really interested in the va1ues of x 1(t) and x2(t) at ev-
ery time t. Rather, we are interested in the qualitative properties of x 1(t) 
and x2(t). Specically, we wish to answer the following questions. 
</p>
<p>372 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.1 lntroduction 
</p>
<p>I. Do there exist values ~ 1 and ~ 2 at which the two species coexist 
together in a steady state? That is to say, are there numbers ~ 1 , ~ 2 such that 
x 1 (t)=~ 1 , xit)=~ 2 is a solution of (1)? Such values ~ 1 ,~ 2 , if they exist, are 
called equilibrium points of (I). 
</p>
<p>2. Suppose that the two species are coexisting in equilibrium. Suddenly, 
we add a few members of species 1 to the microcosm. Will x 1(t) and x2(t) 
remain close to their equilibrium values for all future time? Or perhaps the 
extra few members give species I a large advantage and it will proceed to 
annihilate species 2. 
</p>
<p>3. Suppose that x 1 and x2 have arbitrary values at t=O. What happens 
as t approaches infinity? Will one species ultimately emerge victorious, or 
will the struggle for existence end in a draw? 
</p>
<p>More generally, we are interested in determining the following proper-
ties of solutions of (1). 
</p>
<p>1. Do there exist equilibrium values 
</p>
<p>for which x(t)=::x0 is a solution of (I)? 
2. Let &lt;f&gt; (t) be a solution of (I). Suppose that 1/;(t) is a second solution 
</p>
<p>with 1/;(0) very close to &lt;f&gt; (0); that is, 1/;;(0) is very close to &lt;MO), j = I, ... , n. 
Will 1/;(t) remain close to &lt;f&gt; ( t) for all future time, or will 1/;( t) diverge from 
&lt;/&gt; (t) as t approaches infinity? This question is often referred to as the prob-
lern of stability. lt is the most fundamental problern in the qualitative the-
ory of differential equations, and has occupied the attention of many 
mathematicians for the past hundred years. 
</p>
<p>3. What happens to solutions x(t) of (I) as t approaches infinity? Do all 
solutions approach equilibrium values? If they don't approach equilibrium 
values, do they at least approach a periodic solution? 
</p>
<p>This chapter is devoted to answering these three questions. Remarkably, 
we can often give satisfactory answers to these questions, even though we 
cannot solve Equation (I) explicitly. Indeed, the first question can be 
answered immediately. Observe that x(t) is identically zero if x(t) = x0&bull; 
Hence, x0 is an equilibrium value of (1), if, and only if, 
</p>
<p>(2) 
</p>
<p>Example 1. Find all equilibrium values of the system of differential equa-
tions 
</p>
<p>373 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>Solution. 
</p>
<p>is an equilibrium value if, and only if, 1-x~=O and (x?) 3 +x~=O. This 
</p>
<p>implies that x~ = 1 and x? = - 1. Hence ( - ~ ) is the only equilibrium value 
of this system. 
</p>
<p>Example 2. Find all equilibrium solutions of the system 
</p>
<p>~~ =(x-l)(y-1), 
dy 
dt = (X + } )(y + 1 ). 
</p>
<p>Solution. 
</p>
<p>is an equilibrium value of this system if, and only if, (x0 -1)(y0 -1)=0 and 
(x0 + l)(y0 + 1)=0. The first equation is satisfied if either x 0 or y 0 is 1, 
while the second equation is satisfied if either x0 or y 0 is - 1. Hence, x = 1, 
y = - I and x = - I, y = I are the equilibrium solutions of this system. 
</p>
<p>The question of stability is of paramount importance in all physica1 
applications, since we can never measure initial conditions exactly. For 
example, consider the case of a particle of mass one kgm attached to an 
elastic spring of force constant 1 Njm which is moving in a frictionless 
medium. In addition, an external force F(t) = cos2t N is acting on the 
particle. Let y( t) denote the position of the particle relative to its equi-
librium position. Then (d 2yjdt 2 )+ y = cos2t. We convert this second-order 
equation into a system of two first-order equations by setting x 1 = y, 
x 2 = y'. Then, 
</p>
<p>dx2 
---;[( =- x 1 + cos2t. (3) 
</p>
<p>The functionsy 1(t)=sint andyit)=cost are two independent solutions of 
the homogeneous equationy"+y=O. Moreover,y= -icos2t is a particu-
lar solution of the nonhomogeneous equation. Therefore, every solution 
</p>
<p>of (3) is of the form 
</p>
<p>x(t)=cl(sint)+cz( cC?st)+[-icos2t ]&middot; 
cost -smt jsin2t 
</p>
<p>(4) 
</p>
<p>374 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.1 Introduction 
</p>
<p>At time t = 0 we measure the position and velocity of the particle and ob-
tainy(O)= l,y'(O)=O. This implies that c1 =0 and c2= j. Consequently, the 
position and velocity of the particle for all future time are given by the 
equation 
</p>
<p>( y(t)) (x1(t)) [ jcost-tcos2tl 
y'(t) = x 2(t) = - jsint+ ~sin2t &middot; 
</p>
<p>(5) 
</p>
<p>However, suppose that our measurements permit an error of magnitude 
10-4&bull; Will the position and velocity of the particle remain close to the val-
ues predicted by (5)? The answer to this question had better be yes, for 
otherwise, Newtonian mechanics would be of no practical value to us. For-
tunately, it is quite easy to show, in this case, that the position and velocity 
of the particle remain very close to the values predicted by (5). Lety(t) and 
j'(t) denote the true values of y(t) and y'(t) respectively. Clearly, 
</p>
<p>y(t)-y (t) = (j- c2)cost- c1 sint 
</p>
<p>y'(t)- .Y'(t) =- c1 cost-{j- c2)sint 
</p>
<p>where c1 and c2 are two constants satisfying 
</p>
<p>We can rewrite these equations in the form 
</p>
<p>[ 2]1/2 y'(t)-.Y'(t)= cr+O-c2) cos(t-&laquo;52), 
</p>
<p>c, 
tan&laquo;51=--4 
</p>
<p>c2-3 
</p>
<p>~-c 3 2 
tan&laquo;52=--. 
</p>
<p>c, 
</p>
<p>Hence, both y ( t)-y ( t) and y' ( t)-y' ( t) are bounded in absolute value by 
[cf +(j- c2)2]112. This quantity is at most V2 10-4&bull; Therefore, the true 
values of y(t) and y'(t) are indeed close to the values predicted by (5). 
</p>
<p>As a second example of the concept of stability, consider the case of a 
particle of mass m which is supported by a wire, or inelastic string, of 
length I and of negligible mass. The wire is always straight, and the system 
is free to vibrate in a vertical plane. This configuration is usually referred 
to as a simple pendulum. The equation of motion of the pendulum is 
</p>
<p>where y is the angle which the wire makes with the vertical line AO (see 
</p>
<p>375 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>Figure 1 
</p>
<p>Figure 1). Setting x 1 = y and x2 = dy / dt we see that 
</p>
<p>(6) 
</p>
<p>The system of equations (6) has equilibrium solutions x 1 =0, x2 =0, and x 1 
= '17, x 2 = 0. (If the pendulum is suspended in the upright position y = '1T 
with zero velocity, then it will remain in this upright position for all future 
time.) These two equilibrium solutions have very different properties. If we 
disturb the pendulum slightly from the equilibrium position x 1 = 0, x2 = 0, 
by either displacing it slightly, or giving it a small velocity, then it will ex-
ecute small oscillations about x 1 =0. On the other band, if we disturb the 
pendulum slightly from the equilibrium position x 1 = '17, x2 =0, then it will 
either execute very large oscillations about x 1 =0, or it will rotate around 
and around ad infinitum. Thus, the slightest disturbance causes the 
pendulum to deviate drastically from its equilibrium position x 1 = '17, x 2 = 0. 
Intuitively, we would say that the equilibrium value x 1 =0, x2 =0 of (6) is 
stable, while the equilibrium value x 1 = '17, x2 = 0 of (6) is unstable. This 
concept will be made precise in Section 4.2. 
</p>
<p>The question of stability is usually very difficult to resolve, because we 
cannot solve (1) explicitly. The only case which is manageable is when 
f(t, x) does not depend explicitly on t; that is, f is a function of x alone. 
Such differential equations are called autonomous. And even for autono-
maus differential equations, there are only two instances, generally, where 
we can completely resolve the stability question. The first case is when f(x) 
= Ax and it will be treated in the next section. The second case is when we 
are only interested in the stability of an equilibrium solution of x=f(x). 
This case will be treated in Section 4.3. 
</p>
<p>Question 3 is extremely important in many applications since an answer 
to this question is a prediction concerning the long time evolution of the 
system under consideration. We answer this question, when possible, in 
Sections 4.6-4.8 and apply our results to some extremely important ap-
plications in Sections 4.9-4.12. 
</p>
<p>376 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.1 Introduction 
</p>
<p>EXERCISES 
</p>
<p>In each of Problems 1-8, find all equilibrium values of the given system of 
differential equations. 
</p>
<p>1. ~~ =x-x2-2xy 
</p>
<p>dy =2y-2y2-3xy 
dt 
</p>
<p>dx 
3. dt = ax- bxy 
</p>
<p>~ = -cy+dxy 
</p>
<p>dz =z+x2+y2 
dt 
</p>
<p>5. dx =xy2-x 
dt 
dy 0 
dt =XSID'TT)' 
</p>
<p>7. ~~ = - 1-y- ex 
</p>
<p>dy =x2+y(ex-1) 
dt 
dz 0 
dt =x+smz 
</p>
<p>dx 
2. dt=-&szlig;xy+JL 
</p>
<p>~ =&szlig;xy-yy 
</p>
<p>dx 2 
4. dt= -x-xy 
</p>
<p>dy 2 
dt = -y-yx 
</p>
<p>dz = 1-z+x2 
dt 
</p>
<p>dx 
6. dt =cosy 
</p>
<p>dy 0 1 
dt =smx-
</p>
<p>8. ~~ =x-y2 
</p>
<p>dy =x2-Y 
dt 
</p>
<p>dz =ez-x 
dt 
</p>
<p>9. Consider the systern of differential equations 
</p>
<p>dx dy 
dt =ax+by, dt =cx+dy. 
</p>
<p>(i) Show that x=O,y=O is the only equilibriurn point of (*) if ad-bc=/=0. 
(ii) Show that (*) has a line of equilibriurn points if ad- bc = 0. 
</p>
<p>10. Let x = x(t), y = y(t) be the solution of the initial-value problern 
</p>
<p>dx 
dt =-x-y, 
</p>
<p>dy 
dt =2x-y, x(O)= y(O) = 1. 
</p>
<p>(*) 
</p>
<p>Suppose that we rnake an error of rnagnitude w- 4 in rneasuring x(O) andy(O). 
What is the largest error we rnake in evaluating x(t), y(t) for 0.;;;; t &lt; oo? 
</p>
<p>11. (a) Verify that 
</p>
<p>is the solution of the initial-value problern 
</p>
<p>x=( i 
-3 
</p>
<p>l 
1 
2 
</p>
<p>x(O)= (g). 
377 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>(b) Let x=I/J(t) be the solution of the above differential equation which satis-
fies the initial condition 
</p>
<p>x(O)=x 0 ~U). 
</p>
<p>Show that each component of 1/J(t) approaches infinity, in absolute value, 
as t-Hx;. 
</p>
<p>4.2 Stability of linear systems 
</p>
<p>In this section we consider the stability question for solutions of autono-
maus differential equations. Let x=f[&gt;(t) be a solution of the differential 
equation 
</p>
<p>x=f(x). (I) 
</p>
<p>We are interested in determining whether f[&gt;(t) is stable or unstable. That is 
to say, we seek to determine whether every solution l[;(t) of (l) which starts 
sufficiently close to 4&gt;( t) at t = 0 must remain close to f[&gt;( t) for all future 
time t ~ 0. We begin with the following formal definition of stability. 
</p>
<p>Definition. The solution x=f[&gt;(t) of (1) is stable if every solution l[;(t) of (1) 
which starts sufficiently close to 4&gt;( t) at t = 0 must remain close to 4&gt;( t) 
for all future time t. The solution f[&gt;(t) is unstable if there exists at least 
one solution l[;(t) of (I) which starts near f[&gt;(t) at t=O but which does 
not remain close to f[&gt;(t) for all future time. More precisely, the solution 
f[&gt;(t) is stable if for every e &gt; 0 there exists 8 = 8 ( e) such that 
</p>
<p>ilf1(t)-cpj(t)i&lt;e if ll/li0)-!f&gt;;(O)I&lt;8(e), j=I, ... ,n 
</p>
<p>for every solution l[;(t) of (I). 
</p>
<p>The stability question can be completely resolved for each solution of 
the linear differential equation 
</p>
<p>x=Ax. (2) 
</p>
<p>This is not surprising, of course, since we can solve Equation (2) exactly. 
Wehave the following important theorem. 
</p>
<p>Theorem 1. (a) Every solution x=f[&gt;(t) of (2) is stable if all the eigenvalues 
of A have negative real part. 
(b) Every solution x = f[&gt;( t) of (2) is unstable if at least one eigenvalue of A 
has positive real part. 
(c) Suppose that all the eigenvalues of A have real part ...; 0 and A1 = 
io1, &bull;&bull;&bull; ,A1 = io1 have zero real part. Let Aj = ioj have multip/icity kj. This 
means that the characteristic po/ynomial of A can be factared into the form 
</p>
<p>p(A) = (A- io1)k' . .. (A- io1)k'q(A) 
</p>
<p>378 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.2 Stability of linear systems 
</p>
<p>where all the roots of q(A.) have negative real part. Then, every solution 
x=f/&gt;(t) of (1) is stable if A has ky linearly independent eigenvectors for 
each eigenvalue A.1 = ia1. Otherwise, every solution f/&gt;(t) is unstable. 
</p>
<p>Our first step in proving Theorem 1 is to show that every solution f/&gt;(t) is 
stable if the equilibrium solution x(t)=O is stable, and every solution f/&gt;(t) 
is unstable if x(t)=O is unstable. To this end, Iet t/;(t) be any solution of 
(2). Observe that z( t) = f/&gt;( t)- t/;( t) is again a solution of (2). Therefore, if 
the equilibrium solution x(t)=O is stable, then z(t) =&lt;/&gt;( t)- 1/;(t) will always 
remain small if z(O) =f/&gt;(0)- t/;(0) is sufficiently small. Consequently, every 
solution f/&gt;(t) of (2) is stable. On the other hand suppose that x(t)=O is un-
stable. Then, there exists a solution x = h(t) which is very small initially, 
but which becomes !arge as t approaches infinity. The function 1/;(t) =f/&gt;(t) 
+h(t) is clearly a solution of (2). Moreover, t/;(t) is close to f/&gt;(t) initially, 
but diverges from f/&gt;(t) as t increases. Therefore, every solution x=f/&gt;(t) of 
(2) is unstable. 
</p>
<p>Our next step in proving Theorem I is to reduce the problern of showing 
that n quantities 1/;/ t), j = 1, ... , n are small to the much simpler problern of 
showing that only one quantity is small. This is accomplished by introduc-
ing the concept of length, or magnitude, of a vector. 
</p>
<p>Definition. Let 
</p>
<p>be a vector with n components. The numbers x 1, &bull;&bull;&bull; ,xn may be real or 
complex. We define the length of x, denoted by llxl/ as 
</p>
<p>1/xll =max{lxii, lx2l&bull; &middot; &middot; ., lxnl}&middot; 
</p>
<p>For example, if 
</p>
<p>then llxll = 3 and if 
</p>
<p>[ 
1 + 2il 
</p>
<p>x= 2 
-1 
</p>
<p>then llxl/ = V5 . 
The concept of the length, or magnitude of a vector corresponds to the 
</p>
<p>concept of the length, or magnitude of a number. Observe that llxll ~ 0 for 
</p>
<p>379 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>any vector x and llxll = 0 only if x = 0. Second, observe that 
</p>
<p>IIAxll =max{IXxli, ... ,IXxnl} =IXImax{ixii, ... , lxnl} =IXIIIxll&middot; 
</p>
<p>Finally, observe that 
</p>
<p>llx+yll =max{lxi +yd, ... ,ixn +Yni} ~max{lxii +IYII, ... ,Ixnl +IYnl} 
</p>
<p>~ max{lxii, ... , lxnl} +max{iyd, ... ,IYnl} = llxll + IIYII&middot; 
</p>
<p>Thus, our definition really captures the meaning of length. 
In Section 4.7 we give a simple geometric proof of Theorem 1 for the 
</p>
<p>case n = 2. The following proof is valid for arbitrary n. 
</p>
<p>PRooF OF THEOREM 1. (a) Every solution x=l[;(t) of i=Ax is of the form 
l[;(t) = eA1l[;(O). Let &lt;Pv(t) be the ij element of the matrix eA1, and Iet 
1/1?, ... , 1/12 be the components of 1[;(0). Then, the ith component of 1[;( t) is 
</p>
<p>n 
</p>
<p>1/1;( t) =&lt;Pi! ( t)t/1? + ... + &lt;P;n( t)l/J2= ~ &lt;~&gt;v( t)l/Jr 
j=l 
</p>
<p>Suppose that all the eigenvalues of A have negative real part. Let - a 1 be 
the largest of the real parts of the eigenvalues of A. It is a simple matter to 
show (see Exercise 17) that for every number - a, with - a 1 &lt; - a &lt; 0, we 
can find a number K such that I&lt;Pv(t)l ~ Ke-a1, t ~ 0. Consequently, 
</p>
<p>n n 
</p>
<p>11/J;(t)l ~ ~ Ke-atll/J}I = Ke-at ~ ll/Jj01 
j=l j=l 
</p>
<p>for some positive constants K and a. Now, 11[;1&deg;1 ~ 111[;(0)11&middot; Hence, 
</p>
<p>II 1/;( t) II = max{ ll/J1 ( t)l, &middot; &middot; &middot;, 11/Jn(t)l} ~ nKe -arll 1[;(0)11&middot; 
</p>
<p>Let e&gt;O be given. Choose 8(e)=ejnK. Then, 111/;(t)ll &lt;e if 111[;(0)11 &lt;8(e) 
and t ;;;. 0, since 
</p>
<p>111/;(t)ll ~ nKe-a1 lll[;(O)II &lt; nKe/ nK = e. 
Consequently, the equilibrium solution x(t)=O is stable. 
</p>
<p>(b) Let X be an eigenvalue of A with positive real part and let v be an 
eigenvector of A with eigenvalue X. Then, 1[;( t) = ce&gt;-1v is a solution of i = 
Ax for any constant c. If Ais real then v is also real and 111/;(t)ll = lcle&gt;-1 llvll&middot; 
Clearly, 111/;(t)ll approaches infinity as t approaches infinity, for any choice 
of c~O, no matter how small. Therefore, x(t)=:O is unstable. If X= a + i&szlig; 
is complex, then v=v1 + iv2 is also complex. In this case 
</p>
<p>e&lt;a+i&szlig;)l(v1 + ir) = eal (cos&szlig;t + isin&szlig;t)(v1 + iv2) 
</p>
<p>= ea1[ (v1 cos&szlig;t -rsin&szlig;t) + i(v1 sin&szlig;t+v2 cos&szlig;t)] 
</p>
<p>is a complex-valued solution of (2). Therefore 
</p>
<p>1[; 1 (t) = cear (v1 cos&szlig;t -rsin&szlig;t) 
</p>
<p>is a real-valued solution of (2), for any choice of constant c. Clearly, 
</p>
<p>380 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.2 Stability of linear systems 
</p>
<p>!llf1(t)11 is unbounded as t approaches infinity if c and either v1 or v2 is 
nonzero. Thus, x(t)=O is unstable. 
</p>
<p>(c) If A has kj linearly independent eigenvectors for each eigenvalue 'J.y= 
iaj of multiplicity kj&gt; then we can find a constant K suchthat l(eA1)1il &lt; K 
(see Exercise 18). There, lllf(t)ll &lt; nKII~f(O)II for every solution lf(t) of (2). 
lt now follows immediately from the proof of (a) that x(t):=O is stable. 
</p>
<p>On the other hand, if A has fewer than Js linearly independent eigenvec-
tors with eigenvalue 'J.y = iaj&gt; then :X= Ax has solutions lf( t) of the form 
</p>
<p>lf( t) = ce;"i1 [ v + t(A- ia})v] 
</p>
<p>where (A-i~l)v~O. If ~=0, then lf(t)=c(v+tAv) is real-valued. More-
over, !llf(t)ll is unbounded as t approaches infinity for any choice of c~O. 
Similarly, both the real and imaginary parts of lf(t) are unbounded in mag-
nitude for arbitrarily small lf(O) ~ 0, if aj ~ 0. Therefore, the equilibrium 
solution x(t):=O is unstable. 0 
</p>
<p>If all the eigenvalues of A have negative real part, then every solution 
x(t) of x=Ax approaches zero as t approaches infinity. This follows im-
mediately from the estimate llx(t)ll &lt; Ke-"1 llx(O)II which we derived in the 
proof of part (a) of Theorem I. Thus, not only is the equilibrium solution 
x(t)=O stable, but every solution lf(t) of (2) approaches it as t approaches 
infinity. This very strong type of stability is known as asymptotic stability. 
</p>
<p>Definition. A solution x=&laquo;f&gt;(t) of (I) is asymptotically stableifit is stable, 
and if every solution lf( t) which starts sufficiently close to &laquo;/&gt;( t) must ap-
proach &laquo;f&gt;(t) as t approaches infinity. In particular, an equilibrium solu-
tion x(t) = x0 of (I) is asymptotically stable if every solution x = lf( t) of 
(I) which starts sufficiently close to x0 at time t = 0 not only remains 
close to x0 for all future time, but ultimately approaches x0 as t ap-
proaches infinity. 
</p>
<p>Remark. The asymptotic stability of any solution x=&laquo;f&gt;(t) of (2) is clearly 
equivalent to the asymptotic stability of the equilibrium solution x(t)=O. 
</p>
<p>Example 1. Determine whether each solution x(t) of the differential equa-
tion 
</p>
<p>[
-1 
</p>
<p>x= -2 
-3 
</p>
<p>-~ ~]x 
-2 -1 
</p>
<p>is stable, asymptotically stable, or unstable. 
Solution. The characteristic polynomial of the matrix 
</p>
<p>A=[=~ -~ ~] 
-3 -2 -1 
</p>
<p>381 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>is 
</p>
<p>p(A)=(detA-AI)=det[- ~;A -1&deg;-A ~ l 
-3 -2 -1-A 
</p>
<p>= -(1 +A)3 -4(1 +A)= -(1 +A)(A2 +2A+5). 
</p>
<p>Hence, A = - 1 and A = - 1 &plusmn; 2i are the eigenvalues of A. Since all three ei-
genvalues have negative real part, we conclude that every solution of the 
differential equation x = Ax is asymptotically stable. 
</p>
<p>Example 2. Prove that every solution of the differential equation 
</p>
<p>is unstable. 
Solution. The characteristic po1ynomial of the matrix 
</p>
<p>is 
</p>
<p>Hence A = 6 and A = - 4 are the eigenvalues of A. Since one eigenvalue of 
A is positive, we conclude that every solution x = f/'( t) of x = Ax is unstable. 
</p>
<p>Example 3. Show that every solution of the differential equation 
</p>
<p>x=(o -3) 2 0 X 
is stable, but not asymptotically stable. 
Solution. The characteristic polynomia1 of the matrix 
</p>
<p>is 
</p>
<p>p(A)=det(A-AI)=det( -; =n=A2 +6. 
</p>
<p>Thus, the eigenvalues of Aare A= &plusmn; V6 i. Therefore, by part (c) of Theo-
rem 1, every solution x=f/'(t) of x=Ax is stable. However, no solution is 
asymptotically stab1e. This follows immediate1y from the fact that the gen-
eral solution of x = Ax is 
</p>
<p>x(t)=c1(-V6 sinv'6t)+c2 (V6 cosv'6t). 
2cos V6 t 2sin V6 t 
</p>
<p>382 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.2 Stability of linear systems 
</p>
<p>Hence, every solution x(t) is periodic, with period 2'1T jv'6, and no solu-
tion x(t) (except x(t)=:O) approaches 0 as t approaches infinity. 
</p>
<p>Example 4. Show that every solution of the differential equation 
</p>
<p>x= [ ~ 
-6 
</p>
<p>-3 
-6 
</p>
<p>0 
-~]x 
-3 
</p>
<p>is unstable. 
Solution. The characteristic polynomial of the matrix 
</p>
<p>is 
</p>
<p>A= [ ~ 
-6 
</p>
<p>[
2-X 
</p>
<p>p(X)=det(A-XI)=det 0 
-6 
</p>
<p>-3 
-6 
</p>
<p>0 
-~] 
-3 
</p>
<p>-3 
-6-X 
</p>
<p>0 
</p>
<p>Hence, the eigenvalues of A are X= - 7 and X= 0. Every eigenvector v of A 
with eigenvalue 0 must satisfy the equation 
</p>
<p>Av=[ ~ 
-6 
</p>
<p>-3 
-6 
</p>
<p>0 
</p>
<p>This implies that v1 = 3v2/2 and v3 = - 3v2, so that every eigenvector v of 
A with eigenvalue 0 must be of the form 
</p>
<p>Consequently, every solution x=f[&gt;(t) of x=Ax is unstable, since X=O is an 
eigenvalue of multiplicity two and A has only one linearly independent ei-
genvector with eigenvalue 0. 
</p>
<p>EXERCISES 
</p>
<p>Determine the stability or instability of all solutions of the following sys-
tems of differential equations. 
</p>
<p>1. x={ _J _J)x . ( -3 2. x= 2 -4) I X 
3. x=( -s 
</p>
<p>-I nx 4. x=(! -4) -7 X 
( -7 I -6) 
</p>
<p>6. i=U 
2 nx 5. i= I~ -4 Ii X 0 -I 2 
</p>
<p>383 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>1. x=( -1 2 -qx ( -2 I ~)x -3 s. x= -i 2 
I -I -I -2 
</p>
<p>[ 0 
</p>
<p>2 0 
</p>
<p>~]x 10. &middot;~ [ -~ 
2 I 
</p>
<p>~]x . -2 0 0 0 0 9. x= g 0 0 0 0 
0 -2 0 -2 
</p>
<p>11. Determine whether the solutions x(t)=:=O and x(t)= I of the single scalar equa-
tion x = x(I- x) are stable or unstable. 
</p>
<p>12. Determine whether the solutions x(t)=:=O and x(t)= I of the single scalar equa-
tion x = - x(I- x) are stable or unstable. 
</p>
<p>13. Consider the differential equation x = x 2&bull; Show that all solutions x(t) with x(O) 
;;. 0 are unstable while all solutions x(t) with x(O) &lt; 0 are asymptotically stable. 
</p>
<p>14. Consider the system of differential equations 
</p>
<p>(*) 
</p>
<p>(a) Show that 
</p>
<p>x(t)=(x1(t))=(csin(ct+d) ) 
x 2 (t) c2 cos(ct+d) 
</p>
<p>is a solution of (*) for any choice of constants c and d. 
(b) Assurne that a solution x(t) of (*) is uniquely determined once x 1(0) and 
</p>
<p>x2(0) are prescribed. Prove that (a) represents the general solution of (*). 
(c) Show that the solution x=O of (*) is stable, but not asymptotically stable. 
( d) Show that every solution x( t) =ji 0 of (*) is unstable. 
</p>
<p>15. Show that the stability of any solution x( t) of the nonhomogeneaus equation 
x = Ax + f(t) is equivalent to the stability of the equilibrium solution x = 0 of 
the homogeneous equation x = Ax. 
</p>
<p>16. Determine the stability or instability of all solutions x(t) of the differential 
equation 
</p>
<p>. (-I x= 
2 
</p>
<p>17. (a) Let f(t) = t 0e -bt, for some positive constants a and b, and Iet c be a posi-
tive number smaller than b. Show that we can find a positive constant K 
such that Jf(t)J&lt; Ke-c1, 0 &lt; t &lt; oo. Hint: Show that f(t)/ e-ct approaches 
zero as t approaches infinity. 
</p>
<p>(b) Suppose that all the eigenvalues of A have negative real part. Show that we 
can find positive constants K and a suchthat J(eA1)iiJ .;;; Ke-a1 for I&lt; i, 
j.;;; n. Hint: Each component of eA1 is a finite linear combination of func-
tions of the form q(t)e111, where q(t) is a polynomial in t (of degree .;;; n -1) 
and A is an eigenvalue of A. 
</p>
<p>384 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.3 Stability of equilibrium solutions 
</p>
<p>18. (a) Let x(t)= e 1" 1v, o real, be a complex-valued solution of x=Ax. Show that 
both the real and imaginary parts of x( t) are bounded solutions of x = Ax. 
</p>
<p>(b) Suppose that all the eigenvalues of A have real part .;;; 0 and X1 = io1, ... , ~ 
= io1 have zero real part. Let X1 = io1 have multiplicity ki' and suppose that 
A has k1 linearly independent eigenvectors for each eigenvalue X1,} = I, ... ,1. 
Prove that we can find a constant K suchthat l(eA1)!il&lt; K. 
</p>
<p>19. Let 
</p>
<p>and define llxlh = lxd + ... + lxnl&middot; Show that 
(i) llxiii~Oand llxll 1=0onlyifx=O 
</p>
<p>(ii) IIXxll, = IXIIIxll, 
(iii) llx + Yll1 &lt; llxiii + IIYIII 
</p>
<p>20. Let 
</p>
<p>and define llxll2 =[lxd2 + ... + lxnl2] 112&bull; Show that 
(i) llxll2 ~ 0 and llxllz = 0 only if x = 0 
</p>
<p>(ii) IIXxllz = IXIIIxllz 
(iii) llx + Yllz &lt; llxllz + IIYIIz 
</p>
<p>21. Show that there exist constants M and N such that 
</p>
<p>Mllxiii &lt; IIXIIz &lt; Nllxiii&middot; 
</p>
<p>4.3 Stability of equilibrium solutions 
</p>
<p>In Section 4.2 we treated the simple equation x = Ax. The next simplest 
equation is 
</p>
<p>x=Ax+g(x) (1) 
</p>
<p>where 
</p>
<p>g(x)= 
</p>
<p>is very small compared to x. Specifically we assume that 
</p>
<p>g1 (x) gn(x) 
</p>
<p>max{lx1l, ... ,lxnl} , ... , max{lx1l, ... ,lxnl} 
</p>
<p>385 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>are continuous functions of x 1, ... , xn which vanish for x 1 = ... = xn = 0. 
This is always the case if each component of g(x) is a polynomial in 
x 1, &bull;&bull;&bull; ,xn which begins with terms of order 2 or higher. For example, if 
</p>
<p>( x x2) g(x)= 1 2 , 
xlx2 
</p>
<p>then both x1xi/max{lx11, lx21} and x 1x2jmax{lx11, lx21} are continuous 
functions of x 1,x2 which vanish for x 1 =x2=0. 
</p>
<p>If g(O)=O then x(t)=O is an equilibrium solution of (1). We would like 
to determine whether it is stable or unstable. At first glance this would 
seem impossible to do, since we cannot solve Equation (I) explicitly. How-
ever, if x is very small, then g(x) is very small compared to Ax. Therefore, 
it seems plausible that the stability of the equilibrium solution x(t)=O of 
(1) should be determined by the stability of the "approximate" equation 
x = Ax. This is almost the case as the following theorem indicates. 
</p>
<p>Theorem 2. Suppose that the vector-valued function 
</p>
<p>g(x)/llxll =g(x)jmax{ lx1!, &middot; &middot; &middot;, lxnl} 
</p>
<p>is a continuous function of x 1, ... ,xn which vanishes for x=O. Then, 
(a) The equilibrium solution x(t):=O oj (I) is asymptotically stable if the 
equilibrium solution x(t)=O oj the "linearized" equation x=Ax is asymp-
totically stable. Equivalently, the solution x(t)=O of (1) is asymptotically 
stable if all the eigenvalues of A have negative real part. 
(b) The equilibrium solution x(t)=O of (1) is unstable if at least one eigen-
vatue of A has positive real part. 
(c) The stability of the equilibrium solution x(t)=O of (l) cannot be de-
termined from the stability oj the equilibrium solution x( t) = 0 of x = Ax if 
all the eigenvalues oj A have real part ~ 0 but at least one eigenvalue of A 
has zero real part. 
</p>
<p>PROOF. (a) The key step in many stability proofs is to use the variation of 
parameters formula of Section 3.12. This formu1a implies that any solution 
x(t) of (1) can be written in the form 
</p>
<p>(2) 
</p>
<p>We wish to show that llx(t)il approaches zero as t approaches infinity. To 
this end recall that if all the eigenvalues of A have negative real part, then 
we can find positive constants K and a such that (see Exercise 17, Section 
4.2). 
</p>
<p>and 
</p>
<p>lleA(t-&bull;)g(x(s))ll ~ Ke-a(t-s)llg(x(s))ll&middot; 
</p>
<p>386 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.3 Stability of equilibrium solutions 
</p>
<p>Moreover, we can find a positive constant a such that 
</p>
<p>llg(x)ll &lt; 2 ~ llxll if llxll &lt; a. 
</p>
<p>This follows immediately from our assumption that g(x)/llxll is continuous 
and vanishes at x = 0. Consequently, Equation (2) implies that 
</p>
<p>llx(t)ll &lt; lleA1x(O)II + fo11leA(t-s)g(x(s))ll ds 
&lt; Ke-a1 llx(O)II +!!:.. r1e-a(t-s)llx(s)llds 
</p>
<p>2 Jo 
</p>
<p>as long as llx(s)ll &lt; o, 0 &lt; s &lt; t. Multiplying both sides of this inequality by 
eat gives 
</p>
<p>(3) 
</p>
<p>The inequality (3) can be simplified by setting z(t)=ea1 llx(t)ll, for then 
</p>
<p>a (t 
z(t) &lt; Kllx(O)II + 2 Jo z(s)ds. (4) 
</p>
<p>We would like to differentiate both sides of (4) with respect to t. However, 
we cannot, in general, differentiate both sides of an inequality and still pre-
serve the sense of the inequality. We circumvent this difficulty by the 
clever trick of setting 
</p>
<p>Then 
</p>
<p>or 
</p>
<p>a ( 
U(t)= 2 Jo z(s)ds. 
</p>
<p>dU(t) a aK 
----;[(- 2 U(t) &lt; Tllx(O)II&middot; 
</p>
<p>Multiplying both sides of this inequality by the integrating factor e-at/2 
</p>
<p>gives 
</p>
<p>or 
</p>
<p>~e-at/ 2 [ U(t)+KIIx(O)II] &lt;0. 
</p>
<p>Consequently, 
</p>
<p>e-at/2 [ U(t) + Kllx(O)II] &lt; U(O) + Kllx(O)II = Kllx(O)II, 
</p>
<p>387 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>so that U(t)&lt; -KJJx(O)JJ+KIIx(O)JJeat/2&bull; Returning to the inequality (4), 
we see that 
</p>
<p>JJx(t)/1 = e-atz(t) &lt; e-at[ Kllx(O)JI + U (t)] 
.;;;; Kllx(O)IIe-at/2 (5) 
</p>
<p>as long as llx(s)J/ &lt; a, 0 &lt; s &lt; t. Now, if llx(O)II &lt; a I K, then the inequality 
(5) guarantees that llx(t)ll &lt; a for all future time t. Consequently, the in-
equality (5) is true for all t;;;. 0 if llx(O)II &lt; a I K. Finally, observe from (5) 
that llx(t)ll &lt; Kllx(O)II and llx(t)ll approaches zero as t approaches infinity. 
Therefore, the equilibrium solution x(t)=O of (1) is asymptotically stable. 
(b) The proof of (b) is too difficult to present here. 
(c) We will present two differential equations of the form (I) where the 
nonlinear term g(x) determines the stability of the equilibrium solution x(t) 
:=0. Consider first the system of differential equations 
</p>
<p>dxl- 2 2 dt -x2-xl(xl +x2), (6) 
</p>
<p>The linearized equation is 
</p>
<p>and the eigenvalues of the matrix 
</p>
<p>(- ~ ~) 
are &plusmn; i. To analyze the behavior of the nonlinear system (6) we multiply 
the first equation by x 1, the second equation by x2 and add; this gives 
</p>
<p>dxl dx2 _ 2( 2 2) 2( 2 2) 
xl dt +x2 dt - -xl xl +x2 -x2 xl +x2 
</p>
<p>But 
</p>
<p>Hence, 
</p>
<p>This implies that 
</p>
<p>where 
</p>
<p>388 
</p>
<p>= -(xi+x~( 
</p>
<p>xf(t)+x~(t)= -1 c2 ' + ct 
</p>
<p>c = xf(O) + x~(O). </p>
<p/>
</div>
<div class="page"><p/>
<p>4.3 Stability of equilibrium solutions 
</p>
<p>Thus, xf( t) + x~( t) approaches zero as t approaches infinity for any solu-
tion x 1(t), xit) of (6). Moreover, the value of xf+x~ at any timet is al-
ways less than its value at t=O. We conclude, therefore, that x 1(t)=O, xit) 
=0 is asymptotically stable. 
</p>
<p>On the other band, consider the system of equations 
</p>
<p>dxl 2 2 
dt =x2+xi(xi +x2), 
</p>
<p>Here too, the linearized system is 
</p>
<p>x={ _ ~ ~)x. 
</p>
<p>In this case, though, (d/dt)(x?+x~)=2(xf+x~i. This implies that 
</p>
<p>x?(t)+x~(t)= -1 c2 , c=xi(O)+x~(O). - ct 
</p>
<p>(7) 
</p>
<p>Notice that every solution x 1(t), xit) of (7) with xi{O)+ x~(O)#O ap-
proaches infinity in finite time. We conclude, therefore, that the equi-
librium solution x 1(t)=O, x2(t)=O is unstable. D 
</p>
<p>Example 1. Consider the system of differential equations 
</p>
<p>dxl 3 
dt = -2x1+x2+3x3+9x2 
</p>
<p>dx2 5 
dt = -6x2-5x3+7x3 
</p>
<p>dx3 2 2 
dt = -x3+xl +x2. 
</p>
<p>Determine, if possible, whether the equilibrium solution x 1(t)=O, xit)=O, 
xJCt)=O is stable or unstable. 
Solution. We rewrite this system in the form x=Ax+g(x) where 
</p>
<p>[
-2 
</p>
<p>A= ~ 
1 
</p>
<p>-6 
0 
</p>
<p>-~] 
-1 
</p>
<p>and g(x)= 
</p>
<p>9x~ 
</p>
<p>7x~ 
</p>
<p>The function g(x) satisfies the hypotheses of Theorem 2, and the eigenval-
ues of Aare -2, -6 and -1. Hence, the equilibrium solution x(t)=O is 
asymptotically stable. 
</p>
<p>Theorem 2 can also be used to determine the stability of equilibrium 
solutions of arbitrary autonomous differential equations. Let x0 be an 
equilibrium value of the differential equation 
</p>
<p>x=f(x) (8) 
</p>
<p>389 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>and set z(t)=x(t)-x0&bull; Then 
</p>
<p>:i=x=f{x0 +z). (9) 
</p>
<p>Clearly, z(t)=O is an equilibrium solution of (9) and the stability of x(t)= 
x0 is equivalent to the stability of z(t):=O. 
</p>
<p>Next, we show that f(x0 +z) can be written in the form f(x0 +z)=Az+ 
g(z) where g(z) is small compared to z. 
</p>
<p>Lemma 1. Let f(x) have two continuous partial derivatives with respect to 
each of its variables x 1, &bull;.&bull; ,xn. Then, f(x0 + z) can be written in the form 
</p>
<p>f(x0 + z) = f(x0) + Az + g(z) (10) 
</p>
<p>where g(z)jmax{lz1!, ... ,1znl} is a continuousfunction ofz which vanishes 
for z=O. 
</p>
<p>PROOF # 1. Equation (10) is an immediate consequence of Taylor's Theo-
rem which states that each component Jj(x0 + z) of f(x0 + z) can be written 
in the form 
</p>
<p>aij (x0) aij (x0) 
Jj(x0 +z)= Jj(x0)+ -a-z 1 + ... + -a-zn+g/z) 
</p>
<p>XI Xn 
</p>
<p>where ~(z)jmax{iz 1 1, ... , izni} is a continuous function of z which vanishes 
for z = 0. Hence, 
</p>
<p>f(x0 + z) = f(x0) + Az + g(z) 
</p>
<p>where 
</p>
<p>ajl (xo) ajl (xo) 
</p>
<p>axl axn 
</p>
<p>A= 0 
</p>
<p>ajn (x0) ajn (xo) 
</p>
<p>axl axn 
</p>
<p>PRooF #2. If each component of f(x) is a polynomial (possib1y infinite) in 
x 1, &bull;&bull;&bull; , xn, then each component of f(x0 + z) is a po1ynomia1 in z 1, &bull;&bull;&bull; , zn. 
Thus, 
</p>
<p>Jj (x0 +z) = ~ 0 + a11 z1 + ... + a1nzn + ~(z) (11) 
</p>
<p>where ~(z) is a po1ynomia1 in z1, &bull;&bull;&bull; ,zn beginning with terms of order two. 
Setting z=O in (11) gives Jj(x~ = a10. Hence, 
</p>
<p>f(x0 + z) = f(x0) + Az + g(z), 
</p>
<p>390 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.3 Stability of equilibrium solutions 
</p>
<p>and each component of g(z) is a polynomial in z1, &bull;&bull;&bull; ,zn beginning with 
terms of order two. D 
</p>
<p>Theorem 2 and Lemma I provide us with the following algorithm for 
determining whether an equilibrium solution x(t)=x0 of i=f(x) is stable 
or unstable: 
</p>
<p>I. Set z=x-x0&bull; 
2. Write f(x0 + z) in the form Az + g(z) where g(z) is a vector-valued poly-
</p>
<p>nomial in z1, &bull;&bull;&bull; ,zn beginning with terms of order two or more. 
3. Compute the eigenvalues of A. If all the eigenvalues of A have negative 
</p>
<p>real part, then x(t)=x0 is asymptotically stable. If one eigenvalue of A 
has positive real part, then x( t) = x0 is unstable. 
</p>
<p>Example 2. Find all equilibrium solutions of the system of differential 
equations 
</p>
<p>dx 
dt =I-xy, 
</p>
<p>dy 3 -=x-y 
dt 
</p>
<p>and determine (if possible) whether they are stable or unstable. 
</p>
<p>(12) 
</p>
<p>Solution. The equations I - xy = 0 and x- y 3 = 0 imply that x = I, y = I or 
x =-I, y = -1. Hence, x(t)= I, y(t)= I, and x(t)= -I, y(t)=- I are the 
oniy equiiibrium soiutions of (I2). 
</p>
<p>(i) x(t)= I,y(t)= I: Set u=x-I, v=y-1. Then, 
du dx 
dt = dt = I - (I + u )(I +V)= - u- V- uv 
</p>
<p>~~ = ~ =(I+u)-(I+v)3=u-3v-3v2 -v3&bull; 
We rewrite this system in the form 
</p>
<p>The matrix 
</p>
<p>(-: -I) -3 
has a single eigenvalue A = -2 since 
</p>
<p>d ( -I-A. et I 
</p>
<p>Hence, the equilibrium solution x(t)= I, y(t)= I of (I2) is asymptotically 
stable. 
</p>
<p>(ii) x(t)= -I,y(t)= -I: Set u=x+ I, v=y+ I. Then, 
du dx 
dt = dt = I - ( u- I)( V- I) = u + V - uv 
</p>
<p>dv dy 3 2 3 
- =- =(u-I)-(v-I) = u-3v+3v -v dt dt . 
</p>
<p>391 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>We rewrite this system in the form 
</p>
<p>~(~)=( ~ _j)(~)+(3~~vv 3 ). 
The eigenvalues of the matrix 
</p>
<p>are ;\1 = - 1- V5 , which is negative, and ;\2 = - 1 + V5 , which is positive. 
Therefore, the equilibrium solution x(t)= -1, y(t)= -1 of (12) is unsta-
ble. 
</p>
<p>Example 3. Find all equilibrium solutions of the system of differential 
equations 
</p>
<p>dx . ( ) dt =sm x+y, 
dy 
- =ex-1 
dt 
</p>
<p>and determine whether they are stable or unstable. 
</p>
<p>(13) 
</p>
<p>Solution. The equilibrium points of (13) are determined by the two equa-
tions sin(x+ y)=O and ex -1 =0. The second equation implies that x=O, 
while the first equation implies that x + y = mr, n an integer. Consequently, 
x(t)=:O, y(t)= mr, n = 0, &plusmn; 1, &plusmn; 2, ... , are the equilibrium solutions of (13). 
Setting u = x, v = y- n'7T, gives 
</p>
<p>du . ( ) dt = sm u + v + n'7T , ~~ =e"-1. 
</p>
<p>Now, sin(u + v + n77)=cosn'7Tsin(u + v)=( -ltsin(u + v). Therefore, 
</p>
<p>~~ = ( -l)nsin(u+ v), ~~ = e" -1. 
</p>
<p>Next, observe that 
</p>
<p>(u+v) 3 
sin(u+v)=u+v- 3, + ... , 
</p>
<p>u2 
e" -1 = u + 2! + .... 
</p>
<p>Hence, 
</p>
<p>du n [ ( U +V )
3 l 
</p>
<p>dt = (- 1) ( U + V) - 3! + .. . ' 
</p>
<p>We rewrite this system in the form 
</p>
<p>fi(u)=((-l)n 
dt V 1 
</p>
<p>( -l)n )( ~) + terms of order 2 or 
0 higher in u and v. 
</p>
<p>The eigenvalues of the matrix 
</p>
<p>((-/)n (-Ol)n) 
</p>
<p>392 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.3 Stability of equilibrium solutions 
</p>
<p>are 
</p>
<p>When n is even, A1 =(1- V5 )/2 is negative and A2 =(1 + V5 )/2 is posi-
tive. Hence, x(t)=O,y(t)=mr is unstable if n is even. When n is odd, both 
A1 = (- 1- V3 i) /2 and A2 = (- 1 + V3 i) /2 have negative real part. There-
fore, the equilibrium solution x( t) = 0, y (t) = mr is asymptotically stable if 
n is odd. 
</p>
<p>EXERCISES 
</p>
<p>Find all equilibrium solutions of each of the following systems of equa-
tions and determine, if possible, whether they are stable or unstable. 
</p>
<p>I. x=x-x3-xy2 
j=2y-ys-yx4 
</p>
<p>4. x=6x-6x2-2xy 
j=4y-4y2-2xy 
</p>
<p>2 &bull; .X=x2+y2-J 
j=x2-y2 
</p>
<p>5. x=tan(x+y) 
j=x+x3 
</p>
<p>3. x=x2+ y 2 -1 
j=2xy 
</p>
<p>6. x=eY-x 
j=ex+y 
</p>
<p>Verify that the origin is an equilibrium point of each of the following sys-
tems of equations and determine, if possible, whether it is stable or unsta-
ble. 
</p>
<p>7. x=y+3x2 
</p>
<p>j=x-3y2 
</p>
<p>10. x=Jn(1 +X+ y 2) 
j= -y+x3 
</p>
<p>12. x=8x-3y+eY-1 
j=sinx2-1n(1- x-y) 
</p>
<p>14. x=x-y+z2 
</p>
<p>j=y+z-x2 
</p>
<p>i=z-x+y2 
</p>
<p>16 &bull; .X=ln(1-z) 
j=ln(1-x) 
i=ln(1-y) 
</p>
<p>8. x=y +cosy -1 
j= -sinx+x3 
</p>
<p>9.x=ex+y_1 
j=sin(x+y) 
</p>
<p>II &bull; .X=cosy-sinx-1 
j=x-y-y2 
</p>
<p>13. x= -x-y-(x2+y2)312 
j= x-y +(x2+ y2)3/2 
</p>
<p>15. x= ex+y+z -1 
</p>
<p>j=sin(x+y+z) 
i=x-y-z2 
</p>
<p>17. x=x-cosy-z+ 1 
j=y-cosz-x+ 1 
i=z-cosx-y+1 
</p>
<p>18 (a) Findall equilibrium solutions of the system of differential equations 
</p>
<p>dx -=gz-hx 
dt ' 
</p>
<p>dy c 
dt = a+bx -ky, 
</p>
<p>dz - =ey-jz. 
dt . 
</p>
<p>(fhis system is a model for the contro1 of protein synthesis.) 
(b) Determine the stability or instability of these solutions if either g, e, or c is 
</p>
<p>zero. 
</p>
<p>393 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>4.4 The phase-plane 
</p>
<p>In this section we begin our study of the "geometric" theory of differential 
equations. For simplicity, we will restriet ourselves, for the most part, tc 
the case n = 2. Our aim is to obtain as complete a description as possible ol 
all solutions of the system of differential equations 
</p>
<p>~~ =J(x,y), 
dy 
dt =g(x,y). {1) 
</p>
<p>Tothis end, observe that every solution x=x(t),y=y(t) of (I) defines a 
curve in the three-dimensional space t,x,y. That is to say, the set of all 
points (t,x(t),y(t)) describe a curve in the three-dimensional space t,x,y. 
For example, the solution x = cos t, y = sin t of the system of differential 
equations 
</p>
<p>dx dy 
dt = -y, -=x dt 
</p>
<p>describes a helix (see Figure 1) in (t,x,y) space. 
The geometric theory of differential equations begins with the important 
</p>
<p>observation that every solution x=x(t),y=y(t), t0 &lt;. t&lt;. 11, of (1) also de-
fines a curve in the x-y plane. To wit, as t runs from t0 to t 1, the set of 
points (x(t),y(t)) trace out a curve C in the x- y plane. This curve is 
called the orbit, or trajectory, of the solution x = x(t),y = y(t), and the x-y 
plane is called the phase-plane of the solutions of (1). Equivalently, we can 
think of the orbit of x(t), y(t) as the path that the solution traverses in the 
x-y plane. 
</p>
<p>y 
</p>
<p>Figure 1. Graph of the solution x = cos t, y = sin t 
</p>
<p>Example 1. It is easily verified that x = cos t, y = sin t is a solution of the 
system of differential equations x =-y, y = x. As t runs from 0 to 277, the 
set of points (cos t, sin t) trace out the unit circle x2 + y 2 = 1 in the x- y 
plane. Hence, the unit circle x 2 + y 2 = 1 is the orbit of the solution 
x=cost, y=sint, 0&lt;. t&lt;.2TT. Ast runs from 0 to oo, the set of points 
(cost,sint) trace out this circle infinitely often. 
</p>
<p>394 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.4 The phase-plane 
</p>
<p>Example 2. It is easily verified that x = e- 1 cost, y = e- 1 sint, - oo &lt; t &lt; oo, 
is a solution of the system of differential equations dx I dt = - x-y, dy I dt 
=x-y. Astruns from -oo to oo, the set of points (e- 1 cost,e- 1 sint) 
trace out a spiral in the x - y plane. Hence, the orbit of the solution 
x = e- 1 cos t, y = e- 1 sin t is the spiral shown in Figure 2. 
</p>
<p>y 
</p>
<p>Figure 2. Orbit of x = e- 1 cost, y = e- 1 sint 
</p>
<p>Example 3. It is easily verified that x = 3t + 2, y = 5t + 7, - oo &lt; t &lt; oo is a 
solution of the system of differential equations dx I dt = 3, dy I dt = 5. As t 
runs from - oo to oo, the set of points (3t + 2, 5t + 7) trace out the straight 
line through the point (2, 7) with slope t&middot; Hence, the orbit of the solution 
x=3t+2,y=5t+7 is the straight liney=i(x-2)+7, -oo&lt;x&lt;oo. 
</p>
<p>Example 4. It is easily verified that x=3t2 +2, y=5t2 +7, O.;;; t&lt;oo is a 
solution of the system of differential equations 
</p>
<p>~~ =6[(y-7)1sr12, ~ =w[&lt;x-2)13r12. 
All of the points (3t2 +2,5t2 +7) lie on the line through (2,7) with slope t&middot; 
However, x is always greater than or equal to 2, and y is always greater 
than or equal to 7. Hence, the orbit of the solution x=3t2+2,y=5t2 +7, 
0.;;;; t &lt; oo, is the straight line y = 1&lt;x- 2)+ 7, 2.;;;; x &lt; oo. 
</p>
<p>Example 5. lt is easily verified that x = 3t + 2, y = 5t2 + 7, - oo &lt; t &lt; oo, is a 
solution of the system of differential equations 
</p>
<p>dy 10 
dt = T(x- 2)&middot; 
</p>
<p>395 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>The orbit of this solution is the set of all points (x,y) = (31 + 2, 512 + 7). 
Solving for l=~(x-2), we see thaty= ~(x-2f+7. Hence, the orbit of the 
solution x =31+2, y =512 + 7 is the parabola y = ~(x- 2)2+7, lxl &lt; oo. 
</p>
<p>One of the advantages of considering the orbit of the solution rather 
than the solution itself is that is is often possible to obtain the orbit of a 
solution without prior knowledge of the solution. Let x = x( 1), y = y( I) be a 
solution of (1). If x'(t) is unequal to zero at t= t1, then we can solve for 
I= t(x) in a neighborhood of the point x1 = x(t1) (see Exercise 4). Thus, for 
I near 11&bull; the orbit of the solution x(t), y(l) is the curve y = y(l(x)). Next, 
observe that 
</p>
<p>dy dy dt dyjdt g(x,y) 
</p>
<p>dx = dl dx = dx/ dt = f(x,y) &middot; 
</p>
<p>Thus, the orbits of the solutions x = x(t), y = y(l) of (I) are the solution 
curves of the first-order scalar equation 
</p>
<p>dy g(x,y) 
</p>
<p>dx = j(x,y) &middot; 
{2) 
</p>
<p>Therefore, it is not necessary to find a solution x(l), y(t) of (1) in order to 
compute its orbit; we need only solve the single first-order scalar differen-
tial equation (2). 
</p>
<p>Remark. From now on, we will use the phrase "the orbits of (I)" to denote 
the totality of orbits of solutions of (I). 
</p>
<p>Example 6. The orbits of the system of differential equations 
</p>
<p>dx _ 2 dy =x2 
dl -y' dt {3) 
</p>
<p>are the solution curves of the scalar equation dy / dx = x2 jy2&bull; This equation 
is separable, and it is easily seen that every solution is of the formy(x)= 
(x3 - c)113, c constant. Thus, the orbits of (3) are the set of all curves 
y = (x3 _ c)I/3. 
</p>
<p>Example 7. The orbits of the system of differential equations 
</p>
<p>dx =y(I+x2+y 2) dy = -2x(l+x2 +y2) {4) 
dt ' dl 
</p>
<p>are the solution curves of the scalar equation 
</p>
<p>dy 2x(I + x2+ y2) 2x 
</p>
<p>dx =- y(I +x2+y2) =- -y 
</p>
<p>This equation is separable, and all solutions are of the form iY 2 + x2 = c2&bull; 
Hence, the orbits of (4) are the families of ellipses iy2+x2=c2. 
</p>
<p>396 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.4 The phase-plane 
</p>
<p>Warning. A solution curve of (2) is an orbit of (l) only if dx I dt and dy I dt 
are not zero simultaneously along the solution. If a solution curve of (2) 
passes through an equilibrium point of (1), then the entire solution curve is 
not an orbit. Rather, it is the union of several distinct orbits. For example, 
consider the system of differential equations 
</p>
<p>dx = y(l- x2-y2) dy =- x(I- x2-y2). (5) 
dt ' dt 
</p>
<p>The solution curves of the scalar equation 
</p>
<p>dy dyldt X 
dx = dx I dt = - y 
</p>
<p>are the family of concentric circles x 2 + y 2 = c2. Observe, however, that ev-
ery point on the unit circle x 2 + y 2 = 1 is an equilibrium point of (5). Thus, 
the orbits of this system are the circles x 2 +y 2 =c2, for c"el, and all points 
on the unit circle x 2 + y 2 = 1. Similarly, the orbits of (3) are the curves y = 
(x3 -c)113, c"eO; the half-linesy=x, x&gt;O, andy=x, x&lt;O; and the point 
(0,0). 
</p>
<p>It is not possible, in general, to explicitly solve Equation (2). Hence, we 
cannot, in general, find the orbits of (1). Nevertheless, it is still possible to 
obtain an accurate description of all orbits of (1). This is because the sys-
tem of differential equations (1) sets up a direction field in the x-y plane. 
That is to say, the system of differential equations (1) tells us how fast a 
solution moves along its orbit, and in what direction it is moving. More 
precisely, Iet x = x(t), y = y(t) be a solution of (1). As t increases, the point 
(x(t),y(t)) moves along the orbit of this solution. Its velocity in the x-di-
rection is dx I dt; its velocity in the y-direction is dy I dt; and the magnitude 
of its velocity is [(dx(t)l dti +(dy(t)l dt)2] 112&bull; But dx(t)l dt = f(x(t), y(t)), 
and dy(t)l dt = g(x(t), y(t)). Hence, at each point (x,y) in the phase plane 
of (1) we know (i), the tangent to the orbit through (x,y) (the line through 
(x, y) with direction numbers f(x, y), g(x, y) respectively) and (ii), the 
speed [J 2(x, y)+ g 2(x, y)] 112 with which the solution is traversing its orbit. 
As we shall see in Sections 4.8-13, this information can often be used to 
deduce important properties of the orbits of (1). 
</p>
<p>The notion of orbit can easily be extended to the case n &gt; 2. Let x = x( t) 
be a solution of the vector differential equation 
</p>
<p>ft (X I' &middot; &middot; &middot; 'xn) 
x=f(x), f(x)= (6) 
</p>
<p>on the interval t0 &lt; t &lt; t 1&bull; As t runs from t0 to t 1, the set of points 
(x 1(t), ... ,xn(t)) trace out a curve C in the n-dimensional space 
x 1,x2, &bull;&bull;&bull; ,xn. This curve is called the orbit of the solution x=x(t), for t 0 ~ t 
&lt; t 1, and the n-dimensional space x 1, &bull;&bull;&bull; , xn is called the phase-space of the 
solutions of (6). 
</p>
<p>397 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>EXERCISES 
</p>
<p>In each of Problems l-3, verify that x(t),y(t) is a solution of the given sys-
tem of equations, and find its orbit. 
</p>
<p>1. x = l, y = 2(1- x)sin(l- x)2 
x(t)=l+t, y(t)=cost2 
</p>
<p>2. x=e-X, y=e&middot;X-( 
</p>
<p>x(t)=1n(1+t), y(t)=e 1 
</p>
<p>3. x=1+x2, y=(1+x2)sec2x 
x(t)=tant, y(t)=tan(tant) 
</p>
<p>4. Suppose that x'(t1)7to0. Show that we can solve the equation x=x(t) fort= 
t(x) in a neighborhood of the point x 1 =x(t1). Hint: If x'(t1)7to0, then x(t) is a 
strictly monotonic function of t in a neighborhood of t = t 1&bull; 
</p>
<p>Find the orbits of each of the following systems. 
</p>
<p>s. x=y, 
y=-x 
</p>
<p>7. x=y(1 +x+y), 
y= -x(1 +x+y) 
</p>
<p>9. x=xye- 3x, 
y= -2xy2 
</p>
<p>11. x=ax-bxy, 
y=cx-dxy 
(a,b,c,d positive) 
</p>
<p>13. x=2xy, 
y=x2-y2 
</p>
<p>6. x= y(1 + x 2+ y 2), 
y= -x(1 +x2+ y 2) 
</p>
<p>8. x=y+x:Y, 
y=3x+xy2 
</p>
<p>10. x=4y, 
y=x+xy2 
</p>
<p>12. x = x 2 + cosy, 
y= -2xy 
</p>
<p>14. x=y+sinx, 
y=x-ycosx 
</p>
<p>4.5 Mathematical theories of war 
</p>
<p>4.5.1. L. F. Richardson's theory of conflict 
</p>
<p>In this section we construct a mathematical model which describes the re-
lation between two nations, each determined to defend itself against a pos-
sible attack by the other. Each nation considers the possibility of attack 
quite real, and reasonably enough, bases its apprehensions on the readiness 
of the other to wage war. Our model is based on the work of Lewis Fry 
Richardson. It is not an attempt to make scientific Statements about fore-
ign politics or to predict the date at which the next war will break out. 
This, of course, is clearly impossible. Rather, it is a description of what 
people would do if they did not stop to think. As Richardson writes: "Why 
are so many nations reluctantly but steadily increasing their armaments as 
if they were mechanically compelled to do so? Because, I say, they follow 
their traditions which are fixtures and their instincts which are mechanical; 
</p>
<p>398 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.5 Mathematical theories of war 
</p>
<p>and because they have not yet made a sufficiently strenuous intellectual 
and moral effort to control the situation. The process described by the en-
suing equations is not to be thought of as inevitable. lt is what would occur 
if instinct and tradition were allowed to act uncontrolled." 
</p>
<p>Let x = x ( t) denote the war potential, or armaments, of the first nation, 
which we will call Jedesland, and Iet y(t) denote the war potential of the 
second nation, which we will call Andersland. The rate of change of x(t) 
depends, obviously, on the war readiness y(t) of Andersland, and on the 
grievances that Jedesland feels towards Andersland. In the most simplistic 
model we represent these terms by ky and g respectively, where k and g 
are positive constants. These two terms cause x to increase. On the other 
hand, the cost of armaments has a restraining effect on dx/ dt. We repre-
sent this term by - ax, where a is a positive constant. A similar analysis 
holds for dy / dt. Consequently, x = x(t), y = y(t) is a solution of the linear 
system of differential equations 
</p>
<p>dx 
dt =ky-ax+g, 
</p>
<p>dy 
dt =lx-&szlig;y+h. (I) 
</p>
<p>Remark. The model (l) is not limited to two nations; it can also represent 
the relation between two alliances. For example, Andersland and Jedes-
land can represent the alliances of France with Russia, and Germany with 
Austria-Hungary during the years immediately prior to World War I. 
</p>
<p>Throughout history, there has been a constant debate on the cause of 
war. Over two thousand years ago, Thucydides claimed that armaments 
cause war. In his account of the Peloponnesian war he writes: "The real 
though unavowed cause I believe to have been the growth of Athenian 
power, which terrified the Lacedaemonians and forced them into war." Sir 
Edward Grey, the British Foreign Secretary during World War I agrees. 
He writes: "The increase of armaments that is intended in each nation to 
produce consciousness of strength, and a sense of security, does not pro-
duce these effects. On the contrary, it produces a consciousness of the 
strength of other nations and a sense of fear. The enormous growth of 
armaments in Europe, the sense of insecurity and fear caused by them-it 
was these that made war inevitable. This is the real and final account of 
the origin of the Great War." 
</p>
<p>On the other hand, L. S. Amery, a member of Britain's parliament 
during the 1930's vehemently disagrees. When the opinion of Sir Edward 
Grey was quoted in the House of Commons, Amery replied: "With all due 
respect to the memory of an eminent statesman, I believe that statement to 
be entirely mistaken. The armaments were only the symptoms of the con-
flict of ambitions and ideals, of those nationalist forces which created the 
War. The War was brought about because Serbia, ltaly and Rumania 
passionately desired the incorporation in their states of territories which at 
</p>
<p>399 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>that time belonged to the Austrian Empire and which the Austrian govem-
ment was not prepared to abandon without a struggle. France was pre-
pared, if the opportunity ever came, to make an effort to recover Alsace-
Lorraine. lt was in those facts, in those insoluble conflicts of ambitions, 
and not in the armaments themselves, that the cause of the War lay." 
</p>
<p>The system of equations (1) takes both conflicting theories into account. 
Thucydides and Sir Edward Grey would take g and h small compared to k 
and /, while Mr. Amery would take k and I small compared to g and h. 
</p>
<p>The system of equations (1) has several important implications. Suppose 
that g and h are both zero. Then, x(t)=O, y(t)=O is an equilibrium solu-
tion of (1). That is, if x, y, g, and h are all made zero simultaneously, then 
x(t) and y(t) will always remain zero. This ideal condition is permanent 
peace by disarmament and satisfaction. lt has existed since 1817 on the 
border between Canada and the United States, and since 1905 on the 
border between Norway and Sweden. 
</p>
<p>These equations further imply that mutual disarmament without satis-
faction is not permanent. Assurne that x and y vanish simultaneously at 
some time t = t0&bull; At this time, dx I dt = g and dy I dt = h. Thus, x and y will 
not remain zero if g and h are positive. Instead, both nations will rearm. 
</p>
<p>Unilateral disarmament corresponds to setting y = 0 at a certain instant 
of time. At this time, dy I dt = lx + h. This implies that y will not remain 
zero if either h or x is positive. Thus, unilateral disarmament is never per-
manent. This accords with the historical fact that Germany, whose army 
was reduced by the Treaty of Versailles to 100,000 men, a Ievel far below 
that of several of her neighbors, insisting on rearming during the years 
1933-36. 
</p>
<p>A race in armaments occurs when the "defense" terms predominate in 
(1). In this case, 
</p>
<p>dx 
dt=ky, 
</p>
<p>dy 
dt = lx. (2) 
</p>
<p>Every solution of (2) is of the form 
</p>
<p>y(t)=Vf [Aevk/ 1 -Be-vk/ 1 ]. 
</p>
<p>Therefore, both x(t) and y(t) approach infinity if A is positive. This infin-
ity can be interpreted as war. 
</p>
<p>Now, the system of equations (1) is not quite correct, since it does not 
take into effect the cooperation, or trade, between Andersland and Jedes-
land. As we see today, mutual cooperation between nations tends to de-
crease their fears and suspicions. We correct our model by changing the 
meaning of x(t) and y(t); we let the variables x(t) and y(t) stand for 
"threats" minus "cooperation." Specifically, we set x = U- U0 and y = 
V- V0 , where U is the defense budget of Jedes1and, V is the defense 
budget of Andersland, U0 is the amount of goods exported by Jedesland to 
</p>
<p>400 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.5 Mathematical theories of war 
</p>
<p>Andersland and V0 is the amount of goods exported by Andersland to 
Jedesland. Observe that cooperation evokes reciprocal cooperation, just as 
armaments provoke more armaments. In addition, nations have a tendency 
to reduce cooperation on account of the expense which it involves. Thus, 
the system of equations (I) still describes this more general state of affairs. 
</p>
<p>The system of equations (I) has a single equilibrium solution 
</p>
<p>kh+&szlig;g 
x = Xo = a&szlig;- kl ' 
</p>
<p>lg+ah 
y=yo= a&szlig;-kl (3) 
</p>
<p>if a&szlig;- kr=l= 0. We are interested in determining whether this equilibrium 
solution is stable or unstable. Tothis end, we write (I) in the form w=Aw 
+f, where 
</p>
<p>( x(t)) w(t)= y(t) , 
</p>
<p>The equilibrium solution is 
</p>
<p>w=w0 = ( ~:). 
</p>
<p>where Aw0 +f=O. Setting z=w-w0, we obtain that 
</p>
<p>z =w= Aw + f= A(z +w0) + f= Az+ Aw0 + f=Az. 
Clearly, the equilibrium solution w(t)=w0 of w=Aw+f is stable if, and 
only if, z = 0 is a stable solution of z = Az. To determine the stability of z = 
0 we compute 
</p>
<p>p (;\) = det( - al- A 
</p>
<p>The roots of p(A) are 
</p>
<p>_ ; _ ;\ ) = ;\ 2 + ( a + &szlig; );\ + a&szlig;- kl. 
</p>
<p>- ( a + &szlig;) &plusmn; [ ( a + &szlig; )2 - 4( a&szlig;- kl) J 112 
;\= 2 
</p>
<p>- ( a + &szlig; ) &plusmn; [ ( a - &szlig; )2 + 4kl J 112 
</p>
<p>2 
Notice that both roots are real and unequal to zero. Moreover, both roots 
are negative if a&szlig;- kl &gt; 0, and one root is positive if a&szlig;- kl &lt; 0. Thus, z( t) 
=0, and consequently the equilibrium solution x(t)=x0,y(t)=y0 is stable 
if a&szlig;- kl &gt; 0 and unstable if a&szlig;- kl &lt; 0. 
</p>
<p>Let us now tackle the difficult problern of estimating the coefficients a, 
&szlig;, k, I, g, and h. There is no way, obviously, of measuring g and h. How-
ever, it is possible to obtain reasonable estimates for a, &szlig;, k, and /. Observe 
that the units of these coefficients are reciprocal times. Physicists and en-
gineers would call a - 1 and &szlig; - 1 relaxation times, for if y and g were identi-
cally zero, then x(t) = e-a(t-to&gt;x(t0). This implies that x(t0 + a -I)= 
</p>
<p>401 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>x(t0)je. Hence, a- 1 is the time required for Jedesland's armaments tobe 
reduced in the ratio 2.718 if that nation has no grievances and no other na-
tion has any armaments. Richardson estimates a- 1 to be the lifetime of 
Jedesland's parliament. Thus, a = 0.2 for Great Britain, since the lifetime of 
Britain's parliament is five years. 
</p>
<p>To estimate k and l we take a hypothetical case in which g = 0 and y = 
y 1, so that dxjdt=ky 1-ax. When x=O, 1/k=y1/(dxjdt). Thus, 1/k is 
the time required for Jedesland to catch up to Andersland provided that (i) 
Andersland's armaments remain constant, (ii) there are no grievances, and 
(iii) the cost of armaments doesn't slow Jedesland down. Consider now the 
German rearmament during 1933-36. Germany started with nearly zero 
armaments and caught up with her neighbors in about three years. Assum-
ing that the slowing effect of a nearly balanced the Germans' very strong 
grievances g, we take k = 0.3 (year) -I for Germany. Further, we observe 
that k is obviously proportional to the amount of industry that a nation 
has. Thus, k = 0.15 for a nation which has only half the industrial capacity 
of Germany, and k = 0.9 for a nation which has three times the industrial 
capacity of Germany. 
</p>
<p>Let us now check our model against the European arms race of 
1909-1914. France was allied with Russia, and Germany was allied with 
Austria-Hungary. Neither ltaly or Britain was in a definite alliance with 
either party. Thus, let Jedesland represent the alliance of France with 
Russia, and let Andersland represent the alliance of Germany with 
Austria-Hungary. Since these two alliances were roughly equal in size we 
take k = !, and since each alliance was roughly three times the size of 
Germany, we take k=/=0.9. We also assume that a=&szlig;=0.2. Then, 
</p>
<p>dx dy 
dt = - ax + ky + g, dt = kx- ay + h. ( 4) 
</p>
<p>Equation (4) has a unique equilibrium point 
</p>
<p>kh+ag 
X-o- 2 k2' a -
</p>
<p>This equilibrium is unstable since 
</p>
<p>kg+ah 
Yo= 2 k2 . a-
</p>
<p>a&szlig;- kl= a 2 - k2 =0.04-0.81 = -0.77. 
</p>
<p>This, of course, is in agreement with the historical fact that these two alli-
ances went to war with each other. 
</p>
<p>Now, the model we have constructed is very crude since it assumes that 
the grievances g and h are constant in time. This is obviously not true. The 
grievances g and h are not even continuous functions of time since they 
jump instantaneously by 1arge amounts. (It's safe to assume, though, that g 
and h are relatively constant over long periods of time.) In spite of this, the 
system of equations (4) still provides a very accurate description of the 
arms race preceding World War I. To demonstrate this, we add the two 
</p>
<p>402 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.5 Mathematica1 theories of war 
</p>
<p>equations of (4) together, to obtain that 
</p>
<p>d 
dt (X+ y) = ( k- CX )(X+ y) + g + h. (5) 
</p>
<p>Recall that x = U- U0 and y = V- V0, where U and V are the defense 
budgets of the two alliances, and U0 and V0 are the amount of goods ex-
ported from each alliance to the other. Hence, 
</p>
<p>The defense budgets for the two alliances are set out in Table I. 
</p>
<p>Table I. Defense budgets expressed in millions of &euro; ster-
ling 
</p>
<p>1909 1910 1911 1912 1913 
</p>
<p>France 48.6 50.9 57.1 63.2 74.7 
Russia 66.7 68.5 70.7 81.8 92.0 
</p>
<p>Germany 63.1 62.0 62.5 68.2 95.4 
Austria-Hungary 20.8 23.4 24.6 25.5 26.9 
</p>
<p>Tota1U+V 199.2 204.8 214.9 238.7 289.0 
d(U+ V) 5.6 10.1 23.8 50.3 
</p>
<p>u + V at same date 202.0 209.8 226.8 263.8 
</p>
<p>In Figure 1 we plot the annua1 increment of U + V against the average 
of U + V for the two years used in forming the increment. Notice how 
close these four points, denoted by o, are to the straight line 
</p>
<p>d(U+ V)=0.73(U+ V-194). (7) 
</p>
<p>Thus, foreign politics does indeed have a machine-1ike predictabi1ity. 
Equations (6) and (7) imply that 
</p>
<p>g+h=(k-a)(U0 + V0 )-d(U0 + V0 )-194 
</p>
<p>and k- a = 0.73. This is in excellent agreement with Richardson's esti-
mates of 0.9 for k and 0.2 for a. Finally, observe from (7) that the total de-
fense budgets of the two alliances will increase if U + V is greater than 194 
million, and will decrease otherwise. In actual fact, the defense expendi-
tures of the two alliances was 199.2 million in 1909 while the trade between 
the two alliances amounted to only 171.8 million. Thus began an arms race 
which led eventually to World War I. 
</p>
<p>403 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>&gt; 30 
+ 
:::) 
</p>
<p>&lt;J 20 
</p>
<p>o~L-J---~----~--J---~----~--J----J 
</p>
<p>190 200 210 220 230 240 250 260 270 
u~v 
</p>
<p>Figure 1. Graph of d( U + V) versus U + V 
</p>
<p>Rejerence 
Richardson, L. F ., "Generalized foreign politics," The British Journal of Psychol-
</p>
<p>ogy, monograph supplement #23, 1939. 
</p>
<p>ExERCISES 
</p>
<p>1. Suppose that what moves a government to arm is not the magnitude of other na-
tions' armaments, but the difference between its own and theirs. Then, 
</p>
<p>'!;; =k(y-x)-ax+g, dy dt =l(x-y)-&szlig;y+h. 
Show that every solution of this system of equations is stable if k1/ 1 &lt; (a 1 + 
k 1)( &szlig;1 + /1) and unstable if k1/ 1 &gt; (a 1 + k1)( &szlig;1 + /1). 
</p>
<p>2. Consider the case of three nations, each having the same defense coefficient k 
and the same restraint coefficient a. Then, 
</p>
<p>dx 
dt = -ax+ky+kz+g1 
dy 
dt = kx- ay + kz + g2 
</p>
<p>dz 
dt =kx+ky-az+g3&bull; 
</p>
<p>Setting 
</p>
<p>u=(~)&middot; (
-a 
</p>
<p>A= z 
k 
</p>
<p>-a 
k 
</p>
<p>we see that u=Au+g. 
(a) Show thatp(A)=det(A-AI)= -(a+A)3 +3k2(a+A)+2k3&bull; 
(b) Show that p(A) = 0 when A = - a- k. Use this information to find the re-
maining two roots of p(A). 
</p>
<p>404 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.5 Mathematical theories of war 
</p>
<p>(c) Show that every solution u(t) is stable if 2k &lt; a, and unstable if 2k &gt; a. 
~. Suppose in Problem 2 that the z nation is a pacifist nation, while x and y are 
</p>
<p>pugnacious nations. Then, 
</p>
<p>dx 
dt = -ax+ky+kz+gi 
</p>
<p>: =kx-ay+kz+g2 
</p>
<p>dz 
dt =0&middot;x+O&middot;y-az+g3&bull; 
</p>
<p>(*) 
</p>
<p>Show that every solution x(t),y(t),z(t) of (*) is stable if k &lt; a, and unstable if 
k&gt;a. 
</p>
<p>4.5.2 Lanchester's combat models and the battle of /wo Jima 
</p>
<p>During the first World War, F. W. Lanchester [4) pointed out the impor-
tance of the concentration of troops in modern combat. He constructed 
mathematical models from which the expected results of an engagement 
could be obtained. In this section we will derive two of these models, that 
of a conventional force versus a conventional force, and that of a conven-
tional force versus a guerilla force. We will then solve these models, or 
equations, and derive "Lanchester's square law," which states that the 
strength of a combat force is proportional to the square of the number of 
combatants entering the engagement. Finally, we will fit one of these mod-
els, with astonishing accuracy, to the battle of Iwo Jima in World War II. 
</p>
<p>( a) Construction of the models 
</p>
<p>Suppose that an "x-force" and a "y-force" are engaged in combat. For 
simplicity, we define the strengths of these two forces as their number of 
combatants. (See Howes and Thrall [3] for another definition of combat 
strength.) Thus Iet x(t) andy(t) denote the number of combatants ofthex 
and y forces, where t is measured in days from the start of the combat. 
Clearly, the rate of change of each of these quantities equals its reinforce-
ment rate minus its operationalloss rate minus its combat loss rate. 
</p>
<p>The operationalloss rate. The operationalloss rate of a combat force is its 
loss rate due to non-combat mishaps; i.e., desertions, diseases, etc. 
Lanchester proposed that the operational loss rate of a combat force is 
proportional to its strength. However, this does not appear to be very real-
istic. For example, the desertion rate in a combat force depends on a host 
of psychological and other intangible factors which are difficult even to de-
scribe, let alone quantify. We will take the easy way out here and consider 
only those engagements in which the operationalloss rates are negligible. 
</p>
<p>The combat /oss rate. Suppose that the x-force is a conventional force 
which operates in the open, comparatively speaking, and that every mem-
ber of this force is within "kill range" of the enemy y. We also assume that 
</p>
<p>405 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>as soon as the conventional force suffers a loss, fire is concentrated on the 
remaining combatants. Under these "ideal" conditions, the combat loss 
rate of a conventional force x equals ay(t), for some positive constant a. 
This constant is called the combat effectiveness coefficient of the y-force. 
</p>
<p>The situation is very different if x is a guerilla force, invisible to its 
opponent y and occupying a region R. The y-force fires into R but cannot 
know when a kill has been made. It is certainly plausible that the combat 
loss rate for a guerilla force x should be proportional to x(t), for the !arger 
x(t), the greater the probability that an opponent's shot will kill. On the 
other hand, the combat loss rate for x is also proportional to y(t), for the 
!arger y, the greater the number of x-casualties. Thus, the combat loss rate 
for a guerilla force x equals cx(t)y(t), where the constant c is called the 
combat effectiveness coefficient of the Opponent y. 
</p>
<p>The reinforcement rate. The reinforcement rate of a combat force is the 
rate at which new combatants enter (or are withdrawn from) the battle. We 
denote the reinforcement rates of the x- and y-forces by f(t) and g(t) re-
spectively. 
</p>
<p>Under the assumptions listed above, we can now write down the follow-
ing two Lanchestrian models for conventional-guerilla combat. 
</p>
<p>Conventional combat: 
</p>
<p>Conventional-guerilla combat: 
</p>
<p>( x = guerilla) 
</p>
<p>{ 
dx = -ay+ f(t) 
dt 
dy 
- = -bx+ g(t) 
dt 
</p>
<p>{ 
dx =- cxy+ f(t) 
dt 
dy 
- = -dx+ g(t) 
dt 
</p>
<p>(la) 
</p>
<p>{lb) 
</p>
<p>The system of equations (la) isalinear system and can be solved explicitly 
once a, b,f(t), and g(t) are known. On the other hand, the system of equa-
tions (lb) is nonlinear, and its solution is much more difficult. (Indeed, it 
can only be obtained with the aid of a digital computer.) 
</p>
<p>It is very instructive to consider the special case where the reinforce-
ment rates are zero. This situation occurs when the two forces are "iso-
lated." In this case (la) and (lb) reduce to the simpler systems 
</p>
<p>dx 
dt = -ay, 
</p>
<p>and 
</p>
<p>dx 
dt = -cxy, 
</p>
<p>406 
</p>
<p>dy 
-=-bx 
dt 
</p>
<p>dy 
dt = -dx. 
</p>
<p>(2a) 
</p>
<p>(2b) </p>
<p/>
</div>
<div class="page"><p/>
<p>4.5 Mathematical theories of war 
</p>
<p>Conventional combat: The square law. The orbits of system (2a) are the 
solution curves of the equation 
</p>
<p>dy bx 
-=-
dx ay 
</p>
<p>dy 
or ay dx =bx. 
</p>
<p>Integrating this equation gives 
</p>
<p>ay 2 - bx2 = ay&amp;- bx&amp;= K. (3) 
</p>
<p>The curves (3) define a family of hyperbolas in the x-y plane and we have 
indicated their graphs in Figure 1. The arrowheads on the curves indicate 
the direction of changing strengths as time passes. 
</p>
<p>Let us adopt the criterion that one force wins the battle if the other 
force vanishes first. Then, y wins if K &gt; 0 since the x-force has been 
annihilated by the time y(t) has decreased to Y K/ a . Similarly, x wins if 
K&lt;O. 
</p>
<p>y(t) 
</p>
<p>Y-K/b x(t) 
</p>
<p>Figure I. The hyperbolas defined by (3) 
</p>
<p>Remark 1. Equation (3) is often referred to as "Lanchester's square law," 
and the system (2a) is often called the square law model, since the 
strengths of the opposing forces appear quadratically in (3). This terminol-
ogy is rather anomolous since the system (2a) is actually a linear system. 
</p>
<p>Remark 2. The y-force always seeks to establish a setting in which K &gt; 0. 
That is to say, the y-force wants the inequality 
</p>
<p>ay&amp;&gt; bx&amp; 
</p>
<p>to hold. This can be accomplished by increasing a; i.e. by using stronger 
and more accurate weapons, or by increasing the initial force y 0&bull; Notice 
though that a doubling of a results in a doubling of ay&amp; while a doubling of 
y 0 results in a jour-fold increase of ay&amp;. This is the essence of Lanchester's 
square law of conventional combat. 
</p>
<p>407 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>Conventional-gueril/a combat. The orbits of system (2b) are the solution 
curves of the equation 
</p>
<p>dy = dx =!!:._ 
dx cxy cy 
</p>
<p>Multiplying both sides of (4) by cy and integrating gives 
</p>
<p>cy2 -2dx= cy5-2dx0 = M. 
</p>
<p>(4) 
</p>
<p>(5) 
</p>
<p>The curves (5) define a family of parabolas in the x-y plane, and we have 
indicated their graphs in Figure 2. The y-force wins if M &gt; 0, since the x-
force has been annihilated by the timey(t) has decreased to ~. Simi-
larly, x wins if M &lt; 0. 
</p>
<p>y (t) 
</p>
<p>M=O:tie 
</p>
<p>x(t) 
</p>
<p>Figure 2. The parabolas defined by (5) 
</p>
<p>Remark. It is usually impossible to determine, a priori, the numerical value 
of the combat coefficients a, b, c, and d. Thus, it would appear that 
Lanchester's combat models have little or no applicability to real-life en-
gagements. However, this is not so. As we shall soon see, it is often possi-
ble to determine suitable values of a and b (or c and d) using data from the 
battle itself. Once these values are established for one engagement, they are 
known for all other engagements which are fought under similar condi-
tions. 
</p>
<p>(b) The battle oj !wo Jima 
</p>
<p>One of the fiercest battles of World War II was fought on the island of lwo 
Jima, 660 miles south of Tokyo. Our forces coveted lwo Jima as a bornher 
base close to the Japanese mainland, while the Japanese needed the island 
as a base for fighter planes attacking our aircraft on their way to bornhing 
missions over Tokyo and other major Japanese cities. The American inva-
</p>
<p>408 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.5 Mathematical theories of war 
</p>
<p>sion of lwo Jima began on February 19, 1945, and the fighting was intense 
throughout the month long combat. Both sides suffered heavy casualties 
(see Table 1). The Japanese had been ordered to fight to the last man, and 
this is exactly what they did. The island was declared "secure" by the 
American forces on the 28th day of the battle, and all active combat 
ceased on the 36th day. (The last two Japanese holdouts surrendered in 
1951!) 
</p>
<p>Table 1. Casualties at Iwo Jima 
</p>
<p>Total United States casualties at I wo Jima 
</p>
<p>Marines 
Navy units: 
Ships and air units 
Medical corpsmen 
Seabees 
Doctors and dentists 
Army units in battle 
Grand totals 
</p>
<p>Defense forces 
(Estimated) 
</p>
<p>21,000 
</p>
<p>(Newcomb [6J, page 296) 
</p>
<p>Killed, missing or Wounded Combat Fatigue 
died of wounds 
</p>
<p>5,931 
</p>
<p>633 
195 
</p>
<p>51 
2 
9 
</p>
<p>6,821 
</p>
<p>17,272 
</p>
<p>1,158 
529 
218 
</p>
<p>12 
28 
</p>
<p>19,217 
Japanese casualties at Iwo Jima 
</p>
<p>Prisoners 
</p>
<p>Marine 216 
Army 867 
Total 1,083 
</p>
<p>2,648 
</p>
<p>2,648 
</p>
<p>Total 
</p>
<p>25,851 
</p>
<p>1,791 
724 
269 
</p>
<p>14 
37 
</p>
<p>28,686 
</p>
<p>Killed 
</p>
<p>20,000 
</p>
<p>The following data is available to us from the battle of lwo Jima. 
1. Reinforcement rates. During the conflict Japanese troops were 
</p>
<p>neither withdrawn nor reinforced. The Americans, on the other band, 
landed 54,000 troops on the first day of the battle, none on the second, 
6,000 on the third, none on the fourth and fifth, 13,000 on the sixth day, 
and none thereafter. There were no American troops on lwo Jima prior to 
the start of the engagement. 
</p>
<p>2. Combat losses. Captain Clifford Morehouse of the United States 
Marine Corps (see Morehouse [5]) kept a daily count of all American com-
bat losses. Unfortunately, no such records are available for the Japanese 
forces. Most probably, the casualty lists kept by General Kuribayashi 
(commander of the Japanese forces on Iwo Jima) were destroyed in the 
battle itself, while whatever records were kept in Tokyo were consumed in 
the fire bombings of the remaining five months of the war. However, we 
can infer from Table I that approximately 21,500 Japanese forces were on 
lwo Jima at the start of the battle. (Actually, Newcomb arrived at the fig-
</p>
<p>409 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>ure of 21,000 for the Japanese forces, but this is a 1ittle 1ow since he appar-
ently did not include some of the living and dead found in the caves in the 
final days.) 
</p>
<p>3. Operationallosses. The operationa11osses on both sides were negligi-
ble. 
</p>
<p>Now, let x(t) and y(t) denote respective1y, the active American and 
Japanese forces on Iwo Jima t days after the battle began. The data above 
suggests the following Lanchestrian mode1 for the battle of Iwo Jima: 
</p>
<p>dx = -ay+j(t) 
dt 
dy 
-=-bx 
dt 
</p>
<p>(6) 
</p>
<p>where a and b are the combat effectiveness coefficients of the Japanese 
and American forces, respectively, and 
</p>
<p>54,000 O"t&lt;1 
0 1"t&lt;2 
</p>
<p>f(t)= 6,000 2"t&lt;3 
0 3"t&lt;5 
</p>
<p>13,000 5"t&lt;6 
0 1~6 
</p>
<p>Using the method of variation of parameters deve1oped in Section 3.12 or 
the method of elimination in Section 2.14, it is easily seen that the solution 
of (6) which satisfies x(O)=O, y(O)=y0 =21,500 is given by 
</p>
<p>x(t) =-Vf y0 coshv'lib t + {coshv'lib (t -s)f(s)ds (7a) 
and 
</p>
<p>y(t)=y0 coshv'lib t-Vf {sinhv'lib (t-s)f(s)ds (7b) 
</p>
<p>where 
</p>
<p>The problern before us now is this: Do there exist constants a and b so 
that (7a) yields a good fit to the data compiled by Morehouse? This is an 
extremely important question. An affirmative answer would indicate that 
Lanchestrian models do indeed describe real life battles, while a negative 
answer would shed a dubious light on much of Lanchester's work. 
</p>
<p>As we mentioned previously, it is extremely difficult to compute the 
combat effectiveness coefficients a and b of two opposing forces. However, 
it is often possible to determine suitable values of a and b once the data for 
the battle is known, and such is the case for the battle of lwo Jima. 
</p>
<p>410 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.5 Mathematical theories of war 
</p>
<p>The calculation of a and b. Integrating the second equation of (6) between 
0 and s gives 
</p>
<p>so that 
</p>
<p>b= Yo-y(s). 
</p>
<p>fosx(t)dt 
</p>
<p>In particular, setting s = 36 gives 
</p>
<p>b= Yo-y(36) = 21,500 
(36 (36 
</p>
<p>Jo x(t)dt Jo x(t)dt 
</p>
<p>(8) 
</p>
<p>(9) 
</p>
<p>Now the integral on the right-hand side of (9) can be approximated by the 
Riemann sum 
</p>
<p>36 36 l x(t)dt:;;t. ~ x(i) 
0 i= I 
</p>
<p>and for x(i) we enter the number of effective American troops on the ith 
day of the battle. Using the data available from Morehouse, we compute 
for b the value 
</p>
<p>21,500 
b= 2,037,000 =0.0106. (10) 
</p>
<p>Remark. We would prefer to set s = 28 in (8) since that was the day the is-
land was declared secure, and the fighting was only sporadic after this day. 
However, we don't know y(28). Thus, we are forced here to take s=36. 
</p>
<p>Next, we integrate the first equation of (6) between t=O and t=28 and 
obtain that 
</p>
<p>(28 (28 
x(28)= -a Jo y(t)dt+ Jo f(t)dt 
</p>
<p>(28 
=- a Jo y(t)dt+73,000. 
</p>
<p>There were 52,735 effective American troops on the 28th day of the battle. 
Thus 
</p>
<p>a = 73,000- 52,735 = 20,265 
(28 (28 
</p>
<p>Jo y(t)dt Jo y(t)dt 
(11) 
</p>
<p>411 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>Finally, we approximate the integral on the right-hand side of (11) by the 
Riemann sum 
</p>
<p>28 28 l y(t)dt~ ~ y(J) 
0 j= I 
</p>
<p>and we approximate y(j) by 
</p>
<p>y(i)=y0 -b fojx(t)dt 
</p>
<p>j 
</p>
<p>~21,500- b ~ x(i). 
i=i 
</p>
<p>Again, we replace x(i) by the number of effective American troops on the 
ith day of the battle. The result of this calculation is (see Engel [2]) 
</p>
<p>20,265 
a = 372,500 = 0.0544. (12) 
</p>
<p>Figure 3 below compares the actual American troop strength with the val-
ues predicted by Equation (7a) (with a=0.0544 and b=0.0106). The fit is 
remarkably good. Thus, it appears that a Lanchestrian model does indeed 
describe reallife engagements. 
</p>
<p>(/) 
</p>
<p>LLI 
(.J 
er: 
0 
LL 
</p>
<p>z 
Cl 
(.J 
</p>
<p>er: 
LLI 
:Ii 
Cl 
</p>
<p>74,000 
</p>
<p>70,000 
</p>
<p>66,000 
</p>
<p>62,000 
</p>
<p>58,000 
</p>
<p>54,000 
</p>
<p>50,000 
</p>
<p>--- ACTUAL 
-PREDICTED 
</p>
<p>TROOPS 
</p>
<p>4 8 12 16 20 24 28 32 36 
</p>
<p>DAYS 
</p>
<p>Figure 3. Comparison of actual troop strength with predicted troop strength 
</p>
<p>Remark. The figures we have used for American reinforcements include 
a/1 the personnel put ashore, both combat troops and support troops. Thus 
the numbers a and b that we have computed should be interpreted as the 
average effectiveness per man ashore. 
</p>
<p>412 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.5 Mathematical theories of war 
</p>
<p>References 
I. Coleman, C. S., Combat Models, MAA Workshop on Modules in Applied 
</p>
<p>Math, Cornell University, Aug. 1976. 
</p>
<p>2. Engel, J. H., A verification of Lanchester's law, Operations Research, 2, (1954), 
163-171. 
</p>
<p>3. Howes, D. R., and Thrall, R. M., A theory of ideallinear weights for heteroge-
neous combat forces, Naval Research Logislies Quarterly, vol. 20, 1973, pp. 
645-659. 
</p>
<p>4. Lanchester, F. W., Aircraft in Warfare, the Dawn of the Fourth Arm. Tiptree, 
Constable and Co., Ltd., 1916. 
</p>
<p>5. Morehouse, C. P., The /wo Jima Operation, USMCR, Historical Division, Hdqr. 
USMC, 1946. 
</p>
<p>6. Newcomb, R. F., /wo Jima. New York: Holt, Rinehart, and Winston, 1965. 
</p>
<p>EXERCISES 
</p>
<p>1. Derive Equations (7a) and (7b). 
</p>
<p>2. The system of equations 
</p>
<p>.X= -ay 
(13) 
</p>
<p>y= -by-cxy 
is a Lanchestrian model for conventional-guerilla combat, in which the opera-
tionalloss rate of the guerilla force y is proportional to y(t). 
(a) Find the orbits of (13). 
(b) Who wins the battle? 
</p>
<p>3. The system of equations 
.X= -ay 
</p>
<p>y= -bx-cxy 
(14) 
</p>
<p>is a Lanchestrian model for conventional-guerilla combat, in which the opera-
tionalloss rate of the guerilla force y is proportional to the strength of the con-
ventional force x. Find the orbits of (14). 
</p>
<p>4. The system of equations 
.X= -cxy 
</p>
<p>y= -dxy 
(15) 
</p>
<p>is a Lanchestrian model for guerilla-guerilla combat in which the operational 
loss rates are negligible. 
(a) Find the orbits of (15). 
(b) Who wins the battle? 
</p>
<p>5. The system of equations 
.X= -ay-cxy 
</p>
<p>y= -bx-dxy 
(16) 
</p>
<p>is a Lanchestrian model for guerilla-guerilla combat in which the operational 
loss rate of each force is proportional to the strength of its opponent. Find the 
orbits of (16). 
</p>
<p>413 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>6. The system of equations 
</p>
<p>x= -ax-c.zy 
y= -by-d.zy 
</p>
<p>(17) 
</p>
<p>is a Lanchestrian model for guerilla-guerilla combat in which the operational 
loss rate of each force is proportional to its strength. 
(a) Find the orbits of (17). 
(b) Show that the x andy axes are both orbits of (17). 
(c) Using the fact (tobe proved in Section 4.6) that two orbits of (17) cannot 
intersect, show that there is no clear-cut winner in this battle. Hint: Show that 
x(t) and y(t) can never become zero in finite time. (Using lemmas l and 2 of 
Section 4.8, it is easy to show that both x(t) and y(t) approach zero as t-+oo.) 
</p>
<p>4.6 Qualitative properties of orbits 
</p>
<p>In this section we will derive two very important properties of the solutions 
and orbits of the system of differential equations 
</p>
<p>_ [f1 (~1, ... ,xn) 
f(x)- . . 
</p>
<p>fn(x1, ... ,xn) 
</p>
<p>x=f(x), (1) 
</p>
<p>The first property deals with the existence and uniqueness of orbits, and 
the second property deals with the existence of periodic solutions of (1). 
We begin with the following existence-uniqueness theorem for the solu-
tions of (1). 
</p>
<p>Theorem 3. Let each of the functions j 1(x 1, ... ,xn), ... Jn(x 1, ... ,xn) have con-
tinuous partial derivatives with respect to x 1, &bull;&bull;&bull; , xn. Then, the initial-value 
problern x = f(x), x(t0) = x0 has one, and only one solution x = x( t), for ev-
ery x0 in Rn. 
</p>
<p>We prove Theorem 3 in exactly the samemanneras we proved the ex-
istence-uniqueness theorem for the scalar differential equation .X= f(t,x). 
Indeed, the proof given in Section 1.10 carries over here word for word. 
We need only interpret the quantity !x( t)- y( t)l, where x( t) and y( t) are 
vector-valued functions, as the length of the vector x( t)- y( t). That is to 
say, if we interpret !x(t)-y(t)i as 
</p>
<p>lx(t) -y(t)l =max{lx1 (t)-Y 1 (t)i, .. . , lxn(t)-Yn(t)i }, 
</p>
<p>then the proof of Theorem 2, Section 1.10 is valid even for vector-valued 
functions f(t,x) (see Exercises 13-14). 
</p>
<p>Next, we require the following simple but extremely usefullemma. 
</p>
<p>Lemma 1. ljx=q,(t) is a solution of(l), then x=q,(t+c) is again a solution 
of (1). 
</p>
<p>414 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.6 Qualitative properties of orbits 
</p>
<p>The meaning of Lemma 1 is the following. Let x=f[&gt;(t) be a solution of 
(1) and let us replace every t in the formula for f[&gt;(t) by t + c. In this 
manner we obtain a new function i(t)=f[&gt;(t+ c). Lemma 1 states that x(t) 
is again a solution of (1). For example, x 1 = tant, x2 =sec2 t is a solution of 
the system of differential equations dx1/ dt = x2, dx2/ dt = 2x1x2&bull; Hence, 
x1 =tan(t+c), x2 =sec2(t+c) is again a solution, for any constant c. 
</p>
<p>PR.ooF OF LEMMA 1. If x=f[&gt;(t) is a solution of (1), then df[&gt;(t)/ dt=f(f[&gt;(t)); 
that is, the two functions df[&gt;(t)/ dt and h(t)=f(f[&gt;(t)) agree at every single 
time. Fixa timet and a constant c. Since dq,j dt and h agree at every time, 
they must agree at time t + c. Hence, 
</p>
<p>dq, 
dt(t + c) = h(t + c) =f(q,(t + c)). 
</p>
<p>But, dq,jdt evaluated at t+c equals the derivative of i(t)=f/&gt;(t+c), 
evaluated at t. Therefore, 
</p>
<p>d 
dt q,(t + c) =f(q,(t + c)). 0 
</p>
<p>Remark 1. Lemma I can be verified explicitly for the linear equation x = 
Ax. Every solution x( t) of this equation is of the form x( t) = eA1v, for some 
constant vector v. Hence, 
</p>
<p>x(t + c) = eA(t+c)v= eAteAcv 
</p>
<p>since (At)Ac=Ac(At) for all values oft and c. Therefore, x(t+c) is again 
a solution of x = Ax since it is of the form eA1 times the constant vector 
eAcv. 
</p>
<p>Remark 2. Lemma I is not true if the function f in (I) depends explicitly 
on t. To see this, suppose that x=f[&gt;(t) is a solution of the nonautonomaus 
differential equation x = f(t, x). Then, 1&gt;U + c) = f(t + c, f[&gt;(t + c)). Conse-
quently, the function x = f/&gt;( t + c) satisfies the differential equation 
</p>
<p>x=f(t+ c,x), 
</p>
<p>and this equation is different from (1) if f depends explicitly on t. 
</p>
<p>We are now in a position to derive the following extremely important 
properties of the solutions and orbits of (1). 
</p>
<p>Property 1. (Existence and uniqueness of orbits.) Let each of the functions 
/ 1(x1,. &bull;&bull; ,xn), ... Jn(x 1, &bull;&bull;&bull; ,xn) have continuous partial derivatives with re-
spect to x 1, &bull;&bull;&bull; ,xn. Then, there exists one, and only one, orbit through 
every point x0 in Rn. In particular, if the orbits of two solutions x=f[&gt;(t) 
and x=t{;(t) of (I) have one point in common, then they must be identi-
cal. 
</p>
<p>415 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>Property 2. Let x = cf&gt;( t) be a solution of (I). If cp(t0 + T) = cp(t0) for some t0 
and T &gt; 0, then cf&gt;( t + T) is identically equal to cf&gt;( t). In other words, if a 
solution x( t) of (1) returns to its starting value after a time T &gt; 0, then it 
must be periodic, with period T (i.e. it must repeat itself over every time 
interval of length T.) 
</p>
<p>PROOF OF PROPERTY 1. Let x0 be any point in the n-dimensional phase 
space x 1, ... ,xn, and Iet x=c[&gt;(t) be the solution of the initial-value problern 
x = f(x), x(O) = x0. The orbit of this solution obviously passes through x0&bull; 
Hence, there exists at least one orbit through every point x0&bull; Now, suppose 
that the orbit of another solution x = l[i(t) also passes through x0. This 
means that there exists t0(*0) suchthat l[i(t0)=x0&bull; By Lemma l, 
</p>
<p>x=l[i(t+t0 ) 
</p>
<p>is also a solution of (I). Observe that l[i(t + t0) and cp(t) have the same 
value at t = 0. Hence, by Theorem 3, l[i(t + t0) equals cp(t) for all time t. 
This implies that the orbits of cp(t) and l[i(t) are identical. To wit, if ~ is a 
point on the orbit of cf&gt;(t); that is, ~=cp(t 1 ) for some t 1, then ~ is also on the 
orbit of I[!( t), since ~= cf&gt;( t 1) =I[!( t 1 + t0). Conversely, if ~ is a point on the 
orbit of l[i(t); that is, there exists t2 suchthat l[i(t 2 )=~, then ~ is also on the 
orbit of cf&gt;( t) since ~= l[i(t2) = cf&gt;( t2 - t0). 0 
</p>
<p>PROOF OF PROPERTY 2. Let x=c[&gt;(t) be a solution of (1) and suppose that 
cf&gt;(t0 + T) = cp(t0) for some numbers t0 and T. Then, the function I[!( t) = 
cf&gt;( t + T) is also a solution of (1) which agrees with cf&gt;( t) at time t = t0&bull; By 
Theorem 3, therefore, I[!( t) = cf&gt;( t + T) is identically equal to cf&gt;( t). 0 
</p>
<p>Property 2 is extremely useful in applications, especially when n = 2. Let 
x = x(t), y = y(t) be a periodic solution of the system of differential equa-
tions 
</p>
<p>~~ =f(x,y), 
dy 
dt =g(x,y). (2) 
</p>
<p>If x(t + T) = x(t) and y(t + T) = y(t), then the orbit of this solution is a 
closed curve C in the x-y plane. In every time interval t0 &lt; t &lt; t0 + T, the 
solution moves once around C. Conversely, suppose that the orbit of a 
solution x = x(t), y = y(t) of (2) is a closed curve containing no equilibrium 
points of (2). Then, the solution x = x(t), y = y(t) is periodic. To prove this, 
recall that a solution x = x(t), y = y(t) of (2) moves along its orbit with 
velocity [P(x,y)+ g2(x,y)] 112&bull; If its orbit Cis a closed curve containing no 
equilibrium points of (2), then the function [J2(x,y) + g2(x,y)] 112 has a 
positive minimum for (x,y) on C. Hence, the orbit of x = x(t), y = y(t) 
mustreturn to its starting point x 0 =x(t0),y0 =y(t0) in some finite timeT. 
Butthis implies that x(t+ T)=x(t) andy(t+ T)=y(t) for all t. 
</p>
<p>Example 1. Prove that every solution z(t) of the second-order differential 
equation ( d 2z j dt 2) + z + z3 = 0 is periodic. 
</p>
<p>416 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.6 Qualitative properties of orbits 
</p>
<p>PROOF. We convert this second-order equation into a system of two first-
order equations by setting x=z, y=dzldt. Then, 
</p>
<p>~~ =y, ~ = -x-x3&bull; (3) 
The orbits of (3) are the solution curves 
</p>
<p>y2 x2 x4 2 
2+2+4=c (4) 
</p>
<p>of the scalar equation dyldx= -(x+x3)IY&middot; Equation (4) defines a closed 
curve in the x-y plane (see Exercise 7). Moreover, the only equilibrium 
point of (3) is x =O,y =0. Consequently, every solution x = z(t),y = z'(t) of 
(3) is a periodic function of time. Notice, however, that we cannot compute 
the period of any particular solution. 0 
</p>
<p>Example 2. Prove that every solution of the system of differential equa-
tions 
</p>
<p>(5) 
</p>
<p>is periodic. 
Solution. The orbits of (5) are the solution curves x 2 + y 2 = c2 of the first-
order scalar equation dy I dx = - x I y. Moreover, x = 0, y = 0 is the only 
equilibrium point of (5). Consequently, every solution x = x(t), y = y(t) of 
(5) is a periodic function of time. 
</p>
<p>EXERCISES 
</p>
<p>1. Show that all solutions x(t),y(t) of 
</p>
<p>dx =x2 +ysinx 
dt ' 
</p>
<p>dy 
- = -1 +xy+cosy 
dt 
</p>
<p>which start in the first quadrant (x &gt; 0, y &gt; 0) must remain there for all time 
(both backwards and forwards). 
</p>
<p>2. Show that all solutions x(t),y(t) of 
</p>
<p>'! =y(ex-1), dy -=x+eY 
dt 
</p>
<p>which start in the right half plane (x &gt; 0) must remain there for all time. 
</p>
<p>3. Show that all solutions x(t), y(t) of 
dy 
-=xy+tany 
dt 
</p>
<p>which start in the upper half plane (y &gt; 0) must remain there for all time. 
</p>
<p>4. Show that all solutions x(t), y(t) of 
</p>
<p>dx 2 -= -1-y+x 
dt ' 
</p>
<p>dy 
dt =x+xy 
</p>
<p>which start inside the unit circle x 2 + y 2 = I must remain there for all time. 
Hint: Compute d(x 2 +y2)/dt. 
</p>
<p>417 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>5. Let x(t), y(t) be a solution of 
</p>
<p>~~ =y+x2, : =x+y2 
</p>
<p>with x(t 0 h~' y(t0). Show that x(t) can never equal y(t). 
</p>
<p>6. Can a figure 8 ever be an orbit of 
</p>
<p>dx 
dt =J(x,y), 
</p>
<p>dy 
dt =g(x,y) 
</p>
<p>where f and g have continuous partial derivatives with respect to x and y? 
</p>
<p>7. Show that the curvey2+x2+x4/2=2c2 is closed. Hint: Show that there exist 
</p>
<p>two points y = 0, x = &plusmn; a which lie on this curve. 
</p>
<p>Prove that all solutions of the following second-order equations are peri-
odic. 
</p>
<p>8. d2z +z3=0 
dt2 
</p>
<p>10. d2z + ez2= I 
dt2 
</p>
<p>9. d2z +z+zs=o 
dt2 
</p>
<p>1 d 2z +-z-=O 1 . 2 
dt2 l+z 
</p>
<p>12. Show that all solutions z(t) of 
</p>
<p>d2z +z-2z3=0 
dt2 
</p>
<p>are periodic if i 2(0) + z2(0)- z4(0) &lt; ! , and unbounded if 
</p>
<p>i 2{0)+z2(0)- z4(0) &gt;!&middot; 
</p>
<p>13. (a) Let 
</p>
<p>L=nx . . max la.fi/axA, for lx-x0l&lt;:b. 
IJ-= l, ... ,n 
</p>
<p>Show that lf(x)-f(y)l &lt; Llx-yl if lx-x01 &lt;band ly-x01 &lt; b. 
(b) Let M=maxlf(x)l for lx-x01 &lt; b. Show that the Picard iterates 
</p>
<p>converge to a solution x(t) of the initial-value problern i=f(x), x(t0)=x0 on 
the interval lt- t0l &lt; b / M. Hint: The proof of Theorem 2, Section 1.10 
carries over here word for word. 
</p>
<p>14. Cornpute the Picard iterates xi(t) of the initial-value problern i=Ax, x(O)-x0, 
and verify that they approach eA1x0 asj approaches infinity. 
</p>
<p>4.7 Phaseportraits of linear systems 
</p>
<p>In this section we present a complete picture of all orbits of the linear dif-
ferential equation 
</p>
<p>i=Ax, x=(~~). A=(~ ~)&middot; (I) 
</p>
<p>418 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.7 Phaseportraits of linear systems 
</p>
<p>This picture is called a phase portrait, and it depends almost completely on 
the eigenvalues of the matrix A. lt also changes drastically as the eigenval-
ues of A change sign or become imaginary. 
</p>
<p>When analyzing Equation (1), it is often helpful to visualize a vector 
</p>
<p>x=(~~) 
in R2 as a direction, or directed line segment, in the plane. Let 
</p>
<p>be a vector in R2 and draw the directed line segment x from the point (0, 0) 
to the point (x1,x2), as in Figure la. This directed line segment is parallel 
to the line through (0,0) with direction numbers x 1,x2 respectively. If we 
visualize the vector x as being this directed line segment x, then we see that 
the vectors x and cx are parallel if c is positive, and antiparallel if c is 
negative. We can also give a nice geometric interpretation of vector addi-
tion. Let x and y be two vectors in R2&bull; Draw the directed line segment x, 
and place the vector y at the tip of x. The vector x + y is then the composi-
</p>
<p>(-2,-1) 
</p>
<p>(a) (b) 
</p>
<p>Figure I 
</p>
<p>Figure 2 
</p>
<p>419 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>tion of these two directed line segments (see Figure 2). This construction is 
known as the parallelogram law of vector addition. 
</p>
<p>We are now in a position to derive the phase portraits of (1). Let A1 and 
A2 denote the two eigenvalues of A. W e distinguish the following cases. 
</p>
<p>1. A2 &lt; A1 &lt; 0. Let v1 and v2 be eigenvectors of A with eigenvalues A1 and 
A2 respectively. In the x 1 - x2 plane we draw the four half-lines /1, /), / 2, and 
12, as shown in Figure 3. The rays /1 and /2 areparallel to v1 and v2, while 
the rays /) and 12 areparallel to -v1 and -v2&bull; Observe first that x(t)= 
ce&gt;--'1v1 is a solution of (1) for any constant c. This solution is always pro-
portional to v1, and the constant of proportionality, ce&gt;--'1, runs from &plusmn; oo to 
0, depending as to whether c is positive or negative. Hence, the orbit of this 
solution is the half-line /1 for c &gt; 0, and the half-line /) for c &lt; 0. Similarly, 
the orbit of the solution x(t)=ce&gt;--21v2 is the half-line /2 for c&gt;O, and the 
half-line 12 for c &lt; 0. The arrows on these four lines in Figure 3 indicate in 
what direction x(t) moves along its orbit. 
</p>
<p>Next, recall that every solution x(t) of (1) can be written in the form 
</p>
<p>x(t)= c1e&gt;..&bull;1v1 + c2e&gt;..21v2 (2) 
</p>
<p>for some choice of constants c1 and c2&bull; Obviously, every solution x(t) of (I) 
approaches C8) as t approaches infinity. Hence, every orbit of (1) ap-
proaches the origin x 1 = x2 = 0 as t approaches infinity. We can make an 
even stronger statement by observing that e&gt;--21v2 is very small compared to 
e&gt;--'1v1 when t is very large. Therefore, x(t), for c1 *0, comes closer and 
closer to c1e&gt;..&bull;1v1 as t approaches infinity. This implies that the tangent to 
the orbit of x(t) approaches /1 if c1 is positive, and /) if c1 is negative. Thus, 
</p>
<p>Figure 3. Phase portrait of a stable node 
</p>
<p>420 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.7 Phase portraits of linear systems 
</p>
<p>the phase portrait of (1) has the form described in Figure 3. The dis-
tinguishing feature of this phase portrait is that every orbit, with the excep-
tion of a single 1ine, approaches the origin in a fixed direction (if we con-
sider the directions v1 and - v1 equiva1ent). In this case we say that the 
equilibrium solution x=O of (l) is a stab1e node. 
</p>
<p>Remark. The orbit of every solution x(t) of (l) approaches the origin x 1 = 
x2 = 0 as t approaches infinity. However, this point does not belang to the 
orbit of any nontrivial solution x( t). 
</p>
<p>1'. 0&lt;.\1 &lt;.\2&bull; The phase portrait of (1) in this case is exactly the same 
as Figure 3, except that the direction of the arrows is reversed. Hence, the 
equi1ibrium solution x(t)=O of (I) is an unstable node if both eigenvalues 
of A are positive. 
</p>
<p>2 . .\1 =.\2 &lt;0. In this case, the phase portrait of (1) depends on whether 
Ahasone or two linearly independent eigenvectors. (a) Suppose that A has 
two linearly independent eigenvectors v1 and v2 with eigenvalue .\ &lt; 0. In 
this case, every solution x(t) of (1) can be written in the form 
</p>
<p>(2) 
</p>
<p>for some choice of constants c1 and c2. Now, the vector eM(c1v1+c2v2) is 
parallel to c1v 1 + c2v2 for all t. Hence, the orbit of every solution x(t) of (l) 
is a half-line. Moreover, the set of vectors { c1v1 + c2v2}, for all choices of c1 
and c2, cover every direction in the x 1 - x2 plane, since v1 and v2 are lin-
early independent. Hence, the phase portrait of (I) has the form described 
in Figure 4a. (b) Suppose that A has only one linearly independent eigen-
vector v, with eigenvalue .\. In this case, x1(t) = eMv is one solution of (I). 
To find a second solution of (I) which is independent of x1, we observe 
that (A-.\1)2u=O for every vector u. Hence, 
</p>
<p>(3) 
</p>
<p>is a solution of (l) for any choice of u. Equation (3) can be simplified by 
observing that (A- .\l)u must be a multiple k of v. This follows im-
mediately from the equation (A- .\I)[(A- .\I)u] = 0, and the fact that A has 
only one linearly independent eigenvector v. Choosing u independent of v, 
we see that every solution x(t) of (1) can be written in the form 
</p>
<p>x(t) = c1eMv+ c2eM (u+ ktv)= e&gt;..t (c1v+ c2u+ c2ktv), (4) 
for some choice of constants c1 and c2&bull; Obviousiy, every solution x(t) of (1) 
approaches (8) as t approaches infinity. In addition, observe that c1 v + c2u 
is very small compared to c2ktv if c2 is unequal to zero and t is very large. 
Hence, the tangent to the orbit of x(t) approaches &plusmn; v (depending on the 
sign of c2) as t approaches infinity, and the phase portrait of (1) has the 
form described in Figure 4b. 
</p>
<p>421 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>(a) (b) 
</p>
<p>Figure 4 
</p>
<p>2'. A1 =A2 &gt;0. The phase portraits of (1) in the cases (2a)' and (2b)' are 
exactly the same as Figures 4a and 4b, except that the direction of the 
arrows is reversed. 
</p>
<p>3. A1 &lt;0&lt;A2&bull; Let v1 and v2 be eigenvectors of A with eigenvalues A1 and 
A2 respectively. In the x 1 - x2 plane we draw the four half-lines 11, 1{, 12, and 
I~; the half-lines 11 and 12 are parallel to v1 and v2, while the half-lines I{ 
and /~ areparallel to -v1 and -v2&bull; Observe first that every solution x(t) of 
(f) is of the form 
</p>
<p>(5) 
</p>
<p>for some choice of constants c1 and c2&bull; The orbit of the solution x(t)= 
c 1 e~' 1 v 1 is /1 for c1 &gt; 0 and /{ for c1 &lt; 0, while the orbit of the solution 
x(t)=c 2 e~ 21 V 2 is /2 for c2 &gt;0 and /~ for c2 &lt;0. Note, too, the direction of the 
arrows on /1, /{, 12, and /~; the solution x(t)=c 1 e~' 1 V 1 approaches (8) as t 
approaches infinity, where.as the solution x(t) = c 2 e~ 21 v 2 becomes un-
bounded (for c2 =FO) as t approaches infinity. Next, observe that e~' 1 v 1 is 
very small compared to e~ 21 V 2 when t is very large. Hence, every solution 
x(t) of (1) with c2 =FO becomes unbounded as t approaches infinity, and its 
orbit approaches either /2 or /~. Finally, observe that e~ 21 v 2 is very small 
compared to e~' 1 v 1 when t is very large negative. Hence, the orbit of any 
solution x(t) of (1), with c1 =FO, approaches either /1 or /{ as t approaches 
minus infinity. Consequently, the phase portrait of (I) has the form de-
scribed in Figure 5. This phase portrait resembles a "saddle" near x 1 = x2 = 
</p>
<p>422 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.7 Phaseportraits of linear systems 
</p>
<p>Figure 5. Phaseportrait of a saddle point 
</p>
<p>0. Forthis reason, we say that the equilibrium solution x(t)=O of (l) is a 
saddle point if the eigenvalues of A have opposite sign. 
</p>
<p>4. A1 = a + i&szlig;, A2 = a- i&szlig;, &szlig; =I= 0. Our first step in deriving the phase 
portrait of (1) is to find the general solution of (1). Let z=u+iv be an ei-
genvector of A with eigenvalue a + i&szlig;. Then, 
</p>
<p>x{t) = e&lt;a+i&szlig;)t(u + iv) = ea1 (cos&szlig;t + i sin&szlig;t)(u + iv) 
</p>
<p>= ea1 [ ucos&szlig;t -vsin&szlig;t] + ie"1 [ usin&szlig;t+vcos&szlig;t] 
</p>
<p>is a complex-valued solution of (1). Therefore, 
</p>
<p>x1{t) = ea1[ ucos&szlig;t -vsin&szlig;t] 
</p>
<p>and 
</p>
<p>x2(t) = e"1[ usin&szlig;t+vcos&szlig;t] 
</p>
<p>are two real-valued linearly independent solutions of (1), and every solu-
tion x(t) of (l) is of the form x(t)=c1x 1(t)+c2x2(t). This expression can be 
written in the form (see Exercise 15) 
</p>
<p>x(t)=eat(Ricos(&szlig;t-81)) {6) 
R2 cos{ &szlig;t - 82 ) 
</p>
<p>for some choice of constants R1 &gt; 0, R2 &gt; 0, 81, and 82&bull; We distinguish the 
following cases. 
</p>
<p>(a) a=O: Observe that both 
</p>
<p>x1 (t)= R1 cos(&szlig;t- 81 ) and xit) = R2 cos( &szlig;t- 82 ) 
</p>
<p>are periodic functions of time with period 27T / &szlig;. The function x 1(t) varies 
between - R1 and + R1, while x2(t) varies between - R2 and + R2&bull; Conse-
</p>
<p>423 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>quently, the orbit of any solution x(t) of (1) is a closed curve surrounding 
the origin x1 =x2 =0, and the phase portrait of (1) has the form described 
in Figure 6a. Forthis reason, we say that the equilibrium solution x(t)=O 
of (1) is a center when the eigenvalues of Aare pure imaginary. 
</p>
<p>The direction of the arrows in Figure 6a must be determined from the 
differential equation (1). The simplest way of doing this is to check the sign 
of .X2 when x2 = 0. If .X2 is greater than zero for x2 = 0 and x 1 &gt; 0, then all 
so1utions x(t) of (1) move in the counterc1ockwise direction; if .X2 is less 
than zero for x2 =0 and x1 &gt;0, then all solutions x(t) of (1) move in the 
clockwise direction. 
</p>
<p>{a) {b) 
</p>
<p>(c) 
</p>
<p>Figure 6. (a) a=O; (b) a&lt;O; (c) a&gt;O 
</p>
<p>424 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.7 Phaseportraits of linear systems 
</p>
<p>(b) a&lt;O: In this case, the effect of the factor ea1 in Equation (6) is to 
change the simple closed curves of Figure 6a into the spirals of Figure 6b. 
This is because the point x(27T / &szlig;) = e2wa/ &szlig;x(O) is closer to the origin than 
x(O). Again, the direction of the arrows in Figure 6b must be determined 
directly from the differential equation (1). In this case, we say that the 
equilibrium solution x(t)=O of (1) is a stable focus. 
</p>
<p>(c) a &gt; 0: In this case, all orbits of (1) spiral away from the origin as t 
approaches infinity (see Figure 6c), and the equilibrium solution x(t)=O of 
(1) is called an unstable focus. 
</p>
<p>Finally, we mention that the phase portraits of nonlinear systems, in the 
neighborhood of an equilibrium point, are often very similar to the phase 
portraits of linear systems. More precisely, let x = x0 be an equilibrium 
solution of the nonlinear equation x = f(x), and set u = x- x0&bull; Then, (see 
Section 4.3) we can write the differential equation x=f(x) in the form 
</p>
<p>&uuml;=Au+g(u) (7) 
</p>
<p>where A is a constant matrix and g(u) is very small compared to u. We 
state without proof the following theorem. 
</p>
<p>Theorem 4. Suppose that u=O is either a node, saddle, or focus point of the 
differential equation &uuml; =Au. Then, the phase portrait of the differential 
equation x = f(x), in a neighborhood of x = x0, has one of the forms de-
scribed in Figures 3, 5, and 6 (band c), depending as to whether u=O is a 
node, saddle, or focus. 
</p>
<p>Example 1. Draw the phase portrait of the linear equation 
</p>
<p>. Ax ( -2 X= = 4 -1) -7 X. (8) 
Solution. It is easily verified that 
</p>
<p>v1={ D and v2={!) 
are eigenvectors of A with eigenvalues -3 and -6, respectively. There-
fore, x = 0 is a stable node of (8), and the phase portrait of (8) has the form 
described in Figure 7. The half-line /1 makes an angle of 45&deg; with the x1 
axis, while the half-line 12 makes an angle of 0 degrees with the x 1-axis, 
where tan 0 = 4. 
</p>
<p>Example 2. Draw the phase portrait of the linear equation 
</p>
<p>x=Ax=( I 
-3 
</p>
<p>Solution. It is easily verified that 
</p>
<p>-3) I X. 
</p>
<p>v1={ D and v2={- D 
</p>
<p>(9) 
</p>
<p>425 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>Figure 7. Phase portrait of (8) 
</p>
<p>Figure 8. Phase portrait of (9) 
</p>
<p>are eigenvectors of A with eigenvalues -2 and 4, respectively. Therefore, 
x = 0 is a saddle point of (9), and its phase portrait has the form described 
in Figure 8. The half-line /1 makes an angle of 45&deg; with the x 1-axis, and the 
half-line /2 is at right angles to /1&bull; 
</p>
<p>Example 3. Draw the phase portrait of the linear equation 
</p>
<p>x = Ax = ( - 1 1 )x. 
-1 -1 
</p>
<p>(10) 
</p>
<p>426 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.7 Phase portraits of linear systems 
</p>
<p>Solution. The eigenvalues of A are - 1 &plusmn; i. Hence, x = 0 is a stable focus of 
(10) and every nontrivial orbit of (10) spirals into the origin as t ap-
proaches infinity. To determine the direction of rotation of the spiral, we 
observe that i 2 = - x 1 when x 2 = 0. Thus, i 2 is negative for x 1 &gt; 0 and x2 = 
0. Consequently, all nontrivial orbits of (10) spiral into the origin in the 
clockwise direction, as shown in Figure 9. 
</p>
<p>Xz 
</p>
<p>Figure 9. Phase portrait of (10) 
</p>
<p>EXERCISES 
</p>
<p>Draw the phase portraits of each of the following systems of differential 
equations. 
</p>
<p>1 . (-5 1) . x= 1 -5 x 2. x=(~ -1) -6 X 3. x=( -~ -1) 5 X 
4. x=( -1 -1) -6 X s. x=( -~ -4) 4 X 6. x=(~ -1) -3 X 
7. x=(-~ 2)x -1 s. x=O -1) -3 X 9. x=( _; 1 )x -2 
</p>
<p>10. Show that every orbit of 
</p>
<p>x=( o 
-9 ci )x 
</p>
<p>is an ellipse. 
</p>
<p>11. The equation of motion of a spring-mass system with damping (see Section 2.6) 
is mi + ci + kz = 0, where m, c, and k are positive numbers. Convert this equa-
tion to a system of first-order equations for x=z, y=i, and draw the phase 
portrait of this system. Distinguish the overdamped, critically damped, and un-
derdamped cases. 
</p>
<p>12. Suppose that a 2 X 2 matrix A has 2 1inearly independent eigenvectors with ei-
genvalue A.. Show that A ='Al 
</p>
<p>427 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>13. This problern illustrates Theorem 4. Consider the system 
</p>
<p>~~ =y, : =x+2x3&bull; (*) 
</p>
<p>(a) Show that the equilibrium solution x=O,y=O of the linearized system x= 
y, j = x is a saddle, and draw the phase portrait of the linearized system. 
</p>
<p>(b) Find the orbits of (*), and then draw its phase portrait. 
(c) Show that there are exactly two orbits of (*) (one for x &gt;0 and one for x &lt; 
</p>
<p>0) on which x-+0, y-+0 as t-+oo. Similarly, there are exactly two orbits of 
(*) on which x-+0, y-+0 as t-+- oo. Thus, observe that the phase portraits 
of (*) and the linearized system Iook the same near the origin. 
</p>
<p>14. Verify Equation (6). Hint: The expression acos"'t+bsin"'t can always be 
written in the form Rcos("'t-8) for suitable choices of Rand 8. 
</p>
<p>4.8 Long time behavior of solutions; 
the Poincare-Bendixson Theorem 
</p>
<p>We consider now the problern of determining the long time behavior of all 
solutions of the differential equation 
</p>
<p>x=f(x), (I) 
</p>
<p>This problern has been solved completely in the special case that f(x) = Ax. 
As we have seen in Sections 4.2 and 4.7, all solutions x(t) of x=Ax must 
exhibit one of the following four types of behavior: (i) x(t) is constant in 
time; (ii) x(t) is a periodic function of time; (iii) x(t) is unbounded as t ap-
proaches infinity; and (iv) x(t) approaches an equilibrium point as t ap-
proaches infinity. 
</p>
<p>A partial solution to this problem, in the case of nonlinear f(x), was 
given in Section 4.3. In that section we provided sufficient conditions that 
every solution x(t) of (1), whose initial value x(O) is sufficiently close to an 
equilibrium point ~. must ultimately approach ~ as t approaches infinity. In 
many applications it is often possible to go much further and prove that 
every physically (biologically) realistic solution approaches a single 
equilibrium point as time evolves. In this context, the following two 
Iemmas play an extremely important role. 
</p>
<p>Lemma 1. Let g(t) be a monotonic increasing (decreasing) function of time 
fort&gt; t0, with g(t) &lt; c( &gt; c) for some constant c. Then, g(t) has a Iimit as 
t approaches infinity. 
</p>
<p>PRooF. Suppose that g(t) is monotonic increasing for t &gt; t0, and g(t) is 
bounded from above. Let I be the least upper bound of g; that is, I is the 
smallest number which is not exceeded by the values of g(t), fort;&gt; t0&bull; This 
</p>
<p>428 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.8 Long time behavior of solutions: the Poincarb-Bendixson Theorem 
</p>
<p>number must be the Iimit of g(t) as 1 approaches infinity. To prove this, let 
E &gt; 0 be given, and observe that there exists a time 1. ~ 10 such that /- g( 1.) 
&lt; E. (If no such time 1. exists, then I is not the least upper bound of g.) 
Since g( t) is monotonic, we see that /- g( I)&lt; E for t ~ t &bull;. This shows that 
/=limH 00 g(l). D 
</p>
<p>Lemma 2. Suppose lhal a solulion x(t) of (1) approaches a veclor ~ as I ap-
proaches infinity. Then, ~ is an equilibrium poinl of (1). 
</p>
<p>PROOF. Suppose that x(t) approaches ~ as 1 approaches infinity. Then, 
~(I) approaches ~. where ~ is the jth component of ~&middot; This implies that 
lx1(t1)- x1 (t2)1 approaches zero as both 11 and 12 approach infinity, since 
</p>
<p>lxi 11)- xi 12)1 =I( x1( 11)- ~J) + (~ 1 - x1( t2))1 
</p>
<p>~ lxAtl) -~ 1 1 + lxA12)-~I&middot; 
In particular, let t 1 = t and t2 = t 1 + h, for some fixed positive number h. 
Then, lx/t + h)- x/t)l approaches zero as t approaches infinity. But 
</p>
<p>dx/T) 
x1(t + h)- x1(t) = h--;[1 = hjj (x 1 ( T), ... ,xn(T)), 
</p>
<p>where r is some number between t and t + h. Finally, observe that 
jj(x 1(T), ... ,xn(T)) must approach jj(~p ... '~n) as t approaches infinity. 
Hence,jj(~ 1 , &bull;&bull;&bull; ,~n)=O,j= 1,2, ... ,n, and this proves Lemma 1. D 
</p>
<p>Example 1. Consider the system of differential equations 
</p>
<p>dx 2 - =ax-bxy-ex 
dt ' 
</p>
<p>dy 
- = -cy+dxy-jy2 
dt 
</p>
<p>(2) 
</p>
<p>where a, b, c, d, e, and f are positive constants. This system (see Section 
4.10) describes the population growth of two species x andy, where species 
y is dependent upon species x for its survival. Suppose that c I d &gt; a I e. 
Prove that every solution x(t), y(t) of (2), with x(O) and y(O) &gt; 0, ap-
proaches the equilibrium solution x = a I e, y = 0, as t approaches infinity. 
Solution. Our first step is to show that every solution x( t), y ( t) of (2) which 
starts in the first quadrant (x &gt; 0, y &gt; 0) at t = 0 must remain in the first 
quadrant for all future time. (If this were not so, then the model (2) could 
not correspond to reality.) To this end, recall from Section 1.5 that 
</p>
<p>ax0 
x(l)= , 
</p>
<p>ex0 + (a- ex0 )e-ar 
y(t)=O 
</p>
<p>is a solution of (2) for any choice of x0&bull; The orbit of this solution is the 
point (0,0) for x0 = 0; the line 0 &lt; x &lt; al e for 0 &lt; x0 &lt; al e; the point 
(ale,O) for x0 =ale; and the line ale&lt;x&lt;oo for x0 &gt;ale. Thus, the x-
axis, for x ~ 0, is the union of four disjoint orbits of (2). Similarly, (see Ex-
ercise 14), the positive y-axis is a single orbit of (2). Thus, if a solution 
</p>
<p>429 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>y 
</p>
<p>a/b 
</p>
<p>II 
I 
</p>
<p>'&lt;0, y&lt;O 
</p>
<p>L-------------~--------~---------------- X 
ale c/d 
</p>
<p>Figure 1 
</p>
<p>x(t), y(t) of (2) leaves the first quadrant, its orbit must cross another orbit, 
and this is precluded by the uniqueness of orbits (Property 1, Section 4.6). 
</p>
<p>Our next step is to divide the first quadrant into regions where dx I dt 
and dy I dt have fixed signs. This is accomplished by drawing the lines 
/ 1 : a- by- ex =0, and /2 : - c + dx- fy =0, in the x-y plane. These lines 
divide the first quadrant into three regions I, II, and 111 as shown in Figure 
1. (The lines /1 and /2 do not intersect in the first quadrant if c I d &gt; a I e.) 
Now, observe that ex + by is less than a in region I, while ex + by is greater 
than a in regions II and 111. Consequently, dx I dt is positive in region I 
and negative in regions II and III. Similarly, dy I dt is negative in regions I 
and II and positive in region 111. 
</p>
<p>Next, we prove the following four simple Iemmas. 
</p>
<p>Lemma 3. Any solution x(t), y(t) of (2) which starts in region I at timet= t0 
will remain in this region jor all future time t ;;;. t0 and ultimately approach 
the equilibrium solution x = a I e, y = 0. 
</p>
<p>PROOF. Suppose that a solution x(t), y(t) of (2) leaves region I at timet= 
t*. Then, .X( t*) = 0, since the only way a solution can leave region I is by 
crossing the line /1&bull; Differentiating both sides of the first equation of (2) 
with respect to t and setting t = t* gives 
</p>
<p>d 2x(t*) dy(t*) 
dt2 = -bx(t*)~. 
</p>
<p>This quantity is positive. Hence, x( t) has a minimum at t = t*. But this is 
impossible, since x(t) is always increasing whenever x(t), y(t) is in region 
</p>
<p>430 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.8 Long time behavior of solutions; the Poincare-Bendixson Theorem 
</p>
<p>I. Thus, any solution x(t), y(t) of (2) which starts in region I at timet= t0 
will remain in region I for all future time t ~ t0. This implies that x(t) is a 
monotonic increasing function of time, and y ( t) is &middot; a monotonic decreasing 
function of time fort~ t0, with x(t)&lt;ale andy(t)&gt;O. Consequently, by 
Lemma I, both x(t) and y(t) have Iimits ~' 11 respectively, as t approaches 
infinity. Lemma 2 implies that (~, T/) is an equilibrium point of (2). Now, it 
is easily verified that the only equilibrium points of (2) in the region x ~ 0, 
y ~ 0 are x = 0, y = 0, and x = a I e, y = 0. Clearly, ~ cannot equal zero since 
x( t) is increasing in region I. Therefore, ~ = a I e and 11 = 0. 0 
</p>
<p>Lemma 4. Any solution x(t), y(t) of (2) which starts in region 111 at timet= 
t0 must leave this region at some later time. 
</p>
<p>PROOF. Suppose that a solution x(t), y(t) of (2) remains in region 111 for 
all time t ~ t0 &bull; Then, x(t) is a monotonic decreasing function of time, and 
y(t) is a monotonic increasing function of time, fort~ t0&bull; Moreover, x(t) is 
greater than c I d and y(t) is less than (dx(t0)- c)l f. Consequently, both 
x(t) and y(t) have Iimits ~' 11 respectively, as t approaches infinity. Lemma 
2 implies that (~, 11) is an equilibrium point of (2). But (~, 11) cannot equal 
(0, 0) or ( a I e, 0) if x( t), y ( t) is in region III for t ~ t0. This contradiction 
establishes Lemma 4. 0 
</p>
<p>Lemma 5. Any solution x(t), y(t) of (2) which starts in region II at time t = 
t0 and remains in region II for all future time t ~ t0 must approach the 
</p>
<p>equilibrium solution x = a I e, y = 0. 
</p>
<p>PRooF. Suppose that a solution x(t), y(t) of (2) remains in region II for all 
timet~ t0&bull; Then, both x(t) andy(t) are monotonic decreasing functions of 
timefort ~ t0 , with x(t)&gt;O andy(t)&gt;O. Consequently, by Lemma I, both 
x(t) and y(t) have Iimits ~' 11 respectively, as t approaches infinity. Lemma 
2 implies that (~, T/) is an equilibrium point of (2). Now, (~, T/) cannot equal 
(0, 0). Therefore, ~ = a I e, 11 = 0. 0 
</p>
<p>Lemma 6. A solution x(t),y(t) of (2) cannot enter region III from region II. 
</p>
<p>PROOF. Suppose that a solution x(t), y(t) of (2) leaves region II at timet= 
t* and enters region III. Then, y( t*) = 0. Differentiating both sides of the 
second equation of (2) with respect to t and setting t = t* gives 
</p>
<p>d 2y(t*) dx(t*) 
2 =4Y(t*)-d-. 
</p>
<p>dt t 
</p>
<p>This quantity is negative. Hence, y(t) has a maximum at t = t*. But this is 
impossible, sincey(t) is decreasing whenever x(t),y(t) is in region II. 0 
</p>
<p>Finally, observe that a solution x(t), y(t) of (2) which starts on 11 must 
immediately enter region I, and that a solution which starts on 12 must im-
</p>
<p>431 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>mediately enter region II. It now follows immediately from Lemmas 3-6 
that every solution x(t),y(t) of (2), with x(O)&gt;O andy(O)&gt;O, approaches 
the equilibrium solution x=aje,y=O as t approaches infinity. 
</p>
<p>Up to now, the solutions and orbits of the nonlinear equations that we 
have studied behaved very much like the solutions and orbits of linear 
equations. In actual fact, though, the situation is very different. The solu-
tions and orbits of nonlinear equations, in general, exhibit a completely 
different behavior than the solutions and orbits of linear equations. A 
standard example is the system of equations 
</p>
<p>: = -y+x(1-x2-y2), ~ =x+y(1-x2-y2). (3) 
</p>
<p>Since the term x 2 + y 2 appears prominently in both equations, it suggests 
itself to introduce polar coordinates r,O, where x=rcosO,y=rsinO, and to 
rewrite (3) in terms of r and 0. To this end, we compute 
</p>
<p>d 2 dr dx dy 
dtr = 2r dt = 2x dt + 2y dt 
</p>
<p>=2(x2+ y2)-2(x2+y2)2 =2r2(1- r2). 
</p>
<p>Similarly, we compute 
</p>
<p>dy dx 
dO d Y 1 x dt - Y dt x 2 + y 2 
- = -arctan- =- =---=I. 
dt dt x x2 1+(yjx)2 x2+y2 
</p>
<p>Consequently, the system of equations (3) is equivalent to the system of 
equations 
</p>
<p>dr 2 -=r(I-r) 
dt ' 
</p>
<p>d() = 1 
dt . 
</p>
<p>The general solution of (4) is easily seen to be 
</p>
<p>ro 
r( t) = I/2 ' 
</p>
<p>[r6+(I-r6)e- 2'] 
</p>
<p>where r0 = r(O) and 00 = 0(0). Hence, 
</p>
<p>ro 
x(t)= 112 cos(t+00 ), 
</p>
<p>[r6+(1-r6)e- 2'] 
</p>
<p>ro . 
y(t)= 112 sm(t+00 ). 
</p>
<p>[ r6+ (1- r6)e- 21 ] 
</p>
<p>(4) 
</p>
<p>(5) 
</p>
<p>N ow, observe first that x = 0, y = 0 is the only equilibrium solution of (3). 
Second, observe that 
</p>
<p>x(t) =cos(t + 00 ), y(t) = sin(t + 00 ) 
</p>
<p>432 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.8 Long time behavior of solutions; the Poincare-Bendixson Theorem 
</p>
<p>y 
</p>
<p>Figure 2. The phase portrait of (3) 
</p>
<p>when r0 = 1. This solution is periodic with period 2'17, and its orbit is the 
unit circle x 2 + y 2 = 1. Finally, observe from (5) that r( t) approaches one as 
t approaches infinity, for r0 i=O. Hence, all the orbits of (3), with the excep-
tion of the equilibrium point x = 0, y = 0, spiral into the unit circle. This 
situation is depicted in Figure 2. 
</p>
<p>The system of equations (3) shows that the orbits of a nonlinear system 
of equations may spiral into a simple closed curve. This, of course, is not 
possible for linear systems. Moreover, it is often possible to prove that 
orbits of a nonlinear system spiral into a closed curve even when we 
cannot explicitly solve the system of equations, or even find its orbits. This 
is the content of the following celebrated theorem. 
</p>
<p>Theorem S. (Poincare-Bendixson.) Suppose that a solution x = x(t), y = 
y(t) of the system of differential equations 
</p>
<p>dx dy 
dt=j(x,y), dt=g(x,y) (6) 
</p>
<p>remains in a bounded region of the plane which contains no equi/ibrium 
points oj (6). Then, its orbit must spiral into a simple c/osed curoe, which is 
itself the orbit of a periodic solution of (6). 
</p>
<p>Example 2. Prove that the second-order differential equation 
</p>
<p>i+(z2 +2i2 -I)i+z=O (7) 
</p>
<p>has a nontrivial periodic solution. 
</p>
<p>433 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>Solution. First, we convert Equation (7) to a system of two first-order 
equations by setting x = z and y = i. Then, 
</p>
<p>dy 
dt = -x+(I-x2-2y2)y. dx dt =y, (8) 
</p>
<p>Next, we try and find a bounded region R in the x-y plane, containing no 
equilibrium points of (8), and having the property that every solution x(t), 
y(t) of (8) which starts in R at time t = t0, remains there for allfuturetime 
t ~ t0&bull; lt can be shown that a simply connected region such as a square or 
disc will never work. Therefore, we try and take R to be an annulus 
surrounding the origin. To this end, compute 
</p>
<p>!!_ ( x2+ y2) = x dx + y dy =(I- x2-2y2)y2 
dt 2 dt dt , 
</p>
<p>and observe that 1- x2- 2y2 is positive for x2 + y 2 &lt; t and negative for 
x2 + y 2 &gt; I. Hence, x2( t) + y 2( t) is increasing along any solution x( t), y ( t) 
of (8) when x2 + y 2 &lt; t and decreasing when x2 + y 2 &gt; I. This implies that 
any solution x(t),y(t) of (8) which starts in the annulus i&lt;x2 +y 2 &lt;1 at 
time t = t0 will remain in this annulus for all future time t ~ t0&bull; Now, this 
annulus contains no equilibrium points of (8). Consequently, by the 
Poincare-Bendixson Theorem, there exists at least one periodic solution 
x(t), y(t) of (8) lying entirely in this annulus, and then z = x(t) is a nontri-
vial periodic solution of (7). 
</p>
<p>EXERCISES 
</p>
<p>1. What Really Happened at the Paris Peace Talks 
</p>
<p>434 
</p>
<p>The original plan developed by Henry Kissinger and Le Duc Tho to settle the 
Vietnamese war is described below. It was agreed that 1 million South Viet-
namese ants and 1 million North Vietnamese ants would be placed in the back-
yard of the Presidential palace in Paris and be allowed to fight it out for a long 
period of time. If the South Vietnamese ants destroyed nearly all the North 
Vietnamese ants, then South Vietnam would retain control of all of its land. If 
the North Vietnamese ants were victorious, then North Vietnam would take 
over all of South Vietnam. If they appeared to be fighting to a standoff, then 
South Vietnam would be partitioned according to the proportion of ants re-
maining. Now, the South Vietnamese ants, denoted by S, and the North Viet-
namese ants, denoted by N, compete against each other according to the 
following differential equations: 
</p>
<p>dS 1 1 
dt=WS- 20SXN 
</p>
<p>(&bull;) 
</p>
<p>Note that these equations correspond to reality since the South Vietnamese 
ants multiply much more rapidly than the North Vietnamese ants, but the 
North Vietnamese ants are much better fighters. </p>
<p/>
</div>
<div class="page"><p/>
<p>4.8 Long time behavior of solutions; the Poincare-Bendixson Theorem 
</p>
<p>The battle began at 10:00 sharp on the morning of May 19, 1972, and was 
supervised by a representative of Poland and a representative of Canada. At 
2:43p.m. on the afternoon of May 21, the representative of Poland, being un-
happy with the progress of the battle, slipped a bag of North Vietnamese ants 
into the backyard, but he was spotted by the eagle eyes of the representative of 
Canada. The South Vietnamese immediately claimed a foul and called off the 
agreement, thus setting the stage for the protracted talks that followed in Paris. 
The representative of Poland was hauled before a judge in Paris for sentencing. 
The judge, after making some remarks about the stupidity of the South Viet-
namese, gave the Polish representative a very light sentence. Justify mathemati-
cally the judge's decision. Hint: 
(a) Show that the lines N = 2 and N + S = I divide the first quadrant into three 
</p>
<p>regions (see Figure 3) in which dS I dt and dN I dt have fixed signs. 
(b) Show that every solution S ( t), N ( t) of (*) which starts in either region I or 
</p>
<p>region 111 must eventually enter region II. 
(c) Show that every solution S(t),N(t) of (*) which starts in region II mustre-
</p>
<p>main there for all future time. 
(d) Conclude from (c) that S(t)~oo for all solutions S(t),N(t) of (*) with 
</p>
<p>S ( t0) and N ( t0) positive. Conclude too that N ( t) has a finite Iimit ( .;;; 2) as 
t~oo. 
</p>
<p>(e) To prove that N (t)~o. observe that there exists t0 such that dN I dt.;;; - N 
fort&gt; t0&bull; Conclude from this inequality that N(t)~O as t~oo. 
</p>
<p>N 
</p>
<p>m 
. . 
S&lt; 0, N&lt;O 
</p>
<p>2 
</p>
<p>1I S&gt;O,N&lt;O 
</p>
<p>1 
</p>
<p>Figure 3 
</p>
<p>2. Consider the system of differential equations 
</p>
<p>dx dy 
-=ax-bxy -=cy-dxy-ey2 
dt ' dt 
</p>
<p>(*) 
</p>
<p>with alb&gt;cle. Prove thaty(t)~O as t~oo, for every solu~on x(t),y(t) of (*) 
with x(t0) andy(t0) positive. Hint: Follow the outline in Exercise 1. 
</p>
<p>3. (a) Without computing the eigenvalues of the matrix 
</p>
<p>( -~ -D&middot; 
435 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>X1&lt;0 
.nz: Xa&lt; 0 x,= 3x1 
</p>
<p>x, 
</p>
<p>JI[ x.&lt; o x2&gt;0 
</p>
<p>Figure 4 
</p>
<p>prove that every solution x(t) of 
</p>
<p>x=(-i I )x -3 
approaches zero as t approaches infinity. Hint: (a) Show that the lines x2 = 
3x1 and x1 =3x2 divide the x 1- x2 plane into four regions (see Figure 4) in 
which .X 1 and .X2 have fixed signs. 
</p>
<p>(b) Show that every solution x(t) which starts in either region I or II must re-
main there for all future time and ultimately approach the equilibrium solu-
tion x=O. 
</p>
<p>(c) Show that every solution x(t) which remains exclusively in region III or IV 
must ultimately approach the equilibrium solution x = 0. 
</p>
<p>A closed curve C is said to be a Iimit cycle of 
</p>
<p>x=f(x,y), .Y= g(x,y) (*) 
</p>
<p>if orbits of (*) spiral into it, or away from it. lt is stable if all orbits of (*) 
passing sufficiently close to it must ultimately spiral into it, and unstable 
otherwise. Find alllimit cycles of each of the following systems of differen-
tial equations. (Hint: Compute d(x 2 + y 2)/ dt. Observe too, that C must be 
the orbit of a periodic solution of (*) if it contains no equilibrium points of 
(*).) 
</p>
<p>x(x2 +y2 -2) 
4 &bull; .X= - y- ---====--
</p>
<p>Yx2+y2 
</p>
<p>y(x2+y2-2) 
y =X- ---====--
</p>
<p>Vx2+y2 
</p>
<p>436 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.9 Introduction to bifurcation theory 
</p>
<p>6. x= y+ x(x2+y2-l)(x2+ y 2-2) 
j= -x+y(x2+y2-1Xx2+y2-2) 
</p>
<p>8. (a) Show that the system 
</p>
<p>7. x=xy+xcos(x2+y2) 
j= -x2+ycos(x2+y2) 
</p>
<p>x=y+xf(r)/r, j= -x+yf(r)/r (*) 
</p>
<p>has Iimit cycles corresponding to the zeros of f(r). What is the direction of 
motion on these curves? 
</p>
<p>(b) Determine all Iimit cycles of (*) and discuss their stability if f(r)= 
(r-3)2(r2-5r+4). 
</p>
<p>Use the Poincare-Bendixson Theorem to prove the existence of a nontri-
vial periodic solution of each of the following differential equations. 
</p>
<p>11. (a) According to Green's theorem in the plane, if Cis a closed curve which is 
sufficiently "smooth," and if f and g are continuous and have continuous 
first partial derivatives, then 
</p>
<p>9i [f(x,y)dy- g(x,y)dx) = J J [fx(x,y)+ gy(x,y) J dxdy 
C R 
</p>
<p>where R is the region enclosed by C. Assurne that x(t), y(t) is a periodic 
solution of x = f(x,y), j = g(x,y), and Iet C be the orbit of this solution. 
Show that for this curve, the line integral above is zero. 
</p>
<p>(b) Suppose that fx + gY has the same sign throughout a simply connected re-
gion D in the x-y plane. Show that the system of equations x = f(x,y), 
j = g(x,y) can have no periodic solution which is entirely in D. 
</p>
<p>12. Show that the system of differential equations 
</p>
<p>x=x+y2+x3, j= -x+y+yx2 
</p>
<p>has no nontrivial periodic solution. 
</p>
<p>13. Show that the system of differential equations 
</p>
<p>has no nontrivial periodic solution which lies inside the circle x 2 + y 2 = 4. 
</p>
<p>14. (a) Show that x = 0, y = 1/;( t) is a solution of (2) for any function 1/;( t) satisfying 
~=-ctJ;-ft/12. 
</p>
<p>(b) Choose 1/;( t0) &gt; 0. Show that the orbit of x = 0, y = 1/;( t) (for all t for which 1/; 
exists) is the positive y axis. 
</p>
<p>4.9 Introduction to bifurcation theory 
</p>
<p>Consider the system of equations 
</p>
<p>x=f(x,e) 
where 
</p>
<p>(1) 
</p>
<p>437 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>and e is a scalar. Intuitively speaking a bifurcation point of (1) is a value of e 
at which the solutions of (1) change their behavior. More precisely, we say 
that e= e0 is a bifurcation point of (I) if the phase portraits of (I) for e&lt; e0 
and e &gt; e0 are different. 
</p>
<p>Remark. In the examples that follow we will appeal to our intuition in 
deciding whether two phase portraits are the same or are different. In more 
advanced courses we define two phase portraits to be the same, or topologi-
cally equivalent, if there exists a continuous transformation of the plane 
onto itself which maps one phase portrait onto the other. 
</p>
<p>Example 1. Find the bifurcation points of the system 
</p>
<p>x=Ax=(~ _nx 
Solution. The characteristic polynomial of the matrix A is 
</p>
<p>p(A.) = det(A- Al) 
</p>
<p>= det{ I -1 A. e ) 
-I-A. 
</p>
<p>= (A. -I)(A. +I)- e 
</p>
<p>=A.2 -(I+e). 
</p>
<p>(2) 
</p>
<p>The roots ofp(A.) are &plusmn;y'f+""E for e&gt; -I, and &plusmn;/- e-I i for e&lt; -I. This 
</p>
<p>12: 
</p>
<p>x1 = (1 +v'l+&euro;) x2 
</p>
<p>Figure 1. Phaseportrait of (2) fort:&gt; -1 
</p>
<p>438 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.9 Introduction to bifurcation theory 
</p>
<p>x, 
</p>
<p>Figure 2. Phase portrait of (2) for e == - 1 
</p>
<p>implies that x = 0 is a saddle for e&gt; -1, and a center for e&lt; -1. We 
conclude, therefore, that e = - I is a bifurcation point of (2). lt is also clear 
that Eq. (2) has no other bifurcation points. 
</p>
<p>lt is instructive to see how the solutions of (2) change as e passes through 
the bifurcation value -1. For e &gt; -1, the eigenvalues of A are 
</p>
<p>A1 =/I+e, A2 =-/I+e. 
lt is easily verified (see Exercise 10) that 
</p>
<p>xl=(l+v11+e) 
</p>
<p>is an eigenvector of A with eigenva1ue /I+E, whi1e 
</p>
<p>is an eigenvector with eigenva1ue -li+&euro;. Hence, the phase portrait of (2) 
has the form shown in Figure 1. As e-&gt; -1 from the 1eft, the lines /1 and /2 
both approach the line x 1 = x2 . This 1ine is a 1ine of equilibrium points of 
(2) when e = -1, whi1e each line x 1 - x2 = c ( c'i' 0) is an orbit of (2) for 
e = - 1. The phase portrait of (2) for e = - 1 is given in Figure 2. 
</p>
<p>Example 2. Find the bifurcation points of the system 
</p>
<p>x = Ax = ( ~ = ~ )x. (3) 
439 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>Solution. The characteristic polynomial of the matrix A is 
</p>
<p>p(A)=det(A-AI)=det( -eA 
</p>
<p>=A(l+A)+e 
</p>
<p>and the roots of p( A) are 
</p>
<p>-1 ) 
-1-A 
</p>
<p>Observe that A 1 is positive and A 2 is negative for e &lt; 0. Hence, x = 0 is a 
saddle for e &lt; 0. F or 0 &lt; e &lt; 114, both A 1 and A 2 are negative. Hence x = 0 
is a stable node for 0 &lt; e &lt; 114. Both A 1 and A 2 are complex, with negative 
real part, for e&gt; 114. Hence x = 0 is a stable focus for e&gt; 114. Note that the 
phase portrait of (3) changes as e passes through 0 and 114. W e conclude, 
therefore, that e = 0 and e = 1 I 4 are bifurcation points of (3). 
</p>
<p>Example 3. Find the bifurcation points of the system of equations 
</p>
<p>dx 1 
---;]( = x2 
</p>
<p>dx2- 2 
dt -xl-x2-e. 
</p>
<p>(4) 
</p>
<p>Solution. (i) We first find the equilibrium points of ( 4). Setting dx 11 dt = 0 
gives x 2 = 0, and then setting dx 2 ldt = 0 gives xf- e= 0, so that x 1 = &plusmn;1&euro;, 
e &gt; 0. Hence, ( 1&euro;, 0) and (-1&euro;, 0) are two equilibrium points of ( 4) for 
e &gt; 0. The system ( 4) has no equilibrium points when e &lt; 0. We conclude, 
therefore, that e= 0 is a bifurcation point of (4). (&uuml;) We now analyze the 
behavior of the solutions of ( 4) near the equilibrium points ( &plusmn;.f&euro;, 0) to 
determine whether this system has any additional bifurcation points. Setting 
</p>
<p>U = X 1 +-{e, V= X 2 
</p>
<p>gives 
</p>
<p>du 
dt =v 
</p>
<p>~~ =(u&plusmn;{e)2 -v-e=&plusmn;2{eu-v+u2 &bull; 
(5) 
</p>
<p>440 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.9 Introduction to bifurcation theory 
</p>
<p>The system (5) can be written in the form 
</p>
<p>By Theorem 4, the phase portrait of (4) near the equilibrium solution 
</p>
<p>is determined by the phase portrait of the linearized system 
</p>
<p>To find the eigenvalues of A we compute 
</p>
<p>p(A) = det(A- Al) 
</p>
<p>( 
-A 
</p>
<p>= det &plusmn; 2{e 
</p>
<p>Hence, the eigenvalues of A when u = x 1 -Ii are 
</p>
<p>-I+JI+S{e -1-JI+S{e 
AI= 2 ' Az = 2 (6) 
</p>
<p>while the eigenvalues of A when u = x 1 + Ii are 
</p>
<p>-1+/t-s{e -l-~I-8{e 
AI= ___ 2 ___ ' Az = ___ 2 __ _ (7) 
</p>
<p>Observe from (6) that A1 &gt; 0, while A2 &lt; 0. Thus, the system (4) behaves like 
</p>
<p>a saddle near the equilibrium points ( ~ ) . On the other band, we see from 
(7) that both A 1 and A 2 are negative for 0 &lt; e &lt; I I 64, and complex for 
e&gt;1164. Consequently, the system (4) near the equilibrium solution 
</p>
<p>( -: ) behaves like a stable node for 0 &lt; e &lt; 1164, and a stable focus for 
</p>
<p>e&gt; 1164. It can be shown that the phase portraits of a stable node and a 
stable focus are equivalent. Consequently, e = 1164 is not a bifurcation point 
of (4). 
</p>
<p>441 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>Another situation which is included in the context of bifurcation theory, 
</p>
<p>and which is of much current research interest now, is when the system (1) 
</p>
<p>has a certain number of equilibrium, or periodic, solutions for e = e0 , and a 
different number for e* e0 &bull; Suppose, for example, that x(t) is an equi-
librium, or periodic, solution of ( 1) for e = 0, and x 1( t ), x 2( t ), ... , x k( t) are 
equilibria, or periodic solutions of ( 1) for e * 0 which approach x( t) as 
e--&gt; 0. In this case we say that the solutions x1(t),x2(t), ... ,xk(t) bifurcate 
from x(t). Weillustrate this situation with the following example. 
</p>
<p>Example 4. Find all equilibrium solutions of the system of equations 
</p>
<p>dx!- 2 2 dt-3ex 1 -3ex2 -x 1 -x2 
</p>
<p>dx 
dt = ex 1 - x 1x 2 =x 1(e- x 2 ). 
</p>
<p>(8) 
</p>
<p>Solution. Let ( ;~) be an equilibrium solution of the system (8). The second 
equation of (8) implies that x 1 = 0 or x 2 = e. 
</p>
<p>x 1 = 0. In this case, the first equation of (8) implies that 
</p>
<p>0 = 3ex2 + x~ = x 2(3e+ x 2 ) 
</p>
<p>so that x 2 = 0 or x 2 =- 3e. Thus { ~) and { _03e) are two equilibrium 
points of (8). 
</p>
<p>x 2 = e. In this case, the first equation of (8) imp1ies that 
</p>
<p>or 
</p>
<p>The solutions 
</p>
<p>of (9) are complex. Thus, 
</p>
<p>3e&plusmn;}9e2 -16e2 
</p>
<p>x!= 2 
</p>
<p>and x 2 = { 0 ) -3e 
</p>
<p>(9) 
</p>
<p>are two equilibrium points of (8), for e * 0, which bifurcate from the single 
equilibrium point x = { ~) when e = 0. 
</p>
<p>442 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.10 Predator-prey prob1ems 
</p>
<p>EXERCISES 
</p>
<p>Find the bifurcation points of each of the following systems of equations. 
</p>
<p>l.x={! 
3. x={ ~ 2 ;)x 
5. x =( ~ ~ E )x 
</p>
<p>2.x={! 
4. x = ( ~ 
</p>
<p>In each of Problems 6-8, show that more than one equilibrium solutions 
bifurcate from the equilibrium solution x = 0 when e = 0. 
6. x1 = EX 1 - EX 2 - x? + xi 
</p>
<p>Xz = EXz + x 1x 2 
8. x1 = EX 2 + x 1x 2 
</p>
<p>Xz =- EX 1 + EXz + xf + xi 
9. Consider the system of equations 
</p>
<p>x1 = 3Ex 1-5Ex2 - xf + xi 
x2 = 2Ex 1 - EX 2 . 
</p>
<p>7. x]=Ex]-x?-x!x1 
x2 = -2Ex1 +2Ex2 + x 1x 2 - xi 
</p>
<p>(a) Show that each point on the lines x 2 = x 1 
points of ( *) for E = 0. 
</p>
<p>and x 2 = - x 1 are equilibrium 
</p>
<p>(b) Show that 
</p>
<p>(XI) _ ( 0) ( X1) _ 7 ( 1) Xz - 0 and Xz -"JE 2 . 
are the only equilibrium points of ( *) for E =!= 0. 
</p>
<p>10. Show that 
</p>
<p>are eigenvectors of the matrix { ~ _:. 1 ) with eigenvalues v"f+f and - v"f+f 
respectively. 
</p>
<p>4.10 Predator-prey problems; or why the 
percentage of sharks caught in the 
Mediterranean Sea rose dramatically 
during World War I 
</p>
<p>In the mid 1920's the ltalian biologist Umberto D'Ancona was studying 
the population variations of various species of fish that interact with each 
other. In the course of his research, he came across some data on per-
</p>
<p>443 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>centages-of-total-catch of several species of fish that were brought into dif-
ferent Mediterranean ports in the years that spanned World War I. In par-
ticular, the data gave the percentage-of-total-catch of selachians, (sharks, 
skates, rays, etc.) which are not very desirable as food fish. The data for 
the port of Fiume, Italy, during the years 1914-1923 is given below. 
</p>
<p>1914 
11.9% 
</p>
<p>1919 
27.3% 
</p>
<p>1915 
21.4% 
</p>
<p>1920 
16.0% 
</p>
<p>1916 
22.1% 
</p>
<p>1921 
15.9% 
</p>
<p>1917 
21.2% 
</p>
<p>1922 
14.8% 
</p>
<p>1918 
36.4% 
</p>
<p>1923 
10.7% 
</p>
<p>D' Ancona was puzzled by the very large increase in the percentage of 
selachians during the period of the war. Obviously, he reasoned, the in-
crease in the percentage of selachians was due to the greatly reduced Ievel 
of fishing during this period. But how does the intensity of fishing affect 
the fish populations? The answer to this question was of great concern to 
D' Ancona in bis research on the struggle for existence between competing 
species. It was also of concern to the fishing industry, since it would have 
obvious implications for the way fishing should be done. 
</p>
<p>Now, what distinguishes the selachians from the food fish is that the 
selachians are predators, while the food fish are their prey; the selachians 
depend on the food fish for their survival. At first, D' Ancona thought that 
this accounted forthelarge increase of selachians during the war. Since the 
Ievel of fishing was greatly reduced during this period, there were more 
prey available to the selachians, who therefore thrived and multiplied 
rapidly. However, this explanation does not hold any water since there 
were also more food fish during this period. D' Ancona's theory only shows 
that there are more selachians when the Ievel of fishing is reduced; it does 
not explain why a reduced Ievel of fishing is more beneficial to the preda-
tors than to their prey. 
</p>
<p>After exhausting all possible biological explanations of this phenome-
non, D'Ancona turned to his colleague, the famous ltalian mathematician 
Vito Volterra. Hopefully, Volterra would formulate a mathematical model 
of the growth of the selachians and their prey, the food fish, and this 
model would provide the answer to D' Ancona's question. Volterra began 
bis analysis of this problern by separating all the fish into the prey popula-
tion x(t) and the predator populationy(t). Then, he reasoned that the food 
fish do not compete very intensively among themselves for their food 
supply since this is very abundant, and the fish population is not very 
dense. Hence, in the absence of the selachians, the food fish would grow 
according to the Malthusian law of population growth x = ax, for some 
positive constant a. Next, reasoned Volterra, the nurober of contacts per 
unit time between predators and prey is bxy, for some positive constant b. 
Hence, x = ax- bxy. Similarly, Volterra concluded that the predators have 
a natural rate of decrease - cy proportional to their present number, and 
</p>
<p>444 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.10 Predator-prey problems 
</p>
<p>that they also increase at a rate dxy proportional to their present number y 
and their food supply x. Thus, 
</p>
<p>dx -=ax-bxy 
dt ' 
</p>
<p>dy 
dt = - cy + dxy. (1) 
</p>
<p>The system of equations (1) governs the interaction of the selachians 
and food fish in the absence of fishing. W e will carefully analyze this sys-
tem and derive several interesting properties of its solutions. Then, we will 
include the effect of fishing in our model, and show why a reduced level of 
fishing is more beneficial to the selachians than to the food fish. In fact, we 
will derive the surprising result that a reduced level of fishing is actually 
harmful to the food fish. 
</p>
<p>Observe first that (1) has two equilibrium solutions x(t)=O,y(t)=O and 
x(t)= cl d, y(t) = al b. The first equilibrium solution, of course, is of no in-
terest to us. This systemalso has the family of solutions x(t) = x0ea1, y(t) = 
0 and x(t)=O,y(t)=y0e-c1&bull; Thus, both the x andy axes are orbits of (1). 
This implies that every solution x(t), y(t) of (1) which starts in the first 
quadrant x &gt; 0, y &gt; 0 at time t = t0 will remain there for all future time t ~ 
lo. 
</p>
<p>The orbits of (1), for x,y;FO are the solution curves of the first-order 
equation 
</p>
<p>dy -cy+dxy y(-c+dx) 
</p>
<p>dx = ax - bxy x ( a - by) &middot; 
(2) 
</p>
<p>This equation is separable, since we can write it in the form 
</p>
<p>a-by dy -c+dx 
</p>
<p>y dx x 
</p>
<p>Consequently, a lny- by + clnx- dx = k 1, for some constant k 1&bull; Taking 
exponentials of both sides of this equation gives 
</p>
<p>(3) 
</p>
<p>for some constant K. Thus, the orbits of (1) are the family of curves de-
fined by (3), and these curves are closed as we now show. 
</p>
<p>Lemma 1. Equation (3) defines a family of closed curves for x, y &gt; 0. 
</p>
<p>PROOF. Our first step is to determine the beha vior of the functions f (y) = 
y a I eby and g(x) = xc I edx for x and y positive. To this end, observe that 
f(O) = 0, f( oo) = 0, and f(y) is positive for y &gt; 0. Computing 
</p>
<p>aya-l_bya ya-l(a-by) 
f' (y) = by = by ' 
</p>
<p>e e 
</p>
<p>we see thatf(y) has a single critical point aty=alb. Consequently,j(y) 
achieves its maximum value My=(albtlea aty=alb, and the graph of 
</p>
<p>445 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>f(y) 
</p>
<p>--~------~----~==~y 
</p>
<p>alb 
</p>
<p>(a) 
</p>
<p>g(x) 
</p>
<p>--~------~--------~x 
c/d 
</p>
<p>(b) 
</p>
<p>Figure 1. (a) Graph off(y)=yae-hY; (b) Graph of g(x)=xce-dx 
</p>
<p>j(y) has the form described in Figure la. Similarly, g(x) achieves its maxi-
mum value Mx =(cl dY I ec at x = cl d, and the graph of g(x) has the form 
described in Figure 1 b. 
</p>
<p>From the preceding analysis, we conclude that Equation (3) has no solu-
tion x,y&gt;O for K&gt;MxMy, and the single solution x=cld,y=alb for K 
=Mx MY. Thus, we need only consider the case K = A.MY, where A. is a posi-
tive number less than Mx. Observe first that the equation xcledx=A. has 
one solution x = xm &lt; c I d, and one solution x = xM &gt; c I d. Hence, the 
equation 
</p>
<p>has no solutiony when x is less than xm or greater than xM. It has the sin-
gle solutiony = al b when x =xm or xM, and it has two solutionsy 1(x) and 
h(x) for each x between xm and xM. The smaller solution y 1(x) is always 
less than al b, while the larger solution h(x) is always greater than a/ b. 
As x approaches either xm or xM, bothy 1(x) andyix) approach al b. Con-
sequently, the curves defined by (3) are closed for x and y positive, and 
have the form described in Figure 2. Moreover, none of these closed curves 
(with the exception of x = c I d, y = a I b) contain any equilibrium points of 
(1). Therefore, all solutions x(t), y(t) of (1), with x(O) and y(O) positive, 
are periodic functions of time. That is to say, each solution x(t), y(t) of 
(1), with x(O) andy(O) positive, has the property that x(t+ T)=x(t) and 
y(t + T) = y(t) for some positive T. 0 
</p>
<p>Now, the data of D'Ancona is really an average over each one year 
period of the proportion of predators. Thus, in order to compare this data 
with the predictions of (1), we must compute the "average values" of x(t) 
and y(t), for any solution x(t), y(t) of (1). Remarkably, we can find these 
average values even though we cannot compute x(t) andy(t) exactly. This 
is the content of Lemma 2. 
</p>
<p>446 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.10 Predator-prey problems 
</p>
<p>y 
</p>
<p>o/b &bull; 
</p>
<p>L-------~------------~~-------------J---X 
xm c/d 
</p>
<p>Figure 2. Orbits of (1) for x,y positive 
</p>
<p>Lemma 2. Let x( t), y ( t) be a periodic solution of (I), with period T &gt; 0. De-
fine the average values of x and y as 
</p>
<p>I (T 
x= T Jo x(t)dt, 
</p>
<p>I (T 
y = T Jo y(t)dt. 
</p>
<p>Then, x=cld andy=alb. In other words, the average values of x(t) and 
y(t) are the equilibrium values. 
</p>
<p>PRooF. Dividing both sides of the first equation of (1) by x gives .X I x = 
a-by, so that 
</p>
<p>I (T i(t) I (T 
T }
</p>
<p>0 
x(t)dt= T)o [a-by(t)]dt. 
</p>
<p>Now, JoTx(t)lx(t)dt=Inx(T)-Inx(O), and this equals zero since x(T)= 
</p>
<p>x(O). Consequently, 
</p>
<p>l. (Tby(t)dt= l. (Tadt=a, 
T Jo T Jo 
</p>
<p>so that y = a I b. Similarly, by dividing both sides of the second equation of 
(I) by Ty ( t) and integrating from 0 to T, we obtain that .X= c I d. D 
</p>
<p>We are now ready to include the effects of fishing in our model. Ob-
serve that fishing decreases the population of food fish at a rate u(t), and 
decreases the population of selachians at a rate ey(t). The constant e re-
flects the intensity of fishing; i.e., the number of boats at sea and the num-
ber of nets in the water. Thus, the true state of affairs is described by the 
</p>
<p>447 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>modified system of differential equations 
</p>
<p>dx = ax- b.xy- ex= (a- e)x- b.xy 
dt 
dy 
dt = - cy + dxy - ey = - ( c + e) y + dxy. 
</p>
<p>(4) 
</p>
<p>This system is exactly the same as (1) (for a- e &gt; 0), with a replaced by 
a-e, and c replaced by c+e. Hence, the average values of x(t) andy(t) 
are now 
</p>
<p>- c+e x=--d , 
- a-e 
y=-b-. (5) 
</p>
<p>Consequently, a moderate amount of fishing (e &lt; a) actually increases the 
number of food fish, on the average, and decreases the number of 
selachians. Conversely, a reduced Ievel of fishing increases the number of 
selachians, on the average, and decreases the number of food fish. This re-
markable result, which is known as Volterra's principle, explains the data 
of D' Ancona, and completely solves our problem. 
</p>
<p>Volterra's principle has spectacular applications to insecticide treat-
ments, which destroy both insect predators and their insect prey. lt implies 
that the application of insecticides will actually increase the population of 
those insects which are kept in control by other predatory insects. A re-
markable confirmation comes from the cottony cushion scale insect 
(Icerya purchasi), which, when accidentally introduced from Australia in 
1868, threatened to destroy the American citrus industry. Thereupon, its 
natural Australian predator, a ladybird beetle (Novius Cardinalis) was in-
troduced, and the beetles reduced the scale insects to a low Ievel. When 
DDT was discovered to kill scale insects, it was applied by the orchardists 
in the hope of further reducing the scale insects. However, &middot;in agreement 
with Volterra's principle, the effect was an increase of the scale insect! 
</p>
<p>Oddly enough, many ecologists and biologists refused to accept 
Volterra's model as accurate. They pointed to the fact that the oscillatory 
behavior predicted by Volterra's model is not observed in most pre-
dator-prey systems. Rather, most predator-prey systems tend to 
equilibrium states as time evolves. Our answer to these critics is that the 
system of differential equations (I) is not intended as a model of the gen-
eral predator-prey interaction. This is because the food fish and selachians 
do not compete intensively among themselves for their available resources. 
A more general model of predator-prey interactions is the system of dif-
ferential equations 
</p>
<p>x=ax-bxy-ex2, y=-cy+d.xy-jy 2&bull; (6) 
</p>
<p>Here, the term ex2 reflects the internal competition of the prey x for their 
limited external resources, and the termjy2 reflects the competition among 
the predators for the limited number of prey. The solutions of (6) are not, 
in general, periodic. Indeed, we have already shown in Example 1 of Sec-
</p>
<p>448 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.10 Predator-prey problems 
</p>
<p>tion 4.8 that all solutions x(t), y(t) of (6), with x(O) and y(O) positive, 
ultimately approach the equilibrium solution x = a I e, y = 0 if c I d is 
greater than al e. In this situation, the predators die out, since their availa-
ble food supply is inadequate for their needs. 
</p>
<p>Surprisingly, some ecologists and biologists even refuse to accept the 
moregenerat model (6) as accurate. As a counterexample, they cite the ex-
periments of the mathematical biologist G. F. Gause. In these experiments, 
the population was composed of two species of protozoa, one of which, Di-
dinium nasatum, feeds on the other, Paramecium caudatum. In all of 
Gause's experiments, the Didinium quickly destroyed the Paramecium and 
then died of starvation. This situation cannot be modeled by the system of 
equations (6), since no solution of (6) with x(O)y(O)*O can reach x=O or 
y = 0 in finite time. 
</p>
<p>Our answer to these critics is that the Didinium are a special, and atypi-
cal type of predator. On the one hand, they are ferocious attackers andre-
quire a tremendous amount of food; a Didinium demands a fresh Para-
mecium every three hours. On the other hand, the Didinium don't perish 
from an insufficient supply of Paramecium. They continue to multiply, but 
give birth to smaller offspring. Thus, the system of equations (6) does not 
accurately model the interaction of Paramecium and Didinium. A better 
model, in this case, is the system of differential equations 
</p>
<p>dx ,c -=ax-bvxy 
dt ' 
</p>
<p>dy = { dYx y, 
dt -cy, 
</p>
<p>x*O 
x=O 
</p>
<p>(7) 
</p>
<p>lt can be shown (see Exercise 6) that every solution x(t), y(t) of (7) with 
x(O) andy(O) positive reaches x=O in finite time. This does not contradict 
the existence-uniqueness theorem, since the function 
</p>
<p>g(x,y)= { dYx y, x*O 
-cy, x=O 
</p>
<p>does not have a partial derivative with respect to x or y, at x = 0. 
Finally, we mention that there are several predator-prey interactions in 
</p>
<p>nature which cannot be modeled by any system of ordinary differential 
equations. These situations occur when the prey are provided with a refuge 
that is inaccessible to the predators. In these situations, it is impossible to 
make any definitive Statements about the future number of predators and 
prey, since we cannot predict how many prey will be stupid enough to 
leave their refuge. In other words, this process is now random, rather than 
deterministic, and therefore cannot be modeled by a system of ordinary dif-
ferential equations. This was verified directly in a famous experiment of 
Gause. He placed five Paramecium and three Didinium in each of thirty 
identical test tubes, and provided the Paramecium with a refuge from the 
Didinium. Two days later, he found the predators dead in four tubes, and 
a mixed population containing from two to thirty-eight Paramecium in the 
remaining twenty-six tubes. 
</p>
<p>449 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>Reference 
Volterra, V: "Leyons sur la theorie mathematique de la lutte pour la vie." Paris, 
</p>
<p>1931. 
</p>
<p>EXERCISES 
</p>
<p>1. Findall biologically realistic equilibrium points of (6) and determine their stabil-
ity. 
</p>
<p>2. We showed in Section 4.8 thaty(t) ultimately approaches zero for all solutions 
x(t),y(t) of (6), if c/d&gt;aje. Show that there exist solutions x(t),y(t) of (6) for 
whichy(t) increases at first to a maximum value, and then decreases to zero. (To 
an observer who sees only the predators without noticing the prey, such a case 
of a population passing through a maximum to total extinction would be very 
difficult to explain.) 
</p>
<p>3. In many instances, it is the adult members of the prey who are chiefly attacked 
by the predators, while the young members are better protected, either by their 
smaller size, or by their living in a different station. Let x 1 be the number of 
adult prey, x2 the number of young prey, and y the number of predators. Then, 
</p>
<p>.X1= -a1x 1+a2x 2-bx1y 
x2= nxl- (al + a2)x2 
y= -cy+dx1y 
</p>
<p>where a2x2 represents the number of young (per unit time) growing into adults, 
and n represents the birth rate proportional to the number of adults. Find all 
equilibrium solutions of this system. 
</p>
<p>4. There are several situations in nature where species 1 preys on species 2 which in 
turn preys on species 3. One case of this kind of population is the Island of 
Komodo in Malaya which is inhabited by giant carnivorous reptiles, and by 
mammals-their food-which feed on the rieb vegetation of the island. We 
assume that the reptiles have no direct influence on the vegetation, and that only 
the plants compete among themselves for their available resources. A system of 
differential equations governing this interaction is 
</p>
<p>.XI= -alxl- b12x1x2+c13x1x3 
</p>
<p>X2 =- Q2X2 + b21XIX2 
X3= a3X3 -a4x~- C31X1X3 
</p>
<p>Find all equilibrium solutions of this system. 
</p>
<p>5. Consider a predator-prey system where the predator has alternate means of sup-
port. This system can be modelled by the differential equations 
</p>
<p>.X1 = a 1x 1 ( &szlig;1 - x 1) + y 1x 1x 2 
X2= a2x2( &szlig;2- X2)- 'Y2X1X2 
</p>
<p>where x 1(t) and x2(t) are the predators and prey populations, respectively, at 
timet. 
</p>
<p>450 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.11 The principle of competitive exclusion in population biology 
</p>
<p>(a) Show that the change of coordinates &szlig;;Y;(t)=x;(t/a;&szlig;;) reduces this system 
of equations to 
</p>
<p>YJ = Y1 (1-YJ)+aiYJY2&bull; h= Y2(1-Y2)- a2Y1Y2 
where a 1 = Y1 &szlig;2/ 01.1 &szlig;1 and a2 = Y2 &szlig;d 01.2 &szlig;2&middot; 
</p>
<p>(b) What are the stable equilibrium populations when (i) 0 &lt; a2 &lt; I, (ii) a2 &gt; l? 
( c) It is observed that a 1 = 3a2 ( a2 is a measure of the aggressiveness of the pre-
</p>
<p>dator). What is the value of a2 if the predator's instinct is to maximize its 
stable equilibrium population? 
</p>
<p>6. (a) Let x(t) be a solution of .X= ax- MVx, with M &gt; a Vx{tJ . Show that 
</p>
<p>aVx =M-(M-aVx{iJ )ea(t-to)/2. 
</p>
<p>(b) Conclude from (a) that x(t) approaches zeroinfinite time. 
</p>
<p>(c) Let x(t), y(t) be a solution of (7), with by(t0) &gt; a Vx(tJ . Show that x(t) 
reaches zero in finite time. Hint: Observe that y(t) is increasing fort&gt; t0&bull; 
</p>
<p>( d) It can be shown that by ( t) will eventually exceed a -v-;(i) for every solu-
tion x(t), y(t) of (7) with x(t0) and y(t0) positive. Conclude, therefore, that 
all solutions x(t), y(t) of (7) achieve x=O in finite time. 
</p>
<p>4.11 The principle of competitive exclusion 
in population biology 
</p>
<p>lt is often observed, in nature, that the struggle for existence between two 
similar species competing for the same limited food supply and living 
space nearly always ends in the complete extinction of one of the species. 
This phenomenon is known as the "principle of competitive exclusion." lt 
was first enunciated, in a slightly different form, by Darwin in 1859. In his 
paper 'The origin of species by natural selection' he writes: "As the species 
of the same genus usually have, though by no means invariably, much sim-
ilarity in habits and constitutions and always in structure, the struggle will 
generally be more severe between them, if they come into competition with 
each other, than between the species of distinct genera." 
</p>
<p>There is a very interesting biological explanation of the principle of 
competitive exclusion. The cornerstone of this theory is the idea of a 
"niche." A niche indicates what place a given species occupies in a com-
munity; i.e., what are its habits, food and mode of life. It has been ob-
served that as a result of competition two similar species rarely occupy the 
same niche. Rather, each species takes possession of those kinds of food 
and modes of life in which it has an advantage over its competitor. If the 
two species tend to occupy the same niche then the struggle for existence 
between them will be very intense and result in the extinction of the 
weaker species. 
</p>
<p>An excellent illustration of this theory is the colony of terns inhabiting 
the island of Jorilgatch in the Black Sea. This colony consists of four diffe-
rent species of terns: sandwich-tern, common-tern, blackbeak-tern, and lit-
</p>
<p>451 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>tle-tern. These four species band together to chase away predators from the 
colony. However, there is a sharp difference between them as regards the 
procuring of food. The sandwich-tern flies far out into the open sea to hunt 
certain species, while the blackbeak-tern feeds exclusively on land. On the 
other hand, common-tern and Iittle-tern catch fish close to the shore. They 
sight the fish while flying and dive into the water after them. The Iittle-tern 
seizes his fish in shallow swampy places, whereas the common-tern hunts 
somewhat further from shore. In this manner, these four similar species of 
tern living side by side upon a single small island differ sharply in all their 
modes of feeding and procuring food. Each has a niche in which it has a 
distinct advantage over its competitors. 
</p>
<p>In this section we present a rigorous mathematical proof of the law of 
competitive exclusion. This will be accomplished by deriving a system of 
differential equations which govern the interaction between two similar 
species, and then showing that every solution of the system approaches an 
equilibrium state in which one of the species is extinct. 
</p>
<p>In constructing a mathematical model of the struggle for existence be-
tween two competing species, it is instructive to Iook again at the logistic 
law of population growth 
</p>
<p>(1) 
</p>
<p>This equation governs the growth of the population N ( t) of a single species 
whose members compete among themselves for a limited amount of food 
and living space. Recall (see Section 1.5) that N (t) approaches the limiting 
population K = a I b, as t approaches infinity. This limiting population can 
be thought of as the maximum population of the species which the micro-
cosm can support. In terms of K, the logistic law (I) can be rewritten in the 
form 
</p>
<p>Equation (2) has the following interesting interpretation. When the 
population N is very low, it grows according to the Malthusian law dN I dt 
=aN. The term aN is called the "biotic potential" of the species. It is the 
potential rate of increase of the species under ideal conditions, and it is re-
alized if there are no restrictions on food and living space, and if the indi-
vidual members of the species do not excrete any toxic waste products. As 
the population increases though, the biotic potential is reduced by the fac-
tor (K- N)l K, which is the relative number of still vacant places in the 
microcosm. Ecologists call this factor the environmental resistance to 
growth. 
</p>
<p>Now, Iet N 1(t) and N 2(t) be the population at timet of species 1 and 2 
respectively. Further, Iet K 1 and K 2 be the maximum population of species 
1 and 2 which the microcosm can support, and 1et a1N 1 and a2N 2 be the 
biotic potentials of species 1 and 2. Then, N 1(t) and Nit) satisfy the sys-
</p>
<p>452 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.11 The princip1e of competitive exclusion in popu1ation bio1ogy 
</p>
<p>(3) 
</p>
<p>where m2 is the total number of places of the first species which are taken 
up by members of the second species, and m 1 is the total number of places 
of the second species which are taken up by members of the first species. 
At first glance it would appear that m2 = N2 and m 1 = N 1&bull; However, this is 
not generally the case, for it is highly unlikely that two species utilize the 
environment in identical ways. Equal numbers of individuals'of species I 
and 2 do not, on the average, consume equai quantities of food, take up 
equal amounts of living space and excrete equal amounts of waste prod-
ucts of the same chemical composition. In general, we must set m2 = a.N1 
and m 1 = &szlig;N1, for some constants a. and &szlig;. The constants a. and &szlig; indicate 
the degree of influence of one species upon the other. If the interests of the 
two species do not clash, and they occupy separate niches, then both a. and 
&szlig; are zero. If the two species lay claim to the same niche and are very sim-
ilar, then a. and &szlig; are very close to one. On the other hand, if one of the 
species, say species 2, utilizes the environment very unproductively; i.e., it 
consumes a great deal of food or excretes very poisonous waste products, 
then one individual of species 2 takes up the place of many individuals of 
species l. In this case, then, the coefficient a. is very large. 
</p>
<p>We restriet ourselves now to the case where the two species are nearly 
identical, and lay claim to the same niche. Then, a. = &szlig; = 1, and N 1(t) and 
Nit) satisfy the system of differential equations 
</p>
<p>(4) 
</p>
<p>In this instance, we expect the struggle for existence between species I and 
2 to be very intense, and to result in the extinction of one of the species. 
This is indeed the case as we now show. 
</p>
<p>Theorem 6 (Principle of competitive exclusion). Suppose that K 1 is greater 
than K2&bull; Then, every solution N 1(t), Nit) of (4) approaches the 
equilibrium solution N 1 = K1, N2 = 0 as t approaches infinity. In other 
words, if species I and 2 are very nearly identical, and the microcosm can 
support more members of species 1 than of species 2, then species 2 will 
ultimately become extinct. 
</p>
<p>Our first step in proving Theorem 6 is to show that N 1(t) and Nit) can 
never become negative. To this end, recall from Section 1.5 that 
</p>
<p>453 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>is a solution of (4) for any choice of NI(O). The orbit of this solution in the 
NI-N2 plane is the point (0,0) for NI(O)=O; the line 0&lt; NI&lt; KI, N2=0 for 
O&lt;NI(O)&lt;KI; the point (KI,O) for NI(O)=KI; and the line KI &lt;NI &lt;oo, 
N2 =0 for NI(O)&gt; KI. Thus, the NI axis, for NI;;;. 0, is the union of four dis-
tinct orbits. Similarly, the N 2 axis, for N 2 ;;;. 0, is the union of four dis-
tinct orbits of (4). This implies that all solutions NI(t), N2(t) of (4) which 
start in the first quadrant (NI &gt;0,N2 &gt;0) of the NI-N2 plane must remain 
there for all future time. 
</p>
<p>Our second step in proving Theorem 6 is to split the first quadrant into 
regions in which both dNI/ dt and dNd dt have fixed signs. This is accom-
plished in the following manner. Let /I and /2 be the lines KI- NI- N 2 = 0 
and K 2 - NI- N2 = 0, respectively. Observe that dNI/ dt is negative if 
(NI,N2) lies above /I, and positive if (NI,N2) lies below /I. Similarly, 
dN2/dt is negative if (NI,N2) lies above /2&gt; and positive if (NI,N~ lies be-
low /2. Thus, the two parallellines /I and /2 split the first quadrant of the 
NI-N2 plane into three regions (see Figure I) in which both dNI/ dt and 
dNd dt have fixed signs. Both NI(t) and Nit) increase with time (along 
any solution of (4)) in region I; NI(t) increases, and Nit) decreases, with 
time in region II; and both NI(t) and Nit) decrease with time in region 
III. 
</p>
<p>lii 
</p>
<p>I 
~,&gt; 0 
N2&gt;o 
</p>
<p>~~------~~--------~------- N, 
K, 
</p>
<p>Figure l 
</p>
<p>Lemma l. Any solution NI(t), Nit) of (4) which starts in region I at t = t0 
must leave this region at some later time. 
</p>
<p>PROOF. Suppose that a solution NI(t), Nit) of (4) remains in region I for 
all time t;;;. t0 &bull; This implies that both NI(t) and Nit) are monotonic in-
creasing functions of time for t;;;. t0, with NI(t) and Nit) less than K2&bull; 
Consequently, by Lemma I of Section 4.8, both NI(t) and N2(t) have Iimits 
</p>
<p>454 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.11 The princip1e of competitive exclusion in population bio1ogy 
</p>
<p>~. 'IJ respectively, as t approaches infinity. Lemma 2 of Section 4.8 implies 
that (~,'IJ) is an equilibrium point of (4). Now, the only equilibrium points 
of (4) are (0,0), (K1,0), and (O,K2), and (~,'IJ) obviously cannot equal any of 
these three points. We conclude therefore, that any solution N 1(t), N2(t) of 
(4) which starts in region I must leave this region at a later time. 0 
</p>
<p>Lemma 2. Any solution N 1(t), N2(t) of (4) which starts in region II at time 
t = t0 will remain in this region for all future time t ;&gt; t0, and ultimately ap-
proach the equilibrium solution N 1 =K1, N2 =0. 
</p>
<p>PR.ooF. Suppose that a solution N1(t), N2(t) of (4) leaves region II at time 
t = t*. Then, either N 1(t*) or Nit*) is zero, since the only way a solution of 
(4) can leave region II is by crossing /1 or /2&bull; Assurne that N1(t*)=O. Dif-
ferentiating both sides of the first equation of (4) with respect tot and set-
ting t = t* gives 
</p>
<p>-a1N 1 (t*) dN2 (t*) 
</p>
<p>K 1 dt 
</p>
<p>This quantity is positive. Hence, N 1(t) has a minimum at t=t*. Butthis is 
impossible, since N 1(t) is increasing whenever a solution N 1(t), N2(t) of (4) 
is in region II. Similarly, if Nit*)=O, then 
</p>
<p>d 2N 2 (t*) -a2N 2 (t*) dN1 (t*) 
</p>
<p>dt 
</p>
<p>This quantity is negative, implying that N2(t) has a maximum at t= t*. But 
this is impossible, since N2(t) is decreasing whenever a solution N 1(t), N2(t) 
of (4) is in region II. 
</p>
<p>The previous argument shows that any solution N 1(t), N2(t) of (4) which 
starts in region II at time t = t0 will remain in region II for all future time 
t &gt; t0&bull; This implies that N 1(t) is monotonic increasing and N2(t) is mono-
tonic decreasing for t;&gt;t0, with N 1(t)&lt;K1 and N2(t)&gt;K2&bull; Consequently, 
by Lemma 1 of Section 4.8, both N 1(t) and N2(t) have limits ~,'IJ respec-
tively, as t approaches infinity. Lemma 2 of Section 4.8 implies that (~, 'IJ) is 
an equilibrium point of (4). Now, (~, 'IJ) obviously cannot equal (0, 0) or 
(O,K2). Consequently, (~,1J)=(K 1 ,0), and this proves Lemma 2. 0 
</p>
<p>Lemma 3. Any so/ution N 1(t), N2(t) of (4) which starts in region 111 at time 
t = t0 and remains there for all future time must approach the equilibrium 
solution N 1(t)=K1, N2(t)=O as t approaches infinity. 
</p>
<p>PR.ooF. If a solution N1(t), N2(t) of (4) remains in region 111 fort&gt; t0, then 
both N 1(t) and N2(t) are monotonic decreasing functions of timefort ;&gt; tO&gt; 
with N 1(t)&gt;O and N2(t)&gt;O. Consequently, by Lemma 1 of Section 4.8, 
both N 1(t) and N2(t) have limits ~,'IJ respectively, as t approaches infinity. 
Lemma 2 of Section 4.8 implies that (~,'IJ) is an equilibrium point of (4). 
Now, (~,'IJ) obviously cannot equal (0,0) or (O,KJ. Consequently, (~,1J)= 
(K1,0). 0 
</p>
<p>455 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>PRooF OF THEOREM 6. Lemmas I and 2 above state that every solution 
N1(t), N2(t) of (4) which starts in regions I or II at time t=t0 must ap-
proach the equilibrium solution N1 = K1, N2 =0 as t approaches infinity. 
Similarly, Lemma 3 shows that every solution N1(t), N2(t) of (4) which 
starts in region 111 at time t = t0 and remains there for all future time must 
also approach the equilibrium solution N1 = K1, N2 = 0. Next, observe that 
any solution N 1(t), Nit) of (4) which starts on /1 or /2 must immediately 
afterwards enter region II. Finally, if a solution N1(t),N2(t) of (4) leaves re-
gion 111, then it must cross the line /1 and immediately afterwards enter re-
gion II. Lemma 2 then forces this solution to approach the equilibrium 
solution N 1 = K1, N2 = 0. D 
</p>
<p>Theorem 6 deals with the case of identical species; i.e., a = &szlig; = 1. By a 
similar analysis (see Exercises 4-6) we can predict the outcome of the 
struggle for existence for all values of a and &szlig;. 
</p>
<p>Reference 
Gause, G. F., 'The Struggle for Existence,' Dover Publications, New York, 1964. 
</p>
<p>EXERCISES 
</p>
<p>1. Rewrite the system of equations (4) in the form 
</p>
<p>K 1 dN1 K2 dN2 
----=K1-N1-N2, ----=K2-N1-N2&bull; a 1N 1 dt a2N 2 dt 
</p>
<p>Then, subtract these two equations and integrate to obtain directly that N2(t) 
approaches zero for all solutions N1(t), N2(t) of (4) with N1(t0)&gt;0. 
</p>
<p>2. The system of differential equations 
</p>
<p>dN1 
dt =N1 [ -al +c1(l-b1N1 -b2N2 )] 
</p>
<p>dN2 
dt =N2 [ -a2 + c2 (l-b1N 1 -b2N2 )] 
</p>
<p>(*) 
</p>
<p>is a model of two species competing for the same limited resource. Suppose that 
c1 &gt; a1 and c2 &gt; a2&bull; Deduce from Theorem 6 that N1(t) ultimately approaches 
zero if a1c2 &gt;a2c1, and N2(t) ultimately approaches zero if a1c2 &lt;a2c1&bull; 
</p>
<p>3. In 1926, Volterra presented the following model of two species competing for 
the same limited food supply: 
</p>
<p>dN1 
dt =[bJ-A1(h1N1+h2N2)]N1 
</p>
<p>dN2 
dt =[b2-X2(h1N1 +h2N2 )]N2&bull; 
</p>
<p>Suppose that bJ/A1 &gt; bdX2&bull; (The coefficient b;/A; is called the susceptibility of 
species i to food shortages.) Prove that species 2 will ultimately become extinct if 
N1(t0)&gt;0. 
</p>
<p>456 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.11 The princip1e of competitive exclusion in popu1ation bio1ogy 
</p>
<p>Problems 4-6 are concerned with the system of equations 
</p>
<p>dN1 a 1N 1 dN2 a2N2 
dt=K;""(KI-NI-aN2), dt= K2 (K2-N2-&szlig;NI). (*) 
</p>
<p>4. (a) Assurne that K1/ a &gt; K2 and Kd &szlig; &lt; K1&bull; Show that N2(t) approaches zero as 
t approaches infinity for every solution N 1(t), N 2(t) of (*) with N 1(t0) &gt; 0. 
</p>
<p>(b) Assurne that Kif a &lt; K2 and K2/ &szlig; &gt; K1&bull; Show that N 1(t) approaches zero as 
t approaches infinity for every solution N 1(t), N2(t) of (*) with N 1Nit0)&gt;0. 
Hint: Draw the lines /1 :N1 +aN2 = K1 and /2 :N2 + &szlig;N1 =K2, and follow the 
proof of Theorem 6. 
</p>
<p>5. Assurne that K1/ a &gt; K2 and K2/ &szlig; &gt; K1&bull; Prove that all solutions N 1(t), N 2(t) of 
(*), with both N 1(t0) and Nit0) positive, ultimately approach the equilibrium 
solution 
</p>
<p>Hint: 
(a) Draw the lines /1 :N1 + aN2 = K1 and /2 :N2 + &szlig;N1 =K2&bull; The two 1ines divide 
</p>
<p>the first quadrant into four regions (see Figure 2) in which both N1 and N2 
have fixed signs. 
</p>
<p>I 
N?O 
N&gt;O 2 
</p>
<p>~----------~--~------~--------------NI 
K, 
</p>
<p>Figure 2 
</p>
<p>(b) Show that all solutions N 1(t), N 2(t) of (*) which start in either region II or 
III must remain in these regions and ultimately approach the equilibrium 
solution N 1 =NP, N2 =Nf. 
</p>
<p>(c) Show that all solutions N 1(t), N2(t) of (*) which remain exclusively in region 
I or region IV for all time t ;;. t0 must ultimately approach the equilibrium 
solution N 1 =NP, N2 = Nr. 
</p>
<p>457 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>K/a 
</p>
<p>Figure 3 
</p>
<p>6. Assurne that K1/ a &lt; K2 and K2/ &szlig; &lt; K1&bull; 
(a) Show that the equilibrium solution N1 =0, N 2 =0 of (*) is unstable. 
(b) Show that the equilibrium solutions N 1 =K~&gt; N2 =0 and N1=0, N 2=K2 of 
</p>
<p>(*) are asymptotically stable. 
(c) Show that the equilibrium solution N1 = Nf, N 2 = Nf (see Exercise 5) of (*) 
</p>
<p>is a saddle point. (This calculation is very cumbersome.) 
(d) It is not too difficult to see that the phase portrait of (*) must have the form 
</p>
<p>described in Figure 3. 
</p>
<p>4.12 The Threshold Theorem of epidemiology 
</p>
<p>Consider the situation where a small group of people having an infectious 
disease is inserted into a large population which is capable of catching the 
disease. What happens as time evolves? Will the disease die out rapidly, or 
will an epidemic occur? How many people will ultimately catch the dis-
ease? To answer these questions we will derive a system of differential 
equations which govern the spread of an infectious disease within a popu-
lation, and analyze the behavior of its solutions. This approach will also 
lead us to the famous Threshold Theorem of epidemiology which states 
that an epidemic will occur only if the number of people who are suscept-
ible to the disease exceeds a certain threshold value. 
</p>
<p>W e begin with the assumptions that the disease under consideration 
confers permanent immunity upon any individual who has completely re-
covered from it, and that it has a negligibly short incubation period. This 
latter assumption implies that an individual who contracts the disease be-
comes infective immediately afterwards. In this case we can divide the 
population into three classes of individuals: the infective class (/), the sus-
ceptible class (S) and the removed class (R). The infective class consists of 
those individuals who are capable of transmitting the disease to others. 
</p>
<p>458 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.12 The Threshold Theorem of epidemiology 
</p>
<p>The susceptible dass consists of those individuals who are not infective, 
but who are capable of catching the disease and becoming infective. The 
removed dass consists of those individuals who have had the disease and 
are dead, or have recovered and are permanently immune, or are isolated 
until recovery and permanent immunity occur. 
</p>
<p>The spread of the disease is presumed to be governed by the following 
rules. 
</p>
<p>Rule 1: The population remains at a fixed Ievel N in the time interval 
under consideration. This means, of course, that we neglect births, deaths 
from causes unrelated to the disease under consideration, immigration and 
emigration. 
</p>
<p>Rule 2: The rate of change of the susceptible population is proportional 
to the product of the number of members of ( S) and the number of mem-
bers of (/). 
</p>
<p>Rule 3: Individuals are removed from the infectious dass (/) at a rate 
proportional to the size of (I). 
</p>
<p>Let S ( t),/ ( t), and R ( t) denote the number of individuals in classes ( S), 
(I), and (R), respectively, at timet. lt follows immediately from Rules l-3 
that S (t),l ( t), R (t) satisfies the system of differential equations 
</p>
<p>dS = -rSI 
dt 
di 
dt =rSI-yi (1) 
</p>
<p>dR =yi 
dt 
</p>
<p>for some positive constants r and y. The proportionality constant r is 
called the infection rate, and the proportionality constant y is called the re-
moval rate. 
</p>
<p>The first two equations of (1) do not depend on R. Thus, we need only 
consider the system of equations 
</p>
<p>dS 
-= -rSI 
dt ' 
</p>
<p>di - =rSI-yi 
dt 
</p>
<p>(2) 
</p>
<p>for the two unknown functions S (t) and I (t). Once S (t) and I (t) are 
known, we can solve for R (t) from the third equation of (1). Alternately, 
observe that d(S+I+R)/dt=O. Thus, 
</p>
<p>S (t)+ I (t) + R (t) =constant= N 
so that R ( t) = N- S ( t)- I ( t). 
</p>
<p>The orbits of (2) are the solution curves of the first-order equation 
</p>
<p>di rSI-yi y 
dS = - rSI = - l + rS . (J) 
</p>
<p>Integrating this differential equation gives 
s 
</p>
<p>I(S)= I0 + S0 - S+plns, 
0 
</p>
<p>(4) 
</p>
<p>459 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>I 
</p>
<p>(So,Io) 
</p>
<p>~--~--~---L------~------------5 
</p>
<p>p 
</p>
<p>Figure 1. The orbits of (2) 
</p>
<p>where S0 and I0 are the number of susceptibles and infectives at the initial 
timet= t0 , and p = y Ir. To analyze the behavior of the curves (4), we com-
pute I'(S)= -1 +PIS. The quantity -1 +PIS is negative for S &gt; p, and 
positive for S &lt; p. Hence, I (S) is an increasing function of S for S &lt; p, and 
a decreasing function of S for S &gt; p. 
</p>
<p>N ext, observe that I (0) = - oo and I ( S0) = I 0 &gt; 0. Consequently, there 
exists a unique point S~, with 0&lt; S~ &lt; S0, suchthat I(S~)=O, and I(S) 
&gt; 0 for S ~ &lt; S ,.;; S 0. The point ( S ~, 0) is an equilibrium point of (2) since 
both dS I dt and di I dt vanish when I= 0. Thus, the orbits of (2), for t0 ..; t 
&lt; oo, have the form described in Figure I. 
</p>
<p>Let us see what all this implies about the spread of the disease within 
the population. Astruns from t0 to oo, the point (S(t),/(t)) travels along 
the curve (4), and it moves along the curve in the direction of decreasing S, 
since S (t) decreases monotonically with time. Consequently, if S0 is less 
than p, then I ( t) decreases monotonically to zero, and S ( t) decreases 
monotonically toS~. Thus, if a small group of infectives I0 is inserted into 
a group of susceptibles S0 , with S0 &lt; p, then the disease will die out rapid1y. 
On the other hand, if S0 is greater than p, then I ( t) increases as S ( t) de-
creases to p, and it achieves a maximum value when S = p. lt only starts 
decreasing when the number of susceptibles falls below the threshold value 
p. From these results we may draw the following conclusions. 
</p>
<p>Conclusion 1: An epidemic will occur only if the number of susceptibles 
in a population exceeds the threshold value p = y Ir. 
</p>
<p>Conclusion 2: The spread of the disease does not stop for lack of a sus-
ceptible population; it stops only for lack of infectives. In particular, some 
individuals will escape the disease altogether. 
</p>
<p>Conclusion 1 corresponds to the general observation that epidemics 
tend to build up more rapidly when the density of susceptibles is high due 
to overcrowding, and the removal rate is low because of ignorance, inade-
quate isolation and inadequate medical care. On the other hand, outbreaks 
tend to be of only limited extent when good social conditions entaillower 
</p>
<p>460 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.12 The Threshold Theorem of epidemiology 
</p>
<p>densities of susceptibles, and when removal rates are high because of good 
public health vigilance and control. 
</p>
<p>If the number of susceptibles S0 is initially greater than, but close to, the 
threshold value p, then we can estimate the number of individuals who 
ultimately contract the disease. Specifically, if S0 - p is small compared to 
p, then the number of individuals who ultimately contract the disease is ap-
proximately 2( S0 - p ). This is the famous Threshold Theorem of epidemiol-
ogy, which was first proven in 1927 by the mathematical biologists 
Kermack and McKendrick. 
</p>
<p>Theorem 7 (Threshold Theorem of epidemiology). Let S0 = p + v and 
assume that v / p is very small compared to one. Assurne moreover, that the 
number of initial infectives / 0 is very small. Then, the number of individu-
</p>
<p>als who ultimately contract the disease is 2v. In other words, the Ievel of 
</p>
<p>susceptibles is reduced to a point as far below the Ihreshold as it origina/ly 
was above it. 
</p>
<p>PROOF. Letting t approach infinity in (4) gives 
</p>
<p>soo 
0= 10 + S0 - S 00 + plny. 
</p>
<p>0 
</p>
<p>If / 0 is very small compared to S0, then we can neglect it, and write 
</p>
<p>s&lt;YJ 
0= S0 - S&lt;YJ +plnSo 
</p>
<p>Now, if S0 - pissmall compared top, then S0 - S&lt;YJ will be small compared 
to S0. Consequently, we can truncate the Taylor series 
</p>
<p>[ _ ( So- S &lt;YJ ) l = _ ( S0 - S &lt;YJ ) _ _!_ ( S0 - S 00 ) 2 In 1 S S 2 S + ... 
0 0 0 
</p>
<p>after two terms. Then, 
</p>
<p>= (S0 - S&lt;YJ )[ 1- ; 0 - 2; 5 (So- Soo) J. 
</p>
<p>461 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>Solving for S0 - S 00 , we see that 
</p>
<p>So-Soo=2S0 ( : 0 -1)=2(p+v)[ p;v -1] 
</p>
<p>=2(p+ v)~ =2p(l + ~) ~ ;;;;2v. 
p p p 0 
</p>
<p>During the course of an epidemic it is impossible to accurately ascertain 
the number of new infectives each day or week, since the only infectives 
who can be recognized and removed from circulation are those who seek 
medical aid. Public health statistics thus record only the number of new re-
movals each day or week, not the number of new infectives. Therefore, in 
order to compare the results predicted by our model with data from actual 
epidemics, we must find the quantity dR/ dt as a function of time. This is 
accomplished in the following manner. Observe first that 
</p>
<p>Second, observe that 
</p>
<p>dR dt = y/= y(N- R- S). 
</p>
<p>dS dSjdt -rSI -S 
dR = dRjdt = -y! = -p-
</p>
<p>Hence, S(R)=S0e-R/p and 
</p>
<p>~~ =y(N-R-S0e-RIP). (5) 
</p>
<p>Equation (5) is separable, but cannot be solved explicitly. However, if the 
epidemic is not very large, then R j p is small and we can truncate the 
Taylor series 
</p>
<p>2 
</p>
<p>e-R/p=l-~+t(~) + ... 
</p>
<p>after three terms. With this approximation, 
</p>
<p>~~ =y[N-R-s0 [ 1-Rjp+t(Rjp)2 ]] 
</p>
<p>The solution of this equation is 
</p>
<p>(6) 
</p>
<p>462 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.12 The Threshold Theorem of epidemiology 
</p>
<p>where 
</p>
<p>1 1 (So ) &lt;j&gt;=tanh- ~ P-I 
and the hyperbolic tangent function tanhz is defined by 
</p>
<p>ez-e-z 
tanhz= z z. 
</p>
<p>e +e 
</p>
<p>lt is easily verified that 
</p>
<p>Hence, 
</p>
<p>~tanhz=sech 2 z= 4 . 
dz (ez+e-z)2 
</p>
<p>dR ya_2p2 2( 1 ) dt = 2S0 sech 2ayt-&lt;j&gt; . (7) 
</p>
<p>Equation (7) defines a symmetric bell shaped curve in the t-dR/ dt plane 
(see Figure 2). This curve is called the epidemic curve of the disease. lt 
illustrates very weil the common observation that in many actual epidem-
ics, the number of new cases reported each day climbs to a peak value and 
then dies away again. 
</p>
<p>dR 
dt 
</p>
<p>2&lt;/&gt;ltXY 
</p>
<p>Figure 2 
</p>
<p>Kermack and McKendrick compared the values predicted for dR/ dt 
from (7) with data from an actual plague in Bombay which spanned the 
last half of 1905 and the firsthalf of 1906. They set 
</p>
<p>dR dt = 890sech2(0.2t- 3.4) 
</p>
<p>with t measured in weeks, and compared these values with the number of 
deaths per week from the plague. This quantity is a very good approxima-
tion of dR/ dt, since almost all cases terminated fatally. As can be seen 
from Figure 3, there is excellent agreement between the actual values of 
</p>
<p>463 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>200 
</p>
<p>5 10 15 20 25 30 
</p>
<p>WEEKS 
</p>
<p>Figure 3 
</p>
<p>dR/ dt, denoted by &bull;, and the values predicted by (7). This indicates, of 
course, that the system of differential equations (I) is an accurate and reli-
</p>
<p>able model of the spread of an infectious disease within a population of 
fixed size. 
</p>
<p>References 
</p>
<p>Bailey, N. T. J., 'The mathematical theory of epidemics,' 1957, New York. 
</p>
<p>Kermack, W. 0. and McKendrick, A. G., Contributions to the mathematical the-
ory of epidemics, Proceedings Roy. Stat. Soc., A, 115, 700-721, 1927. 
</p>
<p>Waltman, P., 'Deterministic threshold models in the theory of epidemics,' 
Springer-Verlag, New York, 1974. 
</p>
<p>EXERCISES 
</p>
<p>1. Derive Equation (6). 
</p>
<p>2. Suppose that the members of (S) are vaccinated agairrst the disease at a rate ll. 
proportional to their number. Then, 
</p>
<p>dS -= -rSI-li.S 
dt ' 
</p>
<p>(a) Find the orbits of (*). 
</p>
<p>dl - =rSI-yl dt . (*) 
</p>
<p>(b) Conclude from (a) that S (t) approaches zero as t approaches infinity, for ev-
</p>
<p>ery solution S ( t), I ( t) of (*). 
</p>
<p>464 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.13 A model for the spread of gonorrhea 
</p>
<p>3. Suppose that the members of (S) are vaccinated against the disease at a rate A. 
proportional to the product of their numbers and the square of the members of 
(/). Then, 
</p>
<p>dS , 2 
- = -rSI-1\SI 
dt ' 
</p>
<p>(a) Find the orbits of (*). 
</p>
<p>di - =I(rS-y) dt . 
</p>
<p>(b) Will any susceptibles remain after the disease dies out? 
</p>
<p>(&bull;) 
</p>
<p>4. The intensity i of an epidemic is the proportion of the total number of suscept-
ibles that finally contracts the disease. Show that 
</p>
<p>where S 00 is a root of the equation 
</p>
<p>S = Soe&lt;S- So-10 )/P, 
</p>
<p>5. Compute the intensity of the epidemic if p= 1000, I 0 = 10, and (a) S0 = 1100, (b) 
S0 = 1200, (c) S0 = 1300, (d) S0 = 1500, (e) S0 = 1800, (f) S0 = 1900. (This cannot 
be done analytically.) 
</p>
<p>6. Let R 00 denote the total number of individuals who contract the disease. 
(a) Show that R 00 = I0 + S0 - S 00 &bull; 
(b) Let R1 denote the members of (R) who are removed from the population 
</p>
<p>prior to the peak of the epidemic. Compute R 11 R 00 for each of the values of 
S0 in 5a-5f. Notice that most of the removals occur after the peak. This type 
of asymmetry is often found in actual notifications of infectious diseases. 
</p>
<p>7. It was observed in London during the early 1900's, that large outbreaks of 
measles epidemics recurred about once every two years. The mathematical biol-
ogist H. E. Soper tried to explain this phenomenon by assuming that the stock 
of susceptibles is constantly replenished by new recruits to the population. Thus, 
he assumed that 
</p>
<p>dS 
-= -rSI+n dt r&bull; 
</p>
<p>for some positive constants r, y, and p.. 
</p>
<p>di - =rSI-yi 
dt 
</p>
<p>(a) Show that S = y Ir, I= !LI y is the only equilibrium solution of (*). 
</p>
<p>(*) 
</p>
<p>(b) Show that every solution S(t), I(t) of (*) which starts sufficiently close to 
this equilibrium point must ultimately approach it as t approaches infinity. 
</p>
<p>(c) lt can be shown that every solution S(t), I(t) of (*) approaches the 
equilibrium solution S = y Ir, I= !LI y as t approaches infinity. Conclude, 
therefore, that the system (*) does not predict recurrent outbreaks of measles 
epidemics. Rather, it predicts that the disease will ultimately approach a 
steady state. 
</p>
<p>4.13 A model for the spread of gonorrhea 
</p>
<p>Gonorrhea ranks first today among reportable communicable diseases in 
the United States. There are more reported cases of gonorrhea every year 
than the combined totals for syphilis, measles, mumps, and infectious 
hepatitis. Public health officials estimate that more than 2,500,000 Ameri-
</p>
<p>465 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>cans contract gonorrhea every year. This painful and dangerous disease, 
which is caused by the gonococcus germ, is spread from person to person 
by sexual contact. A few days after the infection there is usually itching 
and burning of the genital area, particularly while urinating. About the 
same time a discharge develops which males will notice, but which females 
may not notice. Infected women may have no easily recognizable symp-
toms, even while the disease does substantial internal damage. Gonorrhea 
can only be cured by antibiotics (usually penicillin). However, treatment 
must be given early if the disease is to be stopped from doing serious 
darnage to the body. If untreated, gonorrhea can result in blindness, steril-
ity, arthritis, heart failure, and ultimately, death. 
</p>
<p>In this section we construct a mathematical model of the spread of 
gonorrhea. Our work is greatly simplified by the fact that the incubation 
period of gonorrhea is very short (3-7 days) compared to the often quite 
long period of active infectiousness. Thus, we will assume in our model 
that an individual becomes infective immediately after contracting gonor-
rhea. In addition, gonorrhea does not confer even partial immunity to 
those individuals who have recovered from it. Immediately after recovery, 
an individual is again susceptible. Thus, we can split the sexually active 
and promiscuous portion of the population into two groups, susceptibles 
and infectives. Let c1(t) be the total number of prorniscuous males, cit) 
the total number of promiscuous females, x(t) the total number of infec-
tive males, and y(t) the total number of infective females, at time t. Then, 
the total numbers of susceptible males and susceptible females are c1(t)-
x(t) and cit)-y(t) respectively. The spread of gonorrhea is presumed to 
be governed by the following rules: 
</p>
<p>1. Male infectives are cured at a rate a1 proportional to their total num-
ber, and female infectives are cure.d at a rate a2 proportional to their total 
number. The constant a1 is larger than a2 since infective males quickly de-
velop painful symptoms and therefore seek prompt medical attention. 
Fernale infectives, on the other hand, are usually asymptomatic, and there-
fore are infectious for much Ionger periods. 
</p>
<p>2. New infectives are added to the male population at a rate b1 propor-
tional to the total number of male susceptibles and female infectives. Sirni-
larly, new infectives are added to the female population at a rate b2 pro-
portional to the total number of female susceptibles and male infectives. 
</p>
<p>3. The total numbers of prorniscuous males and prorniscuous females re-
main at constant levels c1 and c2, respectively. 
</p>
<p>It follows immediately from rules 1-3 that 
</p>
<p>dx 
dt =-a1x+b1(c 1-x)y 
</p>
<p>(1) 
</p>
<p>466 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.13 A model for the spread of gonorrhea 
</p>
<p>Remark. The system of equations (I) treats only those cases of gonorrhea 
which arise from heterosexual contacts; the case of homosexual contacts 
(assuming no interaction between heterosexuals and homosexuals) is 
treated in Exercises 5 and 6. The number of cases of gonorrhea which arise 
from homosexual encounters is a small percentage of the total number of 
incidents of gonorrhea. Interestingly enough, this situation is completely 
reversed in the case of syphilis. Indeed, more than 90% of all cases of 
syphilis reported in the state of Rhode Island during 1973 resulted from 
homosexual encounters. (This statistic is not as startling as it first appears. 
Within ten to ninety days after being infected with syphilis, an individual 
usually develops a chancre sore at the spot where the germs entered the 
body. A homosexual who contracts syphilis as a result of anal intercourse 
with an infective will develop a chancre sore on his rectum. This individ-
ual, naturally, will be reluctant to seek medical attention, since he will then 
have to reveal his identity as a homosexuaL Moreover, he feels no sense of 
urgency, since the chancre sore is usually painless and disappears after 
several days. With gonorrhea, on the other hand, the symptoms are so 
painful and unmistakable that a homosexual will seek prompt medical 
attention. Moreover, he need not reveal his identity as a homosexual since 
the symptoms of gonorrhea appear in the genital area.) 
</p>
<p>Our first step in analyzing the system of differential equations (1) is to 
show that they are realistic. Specifically, we must show that x(t) and y(t) 
can never become negative, and can never exceed c1 and c2, respectively. 
This is the content of Lemmas 1 and 2. 
</p>
<p>Lemma 1. If x(t0) and y(t0) are positive, then x(t) and y(t) arepositive for 
a/1 t;;.. t0&bull; 
</p>
<p>Lemma 2. If x(t0) is less than c1 and y(t0) is less than c2, then x(t) is less 
than c1 andy(t) is less than c2 for all t;;.. t0&bull; 
</p>
<p>PROOF OF LEMMA 1. Suppose that Lemma 1 is false. Let t* &gt; t0 be the first 
time at which either x or y is zero. Assurne that x is zero first. Then, 
evaluating the first equation of (1) at t=t* gives x(t*)=b1c1y(t*). This 
quantity is positive. (Note that y ( t*) cannot equal zero since x = 0, y = 0 is 
an equilibrium solution of (1).) Hence, x(t) is less than zero for t close to, 
and less than t*. But this contradicts our assumption that t* is the first 
time at which x(t) equals zero. We run into the same contradiction if y(t*) 
=0. Thus, both x(t) andy(t) arepositivefort;;.. t0&bull; D 
</p>
<p>PRooF OF LEMMA 2. Suppose that Lemma 2 is false. Let t* &gt; t0 be the first 
time at which either x=c1, or y=c2&bull; Suppose that x(t*)=c1&bull; Evaluating 
the first equation of (1) at t=t* gives x(t*)= -a1c1&bull; This quantity is nega-
tive. Hence, x(t) is greater than c1 fort close to, and less than t*. Butthis 
</p>
<p>467 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>contradicts our assumption that t* is the firsttime at which x(t) equals c1&bull; 
We run into the same contradiction if y(t*) = c2&bull; Thus, x(t) is less than c1 
andy(t) is less than c2 fort&gt; t0&bull; D 
</p>
<p>Having shown that the system of equations (1) is a realistic model of 
gonorrhea, we now see what predictions it makes concerning the future 
course of this disease. Will gonorrhea continue to spread rapidly and un-
controllably as the data in Figure 1 seems to suggest, or will it Ievel off 
eventually? The following extremely important theorem of epidemiology 
provides the answer to this question. 
</p>
<p>Theorem 8. 
(a) Suppose that a1a2 is less than b1b2c 1c2&bull; Then, every solution x(t), 
</p>
<p>y(t) of (1) with 0 &lt; x(t0) &lt; c1 and 0 &lt; y(t0) &lt; c2, approaches the 
equilibrium solution 
</p>
<p>as t approaches infinity. In other words, the total numbers of infective 
males and infective females will ultimately Ievel off. 
</p>
<p>(b)Suppose that a1a2 is greater than b1b2c1c2&bull; Then every solution x(t), 
y(t) of (1) with 0&lt; x(t0) &lt; c1 and O&lt;y(t0) &lt; c2, approaches zero as t ap-
proaches infinity. In other words, gonorrhea will ultimately die out. 
</p>
<p>Our first step in proving part (a) of Theorem 8 is to split the reetangle 
0 &lt; x &lt; c1, 0 &lt;y &lt; c2 into regions in which both dx I dt and dy I dt have 
fixed signs. This is accomplished in the following manner. Setting dx I dt = 
0 in (1), and solving for y as a function of x gives 
</p>
<p>Similarly, setting dy I dt = 0 in ( 1) gives 
</p>
<p>Observe first that &lt;P1(x) and &lt;Pz(x) are monotonic increasing functions of x; 
&lt;P1(x) approaches infinity as x approaches c1, and &lt;Pz(x) approaches c2 as x 
approaches infinity. Second, observe that the curvesy=&lt;P1(x) andy=&lt;Pz(x) 
intersectat (0,0) and at (x0, y 0) where 
</p>
<p>468 </p>
<p/>
</div>
<div class="page"><p/>
<p>6
0
</p>
<p>0
 ,
</p>
<p>_ 
</p>
<p>5
5
</p>
<p>0
&middot;-
</p>
<p>5
0
</p>
<p>0
 
</p>
<p>4
5
</p>
<p>0
&middot;-
</p>
<p>4
0
</p>
<p>0
 
</p>
<p>3
5
</p>
<p>0
 
</p>
<p>3
0
</p>
<p>0
 
</p>
<p>2
5
</p>
<p>0
 
</p>
<p>2
0
</p>
<p>0
&middot;-
</p>
<p>0 
f 
</p>
<p>I 
f 
</p>
<p>1
9
</p>
<p>5
0
</p>
<p> 
1
</p>
<p>9
5
</p>
<p>2
 
</p>
<p>1
9
</p>
<p>5
4
</p>
<p> 
1
</p>
<p>9
5
</p>
<p>6
 
</p>
<p>1
9
</p>
<p>5
8
</p>
<p> 
1
</p>
<p>9
6
</p>
<p>0
 
</p>
<p>1
9
</p>
<p>6
2
</p>
<p> 
1
</p>
<p>9
6
</p>
<p>4
 
</p>
<p>1
9
</p>
<p>6
6
</p>
<p> 
1
</p>
<p>9
6
</p>
<p>8
 
</p>
<p>1
9
</p>
<p>7
0
</p>
<p> 
1
</p>
<p>9
7
</p>
<p>2
 
</p>
<p>F
IS
</p>
<p>C
A
</p>
<p>L
 
</p>
<p>Y
E
</p>
<p>A
R
</p>
<p> 
</p>
<p>F
ig
</p>
<p>ur
e 
</p>
<p>I.
 R
</p>
<p>ep
or
</p>
<p>te
d 
</p>
<p>ca
se
</p>
<p>s 
of
</p>
<p> g
on
</p>
<p>or
rh
</p>
<p>ea
, 
</p>
<p>in
 t
</p>
<p>ho
us
</p>
<p>an
ds
</p>
<p>, 
fo
</p>
<p>r 
19
</p>
<p>50
-1
</p>
<p>97
3.
</p>
<p> </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>y=~(x) 
I 
</p>
<p>y 
</p>
<p>Cz~-------------------------7~-------, 
</p>
<p>x&gt; 0 
y&lt; 0 
</p>
<p>Figure 2 
</p>
<p>Third, observe that cJ&gt;ix) is increasing faster than cp1(x) at x=O, since 
</p>
<p>Hence, cp2(x) lies above cp1(x) for 0&lt;x&lt;x0 , and cJ&gt;ix) lies below cp 1(x) for 
x0 &lt; x &lt; c1, as shown in Figure 2. The point (x0, y 0) is an equilibrium point 
of (I) since both dx I dt and dy I dt are zero when x = x 0 and y = y 0&bull; 
</p>
<p>Finally, observe that dxl dt is positive at any point (x,y) above the 
curvey=cJ&gt;1(x), and negative at any point (x,y) below this curve. Similarly, 
dyldt is positive at any point (x,y) below the curvey=cp2(x), and negative 
at any point (x,y) above this curve. Thus, the curves y =cp1(x) and y = 
cp2(x) split the reetangle 0 &lt; x &lt; c1, 0 &lt;y &lt; c2 into four regions in which 
dx I dt and dy I dt have fixed signs (see Figure 2). 
</p>
<p>Next, we require the following four simple Iemmas. 
</p>
<p>Lemma 3. Any solution x(t), y(t) of (I) which starts in region I at timet= t0 
will remain in this region for all future time t ;;. t0 and approach the 
equilibrium solution x = x 0, y = y 0 as t approaches infinity. 
</p>
<p>PROOF. Suppose that a solution x(t),y(t) of (I) leaves region I at timet= 
t*. Then, either x(t*) or y(t*) is zero, since the only way a solution of (I) 
can leave region I is by crossing the curve y =cJ&gt;1(x) or y =cp2(x). Assurne 
that .X(t*)=O. Differentiating both sides of the first equation of (I) with re-
</p>
<p>470 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.13 A model for the spread of gonorrhea 
</p>
<p>spect to t and setting t = t* gives 
</p>
<p>This quantity is positive, since x(t*) is less than c1, and dy I dt is positive on 
the curvey=cp1(x), 0&lt;x&lt;x0&bull; Hence, x(t) has a minimum at t=t*. But 
this is impossible, since x(t) is increasing whenever the solution x(t), y(t) is 
in region I. Similarly, if y(t*)=O, then 
</p>
<p>This quantity is positive, since y( t*) is less than c2, and dx I dt is positive on 
the curvey=cpix), 0&lt;x&lt;x0&bull; Hence,y(t) has a minimum at t=t*. But 
this is impossible, since y(t) is increasing whenever the solution x(t), y(t) is 
in region I. 
</p>
<p>The previous argument shows that any solution x(t),y(t) of (I) which 
starts in region I at time t = t0 will remain in region I for all future time t;.. 
t0&bull; This implies that x(t) and y(t) are monotonic increasing functions of 
time fort;.. t0 , with x(t)&lt;x0 andy(t)&lt;y0&bull; Consequently, by Lemma I of 
Section 4.8, both x( t) and y ( t) have Iimits ~. 1J, respectively, as t approaches 
infinity. Lemma 2 of Section 4.8 implies that (~. 1J) is an equilibrium point 
of (1). Now, it is easily seen from Figure 2 that the only equilibrium points 
of (1) are (0,0) and (x0, y 0). But (~,7J) cannot equal (0,0) since both x(t) 
and y(t) are increasing functions of time. Hence, (~;1J)=(x 0 , y 0), and this 
proves Lemma 3. D 
</p>
<p>Lemma 4. Any solution x(t), y(t) of (1) which starts in region Ill at timet= 
t0 will remain in this region for a/1 future time and ultimately approach the 
equilibrium solution x = x 0 , y = Yo&middot; 
</p>
<p>PROOF. Exactly the same as Lemma 3 (see Exercise 1). D 
</p>
<p>Lemma 5. Any solution x(t), y(t) of (1) which starts in region II at time t = 
t0, and remains in region II for a/1 future time, must approach the 
equilibrium solution x = x0 , y = y 0 as t approaches infinity. 
</p>
<p>PROOF. If a solution x(t), y(t) of (1) remains in region II for t;.. t0 , then 
x(t) is monotonic decreasing and y(t) is monotonic increasing for t;.. t0&bull; 
Moreover, x(t) is positive andy(t) is less than c2, fort;.. t0&bull; Consequently, 
by Lemma 1 of Section 4.8, both x(t) andy(t) have Iimits ~.1/ respectively, 
as t approaches infinity. Lemma 2 of Section 4.8 implies that (~, 1J) is an 
equilibrium point of (1). Now, (~,7J) cannot equal (0,0) sincey(t) is increas-
ing fort;.. t0 &bull; Therefore, (~,1J)=(x 0 ,y 0 ), and this proves Lemma 5. D 
</p>
<p>471 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>Lemma 6. Any solution x(t), y(t) of (I) which starts in region IV at timet= 
t0 and remains in region IV for al/ future time, must approach the 
equilibrium solution x = x0, y = y 0 as t approaches infinity. 
</p>
<p>PR.ooF. Exactly the same as Lemma 5 (see Exercise 2). D 
</p>
<p>W e are now in a position to prove Theorem 8. 
</p>
<p>PROOF OF THEOREM 8. (a) Lemmas 3 and 4 state that every solution x(t), 
y(t) of (1) which starts in region I or III at time t = t0 must approach the 
equilibrium solution x = x 0 , y = y 0 as t approaches infinity. Similarly, 
Lemmas 5 and 6 state that every solution x(t), y(t) of (I) which starts in 
region li or IV and which remains in these regions for all future time, must 
also approach the equilibrium solution x = x0, y = y 0&bull; Now, observe that if 
a solution x(t), y(t) of (I) leaves region li or IV, then it must cross the 
curve y =&lt;t&gt;1(x) or y =&lt;t&gt;2(x), and immediately afterwards enter region I or 
region III. Consequently, all solutions x(t), y(t) of (I) which start in re-
gions II and IV or on the curves y =cf&gt;1(x) and y =&lt;t&gt;2(x), must also ap-
proach the equilibrium solution x(t) = x0,y(t) = y 0&bull; D 
</p>
<p>(b) PROOF #I. If a1a2 is greater than b1b2c1c2, then the curves y =&lt;t&gt;1(x) 
and y =&lt;f&gt;lx) have the form described in Figure 3 below. In region I, 
dx I dt is positive and dy I dt is negative; in region II, both dx I dt and dy I dt 
are negative; and in region III, dx I dt is negative and dy I dt is positive. lt 
is a simple matter to show (see Exercise 3) that every solution x(t), y(t) of 
(I) which starts in region II at timet= t0 must remain in this region for all 
</p>
<p>Figure 3 
</p>
<p>472 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.13 A model for the spread of gonorrhea 
</p>
<p>future time, and approach the equilibrium solution x = 0, y = 0 as t ap-
proaches infinity. 1t is also trivial to show that every solution x(t), y(t) of 
(1) which starts in region I or region 111 at time t = t0 must cross the curve 
y=cPJ(x) or y=cf&gt;ix), and immediately afterwards enter region II (see Ex-
ercise 4). Consequently, every solution x(t),y(t) of (1), with O&lt;x(t0)&lt;c1 
and O&lt;y(t0)&lt; c2, approaches the equilibrium solution x=O, y =0 as t ap-
proaches infinity. D 
</p>
<p>PRooF #2. We would now like to show how we can use the Poincare-
Bendixson theorem to give an elegant proof of part (b) of Theorem 8. Ob-
serve that the system of differential equations (1) can be written in the 
form 
</p>
<p>(2) 
</p>
<p>Thus, by Theorem 2 of Section 4.3, the stability of the solution x = 0, y = 0 
of (2) is determined by the stability of the equilibrium solution x = 0, y = 0 
of the linearized system 
</p>
<p>~(~)=A(~)=( ~;~ ~:J(~)&middot; 
The characteristic polynomial of the matrix A is 
</p>
<p>A2 +(a1 + a2)A+ a1a2 - b1b2c1c2 
whose roots are 
</p>
<p>[ 2 ]1/2 -(a1+a2)&plusmn; (a 1+a2) -4(a1a2-b1b2c1c2) 
A= 2 
</p>
<p>lt is easily verified that both these roots are real and negative. Hence, the 
equilibrium solution x = 0, y = 0 of (2) is asymptotically stable. This implies 
that any solution x(t), y(t) of (1) which starts sufficiently close to the 
origin x = y = 0 will approach the origin as t approaches infinity. Now, 
suppose that a solution x(t),y(t) of (1), with 0&lt;x(t0)&lt;c1 and O&lt;y(t0)&lt; 
c2, does not approach the origin as t approaches infinity. By the previous 
remark, this solution must always remain a minimum distance from the 
origin. Consequently, its orbit for t ~ t0 lies in a bounded region in the x-
y plane which contains no equilibrium points of (1). By the Poincare-
Bendixson Theorem, therefore, its orbit must spiral into the orbit of a peri-
odic solution of (1). But the system of differential equations (1) has no 
periodic solution in the first quadrant x ~ 0, y ~ 0. This follows im-
mediate1y from Exercise 11, Section 4.8, and the fact that 
</p>
<p>a a ax[ -alx+bl(cl-x)y]+ ay[-a2y+bic2-y)x] 
= -(a1 +a2 +&Ouml;1y+b2x) 
</p>
<p>is strictly negative if both x and y are nonnegative. Consequently, every 
</p>
<p>473 </p>
<p/>
</div>
<div class="page"><p/>
<p>4 Qualitative theory of differential equations 
</p>
<p>solution x(t), y(t) of (1), with 0&lt;x(t0)&lt;c1 and 0&lt;y(t0)&lt;c2 approaches 
the equilibrium solution x = O,y = 0 as t approaches infinity. 0 
</p>
<p>Now, it is quite difficult to evaluate the coefficients a 1, a2, b1, o2, c1, and 
c2&bull; Indeed, it is impossible to obtain even a crude estimate of a2, which 
should be interpreted as the average amount of time that a female remains 
infective. (Similarly, a1 should be interpreted as the average amount of 
time that a male remains infective.) This is because most females do not 
exhibit symptoms. Thus, a female can be infective for an amount of time 
varying from just one day to well over a year. Nevertheless, it is still possi-
ble to ascertain from public health data that a1a2 is less than b1b2c1c2, as 
we now show. Observe that the condition a 1a2 &lt; b1b2c1c2 is equivalent to 
</p>
<p>The quantity b1c1/ a2 can be interpreted as the average number of males 
that one female infective contacts during her infectious period, if every 
male is susceptible. Similarly, the quantity b2c2/ a 1 can be interpreted as 
the average number of females that one male infective contacts during his 
infectious period, if every female is susceptible. The quantities b1c1/ a2 and 
b2c2/ a1 are called the maximal female and male contact rates, respectively. 
Theorem 8 can now be interpreted in the following manner. 
</p>
<p>(a) If the product of the maximal male and female contact rates is greater 
than one, then gonorrhea will approach a nonzero steady state. 
</p>
<p>(b) If the product of the maximal male and female contact rates is less 
than one, then gonorrhea will die out eventually. 
</p>
<p>In 1973, the average number of female contacts named by a male infec-
tive during his period of infectiousness was 0.98, while the average number 
of male contacts named by a female infective during her period of infec-
tiousness was 1.15. These numbers are very good approximations of the 
maximal male and female contact rates, respectively, and their product 
does not exceed the product of the maximal male and female contact rates. 
(The number of contacts of a male or female infective during their period 
of infectiousness is slightly less than the maximal male or female contact 
rates. However, the actual number of contacts is often greater than the 
number of contacts named by an infective.) The product of 1.15 with 0.98 
is 1.0682. Thus, gonorrhea will ultimately approach a nonzero steady state. 
</p>
<p>Remark. Our model of gonorrhea is rather crude since it lumps all prom-
iscuous males and all promiscuous females together, regardless of age. A 
more accurate model can be obtained by separating the male and female 
populations into different age groups and then computing the rate of 
change of infectives in each age group. This has been done recently, but 
the analysis is too difficult to present here. We just mention that a result 
</p>
<p>474 </p>
<p/>
</div>
<div class="page"><p/>
<p>4.13 A model for the spread of gonorrhea 
</p>
<p>completely analogous to Theorem 8 is obtained: either gonorrhea dies out 
in each age group, or it approaches a constant, positive Ievel in each age 
group. 
</p>
<p>EXERCISES 
</p>
<p>In Problems 1 and 2, we assume that a1a2 &lt; b1b2c1c2&bull; 
1. (a) Suppose that a solution x(t), y(t) of (1) leaves region III of Figure 2 at time 
</p>
<p>t = t* by crossing the curve y =ci&gt;I(x) or y =cp2(x). Conclude that either x(t) 
or y(t) has&middot; a maximum at t= t*. Then, show that this is impossible. Con-
clude, therefore, that any solution x(t), y(t) of (1) which starts in region III 
at time t = t0 must remain in region III for all future time t &gt; t0. 
</p>
<p>(b) Conclude from (a) that any solution x(t), y(t) of (1) which starts in region 
III has a 1imit ~. 11 as t approaches infinity. Then, show that (~, 'IJ) must equal 
(xo. Yo). 
</p>
<p>2. Suppose that a solution x(t), y(t) of (1) remains in region IV of Figure 2 for all 
time t &gt; t0. Prove that x(t) and y(t) have Iimits ~. 11 respectively, as t approaches 
infinity. Then conclude that (~, 'IJ) must equal (x0, y 0). 
</p>
<p>In Problems 3 and 4, we assume that a1a2&gt; b1b2c1c2. 
</p>
<p>3. Suppose that a solution x(t), y(t) of (1) leaves region II of Figure 3 at time t = t* 
by crossing the curve y =cp1(x) or y =cp2(x). Show that either x(t) or y(t) has a 
maximum at t = t*. Then, show that this is impossible. Conclude, therefore, that 
every solution x(t),y(t) of (1) which starts in region II at timet= t0 must remain 
in region II for all future time t &gt; t0. 
</p>
<p>4. (a) Suppose that a solution x(t), y(t) of (1) remains in either region I or III of 
Figure 3 for all time t &gt; t0&bull; Show that x( t) and y ( t) have Iimits ~. 11 respec-
tively, as t approaches infinity. 
</p>
<p>(b) Conclude from Lemma 1 of Section 4.8 that (~,1J)=(O,O). 
(c) Show that (~,'IJ) cannot equal (0,0) if x(t),y(t) remains in region I or region 
</p>
<p>III for all time t &gt; t0&bull; 
(d) Show that any solution x(t),y(t) of (1) which starts on either y =cp1(x) or y = 
</p>
<p>cp2(x) will imrnediately afterwards enter region II. 
</p>
<p>5. Assurne that a1a2 &lt; b1b2c1c2&bull; Prove directly, using Theorem 2 of Section 4.3, that 
the equilibrium solution x=x0,y=y0 of (1) is asymptotically stable. Warning: 
The calculations are extremely tedious. 
</p>
<p>6. Assurne that the number of homosexuals remains constant in time. Call this con-
stant c. Let x(t) denote the number of homosexuals who have gonorrhea at time 
t. Assurne that homosexuals are cured of gonorrhea at a rate a 1, and that new 
infectives are added at a rate &szlig;1(c-x)x. 
(a) Show that i= -a1x+&szlig;1x(c-x). 
(b) What happens to x(t) as t approaches infinity? 
</p>
<p>7. Suppose that the number of homosexuals c(t) grows according to the logistic 
1aw c=c(a-bc), for some positive constants a and b. Let x(t) derrote the num-
ber of homosexuals who have gonorrhea at timet, and assume (see Problem 6) 
that x= -alx+&szlig;Jx(c-x). What happens to x(t) as t approaches infinity? 
</p>
<p>475 </p>
<p/>
</div>
<div class="page"><p/>
<p>5 
Separation of variables 
</p>
<p>and Fourier series 
</p>
<p>5.1 Two point boundary-value problems 
</p>
<p>In the applications which we will study in this chapter, we will be con-
fronted with the following problem. 
</p>
<p>Problem: For which values of A can we find nontrivial functions y(x) 
which satisfy 
</p>
<p>d2y 
dx 2 +Ay=O; ay(O)+by'(O)=O, cy(/)+dy'(/)=0? (I) 
</p>
<p>Equation (I) is called a boundary-value problem, since we prescribe infor-
mation about the solution y(x) and its derivative y'(x) at two distinct 
points, x = 0 and x = /. In an initial-value prob lern, on the other band, we 
prescribe the value of y and its derivative at a single point x = x0&bull; 
</p>
<p>Our intuitive feeling, at this point, is that the boundary-value problern 
(1) has nontrivial solutions y(x) only for certain exceptional values A. To 
wit, y(x)=O is certainly one solution of (1), and the existence-uniqueness 
theorem for second-order linear equations would seem to imply that a 
solution y(x) of y" +Ay =0 is determined uniquely once we prescribe two 
additional pieces of information. Let us test our intuition on the following 
simple, but extremely important example. 
</p>
<p>Example 1. For which values of A does the boundary-value problern 
</p>
<p>d2y 
dx2 +Ay=O; y(O)=O, y(/)=0 (2) 
</p>
<p>have nontrivial solutions? 
</p>
<p>476 </p>
<p/>
</div>
<div class="page"><p/>
<p>5.1 Two point boundary-value problems 
</p>
<p>Solution. 
(i) ;\=0. Every solutiony(x) of the differential equationy"=O is of the 
</p>
<p>formy(x)=c 1x+c2&gt; for some choice of constants c1 and c2&bull; The condition 
y(O)=O implies that c2 =0, and the conditiony(/) =0 then implies that c 1 = 
0. Thus, y(x)=O is the only solution of the boundary-value problern (2), 
for ;\=0. 
</p>
<p>(ii) ;\&lt;0: In this case, every solutiony(x) of y"+~=O is of the form 
</p>
<p>y(x)= c1e -v=x x + c2e- \."=&gt;:X, for some choice of constants c1 and c2&bull; The 
boundary conditions y (0) = y ( /) = 0 imply that 
</p>
<p>(3) 
</p>
<p>The system of equations (3) has a nonzero solution c1,c2 if, and only if, 
</p>
<p>This implies that e \."=&gt;: 1 = e- \."=&gt;: 1, or e2v=x 1 = I. But this is impossible, 
since ez is greater than one for z &gt; 0. Hence, c 1 = c2 = 0 and the boundary-
value problern (2) has no nontrivial solutions y(x) when Ais negative. 
</p>
<p>(iii) A &gt; 0: In this case, every solution y ( x) of y" + ;\y = 0 is of the form 
y(x)=c1 cosv'X x+c2 sinv'X x, for some choice of constants c1 and c2&bull; 
The conditiony(O)=O implies that c1=0, and the conditiony(/)=0 then 
implies that c2 sin v'X I= 0. This equation is satisfied, for any choice of c2, 
if VX I= mr, or A = n 2 7T 2 /1 2, for some positive integer n. Hence, the 
boundary-value problern (2) has nontrivial solutionsy(x)=csinn'lTx/1 for 
A=n 2 7T2/l 2, n=I,2, .... 
</p>
<p>Remark. Our calculations for the case ;\ &lt; 0 can be simplified if we write 
every solutiony(x) in the formy=c 1 coshY=X x+c2 sinhY=X x, where 
</p>
<p>'~ ev'=Xx+e-v'=Xx 
cosh v -I\ x = ------,---
</p>
<p>2 
and 
</p>
<p>ev'=Xx_e-Y=Xx 
sinhY=X x= 2 . 
</p>
<p>The condition y(O)=O implies that c1 =0, and the condition y(/)=0 then 
implies that c2 sinh"V=X 1=0. But sinhz is positive for z &gt;0. Hence, c2 =0, 
andy(x)=O. 
</p>
<p>Example I is indicative of the general boundary-value problern (I). In-
deed, we have the following remarkable theorem which we state, but do 
not prove. 
</p>
<p>477 </p>
<p/>
</div>
<div class="page"><p/>
<p>5 Separation of variables and Fourier series 
</p>
<p>Theorem 1. The boundary-value problern (1) has nontrivial solutions y(x) 
on/y for a denumerable set of values A 1, A2, &bull;&bull;&bull; , where A 1 ~ A2 &bull;&bull;&bull; , and A" ap-
proaches infinity as n approaches infinity. These special values of A are 
called eigenvalues oj (1), and the nontrivial solutions y(x) are called eigen-
functions of (1). In this terminology, the eigenvalues of (2) are 
772 I 12,4772 I 12,9772 I 12, ... , and the eigenfunctions of (2) are all constant 
multiples of sin 77X I l, sin277x I l, ... . 
</p>
<p>There is a very natural explanation of why we use the terms eigenvalue 
and eigenfunction in this context. Let V be the set of all functions y(x) 
which have two continuous derivatives and which satisfy ay(O)+by'(O)= 
0, cy(l) + dy'(l) = 0. Clearly, V is a vector space, of infinite dimension. 
Consider now the linear operator, or transformation L, defined by the 
equation 
</p>
<p>d2y 
[ Ly ](x)=- - 2 (x). 
</p>
<p>dx 
(4) 
</p>
<p>The solutionsy(x) of (1) are those functionsy in V for which Ly =Ay. That 
is to say, the solutions y(x) of (1) are exactly those functions y in V which 
are transformed by L into multiples A of themselves. 
</p>
<p>Example 2. Find the eigenvalues and eigenfunctions of the boundary-value 
problern 
</p>
<p>y(O)+y'(O)=O, y(1)=0. (5) 
</p>
<p>Solution. 
(i) A=O. Every solutiony(x) ofy"=O is of the formy(x)=c 1x+c2&gt; for 
</p>
<p>some choice of constants c1 and c2. The conditionsy(O)+y'(O)=O andy(l) 
=0 both imply that c2 = -c1&bull; Hence,y(x)=c(x-1), ci'O, isanontrivial 
solution of (5) when A=O; i.e.,y(x)=c(x-1), c~O, is an eigenfunction of 
(5) with eigenva1ue zero. 
</p>
<p>(ii) A&lt;O. In this case, every solutiony(x) ofy"+Ay=O is of the form 
y(x)=c1cosh"V=X x+c2 sinh"V=X x, for some choice of constants c1 and 
c2&bull; The boundary conditionsy(O)+y'(O)=O andy(1)=0 imply that 
</p>
<p>c1 +V-A c2 =0, cosh"V=X c1 +sinh"V=X c2 =0. (6) 
</p>
<p>(Observe that (coshx)' = sinhx and (sinhx)' = coshx.) The system of equa-
tions (6) has a nontrivial solution c1,c2 if, and only if, 
</p>
<p>det( 1 Y=X ) = sinh V-A - ~ cosh ~ = 0. 
cosh~ sinh~ 
</p>
<p>This implies that 
</p>
<p>sinh V-A = ~ cosh ~ . (7) 
</p>
<p>But Equation (7) has no solution A &lt; 0. To see this, Iet z = ~ , and con-
</p>
<p>478 </p>
<p/>
</div>
<div class="page"><p/>
<p>5.1 Two point boundary-value problems 
</p>
<p>sider the function h(z) = z coshz- sinhz. This function is zero for z = 0 and 
is positive for z &gt; 0, since its derivative 
</p>
<p>h ' ( z) = cosh z + z sinh z - cosh z = z sinh z 
is strictly positive for z &gt; 0. Hence, no negative number &gt;.. can satisfy (7). 
</p>
<p>(iii) "A&gt;O. In this case, every solutiony(x) of y"+A.y=O is of the form 
y(x) = c1 cosv'X x + c2 sin \IX x, for some choice of constants c1 and c2&bull; 
The boundary conditions imply that 
</p>
<p>c1 +\IX c2 =0, cos\IX c1 +sin\IX c2 =0. (8) 
</p>
<p>The system of equations (8) has a nontrivial solution cpc2 if, and only if, 
</p>
<p>det( 1 \IX ) = sin VX - \IX cos \IX = 0. 
cosv'X sinv'X 
</p>
<p>This implies that 
</p>
<p>tanv'X =YX. (9) 
</p>
<p>To find those values of &gt;.. which satisfy (9), we set ~= VX and draw the 
graphs of the functions 11 =~ and 11 = tan~ in the ~- 11 plane (see Figure 1); 
the ~ coordinate of each point of intersection of these curves is then a root 
of the equation ~ = tan f lt is clear that these curves intersect exactly once 
in the interval 7T /2 &lt; ~ &lt; 37T /2, and this occurs at a point ~ 1 &gt; 7T. Similarly, 
these two curves intersect exactly once in the interval 37T /2 &lt; ~ &lt; 57T /2, and 
this occurs at a point ~ 2 &gt; 27T. More generally, the curves YJ = ~ and YJ = tan~ 
intersect exactly once in the interval 
</p>
<p>(2n -1)7T (2n + 1)7T 
2 &lt;~&lt; 2 
</p>
<p>and this occurs at a point ~n &gt; n7T. 
</p>
<p>I 
7]= tan t 
</p>
<p>I 
I 
I 
</p>
<p>Figure 1. Graphs of 'II = ~ and 'II = tan~ 
</p>
<p>479 </p>
<p/>
</div>
<div class="page"><p/>
<p>5 Separation of variables and Fourier series 
</p>
<p>Finally, the curves 11 = ~ and 11 = tan ~ do not intersect in the interval 0 &lt; 
~&lt;'TT/2. To prove this, set h(~)=tan~-~ and compute 
</p>
<p>h'(~) = sec2 ~-1 = tan2 ~. 
</p>
<p>This quantity is positive for 0 &lt; ~ &lt; 'TT j2. Consequently, the eigenvalues of 
(5) are A1 = ~?,A 2 = ~f, ... , and the eigenfunction of (5) are all constant mul-
tiples of the functions - "V&gt;:; cos "V&gt;:; x + sin "V&gt;:; x, - -v&gt;:; cos -v&gt;:; x 
+ sin VA2 x, ... . We cannot compute An exactly. Nevertheless, we know 
that 
</p>
<p>n2'TT2&lt;An &lt;(2n + 1)2'TT2 /4. 
In addition, it is clear that ~ approaches (2n + 1 i'TT2 /4 as n approaches in-
finity. 
</p>
<p>EXERCISES 
</p>
<p>Find the eigenvalues and eigenfunctions of each of the following 
boundary-value problems. 
</p>
<p>1. y" +Xy=O; y(O)=O, y'(l)=O 
</p>
<p>2. y" +Xy=O; y'(O)=O, y'(l)=O 
</p>
<p>3. y" -Xy =0; y'(O)=O, y'(l)=O 
</p>
<p>4. y"+~=O; y'(O)=O, y(l)=O 
</p>
<p>S. y"+Xy=O; y(O)=O, y('IT)-y'('IT)=O 
</p>
<p>6. y"+Xy=O; y(O)-y'(O)=O, y(l)=O 
</p>
<p>7. y"+Xy=O; y(O)-y'(O)=O, y('1T)-y'('1T)=O 
</p>
<p>8. For which values of X does the boundary-value problern 
</p>
<p>y"-2y'+(l+X)y=O; y(O)=O, y(l)=O 
</p>
<p>have a nontrivial solution? 
</p>
<p>9. For which values of X does the boundary-value problern 
</p>
<p>y"+Xy=O; y(O)=y(2'1T), y'(O)=y'(2'1T) 
</p>
<p>have a nontrivial solution? 
</p>
<p>10. Consider the boundary-value problern 
</p>
<p>y"+Xy=J(t); y(O)=O, y(l)=O (*) 
</p>
<p>(a) Show that (*) has a unique solutiony(t) if Xis not an eigenvalue of the ho-
rnogeneous problern. 
</p>
<p>480 
</p>
<p>(b) Show that (*) rnay have no solutiony(t) if Ais an eigenvalue of the horno-
geneous problern. 
</p>
<p>(c) Let A be an eigenvalue of the hornogeneous prob1ern. Determine conditions 
on f so that (*) has a solution y(t). Is this solution unique? </p>
<p/>
</div>
<div class="page"><p/>
<p>5.2 Introduction to partial differential equations 
</p>
<p>5.2 Introduction to partial differential equations 
</p>
<p>Up to this point, the differential equations that w.e have studied have all 
been relations involving one or more functions of a single variable, and 
their derivatives. In this sense, these differential equations are ordinary dif-
ferential equations. On the other hand, many important problems in ap-
plied mathematics give rise to partial differential equations. A partial dif-
ferential equation is a relation involving one or more functions of several 
variables, and their partial derivatives. For example, the equation 
</p>
<p>03 U +( OU ) 2 = o2 U 
OX3 ot ox2 
</p>
<p>is a partial differential equation for the function u(x, t), and the equations 
</p>
<p>ou ov ou ov 
ax = oy ' oy = - ox 
</p>
<p>are a system of partial differential equations for the two functions u(x,y) 
and v(x,y). The order of a partial differential equation is the order of the 
highest partial derivative that appears in the equation. For example, the 
order of the partial differential equation 
</p>
<p>o2u ()2u 
-=2--+u 
ot2 axot 
</p>
<p>is two, since the order of the highest partial derivative that appears in this 
equation is two. 
</p>
<p>There are three classical partial differential equations of order two 
which appear quite often in applications, and which dominate the theory 
of partial differential equations. These equations are 
</p>
<p>OU 2 o2 u 
-=a --
ot ox2 ' 
</p>
<p>(1) 
</p>
<p>o2u o2u --=c2 __ 
ot2 ox2 
</p>
<p>(2) 
</p>
<p>and 
</p>
<p>o2 U + o2 u =&Uuml;. 
ox2 oy2 
</p>
<p>(3) 
</p>
<p>Equation (1) is known as the heat equation, and it appears in the study 
of heat conduction and other diffusion processes. For example, consider a 
thin metal bar of length I whose surface is insulated. Let u(x, t) denote the 
temperature in the bar at the point x at time t. This function satisfies the 
partial differential equation (1) for O&lt;x&lt;l. The constant a2 is known as 
the thermal diffusivity of the bar, and it depends solely on the material 
from which the bar is made. 
</p>
<p>481 </p>
<p/>
</div>
<div class="page"><p/>
<p>5 Separation of variables and Fourier series 
</p>
<p>Equation (2) is known as the wave equation, and it appears in the study 
of acoustic waves, water waves and electromagnetic waves. Some form of 
this equation, or a generalization of it, almost invariably arises in any 
mathematical analysis of phenomena involving the propagation of waves 
in a continuous medium. (We will gain some insight into why this is so in 
Section 5.7.) The wave equation also appears in the study of mechanical 
vibrations. Suppose, for example, that an elastic string of length /, such as 
a violin string or guy wire, is set in motion so that it vibrates in a vertical 
plane. Let u(x, t) denote the vertical displacement of the string at the point 
x at timet (see Figure 1). If all damping effects, such as air resistance, are 
negligible, and if the amplitude of the motion is not too large, then u(x, t) 
will satisfy the partial differential equation (2) on the interval 0 &lt;~t; x &lt;~t; /. In 
this case, the constant c2 is H / p, where H is the horizontal component of 
the tension in the string, and p is the mass per unit length of the string. 
</p>
<p>u 
</p>
<p>u(x,t) 
</p>
<p>Figure 1 
</p>
<p>Equation (3) is known as Laplace's equation, and is the most famous of 
all partial differential equations. It arises in the study of such diverse ap-
plications as steady state heat flow, vibrating membranes, and e1ectric and 
gravitational potentials. For this reason, Laplace's equation is often re-
ferred to as the potential equation. 
</p>
<p>In addition to the differential equation (1), (2), or (3), we will often im-
pose initial and boundary conditions on the function u. These conditions 
will be dictated to us by the physical and biological problems themselves; 
they will be chosen so as to guarantee that our equation has a unique solu-
tion. 
</p>
<p>As a model case for the heat equation (1), we consider a thin metal bar 
of length I whose sides are insulated, and we Iet u(x,t) denote the tempera-
turein the bar at the point x at timet. In order to dermine the temperature 
in the bar at any time t we need to know (i) the initial temperature distrib-
ution in the bar, and (ii) what is happening at the ends of the bar. Are they 
held at constant temperatures, say ooc, or are they insulated, so that no 
heat can pass through them? (This latter condition implies that ux&lt;O, t) = 
ux&lt;l, t) = 0.) Thus, a "well posed" problern for diffusion processes is the 
</p>
<p>482 </p>
<p/>
</div>
<div class="page"><p/>
<p>5.3 The heat equation; Separation of variables 
</p>
<p>heat equation (1), tagether with the injtial condition u(x, 0) = f(x), 0 &lt; x &lt; 
I, and the boundary conditions u(O,t)= u(l,t)=O, or ux(O,t)= ux&lt;l,t)=O. 
</p>
<p>As a model case for the wave equation, we consider an elastic string of 
length /, whose ends are fixed, and which is set in motion in a vertical 
plane. In order to determine the position u(x, t) of the string at any time t 
we need to know (i) the initial position of the string, and (ii) the initial 
velocity of the string. lt is also implicit that u(O, t) = u(l, t) = 0. Thus, a weil 
posed problern for wave propagation is the differential equation (2) 
tagether with the initial conditions u(x, 0) = f(x), u1(x, 0) = g(x), and the 
boundary conditions u(O,t)= u(l,t)=O. 
</p>
<p>The partial differential equation (3) does not contain the time t, so that 
we do not expect any "initial conditions" to be imposed here. In the prob-
lems that arise in applications, we are given u, or its normal derivative, on 
the boundary of a given region R, and we seek to deterrnine u(x,y) inside 
R. The problern of finding a solution of Laplace's equation which takes on 
given boundary values is known as a Dirichlet problem, while the problern 
of finding a solution of Laplace's equation whose normal derivative takes 
on given boundary values is known as a Neumann problem. 
</p>
<p>In Section 5.3 we will develop a very powerful method, known as the 
method of separation of variables, for solving the boundary-value problern 
(strictly speaking, we should say "initial boundary-value problem") 
</p>
<p>u(x,O)=f(x), O&lt;x&lt;l; u(O,t)=u(l,t)=O. 
</p>
<p>After developing the theory of Fourier series in Sections 5.4 and 5.5, we 
will show that the method of separation of variables can also be used to 
solve more general problems of heat conduction, and several important 
problems of wave propagation and potential theory. 
</p>
<p>5.3 The heat equation; separation of variables 
</p>
<p>Consider the boundary-value problern 
</p>
<p>u(x,O)=f(x), O&lt;x&lt;l; u(O,t)=u(l,t)=O. (I) 
</p>
<p>Our goal is to find the solution u(x, t) of (1). To this end, it is helpful to 
recall how we solved the initial-value problern 
</p>
<p>d2y dy 
- 2 +p(t)-d +q(t)y=O; 
dt t 
</p>
<p>y(O) = y 0, y'(O) = y~. (2) 
</p>
<p>First we showed that the differential equation 
</p>
<p>d2y dy 
- 2 +p(t)-d +q(t)y=O 
dt t 
</p>
<p>(3) 
</p>
<p>483 </p>
<p/>
</div>
<div class="page"><p/>
<p>5 Separation of variables and Fourier series 
</p>
<p>is linear; that is, any linear cornbination of solutions of (3) is again a solu-
tion of (3). And then, we found the solution y(t) of (2) by taking an ap-
propriate linear cornbination c1y 1(t)+c2Y2(t) of two linearly independent 
solutions y 1(t) and yit) of (3). Now, it is easily verified that any linear 
cornbination c1u1(x,t)+ ... + cnun(x,t) of solutions u1(x,t), ... ,un(x,t) of 
</p>
<p>au =a23 2u (4) 
at ax2 
</p>
<p>is again a solution of (4). In addition, if u1(x, t), ... , un(x, t) satisfy the 
boundary conditions u(O, t) = u(l, t) = 0, then the linear cornbination c1 u1 
+ ... + cnun also satisfies these boundary conditions. This suggests the 
following "garne plan" for solving the boundary-value problern (1): 
</p>
<p>(a) Find as rnany solutions u 1(x, t), uix, t), ... as we can of the 
boundary-value problern 
</p>
<p>au = ,..2 a 2u . (0 ) (/ ) 0 (5) at u ax2' u ,t = u ,t = . 
</p>
<p>(b) Find the solution u(x,t) of (1) by taking an appropriate linear corn-
bination of the functions un ( x, t), n = 1' 2, .... 
</p>
<p>(a) Since we don't know, as yet, how to solve any partial differential 
equations, we rnust reduce the problern of solving (5) to that of solving one 
or rnore ordinary differential equations. This is accornplished by setting 
u(x,t)=X(x)T(t) (hence the narne separation of variables). Cornputing 
</p>
<p>au -XT' d a2u -X"T -- an --
at ax2 
</p>
<p>we see that u(x, t) =X (x) T(t) is a solution of the equation u1 = a 2 uxx 
(ul = auj at and uxx = a 2u/ ax2) if 
</p>
<p>XT'=a 2X"T. (6) 
</p>
<p>Dividing both sides of (6) by a 2XT gives 
</p>
<p>X" T' 
-x= azr&middot; (7) 
</p>
<p>Now, observe that the left-hand side of (7) is a function of x alone, while 
the right-hand side of (7) is a function of t alone. This irnplies that 
</p>
<p>X" T' - = - A and - = - A (8) 
X ' azT 
</p>
<p>for sorne constant A. (The only way that a function o( x can equal a func-
tion oft is if both are constant. To convince yourself of this, letf(x)= g(t) 
and fix t0&bull; Then,j(x)=g(t0) for all x, so thatf(x)=constant=c1, and this 
irnrnediately irnplies that g(t) also equals c1.) In addition, the boundary 
conditions 
</p>
<p>0= u(O,t)=X(O)T(t), 
</p>
<p>484 </p>
<p/>
</div>
<div class="page"><p/>
<p>5.3 The heat equation; separation of variables 
</p>
<p>and 
</p>
<p>O=u(l,t)=X(l)T(t) 
</p>
<p>imply that X (0) = 0 and X (I)= 0 ( otherwise, u must be identically zero ). 
Thus, u(x,t)=X(x)T(t) is a solution of (5) if 
</p>
<p>X"+AX=O; X(O)=O, X{l)=O (9) 
</p>
<p>and 
</p>
<p>(10) 
</p>
<p>At this point, the constant A is arbitrary. However, we know from Example 
1 of Section 5.1 that the boundary-value problern (9) has a nontrivial solu-
tion X (x) only if A=\, = n2 'TT2 I 12, n = 1,2, ... ; andin this case, 
</p>
<p>X ( x) = X" ( x) = sin n~x . 
</p>
<p>Equation (10), in turn, implies that 
</p>
<p>T(t) = Tn (t) = e-a'n'.,'r/1'. 
</p>
<p>(Actually, we should multiply both Xn(x) and Tn(t) by constants; however, 
we omit these constants here since we will soon be taking linear combina-
tions of the functions X"(x) Tn(t).) Hence, 
</p>
<p>( ) - &middot; n7TX -a
2 n2 1r2 tjl 2 u" x,t -sin-1-e 
</p>
<p>is a nontrivial solution of (5) for every positive integer n. 
(b) Suppose that j(x) is a finite linear combination of the functions 
</p>
<p>sinn'TTx I I; that is, 
N 
</p>
<p>f(x)= ~ c,.sin n~x. 
n=l 
</p>
<p>Then, 
N 
</p>
<p>( ) _ ~ &middot; n7TX -a
2n 2.,2 tjl2 
</p>
<p>u x,t - ~ c"sm-1-e 
n=l 
</p>
<p>is the desired solution of (1), since it is a linear combination of solutions of 
(5), and it satisfies the initial condition 
</p>
<p>N 
</p>
<p>u(x,O)= ~ c"sin n~x = f(x), 
n=l 
</p>
<p>O&lt;x&lt;l. 
</p>
<p>Unfortunately, though, most functions f(x) cannot be expanded as a finite 
linear combination of the functions sinn1rx I l, n = 1, 2, ... , on the interval 
0 &lt; x &lt; I. This leads us to ask the following question. 
Question; Can an arbitrary function f(x) be written as an infinite linear 
combination of the functions sin n1rx I I, n = 1, 2, ... , on the interval 0 &lt; x &lt; 
</p>
<p>485 </p>
<p/>
</div>
<div class="page"><p/>
<p>5 Separation of variables and Fourier series 
</p>
<p>l? In other words, given an arbitrary function j, can we find constants 
c1,c2, &bull;&bull;&bull; , suchthat 
</p>
<p>O&lt;x&lt;l? 
</p>
<p>Remarkably, the answer to this question is yes, as we show in Section 5.5. 
</p>
<p>Example 1. At time t=O, the temperature u(x,O) in a thin copperrod (a2 
</p>
<p>= 1.14) of length one is 2sin37Tx+5sin87Tx, 0&lt; x &lt; l. The ends of the rod 
are packed in ice, so as to maintain them at ooc. Find the temperature 
u(x, t) in the rod at any time t &gt; 0. 
Solution. The temperature u(x, t) satisfies the boundary-value problern 
</p>
<p>au = 1.14 a2u. ( u(x,0}=2sin37Tx+5sin87TX, O&lt;x&lt; l 
ot ox2 ' u(O,t}=u(l,t}=O 
</p>
<p>and this implies that 
</p>
<p>u(x, t} = 2 sin 37TX e - 9(1.1 4)"21 + 5 sin 87Tx e - 64(1.! 4)"21&bull; 
</p>
<p>ExERCISES 
</p>
<p>Find a solution u(x, t) of the following problems. 
</p>
<p>{ 
u(x,O)=sin7rx/2+3sin57rx/2, 
</p>
<p>u(O,t)=u(2,t)=O 
</p>
<p>{ 
u(x,O)=sin'1Tx/2-3sin2'1Tx, 
</p>
<p>u(O,t)=u(2,t)=O 
</p>
<p>3. Use the method of separation of variables to solve the boundary-value problern 
</p>
<p>au = a2u +U' { u(x,0)=3sin2'1TX-7sin4'1TX, &Uuml;&lt;x&lt;lO 
at ax2 ' u(O,t)=u(lO,t)=O 
</p>
<p>Use the method of separation of variables to solve each of the following 
boundary-value problems. 
</p>
<p>4 au = au. u(O,y)=eY+e-2y 
&bull; at ay' 
</p>
<p>au- au. 5. at- ay' u(t,O)=e-3'+e2t 
</p>
<p>6. ~~ = ~~ +u; u(O,y)=2e-Y-e2Y 
</p>
<p>au au 7. at = ay -u; u(t,O)=e-s'+2e-7'-14et3t 
</p>
<p>486 </p>
<p/>
</div>
<div class="page"><p/>
<p>5.4 Fourier series 
</p>
<p>8. Determine whether the method of separation of variables can be used to re-
place each of the following partial differential equations by pairs of ordinary 
differential equations. If so, find the equations. 
(a) tu11 +ux=O (b) tuxx+xu1 =0 
(c) Uxx+(x-y)Uyy=O (d) Uxx+2ux1 +u1 =0 
</p>
<p>9. The heat equation in two space dimensions is 
</p>
<p>ul=o:2(uxx+Uyy). (*) 
</p>
<p>(a) Assuming that u(x,y,t)=X(x)Y(y)T(t), find ordinary differential equa-
tions satisfied by X, Y, and T. 
</p>
<p>(b) Find solutions u(x,y, t) of (*) which satisfy the boundary conditions 
u(O,y,t)=O, u(a,y,t)=O, u(x,O,t)=O, and u(x,b,t)=O. 
</p>
<p>10. The heat equation in two space dimensions may be expressed in terms of polar 
Coordinates as 
</p>
<p>Assuming that u(r,O,t)= R(r)0(0)T(t), find ordinary differential equations 
satisfied by R, e, and T. 
</p>
<p>5.4 Fourier series 
</p>
<p>On December 21, 1807, an engineer named Joseph Fourier announced to 
the prestigious French Academy of Seiences that an arbitrary functionf(x) 
could be expanded in an infinite series of sines and cosines. Specifically, Iet 
f(x) be defined on the interval -I,;;;;; x,;;;;; I, and compute the numbers 
</p>
<p>I fl ( ) n'TrX an= I f X cos -,- dx, n = 0, I' 2, ... 
-I 
</p>
<p>(I) 
</p>
<p>and 
</p>
<p>I Jt ( ) . n1rx bn = 1 f x sm - 1- dx, 
-I 
</p>
<p>n= 1,2, ... (2) 
</p>
<p>Then, the infinite series 
00 
</p>
<p>ao 7TX . 7TX ao "" [ n1rx . mrx ] 2 +a1 cos-1- + b1sm-1- + ... = 2 + ~ ancos-1- +bnsm-1-
n=l 
</p>
<p>(3) 
</p>
<p>converges to f(x). Fourier's announeerneut caused a loud furor in the 
Academy. Many of its prominent members, including the famous mathe-
matician Lagrange, thought this result to be pure nonsense, since at that 
time it could not be placed on a rigorous foundation. However, mathema-
ticians have now developed the theory of "Fourier series" to such an extent 
that whole volumes have been written on it. (Just recently, in fact, they 
have succeeded in establishing exceedingly sharp conditions for the Four-
ier series (3) to converge. This result ranks as one of the great mathemati-
</p>
<p>487 </p>
<p/>
</div>
<div class="page"><p/>
<p>5 Separation of variables and Fourier series 
</p>
<p>ca1 theorems of the twentieth century.) The following theorem, whi1e not 
the most genera1 theorem possible, covers most of the situations that arise 
in applications. 
</p>
<p>Theorem 2. Let f and j' be piecewise continuous on the interval - I..;; x ..;; I. 
( This means that fand f' have only a finite number of discontinuities on 
this interval, and both f and j' have right- and left-hand Iimits at each 
point of discontinuity.) Compute the numbers an and bn from (I) and (2) 
and form the infinite series (3). This series, which is called the Fourier 
series for f on the interval -I..;; x..;; I, converges to f(x) if f is continuous 
at x, and to Hf(x+O)+ f(x-0)]* if f is discontinuous at x. At x= &plusmn;I, 
the Fourier series (3) converges to Hf(!)+ f( -I)], where f( &plusmn;I) is the 
Iimit of f(x) as x approaches &plusmn;I. 
</p>
<p>Remark. The quantity Hf(x + 0) + f(x- 0)] is the average of the right-
and left-hand Iimits of f at the point x. If we define f(x) to be the average 
of the right- and 1eft-hand Iimits of f at any point of discontinuity x, then 
the Fourier series (3) converges to f(x) for all points x in the interva1 -I&lt; 
x&lt; I. 
</p>
<p>Examp1e 1. Let f be the, function which is 0 for - 1 ..;; x &lt; 0 and 1 for 0 &lt; x 
..;; 1. Compute the Fourier series for f on the interva1 - 1 ..;; x..;; 1. 
Solution. In this prob1em, I= 1. Hence, from ( 1) and (2), 
</p>
<p>a0 = J 1 f ( x) dx = ( 1 dx = 1, 
-1 Jo 
</p>
<p>an=f 1 f(x)cosmrxdx= ( 1cosmrxdx=O, n~ 1 
-1 Jo 
</p>
<p>and 
</p>
<p>bn=f 1 f(x)sinmrxdx= ( 1sinmrxdx 
-1 Jo 
1 1-(-1( 
</p>
<p>= - ( 1 - cos mr) = n ~ 1. 
nw nw 
</p>
<p>Notice that bn=O for n even, and bn=2/nw for n odd. Hence, the Fourier 
series for f on the interva1 - 1 ..;; x..;; 1 is 
</p>
<p>.!. + 2sinwx + 2sin3wx + 2sin5wx + 
2 w 3w 5w &middot;&middot;&middot; &middot; 
</p>
<p>By Theorem 2, this series converges to 0 if - 1 &lt; x &lt; 0, and to 1 if 0 &lt; x &lt; I. 
At x = - I, 0, and + 1, this series reduces to the single nurober ~, which is 
the value predicted for it by Theorem 2. 
</p>
<p>*The quantity f(x+O) denotes the Iimit from the right of f at the point x. Similarly, f(x -0) 
denotes the Iimit of f from the Jeft. 
</p>
<p>488 </p>
<p/>
</div>
<div class="page"><p/>
<p>5.4 Fourier series 
</p>
<p>Example 2. Let f be the function which is I for -2 &lt; x &lt; 0 and x for 0 &lt; x 
&lt; 2. Compute the Fourier series for f on the interval -2 &lt; x &lt; 2. 
Solution. In this problem /=2. Hence from (I) and (2), 
</p>
<p>I (2 I (o I (2 
a0 = 2 L/(x)dx= 2 L/x+ 2 Jo xdx=2 
</p>
<p>I J2 ( ) mrx I jo mrx I 12 mrx a =- f x cos- dx=- cos- dx+- xcos- dx 
n 2 _ 2 2 2 _ 2 2 2 0 2 
</p>
<p>2 
= --2 (cosmr-1), n ~I 
</p>
<p>(mr) 
</p>
<p>and 
</p>
<p>I 12 ( ) . mrx I Jo . mrx I 12 . mrx b =- f x sm-dx=- sm-dx+- xsm-dx 
n 2 _ 2 2 2 _ 2 2 2 O 2 
</p>
<p>I 
=- m/1 +cosmr), n ~I. 
</p>
<p>Notice that an=O if n is even; an= -4/n2 TT 2 if n is odd; bn=O if n is odd; 
and bn =-2/ nTT if n is even. Hence, the Fourier series for f on the interval 
-2&lt;x&lt;2 is 
</p>
<p>4 7TX I . 4 37TX I . 1- -cos-- -smTTx- -cos--- -sm2TTx+ ... 
7T2 2 7T 9772 2 27T 
</p>
<p>= 1 _ _i_ i cos(2n+ I)TTx/2 _l_ i sinnTTx. (4) 
772 n=O (2n + 02 77 n= I n 
</p>
<p>By Theorem 2, this series converges to I if -2 &lt; x &lt; 0; to x, if 0 &lt; x &lt; 2; to 
t if x=O; and to ~ if x&plusmn;2. Now, at x=O, the Fourier series (4) is 
</p>
<p>1- _i_ [ _!_ + _!_ + _!_ + _!_ + ... ]&middot; 
7T2 12 32 52 72 
</p>
<p>Thus, we deduce the remarkable identity 
</p>
<p>or 
</p>
<p>The Fourier coefficients an and bn defined by (I) and (2) can be derived 
in a simple manner. Indeed, if a piecewise continuous functionj can be ex-
panded in a series of sines and cosines on the interval - I&lt; x &lt; /, then, of 
necessity, this series must be the Fourier series (3). We prove this in the 
</p>
<p>489 </p>
<p/>
</div>
<div class="page"><p/>
<p>5 Separation of variables and Fourier series 
</p>
<p>following manner. Suppose that f is piecewise continuous, and that 
CO 
</p>
<p>Co "" [ k'TTX . k'TTX ] f(x)= 2 + ~ ckcos-1- +dksm-1-
k=I 
</p>
<p>(5) 
</p>
<p>for some numbers ck and dk. Equation (5) is assumed to hold at all but a 
finite number of points in the interval -/ ~ x ~I. Integrating both sides of 
</p>
<p>(5) between -I and I gives c0 /= J_', j(x)dx, since 
</p>
<p>cos-- dx= sm-- dx=O&middot; I l k'TTX il &middot; k'TTX 
-t I -t I ' 
</p>
<p>k= 1,2, ... * 
</p>
<p>Similarly, multiplying both sides of (5) by cos n'TTX /I and integrating be-
tween - I and I gives 
</p>
<p>11 n'TTX lcn= f(x)cos-1-dx 
-I 
</p>
<p>while multiplying both sides of (5) by sinn'TTx/ I and integrating between 
-I and I gives 
</p>
<p>11 n'TTX ldn= f(x)sin-1- dx. 
-I 
</p>
<p>This follows immediately from the relations (see Exercise 19) 
</p>
<p>and 
</p>
<p>I' cos n'TTx cos k'TTx dx = { 0, 
_ 1 I I /, 
</p>
<p>I' cos n'TTx sin k'TTx dx = 0 _ 1 I I 
</p>
<p>I / . n'TTX &middot; k'TTX d { 0 sm--sm-- x= ' 
-I I I /, 
</p>
<p>k=l=n 
k=n 
</p>
<p>k=l=n 
k=n&middot; 
</p>
<p>(6) 
</p>
<p>(7) 
</p>
<p>(8) 
</p>
<p>Hence, the coefficients cn and dn must equal the Fourier coefficients an and 
bn. In particular, therefore, a function f can be expanded in one, and only 
one, Fourier series on the interval -/ ~ x ~ /. 
</p>
<p>Examp1e 3. Find the Fourier series for the functionj(x) =cos2 x on the in-
terval - 'TT ~ x ~ 'TT. 
Solution. By the preceding remark, the functionf(x)=cos2x has a unique 
Fourier series 
</p>
<p>*It can be shown that it is permissible to integrate the series (5) term by term. 
</p>
<p>490 </p>
<p/>
</div>
<div class="page"><p/>
<p>5.4 Fourier series 
</p>
<p>on the interval -7r.;;;; x.;;;; 1r. But we already know that 
</p>
<p>2 1 + cos2x cos x= 2 - 2-. 
</p>
<p>Hence, the Fourier series for cos2 x on the interval - 1r.;;;; x .;;;; 1r must be 
I I 2 
2 + 2cos x. 
</p>
<p>The functions cosnTTxjl and sinnTTxjl, n=1,2, ... all have the interest-
ing property that they are periodic with period 2/; that is, they repeat 
themselves over every interval of length 2/. This follows trivially from the 
identities 
</p>
<p>n1r { n1rx ) n1rx cos -1- ( x + 2/) = cos - 1- + 2n1T = cos - 1-
</p>
<p>and 
</p>
<p>. n1r( 21 ) . (n1rx 2 ) . n1rx sm-1- x+ =sm - 1- + n1r =sm-1-. 
</p>
<p>Hence, the Fourier series (3) converges for all x to a periodic function 
F(x). This function is called the periodic extension of f(x). It is defined by 
the equations 
</p>
<p>{
F(x)=J(x), -l&lt;x&lt;l 
</p>
<p>F(x)=HJU)+j(-1)], x=&plusmn;l 
</p>
<p>F(x+2/)=F(x). 
</p>
<p>F or examp1e, the periodic extension of the function f ( x) = x is described in 
Figure 1, and the periodic extension of the function f(x) = lxl is the saw-
toothed function described in Figure 2. 
</p>
<p>Figure l. Periodic extension of f(x)=x 
</p>
<p>-4 ~ -3t -2~ -t 
</p>
<p>Figure 2. Periodic extension of f(x)= lxl 
</p>
<p>491 </p>
<p/>
</div>
<div class="page"><p/>
<p>5 Separation of variables and Fourier series 
</p>
<p>EXERCISES 
</p>
<p>In each of Problems 1-13, find the Fourier series for the given function f 
on the prescribed interval. 
</p>
<p>l.j(x)={ -11,, -l&lt;x&lt;O. lxi..::I 
O.;;;; X.;;;; 1' ""' 
</p>
<p>2. f(x)= { ~: -2&lt;x&lt;0. lxl&lt;2 O.;;;;x.;;;;2' 
</p>
<p>3. f(x)=x; -},;;;;X,;;;; J 4.j(x)={ -x, -l&lt;x&lt;O. 
X, 0.;;;; x.;;;; 1' 
</p>
<p>c&middot; -2&lt;x&lt;0 S. f(x)= 0, 0.;;;; x&lt; 1; lxl&lt;2 1, l&lt;x&lt;2 
6. f(x)= { ~: -2&lt;x&lt;l. lxl&lt;2 I&lt; X.;;;; 2' 
</p>
<p>7. f(x)= { ~&middot; -l&lt;x&lt;O. lxl&lt; I 
e ' 0,;;;; X,;;;; I' 
</p>
<p>8. f(x)= { eo~' -l&lt;x&lt;O. lxl&lt; I O.;;;; X.;;;; I ' 
</p>
<p>9. f(x)= { e:X, -l&lt;x&lt;O. -I.;;; x.;;;; I 
e ' O.;;;; X.;;;; I' 
</p>
<p>10. j(X)=e\ lxl&lt; I 11. f(x)=e-x; lxl&lt; I 
</p>
<p>12. f(x)=sin2 x; lxi&lt;'TT 13. f(x) = sin3 x; lxi&lt;'TT 
</p>
<p>14. Letf(x)=('TTcosax)j2asina'TT, a not an integer. 
(a) Find the Fourier series for f on the interval - 'lT.;;;; x.;;;; 'TT. 
(b) Show that this series converges at x='TT to the value ('TT/2a)cot'!Ta. 
(c) Use this result to sum the series 
</p>
<p>1 1 1 
-2--2 + -2--2 + -2--2 + .... 
1 -a 2 -a 3 -a 
</p>
<p>lxl&lt; 1 
</p>
<p>15. Suppose thatf andf' are piecewise continuous on the interval -I.;;; x.;;;; I. Show 
that the Fourier coefficients an and bn approach zero as n approaches infinity. 
</p>
<p>16. Let 
</p>
<p>492 
</p>
<p>Show that 
</p>
<p>This relation is known as Parseval's identity. Hint: Square the Fourier series 
for fand integrate term by term. </p>
<p/>
</div>
<div class="page"><p/>
<p>5.5 Even and odd functions 
</p>
<p>17. (a) Find the Fourier series for the functionf(x)= x 2 on the interval - 'IT.;;;; x.;;;; 
'ITo 
</p>
<p>(b) Use Parseval's identity to show that 
</p>
<p>1 1 1 '17'4 
? + 24 + 34 + 0 0 0 = 90 0 
</p>
<p>18. If the Dirac delta function I) (x) had a Fourier series on the interval - i.;;;; x.;;;; I, 
what would it be? 
</p>
<p>19. Derive Equations (6)-(8)0 Hint: Use the trigonometric identities 
</p>
<p>sinA cosB= Hsin(A + B) +sin(A- B )] 
</p>
<p>sinA sinB = Hcos(A- B) -cos(A + B )] 
</p>
<p>cosAcosB = Hcos(A + B) +cos(A- B )]o 
</p>
<p>5.5 Even and odd functions 
</p>
<p>There are certain special cases when the Fourier series of a function f re-
duces to a pure cosine or a pure sine serieso These special cases occur when 
f is even or oddo 
</p>
<p>Definition. A functionjis said tobe even ifj(-x)=j(x)o 
</p>
<p>Example 1. The function f(x) = x 2 is even since 
</p>
<p>f(- x) = (- x)2 = x 2= f(x)o 
</p>
<p>Example 2. The functionf(x)=cosn'ITx/1 is even since 
-n'ITX n'ITX 
</p>
<p>f( -x)=cos-1- =cos-1- = f(x)o 
</p>
<p>Definition. A function f is said to be odd if f (- x) = - f ( x )o 
</p>
<p>Example 3. The function f ( x) = x is odd since 
J(-x)= -x= -J(x)o 
</p>
<p>Example 4. The functionf(x)=sinn'ITx/1 is odd since 
</p>
<p>f( ) 0 - n'ITX 0 n'ITx f( ) -x =stn-1- = -stn-1- =- x 0 
</p>
<p>Even and odd functions satisfy the following elementary properties. 
</p>
<p>1. The product of two even functions is eveno 
20 The product of two odd functions is eveno 
30 The product of an odd function with an even function is oddo 
</p>
<p>The proofs of these assertions are trivial and follow immediately from the 
definitionso For example, letj and g be odd and Iet h(x)= f(x)g(x)o This 
</p>
<p>493 </p>
<p/>
</div>
<div class="page"><p/>
<p>5 Separation of variables and Fourier series 
</p>
<p>function h is even since 
</p>
<p>h(-x)=f(-x)g(-x)=[ -f(x)][ -g(x)]=f(x)g(x)=h(x). 
</p>
<p>In addition to the multiplicative properties l-3, even and odd functions 
satisfy the following integral properties. 
</p>
<p>4. The integral of an odd function f over a symmetric interval [-I, I] is 
</p>
<p>zero; that is, (' f(x)dx = 0 if f is odd. 
J-1 
</p>
<p>5. The integral of an even function f over the interval [-I, I] is twice the 
integral of f over the interval [0, I]; that is, 
</p>
<p>r' f(x)dx=2 r'f(x)dx 
)_, Jo 
</p>
<p>if f is even. 
</p>
<p>PROOF OF PROPERTY 4. If f is odd, then the area under the curve of f be-
tween - I and 0 is the negative of the area under the curve of f between 0 
</p>
<p>andi.Hence, (' f(x)dx=Oiffisodd. 0 Lt 
PROOF OF PROPERTY 5. If f is even, then the area under the curve of f be-
tween - I and 0 equals the area under the curve of f between 0 and /. 
Hence, 
</p>
<p>r' f(x)dx= ro f(x)dx+ r'f(x)dx=2 r'f(x)dx )_, L, Jo Jo 
if fis even. 0 
</p>
<p>Concerning even and odd functions, we have the following important 
Iemma. 
</p>
<p>Lemma 1. 
</p>
<p>(a) The Fourier series for an even function is a pure cosine series; that 
is, it contains no terms of the form sinmrx I I. 
</p>
<p>(b) The Fourier series for an odd function isapure sine series; that is, 
it contains no terms of the form cosmrxl I. 
</p>
<p>PROOF. (a) If f is even, then the function f(x)sinmrxl I is odd. Thus, by 
Property 4, the coefficients 
</p>
<p>I j_' ) . mrx bn = 7 f(x sm-1-dx, 
-I 
</p>
<p>n=l,2,3, ... 
</p>
<p>in the Fourier series for f are all zero. 
(b) If f is odd, then the function f ( x) cos mrx I I is also odd. Conse-
</p>
<p>quently, by Property 4, the coefficients 
</p>
<p>I j 1 ( ) mrx an= 7 f x cos-1-dx, 
-I 
</p>
<p>n=O, 1,2, ... 
</p>
<p>in the Fourier series for f are all zero. 0 
494 </p>
<p/>
</div>
<div class="page"><p/>
<p>5.5 Even and odd functions 
</p>
<p>We are now in a position to prove the following extremely important ex-
tension of Theorem 2. This theorem will enable us to solve the heat con-
duction problern of Section 5.3 and many other boundary-value problems 
that arise in applications. 
</p>
<p>Theorem 3. Let f and f' be piecewise continuous on the interval 0.;;; x .;;; I. 
Then, on this interval, f(x) can be expanded in eilher a pure cosine series 
</p>
<p>or a pure sine series 
</p>
<p>00 
</p>
<p>ao " mrx T + L..J an cos-1-, 
n=! 
</p>
<p>00 
</p>
<p>"b . mrx L..J n sm-,-. 
n=! 
</p>
<p>In the former case, the coefficients an are given by the formula 
</p>
<p>2 ( ) n77x 
an= 1 Jo f(x cos-1-dx, n=O, 1,2, ... 
</p>
<p>while in the latter case, the coefficients bn are given by the formula 
</p>
<p>2 ( ( ) . n'lTX 
bn =I Jo f x sm-1-dx. 
</p>
<p>PROOF. Consider first the function 
</p>
<p>F(x)= ( f(x), 
j(-x), 
</p>
<p>o.;;; x.,:;; 1 
-!.;;;x&lt;O 
</p>
<p>(1) 
</p>
<p>(2) 
</p>
<p>The graph of F(x) is described in Figure 1, and it is easily seen that Fis 
even. (For this reason, F is called the even extension of f.) Hence, by 
</p>
<p>------l~--------4---------~------x 
</p>
<p>Figure 1. Graph of F(x) 
</p>
<p>495 </p>
<p/>
</div>
<div class="page"><p/>
<p>5 Separation of variables and Fourier series 
</p>
<p>Lemma 1, the Fourier series for Fon the interval -I&lt;; x &lt;;I is 
</p>
<p>ao ~ mrx 
F(x)= 2 + ~ ancos-1-; 
</p>
<p>n=I 
</p>
<p>1 rl mrx 
an= I)_ F(x)cos-1-dx. 
</p>
<p>-I 
</p>
<p>(3) 
</p>
<p>Now, observe that the function F(x)cosmrx/ I is even. Thus, by Property 5 
</p>
<p>2 t ( ) mrx 2 ( 1 ( ) n'TTX dx an=IJ
0
</p>
<p>F x cos-1-dx=IJ0 j x cos-1- . 
</p>
<p>Finally, since F(x)= j(x), 0&lt;; x &lt;;I, we conclude from (3) that 
00 
</p>
<p>( ) ao ""' n'TTx f x = 2 + ~ ancos-1-, 
n=I 
</p>
<p>0&lt;; X"' I. 
</p>
<p>Observe too, that the series (3) converges toj(x) for x=O and x=l. 
To show that j(x) can also be expanded in a pure sine series, we con-
</p>
<p>sider the function 
</p>
<p>{ 
j(x), 
</p>
<p>G(x)= -J(-x), 
</p>
<p>0, 
</p>
<p>O&lt;x&lt;l 
</p>
<p>-l&lt;x&lt;O 
</p>
<p>x=O, &plusmn;I. 
</p>
<p>--~----------+---------~--.x -.r 
</p>
<p>Figure 2. Graph of G(x) 
</p>
<p>The graph of G(x) is described in Figure 2, and it is easily seen that G is 
odd. (For this reason, G is called the odd extension of j.) Hence, by 
Lemma 1, the Fourier series for Gon the interval -/ &lt;; x &lt;I is 
</p>
<p>00 
</p>
<p>G(x)= ~ bnsin n~x; 
n=I 
</p>
<p>1 11 . Tl'TTX bn= I G(x)sm-1-dx. 
-I 
</p>
<p>{4) 
</p>
<p>496 </p>
<p/>
</div>
<div class="page"><p/>
<p>5.5 Even and odd functions 
</p>
<p>Now, observe that the function G (x) sinmrx /I is even. Thus, by Property 
5, 
</p>
<p>2 r' 0 mrx 2 i' 0 mrx bn= 1 J. G(x)sm-1- dx= I f(x)sm - 1- dx. 
0 0 
</p>
<p>Finally, since G(x)=j(x),O&lt;x&lt;l, we conclude from (4) that 
</p>
<p>CXl 
</p>
<p>f(x)= ~ bnsin n~x, 
n=l 
</p>
<p>O&lt;x&lt;l. 
</p>
<p>Observe too, that the series ( 4) is zero for x = 0 and x = I. D 
</p>
<p>Example 5. Expand the functionj(x)= 1 in a pure sine series on the inter-
val O&lt;x&lt;'IT. 
</p>
<p>Solution. By Theorem 3,j(x)= L:...,bnsinnx, where 
</p>
<p>2 ., 2 { 0 , n even 
b = -l sinnxdx= -(1-cosmr)= 4 n odd. 
n 'IT 0 n'IT -' 
</p>
<p>n'IT 
</p>
<p>Hence, 
</p>
<p>I =i[ sinx + sin3x + sin5x + ] 
'IT I 3 5 ... ' 
</p>
<p>Example 6. Expand the functionj(x)= ex in a pure cosine series on the in-
terval 0 ..;; x ..;; 1. 
Solution. By Theorem 3,j(x)=a0 j2+ L:_ 1ancosn'ITX, where 
</p>
<p>and 
</p>
<p>=2Re eO+inw)xdx=2Re . -l l { el+in" 1 } 
o 1+m'IT 
</p>
<p>Hence, 
</p>
<p>~ (ecosn'IT-1) 
ex=e-1+2.tC..J 2 2 COSn'ITX, 
</p>
<p>n=l 1+n 'IT 
o..;;xo;;;t. 
</p>
<p>497 </p>
<p/>
</div>
<div class="page"><p/>
<p>5 Separation of variables and Fourier series 
</p>
<p>EXERCISES 
</p>
<p>Expand each of the following functions in a Fourier cosine series on the 
prescribed interval. 
</p>
<p>3. f(x)= { x, 
a, 
</p>
<p>4. f(x)=cos 2 x; 
</p>
<p>O&lt;x&lt;a. 
a&lt; x&lt;2a' 
</p>
<p>5. f(x)= { /-~: &Uuml;&lt;O; X &lt;0; f/2. f/2 &lt;0; X &lt;0; f' 
</p>
<p>2. f(x)= { ~: 
</p>
<p>Expand each of the following functions in a Fourier sine series on the pre-
scribed interval. 
</p>
<p>6. f(x)= e-x; 
</p>
<p>8. f(x)= { x, 
a, 
</p>
<p>O&lt;x&lt;a . 
a&lt; x&lt;2a' 
</p>
<p>7. f(x)= { ~: 
</p>
<p>0&lt;x&lt;2a 
</p>
<p>9. f(x)=2sinxcosx; O&lt;x&lt;'IT 
</p>
<p>10.j(x)={ x, O&lt;x&lt;l/2; O&lt;x&lt;l 
1-x, l/2&lt;x&lt;l 
</p>
<p>O&lt;x&lt;l. 
1 &lt;x&lt;2' 
</p>
<p>11. (a) Expand the function j(x) = sinx in a Fourier cosine series on the interval 
O&lt;x&lt;'IT. 
</p>
<p>(b) Expand the functionj(x}=cosx in a Fourier sine series on the interval 0&lt; 
X&lt;'IT. 
</p>
<p>(c) Can you expand the functionj(x}=sinx in a Fourier cosine series on the 
interval - 'IT &lt; x &lt; ?T? Explain. 
</p>
<p>5.6 Return to the heat equation 
</p>
<p>We return now to the boundary-value problern 
</p>
<p>( 
u(x,O)=J(x) 
</p>
<p>u(O,t) = u(l, t) =0 &middot; 
</p>
<p>We showed in Section 5.3 that the function 
</p>
<p>is (forrnally) a solution of the boundary-value problern 
</p>
<p>(1) 
</p>
<p>au =a2a 2u. (0) (/) 0 (2) at ax2 ' u ,t = u ,t = 
</p>
<p>for any choice of constants c1,c2, .... This led us to ask whether we can 
</p>
<p>498 </p>
<p/>
</div>
<div class="page"><p/>
<p>5.6 Return to the heat equation 
</p>
<p>find constants c1,c2, &bull;&bull;&bull; suchthat 
</p>
<p>00 
</p>
<p>u(x,O)= ~ cnsin n~x =J(x), 
n=l 
</p>
<p>O&lt;x&lt;l. (3) 
</p>
<p>As we showed in Section 5.5, the answer to this question is yes; if we 
choose 
</p>
<p>2 ( 1 ( ) . mrx 
cn = 7 )" f x sm-1-dx, 
</p>
<p>0 
</p>
<p>then the Fourier series L:=lcnsinmrx/1 converges toj(x) ifjis continu-
ous at the point x. Thus, 
</p>
<p>( t) 2 Loo [LIJ() &middot; n'TTXd] &middot; n'TTX -a'n''TT't/1' u x = - x s1n-- x sm -e 
' I I I n=l 0 
</p>
<p>(4) 
</p>
<p>is the desired solution of (1). 
</p>
<p>Remark. Strictly speaking, the solution (4) cannot be regarded as the solu-
tion of (1) until we rigorously justify all the limiting processes involved. 
Specifically, we must verify that the function u(x, t) defined by (4) actually 
has partial derivatives with respect to x and t, and that u(x, t) satisfies the 
heat equation u1 = a2uxx&middot; (lt is not true, necessarily, that an infinite sum of 
solutions of a linear differential equation is again a solution. Indeed, an 
infinite sum of solutions of a given differential equation need not even be 
differentiable.) However, in the case of (4) it is possible to show (see Ex-
ercise 3) that u(x, t) has partial derivatives with respect to x and t of all 
orders, and that u(x, t) satisfies the boundary-value problern (1). The argu-
ment rests heavily upon the fact that the infinite series (4) converges very 
rapidly, due to the presence of the factor e-a'n''TT't!t'. Indeed, the function 
u(x, t), for fixed t &gt; 0, is even analytic for 0 &lt; x &lt;I. Thus, heat conduction 
is a diffusive process which instantly smooths out any discontinuities that 
may be present in the initial temperature distribution in the rod. Finally, 
we observe that limt-&gt; 00 u(x, t) = 0, for all x, regardless of the initial temper-
ature in the rod. This is in accord with our physical intuition that the heat 
distribution in the rod should ultimately approach a "steady state"; that is, 
a state in which the temperature does not change with time. 
</p>
<p>Example 1. A thin alurninum bar (a 2 =0.86 cm2 js) 10 cm long is heated to 
a uniform temperature of 100&deg;C. At time t = 0, the ends of the bar are 
plunged into an ice bath at 0&deg;C, and thereafter they are maintained at this 
temperature. No heat is allowed to escape through the lateral surface of the 
bar. Find an expression for the temperature at any point in the bar at any 
later time t. 
</p>
<p>499 </p>
<p/>
</div>
<div class="page"><p/>
<p>5 Separation of variables and Fourier series 
</p>
<p>Solution. Let u(x, t) denote the temperature in the bar at the point x at 
time t. This function satisfies the boundary-value problern 
</p>
<p>au =0.86 a2u. 
at ax2 , (
</p>
<p>u(x,O)=IOO, 0&lt;x&lt;10 
</p>
<p>u(O, t) = u(IO, t) = 0 
</p>
<p>The solution of (5) is 
00 
</p>
<p>u(x t)= ""c sinmrxe-0.86n2.".2r;too 
' ~n 10 
</p>
<p>n-1 
</p>
<p>where 
</p>
<p>I l 10 mrx 200 c =- IOOsin-dx= -(1-cosmr). 
n 5 0 10 mr 
</p>
<p>N otice that cn = 0 if n is even, and cn = 400/ mr if n is odd. Hence, 
</p>
<p>oo sin(2n + I) '!TX 
( t) = 400 ~ 10 -0.86(2n+ 1)2".2t/100 
</p>
<p>u x, 'lT ~ (2n + I) e . 
</p>
<p>(5) 
</p>
<p>There are several other problems of heat conduction which can be 
solved by the method of separation of variables. Example 2 below treats 
the case where the ends of the bar are also insulated, and Exercise 4 treats 
the case where the ends of the bar are kept at constant, but nonzero tem-
peratures T1 and T2&bull; 
</p>
<p>Example 2. Consider a thin metal rod of length l and thermal diffusivity 
a 2, whose sides and ends are insulated so that there is no passage of heat 
through them. Let the initial temperature distribution in the rod be f(x). 
Find the temperature distribution in the rod at any later time t. 
Solution. Let u(x, t) denote the temperature in the rod at the point x at 
time t. This function satisfies the boundary-value problern 
</p>
<p>{ u(x,O):j(x), _ O&lt;x&lt;l 
</p>
<p>ux(O, t)- ux(l, t)- 0 
(6) 
</p>
<p>We solve this problern in two steps. First, we will find infinitely many solu-
tions un(x,t)=Xn(x)Tn(t) of the boundary-value problern 
</p>
<p>u,=a2uxx; ux(O,t)=ux(l,t)=O, (7) 
</p>
<p>and then we will find constants c0, c 1, c2, &bull;&bull;&bull; such that 
00 
</p>
<p>u(x,t)= L cnun(x,t) 
n=O 
</p>
<p>satisfies the initial condition u(x, 0) = j(x). 
</p>
<p>500 </p>
<p/>
</div>
<div class="page"><p/>
<p>5.6 Return to the heat equation 
</p>
<p>Step 1: Let u(x,t)=X(x)T(t). Computing 
</p>
<p>au -XT' d a2u -X"T -- an --
at ax2 
</p>
<p>we see that u(x, t) is a solution of u1 = a2 uxx if 
X" T' 
</p>
<p>XT'=a 2X"T, or -X =-2-. 
aT 
</p>
<p>(8) 
</p>
<p>As we showed in Section 5.3, Equation (8) implies that 
</p>
<p>X"+l\X=O and T'+l\a 2T=O 
for some constant A. In addition, the boundary conditions 
</p>
<p>0= ux(O,t) = X'(O)T(t) and 0= ux(l,t) =X'(l)T(t) 
</p>
<p>imply that X'(O)=O and X'(l)=O. Hence u(x,t)=X(x)T(t) is a solution 
of (7) if 
</p>
<p>X"+l\X=O; 
and 
</p>
<p>X'(O)=O, X'(/)=0 (9) 
</p>
<p>(10) 
</p>
<p>At this point, the constant A is arbitrary. However, the boundary-value 
problern (9) has a nontrivial solution X(x) (see Exercise I, Section 5.1) 
only if A = n21r2 //2, n = 0, 1, 2, ... , and in this case 
</p>
<p>X(x)=Xn(x)=cosn~x. 
</p>
<p>Equation (10), in turn, implies that T(t)=e~a 2 n 2 '1T 21 1 12 &bull; Hence, 
</p>
<p>n1rx 2 2 2 112 U (X t)=COS- e-a n '1T I 
n ' I 
</p>
<p>is a solution of (7) for every nonnegative integer n. 
Step 2: Observe that the linear combination 
</p>
<p>Co 00 n1rx 2 2 2 2 
u(x t)=- + "'"'c cos-e-a n '1T t/l 
'2 "'-on I 
</p>
<p>n=l 
</p>
<p>is a solution (formally) of (7) for every choice of constants c0, c" c2, &bull;&bull;.. lts 
ini tial value is 
</p>
<p>Co ~ n1rx 
u(x,O)=T+ "'-- cncos-1-. 
</p>
<p>n=l 
</p>
<p>Thus, in order to satisfy the initial condition u(x,O)= f(x) we must choose 
constants c0, c" c2, &bull;&bull;&bull; such that 
</p>
<p>Co ~ n'lTx 
f(x) = T + "'-- cncos-1-, 0 &lt; x &lt;I. 
</p>
<p>n=l 
</p>
<p>In other words, we must expand f in a Fourier cosine series on the interval 
</p>
<p>501 </p>
<p/>
</div>
<div class="page"><p/>
<p>5 Separation of variables and Fourier series 
</p>
<p>0" x" I. This is precisely the situation in Theorem 3 of Section 5.5, and 
we conclude, therefore, that 
</p>
<p>2 ( 1 ( ) mrx cn= 7 Jo f x cos-1-dx. 
Hence, 
</p>
<p>1 ( 1 2 ~ [l' n'TTX ] n'ITX _ 2 2 2 2 u(x,t)= y Jn f(x)dx+ y ~ f(x)cos-1-dx cos-1-e an w t/l (11) 
0 n=l 0 
</p>
<p>is the desired solution of (6). 
</p>
<p>Remark. Observe from (11) that the temperaturein the rod ultimately ap-
proaches the steady state temperature 
</p>
<p>I r' 7 Jo f(x)dx. 
This steady state temperature can be interpreted as the "average" of the 
initial temperature distribution in the rod. 
</p>
<p>EXERCISES 
</p>
<p>1. The ends x = 0 and x = 10 of a thin aluminum bar ( a 2 = 0.86) are kept at 0&deg; C, 
while the surface of the bar is insulated. Find an expression for the temperature 
u(x, t) in the bar if initially 
(a) u(x,0)=70, 0 &lt; x &lt; 10 
(b) u(x,0)=70cosx, O&lt;x&lt; 10 
</p>
<p>{ !Ox, 0&lt;x&lt;5 (c) u(x,O)= 10(10-x), 5.;;;; x&lt; 10 
</p>
<p>(d) u(x,O)= { 0, 0&lt;x&lt;3 
65, 3.;;;x&lt;l0 
</p>
<p>2. The ends and sides of a thin copper bar ( a 2 = 1.14) of length 2 are insulated so 
that no heat can pass through them. Find the temperature u(x, t) in the bar if 
initially 
(a) u(x,0)=65cos2 '1Tx, O.;;;x.;;;2 
(b) u(x,0)=70sinx, O.;;; x.;;;; 2 
</p>
<p>{ 60x 0.;;; x&lt; 1 (c) u(x,O)= 60(2- x), I.;;; x &lt; 2 
</p>
<p>(d) u(x,O)={ 0, O.;;;x&lt;l 
75, 1.,;; X.,;;; 2 
</p>
<p>3. Verify that the function u(x,t) defined by {4) satisfies the heat equation. Hint: 
Use the Cauchy ratio test to show that the infinite series (4) can be differenti-
ated term by term with respect to x and t. 
</p>
<p>4. A steady state solution u(x, t) of the heat equation u, = a2 uxx is a solution u(x, t) 
which does not change with time. 
(a) Show that all steady state solutions of the heat equation are linear functions 
</p>
<p>of x; i.e., u(x)=Ax+B. 
</p>
<p>502 </p>
<p/>
</div>
<div class="page"><p/>
<p>5.7 The wave equation 
</p>
<p>(b) Find a steady state solution of the boundary-value problern 
</p>
<p>u(O,t)= T1, u(l,t)= T2&bull; 
</p>
<p>(c) Solve the heat conduction problern 
</p>
<p>{ 
u(x,0)_:=15, 
</p>
<p>u(O,t)-20, 
</p>
<p>0&lt;x&lt;1 
</p>
<p>u(1,t)=60 
</p>
<p>Hint: Let u(x,t)=v(x)+w(x,t) where v(x) is the steady state solution of 
the boundary-value problern u1 =a2 uxx; u(O,t)=20, u(1,t)=60. 
</p>
<p>5. (a) The ends of a copper rod (a 2 = l.l4) 10 cm long are maintained at 0&deg;C, 
while the center of the rod is maintained at l00&deg;C by an extemal heat source. 
Show that the temperature in the rod will ultimately approach a steady state dis-
tribution regardless of the initial temperature in the rod. Hint: Split this problern 
into two boundary-value problems. 
(b) Assurne that the temperaturein the rod is at its steady state distribution. At 
time t = 0, the extemal heat source is removed from the center of the rod, and 
placed at the left end of the rod. Find the temperature in the rod at any later 
timet. 
</p>
<p>6. Solve the boundary-value problern 
</p>
<p>{ 
u(x,O)_=cosx, 
</p>
<p>u1 =uxx+u; 
u(O,t)-0, 
</p>
<p>5.7 The wave equation 
</p>
<p>We consider now the boundary-value problern 
</p>
<p>( 
u(x,O)=j(x), 
</p>
<p>u(O, t) = u(l, t) =0 
</p>
<p>O&lt;x&lt;l 
u(l,t)=O. 
</p>
<p>(I) 
</p>
<p>which characterizes the propagation of waves in various rnedia, and the 
rnechanical vibrations of an elastic string. This problern, too, can be solved 
by the rnethod of separation of variables. Specifically, we will (a) find solu-
tions un(x,t)=Xn(x)Tn(t) of the boundary-value problern 
</p>
<p>u(O, t) = u(l, t) =0 (2) 
</p>
<p>and (b) find the solution u(x,t) of (1) by taking a suitable linear cornbina-
tion of the functions un(x,t). 
</p>
<p>(a) Let u(x,t)= X(x)T(t). Cornputing 
</p>
<p>a2u =XT" and a2u =X"T 
at2 ax2 
</p>
<p>we see that u(x,t)=X(x)T(t) is a solution of the wave equation u11 =c2 uxx 
</p>
<p>503 </p>
<p/>
</div>
<div class="page"><p/>
<p>5 Separation of variables and Fourier series 
</p>
<p>if XT"=c 2X"T, or 
</p>
<p>T" X" 
c2T = x&middot; (3) 
</p>
<p>Next, we observe that the left-hand side of (3) is a function of t alone, 
while the right-hand side is a function of x alone. This irnplies that 
</p>
<p>T" X" -=-"A=-
c2T A 
</p>
<p>for sorne constant A.. In addition, the boundary conditions 
</p>
<p>0= u(O,t)=X (O)T(t), and 0= u(l,t)=X (l)T(t) 
</p>
<p>irnply that X(O)=O and X(/)=0. Hence u(x,t)=X(x)T(t) is a solution of 
(2) if 
</p>
<p>X"+"AX=O; X (0) =X (I) =0 (4) 
</p>
<p>and 
</p>
<p>(5) 
</p>
<p>At this point, the constant A. is arbitrary. However, the boundary-value 
problern (4) has a nontrivial solution X(x) only if "A=A"=n2."2j/2, andin 
this case, 
</p>
<p>X(x)=Xn(x)=sin n~x. 
</p>
<p>Equation (5), in turn, irnplies that 
</p>
<p>n'TTct . mrct 
T(t) = Tn (t) =an cos-1- + bn sm-1-. 
</p>
<p>Hence, 
</p>
<p>. mrx [ mrct . mrct ] un(x,t)=sm-,- ancos-1- +bnsm-1-
</p>
<p>is a nontrivial solution of (2) for every positive integer n, and every pair of 
constants an, bn. 
</p>
<p>(b) The linear cornbination 
00 
</p>
<p>"" . n'TTX [ n'TTCI . n'TTCt ] u(x,t)= f:
1 
sm-1- ancos-1- + bnsm-1-
</p>
<p>forrnally satisfies the boundary-value problern (2) and the initial conditions 
00 00 
</p>
<p>( 0) ~ . mrx ~ n'TTC . n'TTX u x, = ~ ansm-1- and u1(x,O)= ~ - 1-bnsm-1-. 
n-1 n-1 
</p>
<p>Thus, to satisfy the initial conditions u(x,O)=f(x) and u1(x,O)=g(x), we 
rnust choose the constants an and bn such that 
</p>
<p>00 00 
</p>
<p>f ~ . n'TTx ~ n'TTC . n'TTx (x)= ~ ansm-1- and g(x)= ~ - 1-bnsm-1-
n=1 n=1 
</p>
<p>504 </p>
<p/>
</div>
<div class="page"><p/>
<p>5.7 The wave equation 
</p>
<p>on the interva1 0 &lt; x &lt; I. In other words, we must expand the functions 
f(x) and g(x) in Fourier sine series on the interval 0&lt; x &lt;I. This is pre-
cisely the situation in Theorem 3 of Section 5.5, and we conclude, there-
fore, that 
</p>
<p>211 ( ) . mrx 2 11 ( ) . n'TTX an=[ 0 f x sm-1-dx and bn= n'TTC 0 g x sm-1-dx. 
For simplicity, we now restriet ourse1ves to the case where g(x) is zero; 
</p>
<p>that is, the string is released with zero initial velocity. In this case the dis-
placement u(x, t) of the string at any time t &gt; 0 is given by the formula 
</p>
<p>00 
</p>
<p>( ) ""' . n'TTX n'TTCI u x,t = ~ ansln-1-cos-1-; 
n=l 
</p>
<p>211 ( ) . n'TTX an= 7 
0 
</p>
<p>f x sm-1-dx. (6) 
</p>
<p>There is a physica1 significance to the various terms in (6). Each term rep-
resents a particular mode in which the string vibrates. The first term (n = 1) 
represents the first mode of vibration in which the string oscillates about 
its equilibrium position with frequency 
</p>
<p>1 'TTC C 
w1 = 277 T = 21 cycles per second. 
</p>
<p>This lowest frequency is called the fundamental frequency, or first bar-
monie of the string. Similarly, the nth mode has a frequency 
</p>
<p>1 n'TTc 
wn = 2'TT - 1- = nw1 cycles per second 
</p>
<p>which is called the nth harmonic of the string. 
In the case of the vibrating string, all the harmonic frequencies are in-
</p>
<p>teger multiples of the fundamental frequency w1&bull; Thus, we have music in 
this case. Of course, if the tension in the string is not large enough, then the 
sound produced will be of such very low frequency that it is not in the aud-
ible range. As we increase the tension in the string, we increase the 
frequency, and the result is a musical note that can be heard by the human 
ear. 
</p>
<p>Justification of solution. We cannot prove directly, as in the case of the heat 
equation, that the function u(x, t) defined in (6) is a solution of the wave 
equation. Indeed, we cannot even prove directly that the infinite series (6) 
has a partial derivative with respect to t and x. For examp1e, on formally 
computing ul' we obtain that 
</p>
<p>00 
</p>
<p>L n'TTC . n'TTX . n'TTCI u =- -a sm--sm--
1 I n I I 
</p>
<p>n=l 
</p>
<p>and due to the presence of the factor n, this series may not converge. How-
ever, there is an alternate way to establish the validity of the solution (6). 
At the same time, we will gain additional insight into the structure of 
</p>
<p>505 </p>
<p/>
</div>
<div class="page"><p/>
<p>5 Separation of variables and Fourier series 
</p>
<p>u(x,t). Observe first that 
</p>
<p>. mrx mrct 1 [ . mr ( ) . mr ( ) ] sm-1-cos-1- = i sm-1- x-ct +sm-1- x+ct . 
</p>
<p>Next, let F be the odd periodic extension of f on the interval -I&lt; x &lt;I; 
that is, 
</p>
<p>F(x)= ( j(x), 
-j(-x), 
</p>
<p>O&lt;x&lt;l 
and F(x+2/)=F(x). 
</p>
<p>-l&lt;x&lt;O 
</p>
<p>It is easily verified (see Exercise 6) that the Fourier series for Fis 
</p>
<p>00 
</p>
<p>F(x)= ~ cnsin n~x, 
n=l 
</p>
<p>2 ( 1 ( ) . n7TX 
cn = l Jo f x sm-1-dx. 
</p>
<p>Therefore, we can write u(x,t) in the form 
</p>
<p>u(x,t)=t[ F(x-ct)+F(x+ct)] (7) 
</p>
<p>and it is now a trivial matter to show that u(x, t) satisfies the wave equa-
tion if f(x) has two continuous derivatives. 
</p>
<p>Equation (7) has the following interpretation. lf we plot the graph of the 
function y = F(x- ct) for any fixed t, we see that it is the same as the 
graph of y = F(x), except that it is displaced a distance ct in the positive x 
direction, as shown in Figures la and lb. Thus, F(x- ct) is a wave which 
travels with velocity c in the positive x direction. Similarly, F(x + ct) is a 
wave which travels with velocity c in the negative x direction. The number 
c represents the velocity with which a disturbance propagates along the 
string. If a disturbance occurs at the point x0, then it will be felt at the 
point x after a time t=(x- x0)/ c has elapsed. Thus, the wave equation, or 
some form of it, characterizes the propagation of waves in a medium where 
disturbances (or signals) travel with a finite, rather than infinite, velocity. 
</p>
<p>y y 
</p>
<p>Y = F(x) 
y=F(x&middot;&middot;l) 
</p>
<p>--~-+-----'----'al- X --~---._-~--~--x 
-I 2 
</p>
<p>(b) (a) 
</p>
<p>Figure 1 
</p>
<p>506 </p>
<p/>
</div>
<div class="page"><p/>
<p>5.7 The wave equation 
</p>
<p>EXERCISES 
</p>
<p>Solve each of the following boundary-value problems. 
</p>
<p>{
u(x,O)=cosx-1, u1(x,O)=O, O.;;x.;;2'1T 
</p>
<p>u(O,t)=O, u(2'1T,t)=O 
</p>
<p>{
u(x,O)=O, u1(x,O)=l, O.;;x.;;l 
</p>
<p>u(O,t)=O, u(l,t)=O 
</p>
<p>3 tt xx &middot;uxO= u =c
2 u { x, 
</p>
<p>' u(O,t)=u(3,t)=O' ( ' ) 3 ~&middot;x, 
0";;;; X";;;; 1, 
</p>
<p>I.;; X ";;;;2 
2.;;x ";;;;3 
</p>
<p>{
u(x,O)=xcos'1Txj2, u1(x,O)=O, O.;;x.;;l 
</p>
<p>u(O,t)=O, u(l,t)=O 
</p>
<p>5. A string of length 10 ft is raised at the middle to a distance of 1 ft, and then 
released. Describe the rnotion of the string, assuming that c2 = 1. 
</p>
<p>6. Let F be the odd periodic extension of f on the interval -/ &lt; x &lt; I. Show that 
the Fourier series 
</p>
<p>2 ~ [ ('!( ) . n'ITX d ] . n'ITX 7 .ttC..J Jo x sm-1- x sm-1-
n-1 
</p>
<p>converges to F(x) if Fis continuous at x. 
</p>
<p>7. Show that the transforrnation ~ = x- ct, 11 = x + ct reduces the wave equation to 
the equation uEri = 0. Conclude, therefore, that every solution u(x, t) of the wave 
equation is of the form u(x,t)= F(x- ct)+ G(x + ct) for sorne functions Fand 
G. 
</p>
<p>8. Show that the solution of the boundary-value problern 
</p>
<p>is 
</p>
<p>{ 
u(x,O)=j(x), u1(x,O)=g(x), -l&lt;x&lt;l 
</p>
<p>u(O,t)= u(l,t)=O 
</p>
<p>1 [ ] 1 fx+ct u(x,t)= -2 F(x-ct)+F(x+ct) + -2 g(s)ds 
C x-ct 
</p>
<p>where F is the odd periodic extension of j. 
</p>
<p>9. The wave equation in two dirnensions is u11 = c2( uxx + Uyy)&middot; Find solutions of 
this equation by the rnethod of separation of variables. 
</p>
<p>10. Solve the boundary-value problern 
</p>
<p>{ 
u(x,O):f(x), 
</p>
<p>u(O,t)-0, 
</p>
<p>U1(x,0)=0, 
</p>
<p>u(l,t)=O 
</p>
<p>O&lt;x&lt;l 
</p>
<p>507 </p>
<p/>
</div>
<div class="page"><p/>
<p>5 Separation of variables and Fourier series 
</p>
<p>5.8 Laplace's equation 
</p>
<p>We consider now Laplace's equation 
</p>
<p>o2u + a2u =0. 
ax2 oy2 
</p>
<p>(1) 
</p>
<p>As we mentioned in Section 5.2, two important boundary-value problems 
that arise in connection with (1) are the Dirichlet problern and the Neu-
mann problem. In a Dirichlet problern we seek a function u(x,y) which 
satisfies Laplace's equation inside a region R, and which assumes pre-
scribed values on the boundary of R. In a Neumann problem, we seek a 
function u(x,y) which satisfies Laplace's equation inside a region R, and 
whose derivative in the direction normal to the boundary of R takes on 
prescribed values. Both of these problems can be solved by the method of 
separation of variables if R is a rectangle. 
</p>
<p>Example 1. Find a function u(x,y) which satisfies Laplace's equation in 
the reetangle 0 &lt; x &lt; a, 0 &lt;y &lt; b and which also satisfies the boundary 
conditions 
</p>
<p>u(x,O)=O, u(x,b)=O 
</p>
<p>u(O,y)=O, u(a,y) = f(y) 
</p>
<p>y 
</p>
<p>I b u=O u=O I u= f(y) (2) &bull;X 
u=O a 
</p>
<p>Solution. We solve this problern in two steps. First, we will find functions 
un(x,y)=Xn(x)Yn(Y) which satisfy the boundary-value problern 
</p>
<p>uxx+t~yy=O; u(x,O)=O, u(x,b)=O, u(O,y)=O. (3) 
</p>
<p>Then, we will find constants cn such that the linear combination 
00 
</p>
<p>u(x,y)= ~ cnun(x,y) 
n=l 
</p>
<p>satisfies the boundary condition u(a,y)= f(y). 
Step 1: Let u(x,y)=X(x)Y(y). Computing uxx=X"Yand uyy=XY", we 
see that u(x,y)=X(x) Y(y) is a solution of Laplace's equation if X" Y + 
XY"=O, or 
</p>
<p>Y" X" 
y-=-x-&middot; (4) 
</p>
<p>Next, we observe that the left-hand side of (4) is a function of y alone, 
</p>
<p>508 </p>
<p/>
</div>
<div class="page"><p/>
<p>5.8 Laplace's equation 
</p>
<p>while the right-hand side is a function of x alone. This implies that 
</p>
<p>Y" X" --y=--y=-A. 
</p>
<p>for some constant A. In addition, the boundary conditions 
</p>
<p>0= u(x,O) =X (x) Y (0), 
</p>
<p>0= u(O,y) =X (0) Y(y) 
</p>
<p>0= u(x,b)=X(x) Y(b), 
</p>
<p>imply that Y(O)=O, Y(b)=O, and X(O)=O. Hence u(x,y)=XY is a solu-
tion of (3) if 
</p>
<p>Y"+AY=O; Y(O)=O, Y(b)=O (5) 
</p>
<p>and 
X"-;\X=O, X(O)=O. {6) 
</p>
<p>At this point the constant A is arbitrary. However, the boundary-value 
problern (5) has a nontrivial solution Y (y) only if A = A" = n2 'TT 2 / b2, and in 
this case, 
</p>
<p>Y(y)= Yn(y)=sinn'TTyjb. 
</p>
<p>Equation (6), in turn, implies that Xn(x) is proportional to sinhn'TTxjb. 
(The differential equation X"-(n 2 'TT 2 jb 2)X=O implies that X(x)= 
c1 coshn'TTx/ b + c2 sinhn'TTx/ b for some choice of constants c1,c2, and the 
initial condition X (0) = 0 forces c1 to be zero.) We conclude, therefore, that 
</p>
<p>. n'TTx . n'TTy 
un( x,y) = smh b sm b 
</p>
<p>is a solution of (3) for every positive integer n. 
Step 2: The function 
</p>
<p>is a solution (formally) of (3) for every choice of constants c1,c2, .... Its 
value at x=a is 
</p>
<p>0() 
</p>
<p>""' . n'TTa . mry 
u(a,y)= ~cnsmhbsmb. 
</p>
<p>n=l 
</p>
<p>Therefore, we must choose the constants cn such that 
</p>
<p>O&lt;y&lt;b. 
</p>
<p>In other words, we must expand f in a Fourier sine series on the interval 
0 &lt;y &lt; b. This is precisely the situation described in Theorem 3 of Section 
</p>
<p>509 </p>
<p/>
</div>
<div class="page"><p/>
<p>5 Separation of variables and Fourier series 
</p>
<p>5.5, and we conclude, therefore, that 
</p>
<p>2 lb . mry 
cn= . mra j(y)smbdy, 
</p>
<p>bsmhb o 
n= 1,2, .... 
</p>
<p>Remark. The rnethod of separation of variables can always be used to 
solve the Dirichlet problern for a reetangle R if u is zero on three sides of 
R. We can solve an arbitrary Dirichlet problern for a reetangle R by split-
ting it up into four problerns where u is zero on three sides of R (see Ex-
ercises 1-4). 
</p>
<p>Example 2. Find a function u(x,y) which satisfies Laplace's equation in 
the reetangle 0 &lt; x &lt; a, 0 &lt;y &lt; b, and which also satisfies the boundary 
conditions 
</p>
<p>uy(x,O)=O, 
</p>
<p>uAO,y)=O, 
</p>
<p>uy(x,b)=O 
</p>
<p>ux&lt; a,y) =J(y) 
</p>
<p>Y 1 uy=O 
ux = ~ 1-----------.J u, ~ :r;l 
</p>
<p>uy=O a 
</p>
<p>(7) 
</p>
<p>Solution. We atternpt to solve this problern in two steps. First, we will find 
functions un(x,y) = Xn(x) Yn(Y) which satisfy the boundary-value problern 
</p>
<p>uxx+~y=O; ~(x,O)=O, uy(x,b)=O, and uAO,y)=O. (8) 
</p>
<p>Then, we will try and find constants cn such that the linear cornbination 
</p>
<p>u(x,y) = ~ :=ocnun(x,y) satisfies the boundary condition ux(a,y) = f(y). 
Step 1: Set u(x,y)=X(x)Y(y). Then, as in Exarnple I, 
</p>
<p>Y" X" 
-y=--y=-;\ 
</p>
<p>for sorne constant ;\, The boundary conditions 
</p>
<p>irnply that 
</p>
<p>0= ~(x,O) =X (x) Y'(O), 0= uy(x,b) = X(x) Y'(b), 
</p>
<p>0= ux&lt;O,y) =X'(O) Y(y) 
</p>
<p>Y'(O)=O, Y'(b)=O and X'(O)=O. 
</p>
<p>Hence, u(x,y)=X(x)Y(y) is a solution of (8) if 
</p>
<p>Y"+;\Y=O; Y'(O)=O, Y'(b)=O 
</p>
<p>510 
</p>
<p>(9) </p>
<p/>
</div>
<div class="page"><p/>
<p>5.8 Laplace's equation 
</p>
<p>and 
</p>
<p>X"-A.X=O; X'(O)=O. (10) 
</p>
<p>At this point, the constant A. is arbitrary. However, the boundary-value 
problern (9) has a nontrivial solution Y (y) only if A. = A" = n2 '!T2 I b2, n = 
0, I, 2, ... , and in this case 
</p>
<p>Y(y)= Yn(y)=cosn'!Tylb. 
</p>
<p>Equation (10), in turn, implies that X(x) is proportional to coshn'ITxlb. 
(The differential equation X"- n 2'1T 2 X I b 2 = 0 implies that X (x) = 
c1coshn'ITxlb+c2 sinhn'ITXIb for some choice of constants c1,c2, and the 
boundary condition X'(O)=O forces c2 tobe zero.) We conclude, therefore, 
that 
</p>
<p>n'!TX n'ITy 
un(x,y)=cosh-;;-cos-;;-
</p>
<p>is a solution of (8) for every nonnegative integer n. 
Step 2: The function 
</p>
<p>is a solution (formally) of (8) for every choice of constants c0, c1, Cz, &bull;&bull;&bull; &bull; The 
value of ux at x=a is 
</p>
<p>Therefore, we must choose the constants c1, c2, &bull;&bull;&bull; , such that 
</p>
<p>O&lt;y&lt;b. (11) 
</p>
<p>Now, Theorem 3 of Section 5.5 states that we can expand j(y) in the 
cosine series 
</p>
<p>I h 2 h n'ITy n'!Ty 
00 [ ] f(y)= b fo f(y)dy+ b ~ fo j(y)cosbdy cosb (12) 
</p>
<p>on the interval 0 &lt; y &lt; b. However, we cannot equate coefficients in (li) 
and (12) since the series (II) has no constant term. Therefore, the condi-
tion 
</p>
<p>ib j(y)dy=O 
is necessary for this Neumann problern to have a solution. If this is the 
</p>
<p>511 </p>
<p/>
</div>
<div class="page"><p/>
<p>5 Separation of variables and Fourier series 
</p>
<p>case, then 
</p>
<p>2 lb mry 
cn= . mra J(y)cosbdy, 
</p>
<p>mrsmhb o 
n ~ 1. 
</p>
<p>Finally, note that c0 remains arbitrary, and thus the solution u(x,y) is only 
determined up to an additive constant. This is a property of all Neumann 
problems. 
</p>
<p>ExERCISES 
</p>
<p>Salve each of the following Dirichlet problems. 
</p>
<p>Uxx+~tyy=O . u(x,O)=O, u(x,b)=O 
1. ' 
</p>
<p>O&lt;x&lt;a, O&lt;y&lt;b u(a,y)=O, u(O,y)=J(y) 
</p>
<p>uxx+~tyy=O . u(O,y)=O, 
2. ' 
</p>
<p>O&lt;x&lt;a, O&lt;y&lt;b u(x,O)=O, 
</p>
<p>u(a,y)=O 
</p>
<p>u(x,b)= f(x) 
</p>
<p>Remark. You can do this problern the long way, by separation of vari-
ables, or you can try something smart, like interchanging x with y and 
using the result of Example 1 in the text. 
</p>
<p>Uxx + llyy = 0 &bull; 
3. ' 
</p>
<p>O&lt;x&lt;a, O&lt;y&lt;b 
</p>
<p>uxx + llyy = 0 . 
4. ' 
</p>
<p>O&lt;x&lt;a, O&lt;y&lt;b 
</p>
<p>u(O,y)=O, u(a,y)=O 
</p>
<p>u(x,b)=O, u(x,O)=f(x) 
</p>
<p>u(x,O)=J(x), u(x,b)=g(x) 
</p>
<p>u(O,y) = h(y ), u(a,y) = k(y) 
</p>
<p>Hint: Write u(x,y) as the sum of 4 functions, each of which is zero on three 
sides of the rectangle. 
</p>
<p>5. 
Uxx+llyy =0 u(x,O)=O, u(x,b)= 1 
</p>
<p>O&lt;x&lt;a, O&lt;y&lt;b' u(O,y)=O, u(a,y)= 1 
</p>
<p>6. 
Uxx+ llyy=O u(x,b)=O, u(x,O)= 1 
</p>
<p>O&lt;x&lt;a, O&lt;y&lt;b' u(O,y)=O, u(a,y)= l 
</p>
<p>7. 
Uxx + llyy =0 u(x,O)= l, u(x,b)= l 
O&lt;x&lt;a, O&lt;y&lt;b' u(O,y)=O, u(a,y)= l 
</p>
<p>8. 
Uxx+ llyy=O u(x,O)= 1, u(x,b)=l 
</p>
<p>O&lt;x&lt;a, O&lt;y&lt;b' u(O,y)= l, u(a,y)= l 
</p>
<p>Remark. Think! 
</p>
<p>9. Solve the boundary-value problern 
</p>
<p>Uxx + llyy = U u(x,O)=O, u(x, 1)=0 
O&lt;x&lt; l, O&lt;y&lt;l' u(O,y)=O, u(I,y)=y 
</p>
<p>512 </p>
<p/>
</div>
<div class="page"><p/>
<p>5.8 Laplace's equation 
</p>
<p>10. (a) For which functions f(y) can we find a solution u(x,y) of the Neumann 
problern 
</p>
<p>Uxx+Uyy=O &bull; 
</p>
<p>0&lt;x&lt;1, 0&lt;y&lt;1' 
</p>
<p>ux(l,y)=O, 
</p>
<p>~(x,O)=O, 
</p>
<p>(b) Solve this problern if f(y)=sinhy. 
</p>
<p>11. Laplace's equation in three dimensions is 
</p>
<p>Uxx + ~y + Uzz =0. 
</p>
<p>ux{O,y) = f(y) 
</p>
<p>~(x,l)=O 
</p>
<p>Assuming that u =X (x) Y (y)Z (z), find 3 ordinary differential equations satis-
fied by X, Y, and Z. 
</p>
<p>513 </p>
<p/>
</div>
<div class="page"><p/>
<p>6 
Sturm-Liouville boundary 
</p>
<p>value problems 
</p>
<p>6.1 Introduction 
</p>
<p>In Section 5.5 we described the remarkable result that an arbitrary piecewise 
differentiable function f(x) could be expanded in either a pure sine series of 
the form 
</p>
<p>oo nnx 
f(x) = n~l bn sin - 1- (1) 
</p>
<p>or a pure cosine series of the form 
</p>
<p>(2) 
</p>
<p>on the interval 0 &lt; x &lt; 1. We were led to the trigonometric functions ap-
pearing in the series (1) and (2) by considering the 2 point boundary value 
problems 
</p>
<p>y" + A.y = 0, y(O) = 0, y(1) = 0, (3) 
and 
</p>
<p>y" + A.y = 0, y'(O) = 0, y'(1) = 0. (4) 
</p>
<p>Recall that Equations (3) and (4) have nontrivial solutions 
</p>
<p>. nnx nnx 
Yn(x) = csm-1- and Yn(x) = ccos-1-, 
</p>
<p>2 2 
</p>
<p>respectively, only if A. = An = n 1: . These special values of A, were called 
</p>
<p>eigenvalues, and the corresponding solutions were called eigenfunctions. 
</p>
<p>514 </p>
<p/>
</div>
<div class="page"><p/>
<p>6.2 Inner product spaces 
</p>
<p>There was another instance in our study of differential equations where 
something interesting happened for special values of a parameter A. To wit, 
in Section 2.8 we studied, either in the text or in the exercises, the four 
differential equations 
</p>
<p>y" - 2xy + A,y = 0, (5) 
</p>
<p>(1 - x2)y"- 2xy' + A,(A, + 1)y = 0, (6) 
</p>
<p>(1 - x 2)y"- xy' + A, 2y = 0, (7) 
</p>
<p>and 
</p>
<p>xy" + (1 - x)y' + A,y = 0. (8) 
</p>
<p>Equations (5)-(8) are the famous Hermite, Legendre, Tchebycheff, and 
Laguerre differential equations, respectively. The Legendre, Tchebycheff, and 
Laguerre equations each have a polynomial solution of degree n if A, = n, 
while the Hermite equation has a polynomial solution of degree n if A = 2n. 
These polynomials, when properly normalized, i.e., when multiplied by a 
suitable constant, are known as the Hermite, Legendre, Tchebycheff, and 
Laguerre polynomials. It turns out, remarkably, that any piecewise differ-
entiable function f(x) can also be expanded in a series of Hermite, Legendre, 
Tchebycheff, and Laguerre polynomials, on an appropriate interval. 
</p>
<p>There is a very pretty theory that ties together not only the trigonometric 
functions and the Hermite, Legendre, Tchebycheff, and Laguerre poly-
nomials, but also many of the other famous functions of mathematical 
physics, such as the various Bessel functions. This theory is commonly called 
Sturm-Liouville Theory; it has its roots, essentially, in an area of linear 
algebra known as inner product spaces, and it is to this area that we now 
turn our attention. 
</p>
<p>6.2 Inner product spaces 
</p>
<p>Up to this point, our study of linear algebra in general and linear vector 
spaces in particular was algebraic in nature. We were able to add two vectors 
together and multiply a vector by a constant. By means of these Operations 
we can define the geometric concepts of dimension, line, plane, and even 
parallelism of lines. Recall that the dimension of a space V is the number of 
elements in a basis, i.e., the fewest number oflinearly independent vectors that 
span V. Once we have the concept of dimension, we can define a line in V as 
a subspace of dimension 1, a plane as a subspace of dimension 2, etc. Finally, 
two vectors are parallel if one is a constant multiple of the other. 
</p>
<p>Many important geometric concepts of so-called Euclidean geometry, 
however, still cannot be defined for arbitrary linear vector spaces. Specifically, 
we have no way of formulating, as yet, the definition of length of a vector 
and the angle between two vectors. To accomplish this, we need to super-
</p>
<p>515 </p>
<p/>
</div>
<div class="page"><p/>
<p>6 Sturm-Liouville boundary value problems 
</p>
<p>impose on V some additional structure. This structure is known as an inner 
product. 
</p>
<p>Our definition of an inner product is modelled after the traditional dot 
product oftwo vectors in R2 and R3 , which we studied in calculus. Recall that 
if x and y are vectors in R2 or R3 , then 
</p>
<p>(1) 
</p>
<p>and 
</p>
<p>(2) 
</p>
<p>where x 1 , x 2 , ... , and Yt&gt; y2 , ... are the components ofx and y, respectively. 
Recall too, the famous identity, proven in most calculus courses, that 
</p>
<p>x &middot; y = 1 x 11 y 1 cos e (3) 
where 0 is the angle between X and y and 
</p>
<p>lxl = (xi + xD112 or (xi + x~ + x~) 112 
</p>
<p>in R 2 and R 3 , respectively, is the Euclidean length of x. Rewriting Equation 
(3) in the form 
</p>
<p>x&middot;y 
cose = --
</p>
<p>lxiiYI 
(4) 
</p>
<p>enables us to compute the angle e between two vectors. Finally, if we observe 
that 
</p>
<p>lxl = (x &middot; x)112 (5) 
</p>
<p>then both the length of a vector and the angle between two vectors can be 
computed from the dot product alone. 
</p>
<p>We are now ready to generalize this concept of dot product. This general-
ization will be called an inner product. We will first define arealinner product, 
and then toward the end of this section, a complex inner product. 
</p>
<p>Definition. Let V be a real vector space. A real inner product on V is a 
real-valued function that associates with each pair of vectors x, y a real 
number, denoted by ( x, y), that satisfies the following properties: 
</p>
<p>(i) (x,y) = (y,x) for all x and y in V, 
(ii) (kx, y) = k(x, y) for all scalars k and vectors x, y, 
(iii) (x + y, z) = (x, z) + (y, z) for all x, y, z in V, 
(iv) (x, x) ~ 0 and (x, x) = 0 only if x = 0. 
</p>
<p>It is customary to refer to the vector space V, together with some inner 
product &lt; , ) as a real inner product space, and a finite-dimensional real 
inner product space is often called a Euclidean space. 
</p>
<p>516 </p>
<p/>
</div>
<div class="page"><p/>
<p>6.2 Inner product spaces 
</p>
<p>Remark. Observe from (i) that properties (ii) and (iii) hold equally weil on 
opposite sides of the inner product bracket, i.e., 
</p>
<p>(x,ky) = k(x,y) and (x,y + z) = (x,y) + (x,z). 
</p>
<p>The dassie example of an inner product on Rn, of course, is the dot product 
</p>
<p>(x,y) = x&middot;y = XlYl + X2Y2 + ... + XnYn&middot; 
It is easily verified that the dot product satisfies properties (i)-(iv). Here 
are some additional examples, which have proven extremely useful in 
applications. 
</p>
<p>Example 1. Let V be the space of all continuous functions on the interval 
[a, b ], and define the inner product of two functions f(x) and g(x) in V as 
</p>
<p>(f,g) = r f(x)g(x)dx. (6) 
It is easily verified that the definition (6) satisfies properties (i)-(iv). 
</p>
<p>Example 2. Let V be as in Example 1, and define 
</p>
<p>&lt;J,g) = r r(x)f(x)g(x)dx (7) 
where r(x) is positive on the open interval (a, b). Again, it is trivial to verify 
that the inner product (7) satisfies properties (i)-(iv). 
</p>
<p>Example 3. Let V = R 3 and set 
</p>
<p>(x, y) = X1Y1 + 2X2Y2 + 2X3Y3 - X1Y2 - X2Y1 - X2Y3 - X3Y2&middot; 
Properties (ii) and (iii) are trivial to check, and property (i) is simple to verify. 
To check property (iv), we write 
</p>
<p>(x,x) = xi + 2x~ + 2x~- x 1 x2 - x 2 x 1 - x 2 x 3 - x 3x 2 
= xi + 2x~ + 2x~- 2x1 x 2 - 2x2 x 3 
= xi- 2x1 x 2 + x~ + x~- 2x2 x 3 + x~ + x~ 
</p>
<p>= (xl - x 2 )2 + (x 2 - x 3 ) 2 + x~, 
and it is now clear that (x, x) = 0 if and only if x = 0. 
</p>
<p>Let x and y be vectors in an arbitrary inner product space V, and suppose, 
following Equation (5), that we define the lengths ofx and y, denoted by llxll 
and IIYII, respectively, as 
</p>
<p>llxll = (x,x/12, IIYII = (y,y) 112, (8) 
</p>
<p>where the double verticallines are used to denote length. It is certainly very 
plausible to try to mirnie Equation (4) and define the angle() between x and 
</p>
<p>517 </p>
<p/>
</div>
<div class="page"><p/>
<p>6 Sturm-Liouville boundary value problems 
</p>
<p>y via the equation 
</p>
<p>cose = (x,y) = (x,y) 
llxiiiiYII (x,x) 112 (y,y) 112 . 
</p>
<p>(9) 
</p>
<p>Clearly, the right-hand side of Equation (9) must be ~ 1 in order for this 
equation to have any meaning at all. A second and more subtle requirement 
isthat the quantity llxll, defined as the length ofx, really is a length; that is, it 
satisfies the geometric properties usually associated with length. Let us there-
fore take one last digression and discuss the concept of length of a vector, or 
as it is traditionally called in linear algebra, the norm of a vector. 
</p>
<p>Definition. A norm on a real or complex vector space V is a real-valued 
function, usually denoted by II II, which satisfies 
</p>
<p>(i) llxll ~ 0 for all x in V and llxll = 0 only ifx = 0, 
(ii) II kx II = I k III x II for all scalars k, 
</p>
<p>(iii) llx + Yll ~ llxll + IIYII. 
</p>
<p>Properties (i) and (ii) are fairly obvious properties of length, while property 
(iii) is simply the triangle law, which states that the length of one side of a 
triangle is always less than (or equal to) the sum of the lengths of the other 
two sides (see Figure 1). 
</p>
<p>The classical example of a norm is ordinary length in R"; i.e., if 
</p>
<p>x~ [I] 
then 
</p>
<p>llxll = (xi + x~ + &middot; &middot; &middot; + x;)112 
</p>
<p>obviously satisfies (i)-(iii). Here are some additional examples, which have 
proven quite useful in applications. 
</p>
<p>Figure 1 
</p>
<p>518 </p>
<p/>
</div>
<div class="page"><p/>
<p>6.2 Inner product spaces 
</p>
<p>Example 4. Let V = R" and define 
</p>
<p>llxllt = lxtl + lxzl + &middot;&middot;&middot; + lxnl&middot; 
lt is extremely easy to verify that II 11 1 is a norm on R". 
</p>
<p>Example 5. Let V = R" and define 
</p>
<p>llxlloo = max[lxtl, lxzl, ... , lxniJ. 
</p>
<p>Again, it is extremely simple to verify that II lloo defines a norm on R". 
</p>
<p>Example 6. Let V = R" and define 
</p>
<p>llxiiP = [lxtiP + lxziP + &middot; &middot;&middot; + lxn1P] 11P. (10) 
</p>
<p>lt is extremely simple to verify that II IIP' referred to as the p norm, satisfies 
properties (i) and (ii). Property (iii) is also true but quite difficult to verify, 
hence we will not do so here. We wish to pointout (see Exercise 6), however, 
that 
</p>
<p>llxlloo = lim llxiiP' 
p-+oo 
</p>
<p>and this is the motivation for the strange notation II lloo&middot; 
</p>
<p>Example 7. Let V be the space of all continuous functions f(x) on the interval 
[0, 1 ], and define 
</p>
<p>11/11 = J: lf(x)l dx. (11) 
lt is easily verified that Equation (11) defines a norm on V. 
</p>
<p>Let us return now to the questions raised via the definitions (8) and (9). As 
mentioned previously, we must show that the right-hand side of Equation (9) 
is always between -1 and + 1 in order for this equation to make sense. But 
this is equivalent to the inequality 
</p>
<p>l(x,y)l::::; (x,x/12(y,y)l/2 
</p>
<p>or, equivalently, 
</p>
<p>l(x,y)l::::; llxiiiiYII- (12) 
</p>
<p>Equation (12) is the precise statement of a very famous theorem, known as 
Schwarz's Inequality, which we now prove. 
</p>
<p>Theorem 1 (Schwarz's Inequality). Let V be a real inner product space with 
inner product ( , ) . Then 
</p>
<p>l(x,y)l::::; llxiiiiYII (13) 
</p>
<p>519 </p>
<p/>
</div>
<div class="page"><p/>
<p>6 Sturm-Liouville boundary value problems 
</p>
<p>for all vectors x, y, where llxll is defined by Equation (8). Furthermore, 
equality holds in Equation (13) only if the vectors x and y are linearly 
dependent, i.e., y = kx for some scalar k. 
</p>
<p>PROOF. There are several ways of proving Theorem 1, but we will choose here 
the proofthat generalizes most easily to the complex case. Observe that 
</p>
<p>/ x- (x,y) y, x- (x,y) y) ~ 0 
\ (y,y) (y,y) 
</p>
<p>(14) 
</p>
<p>for all nonzero vectors x and y in V. This follows immediately from property 
(iv) of inner products. Next, using properties (i)-(iii) of inner products, we can 
rewrite Equation (14) in the form 
</p>
<p>(x,y) (x,y) (x,y)2 
(x,x)--( )(y,x)--( )(x,y)+-( ) 2(y,y) y,y y,y y,y 
</p>
<p>Hence, 
</p>
<p>or, equivalently, 
</p>
<p>= (x x)- 2 (x,y)2 + (x,y)2 
' (y, y) (y, y) 
</p>
<p>- &lt; ) - (x,y)2 
- x,x &lt; &gt; y,y 
</p>
<p>II 11 2 (x,y)2 
= X -lfYIT2. 
</p>
<p>l(x,y)l::::; llxiiiiYII. 
</p>
<p>Finally, again from property (iv), equality holds in Equation (14) only if 
</p>
<p>or 
</p>
<p>x- (x,y) y = 0 
(y,y) 
</p>
<p>X= ky, k = (x,y). 
(y,y) 
</p>
<p>Remark 1. The proof we just gave assumes that y 1= 0. We leave it to the 
reader to verify (see Exercise 13) Schwarz's Inequality in the trivial case that 
y = 0. 
</p>
<p>Remark 2. The vector ((x,y)/(y,y))y introduced in Equation (14) was not 
a luckly guess. This vector is actually the projection of the vector x onto the 
vector y, as shown in Figure 2. 
</p>
<p>520 </p>
<p/>
</div>
<div class="page"><p/>
<p>6.2 Inner product spaces 
</p>
<p>X 
</p>
<p>y 
</p>
<p>Figure 2 
</p>
<p>The second question raised was whether 
</p>
<p>llxll = (x,x) 112 (15) 
</p>
<p>satisfies properties (i)-(iii) of norms. Property (i) follows immediately from 
property (iv) of inner products. To verify property (ii), we compute 
</p>
<p>llkxll = (kx,kx) 112 = [k2 (x,x)] 112 = lkl(x,x) 112 = lklllxll. 
</p>
<p>Property (iii) is a bit more difficult to verify. Observe first that 
</p>
<p>llx + Yll 2 = (x + y,x + y) 
= (x,x) + (x,y) + (y,x) + (y,y) 
</p>
<p>= llxll 2 + 2(x,y) + IIYII 2 
</p>
<p>:";; llxll 2 + 211xiiiiYII + IIYII 2 
</p>
<p>= [ llxll + IIYIIJ 2, 
where the inequality above follows directly from Schwarz's Inequality. Tak-
ing square roots gives the triangle inequality, and this completes our proof. 
</p>
<p>Remark. Schwarz's Inequality is an extremely powerful tool, as witnessed by 
the preceding proof. Here is another illustration of its strength. Let V be the 
space of all continuous functions on the interval [a, b ], and define 
</p>
<p>&lt;f,g) = r f(x)g(x)dx. 
Then, from Schwarz's Inequality, 
</p>
<p>I&lt;J,g)l =Ir f(x)g(x)dxl :";; llf(x)llllg(x)ll-
Hence, 
</p>
<p>Ir f(x)g(x)dxl :";; [r JZ(x)dx J12 [r g2 (x)dx J12 ( 16) 
We defy the reader to give a pure calculus proof of the inequality (16). 
</p>
<p>521 </p>
<p/>
</div>
<div class="page"><p/>
<p>6 Sturm-Liouville boundary value problems 
</p>
<p>Once we have an inner product space V, we can define two vectors in V to 
be orthogonal, or perpendicular to each other, if their inner product is zero; 
i.e., x and y areorthogonal if (x, y) = 0. 
</p>
<p>Example 8. Let V be the space of all continuous functions on the interval 
[ -n, n ], and define an inner product on V via the relation 
</p>
<p>(f,g) = [" f(x)g(x)dx. 
</p>
<p>The set of functions 
</p>
<p>k = 1, 2, ... , 
</p>
<p>are all mutually orthogonal; that is, 
</p>
<p>(jj(x),fk(x)) = 0, 
</p>
<p>since 
</p>
<p>j # k, 
</p>
<p>&lt;fi(x),fk(x) &gt; = r" sin jx sin kx dx = 0, 
following the discussion in Section 5.4. 
</p>
<p>j # k, 
</p>
<p>Example 9. Let V be the space of all continuous functions on the interval 
[ -1, 1], and define 
</p>
<p>(f,g) = J1 f(x)g(x) dx 
-1~ 
</p>
<p>for f and g in V. The set of functions 
</p>
<p>fk (x) = cos(k cos - 1 x), k = 0, 1, 2, ... , 
</p>
<p>are mutually orthogonal with respect to ( , ), i.e., 
</p>
<p>f1 cos(jcos-1 x)cos(kcos-1x) dx = 0 ~ , 
-1 v 1- )I, 
</p>
<p>To establish Equation (17) we make the substitution 
</p>
<p>-1 
du= ~dx. 
</p>
<p>v 1- x2 
Then the left-hand side of Equation (17) becomes 
</p>
<p>-to cos ju cos ku du = J: cos ju cos ku du 
</p>
<p>j # k. 
</p>
<p>1 f" = 2 0 [cos(j + k)u + cos(j- k)u] du= 0, 
522 
</p>
<p>(17) 
</p>
<p>j # k. </p>
<p/>
</div>
<div class="page"><p/>
<p>6.2 Inner product spaces 
</p>
<p>Remark. It can be shown that the functions ,h(x) defined in Example 9 are 
the Tchebycheff polynomials 7k(x). 
</p>
<p>We conclude this section by extending the notion and definition of inner 
product to complex vector spaces. The main problern we have to overcome 
is the requirement that (x, x) be positive for all nonzero vectors x. For 
example, if V is the space of all complex-valued functions 
</p>
<p>h(t) = f(t) + ig(t), a ~ t ~ b, 
then we cannot define 
</p>
<p>as in Example 1, since 
</p>
<p>(h, h) = r [f(t) + ig(t)] [f(t) + ig(t)] dt 
is not even real [for (J, g) =f. 0], Iet alone positive. 
</p>
<p>To motivate the proper extension, we return to the familiar dot product 
</p>
<p>(x,y) = x&middot;y = X1Y1 + XzY2 + ... + XnYn (18) 
</p>
<p>where x and y are real vectors, i.e., their components are real numbers. We 
can extend this definition to complex vector spaces by making the simple 
adjustment 
</p>
<p>x&middot;y = X1Y1 + XzYz + &middot;&middot;&middot; + XnYn&middot; 
Then, following Equation (19), 
</p>
<p>(x,x) = x 1x1 + x 2 x2 + ... + xnxn 
</p>
<p>(19) 
</p>
<p>is always real and nonnegative. The only thing we have to be extra careful 
about now is that 
</p>
<p>instead of (x, y) and 
</p>
<p>x&middot;ky = x 1ky1 + ... + xnk.Yn = k(x,y) 
instead of k (x, y). This Ieads us to the following definition. 
</p>
<p>Definition. Let V be a complex vector space. A complex, or Hermitian, inner 
product on V is a complex-valued function that associates with each pair 
of vectors x, y a complex number, denoted by (x, y), that satisfies the 
following properties: 
</p>
<p>(i) (x, y) = (y, x), 
(ii) (kx,y) = k(x,y), 
</p>
<p>523 </p>
<p/>
</div>
<div class="page"><p/>
<p>6 Sturm-Liouville boundary value problems 
</p>
<p>(iii) (x + y, z) = (x, z) + (y, z), 
(iv) (x,x) ~ 0 and (x,x) = 0 only ifx = 0 
</p>
<p>for all vectors x and y and complex numbers k. 
</p>
<p>Property (i) is known as conjugate symmetry in contrast to the ordinary 
symmetry of the real case. It implies that 
</p>
<p>(x,ky) = (ky,x) = k(y,x) = k(y,x) = k(x,y). 
</p>
<p>Thus, scalars pulled out from the right-hand side of a complex inner product 
must be conjugated. Finally, we leave it to the reader to verify (see Exercise 
14) that 
</p>
<p>(x,y + z) = (x,y) + (x,z). 
</p>
<p>Example 10. Let V be the space of all complex-valued functions h(t) = f(t) + 
ig(t) on the interval [0, 1], and define 
</p>
<p>(h 1 ,h2 ) = J: h1(t)h 2 (t)dt 
</p>
<p>= J: [f1 (t) + ig1(t)][f2(t)- ig2 (t)]dt (20) 
</p>
<p>=I: [fl(t)fz(t) + gl(t)gz(t)] dt + i I: [f2(t)g1(t)- f 1(t)g2(t)] dt 
lt is easily verified that Equation (20) satisfies properties (i)-(iv) of our 
definition. 
</p>
<p>Complex inner product spaces are the same as real inner product spaces, 
essentially, except for the conjugate symmetry property, as noted above. For 
example, we define 
</p>
<p>llxll = (x,x) 112 (21) 
</p>
<p>to be the length of a vector x in a complex vector space, just as in a real vec-
tor space. The only thing that we must do, though, is extend the proof of 
Schwarz's Inequality to the complex case, since our proof made use of the 
symmetry property of real inner products. 
</p>
<p>Theorem 2 (Schwarz's Inequality). Let V be a complex inner product space 
with inner product &lt; , ). Then 
</p>
<p>l&lt;x,y)l ~ llxiiiiYII (22) 
</p>
<p>for all x, y in V, where llxll is defined by Equation (21). Furthermore, equality 
holds in Equation (22) if and only if the vectors x and y are linearly depen-
dent. 
</p>
<p>524 </p>
<p/>
</div>
<div class="page"><p/>
<p>6.2 Inner product spaces 
</p>
<p>PROOF. Observe from property (iv) that 
</p>
<p>/ (x,y) (x,y) )&gt;-
\x- (y,y)y,x- (y,y)y ,....0 (23) 
</p>
<p>for all vectors x and nonzero vectors y in V. U sing properties (i)-(iii), we can 
rewrite the left-hand side of Equation (23) in the form 
</p>
<p>(x,y) (x,y) (x,y) (x,y) 
(x,x)-~( )(y,x)-~( )(x,y)+~( )~( )(y,y) 
</p>
<p>y,y y,y y,y y,y 
</p>
<p>(x,y)-- (x,y) (x,y)--
= (x,x) -~( )(x,y) -~( )(x,y) +~( )(x,y) 
</p>
<p>Hence, 
</p>
<p>y,y y,y y,y 
</p>
<p>= II llz- l(x,y)lz 
X IIYII 2 
</p>
<p>llxii 2 IIYII 2 -l(x,y)l 2 
</p>
<p>IIYII 2 
</p>
<p>(24) 
</p>
<p>and Schwarz's Inequality follows immediately by taking square roots in 
Equation (24). 
</p>
<p>Remark. As in the real case, our proof assumes that y =f 0. We leave it to the 
reader (see Exercise 13) to complete the proof for y = 0 and to verify that 
equality holds if and only if x and y are linearly dependent. 
</p>
<p>EXERCISES 
</p>
<p>1. Show that Equation (6) defines an inner product on C[a,b], the space of all 
continuous functions on the interval [a, b]. 
</p>
<p>2. Show that Equation (7) defines an inner product on C[a,b]. 
</p>
<p>3. Show that llxll 1 defined in Example 4 is a norm. 
</p>
<p>4. Show that llxlloo defined in Example 5 is a norm. 
</p>
<p>5. Show that llxiiP defined in Example 6 is a norm. 
</p>
<p>6. Show that llxlloo = lim llxllp&middot; 
</p>
<p>7. Show that llxll = lx1 1 + 2lx2 1 + 4lx3 1 is a norm on R3&bull; 
</p>
<p>8. Show that lx11 + lx2 1 + lx3 12 does not define a norm on R3 . 
</p>
<p>9. Show that elxd+lx21 does not define a norm on R 2 . 
</p>
<p>10. Show that Equation (11) defines a norm on C[a,b]. 
</p>
<p>525 </p>
<p/>
</div>
<div class="page"><p/>
<p>6 Sturm-Liouville boundary value problems 
</p>
<p>11. Let V be a real inner product space. Prove that 
</p>
<p>12. Let x x y be the vector with components 
</p>
<p>respectively. Show that x x y is perpendicular to both x and y under the inner 
product (x, y). 
</p>
<p>13. Complete the proof of Schwarz's Inequality in both R" and C" for the case y = 0. 
</p>
<p>14. Show that 
</p>
<p>(x,y + z) = (x,y) + (x,z) 
</p>
<p>for all vectors X, y, Z in C". 
</p>
<p>6.3 Orthogonal bases, Hermitian operators 
</p>
<p>It is often the case that a crucial step in the solution of many problems in a 
linear vector space revolves around ajudicious choice ofbasis. A type ofbasis 
that is especially useful is one that is orthogonal. 
</p>
<p>Definition. A set of vectors is said to be orthogonal if the inner product of any 
two distinct vectors in the set is zero. 
</p>
<p>One of the nice things about an orthogonal set of vectors is that they are 
automatically linearly independent. This is the content of Lemma 1. 
</p>
<p>Lemma 1. Let x1 , x2 , &bull;.. , xN be mutually orthogonal, that is, 
</p>
<p>(x;, x) = 0, i =1- j. 
</p>
<p>Then, x 1 , x 2 , ... ,xN are linearly independent. 
</p>
<p>PROOF. Suppose that 
</p>
<p>c1 x 1 + c2 x 2 + &middot; &middot; &middot; + cNxN = 0. (1) 
Taking inner products of both sides of Equation (1) with xi gives 
</p>
<p>c1 (x 1 ,x) + c2 (x2 ,xi) + ... + cN(xN,xi) = 0. (2) 
The left-hand side of Equation (2) reduces to ci(xi, x). Since (xi, xi) &gt; 0, we 
see that ci = 0, j = 1, 2, ... , N, which proves Lemma 1. 
</p>
<p>Another benefit of working with orthogonal bases is that it is relatively 
easy to find the Coordinates of a vector with respect to a given orthogonal 
basis. To wit, Iet u1 , u2 , ... , u. be a mutually orthogonal set ofvectors in a real 
n-dimensional vector space V. By Lemma 1, this set of vectors is also a basis 
</p>
<p>526 </p>
<p/>
</div>
<div class="page"><p/>
<p>6.3 Orthogonal bases, Hermitian operators 
</p>
<p>for V, and every vector x in V can be expanded in the form 
</p>
<p>(3) 
</p>
<p>Taking inner products of both sides of Equation (3) with oi gives &lt;x, oi) = 
ci&lt;oi, o) so that 
</p>
<p>j = 1, 2, ... , n. (4) 
</p>
<p>Example 1. Let V= R 2 and define &lt;x, y) = x 1y1 + x 2 y 2 &bull; The vectors 
</p>
<p>areorthogonal and, thus, form a basis for R 2&bull; Consequently, from Equations 
</p>
<p>(3) and (4), any vector x = (:J can also be written in the form 
</p>
<p>= x 1 + x 2 (1) x 1 - x 2 ( 1) 
2 1 + 2 -1 . 
</p>
<p>Given the benefit ofworking with orthogonal bases, the following question 
naturally arises: Does every n-dimensional Euclidean space have an ortho-
gonal basis? The answer to this question is a resounding yes and is given by 
the following theorem. 
</p>
<p>Theorem 3 (Gram-Schmidt). Every n-dimensional Euclidean space V has an 
orthogonal basis. 
</p>
<p>PROOF. Choose a basis o1, o2, ... , on for V. We will inductively construct an 
orthogonal basis v1 , v2, ... , vn by taking suitable combinations of the vectors 
ot&gt;&middot;&middot;&middot;&bull;on. Tothis end, Iet v1 = o1 and set 
</p>
<p>v2 = o2 + A.vl. (5) 
Taking the inner product of v 2 with v 1 gives 
</p>
<p>&lt;v2,v 1 ) = &lt;o2,v1 ) + A.&lt;v 1 ,v1 ) 
so that v2 will be orthogonal to v1 if A. = -&lt;o2,v1 )/&lt;v1 ,v1 ). Note that v2 
cannot equal 0 by virtue of the linear independence of the vectors o1 , ... , on. 
Proceeding inductively, Iet us assume that v1 , v2, ... , vk are mutually ortho-
</p>
<p>527 </p>
<p/>
</div>
<div class="page"><p/>
<p>6 Sturm-Liouville boundary value problems 
</p>
<p>gonal, and set 
</p>
<p>vk+l = uk+1 + l 1v1 + ... + lkvk. 
</p>
<p>The requirement that vk+1 be orthogonal to v 1 , ... , vk yields 
</p>
<p>0 = &lt;vk+l&bull; vj) = &lt;uk+l&bull; vj) + A.j&lt;vj, vj), 
which gives the desired relation 
</p>
<p>j = 1, ... ,k. 
</p>
<p>(6) 
</p>
<p>With this choice of 21 , ... , lk, the vectors v 1 , ... , vk, vk+l are mutually ortho-
gonal. Moreover, vk+1 cannot be 0 by virtue of the linear independence of 
u1 , ... , uk+1 . Proceeding inductively until k = n, we obtain n mutually ortho-
gonal nonzero vectors v 1 , .&bull;. , v n. 
</p>
<p>Remark 1. The procedure outlined in Theorem 3 is usually referred to as the 
Gram-Schmidt orthogonalization procedure. 
</p>
<p>Remark 2. lfu1 , &bull;&bull;. ,un is an orthogonal set ofvectors, and, in addition, each 
of the vectors uj has length 1, i.e., 
</p>
<p>llujll = &lt;uj, uj) 112 = 1, j = 1, ... , n, 
</p>
<p>then u1 , ... , un is called an orthonormal set of vectors. It is a simple matter to 
construct an orthonormal basis from an orthogonal one: if u1, ... , un is an 
orthogonal basis, then 
</p>
<p>ul 
Vl=~, 
</p>
<p>are orthonormal, since 
</p>
<p>Example 2. Let V be the space of all polynomials of degree n - 1, and define 
</p>
<p>&lt;J.g) = rl f(x)g(x)dx 
for all functions f and g in V. It is easily verified that V is an n-dimensional 
Euclidean space and that 
</p>
<p>fo(x) = 1, fn-1 (x) = xn-1 
</p>
<p>form a basis for V. Applying the Gram-Schmidt orthogonalization procedure 
to the functions / 0 (x), ... ,fn_1 (x) gives 
</p>
<p>P0 (x) = 1; 
</p>
<p>528 </p>
<p/>
</div>
<div class="page"><p/>
<p>where 
</p>
<p>so that 
</p>
<p>with 
</p>
<p>and 
</p>
<p>so that 
</p>
<p>6.3 Orthogonal bases, Hermitian operators 
</p>
<p>f1 xdx 
( ) , &lt;ft,Po) -1 
</p>
<p>Pt x = x + II. = x- (Po. Po)= x- =-f---,'1=-1-d-x = x; 
</p>
<p>2 1 
Pz(X) =X - 3' 
</p>
<p>-1 
</p>
<p>1 
</p>
<p>3 
</p>
<p>These polynomials p0 (x), p1 (x), p2 (x), p3(x), ... , when properly normalized, 
i.e., when multiplied by a suitable constant, are the Legendre Polynomials 
Pk(x) discussed in Chapter 2. 
</p>
<p>We now digress for a moment to discuss the following seemingly totally 
unrelated problem. Let V = cn with inner product 
</p>
<p>(x, y) = (x, y) = X1Y1 + XzYz + &middot; &middot; &middot; + XnYn 
where x 1 , ... , xn and y1 , ... , Yn are the Coordinates ofx and y, respectively, and 
</p>
<p>529 </p>
<p/>
</div>
<div class="page"><p/>
<p>6 Sturm-Liouville boundary value problems 
</p>
<p>Iet A be a given n x n matrixo Does there exist a matrix B such that 
</p>
<p>(A x, y) = (x, By) (7) 
</p>
<p>for all vectors x and y? 
To answer this question, we Iet A = (aii), B = (bii) and observe that 
</p>
<p>n ( n ) n 
(Ax, y) = i~ ;~ aiixi Yi = io~l ai;X;Yi 
</p>
<p>and 
</p>
<p>n ( n n 
(x, By) = L X; L b;iYi = L b;iX;h 
</p>
<p>i=l j=l i,j=l 
</p>
<p>Hence, Equation (7) is satisfied if and only if bii = aii or, equivalently, 
</p>
<p>(8) 
</p>
<p>Definition. The matrix B whose elements are given by Equation (8) is called 
the adjoint of A and is denoted by A*o If A* = A, then A is said to be 
selfadjoint or H ermitian, and 
</p>
<p>(Ax, y) = (x, Ay) for all x and yo 
</p>
<p>Remark 1. If Ais real, then A* is simply AT, the transpose of Ao Thus, if Ais 
real and symmetric, ioeo, A =AT, then Ais Hermitiano 
</p>
<p>Remark 2. It is a simple matter to show (see Exercise 6) that (A *)* = A and 
that 
</p>
<p>(x, Ay) = (A *x, y) for all x and yo 
</p>
<p>Example 3. Let 
</p>
<p>[
l+i 2 i l 
</p>
<p>A = 3 -i 1- i 
</p>
<p>i 2i 3i 
</p>
<p>Then, 
</p>
<p>[ 
1- i 
</p>
<p>A* = 2
0 
</p>
<p>-l 
</p>
<p>3 
-i l -2i 0 
-3i 1 + i 
</p>
<p>Example 4. Let 
</p>
<p>530 </p>
<p/>
</div>
<div class="page"><p/>
<p>6.3 Orthogonal bases, Hermitian operators 
</p>
<p>Then A* = AT= A. 
Seifadjoint matrices have several very important properties, which we now 
</p>
<p>wish to describe. 
</p>
<p>Property 1. Let A be selfadjoint and Iet x be an eigenvector of A with 
eigenvalue A. Since A is selfadjoint, (Ax, x) = (x, Ax), but 
</p>
<p>(Ax, x) = (h, x) = A(x, x), 
</p>
<p>while 
</p>
<p>(x, Ax) = (x, h) = X(x, x). 
</p>
<p>Hence, A =X. 
</p>
<p>Corollary. The eigenvalues of a real symmetric matrix are real. 
</p>
<p>Property 2. Let A be selfadjoint, and Iet ot and o2 be eigenvectors of A with 
eigenvalues At and A2 , respectively, with At # A2 &bull; Then, ot and o2 are 
orthogonal, i.e., (ot, o2 ) = 0. 
</p>
<p>PROOF. Observe first that 
</p>
<p>(Aot,o2 ) = (AtOt,o2 ) = At(ot,o2). 
</p>
<p>Since A is selfadjoint, 
</p>
<p>(Aot,o2 ) = (ot,Ao2 ) = (ot,A2 o2 ) = A2 (ot,o2 ) 
</p>
<p>since A2 is real. Hence, 
</p>
<p>(9) 
</p>
<p>and since At# A2 , Equation (9) now forces (ot,o2 ) = 0, which proves Prop-
erty 2. 
</p>
<p>In actuality, we can state a much stronger property than Property 2: Not 
only are the eigenvectors belonging to distinct eigenvalues of a selfadjoint 
matrix orthogonal, but every n x n selfadjoint matrix posesses a full comple-
ment ofn mutually orthogonal eigenvectors. This is the content ofProperty 3. 
</p>
<p>Property 3. Every n x n selfadjoint matrix A has n mutually orthogonal 
eigenvectors. 
</p>
<p>PROOF. Every matrix has at least one eigenvector. Let v t be an eigenvector of 
A with eigenvalue At, and Iet W be the subspace of V, which consists of all 
vectors in V that areorthogonal to v t&middot; We Ieave it to the reader to verify (see 
Exercise 7) that W is a linear subspace of V of dimension n - 1. The crucial 
observation now isthat A takes W into itself; i.e., if xisorthogonal to v 1 , then 
so is Ax. Butthis follows immediately from the observation that 
</p>
<p>(Ax,vt) = (x,A*vt) = (x,Avt) = (x,A1vd = At(x,vt)&middot; 
</p>
<p>531 </p>
<p/>
</div>
<div class="page"><p/>
<p>6 Sturm-Liouville boundary value problems 
</p>
<p>Thus, (x, vd = 0 =&gt; (Ax, vd = 0. 
The next part of our proof is a little tricky. Recall from Section 3. 7 that 
</p>
<p>every n X n matrix A induces a linear transformation ~ on cn(Rn) with 
</p>
<p>~ (x) = Ax. (10) 
</p>
<p>Conversely, every linear transformation ~ on cn(Rn) can be written in the 
form (10) for some appropriate matrix A. Let ~ be the linear transformation 
induced by A*. From the remarks above, ~ takes W into itself. Thus, assum-
ing that (see Exercise 8) every linear transformation that takes a vector space 
into itself has at least one eigenvector, we see that ~ has at least one eigen-
vector v2 in W; i.e., 
</p>
<p>~(v 2 ) = Av2 = A2 V2 
</p>
<p>for some number A.2 &bull; Proceeding inductively, that is, by considering the 
subspace of W perpendicular to v2 , we can produce n eigenvectors v1 , v2 , &bull;.&bull; , 
vn of A that are mutually orthogonal, and this completes the proof of 
Property 3. 
</p>
<p>Corollary. Every symmetric n x n matrix A has n mutually orthogonal eigen-
vectors. 
</p>
<p>At the beginning of this section we mentioned that orthogonal bases were 
often very useful in applications. In Chapter 3, we observed that a basis that 
consists of eigenvectors of a matrix A is also very useful since in this basis the 
matrix is diagonal. The ideal situation in practice is a basis of eigenvectors 
of a selfadjoint matrix A, for then we have the best of both worlds, i.e., 
the eigenvectors form an orthogonal basis. This is the real secret behind the 
famous Sturm-Liouville Theory to which we now turn our attention. 
</p>
<p>EXERCISES 
</p>
<p>1. Let V be the space of all polynomials of degree ~ 2 on the interval [- 2, 2], with 
inner product 
</p>
<p>&lt;f,g) = r2 x 2f(x)g(x)dx. 
Starting with the basis 1, x, and x2, use the Gram-Schmidt procedure to construct 
an orthonormal basis for V. 
</p>
<p>2. Let V be the space of all polynomials of degree &lt; n, on the interval [ a, b ], and define 
</p>
<p>&lt;J,g) = r r(x)f(x)g(x)dx. 
Use the Gram-Schmidt procedure to obtain an orthogonal basis for V in the case 
(a) (a, b) = ( -1, 1), r(x) = lxl 112 ; 
(b) (a, b) = ( -oo, oo ), r(x) = e -x. 
</p>
<p>532 </p>
<p/>
</div>
<div class="page"><p/>
<p>6.4 Sturm-Liouville theory 
</p>
<p>3. Obtain the first four Hermite polynomials by applying the Gram-Schmidt proce-
dure to the monomials 1, x, x 2 , and x\ with weight function r(x) = e-x212&bull; 
</p>
<p>4. Let V be the n-dimensional space spanned by the n functions e -kx, k = 0, 1, ... , 
n- 1, and Iet 
</p>
<p>(f, g) = [' f(x)g(x) dx 
</p>
<p>for f, g in V. Obtain an orthogonal basis for V. 
</p>
<p>5. Obtain the first four Laguerre polynomials by applying the Gram-Schmidt proce-
dure to the monomials 1, x, x 2 , and x3 , with weight function r(x) = e-x. 
</p>
<p>6. Show that (A *)* = A. 
</p>
<p>7. Show that the subspace W introduced in the proof of Property 3 has dimension 
n- 1. 
</p>
<p>8. Show that every linear transformation that takes a vector space into itself has at 
least one eigenvector. 
</p>
<p>6.4 Sturm-Liouville theory 
</p>
<p>In Chapter 5 we studied equations of the form 
</p>
<p>L[y](x) = y"(x) + Ay(x) = 0 
subject to the boundary conditions 
</p>
<p>a1y(O) + b1y'(O) = 0, 
</p>
<p>(1) 
</p>
<p>(1') 
</p>
<p>Equation (1) together with the boundary conditions (1') was referred to as a 
boundary value problem. We then stated a theorem to the effect that this 
boundary value problern has a nontrivial solution only for a special set of 
numbers 
</p>
<p>At &lt; Az &lt; A3 &lt; ... &lt; An &lt; ... 
</p>
<p>called eigenvalues and every differentiable function y(x) can be expanded in a 
series of these eigenfunctions, i.e., 
</p>
<p>00 
</p>
<p>y(x) = L c.y.(x), 0 &lt;X&lt;[. 
n=l 
</p>
<p>For example, the boundary value problern 
</p>
<p>y"(x) + Ay(x) = 0, y(O) = 0, y(l) = 0, (2) 
</p>
<p>has eigenvalues -1. = n2n2/l2 , with corresponding eigenfunctions 
</p>
<p>( ) . nnx Yn x = sm-1-, n = 1, 2, ... , 
</p>
<p>533 </p>
<p/>
</div>
<div class="page"><p/>
<p>6 Sturm-Liouville boundary value problems 
</p>
<p>and every differentiable function f(x) can be expanded in a Fourier series of 
the form 
</p>
<p>oo nnx 
y(x) = n~l cnsin-1-, &Uuml; &lt;X&lt; l. 
</p>
<p>The theorem we just stated is a special case of a much more general theorem, 
which applies to the more general equation 
</p>
<p>L[y](x) = a(x)y"(x) + b(x)y'(x) + c(x)y(x) = -A.r(x)y(x) (3) 
</p>
<p>and the boundary conditions 
</p>
<p>(3') 
</p>
<p>We can gain a lot of insight into this problern by studying it from a linear 
algebra point of view. To wit, let V be the space of all twice continuously 
differentiable functions. V is a linear vector space but is infinite dimensional, 
rather than finite dimensional. Next, define an inner product on V via the 
relation 
</p>
<p>(f,g) = r f(x)g(x)dx. (4) 
The operator L defined by 
</p>
<p>L[y] (x) = a(x)y"(x) + b(x)y'(x) + c(x)y(x) (5) 
</p>
<p>is a linear operator defined on V (see Section 2.1) and it is natural to ask 
whether L is selfadjoint in the sense that 
</p>
<p>(Lu, v) = (u, Lv) (6) 
</p>
<p>for all functions u, v in V. The answer to this question is given in Theorem 4. 
</p>
<p>Theorem 4. Let V be the space of all twice continuously differentiable functions 
on the interval [a, &szlig;]. Then, the operator L defined by Equation (5) is 
selfadjoint on V, in the sense of Equation (6), if and only if 
</p>
<p>b(x) = a'(x). (7) 
</p>
<p>PRooF. Computing 
</p>
<p>(Lu, v) = r [a(x)u"(x) + b(x)u'(x) + c(x)u(x)]v(x)dx 
and 
</p>
<p>(u,Lv) = r [a(x)v"(x) + b(x)v'(x) + c(x)v(x)]u(x)dx 
we see that 
</p>
<p>534 </p>
<p/>
</div>
<div class="page"><p/>
<p>6.4 Sturm-Liouville theory 
</p>
<p>(Lu, v)- (u, Lv) = r [a(x)v(x)u"(x) + b(x)v(x)u'(x)] dx 
-r [a(x)u(x)v"(x) + b(x)u(x)v'(x)] dx. 
</p>
<p>Integrating the terms containing u"(x) and v"(x) by parts gives 
</p>
<p>(Lu,v)- (u,Lv) =-r a(x)u'(x)v'(x)dx-r a'(x)v(x)u'(x)dx 
+ r b(x)v(x)u'(x)dx + r a(x)u'(x)v'(x)dx 
+ r a'(x)u(x)v'(x)dx-r b(x)u(x)v'(x)dx 
+ a(x)v(x)u'(x)l~- a(x)u(x)v'(x)l~ 
</p>
<p>= r [b(x)- a'(x)] [v(x)u'(x)- u(x)v'(x)] dx 
+ a(x)[v(x)u'(x)- u(x)v'(x)]~. 
</p>
<p>(8) 
</p>
<p>The boundary terms in Equation (8) are zero. To see this, assume that the 
constants b1 , b2 in Equation (3') are not zero (the proof is trivial if they are-
see Exercise 1), and set c1 = adb1 , c2 = a2 /b2 &bull; Then 
</p>
<p>a(x)[v(x)u'(x)- u(x)v'(x)]~ 
</p>
<p>= a(&szlig;)[v(&szlig;)u'(&szlig;)- u(&szlig;)v'(&szlig;)]- a(a)[v(a)u'(a)- u(a)v'(a)]; (9) 
</p>
<p>but 
</p>
<p>u'(&szlig;) = c2 u(&szlig;), v'(&szlig;) = c2 v(&szlig;), 
</p>
<p>since u(x) and v(x) satisfy the boundary conditions (3'). Hence, the right-hand 
side of Equation (9) becomes 
</p>
<p>a(&szlig;) [v(&szlig;)c 2 u(&szlig;) - u(&szlig;)c2 v(&szlig;)] - a(a) [v(a)c1 u(a) - u(a)c1 v(a)] = 0. 
</p>
<p>Thus, we have shown that 
</p>
<p>(Lu, v)- (u, Lv) = r [b(x)- a'(x)] [v(x)u'(x)- u(x)v'(x)] dx (10) 
for all u and v in V. The right-hand side ofEquation (10) is zero if b(x) = a'(x). 
Thus, L is certainly selfadjoint in the sense of Equation (6) if b(x) = a'(x). In 
addition, it is intuitively clear that b(x) = a'(x) is also a necessary condition 
for L tobe selfadjoint; the right-hand side of Equation (10) cannot vanish for 
all u and v in Vif b(x) =f. a'(x). A proof of this assertion is outlined in the 
exercises. 
</p>
<p>535 </p>
<p/>
</div>
<div class="page"><p/>
<p>6 Sturm-Liouville boundary value problems 
</p>
<p>In summary, the boundary value problern (3), (3') is self-adjoint if and only 
if b(x) = a'(x). Setting a(x) = p(x) and c(x) = -q(x), we can now write all 
selfadjoint boundary value problems in the canonical form 
</p>
<p>L[y](x) = [p(x)y'(x)]'- q(x)y(x) = -Ar(x)y(x) (11) 
</p>
<p>(11') 
</p>
<p>Equation (11) together with the boundary conditions (11') is often referred to 
as a Sturm-Liouville boundary value problem. 
</p>
<p>Remark 1. In the notation of Equation (11), Equation (8) becomes 
</p>
<p>(Lu,v)- (u,Lv) = -p(x)[u'(x)v(x)- u(x)v'(x)]~. (12) 
</p>
<p>Equation (12) is known as Lagrange's identity, and if u and v satisfy the 
boundary conditions (11'), then Lagrange's identity reduces to 
</p>
<p>(Lu, v) - (u, Lv) = 0. (13) 
</p>
<p>Remark 2. We have derived Equation (13) in the case that u and v are both 
real, because that is how Lagrange's identity is usually expressed. lt isasimple 
matter, however, to verify (see Exercise 3) that Equation (13) is also true for 
u and v complex, provided we define 
</p>
<p>(f,g) = f f(x)g(x)dx. (14) 
Definition. A Sturm-Liouville boundary value problern is said to be regular 
</p>
<p>if each of the following conditions hold: 
(i) r(x) &gt; 0 and p(x) &gt; 0 for x E [a, &szlig;]. 
</p>
<p>(ii) p(x), p'(x), q(x), and r(x) are continuous on [a, &szlig;]. 
(iii) (a, &szlig;) is finite. 
</p>
<p>W e are now ready to state and prove the main theorem of this chapter. 
</p>
<p>Theorem 5. For any regular Sturm-Liouville boundary value problem: 
(1) All the eigenvalues (and consequently all the eigenfunctions) are real. 
(2) Eigenfunctions belonging to different eigenvalues are orthogonal under 
</p>
<p>the inner product 
</p>
<p>&lt;f,g) = f r(x)f(x)g(x)dx. (15) 
(3) To each eigenvalue, there corresponds one, and only one, eigenfunc-
</p>
<p>tion. 
(4) There are a countably infinite number of eigenvalues A0 , A1 , A2 , ..&bull; with 
</p>
<p>corresponding eigenfunctions y0 (x), y1 (x), y 2 (x), ... . The eigenvalues An can 
be ordered so that n refers to the number of zeros of Yn in the interval [a, &szlig;]. 
</p>
<p>536 </p>
<p/>
</div>
<div class="page"><p/>
<p>6.4 Sturm-Liouville theory 
</p>
<p>In addition, the zeros of Yn+l interlace those of Yn&middot; Finally, A0 &lt; A1 &lt; 
A2 &lt; A3 &middot; &middot; &middot; with An~ oo as n ~ oo. 
</p>
<p>(5) Let f(x) be any continuously dif.ferentiable function on the interval 
[a, &szlig;]. Then, f(x) can be expanded in a convergent series of the eigenfunc-
tions of L; i.e., 
</p>
<p>00 
</p>
<p>f(x) = L anYn(x) 
n=O 
</p>
<p>where r r(x)f(x)yn(x)dx 
an= p . L r(x)y~(x)dx (16) 
</p>
<p>PROOF. (1) The proof of (1) follows immediately from the selfadjointness of L: 
if Ly = -Ay then 
</p>
<p>(Ly,y) = (-Ary,y) =-Ar r(x)!y2 (x)!dx (17) 
and 
</p>
<p>(y,Ly) = (y, -Ary) =-X r r(x)!y2 (x)!dx (18) 
since r(x) is real. Equating Equations (17) and (18), we see that A must be real. 
</p>
<p>(2) Let Yn(x) and Ym(x) be eigenfunctions of L with eigenvalues An and Am, 
respectively, with An #- Am. Then 
</p>
<p>(Lyn, Ym) = (- AnrYn, Ym) 
</p>
<p>= -An r r(x)yn(x)ym(x) dx; 
however, since L is selfadjoint, 
</p>
<p>= (Ym -AmrYm) 
</p>
<p>= -Am r r(x)yn(x)ym(x)dx, 
and since An #- Am, we see that 
</p>
<p>r r(x)yn(x)ym(x) dx = (Yn, Ym) = 0. 
(3) Suppose that u1 (x) and u2 (x) are two independent eigenfunctions 
</p>
<p>with eigenvalue A. Then both u1 and u2 satisfy the second-order differential 
</p>
<p>537 </p>
<p/>
</div>
<div class="page"><p/>
<p>6 Sturm-Liouville boundary value problems 
</p>
<p>equation 
</p>
<p>(p(x)y')'- q(x)y = -.A.r(x)y (19) 
</p>
<p>in addition to the boundary conditions 
</p>
<p>azy(&szlig;) + bzy'(&szlig;) = 0. (20) 
</p>
<p>Since u1 and u2 are independent, they form a basis for all the solutions of 
Equation (19), that is, every solution y(x) of Equation (19) can be written in 
the form 
</p>
<p>(21) 
</p>
<p>for some choice of constants c 1 , c2 . Finally, observe that if u1 (x) and u2 (x) 
satisfy the boundary conditions (20), then so does the linear combination (21). 
Hence, every solution of Equation (19) must satisfy the boundary conditions 
(20), which is clearly absurd. Thus, to each eigenvalue .A. of L, there cor-
responds only one eigenfunction. 
</p>
<p>(4) The proof of (4), though not very difficult, is quite long, so it will be 
omitted here. 
</p>
<p>(5) The convergence part of (5) is too difficult to present here. We wish to 
point out though, that if f(x) can be expanded in a series of the eigenfunctions 
Yn(x), i.e., 
</p>
<p>00 
</p>
<p>f(x) = L anYn(x) (22) 
n=O 
</p>
<p>then an must, of necessity, be given by Equation (16). To see this, assume that 
the series (22) is convergent and that the inner product of f with any function 
y(x) can be distributed, that is, 
</p>
<p>00 
</p>
<p>(J,y) = L an(Yn,y). 
n=O 
</p>
<p>If y(x) = yix), then Equation (23) reduces to 
</p>
<p>(f,y) = ai(yi,yi) 
</p>
<p>(23) 
</p>
<p>(24) 
</p>
<p>by virtue of the orthogonality of the eigenfunctions y0 (x), y1 (x), y2 (x), ... , and 
it now follows immediately from Equation (24) that 
</p>
<p>&lt;J,yj) r r(x)f(x)yj(x)dx 
a. = ~~- = ----,,-;;--~~~-
</p>
<p>1 (yj,yj) r r(x)yJ(x)dx (25) 
Part (5) of Theorem 5 deals with pointwise convergence, i.e., the series (22) 
</p>
<p>converges for each x in (a, &szlig;) if f(x) is continuously differentiable. A different 
type of convergence, which has proven quite useful in applications, is known 
as convergence in the mean. 
</p>
<p>538 </p>
<p/>
</div>
<div class="page"><p/>
<p>6.4 Sturm-Liouville theory 
</p>
<p>Definition. A sequence of functions fn(x), ot: &lt; x &lt; &szlig;, is said to converge in 
the mean to f(x) if 
</p>
<p>[f (J ]1/2 II!- fnll = a r(x)(f(x) - f"(x)) 2 dx 
approaches zero as n ~ 0. 
</p>
<p>Part (5) of Theorem 5 now has the following analogue in terms of mean 
convergence. 
</p>
<p>Theorem 6. Let 
</p>
<p>n 
</p>
<p>fn{x) = L aiyi(x) 
j=O 
</p>
<p>(26) 
</p>
<p>where ai is given by Equation (25). Then, fn(x) converges to f(x) in the mean 
for all functions f(x) with 
</p>
<p>r r(x)jl(x) dx &lt; 00, 
i.e., for all functions f(x) with finite norm. 
</p>
<p>Example 1. Consider the Sturm-Liouville boundary value problern 
</p>
<p>L[y] = y" = -A.y, y'(O) = 0, y'(1) = 0. 
</p>
<p>Here p(x) = r(x) = 1 and q(x) = 0. lt is easily verified that 
</p>
<p>Y = Yn(x) = cos mrx, n = 0, 1, 2, ... , 
</p>
<p>(27) 
</p>
<p>are the nontrivial solutions, i.e., eigenfunctions, of Equation (27), with cor-
responding eigenvalues 
</p>
<p>n = 0, 1, 2, .... 
</p>
<p>Parts (1)-(3) of Theorem 5 are trivial to verify and, in fact, have been done 
already in Chapter 5. The zeros of Yn(x) are located at the n points 
</p>
<p>1 3 5 2n- 1 
</p>
<p>and it is easily verified that the zeros of Yn+l interlace those of Yn&middot; For example, 
the four zeros -k, i, i, and i of y4 (x) interlace the three zeros i, i, ~ ofy3(x) since 
</p>
<p>1 1 3 3 5 5 7 
-&lt;-&lt;-&lt;-&lt;-&lt;-&lt;-
8 6 8 6 s 6 s&middot; 
</p>
<p>Finally, part (5) of Theorem 5 is simply Fourier's Theorem of Section 5.4. 
Let us return now to the Hermite, Legendre, Tchebycheff, and Laguerre 
</p>
<p>differential equations 
</p>
<p>539 </p>
<p/>
</div>
<div class="page"><p/>
<p>6 Sturm-Liouville boundary value problems 
</p>
<p>y" - xy' + A.y = 0, 
</p>
<p>(1 - x 2)y"- 2xy' + A.(A. + 1)y = 0, 
(1 - x 2)y"- xy' + A.2y = 0, 
</p>
<p>xy" + (1 - x)y' + A.y = 0, 
</p>
<p>-00 &lt;X&lt; 00, 
</p>
<p>-1 &lt;X&lt; 1, 
</p>
<p>-1 &lt;X&lt; 1, 
</p>
<p>0 &lt;X&lt; 00, 
</p>
<p>(28) 
</p>
<p>(29) 
</p>
<p>(30) 
</p>
<p>(31) 
</p>
<p>respectively. Except for the Legendre equation (29), the coefficient of y' in 
each ofthese equations is not the derivative ofthe coefficient of y". We remedy 
this situation by multiplying through by an appropriate integrating factor 
(see Section 1.2). Then we can rewrite Equations (28)-(31) in the equivalent 
form 
</p>
<p>d 
L[y] (x) = dx e-x212 y'(x) = -A.e-x212 y(x), -oo &lt; x &lt; oo, (28') 
</p>
<p>d 
L[y](x) = d)1- x2 )y'(x) = -A.(A. + 1)y(x), -1 &lt; x &lt; 1, (29') 
</p>
<p>- d 2 t/2 ' - - A. 2 0') L[y](x)-dx(1-x) y(x)-(1-x2 ) 112 y(x), -1&lt;x&lt;1, (3 
</p>
<p>d 
L[y](x) = dx xe-xy'(x) = -A.e-xy(x), 0 &lt; x &lt; 00. (31') 
</p>
<p>Indeed, we can now begin to understand the presence of the factor r(x) in the 
Sturm-Liouville problern 
</p>
<p>L[y](x) = -A.r(x)y(x). 
</p>
<p>Our next step is to determine what boundary conditions should be im-
posed on the solutions ofEquations (28)-(31). Tothis end, observe that none 
ofthe Equations (28')-(31') are regular in the sense ofthe definition preceding 
Theorem 5. To wit, the functions 
</p>
<p>p(x) = 1 - x 2 and p(x) = (1 - x2 ) 1 i 2 
</p>
<p>for the Legendre and Tchebycheff equations vanish at the end points -1 and 
+ 1 (which in a limiting sense is also true for the functions e-x212 and xe-x, 
which occur in the Hermite and Laguerre equations), and the interval (ct, &szlig;) 
for both the Hermite and Laguerre equations is not finite. 
</p>
<p>Let us return now to our proof ofTheorem 4 where we derived the relation 
</p>
<p>(Lu,v)- (u,Lv) = -p(x)[u'(x)v(x)- u(x)v'(x)]~. (32) 
</p>
<p>For the Operators L appearing in Equations (28)-(31), the integrals appearing 
in the left-hand sides of Equation (32) may now have to be considered as 
improper integrals. In the case of the Legendre and Tchebycheff equations, 
the function p(x) vanishes at the end points. Thus, L will certainly be self-
adjoint if we impose the boundary conditions that y'(x) [and hence y(x), see 
Exercise 12] is bounded as x--+ &plusmn; 1. In the case of the Hermite equation, we 
</p>
<p>540 </p>
<p/>
</div>
<div class="page"><p/>
<p>6.4 Sturm-Liouville theory 
</p>
<p>require that 
</p>
<p>lim e-x212 [u(x)v'(x)- u'(x)v(x)] = 0. (33) 
x--+&plusmn;oo 
</p>
<p>In the case of the Laguerre equation, p(x) vanishes at x = 0. Thus, one 
boundary condition is that y'(x) [and hence y(x)] is bounded as x-+ 0. The 
second boundary condition is determined from the requirement that 
</p>
<p>lim xe-x[u(x)v'(x)- u'(x)v(x)] = 0. (34) 
x--+oo 
</p>
<p>Finally, we note that the conditions (33) and (34) translate into the boundary 
conditions 
</p>
<p>lim e-x212 y(x) = 0 and lim xe-xy(x) = 0 
x--+&plusmn;oo x--+oo 
</p>
<p>for the Hermite and Laguerre equations, respectively. 
lt is interesting to note (but difficult to prove) that the boundary conditions 
</p>
<p>imposed on the solutions of Equations (28)-(31) are exactly sufficient to force 
the power series solutions of these equations to terminate at a finite point. In 
other words, the only solutions of Equations (28)-(31) that satisfy our bound-
ary conditions are the Hermite, Legendre, Tchebycheff, and Laguerre poly-
nomials, respectively; or, in the language oflinear algebra, the only nontrivial 
solutions of the equation 
</p>
<p>L[y](x) = -Ar(x)y(x) 
</p>
<p>for the operators L in Equations (28')-(31') and the boundary condi-
tions discussed above are the eigenfunctions Yn(x) with eigenvalues An, and 
these eigenfunctions, when properly normalized, are the Hermite, Legendre, 
Tchebycheff, and Laguerre polynomials, respectively. 
</p>
<p>Remark. Wehave imposed boundary conditions on Equations (28)-(31) to 
ensure that the respective operators L are selfadjoint. This will guarantee that 
parts (1) and (2) of Theorem 5 are true. More generally, parts (1) and (2) of 
Theorem 5 are true even for singular Sturm-Liouville problems, but parts 
(3)-(5) may sometimes fail to be true, even though they are true for the 
Hermite, Legendre, Tchebycheff, and Laguerre equations. 
</p>
<p>We conclude this section by proving that the only nontrivial solutions of 
the Hermite equation 
</p>
<p>y"- 2xy' + AY = 0 or (e-x 212y')' = -Ae-x212y (35) 
</p>
<p>satisfying the boundary conditions 
</p>
<p>(36) 
x-+&plusmn;oo 
</p>
<p>are the Hermite polynomials Hn(x), which are the polynomial solutions ofthe 
equation 
</p>
<p>y" - 2xy' + 2ny = 0. 
</p>
<p>541 </p>
<p/>
</div>
<div class="page"><p/>
<p>6 Sturm-Liouville boundary value problems 
</p>
<p>In other words, all nonpolynomial solutions of Equation (35) fail to satisfy 
the boundary conditions (36). Tothis end we set 
</p>
<p>00 
</p>
<p>y(x) = L anxn. 
n=O 
</p>
<p>Computing 
</p>
<p>00 00 
</p>
<p>y'(x) = L nanxn-l and y"(x) = L n(n- l)anxn- 2 
n=O n=O 
</p>
<p>and plugging into Equation (35) yields 
</p>
<p>00 00 00 
</p>
<p>L (n + 2)(n + 1)an+2xn- L 2nanxn + L A.anxn = 0. 
n=O n=O n=O 
</p>
<p>This, in turn, implies that 
</p>
<p>(2n- A.) 
(37) 
</p>
<p>an+2 = (n + 2)(n + 1) an. 
</p>
<p>For the moment, Iet us set a 1 = 0 and a0 = 1. Then Equation (37) forces all 
the odd coefficients a 3 , a5 , &bull;&bull;&bull; , tobe zero. Next, observe that 
</p>
<p>For large n, 
</p>
<p>2 (n- A./2) 
an+2 = (n + 2) (n + 1) an. 
</p>
<p>(n - A./2) ::::: 1. 
(n + 1) 
</p>
<p>Thus, for n &gt; N sufficiently large, 
</p>
<p>Next, Iook at 
</p>
<p>where 
</p>
<p>Then, 
</p>
<p>542 
</p>
<p>2 
an+2 ~ --2(.9)an, 
</p>
<p>n+ 
</p>
<p>00 
</p>
<p>z(x) = L bnxn 
n=O 
</p>
<p>n&gt;N. 
</p>
<p>2 
bn+2 = --2 (.9)bn and b0 = 1. n+ 
</p>
<p>2 1 
b2 = -2(.9) = ,(.9) 
</p>
<p>1. 
</p>
<p>(38) 
</p>
<p>(39) 
</p>
<p>(40) </p>
<p/>
</div>
<div class="page"><p/>
<p>6.4 Sturm-Liouville theory 
</p>
<p>23 3 1 3 
b6 = 2. 4&middot; 6 (.9) = 3!(.9) 
</p>
<p>and 
</p>
<p>( ) - 1 (.9) 2 (.9)2 4 (.9)3 6 .&bull;&bull; 
z x - + lfx + 2!x + 3!x + 
</p>
<p>(.9x2) (.9x2)2 (.9x2)3 
=1+-1!-+~+~+&middot;&middot;&middot; 
</p>
<p>It is clear from Equations (39) and (40) that for A. #- 2n (so that an+ 2 is never 0) 
</p>
<p>y(x) ~ PN(x) + e&middot;9" 2 
</p>
<p>for some appropriate polynomial PN(x) of degree N. But then 
</p>
<p>lim e-x2f2y(x) = lim [e-x2J2PN(x) + e&middot;4"2] = oo. 
x-+&plusmn;co 
</p>
<p>Hence, the only way y(x) can satisfy the boundary condition (36) is if A. = 2n, 
so that its series terminates. 
</p>
<p>The case a0 = 0, a 1 = 1 is similar, and we leave it as an exercise for the 
reader (see Exercise 13). 
</p>
<p>EXERCISES 
</p>
<p>1. Show that the boundary terms in Equation (8) are trivially zero if either b1 or b2 
is zero. 
</p>
<p>2. Here is the outline of a proof that L [see Equation (3)] is not selfadjoint if 
b(x) # a'(x). Observe first that if b(x) # a'(x) and we can choose u and v so that 
</p>
<p>v(x)u'(x)- u(x)v'(x) = b(x)- a'(x), 
</p>
<p>then the integral in Equation (10) reduces to 
</p>
<p>I: [b(x) - a'(x)]2 dx # 0. 
The only problern isthat u and v have to satisfy the boundary conditions (3'). To 
modify the proof, 
(a) Observe that 
</p>
<p>v(x)u'(x) - u(x)v'(x) = v2 (x) ( ~ )'. 
</p>
<p>(b) Choose u, v, and constants c1 , c3 , ... , ck+1 (with k tobe determined) so that 
</p>
<p>(~)' =c1 [b(x)-a'(x)]+c3 [b(x)-a'(x)] 3 +c5 [b(x)-a'(x)] 5 + &middot;&middot;&middot;, 
</p>
<p>543 </p>
<p/>
</div>
<div class="page"><p/>
<p>6 Sturrn-Liouville boundary value problerns 
</p>
<p>u and v satisfy the boundary conditions (3'), and the integral in Equation (10) 
</p>
<p>is *0. 
</p>
<p>3. Show that Equation (13) is true even for u, v cornplex. 
</p>
<p>4. Show that Liouville's transforrnation 
</p>
<p>z 
y=---~ 
</p>
<p>(p(x)r(x))1' 4 ' 
</p>
<p>reduces Equation (11) to 
</p>
<p>t'(x) = (rW 
..jp(X) 
</p>
<p>z" - f(t)z = - J.z. 
</p>
<p>What is f(t)? Note that under this transforrnation, the eigenvalues rernain fixed 
and the weight function becornes unity. 
</p>
<p>5. Let P.(x) be the Legendre polynornial of degree n. 
(a) Show that P~(x) satisfies a selfadjoint equation with). = n(n + 1) - 2. 
</p>
<p>(b) Show that r
1 
</p>
<p>P~(x)P~(x)(1- x 2 )dx = 0, m * n. 
</p>
<p>6. Find the eigenvalues and eigenfunctions of the boundary value problern 
</p>
<p>y(1) = 0, y(2) = 0. 
</p>
<p>(Hint: Try y = xP.) 
</p>
<p>In each of Problems 7-9, find the eigenvalues and eigenfunctions of the given 
boundary value problem. 
</p>
<p>7. y" + ).y = 0; 
</p>
<p>8. y" + ).y = 0; 
</p>
<p>y(O) = 0, y(n) - y'(n) = 0 
</p>
<p>y(O)- y'(O) = 0, y(1) = 0 
</p>
<p>9. y" + ).y = 0; y(O)- y'(O) = 0, y(n)- y'(n) = 0 
</p>
<p>10. For which values of). does the boundary value problern 
</p>
<p>y" - 2y' + (1 + J.)y = 0, y(O) = 0, y(1) = 0, 
</p>
<p>have a nontrivial solution? 
</p>
<p>11. Show that the singular boundary value problern 
</p>
<p>y" + A.y = 0, y(O) = y(2n), y'(O) = y'(2n), 
</p>
<p>has a continuurn of eigenvalues. 
</p>
<p>12. Suppose that y'(O) is bounded as x-+ &plusmn; 1. Show that y(x) rnust also be bounded as 
x-+ &plusmn; 1. [Hint: Write y(x) as an integral involving y'(x).] 
</p>
<p>13. Let a0 = 0 and a1 = 1. Show that the power series solution I:=o a.x&bull; of Equation 
(35), with a. deterrnined frorn Equation (37), will not satisfy the boundary condi-
</p>
<p>tions (36) unless the series terrninates, i.e., ). = 2n for sorne integer n. 
</p>
<p>544 </p>
<p/>
</div>
<div class="page"><p/>
<p>Appendix A 
</p>
<p>Some simple facts concerning functions 
of several variables 
</p>
<p>1. A functionj(x,y) is continuous at the point (x0,y0) if for every e&gt;O 
there exists &lt;5 ( e) such that 
</p>
<p>if(x,y)-j(xo,Yo)l&lt;e if lx-xoi+IY-Yol&lt;&lt;5(e). 
</p>
<p>2. The partial derivative of f(x,y) with respect to x is the ordinary de-
rivative of f with respect to x, assuming that y is constant. In other words 
</p>
<p>3. (a) A function f(x 1, ... ,xn) is said to he differentiahte if 
</p>
<p>where el[i&szlig;xd + ... + i&szlig;xniJ approaches zero as l&lt;lx 11 + ... + i&szlig;xnl ap-
proaches zero. (h) A functionj(x 1, ... ,xn) is differentiahte in a region R if 
aj I axl,".' aj I axn are continuous in R. 
</p>
<p>4. Let J= f(x 1, ... ,xn) and xj = gj(y 1, ... .Ym), j = 1, ... ,n. If fand g are 
differentiahle, then 
</p>
<p>This is the chain rule of partial differentiation. 
</p>
<p>545 </p>
<p/>
</div>
<div class="page"><p/>
<p>Appendix 
</p>
<p>5. If all the partial derivatives of order two of f are continuous in a re-
gion R, then 
</p>
<p>a2J a2J 
axjaxk = axkaxj; 
</p>
<p>j,k= l, ... ,n. 
</p>
<p>6. The general term in the Taylor series expansion of f about x 1 = 
0 - 0. 
</p>
<p>X I , &bull;&bull;. , Xn - Xn lS 
</p>
<p>aJ, + ... + inJ(xo xo) 
---:-...::..._,.-:- _____ ~&gt;_&middot; &middot;_&middot; '_n_ ( o)J' ( o)i" 
--; I . I . . X I - X I . . . Xn - Xn &bull; 
1i ... &middot;ln&middot; ax-( 1 &bull;&bull;&bull; ax~&middot; 
</p>
<p>546 </p>
<p/>
</div>
<div class="page"><p/>
<p>Appendix B 
</p>
<p>Sequences and series 
</p>
<p>I. A sequence of numbers an, n =I, 2, ... is said to converge to the Iimit 
a if the numbers an get closer and closer to a as n approaches infinity. 
More precisely, the sequence (an) converges to a if for every e &gt; 0 there ex-
ists N ( e) such that 
</p>
<p>la-anl&lt;e ifn;;;.N(e). 
</p>
<p>2. Theorem 1. If an~a and bn~b, then an&plusmn;bn~a&plusmn;b. 
</p>
<p>PROOF. Let e&gt;O be given. Choose N 1(e),Nie) suchthat 
</p>
<p>la-anl&lt;l forn;;;.N1 (e), and lb-bnl&lt;l forn;;;.N2 (e). 
</p>
<p>Let N(e)=max{N1(e),Nie)}. Then, for n;;;. N(e), 
</p>
<p>I an&plusmn; bn -(a&plusmn; b)l ~I an- ai +Ibn- bl &lt;1 + l =e. 0 
</p>
<p>3. Theorem 2. Suppose that an+!;;;. an, and there exists a number K suchthat 
I an I~ K, for all n. Then, the sequence (an) has a Iimit. 
</p>
<p>PROOF. Exactly the same as the proof of Lemma I, Section 4.8. 0 
</p>
<p>4. The infinite series a 1 + a2 + ... = L an is said to converge if the 
sequence of partial sums 
</p>
<p>has a Iimit. 
</p>
<p>547 </p>
<p/>
</div>
<div class="page"><p/>
<p>Appendix 
</p>
<p>5. The sum and difference of two convergent series are also convergent. 
This follows immediately from Theorem 1. 
</p>
<p>6. Theorem 3. Let an ;;.. 0. The series ~ an converges if there exists a number 
K such that a1 + ... +an ' K for all n. 
</p>
<p>PROOF. The sequence of partial sums sn = a1 + ... +an satisfies sn+ 1 ;;.. sn. 
Since sn ' K, we conclude from Theorem 2 that ~ an converges. D 
</p>
<p>7. Theorem 4. The series ~an converges if there exists a number K such 
that la11 + ... +I an I' K for all n. 
</p>
<p>PROOF. From Theorem 3, ~ lanl converges. Let bn =an+ lanl&middot; Clearly, 
0' bn '2lanl&middot; Thus, ~ bn also converges. This immediately implies that the 
series 
</p>
<p>also converges. D 
</p>
<p>8. Theorem 5 (Cauchy ratio test). Suppose that the sequence I an+ 1/ an I has 
a Iimit A.. Then, the series ~ an converges if A. &lt; 1 and diverges if A. &gt; 1. 
</p>
<p>PROOF. Suppose that "A&lt; 1. Then, there exists p&lt; I, and an index N, such 
that I an+ 11 'plan I for n;;.. N. This implies that laN+pl 'pPiaNI&middot; Hence, 
</p>
<p>N+K K laNI 
~ lani,(I+p+ ... +p )laNI'-I -, 
</p>
<p>n=N -p 
</p>
<p>and ~ an converges. 
If "A&gt; I, then laN+pl;;.. pPiaNI, with p &gt; 1. Thus lani-HlO as n-H~J. But I an I 
</p>
<p>must approach zero if ~an converges tos, since 
</p>
<p>lan+II = lsn+l- snl' lsn+l -sl + lsn- sl 
and both these quantities approach zero as n approaches infinity. Thus, 
</p>
<p>~ an diverges. D 
</p>
<p>548 </p>
<p/>
</div>
<div class="page"><p/>
<p>Appendix C 
</p>
<p>C Programs 
</p>
<p># include (stdio.h) 
# include (math.h) 
</p>
<p>int main( ) 
{ 
</p>
<p>double X[200] = {1}; 
intk,N=15; 
</p>
<p>C Program 1 
</p>
<p>printf(" N%10sX[N]\n"," "); 
</p>
<p>} 
</p>
<p>for (k=O; k&lt;=N; k+ +) 
{ 
</p>
<p>} 
</p>
<p>printf("%4d%4s%17.91f\n", k," ", X[k]); 
X[k + 1] = 0.25 +sin(X[k]); 
</p>
<p>549 </p>
<p/>
</div>
<div class="page"><p/>
<p>Appendix 
</p>
<p>C Program 2 
</p>
<p>:#= include (stdio.h) 
</p>
<p>int main( ) 
{ 
</p>
<p>} 
</p>
<p>double X[200]={1.4}; 
int k, N=5; 
</p>
<p>printf(" N%10sX[N]\n"," "); 
for (k=O; k&lt;=N; k+ +) 
</p>
<p>{ 
</p>
<p>} 
</p>
<p>printf("%4d%4s%17.91f\n", k," ",X[k]); 
X[k+ 1] =X[k]/2+ 1/X[k]; 
</p>
<p>C Program 3 
</p>
<p>:#= include (stdio.h) 
:#= include (math.h) 
</p>
<p>int main( ) 
{ 
</p>
<p>} 
</p>
<p>double a, d, V[200] = {45.7}; 
double c=0.08, g=32.2, W=527.436, 8=470.327; 
int k, N=15; 
</p>
<p>a=(W-B)/c; 
d =300* c * g/W; 
printf(" N%10sX[N]\n"," "); 
for (k=O; k&lt;=N; k+ +) 
</p>
<p>{ 
</p>
<p>} 
</p>
<p>printf("%4d%4s%17.91f\n", k," ", V[k]); 
V[k + 1] = V[k] + ((a- V[k])/V[k]) 
</p>
<p>* (V[k] + d + a * log(1- (V[k]/a))); 
</p>
<p>550 </p>
<p/>
</div>
<div class="page"><p/>
<p>C Program 4 
</p>
<p>* include (stdio.h) * include (math.h) 
int main( ) 
{ 
</p>
<p>double T[1000]={0}, Y[1000]={0.5}, a=1, h; 
int k, N=10; 
</p>
<p>h=a/N; 
for (k=O; k&lt;N; k+ +) 
</p>
<p>{ 
T[k+ 1] =T[k] +h; 
Y[k + 1] = Y[k] + h &bull; (1 + pow(Y[k]- T[k], 2.0)); 
</p>
<p>} 
printf("%4s%16s\n", "T", "Y"); 
for (k=O;k&lt;=N;k++) 
</p>
<p>printf("%10.71f%2s%16.91f\n", T[k]," ", Y[k]); 
</p>
<p>C Program 5 
</p>
<p>* include (stdio.h) * include (math.h) 
int main( ) 
{ 
</p>
<p>} 
</p>
<p>doubleT[1000]={0}, Y[1000]={0.5}, a=1, h; 
intk,N=10; 
</p>
<p>h=a/N; 
for (k=O; k&lt;N; k++) 
</p>
<p>{ 
</p>
<p>} 
</p>
<p>T[k+1]=T[k]+h; 
Y[k+ 1] = Y[k] + h &bull; (1 + pow(Y[k]- T[k], 2.0)) 
</p>
<p>+ h &bull; h &bull; pow(Y[k]- T[k], 3.0); 
</p>
<p>printf("%4s%16s\n", 'T", "Y"); 
for (k=O; k&lt;=N; k++) 
</p>
<p>printf("%10.71f%2s%16.91f\n", T[k]," ", Y[k]); 
</p>
<p>Appendix 
</p>
<p>551 </p>
<p/>
</div>
<div class="page"><p/>
<p>Appendix 
</p>
<p>C Program 6 
</p>
<p>=#= include (stdio.h) 
=#= include (math.h) 
</p>
<p>int main( ) 
{ 
</p>
<p>} 
</p>
<p>double T[1000] = {0}, Y[1000] = {0.5}, a = 1, h, R; 
intk,N=10; 
</p>
<p>h=a/N; 
for (k=O; k&lt; N; k+ +) 
</p>
<p>{ 
</p>
<p>} 
</p>
<p>R = 1 + pow(Y[k]- T[k], 2.0); 
T[k+ 1] = T[k] + h; 
Y[k+ 1] = Y[k] + {h/2) &bull; (R+ 1 
</p>
<p>+ pow(Y[k] + h &bull; R- T[k+ 1], 2.0)); 
</p>
<p>printf("%4s%16s \n", "T", "Y"); 
for (k=O; k&lt;=N; k++) 
</p>
<p>printf("%10.71f%2s%16.91f\n", T[k]," ", Y[k]); 
</p>
<p>C Program 7 
</p>
<p>=#= include (stdio.h) 
=#= include (math.h) 
</p>
<p>int main( ) 
{ 
</p>
<p>} 
</p>
<p>double T[1000] = {0}, Y[1000] = {0.5}, a = 1, h; 
double LK1, LK2, LK3, LK4; 
intk,N=10; 
</p>
<p>h=a/N; 
for (k = 0; k &lt; N; k + +) 
</p>
<p>{ 
</p>
<p>} 
</p>
<p>T[k+ 1] =T[k] +h; 
LK1 = 1 + pow(Y[k]- T[k], 2.0); 
LK2 = 1 + pow((Y[k] + (h/2) &bull; LK1)- (T[k] + h/2), 2.0); 
LK3= 1 + pow((Y[k] + (h/2) &bull; LK2)- {T[k] + h/2), 2.0); 
LK4= 1 + pow((Y[k] + h &bull; LK3)- (T[k] + h), 2.0); 
Y[k+ 1] =Y[k] +(h/6) &bull; (LK1 +LK4+2 &bull; (LK2+LK3)); 
</p>
<p>printf("%4s%16s\n", "T", "Y"); 
for (k=O; k&lt;=N; k++) 
</p>
<p>printf("%10.71f%2s%16.91f\n", T[k]," ", Y[k]); 
</p>
<p>552 </p>
<p/>
</div>
<div class="page"><p/>
<p>C Program 8 
</p>
<p>4f include &lt;stdio.h) 
4f include &lt;math.h) 
</p>
<p>int main( ) 
{ 
</p>
<p>double T[1000]={0}, Y[1000]={0}, a=1, h; 
int k, N=10; 
</p>
<p>h=a/N; 
for (k=O; k&lt;N; k++) 
</p>
<p>{ 
T[k+1]=T[k]+h; 
Y[k + 1] = Y[k] + h * (Y[k] * (1 + exp(- Y[k])) + exp(T[k])); 
</p>
<p>} 
printf("%4s%10s%20s\n", "N", "h", "Y[N]"); 
printf("%4d%2s%10.71f%20.101f\n", N," ", h, Y[N]); 
</p>
<p>C Program 9 
</p>
<p>4f include &lt;stdio.h) 
4f include &lt;math.h) 
</p>
<p>int main( ) 
{ 
</p>
<p>} 
</p>
<p>double T[1000]={0}, Y[1000]={0}, a=1, h; 
double DY1, DY2; 
intk,N=10; 
</p>
<p>h=a/N; 
for (k=O; k&lt;N; k++) 
</p>
<p>{ 
T[k+1]=T[k]+h; 
DY1 = 1 + (1- Y[k]) * exp(- Y[k]); 
DY2 = Y[k] * (1 + exp(- Y[k])) + exp(T[k]); 
Y[k+ 1] =Y[k] +h * DY2+ (h * h/2) * (exp(T[k])+DY1 * DY2); 
</p>
<p>} 
printf("%4s%10s%20s\n", "N", "h", "Y[N]"); 
printf("%4d%2s%10.71f%20.101f\n", N," ", h, Y[N]); 
</p>
<p>Appendix 
</p>
<p>553 </p>
<p/>
</div>
<div class="page"><p/>
<p>Appendix 
</p>
<p>C Program 10 
</p>
<p># include (stdio.h) 
# include (math.h) 
</p>
<p>int main( ) 
</p>
<p>{ 
</p>
<p>} 
</p>
<p>double T[1000) = {0}, Y[1000) = {0}, a= 1, h; 
</p>
<p>double R1, R2; 
intk,N=10; 
</p>
<p>h=a/N; 
for (k=O; k&lt;N; k++) 
</p>
<p>{ 
</p>
<p>} 
</p>
<p>T[k+1)=T[k)+h; 
R1 = Y[k) &bull; (1 + exp(- Y[k])) + exp(T[k]); 
</p>
<p>R2 = (Y[k) + h &bull; R1) &bull; (1 + exp(- (Y[k) + h &bull; R1))) + exp(T[k + 1]); 
</p>
<p>Y[k + 1) = Y[k) + (h/2) &bull; (R1 + R2); 
</p>
<p>printf("%4s%10s%20s\n", "N", "h", "Y[N]"); 
</p>
<p>printf("%4d%2s%10.71f%2s%18.101f\n", N," ", h," ", Y[N]); 
</p>
<p>C Program 11 
</p>
<p># include (stdio.h) 
# include (math.h) 
</p>
<p>int main( ) 
{ 
</p>
<p>double T[1000) = {0}, Y[1000) = {0}, a = 1, h; 
double LK1, LK2, LK3, LK4; 
</p>
<p>int k, N=10; 
</p>
<p>h=a/N; 
for (k=O; k&lt; N; k+ +) 
</p>
<p>{ 
T[k+1]=T[k]+h; 
LK1 = Y[k) &bull; (1 + exp(- Y[k])) + exp(T[k]); 
</p>
<p>LK2=(Y[k] +(h/2) &bull; LK1) &bull; (1 +exp( -(Y[k] +(h/2) &bull; LK1))) 
</p>
<p>+ exp(T[k] + (h/2)); 
LK3=(Y[k) +(h/2) &bull; LK2) &bull; (1 +exp( -(Y[k]+(h/2) &bull; LK2))) 
</p>
<p>+ exp(T[k] + (h/2)); 
LK4= (Y[k) +h &bull; LK3) &bull; (1 +exp( -(Y[k) +h &bull; LK3))) 
</p>
<p>+ exp(T[k + 1]); 
</p>
<p>554 </p>
<p/>
</div>
<div class="page"><p/>
<p>Appendix 
</p>
<p>} 
</p>
<p>Y[k + 1] = Y[k] + (h/6) &bull; (LK1 + 2 &bull; LK2 + 2 &bull; LK3 + LK4); 
} 
</p>
<p>printf("%4s%10s%20s\n", "N", "h", "Y[N]"); 
printf("%4d%2s%10.71f%2s%18.101f\n", N," ", h," ", Y[N]); 
</p>
<p>C Program 12 
</p>
<p>#= include &lt;stdio.h) 
#= include &lt;math.h) 
</p>
<p>int main( ) 
{ 
</p>
<p>} 
</p>
<p>double T[1000] = {0}, Y[1000] = { 1 }, a= 1, h; 
double LK1, LK2, LK3, LK4; 
intk,N=10; 
</p>
<p>h=a/N; 
for(k=O;k&lt;N;k++) 
</p>
<p>{ 
</p>
<p>} 
</p>
<p>T[k+1]=T[k]+h; 
LK1 = T[k] &bull; T[k] + Y[k] &bull; Y[k]; 
LK2 = pow(T[k] + h/2, 2.0) + pow(Y(k] + (h/2) &bull; LK1, 2.0); 
LK3 = pow(T[k] + h/2, 2.0) + pow(Y[k] + (h/2) &bull; LK2, 2.0); 
LK4 = pow(T[k] + h, 2.0) + pow(Y[k] + h &bull; LK3, 2.0); 
Y[k+ 1] = Y[k] + (h/6) &bull; (LK1 +2 &bull; LK2 +2 &bull; LK3+ LK4); 
</p>
<p>printf("%4s%15s\n", "T", "Y"); 
for (k=O; k&lt;=N; k++) 
</p>
<p>printf("%10.71f%2s%16.91f\n", T[k]," ", Y[k]); 
</p>
<p>C Program 13 
</p>
<p>#= include &lt;stdio.h) 
#= include &lt;math.h) 
</p>
<p>#=define Pl3.141592654 
</p>
<p>int main( ) 
{ 
</p>
<p>double T[1000], Y[1000], h; 
int k, N=25; 
</p>
<p>h = 2.0/(double) N; 
T[1]=h; 
</p>
<p>555 </p>
<p/>
</div>
<div class="page"><p/>
<p>Appendix 
</p>
<p>} 
</p>
<p>Y[1)=0; 
for (k= 1; k&lt;N; k++) 
</p>
<p>{ 
</p>
<p>} 
</p>
<p>T[k+1]=T[k)+h; 
if (Y[k) = = 0) Y[k + 1) = h &bull; T[k) &bull; sin (PI/T[k]); eise 
Y[k + 1) = Y[k) + h &bull; (Y[k) &bull; pow(fabs(Y[k]), -0.75) 
</p>
<p>+ T[k) &bull; sin (PI/T[k])); 
</p>
<p>printf("%4s%15s\n", "T", "Y"); 
for (k= 1; k&lt;=N; k++) 
</p>
<p>printf("%10.71f%2s%16.91f\n", T[k]," ", Y[k]); 
</p>
<p>C Program 14 
</p>
<p>* include (stdio.h) * include (math.h) 
int main( ) 
{ 
</p>
<p>} 
</p>
<p>double A[200) = {1, 1}, T=0.5, sum; 
int k, N=20; 
</p>
<p>A[2) = -0.5 &bull; (A[1) + A[O]); 
sum = A[O] +A[1) &bull; T +A[2) &bull; T &bull; T; 
for (k = 1; k &lt; = N-2; k + +) 
</p>
<p>{ 
</p>
<p>} 
</p>
<p>A[k + 2) = ((k + 1) &bull; (k-1) &bull; A[k + 1)-A[k) +A[k-1]) 
/((k+ 1) * (k+2)); 
</p>
<p>sum =sum +A[k+2) &bull; pow(T, (double)(k+2)); 
</p>
<p>printf("For N = o/od and T = %6.41f\ n", N, T); 
printf("the sum is: % 11.91f\n", sum); 
</p>
<p>556 </p>
<p/>
</div>
<div class="page"><p/>
<p>Answers to 
</p>
<p>odd-numbered 
</p>
<p>exerctses 
</p>
<p>Chapter 1 
</p>
<p>SECTION 1.2 
</p>
<p>1. y(t)= ce-&bull;int 3. y(t)= t+ c 5. y(t)=exp(- -jt3)[Jexp(-jt3)dt + c] 
l + 12 
</p>
<p>c + f (I+ 12)1/2(1 + 14)1/4 dl 
7. y(l)= 9. y(t)=exp(- ( 0 '~ e-sds) (1+12)1/\1+14)1/4 J~ 
</p>
<p>ll. y(t) = 3e'~ -I 13. y(t)=e-'[2e+ J.' -s ds] 
1 l +s 
</p>
<p>17. y(l)= { 2(1- e-'), 
2(e-l)e- 1, 
</p>
<p>21. Each solution approaches a distinct Iimit as 1~0. 
</p>
<p>23. All solutions approach zero as I~'TT /2. 
</p>
<p>SECTION 1.3 
</p>
<p>3. 127,328 5. (a) N238(t)=N238(0)2_ 10-&bull;'f4&middot;5 ;(b) N235(t)=N235(0)2_ 10- 91/.?f17 
</p>
<p>7. About 13,550 B.c. 
</p>
<p>SECTION 1.4 
</p>
<p>1. (I)= t+c 
Y I-et 3. y(t)=tan(t-tt
</p>
<p>2 +c) 5. y(t)=arcsin(csint) 
</p>
<p>[ ( l + 12)] I 2 1.y(t)= 9+2ln - 5- , -oo&lt;t&lt;oo 
</p>
<p>557 </p>
<p/>
</div>
<div class="page"><p/>
<p>Answers to odd-numbered exercises 
</p>
<p>9. y(t)= 1-[4+2t+2t2+t3]112, -2&lt; t&lt; 00 
</p>
<p>a2kt -1 . 
ll.y(t)= l+akt' lik&lt;t&lt;oo,Ifa=b 
</p>
<p>ab[1-ek(b-a)l] 1 a 
</p>
<p>y(t)= a-bek(b-a)l , k(b-a) lnb&lt;t&lt;oo; a=Fb 
</p>
<p>ct2 t 2-l 
13. (b) y(t)= - t and y(t)= 1_ ct 15. y(t)= - 2-
</p>
<p>17. y= c2e- 2Vrjy, t &gt;0; y =- c2e2Vrjy, t&lt;O 
</p>
<p>21. (b) j(b + c)(at + by) +an+ bml = ke(b+c)(al-cy) 
23. (t+2y)2 -(t+2y)=c-1t 
</p>
<p>SECTION 1.5 
</p>
<p>3. a&gt;0.4685 
</p>
<p>7. (a) dp =0.003 -0.001 2-0.002&middot; (b) (t)= 1,999,998-999,998e-O.OOII 
dt 'P p ' p 999,999-999,998e-0&middot;0011 ' 
</p>
<p>p(t)~2 as t~oo 
</p>
<p>SECTION 1.6 
</p>
<p>NecN1 
</p>
<p>1. p(t)= N 1 cNI 
- +e 
</p>
<p>SECTION 1.7 
</p>
<p>1. V(t)= W-B[I-e&lt;-cg/W)I] 
c 
</p>
<p>V322(1- Je )+1 
7. V(t)= V322 &deg; , [ 
</p>
<p>/(, e&lt;64A)(I-5)/v'322 +I l 
Koe(64.4)(1-5)/v'322 -1 
</p>
<p>Ko=-------
</p>
<p>V322(1- Je )-1 
9. (a) VV- Wo+ mg In mg-cVV 
</p>
<p>c mg-cWo 
</p>
<p>dv -gR 3 ,~ 
11. (a) vdy = 2 ; (b) V0 = v2gR 
</p>
<p>(y+R) 
</p>
<p>SECTION 1.8 
2In5 
</p>
<p>3. In2 yrs. 7. (a) c(t)=I-e-0&middot;0011 ; (b) IOOOin~ min. 
</p>
<p>9. c(t)=~(l-e-0.021)+ ~~ e-o.021 11. 48% 13. xy=c 
</p>
<p>15. x 2+y2 =cy 17. y 2(lny2-I)=2(c-x2) 
</p>
<p>558 </p>
<p/>
</div>
<div class="page"><p/>
<p>Answers to odd-numbered exercises 
</p>
<p>SECTION 1.9 
</p>
<p>3. 12 siny + y 3e' = c 5. y tan 1 +sec 1 + y2 = c 7. y(l) = 1-213 
</p>
<p>9. y(t) = - 12 + Yl4 - (1 3 - I) 11. ~~ + Hf:?y 2) = 10 
[ 
</p>
<p>1(2t-l)] 1/2 
13. a= -2; y(l)= &plusmn; 
</p>
<p>2(l+ct) 
19. a = 1; y(t) = arc sin[(c- l)e'] 
</p>
<p>SECTION 1.10 
</p>
<p>14 {6 12n 
l.yn(t)=t2+-2f +-31 + ... +----,-. . n. 
</p>
<p>1 + e2' 
3.y 1(1)=e'-l; y 2(t)=t-e'+-2-
</p>
<p>- 107 I 12 _f3 ' ( 1 + t)e2' e3' e4' 
y 3(t)-- 48 + 4 + 2 + 3 +2(l- l)e + 2 -3 + 16 
</p>
<p>12 
19. y(t)=sin 2 
</p>
<p>SECTION 1.11 
</p>
<p>3. (a)O&lt;x0 &lt;10 5. 1.48982 7. (c) 0.73909 
</p>
<p>Section 1.11.1 
</p>
<p>5. 0.61547 7. 0.22105 9. 1.2237 
</p>
<p>SECTION 1.12 
</p>
<p>1. Yn =( -7t- &plusmn;[{ -7t -1] 
</p>
<p>SECTION 1.13 
</p>
<p>1. h=O.l,y 10 =1; h=0.025,y40 =l 
</p>
<p>3. h=O.l,y 10 =1; h=0.025,y40 =l 
</p>
<p>1 [ 24 &middot;] 7. Yzs= 25 1+ ~ 21 
j=l 
</p>
<p>5. h=O.l,y 10 =1.80516901; h=0.025,y40 =1.94633036 
</p>
<p>Section 1.13.1 
</p>
<p>1. Ek&lt;. 32h(e4/5_l) 
4(10- 5) 
</p>
<p>5. h&lt;. --2-
3(e -I) &middot; 
</p>
<p>SECTION 1.14 
</p>
<p>1. h=O.l,y 10 =1; h=0.025,y40 =l 
</p>
<p>5. h=O.l,y 10 =2; h=0.025,y40 =2 
</p>
<p>3. h=O.l,y 10 =1; h=0.025,y40 =I 
</p>
<p>559 </p>
<p/>
</div>
<div class="page"><p/>
<p>Answers to odd-numbered exercises 
</p>
<p>SECTION 1.15 
</p>
<p>1. h=O.l,y 10 =I; h=0.025,y40 =I 3. h=O.l,y 10 =I; h=0.025,y40=I 
</p>
<p>S. h=O.l,y10 =1.98324929; h=0.025,y40 =1.99884368 
</p>
<p>SECTION 1.16 
</p>
<p>1. h =0.1, y 10 = I; h =0.025, y 40= I 3. h=O.l, y 10 = I; h =0.025, y 40= I 
</p>
<p>S. h=O.l,y 10 =1.99997769; h=0.025,y40 =1.9999999 
</p>
<p>SECTION 1.17 
</p>
<p>1. 2.4103 3. 0.0506 s. 0.4388 
</p>
<p>Chapter 2 
</p>
<p>SECTION 2.1 
</p>
<p>1. (a) (4-31)e 1; (b) 3V3 lsinv'3 1; (c) 2(4-31)e 1 +I2V3 lsinv'3 1; 
</p>
<p>(d) 2-312; (e) 5(2-312); (f) 0; (g) 2-312 
</p>
<p>S. (b) W= 2-p;2 ; (d)y(I)=2Vt 
7. (a) -(bsinatsinbt+acosatcosbl); (b) 0; (c) (b-a)e&lt;a+b)t; (d) e201; (e) 1; 
</p>
<p>(f) - be2a1 
</p>
<p>I 
l3.W=t 
</p>
<p>SECTION 2.2 
</p>
<p>1. y(l)=clet+c2e-t 3. y(l)=e3t/2[ cleYs t/2+c2e-Ys t/2] 
</p>
<p>s. y(I)=He4t+4e-t) 1. y(l)= YJ e-t/2[ e3Ys t/IO_e-3Yst/IO] 
9. V;;;. -3 11. y(t)=c1t+c2/t5 
</p>
<p>Section 2.2.1 
</p>
<p>1 ( ) -t/2[ V3 t . V3 I ] &bull; y 1 =e c1cos-2- +c2sm-2-
</p>
<p>3. y(t)=e-1(c 1cosv'2 t+c2 sinV2 t) 
</p>
<p>S. y(l)=e 1 cos---- sm---/2[ v'7 t 3 . v'7 I] 
2 v'7 2 
</p>
<p>9.y(l)=e&lt;t- 2&gt;13 cos ---sin----=---[ 
VIT (1-2) 4 VIT (1-2)] 
</p>
<p>3 vrr 3 
11. y 1(1)=coswl,yil)=sinwl 
</p>
<p>560 </p>
<p/>
</div>
<div class="page"><p/>
<p>Answers to odd-numbered exercises 
</p>
<p>+(1+i) +1 '~-
15. Vi = - ; VT+i = --=-- [ V V'2 + 1 + j V V'2 - 1 ] 
</p>
<p>V'2 V'2 
&plusmn; ( 1 - i) ' r:r. , vC7 = V'2 ; vYi =&plusmn;[YV'2 -1 +iYV'2 +1 J. (Vi =ei"'/4 ) 
</p>
<p>19.y(t)= Jt [c1cos v; lnt+c2sin v; lnt] 
Section 2.2.2 
</p>
<p>I. y(t)=(c1 + c2t)e3' 3. y(t)=(1 + tt)e-'13 7. y(t) = 2(t- 'll")e2&lt;'-."&gt;13 
11. y(t) = (c1 + c2t)e 12 13. y(t) = c1t + c2(t2 - 1) 15. y(t) = c1(t + 1) + c2e2' 
</p>
<p>c1+c21nt 
17. y(t)=c1(1 +3t)+c2e3' 19. y(t)= 1 
</p>
<p>SECTION 2.3 
</p>
<p>I. y(t)=c1+c2e2'+t2 
</p>
<p>SECTION 2.4 
</p>
<p>I. y(t)=(c1 + lncost)cost +(c2 + t)sint 
</p>
<p>3. y(t)= c1e'l2 +[c2 +9t- 2t2 + * t3]e' 
S. y(t)= 1J(2cost -3sint)e-'- e-' + ~e- 1 1 3 
</p>
<p>(' c2 t21nt 7. y(t)= Jo v'S+f [e2&lt;t-&bull;&gt;-e&lt;t-s&gt;]ds' 9. y(t)=clrl+ t + -3-
</p>
<p>11. y(t)=vt [ c1+c2 lnt+ fo'Fv's coss[lnt-lns]ds] 
</p>
<p>SECTION 2.5 
</p>
<p>I. !JI(t)= t3 -;t-1 
</p>
<p>7. !JI(t)= -fot[sin2t- 2tcos2t] 9. !JI(t)= t + 1J-&lt;cos2t -4sin2t) 
- 1 . ( t 1 ) te2' 11. !JI(t)= so&lt;cost+ 7smt)+ 2- 5 5 13. IJ!(t)= t(e2'- e') 
</p>
<p>15. IJ!(t)= --focos3t+~tsint 
</p>
<p>17. (b) IJ!(t)=0.005 + 32 .~. 018 (15 sin 30t- 20,000cos30t)+ .!f sin lOt 
</p>
<p>SECTION 2.6 
</p>
<p>I. Amplitude =!, period = t'IT, frequency = 8 
7. a;;.&szlig;, where [1+(1-&szlig;)2]e- 2&szlig;=I0-6 
</p>
<p>561 </p>
<p/>
</div>
<div class="page"><p/>
<p>Answers to odd-numbered exercises 
</p>
<p>e-&lt;r-") [( 1 ('rr+ 1) ) 7T ] 
9. y(1)= --2- i + - 2-e-" cos(t-1r)+ 2 e-"sin(1-7T) 
</p>
<p>11. 7T /2 seconds 
</p>
<p>Section 2.6.2 
</p>
<p>3. Q(1)= 1 1 ~ 6 [ 1- ( cos500V3 + ~ sin500V3 )e- 500 ] 
3 
</p>
<p>Steady state charge = 250,000 
</p>
<p>-(-1 _Ir_)l/2 
7. w- -LC 2Lz 
</p>
<p>SECTION 2.8 
</p>
<p>00 (-1)n1zn+l 
1 ( ) _ - r2 /2 + "' 
.y t -aoe ain7:_o3&middot;5 ... (2n+1) 
</p>
<p>[ 3t
2 3t4 3t6 3&middot;3t8 3&middot;3&middot;51 10 ] ( 13 ) 3.y(l)=a0 1+-2 +----6-+-8-- 10 + ... +a1 1+-3 2 24&middot;2! 2 &middot;3! 2 &middot;4! 2 &middot;5! 
</p>
<p>00 
</p>
<p>5. y(1)= ~ (n+ 1)(t-1)2n 
n=O 
</p>
<p>16 111 116 
1.y(l)=- 2[t+S-6+ 5&middot;6&middot;10&middot;11 + 5&middot;6&middot;10&middot;11&middot;15&middot;16 + ... ] 
</p>
<p>Atz A(4-A)t4 A(4-A)(8-A)t6 
9.(a)y 1(1)=1-2f- 4! - 6! + ... 
</p>
<p>13 15 17 
(b) y 2(t)= 1+(2-A) 3! +(2-A)(6-A) 5! +(2-A)(6-A)(10-A) ?! + ... 
</p>
<p>2 12 2 2 2 14 
11. (a) y 1(t)= 1-a 2! -a (2 -a) 4! 
</p>
<p>6 
</p>
<p>- a2(2z- a2)(42- a2) ~! + ... 
</p>
<p>- 2 2 13 2 2 2 2 15 yit)-t+(1 -a ) 3! +(1 -a )(3 -a ) 5! + ... 
</p>
<p>l3. (a) y(t)= 1- t t2 - i t3 + i4 t4 + ... (b) y{t)R:j0.8592436 
15. (a) y(t)= 1- t12 - il 3 + ~1 4 + ... (b) y(t)R:j0.86087198 
17. (a)y(1)=3+51-41 2 +13 -t14 + ... (b)y{t)R:j5.3409005 
</p>
<p>Section 2.8.1 
</p>
<p>1. y(t) = c11 + c2 jt 5 
</p>
<p>3. y(t) = c1(t -1)+ c2(t -1) 2 
</p>
<p>5. y(t) = t( c1 + c21n t) 
</p>
<p>7. y(t) = c1cos(ln t)+ c2 sin(1n t) 
</p>
<p>562 </p>
<p/>
</div>
<div class="page"><p/>
<p>Answers to odd-numbered exercises 
</p>
<p>9. y(t) == _t_ [t~3- _1 ] 
2/3 tl3 
</p>
<p>SECTION 2.8.2 
</p>
<p>1. Yes 3. Yes 5. No 
</p>
<p>C1 ( t 2 t3 t 4 ) 7 y(t)==- 1-t-------- ... 
. t 2! 3&middot;3! 3&middot;5&middot;4! 
</p>
<p>( t2 ) ( t t2 t
3 ) 9. y(t)==c1 1+2t+- +c2t112 1+-+-2--- 3 + &middot;&middot; &middot; 3 2 2 &middot;2!&middot;5 2 &middot;3!&middot;5&middot;7 
</p>
<p>( t2 t4 t6 ) y(t)==t-112 1----- - ... 
2 2 2&middot;4 2&middot;4&middot;6&middot;8 
</p>
<p>2 t 5 t 7 t 9 
15. YI(t)==e'j2,yz(t)==t3+5+5-1+ 5&middot;7&middot;9 + ... 
</p>
<p>1 1 -r 
17. y 1(t)==t-l,y2(t)==t[e -(1-t)] 
</p>
<p>19. (e)y2(t)==t 3e-'Je; dt 
t 
</p>
<p>( 4t
2 5t3 6t 4 ) 
</p>
<p>21. (b) YI(t)==t 2-3t+2f-3f+4f &middot;&middot;&middot; 
</p>
<p>(C)Yz(t)==yl(t)j ~-t dt 
Y1 ( t) 
</p>
<p>f dt 23. (c) Yz(t)==J0(t) tJ~(t) 
</p>
<p>25. (b) y(t)==I-~-,\ (l-.\)t 2 + &middot;&middot; &middot; 
(1!)2 (1!)2(2!)2 
</p>
<p>+ (-.\)(1-.\)&middot;&middot;&middot;(n-1-.\)tn+ ... 
( n !)2 
</p>
<p>563 </p>
<p/>
</div>
<div class="page"><p/>
<p>Answers to odd-numbered exercises 
</p>
<p>4t3 (4 
27. (b) y 1(t) = 1+2t + t 2 + lS + l4 + &middot; &middot; &middot; 
</p>
<p>) - 1/2[1 + 5t + 17t2 + 89t 3 + 941t 4 + ... ] 
Y2(t -t 6 60 (60)(21) (36)(21)(60) 
</p>
<p>SECTION 2.8.3 
</p>
<p>1. yJ(t) =I +4t +4t 2 + &middot; &middot; &middot; 
yz(t) =y1(t)lnt- [ 8t+l2t2 + 1 ;~ t 3 + ... ] 
</p>
<p>3 (b) J(t)=lt ~ (-lrr2n 
&bull; 1 2 n~O 22n(n + l)!n! 
</p>
<p>(c) Y2(t)=-JI(t)lnt+.!. 1- ~ - 2 n n t 2n [ 
oo ( Ir ( H + H- I ] 
</p>
<p>t n=l 2 nn!(n-1)! 
</p>
<p>SECTION 2.9 
</p>
<p>1 s-a 
1. 2 3. 2 
</p>
<p>s (s-a) +b2 
</p>
<p>7 .!.[ a+b + a-b ] 
&bull; 2 s2+(a+ b)2 s2+ (a- b)2 
</p>
<p>9.Vf 
</p>
<p>SECTION 2.10 
</p>
<p>3. 
2as 
</p>
<p>'TT s s-b 
7. (a) -2 -arctans; (b) In ; (c) ln-Vs2+a2 s-a 
</p>
<p>. cos -- --sm -- e 11 [ h V57 t + 3 &middot; h V57 I ] 3tj2 
2 V57 2 
</p>
<p>19. y(t)=cosl +% sin t -j tcost 
</p>
<p>23. y(t)=l+e- 1 +[ cos YJ 1 - ..Js sin YJ 1 ]e- 112 
</p>
<p>564 </p>
<p/>
</div>
<div class="page"><p/>
<p>Answers to odd-numbered exercises 
</p>
<p>SECTION 2.11 
</p>
<p>1. y(t)=(2+3t)e- 1 +2H3(t)[ {t-5)+{t-l)e-&lt;1 - 3&gt;J 
</p>
<p>3. y(t)=3cos2t -sin2t + W -cos2t)- H l-cos2{t -4))Hit) 
</p>
<p>5. y(t)=3cost -sint + ~~ sint + ~ H"1it)[ (t- ~w) sint -cost J 
</p>
<p>7.y(t)=J...[{7t-l)+(cos VY!t --13-sin VY!t)e- 112 
49 2 VYi 2 
</p>
<p>-H2(t)(7t-I)-H2(t) 13cosv'27 - 2 -[ 
- (t-2) 
</p>
<p>. VYi (t-2)] - l + VYf sm 2 e (1- 2&gt;/Z 
9. y(t)= te 1 + H 1(t)[ 2 + t +(2t- 5)e1- 1 J- H2(t)[ I+ t + (2t -7)e 1 - 2 ] 
</p>
<p>SECTION 2.12 
</p>
<p>3. (a) y(t) =(cosh ~ t- 3 sinh ~t)e 31 1 2 - 2H2(t)sinh }(t- 2)e3&lt;1 - 2&gt;12 
</p>
<p>5. y(t) = t(sin t- t cos t)- H"(t)sint 
</p>
<p>7. y(t) = 3te -t + ~ t2e -t + 3H3(t)(t- 3)e -(t-J) 
</p>
<p>SECTION 2.13 
</p>
<p>9. -!tsint 
</p>
<p>3. a sinat- bsinbt 
a2-b2 
</p>
<p>11. (t- 2) + (t + 2)e -t 
</p>
<p>17. y(t)=!sint+(I-%t)e- 1 
</p>
<p>SECTION 2.14 
</p>
<p>sin at - at cos at 
5&middot; 2a 
</p>
<p>13. y(t)=t+%sin2t 
</p>
<p>1. x(t)=c1e31 +3c2e41 , y(t)=c 1e31 +2c2eq' 
</p>
<p>7. t-sint 
</p>
<p>15. y(t)= !t2 
</p>
<p>3. x(t)= [(c1 + c2) sin t + (c1 - cz) cos t]e- 21,y(t) = [c 1 cos t + c2 sin t]e- 21 
5. x(t)=;je3t+~e-t, y(t)=ie3t_ie-t 
</p>
<p>7. x(t)=cost e- 1, y(t)=(2cost+sint)e- 1 
</p>
<p>9. x(t)=2(tcost+3tsint+sint)e1, y(t)= -2tsint e1 
</p>
<p>11. x(t)= -4sint- ttsint- tcost + 5cost ln(sect + tant), 
y(t)= - tsint- tcost- t sin2 tcost- 5sintcost+ 5 sin2 t 
</p>
<p>- t sin3 t + 5(cost-sint)ln(sect+ tant) 
</p>
<p>SECTION 2.15 
</p>
<p>I. y(t)=c1e 1+c2e- 1+c3e21 3. y(t)=(c1+c2t+c3t2)e21 +c4e-t 5. y(t)=O 
</p>
<p>7. y(t)=-3-2t- !t2 +(3- t)e 1 9. l{.t(t) = 1-cost -lncost -sintln(sect + tant) 
</p>
<p>565 </p>
<p/>
</div>
<div class="page"><p/>
<p>Answers to odd-numbered exercises 
</p>
<p>11. IJI{t)= - 1- fl[sin{t-s)/Yl cosh(t-s)/Yl 
V2 Jo 
</p>
<p>-cos(t-s)/Yl sinh(t-s)/Yl ]g(s)ds-
</p>
<p>13. !Ji(t)= it(e- 21 -1)- t sint 15. IJI{t)= it2[ 0- tt)cost + H + -kt -fit2) sint] 
17. !Ji{t)=t-1+tte- 1 
</p>
<p>Chapter 3 
</p>
<p>SECTION 3.1 
</p>
<p>l. Xt =x2 
x2=x3 
x3= -xi 
</p>
<p>7.x=(_i ~)x, x(3)=(~) 
x3=x4 
x4= I-x3 
</p>
<p>15. A=( t t) 
-2 4 
</p>
<p>SECTION 3.2 
</p>
<p>1. Yes 3. No 5. No 7. Yes 9. No 11. Yes 
</p>
<p>SECTION 3.3 
</p>
<p>1. Linearly dependent 3. Linearly independent 
</p>
<p>5. (a) Linearly dependent; (b) Linearly dependent 
</p>
<p>7. (b)y 1(t)=e 1, yit)=e- 1 9. p 1{t)=t-l, P2(t)=t2-6 
</p>
<p>17. Xt=Yt 
</p>
<p>1 
x2= V2 (y2-YJ) 
</p>
<p>1 
X3= Yl (Y2+Y3) 
</p>
<p>SECTION 3.4 
</p>
<p>1. x1(t)= [
cos\13 t/2 e- 112 l 
( -tcosv'3 tj2-~v'3 sinv'3 t/2)e- 112 
</p>
<p>x2{t)= [
sin V3 t/2 e- 112 l 
{tcos\13 t/2-tsin V3 t/2)e- 112 
</p>
<p>566 </p>
<p/>
</div>
<div class="page"><p/>
<p>Answers to odd-numbered exercises 
</p>
<p>3. x1(t)=( 0,). x2(t)=( e' ) 5. Yes 7. Yes 9. No 11. (b) No e 2te 1 
</p>
<p>SECTION 3.5 
</p>
<p>3. -48 5. 0 7. -97 11. No solutions 
</p>
<p>SECTION 3.6 
</p>
<p>1. AB=( ~ 
2 
</p>
<p>25) es 52 0 7 10 , BA= 5 -I 10 6 12 10 18 
3. AB=O 
</p>
<p>l 
</p>
<p>1).BA=O 
2 
</p>
<p>D 2 l l l 
1 ( -3 5 9) . ( 2i 0 -2i) 
</p>
<p>9. 72 1~ -6 18 11. i 1-2i -1 -l+i 
14 -18 l-2i 1 1 +i 
</p>
<p>. ( 0 -2i 0) 
13. i -: l 1-i 
</p>
<p>-1 -1-i 
</p>
<p>SECTION 3.7 
</p>
<p>7. No solutions 9. x= ( g) 11 . .\= l, -1 
</p>
<p>13. (a).\=-1; (b)x=i( -b)+c( =f) 
SECTION 3.8 
</p>
<p>&bull;. x(t)=c&middot;(De 3 '+c2(~)e 4 ' 3. x(t)=c&middot;( -~)e-'+c2( _ne-'+c3(&Uuml;e8' 
</p>
<p>~ 1\1)-&middot;&middot;( J)&middot;-&middot;~+m+&middot;,m ]&middot;" 
567 </p>
<p/>
</div>
<div class="page"><p/>
<p>Answers to odd-numbered exercises 
</p>
<p>SECTION 3.9 
</p>
<p>1 x( t) = [ c ( 2 ) + c ( 2 sin t ) ] e- 21 
&bull; 1 1-sint 2 cost+sint 
</p>
<p>3. x(t)=e 1[c&bull;( -~)+c 2 (c?~2t)+c 3 ( s~n2t)] 
3 sm2t -cos2t 
</p>
<p>5 x{t)=( cost )e-1 
&middot; 2cost+sint 
</p>
<p>( 
2) [-V2 sinV'i t-V'i cosV'i tl 
</p>
<p>7. x(t)= -2 e- 21 + cos V2 t- V2 sin V2 t 
1 -3cos V2 t 
</p>
<p>9. x(O) = ( ~:) 
</p>
<p>SECTION 3.10 
</p>
<p>&bull;. x(t)- &bull;&bull; m.~&middot;+m+&middot;,W J&middot;~&middot; 
</p>
<p>). x(t)- &bull;&bull; m.~&middot;+[ .,m+&middot;,( -n J&middot;~&middot; 
( 
1- t) 
</p>
<p>7. x(t)= : e21 
</p>
<p>[ 
7e 1- 5e21 + se-I 
</p>
<p>13. (b) /0 2Ie1- 5e21 -16e-1 
</p>
<p>14e' + 10e21 -24e- 1 
</p>
<p>15. I+ !.(e"1 -1) 
a 
</p>
<p>SECTION 3.11 
</p>
<p>- e1+ 5e21 - 4e-1 3e1- 5e21 -2e-1] 
-3e 1+ 5e21 + se-I 9e 1- 5e21 -4e-l 
-2e'-10e2' + 12e-' 6e' + 10e2'-6e- 1 
</p>
<p>1 [ e-21+5e21_e31 5e21_5e31 
1. 5 _ e-21 + e31 5e31 
</p>
<p>4e- 21 _ 5e21 + e31 _ 5e21 + 5e31 
</p>
<p>568 </p>
<p/>
</div>
<div class="page"><p/>
<p>Answers to odd-numbered exercises 
</p>
<p>1 [6e 21 -cost-2sint 
3. 5 3e21 -3cost-sint 
</p>
<p>5sint 
</p>
<p>- 2e21 + 2cost +4 sint 
- e21 +6cost + 2sint 
</p>
<p>-lOsint 
</p>
<p>2e21 - 2cost +sintl 
e21 - cost + 3sint 
</p>
<p>5cost 
</p>
<p>[ (t+IV' (t+ 1)e-
1-e-21 _, _" l e -e 
</p>
<p>S. -te-l -te-l+ e-21 e-21_ e-1 
</p>
<p>te- 1 te- 1 e-1 
</p>
<p>7. A=O 
1 
</p>
<p>-1) 1 c6 -25 3 -1 9. A=TI ~ -6 
3 -1 13 
</p>
<p>SECTION 3.12 
</p>
<p>1. x(t)= 2 e~( tcost + 3ts~nt +sint) 
-tsmt 
</p>
<p>30) -24 
26 
</p>
<p>-4sint- ttsint- tcost + 5 costln(sect + tant) 
</p>
<p>3. x(t)= 
- tsint- tcost+sintcos2 t- t sin2 tcost 
</p>
<p>-5 sintcost + 5 sin2 t- t sin3 t 
</p>
<p>+ 5(cost- sint) ln(sect + tant) 
</p>
<p>SECTION 3.13 
</p>
<p>1. x(t)=e-1G)+e41( -~) 
</p>
<p>3. x(t)=- ~U)e- 1 + i(i)e21 + l(?)-t( D+3( De1 
</p>
<p>ll.No 
</p>
<p>7. x(t)= 2 e~(tcost+3ts~nt+sint) 
-tsmt 
</p>
<p>{ 
( cos2t.+sin2t ), 
</p>
<p>9. x(t)= 2sm2t 
</p>
<p>( cos2t ) 
sin2t+cos2t ' 
</p>
<p>( 1-t) 11. x(t)= ~ e21 
</p>
<p>t- t2- it3- tt4+ 1it5 
</p>
<p>13. x(t)= -tt2 
</p>
<p>(2 + it3 
15. x(t) = [ 1 ~ t ] e31 
</p>
<p>l +2t 
</p>
<p>569 </p>
<p/>
</div>
<div class="page"><p/>
<p>Answers to odd-numhered exercises 
</p>
<p>Chapter 4 
</p>
<p>SECTION 4.1 
</p>
<p>1. x=O,y=O; x=O,y=I; x=I,y=O; x=t,y=~ 
</p>
<p>3 x=Oy=O z=O&middot; x=E_ y=!!.. z=-(f:_+a2 ) 
. ' ' ' d ' b ' d2 b2 
</p>
<p>5. x=O,y=y0 ; Yo arh. 7. x=O,y= -2, z=mr 
x = x0, y = I; x0 arh. 
x=x0,y= -1; x0 arh. 
</p>
<p>SECTION 4.2 
</p>
<p>1. Stahle 3. Unstahle 5. Asymptotically stahle 
</p>
<p>7. Asymptotically stahle 9. Stahle 
</p>
<p>11. x(t)= I is stahle; x(t)=O is unstahle. 
</p>
<p>SECTION 4.3 
</p>
<p>1. x=O, y =0 is unstahle; x= I, y =0 is unstahle; 
x = -1, y = 0 is unstahle; x = 0, y = 2114 is stable; 
x=O,y= -2114 is stahle. 
</p>
<p>3. x=O,y=I isunstahle; x=O,y=-1 isunstahle; 
x= l, y=O is unstahle; x= -1, y=O is stahle. 
</p>
<p>5. x = 0, y = mr is unstahle for all integers n. 
7. Unstahle 9. Unstahle 11. Stahle 13. Stahle 
</p>
<p>15. Unstahle 17. Unstahle 
</p>
<p>SECTION 4.4 
</p>
<p>1. y=cos(x-li 3. y=tanx 
</p>
<p>7. The points x=x0,y=y0 with x0 +y0 = -1, and the circles x 2+y2=c2, minus 
these points. 
</p>
<p>9. The points x = 0, y = y0 ; x = x0, y = 0, and the curves y = ce -&lt;213)e3x, x &gt; 0; 
y =Ce -(2/3)e3x, X&lt; 0. 
</p>
<p>11. The points x = 0, y = y0, and the curves 
</p>
<p>(ad-bc) 
(by-dx)- d lnlc-qyl=k, x&gt;O 
</p>
<p>(ad-bc) 
(by-dx)- d lnlc-qyl=k, x&lt;O 
</p>
<p>13. The point x = 0, y = 0; and the curves xy2- i x 3 = c. 
</p>
<p>Section 4.5.1 
</p>
<p>Y b x 2 3. -- -ln(b+cy)=- +k 
c c2 2a 
</p>
<p>Y x b a 5. --- = -ln(b+qy)- -ln(a+cx)+k 
d c d2 c2 
</p>
<p>570 </p>
<p/>
</div>
<div class="page"><p/>
<p>Answers to odd-numbered exercises 
</p>
<p>SECTION 4.7 
</p>
<p>13. (b)y2=x2+x4 +c2 
</p>
<p>SECTION 4.8 . 
</p>
<p>5. The circle x2 + y 2 = I. Note that every point on this circle is an equiiibrium 
point. 
</p>
<p>7. The circles x2 + y 2 = (2n + l)'IT /2 
</p>
<p>SECTION 4.9 
</p>
<p>1. e=-1,1 
</p>
<p>3. e=-2,2 
</p>
<p>5. No bifurcation points 
</p>
<p>SECTION 4.10 
</p>
<p>1. x=O,y=O is unstabie; x=(a/e),y=O is stable if ad&lt;ec, and unstable if 
ad&gt;ec; x=(af+bc)j(ef+bd),y=(ad-ec)/(bd+ef) exists only for ad&gt;ec 
and is stable. 
</p>
<p>3. x 1 =0, x2=0,y=O; x 1 =c/ d, x2=ncj[d(a1 +a2)], y =na2-a?-a1a2; 
assuming that na2 &gt; a? + a 1 a2. 
</p>
<p>I +a1 I-a2 
5. (b)(i)yt= I+ata2&bull;y2= I-ata2; (ii)yt=I,y2=0; (c)a2=t 
</p>
<p>SECTION 4.12 
</p>
<p>3. (a) rl+AI2/2=yinS-rS+c; (b) Yes 
</p>
<p>5. (a) 0.24705; (b) 0.356; (c) 0.452I2; (d) 0.60025; (e) 0.74305; (f) 0.7766I 
</p>
<p>SECTION 4.13 
</p>
<p>Chapter 5 
</p>
<p>SECTION 5.1 
</p>
<p>(2n+Ii'1T2 . (2n+I)'1Tx 
1. An= 412 ,y(x)=csm 21 
</p>
<p>-n2'1T2 n'ITX 3. A=O,y=c; A= - 1-2-, y(x)=ccos-1-
</p>
<p>5. y(x)=csinh ~ x, where sinh ~ '1T= ~ cosh ~ 'IT; 
</p>
<p>y(x)=csin V"i:;, x, where tan V"i:;, '1T= V"i:;,. 
7. A= -1, y(x)=cex; A= n2, y(x)= c[ncosnx+sinnx] 
</p>
<p>571 </p>
<p/>
</div>
<div class="page"><p/>
<p>Answers to odd-numbered exercises 
</p>
<p>SECTION 5.3 
</p>
<p>1. u(x, t) = sin !'ITx e -1.?1w2tf4 + 3 sin t'ITX e -&lt;L71&gt;25"2t/4 
</p>
<p>3. u(x, t) = 3 sin2'1Txe&lt;1-4."l)t -7 sin4'1Txe&lt;1- 16."2Jt 
</p>
<p>5. u(t,y)=e2(t+y&gt;+e-3(t+y) 
</p>
<p>7. u(t,y) = e-ste-4y + 2e-1te-6y -I4e13te14y 
</p>
<p>9. (a)X"-p.X=O; Y"-(p.+;\)Y=O; T'-;\a2T=O; 
. n'ITx . n'IT)' '--2 -'(b2 _ 2Jt/ 2b2 (b) u(x,y,t)=sma smbea-n 'Ir a a 
</p>
<p>SECTION 5.4 
</p>
<p>1. f(x)= * [ sintx + sin:'ITX + sin~'ITX + ... J 
3 !( )= l [ sin'1Tx _ sin2'1Tx + sin3'1Tx + J &bull; X '1T I 2 3 _ ... 
</p>
<p>3 I ~ I [ . n'IT n'ITX { n'IT ) . n'ITX J S.f(x)=--- ~- sm-cos-+ I-cos- sm-
4 '1T n- 1 n 2 2 2 2 
</p>
<p>e1-I 00 e'(-Ir-I[ n'ITX &middot; n'ITX] 1.f(x)= 21 + ~ 2 2 2 lcos-1--n'ITsm-1-
n-1 I +n '1T 
</p>
<p>e' oo 1(e1( -Ir-I) n'ITx 
9. f(x)= T +2 ~ 2 2 2 cos-1-
</p>
<p>n-1 I + n '1T 
</p>
<p>e1-I 00 (-Ir(e'-e-/)[ n'ITX &middot; n'ITX] 
11. f(x)= - 1- + ~ 2 2 2 lcos-1- +n'ITsm-1-
</p>
<p>n-1 I +n '1T 
</p>
<p>'17'2 oo (-I)ncosnx 
13. f(x)=*sinx-~sin3x 17. (a)f(x)= 3 +4 ~ 2 
</p>
<p>n=l n 
</p>
<p>SECTION 5.5 
</p>
<p>e-I ~ 2(1-cosn'IT je) 
1. f(x)= -- + ~ 2 2 cosn'ITX 
</p>
<p>e n=l I+n'IT 
</p>
<p>_ 3a ~ 4a(cosn'1Tj2 -I) n'ITx 
3. f(x)- T + ~ 2 2 cos 2a 
</p>
<p>n-1 n '1T 
</p>
<p>5.f(x)=j_+ 21 2 l_[2cosn'1Tj2 -1-(-l)n]cosn'ITX 
4 '17'2 n-1 n2 I 
</p>
<p>7. f(x)= l ~ l(cosn'IT/2 -( -lr)sin n'IT2X 9. f(x)=sin2x 
'1T n=l n 
</p>
<p>11 (). =l+i[cos2x+cos4x+ ]&middot; O&lt;x&lt;I; . a smx '1T '1T 1-22 1-42 ... ' 
</p>
<p>(b) cosx= i [ 2s;n2x + 4s;n4x + ... ]; O&lt;x&lt; I; (c) No 
'1T 2-I 4-1 
</p>
<p>572 </p>
<p/>
</div>
<div class="page"><p/>
<p>Answers to odd-numbered exercises 
</p>
<p>SECTION 5.6 
</p>
<p>1. (a) u(x t)= 280 :f sin(2n+l)'ll'x/IO e-D.86(2n+I)lwlt/IOO. 
' 'lf 0 2n+ 1 ' "_ 
</p>
<p>oo 2n(l-(-l)"cos10) n'IT 
(b) u(x,t)= ~ sin2e-0.86n2..-21/IOO; 
</p>
<p>n-1 n2'11'2-100 10 
</p>
<p>( ) ( t)= 100 ~ [ 4sinn'll' /2 - ( -1)" ] . !!!0.. -0.86n2wli/IOO. c u x, "-" 2 2 sm 100 e , 
n-1 n 'II' n'IT 
</p>
<p>130 oo ((-I)"-cos3'11'/10) 
(d) u(x,t)= .=...._ ~ sin!!!0..e-0.86n2..-21/IOO 
</p>
<p>'II' n-1 n 10 
</p>
<p>5. (b) u(x,t)=I0x+800 :f sin:'ll't2 sin";r; e&lt;I-n2w2&gt;' 
n-1 n 'II' 
</p>
<p>SECTION 5.7 
</p>
<p>1 ) 4 ~ [ 2n + 1 1 ] . x ct &bull; u(x,t =- "-" 2 - 2 +I sm(2n+l)-2 cos(2n+l)-2 
'II' n-o (2n+ I) -4 n 
</p>
<p>3 ( )- 12 ~ sin2n'll'/3 . n'ITX n'ITct &bull; u x,t - 2 "-" 2 sm3 cos-3-
'11' n-1 n 
</p>
<p>5 ( ) 8 ~ 1 . n'IT . n'ITX n'll't &bull; u x,t =2 "-" 2 sm2 sm2 cos10 
'II' n-ln 
</p>
<p>9. u(x,y,t)=X(x)Y(y)T(t); Y(y)=a2 cos \h,2 - p.2 y+ b2sin \fA2- p.2 y 
X(x)=a 1 cosp.x+ b1sinp.x T(t)=a3 cosAct+ b3 sinAct 
</p>
<p>SECTION 5.8 
</p>
<p>oo &bull; n'IT(x-a) . mry -2 (h . mry 
1. u(x,y)= ~ c,.sinh b smb; c"= bsinhn'ITa/b Jno f(y)smbdy 
</p>
<p>n-1 
</p>
<p>~ n'ITX n'IT(y- b) -2 La . n'ITX 
3. u(x,y)= "-" c,.sin-sinh ; c"= 'nh b/ f(x)sm-dx 
</p>
<p>"_ 1 a a as1 n'IT a 0 a 
</p>
<p>4 00 sin(2n - 1) 'II': sinh(2n - I) j;' 
5. u(x,y)=- ~ --------
</p>
<p>'11' n-1 (2n-l)sinh(2n-1)'11'b/a 
</p>
<p>00 sinh(2n - 1) 'II' X sin(2n - 1) '1IJ' 
+~ ~ b b 
</p>
<p>"'n-1 (2n -l)sinh(2n -l)'ITa/b 
</p>
<p>4 00 sinh(2n -1)'11' x b a sin(2n -1) ": 
7. u(x,y)=I+- ~ -~------___..:-
</p>
<p>'11' n-1 (2n-l)sinh(2n-1)'11'a/b 
</p>
<p>-2 ~ (-l)"sinhYI+n2 '11'2 xsinn'l!'y 
9. u(x,y)=- "-" 
</p>
<p>'II' n-1 nsinhYl+n2'1T2 
</p>
<p>11. X"+AX=O; Y"+p.Y=O; Z"-(A+p.)Z=O 
</p>
<p>573 </p>
<p/>
</div>
<div class="page"><p/>
<p>Answers to odd-numbered exercises 
</p>
<p>SECTION 6.3 
</p>
<p>J3 J5 sfi( 2 12) 1. p0 (x) = T' p1 (x) = 8 x, p2 (x) = 32 x -5 
SECTION 6.4 
</p>
<p>7. y(x) = csinh~x, where sinh~n = ~cosh~n; 
</p>
<p>y(x) = csinJI,;x, where tanJI,;n = JI,; 
9 . .A. = -1, y(x) = ce\ .A. = n2, y(x) = c[n cos nx + sin nx] 
</p>
<p>574 </p>
<p/>
</div>
<div class="page"><p/>
<p>Adjoint matrix 315 
Analytic functions 189 
Asymptotic stability 381 
Atomic waste problern 46 
Autonomous systems 376 
</p>
<p>Bemoulli equation 67 
Bessel equation 137 
</p>
<p>order v 218 
order zero 220 
</p>
<p>Bessel function 
J.(t) 218 
J0 (t) 220 
</p>
<p>Boundary conditions for 
elastic string 483 
heat equation 482 
Laplace equation 483 
second order o.d.e. 476, 533 
</p>
<p>Boundary-value problern 476, 483, 533 
heat equation 483 
Laplace equation 508 
wave equation 503 
</p>
<p>Carbon dating 19 
Cauchy ratio test 189 
Cayley-Harnilton theorem 351 
Characteristic equation 138 
</p>
<p>complex roots 141 
real and equal roots 145 
real and unequal roots 138 
</p>
<p>Characteristic polynornial 334 
complex roots 341 
real distinct roots 334 
repeated roots 345 
</p>
<p>Index 
</p>
<p>Combat models 405 
Complex exponentials 141 
Compound interest 57 
Convolution integral 252 
</p>
<p>Damping force 166 
Detecting art forgeries 11 
Detection of diabetes 178 
Difference equations 91 
Differential operators 129 
Diffusion equation 481 
Dirac, P. A. M. 244 
Dirac delta function 244 
</p>
<p>Laplace transform of 246 
Direction field 397 
Dirichlet problern 483 
Discontinuous forcing function 238 
</p>
<p>Eigenfunctions 478 
Eigenvalues of 
</p>
<p>boundary-value problern 478, 533 
matrix 333 
</p>
<p>multiplicity of 347 
Eigenvectors of a matrix 333 
</p>
<p>linear independence of 335 
Elastic membrane 
</p>
<p>vibration of 482 
Elastic string 482, 503 
</p>
<p>boundary conditions for 483 
fundamental frequencies of 505 
initial conditions for 483 
nonzero initial displacement 505 
propagation of initial conditions 506 
</p>
<p>575 </p>
<p/>
</div>
<div class="page"><p/>
<p>Index 
</p>
<p>Electrical eireuits 17 5 
Epidemie models 38 
</p>
<p>gonorrhea 491 
plagues 39 
threshold theorem 460 
</p>
<p>Equilibrium points 373 
Error 
</p>
<p>effeet of step size 102 
for Euler's method 100 
formula 101 
for improved Euler's method 110 
round-off 105 
for Runge-Kutta method 113 
for three-term Taylor series 107 
</p>
<p>Escape veloeity 52 
Euler equation 145, 149, 198 
Euler method 97 
</p>
<p>formula error 101 
Even funetions 493 
Exaet equations 58, 60 
Existenee and uniqueness theorems for 
</p>
<p>first-order equations 67 
orbits 314 
seeond-order equations 129 
systems of first-order equations 291, 414 
</p>
<p>Extension of a funetion 
even 495 
odd 496 
</p>
<p>Finding roots by iteration 81 
First-order differential equations 1, 2 
</p>
<p>exaet 58, 60 
existenee and uniqueness theorem for 67 
general solutions of 4, 21 
homogeneous 3 
initial-value problern 5, 7, 21 
integrating factor for 8, 64 
linear 3 
nonlinear 3 
numerieal solutions of, see Numerical 
</p>
<p>methods 
separable 21 
several variables 264 
systems of 265 
</p>
<p>Fourier series 487, 488 
convergenee of 487,488 
eosine series 494 
Fourier coeffieients 489 
Parseval identity 492 
sine series 494 
</p>
<p>Frobenius method 203 
Fundamental matrix 355 
Fundamental set of solutions 133 
</p>
<p>General solutions 
first-order linear equations 4, 21 
higher-order equations 259 
seeond-order equations 132, 142, 148 
systems of first-order equations 334 
</p>
<p>576 
</p>
<p>Generalized funetions 249 
Gompertzian relation 53 
Gonorrhea model 491 
Green's theorem 437 
</p>
<p>Heat equation 481,499 
bar with insulated ends 500 
boundary eonditions 483 
initial conditions 483 
nonhomogeneous boundary conditions 
</p>
<p>503 
smoothing of discontinuities in initial 
</p>
<p>eonditions 499 
Hermite equation 197, 515, 539 
Hermite polynomial 197, 541 
Higher-order equations 259 
</p>
<p>general solution 259 
variation of parameters 262 
</p>
<p>Homogeneous equations 25 
Hypergeometrie equations 218 
</p>
<p>Identity matrix 311 
Impedanee 177 
Improved Euler method 109 
Indicial equation 209 
Initial conditions 482 
</p>
<p>for elastie string 483 
for heat equation 483 
propagation of initial conditions for wave 
</p>
<p>equation 506 
smoothing of discontinuities for heat 
</p>
<p>equation 499 
Initial-value problern 5, 7, 21, 128, 259 
Inner product 516 
Integral equation 70 
Integrating factor 8, 64 
Inverse matrix 316 
</p>
<p>Jump discontinuities 227, 238 
J udieious guessing of partieular solutions 
</p>
<p>157 
</p>
<p>Kirehoff's second law 176 
</p>
<p>Laguerre equation 218, 539 
Laplaee equation 482, 508 
</p>
<p>boundary eonditions 483 
Dirichlet problern 483 
Neumann problern 483 
</p>
<p>Laplace transform 225 
of the convolution 252 
definition 226 
of derivatives 229 
of the Dirac delta function 246 
existence of 227 </p>
<p/>
</div>
<div class="page"><p/>
<p>inverse of 230 
of systems 368 
</p>
<p>Legendre equation 197, 539 
Legendre polynomials 197 
Limit cycles 436 
Linearalgebra 271, 296 
Linearindependence 136,281 
</p>
<p>of eigenvectors 335 
of vector functions 293 
of vectors 281 
</p>
<p>Linear operators 131 
Linear differential equations, see First-order 
</p>
<p>differential equations, Second-order 
differential equations, or Systems 
of first-order differential equations 
</p>
<p>Linear transformations 324 
Logistic curves 30, 43 
Logistic law of population growth 28 
</p>
<p>Malthusian law of population growth 27 
Matrices 267 
</p>
<p>addition of 276 
adjoint 315 
characteristic polynomial 334 
determinant of 299 
diagonal 301 
</p>
<p>Iower 301 
upper 301 
</p>
<p>eigenvalues of 333 
eigenvectors of 333 
fundamental 355 
Hermitian 530 
identity 311 
inverse 316 
product of 310 
selfadjoint 530 
</p>
<p>Mechanical vibrations 165 
damped forced vibrations 169 
damped free vibrations 167 
forced free vibrations 170 
free vibrations 166 
resonant frequency 173 
</p>
<p>Method of elimination 257 
Mixing problems 53 
</p>
<p>Natural frequency 171 
Neumann problern 483 
Newtonian mechanics 46, 127, 166 
Newton's method 88 
Nonlinear differential equations 
</p>
<p>autonomaus system 376 
Numerical methods 95 
</p>
<p>effect of step size 102 
error 100, 102, 107, 110, 113 
Euler 97 
</p>
<p>formula error 101 
improved Euler 110 
Runge-Kutta 113 
three-term Taylor series 107 
</p>
<p>Index 
</p>
<p>Odd functions 493 
Ohm's law 176 
Orbits 394, 397 
Order of a differential equation 
Ordinary differential equations 
</p>
<p>definition 1 
</p>
<p>Parseval's identity 492 
Partial differential equations 
</p>
<p>definition 481 
Particular solution 151, 364 
Periodic solutions 416 
Phase plane 394 
Phaseportrait 418, 419 
Picard iterates 70 
Piecewise continuous functions 227 
Poincare-Bendixson theorem 433 
Population models 27 
</p>
<p>competitive exclusion 451 
Logistic Iaw of population growth 28 
Malthusian law of population growth 27 
sharks 443, 444 
</p>
<p>Potential equation 482 
Power series 188 
</p>
<p>Qualitative theory 372 
</p>
<p>Radioactive dating 12 
Reduction of order 147 
Reduction to systems of equations 265 
Regular singular points 204 
Resonance 170 
Resonant frequency 173 
Reynolds number 50 
Runge-Kutta method 113 
</p>
<p>Schwartz, Laurent 245, 248 
Second-order differential equations 127, 138 
</p>
<p>characteristic equation 138 
complex roots 141 
real and equal roots 145 
real and unequal roots 138 
</p>
<p>Euler equation 145, 150, 198 
existence and uniqueness theorem 129 
fundamental set of solutions 133 
general solutions 132, 142, 148 
homogeneaus equation 128 
judicious guessing of particular solution 
</p>
<p>157 
nonhomogeneaus equation 151 
</p>
<p>discontinuous function 238 
particular solution 151 
reduction of order 147 
series solution 185, 188 
singular points 198, 204 
variation of parameters 155 
</p>
<p>577 </p>
<p/>
</div>
<div class="page"><p/>
<p>Index 
</p>
<p>Separable equations 20 
Separation of variables 483, 484 
</p>
<p>for heat equation 484, 500 
for Laplace equation 508, 510 
for wave equation 503 
</p>
<p>Sequence of eigenvalues 4 78 
Series solution 185, 188 
</p>
<p>recurrence formula 187 
when roots of the indicial equation are 
</p>
<p>equal 212, 216 
when roots of the indicial equation differ 
</p>
<p>by an integer 212, 216 
Singular points 198, 204 
Solutions, definition 1 
</p>
<p>first-order equations 4, 21, 60 
higher-order equations 259 
second-order equations 132, 142, 148 
systems of first-order equations 334 
</p>
<p>Spread of technological innovations 39 
Spring-mass dashpot system 165 
</p>
<p>damped vibrations 167, 169 
forced vibrations 170 
free vibrations 166 
</p>
<p>Stability 
asymptotic 381 
of equilibrium points 385, 386 
linear systems 378 
of a solution 373, 378 
</p>
<p>Sturm-Liouville boundary value problern 
533 
</p>
<p>Systems of algebraic equations 297 
Systems of linear first-order equations 265 
</p>
<p>characteristic polynomial 334 
complex roots 341 
real distinct roots 334 
repeated roots 345 
</p>
<p>definition 265 
</p>
<p>578 
</p>
<p>existence and uniqueness 291 
fundamental matrix 355 
generat solution of 334 
nonhomogeneaus 360 
reduction to 265 
stability of 378 
variation of parameters 360 
</p>
<p>Tacoma Bridge disaster 173 
Taylor series 189 
Tchebycheff equation 197, 539 
Tchebycheff polynomials 197, 541 
Theory of war 398 
Thermal diffusivity 481 
Three-term Taylor series 106 
Trajectories 394 
Tumor growth 52 
</p>
<p>Variation of parameters 155 
for systems of equations 360 
</p>
<p>Vectors 266 
linear independence of 281 
solutions of systems of equations 297 
valued functions 266 
</p>
<p>Vector spaces 273 
basis 287 
dimension of 283 
</p>
<p>Volterra, Vito 444 
</p>
<p>Wave equation 482, 503 
boundary conditions 483 
initial conditions 483 
solution 504 
</p>
<p>Wronskian 133 </p>
<p/>
</div>
<div class="page"><p/>
<p>Texts in Applied Mathematics 
</p>
<p>(continued from page ii) 
</p>
<p>31. Bnimaud: Markov Chains: Gibbs Fields, Monte Carlo Simulation, and Queues. 
</p>
<p>32. Durran: Numerical Methods for Wave Equations in Geophysical Fluid Dynamics. 
</p>
<p>33. Thomas: Numerical Partial Differential Equations: Conservation Laws and Elliptic 
</p>
<p>Equations. 
</p>
<p>34. Chicone: Ordinary Differential Equations with Applications. 
</p>
<p>35. Kevorkian: Partial Differential Equations: Analytical Solution Techniques, 2nd ed. 
</p>
<p>36. Dullerud/Paganini: A Course in Robust Control Theory: A Convex Approach. 
</p>
<p>37. Quarteroni/Sacco/Saleri: Numerical Mathematics. 
38. Gallier: Geometrie Methods and Applications: For Computer Science and 
</p>
<p>Engineering. 
</p>
<p>39. Atkinson/Han: Theoretical Numerical Analysis: A Functional Analysis Framework. 
40. Brauer!Castillo-Chdvez: Mathematical Models in Population Biology and 
</p>
<p>Epidemiology. 
41. Davies: IntegralTransformsand Their Applications, 3rd ed. 
42. Deujlhard/Bornemann: Scientific Computing with Ordinary Differential Equations. 
43. Deujlhard/Hohmann: Numerical Analysis in Modem Scientific Computing: 
</p>
<p>An Introduction, 2nd ed. 
44. Knabner/Angermann: Numerical Methods for Elliptic and Parabolic Partial 
</p>
<p>Differential Equations. 
45. Larsson/Thomee: Partial Differential Equations with Numerical Methods. 
46. Pedregal: Introduction to Optimization. 
47. Ockendon/Ockendon: Waves and Compressible Flow. 
48. Hinrichsen: Mathematical Systems Theory I. 
49. Bullo/Lewis: Geometrie Control ofMechanical Systems: Modeling, Analysis, and Design for 
</p>
<p>Simple Mechanical Control Systems. </p>
<p/>
</div>
<ul>	<li>Cover</li>
	<li>Title Page</li>
	<li>Copyright Page</li>
	<li>Dedication</li>
	<li>Series Preface</li>
	<li>Preface to the Fourth Edition</li>
	<li>Preface to the Third Edition</li>
	<li>Preface to the First Edition</li>
	<li>Contents</li>
	<li>First-order differential equations 1</li>
<ul>	<li>1.1 Introduction</li>
	<li>1.2 First-order linear differential equations</li>
	<li>1.3 The Van Meegeren art forgeries</li>
	<li>1.4 Separable equations</li>
	<li>1.5 Population models</li>
	<li>1.6 The spread of technological innovations</li>
	<li>1. 7 An atomic waste disposal problern</li>
	<li>1.8 The dynamics of tumor growth, mixing problemsand orthogonal trajectories</li>
	<li>1.9 Exact equations, and why we cannot solve very many differential equations</li>
	<li>1.10 The existence-uniqueness theorem; Picard iteration</li>
	<li>1.11 Finding roots of equations by iteration</li>
<ul>	<li>1.11.1 Newton's method</li>
</ul>
	<li>1.12 Difference equations, and how to compute the interest due on your student loans</li>
	<li>1.13 Numerical approximations; Euler's method</li>
<ul>	<li>1.13.1 Error analysis jor Euler's method</li>
</ul>
	<li>1.14 The three term Taylor series method</li>
	<li>1.15 An improved Euler method</li>
	<li>1.16 The Runge-Kutta method</li>
	<li>1.17 What to do in practice</li>
</ul>
	<li>Second -order linear&#13;differential equations 2</li>
<ul>	<li>2.1 Algebraic properties of solutions</li>
	<li>2.2 Linear equations with constant coefficients</li>
	<li>2.3 The nonhomogeneous equation</li>
	<li>2.4 The method of variation of parameters</li>
	<li>2.5 The method of judicious guessing</li>
	<li>2.6 Mechanical vibrations</li>
<ul>	<li>2.6.1 The Tacoma Bridgedisaster</li>
</ul>
	<li>2.7 A model for the detection of diabetes</li>
	<li>2.8 Series solutions</li>
<ul>	<li>2.8.1 Singular points, Euler equations</li>
	<li>2.8.2 Regularsingular points, the method of Frobenius</li>
	<li>2.8.3 Equal roots, and roots differing by an integer</li>
</ul>
	<li>2.9 The method of Laplace transforms</li>
	<li>2.10 Some useful properties of Laplace transforms</li>
	<li>2.11 Differential equations with discontinuousright-hand sides</li>
	<li>2.12 The Dirac delta function</li>
</ul>
	<li>Systems of differential equations 3</li>
<ul>	<li>3.1 Algebraic properties of solutions of linear systems</li>
	<li>3.2 Vector spaces</li>
	<li>3.3 Dimension of a vector space</li>
	<li>3.4 Applications of linear algebra to differential equations</li>
	<li>3.5 The theory of determinants</li>
	<li>3.6 Solutions of simultaneous linear equations</li>
	<li>3.7 Linear transformations</li>
	<li>3.8 The eigenvalue-eigenvector method of finding solutions</li>
	<li>3.9 Complex roots</li>
	<li>3.10 Equal roots</li>
	<li>3.11 Fundamental matrix solutions; eA1</li>
	<li>3.12 The nonhomogeneous equation;variation of parameters</li>
	<li>3.13 Solving systems by Laplace transforms</li>
</ul>
	<li>Qualitative theory of differential equations 4</li>
<ul>	<li>4.1 Introduction</li>
	<li>4.2 Stability of linear systems</li>
	<li>4.3 Stability of equilibrium solutions</li>
	<li>4.4 The phase-plane</li>
	<li>4.5 Mathematical theories of war</li>
<ul>	<li>4.5.1. L. F. Richardson's theory of conflict</li>
</ul>
	<li>4.6 Qualitative properties of orbits</li>
	<li>4.7 Phase portraits of linear systems</li>
	<li>4.8 Long time behavior of solutions;the Poincare-Bendixson Theorem</li>
	<li>4.9 Introduction to bifurcation theory</li>
	<li>4.10 Predator-prey problems; or why the percentage of sharks caught in the Mediterranean Sea rose dramatically during World War I</li>
	<li>4.11 The principle of competitive exclusion in population biology</li>
	<li>4.12 The Threshold Theorem of epidemiology</li>
	<li>4.13 A model for the spread of gonorrhea</li>
</ul>
	<li>Separation of variables and Fourier series 5</li>
<ul>	<li>5.1 Two point boundary-value problems</li>
	<li>5.2 Introduction to partial differential equations</li>
	<li>5.3 The heat equation; separation of variables</li>
	<li>5.4 Fourier series</li>
	<li>5.5 Even and odd functions</li>
	<li>5.6 Return to the heat equation</li>
	<li>5.7 The wave equation</li>
	<li>5.8 Laplace's equation</li>
</ul>
	<li>Sturm-Liouville boundary value problems 6</li>
<ul>	<li>6.1 Introduction</li>
	<li>6.2 Inner product spaces</li>
	<li>6.3 Orthogonal bases, Hermitian operators</li>
	<li>6.4 Sturm-Liouville theory</li>
</ul>
	<li>Appendix A</li>
<ul>	<li>Some simple facts concerning functionsof several variables</li>
</ul>
	<li>Appendix B</li>
<ul>	<li>Sequences and series</li>
</ul>
	<li>Appendix C</li>
<ul>	<li>C Programs</li>
</ul>
</ul>
</body></html>