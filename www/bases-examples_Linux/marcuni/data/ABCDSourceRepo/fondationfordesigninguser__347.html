<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title></title>
</head>
<body><div class="page"><p/>
<p>Foundations 
for Designing 
User-Centered 
Systems
</p>
<p>Frank E. Ritter
Gordon D. Baxter
Elizabeth F. Churchill
</p>
<p>What System Designers 
Need to Know about People</p>
<p/>
</div>
<div class="page"><p/>
<p>Foundations for Designing User-Centered
Systems</p>
<p/>
</div>
<div class="page"><p/>
<p>Frank E. Ritter &bull; Gordon D. Baxter
Elizabeth F. Churchill
</p>
<p>Foundations for Designing
User-Centered Systems
</p>
<p>What System Designers Need
to Know about People
</p>
<p>123</p>
<p/>
</div>
<div class="page"><p/>
<p>Frank E. Ritter
College of IST
The Pennsylvania State University
University Park, PA
USA
</p>
<p>Gordon D. Baxter
School of Computer Science
University of St Andrews
St Andrews, Fife
UK
</p>
<p>Elizabeth F. Churchill
eBay Research Labs
eBay Inc.
San Jose, CA
USA
</p>
<p>ISBN 978-1-4471-5133-3 ISBN 978-1-4471-5134-0 (eBook)
DOI 10.1007/978-1-4471-5134-0
Springer London Heidelberg New York Dordrecht
</p>
<p>Library of Congress Control Number: 2013957359
</p>
<p>ï¿½ Springer-Verlag London 2014
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of
the material is concerned, specifically the rights of translation, reprinting, reuse of illustrations,
recitation, broadcasting, reproduction on microfilms or in any other physical way, and transmission or
information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar
methodology now known or hereafter developed. Exempted from this legal reservation are brief
excerpts in connection with reviews or scholarly analysis or material supplied specifically for the
purpose of being entered and executed on a computer system, for exclusive use by the purchaser of the
work. Duplication of this publication or parts thereof is permitted only under the provisions of
the Copyright Law of the Publisher&rsquo;s location, in its current version, and permission for use must
always be obtained from Springer. Permissions for use may be obtained through RightsLink at the
Copyright Clearance Center. Violations are liable to prosecution under the respective Copyright Law.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this
publication does not imply, even in the absence of a specific statement, that such names are exempt
from the relevant protective laws and regulations and therefore free for general use.
While the advice and information in this book are believed to be true and accurate at the date of
publication, neither the authors nor the editors nor the publisher can accept any legal responsibility for
any errors or omissions that may be made. The publisher makes no warranty, express or implied, with
respect to the material contained herein.
</p>
<p>Cover Image: Badrul Sarwar
</p>
<p>Printed on acid-free paper
</p>
<p>Springer is part of Springer Science+Business Media (www.springer.com)</p>
<p/>
</div>
<div class="page"><p/>
<p>Foreword
</p>
<p>Our core Masters in Software Engineering course at the University of Southern
</p>
<p>California is a 2-semester course in which students form into about 15&ndash;20 teams of
</p>
<p>six people to define, design, develop, and deploy working software systems for
</p>
<p>clients in the local South Los Angeles community. The clients range from IT
</p>
<p>startups, neighborhood small businesses, local government and local community
</p>
<p>service organizations, to USC doctors, faculty members, librarians, administrators,
</p>
<p>and student organizations. The student developers come from many countries and
</p>
<p>cultures: mostly from the US, India, and China; but also from Europe, Latin
</p>
<p>America, and other parts of Asia.
</p>
<p>One concept that seems to be common among all of their cultures is a version of
</p>
<p>the Golden Rule: &lsquo;&lsquo;Do unto others as you would have others do unto you.&rsquo;&rsquo; One of
</p>
<p>the first things that we now teach the students is that this rule carries a dangerous
</p>
<p>assumption. How, we originally wondered, could such a universally accepted tenet
</p>
<p>be dangerous? However, we found that it carries the assumption &lsquo;&lsquo;Everyone is like
</p>
<p>me,&rsquo;&rsquo; and that many of the students would follow it to create programmer-friendly
</p>
<p>user interfaces, and say, for example, &lsquo;&lsquo;Hard to use? What do you mean? Its tight
</p>
<p>syntax minimizes keystrokes. It gives you the power of direct access to the
</p>
<p>operating system. It doesn&rsquo;t need to pinpoint errors because they&rsquo;re obvious from
</p>
<p>scanning the erroneous command.&rsquo;&rsquo;
</p>
<p>We now teach them the Platinum Rule, &lsquo;&lsquo;Do unto others as others would be
</p>
<p>done unto,&rsquo;&rsquo; emphasize development and exercise of user prototypes, and provide
</p>
<p>readings, user domain models, exercises, and win&ndash;win negotiation capabilities to
</p>
<p>help them learn how their clients would like to be done unto.
</p>
<p>As we&rsquo;ve evolved the course over the last 16 years, we&rsquo;ve learned a lot about
</p>
<p>developers and users the hard way, by trying things out and rethinking approaches
</p>
<p>that didn&rsquo;t work very well.
</p>
<p>We could have avoided a great deal of this learning-the-hard-way if we&rsquo;d had
</p>
<p>access to the book that you&rsquo;re holding now. Foundations for Designing
</p>
<p>User-Centered Systems: What System Designers Need to Know about People is a
</p>
<p>well-organized treasure trove of useful insights and case studies about the char-
</p>
<p>acteristics of users and how to develop systems that best fit their strengths and
</p>
<p>avoid their weak spots.
</p>
<p>The book begins with some good motivation, context, underlying science, and
</p>
<p>conceptual frameworks for human-systems integration. It covers considerations of
</p>
<p>v</p>
<p/>
</div>
<div class="page"><p/>
<p>users&rsquo; physiology (Chap. 3), senses (primarily vision and hearing) (Chap. 4), a
</p>
<p>strong coverage of users&rsquo; memory, attention, and learning aspects (Chap. 5), and
</p>
<p>several good chapters on how to improve human&ndash;computer interaction. These
</p>
<p>provide useful information and guidance on human cognitive capabilities and their
</p>
<p>implications for considerations such as organizing text and menus, mental models
</p>
<p>(for problem solving and decisionmaking), groupware and social processes, types of
</p>
<p>users and their design implications (age, gender, disabilities), error avoidance, task
</p>
<p>analysis, human-system evaluation considerations, and process models supporting
</p>
<p>human-systems integration, such as the incremental commitment spiral model.
</p>
<p>Just to elaborate on one of these, the book is particularly strong in an area most
</p>
<p>frequently in need of improvement: groupware and social processes. Most com-
</p>
<p>puter systems have been developed to help individuals perform individual tasks,
</p>
<p>and tend to focus on improving individuals&rsquo; performance. A lot of groupware also
</p>
<p>gets developed using such systems, so that the individual-focus gets supported
</p>
<p>more strongly than the group-focus.
</p>
<p>An example of the consequences of this has been our series of win&ndash;win
</p>
<p>requirements negotiation tools we&rsquo;ve developed and used in our project course
</p>
<p>mentioned above. Our first three versions of the tools began by enabling stake-
</p>
<p>holders to enter and classify the win conditions they wanted from the project, after
</p>
<p>which efforts were made to identify and resolve conflicts among the win condi-
</p>
<p>tions. This was often difficult after they had bought into the things they wanted.
</p>
<p>Our fourth version of the negotiation toolset was built on top of a group-
</p>
<p>oriented support system (the Ventana/GroupSystems infrastructure). There, once
</p>
<p>stakeholders entered a win condition, they did not stay in their own space, but were
</p>
<p>presented with another entry window showing some win conditions entered by the
</p>
<p>other stakeholders. This often shifted their thinking to focus on understanding and
</p>
<p>accommodating others&rsquo; win conditions (oh, they want this to run on Windows,
</p>
<p>Mac, and Unix platforms; we&rsquo;d better not use any one-platform COTS (com-
</p>
<p>mercial off-the-shelf) products; maybe we should use a Java virtual machine or
</p>
<p>make this a Web application; and do they have all three platforms for us to test
</p>
<p>on?). This opened our eyes to the differences between individual-focused and
</p>
<p>group-focused user interfaces, but it left us wondering how many other dimensions
</p>
<p>of group-oriented user interfaces we needed to consider.
</p>
<p>At that point, if we could have had Chaps. 8 and 9 of Foundations for
</p>
<p>Designing User-Centered Systems, we would have been way ahead. It covers
</p>
<p>various cooperation settings (zero-sum, nonzero-sum, and behavioral games);
</p>
<p>techniques for promoting cooperation; social networking; critical influence factors
</p>
<p>for group performance (group size, group composition, social distance, spatial
</p>
<p>distance, collaboration support, leadership capabilities, task attractiveness); types
</p>
<p>of motivation to contribute to solutions; and social responsibility effects (demo-
</p>
<p>tivators to contribute to solutions).
</p>
<p>The section on What Leads to Good Teamwork makes another distinction
</p>
<p>between the knowledge, skills, and abilities (KSAs) traditionally used to measure
</p>
<p>individual performance and those needed for group performance. &lsquo;&lsquo;Knowledge&rsquo;&rsquo;
</p>
<p>focuses not only on technical and domain knowledge, but also on knowledge of
</p>
<p>vi Foreword</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3">http://dx.doi.org/10.1007/978-1-4471-5134-0_3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4">http://dx.doi.org/10.1007/978-1-4471-5134-0_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5">http://dx.doi.org/10.1007/978-1-4471-5134-0_5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8">http://dx.doi.org/10.1007/978-1-4471-5134-0_8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9">http://dx.doi.org/10.1007/978-1-4471-5134-0_9</a></div>
</div>
<div class="page"><p/>
<p>team objectives and team-mate awareness. &lsquo;&lsquo;Skills&rsquo;&rsquo; focuses not only on analysis
</p>
<p>and synthesis skills, but also on shared situational awareness and conflict resolu-
</p>
<p>tion skills. The &lsquo;&lsquo;A&rsquo;&rsquo; does not represent Abilities but Attitudes, such as mutual
</p>
<p>trust, team cohesion, and collective orientation. The chapter also has valuable
</p>
<p>sections on models of social processes and general implications for system design
</p>
<p>(e.g., structuring user measurement on contributions to mission effectiveness vs.
</p>
<p>user efficiency as a computer peripheral).
</p>
<p>Other strengths of the book are its inclusion of stories, good and bad usage
</p>
<p>snapshots, puzzles to stimulate learning and make it fun, and many references to
</p>
<p>helpful sources of further information. A nice observation was &lsquo;&lsquo;A year in the
</p>
<p>laboratory can save an hour in the library.&rsquo;&rsquo;
</p>
<p>As a bottom line, getting the user interface right can make a fundamental
</p>
<p>difference (just consider Apple Computer&rsquo;s Fall 2011 quarterly sales of $46 billion
</p>
<p>and profits of $13 billion). This book may not make you the next Apple, but
</p>
<p>I believe that it can help make most people and organizations perceptibly better at
</p>
<p>understanding and satisfying user needs.
</p>
<p>Barry Boehm
</p>
<p>TRW Professor of Software Engineering
</p>
<p>Computer Science Department
</p>
<p>University of Southern California
</p>
<p>Member, Committee on Human-System Design
</p>
<p>National Academy of Sciences&rsquo; National Research Council
</p>
<p>Former Director of the Information Science and Technology Office, and
</p>
<p>Director of the DDR&amp;E Software and Computer Technology Office
</p>
<p>DARPA
</p>
<p>Fellow ACM, AIAA, IEEE, INCOSE
</p>
<p>Member U.S. National Academy of Engineering
</p>
<p>Foreword vii</p>
<p/>
</div>
<div class="page"><p/>
<p>Preface
</p>
<p>Many books on user centered design and HCI focus on the way people interact
</p>
<p>with technology. This is an important issue, because people routinely interact with
</p>
<p>technology on a daily basis&mdash;personal computers, mobile phones, airplane cock-
</p>
<p>pits, or even more mundane things like electric kettles and toasters. Despite
</p>
<p>everything that we know about interaction, however, technology still does not
</p>
<p>always support what we, as users, are trying to do, or behave in the way we expect
</p>
<p>it to. This can be exasperating for us: as users, as designers, and as developers.
</p>
<p>In Foundations for Designing User-Centered Systems we help you to under-
</p>
<p>stand why people behave and interact with technology in the way they do. By
</p>
<p>helping you understand both how and why people behave in the way they do, and
</p>
<p>by helping you to develop a more systems oriented perspective, we provide you
</p>
<p>with a framework that will enable you to develop technologies that are both useful
</p>
<p>and usable. These technologies will also be more acceptable to users because they
</p>
<p>will be better suited to the way users work in their normal environment.
</p>
<p>Our Approach
</p>
<p>The people who use technology must be considered to be part of the systems they
</p>
<p>use. Although people&ndash;&lsquo;&lsquo;users&rsquo;&rsquo;&ndash;are diverse, they also have many characteristics in
</p>
<p>common. Not all of these characteristics are directly visible or available to system
</p>
<p>designers without much closer investigation. By understanding the characteristics
</p>
<p>of users, designers are better able to create safer, more usable, and more acceptable
</p>
<p>systems.
</p>
<p>We have designed Foundations for Designing User-Centered Systems to
</p>
<p>encourage you to ask critical and reflective questions throughout the design pro-
</p>
<p>cess about how your users will work with your technology. Whilst we provide key
</p>
<p>facts and characteristics about people as users, we have resisted creating a source
</p>
<p>book filled with lists of endless facts about human characteristics. We have also
</p>
<p>avoided the temptation of promoting design by rules, so we do not provide lists of
</p>
<p>guidelines that must be rigidly followed, or known problems that must be avoided.
</p>
<p>ix</p>
<p/>
</div>
<div class="page"><p/>
<p>Our goal is to help you understand the process of designing interactive tech-
</p>
<p>nologies and to introduce you to a user-centered, systems oriented approach to
</p>
<p>design. We present a detailed, theoretically grounded approach to understanding
</p>
<p>people: how they accomplish the things they do and how they work out what they
</p>
<p>need to do (their tasks) in particular situations.
</p>
<p>We have tried to select the most important things you should know about people,
</p>
<p>based on our experience of working in industry and academia. Foundations for
</p>
<p>Designing User-Centered Systems will help you develop a principled model of
</p>
<p>users, based on regularities of human behavior, which encapsulates this information
</p>
<p>so that you can predict how users will behave in different situations. This model will
</p>
<p>incorporate aspects of how perception, action, cognition, and social processes all
</p>
<p>contribute to human behavior.
</p>
<p>We believe it is important to have the grounding for innovation as well as the
</p>
<p>ability to evaluate existing systems. Our approach will give you a solid foundation
</p>
<p>for dealing with a wide range of situations and provide you with the analytical
</p>
<p>skills to design in innovative ways&mdash;including introducing you to computational
</p>
<p>and cognitive models of how users think. We build on existing methods and
</p>
<p>techniques, providing you with the basic knowledge that will let you invent your
</p>
<p>own methods for design and evaluation based on the different settings that you find
</p>
<p>yourself in.
</p>
<p>For Practitioners
</p>
<p>As the book has developed, many of our colleagues and collaborators from
</p>
<p>industry have reiterated the importance of the issues that we address, and how
</p>
<p>much they support the idea of Foundations for Designing User-Centered Systems.
</p>
<p>They often find that they have to train their staff about users, their tasks, and the
</p>
<p>context in which they perform those tasks. To address this we provide an extensive
</p>
<p>theoretical information about design-relevant user characteristics to make practi-
</p>
<p>tioners aware of the important issues. In addition, throughout the book we consider
</p>
<p>the implications for system design, where we offer concrete examples of how the
</p>
<p>information we present can be applied.
</p>
<p>For Teachers and Advanced Students
</p>
<p>Our book provides enough material for a semester-long course on users, human&ndash;
</p>
<p>computer interaction, human factors, interface design, or human behavior mod-
</p>
<p>eling where users are an inherent part of the envisaged systems. While much more
</p>
<p>x Preface</p>
<p/>
</div>
<div class="page"><p/>
<p>is known about users than we present here, we have intentionally limited ourselves
</p>
<p>to what can be covered in a semester. We provide follow-up reading for those who
</p>
<p>wish to take things further at the end of each chapter. More resources on the topics
</p>
<p>we cover are continually becoming available online and these could be used to
</p>
<p>extend our material to support longer or more advanced courses. You will also find
</p>
<p>some useful resources on the Foundations for Designing User-Centered Systems
</p>
<p>web site (www.frankritter.com/fducs).
</p>
<p>Preface xi</p>
<p/>
<div class="annotation"><a href="http://www.frankritter.com/fducs">http://www.frankritter.com/fducs</a></div>
</div>
<div class="page"><p/>
<p>Acknowledgments
</p>
<p>The book has evolved over time as we and our erstwhile colleague, David
</p>
<p>Gilmore, have taught human&ndash;computer interaction, human factors, user interface
</p>
<p>design, cognitive ergonomics, and cognitive modeling at the University of
</p>
<p>Nottingham, Penn State, the University of York (UK), and the University of St
</p>
<p>Andrews. Collating the material was made possible through the original web site
</p>
<p>created by David as a way to help support students. The idea of turning it into a
</p>
<p>book emerged as the web site expanded, and as the material has been updated.
</p>
<p>While any mistakes remain ours, we need to thank the many people who have
</p>
<p>offered feedback and encouragement along the way. In particular, we would like to
</p>
<p>thank the following people. Peter Lonsdale prepared a talk for a class that turned
</p>
<p>into lecture notes on the application of our approach to the web, and the students at
</p>
<p>Penn State (Andrew Freed) and at the University of Nottingham helped refine
</p>
<p>many of the exercises. Dan Gao, Soo Yeon Lee, and B. S. Sowmyalatha (PSU/UP)
</p>
<p>provided great feedback on improving this text, constantly encouraging more
</p>
<p>examples. Alexander Daise, Mark Kozlowski, David Kaethner, Lars Guenther, and
</p>
<p>Marcel Richter (TU/Chemnitz) also offered many good suggestions on how to
</p>
<p>improve the presentation.
</p>
<p>Our colleagues (and where they used it to teach) provided useful feedback
</p>
<p>based on use. These include Mithu Bhattacharya (PSU/UP), Michael Qin
</p>
<p>(NSMRL, U. of Connecticut/WPI), Mark Ackerman (Michigan), Kuo-Chuan
</p>
<p>(Martin) Yeh (Penn State/World Campus), Marcela Borge (PSU/UP), Pat Clemson
</p>
<p>(PSU/Beaver), and Olivier Georgeon (PSU/UP).
</p>
<p>We received comments from several people at PSU, notably Andrew Freed,
</p>
<p>C. Lee Giles, Alexander Ororbia II, James Wang, and Luke Zhang. Rob St. Amant
</p>
<p>(NCSU) and Magy Seif El-Nasr (Northeastern) provided useful comments to
</p>
<p>improve the direction of this book. Simon Robbie (CMU, Apple) provided
</p>
<p>extensive suggestions throughout the book after a chance meeting at a pterodactyl
</p>
<p>ride. Jack Sparks (MCWL) read each chapter and the breadth and depth of his
</p>
<p>biting but not hurtful comments were encouraging. Lisa Dow (University of St
</p>
<p>Andrews), Ben Dyson (Ryerson University), David Grayson (Fluent Interaction),
</p>
<p>Chandra Harrison, Junya Morita (JAIST), Les Nelson (PARC), and Margaret
</p>
<p>Ritter all provided encouragement and support as well as useful feedback on
</p>
<p>multiple chapters as the book developed. General discussions with Bill Webber
</p>
<p>(Erlbaum) and Rajal Cohen (PSU) improved the presentation. We should also note
</p>
<p>xiii</p>
<p/>
</div>
<div class="page"><p/>
<p>that books by John R. Anderson, Boff and Lincoln, Don Norman, and Chris
</p>
<p>Wickens and his colleagues have helped shape this work, and some of the ways
</p>
<p>they organize topics are reflected here. Don Meeker (PSU) provided photos and
</p>
<p>useful comments about the use of his photos.
</p>
<p>Many people provided feedback on individual chapters which has greatly
</p>
<p>helped the book as well, including Jennifer Bittner (Indiana), Shawn Clark (PSU/
</p>
<p>UP), Georgious Christous (European University Cyprus), Ed Glantz (PSU/UP),
</p>
<p>David Golightly (University of Nottingham), Kate Hone (Brunel University), M.
</p>
<p>Cameron Jones (Google), Bill Kennedy (GMU), Russell Lock (Loughborough
</p>
<p>University), Faidon Loumakis (Fluent Interaction), Naomi Malone (UCF), Sylvie
</p>
<p>Noel (Communications Research Centre Canada/Centre de recherches sur les
</p>
<p>communications Canada), Shamil Parbhoo (Fluent Interaction), Ling Rothrock
</p>
<p>(PSU/UP), Marco de Sa (Twitter), Joe Sanford (PSU/UP), Elaine Seery (Science
</p>
<p>Editing), Sarah Sharples (University of Nottingham), Tim Storer (University of
</p>
<p>Glasgow), and Fiona Woodcock (Fluent Interaction).
</p>
<p>Gordon Baxter&rsquo;s work on the book was supported by funding from the UK
</p>
<p>EPSRC&rsquo;s Large Scale Complex IT Systems project. Frank Ritter has drawn on
</p>
<p>material developed with support from ONR and DTRA and applied this material to
</p>
<p>their projects, having been influenced by these projects and having used this
</p>
<p>material to help train researchers on those projects. A Senior Fulbright Fellowship
</p>
<p>provided support to teach this material at TU/Chemnitz, and the College of IST has
</p>
<p>been supportive.
</p>
<p>Finally, Beverley Ford, Ben Bishop, Jake Kirby, and a copyeditor at Springer
</p>
<p>have been very helpful and encouraging. They helped us push this book over the
</p>
<p>finish line with their kind words and support. Figures and pictures used with
</p>
<p>permission by their authors. Unattributed figures are copyright by the authors and
</p>
<p>are available for use by instructors on an instructors&rsquo; web site.
</p>
<p>Citations are done in Springer house style; references are done in APA format.
</p>
<p>xiv Acknowledgments</p>
<p/>
</div>
<div class="page"><p/>
<p>Contents
</p>
<p>Part I Introduction: Aims, Motivations, and Introduction
</p>
<p>to Human-Centered Design
</p>
<p>1 Introducing User-Centered Systems Design . . . . . . . . . . . . . . . . . 3
</p>
<p>1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
</p>
<p>1.2 Starting to Understand Users . . . . . . . . . . . . . . . . . . . . . . . 4
</p>
<p>1.2.1 Designing Mappings Between Buttons
</p>
<p>and Lights . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
</p>
<p>1.2.2 Designing Stove-Top Mappings . . . . . . . . . . . . . . 6
</p>
<p>1.2.3 Designing Coins . . . . . . . . . . . . . . . . . . . . . . . . . 7
</p>
<p>1.2.4 What Happens If You do not Take Proper
</p>
<p>Account of Users, Tasks, and Context? . . . . . . . . . 10
</p>
<p>1.3 The Benefits and Costs of Understanding Users . . . . . . . . . . 10
</p>
<p>1.3.1 Benefit 1: More Usable Products . . . . . . . . . . . . . 11
</p>
<p>1.3.2 Benefit 2: Financial Savings. . . . . . . . . . . . . . . . . 12
</p>
<p>1.3.3 Benefit 3: Safer Systems . . . . . . . . . . . . . . . . . . . 13
</p>
<p>1.3.4 Cost 1: Understanding the Users Does Not
</p>
<p>Guarantee Success . . . . . . . . . . . . . . . . . . . . . . . 14
</p>
<p>1.3.5 Cost 2: Knowing When to Stop Analyzing
</p>
<p>the Users can be Difficult . . . . . . . . . . . . . . . . . . 14
</p>
<p>1.4 Summarizing Design Relevant User Characteristics:
</p>
<p>The ABCS Framework . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
</p>
<p>1.4.1 Anthropometrics Approach. . . . . . . . . . . . . . . . . . 17
</p>
<p>1.4.2 Behavioral Aspects . . . . . . . . . . . . . . . . . . . . . . . 19
</p>
<p>1.4.3 Cognition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
</p>
<p>1.4.4 Social Factors. . . . . . . . . . . . . . . . . . . . . . . . . . . 21
</p>
<p>1.5 Simulating User Characteristics: Cognitive Architectures. . . . 23
</p>
<p>1.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
</p>
<p>1.6.1 Structure of the Rest of the Book . . . . . . . . . . . . . 25
</p>
<p>1.6.2 Future Work. . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
</p>
<p>1.7 Other Resources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
</p>
<p>1.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
</p>
<p>References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
</p>
<p>xv</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1">http://dx.doi.org/10.1007/978-1-4471-5134-0_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1">http://dx.doi.org/10.1007/978-1-4471-5134-0_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec4">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec4">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec5">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec5">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec6">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec6">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec6">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec10">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec10">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec12">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec12">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec12">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec14">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec14">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec15">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec15">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec16">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec16</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec16">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec16</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec17">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec17</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec17">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec17</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec18">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec18</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec18">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec18</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec19">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec19</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec19">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec19</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec20">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec20</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec20">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec20</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec21">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec21</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec21">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec21</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec23">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec23</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec23">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec23</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec24">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec24</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec24">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Sec24</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Bib1">http://dx.doi.org/10.1007/978-1-4471-5134-0_1#Bib1</a></div>
</div>
<div class="page"><p/>
<p>2 User-Centered Systems Design: A Brief History. . . . . . . . . . . . . . 33
</p>
<p>2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
</p>
<p>2.2 Influential and Related Research Fields . . . . . . . . . . . . . . . . 34
</p>
<p>2.2.1 Ergonomics and Human Factors . . . . . . . . . . . . . . 35
</p>
<p>2.2.2 Socio-Technical Systems Design. . . . . . . . . . . . . . 40
</p>
<p>2.2.3 Cognitive Modeling and Programmable
</p>
<p>User Models. . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
</p>
<p>2.2.4 User-Centered and Human-Centered Design. . . . . . 43
</p>
<p>2.2.5 User Experience . . . . . . . . . . . . . . . . . . . . . . . . . 44
</p>
<p>2.2.6 Human&ndash;Computer Interaction . . . . . . . . . . . . . . . . 45
</p>
<p>2.3 Standards, Principles, and Guidelines . . . . . . . . . . . . . . . . . 46
</p>
<p>2.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
</p>
<p>2.5 Other Resources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51
</p>
<p>2.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52
</p>
<p>References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
</p>
<p>Part II Design Relevant User Characteristics: The ABCS
</p>
<p>3 Anthropometrics: Important Aspects of Users&rsquo; Bodies . . . . . . . . . 57
</p>
<p>3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57
</p>
<p>3.2 Physical Aspects of Interaction. . . . . . . . . . . . . . . . . . . . . . 59
</p>
<p>3.2.1 Posture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59
</p>
<p>3.2.2 Load Bearing . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
</p>
<p>3.3 Interacting with Haptic Devices . . . . . . . . . . . . . . . . . . . . . 62
</p>
<p>3.3.1 Physical Keyboards . . . . . . . . . . . . . . . . . . . . . . . 63
</p>
<p>3.3.2 Touch Screens . . . . . . . . . . . . . . . . . . . . . . . . . . 65
</p>
<p>3.3.3 Pointing Devices. . . . . . . . . . . . . . . . . . . . . . . . . 66
</p>
<p>3.3.4 Mobile Phones . . . . . . . . . . . . . . . . . . . . . . . . . . 69
</p>
<p>3.3.5 Video Games and Virtual Reality Systems. . . . . . . 70
</p>
<p>3.3.6 Other Devices. . . . . . . . . . . . . . . . . . . . . . . . . . . 71
</p>
<p>3.3.7 Advantages and Disadvantages
</p>
<p>of Haptic Interfaces. . . . . . . . . . . . . . . . . . . . . . . 73
</p>
<p>3.4 Implications for System Design . . . . . . . . . . . . . . . . . . . . . 74
</p>
<p>3.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75
</p>
<p>3.6 Other Resources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76
</p>
<p>3.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77
</p>
<p>References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79
</p>
<p>4 Behavior: Basic Psychology of the User . . . . . . . . . . . . . . . . . . . . 81
</p>
<p>4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81
</p>
<p>4.2 Behavioral Psychology Terminology . . . . . . . . . . . . . . . . . . 82
</p>
<p>4.2.1 Thresholds and Just Noticeable
</p>
<p>Differences (JNDs) . . . . . . . . . . . . . . . . . . . . . . . 82
</p>
<p>xvi Contents</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2">http://dx.doi.org/10.1007/978-1-4471-5134-0_2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2">http://dx.doi.org/10.1007/978-1-4471-5134-0_2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec10">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec10">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec12">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec12">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec14">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec14">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec15">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec15">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec16">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec16</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec16">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Sec16</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Bib1">http://dx.doi.org/10.1007/978-1-4471-5134-0_2#Bib1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3">http://dx.doi.org/10.1007/978-1-4471-5134-0_3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3">http://dx.doi.org/10.1007/978-1-4471-5134-0_3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec4">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec4">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec5">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec5">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec6">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec6">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec10">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec10">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec12">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec12">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec12">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec14">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec14">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec15">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec15">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec16">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec16</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec16">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Sec16</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Bib1">http://dx.doi.org/10.1007/978-1-4471-5134-0_3#Bib1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4">http://dx.doi.org/10.1007/978-1-4471-5134-0_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4">http://dx.doi.org/10.1007/978-1-4471-5134-0_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec3</a></div>
</div>
<div class="page"><p/>
<p>4.2.2 Habituation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
</p>
<p>4.2.3 Signal Detection Theory (SDT) . . . . . . . . . . . . . . 83
</p>
<p>4.2.4 Implications for System Design . . . . . . . . . . . . . . 85
</p>
<p>4.3 The Physiology of Vision . . . . . . . . . . . . . . . . . . . . . . . . . 86
</p>
<p>4.3.1 Overview of Vision. . . . . . . . . . . . . . . . . . . . . . . 86
</p>
<p>4.3.2 The Basic Structure of the Eye. . . . . . . . . . . . . . . 86
</p>
<p>4.3.3 Using Eye-Tracking to Measure
</p>
<p>Eye Movements . . . . . . . . . . . . . . . . . . . . . . . . . 88
</p>
<p>4.3.4 Rods and Cones . . . . . . . . . . . . . . . . . . . . . . . . . 89
</p>
<p>4.3.5 Implications for System Design . . . . . . . . . . . . . . 91
</p>
<p>4.4 Low Level Visual Perception . . . . . . . . . . . . . . . . . . . . . . . 92
</p>
<p>4.4.1 Vision and the Measurement of Light . . . . . . . . . . 92
</p>
<p>4.4.2 Color Vision. . . . . . . . . . . . . . . . . . . . . . . . . . . . 94
</p>
<p>4.4.3 Color Blindness . . . . . . . . . . . . . . . . . . . . . . . . . 95
</p>
<p>4.4.4 Color Systems . . . . . . . . . . . . . . . . . . . . . . . . . . 96
</p>
<p>4.4.5 Flicker . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96
</p>
<p>4.4.6 Pop-Out Effects . . . . . . . . . . . . . . . . . . . . . . . . . 97
</p>
<p>4.4.7 Implications for System Design . . . . . . . . . . . . . . 100
</p>
<p>4.5 Higher Level Visual Perception . . . . . . . . . . . . . . . . . . . . . 100
</p>
<p>4.5.1 Movement and Spatial Perception . . . . . . . . . . . . . 101
</p>
<p>4.5.2 Depth Cues . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101
</p>
<p>4.5.3 Subitizing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102
</p>
<p>4.5.4 Gestalt Principles of Grouping . . . . . . . . . . . . . . . 103
</p>
<p>4.5.5 Other Theories of High Level Visual Perception. . . 103
</p>
<p>4.5.6 Implications for System Design . . . . . . . . . . . . . . 105
</p>
<p>4.6 The Auditory System . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106
</p>
<p>4.6.1 Theoretical Description of Sound . . . . . . . . . . . . . 106
</p>
<p>4.6.2 Measuring Sound . . . . . . . . . . . . . . . . . . . . . . . . 108
</p>
<p>4.6.3 Localizing Sound . . . . . . . . . . . . . . . . . . . . . . . . 110
</p>
<p>4.6.4 Discriminating Sounds. . . . . . . . . . . . . . . . . . . . . 111
</p>
<p>4.6.5 Implications for System Design . . . . . . . . . . . . . . 111
</p>
<p>4.7 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112
</p>
<p>4.7.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112
</p>
<p>4.7.2 Maslow&rsquo;s Hierarchical Theory . . . . . . . . . . . . . . . 113
</p>
<p>4.7.3 Extrinsic and Intrinsic Motivation . . . . . . . . . . . . . 113
</p>
<p>4.7.4 Implications for System Design . . . . . . . . . . . . . . 116
</p>
<p>4.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
</p>
<p>4.9 Other Resources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
</p>
<p>4.10 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
</p>
<p>References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
</p>
<p>5 Cognition: Memory, Attention, and Learning . . . . . . . . . . . . . . . 123
</p>
<p>5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
</p>
<p>5.2 Memory. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
</p>
<p>Contents xvii</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec4">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec4">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec5">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec5">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec6">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec6">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec10">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec10">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec10">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec12">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec12">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec14">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec14">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec15">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec15">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec16">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec16</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec16">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec16</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec17">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec17</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec17">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec17</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec18">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec18</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec18">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec18</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec19">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec19</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec19">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec19</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec20">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec20</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec20">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec20</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec21">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec21</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec21">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec21</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec22">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec22</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec22">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec22</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec23">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec23</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec23">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec23</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec24">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec24</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec24">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec24</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec25">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec25</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec25">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec25</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec26">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec26</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec26">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec26</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec27">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec27</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec27">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec27</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec28">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec28</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec28">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec28</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec29">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec29</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec29">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec29</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec30">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec30</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec30">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec30</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec31">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec31</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec31">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec31</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec32">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec32</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec32">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec32</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec33">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec33</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec33">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec33</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec34">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec34</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec34">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec34</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec35">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec35</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec35">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec35</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec36">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec36</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec36">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec36</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec37">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec37</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec37">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec37</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec38">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec38</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec38">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec38</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec39">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec39</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec39">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec39</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec40">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec40</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec40">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec40</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec41">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec41</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec41">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Sec41</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Bib1">http://dx.doi.org/10.1007/978-1-4471-5134-0_4#Bib1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5">http://dx.doi.org/10.1007/978-1-4471-5134-0_5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5">http://dx.doi.org/10.1007/978-1-4471-5134-0_5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec2</a></div>
</div>
<div class="page"><p/>
<p>5.2.1 Types of Memory . . . . . . . . . . . . . . . . . . . . . . . . 124
</p>
<p>5.2.2 Mnemonics and Aids to Memory . . . . . . . . . . . . . 131
</p>
<p>5.2.3 PQ4R: A Way to Improve Reading
</p>
<p>Comprehension . . . . . . . . . . . . . . . . . . . . . . . . . . 133
</p>
<p>5.2.4 Memory Biases. . . . . . . . . . . . . . . . . . . . . . . . . . 133
</p>
<p>5.2.5 Implications for System Design . . . . . . . . . . . . . . 136
</p>
<p>5.3 Attention . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
</p>
<p>5.3.1 Wickens&rsquo; Theory of Attentional Resources . . . . . . 139
</p>
<p>5.3.2 An Information Processing Model of Attention. . . . 140
</p>
<p>5.3.3 Divided Attention . . . . . . . . . . . . . . . . . . . . . . . . 141
</p>
<p>5.3.4 Slips of Action . . . . . . . . . . . . . . . . . . . . . . . . . . 141
</p>
<p>5.3.5 Interruptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142
</p>
<p>5.3.6 Automation Deficit: Keeping the Human
</p>
<p>in the Loop . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
</p>
<p>5.3.7 Implications for System Design . . . . . . . . . . . . . . 144
</p>
<p>5.4 Learning and Skilled Behavior . . . . . . . . . . . . . . . . . . . . . . 144
</p>
<p>5.4.1 The Process of Learning . . . . . . . . . . . . . . . . . . . 145
</p>
<p>5.4.2 Improvements from Learning . . . . . . . . . . . . . . . . 147
</p>
<p>5.4.3 Types of Learning. . . . . . . . . . . . . . . . . . . . . . . . 150
</p>
<p>5.4.4 Skilled Behavior, Users in Complex
</p>
<p>Environments . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
</p>
<p>5.4.5 Expertise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154
</p>
<p>5.4.6 Transfer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155
</p>
<p>5.4.7 Implications for System Design . . . . . . . . . . . . . . 155
</p>
<p>5.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158
</p>
<p>5.6 Other Resources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158
</p>
<p>5.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159
</p>
<p>References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161
</p>
<p>6 Cognition: Mental Representations, Problem Solving,
</p>
<p>and Decision Making . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165
</p>
<p>6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165
</p>
<p>6.2 Mental Representations . . . . . . . . . . . . . . . . . . . . . . . . . . . 166
</p>
<p>6.2.1 Simple Representations . . . . . . . . . . . . . . . . . . . . 167
</p>
<p>6.2.2 User&rsquo;s Mental Models . . . . . . . . . . . . . . . . . . . . . 168
</p>
<p>6.2.3 Feeling of Knowing and Confidence Judgments . . . 171
</p>
<p>6.2.4 Stimulus&ndash;Response Compatibility
</p>
<p>for Mental Models . . . . . . . . . . . . . . . . . . . . . . . 171
</p>
<p>6.2.5 Implications for System Design . . . . . . . . . . . . . . 173
</p>
<p>6.3 Problem Solving . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174
</p>
<p>6.3.1 The Importance of Problem Solving . . . . . . . . . . . 175
</p>
<p>6.3.2 Examples of Problem Solving . . . . . . . . . . . . . . . 175
</p>
<p>6.3.3 Known Influences on Problem Solving . . . . . . . . . 176
</p>
<p>6.3.4 Ill-Structured Problems . . . . . . . . . . . . . . . . . . . . 181
</p>
<p>6.3.5 Summary of Problem Solving with Implications
</p>
<p>for System Design . . . . . . . . . . . . . . . . . . . . . . . 183
</p>
<p>xviii Contents</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec12">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec12">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec12">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec19">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec19</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec19">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec19</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec20">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec20</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec20">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec20</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec21">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec21</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec21">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec21</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec22">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec22</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec22">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec22</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec23">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec23</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec23">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec23</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec24">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec24</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec24">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec24</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec25">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec25</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec25">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec25</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec26">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec26</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec26">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec26</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec26">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec26</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec27">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec27</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec27">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec27</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec28">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec28</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec28">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec28</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec29">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec29</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec29">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec29</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec30">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec30</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec30">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec30</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec31">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec31</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec31">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec31</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec32">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec32</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec32">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec32</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec32">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec32</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec33">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec33</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec33">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec33</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec34">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec34</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec34">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec34</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec35">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec35</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec35">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec35</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec36">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec36</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec36">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec36</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec37">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec37</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec37">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec37</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec38">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec38</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec38">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Sec38</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Bib1">http://dx.doi.org/10.1007/978-1-4471-5134-0_5#Bib1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6">http://dx.doi.org/10.1007/978-1-4471-5134-0_6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6">http://dx.doi.org/10.1007/978-1-4471-5134-0_6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6">http://dx.doi.org/10.1007/978-1-4471-5134-0_6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec4">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec4">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec5">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec5">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec6">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec6">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec6">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec10">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec10">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec17">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec17</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec17">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec17</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec18">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec18</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec18">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec18</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec18">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec18</a></div>
</div>
<div class="page"><p/>
<p>6.4 Decision Making . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183
</p>
<p>6.4.1 Decision Making is Often Not Rational . . . . . . . . . 184
</p>
<p>6.4.2 Simple Decisions: Hicks Law
</p>
<p>and Speed&ndash;Accuracy Trade-Offs. . . . . . . . . . . . . . 184
</p>
<p>6.4.3 Stimulus&ndash;Response Compatibility for Decisions . . . 185
</p>
<p>6.4.4 Known Influences on Decision Making . . . . . . . . . 187
</p>
<p>6.4.5 Larger Scale Decision Making Process:
</p>
<p>Expertise and RPDM. . . . . . . . . . . . . . . . . . . . . . 191
</p>
<p>6.4.6 Summary of Decision Making with Implications
</p>
<p>for System Design . . . . . . . . . . . . . . . . . . . . . . . 192
</p>
<p>6.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196
</p>
<p>6.6 Other Resources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197
</p>
<p>6.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
</p>
<p>References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
</p>
<p>7 Cognition: Human&ndash;Computer Communication . . . . . . . . . . . . . . 201
</p>
<p>7.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201
</p>
<p>7.2 Language. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202
</p>
<p>7.2.1 Symbols, Syntax, and Semantics . . . . . . . . . . . . . . 202
</p>
<p>7.2.2 Grice&rsquo;s Maxims of Conversation. . . . . . . . . . . . . . 203
</p>
<p>7.2.3 Implications for System Design . . . . . . . . . . . . . . 204
</p>
<p>7.3 How Users Read. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205
</p>
<p>7.3.1 The Effects of Fonts . . . . . . . . . . . . . . . . . . . . . . 207
</p>
<p>7.3.2 Graphic Design to Help Reading and Scanning . . . 208
</p>
<p>7.3.3 Paper-Based Versus Screen-Based Reading . . . . . . 208
</p>
<p>7.3.4 Scanning Displays and Menus . . . . . . . . . . . . . . . 210
</p>
<p>7.3.5 Implications for System Design . . . . . . . . . . . . . . 211
</p>
<p>7.4 Information Seeking Behavior . . . . . . . . . . . . . . . . . . . . . . 212
</p>
<p>7.4.1 Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212
</p>
<p>7.4.2 Human Information Behavior . . . . . . . . . . . . . . . . 212
</p>
<p>7.4.3 Human Information Seeking Behavior . . . . . . . . . . 213
</p>
<p>7.4.4 Information Scent . . . . . . . . . . . . . . . . . . . . . . . . 213
</p>
<p>7.4.5 Implications for System Design . . . . . . . . . . . . . . 214
</p>
<p>7.5 Designing Content . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 214
</p>
<p>7.5.1 Content Strategy . . . . . . . . . . . . . . . . . . . . . . . . . 215
</p>
<p>7.5.2 Information Architecture . . . . . . . . . . . . . . . . . . . 215
</p>
<p>7.5.3 Creating Content. . . . . . . . . . . . . . . . . . . . . . . . . 216
</p>
<p>7.5.4 Structuring Content . . . . . . . . . . . . . . . . . . . . . . . 216
</p>
<p>7.5.5 Delivering Content . . . . . . . . . . . . . . . . . . . . . . . 217
</p>
<p>7.6 Implications for System Design . . . . . . . . . . . . . . . . . . . . . 217
</p>
<p>7.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218
</p>
<p>7.8 Other Resources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 219
</p>
<p>7.9 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220
</p>
<p>References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221
</p>
<p>Contents xix</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec19">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec19</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec19">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec19</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec20">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec20</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec20">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec20</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec21">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec21</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec21">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec21</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec21">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec21</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec22">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec22</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec22">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec22</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec23">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec23</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec23">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec23</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec30">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec30</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec30">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec30</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec30">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec30</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec31">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec31</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec31">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec31</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec31">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec31</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec34">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec34</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec34">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec34</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec35">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec35</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec35">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec35</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec36">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec36</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec36">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Sec36</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Bib1">http://dx.doi.org/10.1007/978-1-4471-5134-0_6#Bib1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7">http://dx.doi.org/10.1007/978-1-4471-5134-0_7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7">http://dx.doi.org/10.1007/978-1-4471-5134-0_7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec4">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec4">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec5">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec5">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec6">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec6">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec10">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec10">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec12">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec12">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec14">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec14">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec15">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec15">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec16">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec16</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec16">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec16</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec17">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec17</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec17">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec17</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec18">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec18</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec18">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec18</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec19">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec19</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec19">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec19</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec20">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec20</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec20">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec20</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec21">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec21</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec21">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec21</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec22">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec22</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec22">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec22</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec23">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec23</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec23">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec23</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec24">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec24</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec24">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec24</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec25">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec25</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec25">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec25</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec26">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec26</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec26">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec26</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec27">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec27</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec27">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Sec27</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Bib1">http://dx.doi.org/10.1007/978-1-4471-5134-0_7#Bib1</a></div>
</div>
<div class="page"><p/>
<p>8 Social: Social Cognition and Teamwork . . . . . . . . . . . . . . . . . . . 225
</p>
<p>8.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225
</p>
<p>8.2 Social Effects on Decision Making . . . . . . . . . . . . . . . . . . . 228
</p>
<p>8.2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228
</p>
<p>8.2.2 Social Responsibility Effects . . . . . . . . . . . . . . . . 228
</p>
<p>8.2.3 Attributions and Attributional Style. . . . . . . . . . . . 230
</p>
<p>8.2.4 Majority and Minority Effects . . . . . . . . . . . . . . . 233
</p>
<p>8.2.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234
</p>
<p>8.3 Factors Affecting Team Performance . . . . . . . . . . . . . . . . . 234
</p>
<p>8.3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234
</p>
<p>8.3.2 Team Size . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 235
</p>
<p>8.3.3 Team Competencies . . . . . . . . . . . . . . . . . . . . . . 236
</p>
<p>8.3.4 Team Structure and Composition . . . . . . . . . . . . . 237
</p>
<p>8.3.5 Social Distance. . . . . . . . . . . . . . . . . . . . . . . . . . 239
</p>
<p>8.3.6 Spatial Distance . . . . . . . . . . . . . . . . . . . . . . . . . 240
</p>
<p>8.3.7 Mutual Support and Mutual Surveillance . . . . . . . . 241
</p>
<p>8.3.8 Authority Figures . . . . . . . . . . . . . . . . . . . . . . . . 241
</p>
<p>8.3.9 Task Attractiveness . . . . . . . . . . . . . . . . . . . . . . . 242
</p>
<p>8.3.10 Team Processes and Tasks . . . . . . . . . . . . . . . . . . 243
</p>
<p>8.3.11 Implications for System Design . . . . . . . . . . . . . . 243
</p>
<p>8.3.12 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244
</p>
<p>8.4 Factors Affecting Performance in Community Settings . . . . . 244
</p>
<p>8.5 Implications for System Design . . . . . . . . . . . . . . . . . . . . . 245
</p>
<p>8.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247
</p>
<p>8.7 Other Resources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248
</p>
<p>8.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248
</p>
<p>References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 249
</p>
<p>9 Social: Theories and Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253
</p>
<p>9.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253
</p>
<p>9.2 Analyzing How People Work Together . . . . . . . . . . . . . . . . 254
</p>
<p>9.2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254
</p>
<p>9.2.2 Informal, Pairwise Analyses . . . . . . . . . . . . . . . . . 254
</p>
<p>9.2.3 Exchange Costs and Benefits . . . . . . . . . . . . . . . . 256
</p>
<p>9.2.4 Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260
</p>
<p>9.2.5 Good Personal Social Networks Lead
</p>
<p>to Better Work . . . . . . . . . . . . . . . . . . . . . . . . . . 262
</p>
<p>9.2.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263
</p>
<p>9.3 Higher Social Levels: Organizational and Cultural . . . . . . . . 264
</p>
<p>9.3.1 Organizational Effects . . . . . . . . . . . . . . . . . . . . . 265
</p>
<p>9.3.2 Cultural Effects . . . . . . . . . . . . . . . . . . . . . . . . . 265
</p>
<p>9.3.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266
</p>
<p>xx Contents</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8">http://dx.doi.org/10.1007/978-1-4471-5134-0_8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8">http://dx.doi.org/10.1007/978-1-4471-5134-0_8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec4">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec4">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec5">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec5">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec10">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec10">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec12">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec12">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec14">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec14">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec15">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec15">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec16">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec16</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec16">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec16</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec17">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec17</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec17">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec17</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec18">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec18</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec18">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec18</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec19">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec19</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec19">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec19</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec20">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec20</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec20">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec20</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec21">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec21</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec21">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec21</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec22">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec22</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec22">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec22</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec23">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec23</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec23">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec23</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec24">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec24</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec24">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec24</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec25">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec25</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec25">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec25</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec26">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec26</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec26">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Sec26</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Bib1">http://dx.doi.org/10.1007/978-1-4471-5134-0_8#Bib1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9">http://dx.doi.org/10.1007/978-1-4471-5134-0_9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9">http://dx.doi.org/10.1007/978-1-4471-5134-0_9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec4">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec4">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec5">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec5">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec6">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec6">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec10">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec10">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec12">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec12">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec12</a></div>
</div>
<div class="page"><p/>
<p>9.4 Models of Social Processes . . . . . . . . . . . . . . . . . . . . . . . . 266
</p>
<p>9.4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266
</p>
<p>9.4.2 Descriptive Social Models . . . . . . . . . . . . . . . . . . 267
</p>
<p>9.4.3 Soft Systems Methodology. . . . . . . . . . . . . . . . . . 269
</p>
<p>9.4.4 Rich Pictures . . . . . . . . . . . . . . . . . . . . . . . . . . . 270
</p>
<p>9.4.5 Computational Models of Social Behavior . . . . . . . 272
</p>
<p>9.4.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273
</p>
<p>9.5 General Implications for System Design . . . . . . . . . . . . . . . 273
</p>
<p>9.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 275
</p>
<p>9.7 Other Resources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 275
</p>
<p>9.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 276
</p>
<p>References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277
</p>
<p>10 Errors: An Inherent Part of Human-System Performance . . . . . . 281
</p>
<p>10.1 Introduction to Errors . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281
</p>
<p>10.1.1 What is Error? . . . . . . . . . . . . . . . . . . . . . . . . . . 282
</p>
<p>10.1.2 The Fine Line Between Success and Failure . . . . . 284
</p>
<p>10.1.3 The Accident was Caused
</p>
<p>by Human Error, Right? . . . . . . . . . . . . . . . . . . . 285
</p>
<p>10.2 Studying Error . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288
</p>
<p>10.2.1 Laboratory-Based Experiments . . . . . . . . . . . . . . . 289
</p>
<p>10.2.2 Field-Based Observation . . . . . . . . . . . . . . . . . . . 290
</p>
<p>10.2.3 Archive Data . . . . . . . . . . . . . . . . . . . . . . . . . . . 291
</p>
<p>10.2.4 Selecting the Most Appropriate Data
</p>
<p>Collection Method . . . . . . . . . . . . . . . . . . . . . . . 291
</p>
<p>10.3 Error Taxonomies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 292
</p>
<p>10.3.1 The Technique for Human Error
</p>
<p>Rate Prediction . . . . . . . . . . . . . . . . . . . . . . . . . . 292
</p>
<p>10.3.2 Generic Error Modeling System . . . . . . . . . . . . . . 293
</p>
<p>10.3.3 The Cognitive Reliability and Error
</p>
<p>Analysis Method. . . . . . . . . . . . . . . . . . . . . . . . . 294
</p>
<p>10.4 Analyzing Errors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296
</p>
<p>10.4.1 Event Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296
</p>
<p>10.4.2 Fault Trees. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296
</p>
<p>10.4.3 CREAM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 297
</p>
<p>10.4.4 THEA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298
</p>
<p>10.5 Implications for System Design . . . . . . . . . . . . . . . . . . . . . 300
</p>
<p>10.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 301
</p>
<p>10.7 Other Resources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 302
</p>
<p>10.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 303
</p>
<p>References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 303
</p>
<p>Contents xxi</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec14">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec14">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec15">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec15">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec20">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec20</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec20">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec20</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec21">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec21</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec21">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec21</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec22">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec22</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec22">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec22</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec25">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec25</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec25">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec25</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec26">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec26</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec26">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec26</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec27">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec27</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec27">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec27</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec28">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec28</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec28">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec28</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec29">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec29</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec29">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Sec29</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Bib1">http://dx.doi.org/10.1007/978-1-4471-5134-0_9#Bib1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10">http://dx.doi.org/10.1007/978-1-4471-5134-0_10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10">http://dx.doi.org/10.1007/978-1-4471-5134-0_10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec4">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec4">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec4">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec5">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec5">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec6">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec6">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec10">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec10">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec12">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec12">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec14">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec14">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec15">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec15">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec16">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec16</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec16">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec16</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec17">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec17</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec17">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec17</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec18">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec18</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec18">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec18</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec19">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec19</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec19">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec19</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec20">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec20</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec20">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec20</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec21">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec21</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec21">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec21</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec22">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec22</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec22">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Sec22</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Bib1">http://dx.doi.org/10.1007/978-1-4471-5134-0_10#Bib1</a></div>
</div>
<div class="page"><p/>
<p>Part III Methods
</p>
<p>11 Methodology I: Task Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . 309
</p>
<p>11.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309
</p>
<p>11.2 The Uses of Task Analysis . . . . . . . . . . . . . . . . . . . . . . . . 311
</p>
<p>11.2.1 Allocation of Function. . . . . . . . . . . . . . . . . . . . . 311
</p>
<p>11.2.2 Performance Assurance . . . . . . . . . . . . . . . . . . . . 311
</p>
<p>11.2.3 Task and Interface Design . . . . . . . . . . . . . . . . . . 313
</p>
<p>11.3 Hierarchical Task Analysis . . . . . . . . . . . . . . . . . . . . . . . . 314
</p>
<p>11.3.1 HTA Components . . . . . . . . . . . . . . . . . . . . . . . . 314
</p>
<p>11.3.2 Example Application of HTA. . . . . . . . . . . . . . . . 315
</p>
<p>11.3.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 317
</p>
<p>11.4 Cognitive Task Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . 317
</p>
<p>11.4.1 CTA Components . . . . . . . . . . . . . . . . . . . . . . . . 317
</p>
<p>11.4.2 Example Application of CTA . . . . . . . . . . . . . . . . 318
</p>
<p>11.4.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319
</p>
<p>11.5 GOMS. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319
</p>
<p>11.5.1 GOMS Components . . . . . . . . . . . . . . . . . . . . . . 320
</p>
<p>11.5.2 Example Application of GOMS . . . . . . . . . . . . . . 320
</p>
<p>11.5.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 322
</p>
<p>11.6 The Keystroke Level Model. . . . . . . . . . . . . . . . . . . . . . . . 322
</p>
<p>11.6.1 Description of KLM Components . . . . . . . . . . . . . 324
</p>
<p>11.6.2 Example Application of the KLM. . . . . . . . . . . . . 325
</p>
<p>11.6.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325
</p>
<p>11.7 Considerations When Choosing a TA Method . . . . . . . . . . . 326
</p>
<p>11.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 327
</p>
<p>11.9 Other Resources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 329
</p>
<p>11.10 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 330
</p>
<p>References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 331
</p>
<p>12 Methodology II: Cognitive Dimensions and the Gulfs. . . . . . . . . . 335
</p>
<p>12.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 335
</p>
<p>12.2 The Cognitive Dimensions. . . . . . . . . . . . . . . . . . . . . . . . . 336
</p>
<p>12.2.1 Hidden Dependencies . . . . . . . . . . . . . . . . . . . . . 336
</p>
<p>12.2.2 Viscosity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 338
</p>
<p>12.2.3 Role-Expressiveness . . . . . . . . . . . . . . . . . . . . . . 339
</p>
<p>12.2.4 Premature Commitment . . . . . . . . . . . . . . . . . . . . 340
</p>
<p>12.2.5 Hard Mental Operations. . . . . . . . . . . . . . . . . . . . 341
</p>
<p>12.3 Turning Cognitive Dimensions into a Methodology . . . . . . . 342
</p>
<p>12.4 What is Omitted by the Cognitive Dimensions? . . . . . . . . . . 343
</p>
<p>12.5 Norman&rsquo;s Seven Stages of Action. . . . . . . . . . . . . . . . . . . . 343
</p>
<p>12.5.1 The Gulfs of Evaluation and Execution . . . . . . . . . 345
</p>
<p>12.5.2 The Gulfs in Practice . . . . . . . . . . . . . . . . . . . . . 345
</p>
<p>12.6 Implications of the Gulfs for Design . . . . . . . . . . . . . . . . . . 346
</p>
<p>xxii Contents</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11">http://dx.doi.org/10.1007/978-1-4471-5134-0_11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11">http://dx.doi.org/10.1007/978-1-4471-5134-0_11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec4">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec4">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec5">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec5">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec6">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec6">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec10">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec10">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec12">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec12">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec14">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec14">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec15">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec15">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec16">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec16</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec16">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec16</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec17">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec17</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec17">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec17</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec18">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec18</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec18">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec18</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec19">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec19</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec19">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec19</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec20">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec20</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec20">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec20</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec21">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec21</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec21">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec21</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec22">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec22</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec22">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec22</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec23">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec23</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec23">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec23</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec24">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec24</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec24">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec24</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec25">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec25</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec25">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Sec25</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Bib1">http://dx.doi.org/10.1007/978-1-4471-5134-0_11#Bib1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12">http://dx.doi.org/10.1007/978-1-4471-5134-0_12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12">http://dx.doi.org/10.1007/978-1-4471-5134-0_12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec4">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec4">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec5">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec5">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec6">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec6">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec10">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec10">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec12">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec12">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec13</a></div>
</div>
<div class="page"><p/>
<p>12.7 Limitations of the Gulfs . . . . . . . . . . . . . . . . . . . . . . . . . . 348
</p>
<p>12.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 350
</p>
<p>12.9 Other Resources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 350
</p>
<p>12.10 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 351
</p>
<p>References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 351
</p>
<p>13 Methodology III: Empirical Evaluation . . . . . . . . . . . . . . . . . . . . 353
</p>
<p>13.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 353
</p>
<p>13.1.1 Why Do We Need User Testing? . . . . . . . . . . . . . 354
</p>
<p>13.1.2 When Do We Carry Out User Testing? . . . . . . . . . 355
</p>
<p>13.2 Planning Your Evaluation Study. . . . . . . . . . . . . . . . . . . . . 356
</p>
<p>13.2.1 What Type of Data: Qualitative
</p>
<p>or Quantitative? . . . . . . . . . . . . . . . . . . . . . . . . . 356
</p>
<p>13.2.2 Selecting a Hypothesis. . . . . . . . . . . . . . . . . . . . . 356
</p>
<p>13.2.3 Identifying the Dependent and Independent
</p>
<p>Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 357
</p>
<p>13.2.4 What Type of Evaluation: Formative
</p>
<p>or Summative? . . . . . . . . . . . . . . . . . . . . . . . . . . 357
</p>
<p>13.2.5 Validity, Reliability, and Sensitivity . . . . . . . . . . . 358
</p>
<p>13.3 Evaluation Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 362
</p>
<p>13.3.1 Usability Testing. . . . . . . . . . . . . . . . . . . . . . . . . 362
</p>
<p>13.3.2 Field Studies and Field Experiments . . . . . . . . . . . 364
</p>
<p>13.3.3 (Expert) Heuristic Evaluation . . . . . . . . . . . . . . . . 364
</p>
<p>13.3.4 Co-operative Evaluation. . . . . . . . . . . . . . . . . . . . 366
</p>
<p>13.3.5 A/B Testing . . . . . . . . . . . . . . . . . . . . . . . . . . . . 366
</p>
<p>13.4 What to Evaluate? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 367
</p>
<p>13.4.1 Pencil and Paper Prototypes . . . . . . . . . . . . . . . . . 367
</p>
<p>13.4.2 Computer-Based Prototypes . . . . . . . . . . . . . . . . . 367
</p>
<p>13.4.3 The Final System . . . . . . . . . . . . . . . . . . . . . . . . 368
</p>
<p>13.5 Measuring Usability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 368
</p>
<p>13.5.1 Task Time . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 369
</p>
<p>13.5.2 Errors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 370
</p>
<p>13.5.3 Verbal Protocols . . . . . . . . . . . . . . . . . . . . . . . . . 370
</p>
<p>13.5.4 Video Protocols . . . . . . . . . . . . . . . . . . . . . . . . . 371
</p>
<p>13.5.5 Eye Movement Tracking . . . . . . . . . . . . . . . . . . . 372
</p>
<p>13.5.6 Questionnaires and Surveys . . . . . . . . . . . . . . . . . 372
</p>
<p>13.5.7 Interviews and Focus Groups . . . . . . . . . . . . . . . . 373
</p>
<p>13.5.8 Workload Measures. . . . . . . . . . . . . . . . . . . . . . . 374
</p>
<p>13.5.9 Patterns of Usage . . . . . . . . . . . . . . . . . . . . . . . . 375
</p>
<p>13.5.10 User Experience . . . . . . . . . . . . . . . . . . . . . . . . . 376
</p>
<p>13.6 The Ethics of Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . 376
</p>
<p>13.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 377
</p>
<p>13.8 Other Resources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 377
</p>
<p>13.9 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 378
</p>
<p>References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 379
</p>
<p>Contents xxiii</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec14">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec14">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec15">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec15">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec16">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec16</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec16">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec16</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec17">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec17</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec17">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Sec17</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Bib1">http://dx.doi.org/10.1007/978-1-4471-5134-0_12#Bib1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13">http://dx.doi.org/10.1007/978-1-4471-5134-0_13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13">http://dx.doi.org/10.1007/978-1-4471-5134-0_13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec4">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec4">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec5">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec5">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec5">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec6">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec6">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec13">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec14">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec14">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec15">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec15">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec15</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec16">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec16</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec16">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec16</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec17">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec17</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec17">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec17</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec18">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec18</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec18">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec18</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec19">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec19</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec19">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec19</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec20">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec20</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec20">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec20</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec21">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec21</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec21">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec21</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec22">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec22</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec22">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec22</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec23">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec23</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec23">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec23</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec24">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec24</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec24">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec24</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec25">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec25</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec25">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec25</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec26">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec26</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec26">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec26</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec27">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec27</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec27">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec27</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec28">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec28</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec28">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec28</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec29">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec29</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec29">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec29</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec30">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec30</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec30">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec30</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec31">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec31</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec31">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec31</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec32">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec32</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec32">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec32</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec33">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec33</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec33">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec33</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec34">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec34</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec34">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec34</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec35">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec35</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec35">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec35</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec36">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec36</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec36">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec36</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec37">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec37</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec37">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Sec37</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Bib1">http://dx.doi.org/10.1007/978-1-4471-5134-0_13#Bib1</a></div>
</div>
<div class="page"><p/>
<p>Part IV Summary
</p>
<p>14 Summary: Putting It All Together . . . . . . . . . . . . . . . . . . . . . . . 383
</p>
<p>14.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 383
</p>
<p>14.2 Organizing What We Have Learnt About Users . . . . . . . . . . 384
</p>
<p>14.2.1 Anthropometrics . . . . . . . . . . . . . . . . . . . . . . . . . 384
</p>
<p>14.2.2 Behavior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 385
</p>
<p>14.2.3 Cognition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 386
</p>
<p>14.2.4 Social . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 388
</p>
<p>14.2.5 The Role of Tasks and Environments . . . . . . . . . . 388
</p>
<p>14.2.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 389
</p>
<p>14.3 Models of Users . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 389
</p>
<p>14.3.1 Unified Theories of Cognition . . . . . . . . . . . . . . . 390
</p>
<p>14.3.2 Types of User Models . . . . . . . . . . . . . . . . . . . . . 391
</p>
<p>14.3.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 396
</p>
<p>14.4 Risk-Driven Incremental Commitment Model . . . . . . . . . . . 397
</p>
<p>14.4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . 397
</p>
<p>14.4.2 Insight 1: The RD-ICM Provides a Way
</p>
<p>to Organize User-Related Knowledge
</p>
<p>and Ways of Knowing. . . . . . . . . . . . . . . . . . . . . 400
</p>
<p>14.4.3 Insight 2: RD-ICM is Descriptive as Well
</p>
<p>as Prescriptive . . . . . . . . . . . . . . . . . . . . . . . . . . 401
</p>
<p>14.4.4 Extension 1: Designers are Stakeholders Too . . . . . 403
</p>
<p>14.4.5 Extension 2: Learning Within
</p>
<p>and Between Projects . . . . . . . . . . . . . . . . . . . . . 404
</p>
<p>14.4.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 405
</p>
<p>14.5 Building on the Foundations . . . . . . . . . . . . . . . . . . . . . . . 406
</p>
<p>14.6 Other Resources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 407
</p>
<p>14.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 408
</p>
<p>References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 408
</p>
<p>Appendix: The Kegworth Air Accident (1989) . . . . . . . . . . . . . . . . . . 411
</p>
<p>Glossary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 417
</p>
<p>Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 429
</p>
<p>xxiv Contents</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14">http://dx.doi.org/10.1007/978-1-4471-5134-0_14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14">http://dx.doi.org/10.1007/978-1-4471-5134-0_14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec1">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec2">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec3">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec4">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec4">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec5">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec5">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec6">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec6">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec7">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec8">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec9">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec10">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec10">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec11">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec16">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec16</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec16">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec16</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec17">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec17</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec17">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec17</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec18">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec18</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec18">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec18</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec19">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec19</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec19">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec19</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec19">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec19</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec19">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec19</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec20">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec20</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec20">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec20</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec20">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec20</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec21">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec21</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec21">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec21</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec22">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec22</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec22">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec22</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec22">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec22</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec23">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec23</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec23">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec23</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec24">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec24</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec24">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec24</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec25">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec25</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec25">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec25</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec26">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec26</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec26">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Sec26</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Bib1">http://dx.doi.org/10.1007/978-1-4471-5134-0_14#Bib1</a></div>
</div>
<div class="page"><p/>
<p>Overview of Book
</p>
<p>Foundations for Designing User-Centered Systems is organized into four parts, as
</p>
<p>shown in the Table of Contents. The first part has two chapters. Chapter 1 intro-
</p>
<p>duces the approach of understanding people (commonly referred to as &lsquo;&lsquo;users&rsquo;&rsquo;),
</p>
<p>their tasks, and their context. It motivates when to study the user, including
</p>
<p>examples and some risks that arise when you do not. This chapter also notes some
</p>
<p>ways to organize this knowledge, including risk-driven design and the use of
</p>
<p>cognitive models.
</p>
<p>Chapter 2 provides an overview of the fields that contribute to our approach to
</p>
<p>designing user-centered systems. This chapter will help readers understand the
</p>
<p>relationship between different research communities and point to relevant litera-
</p>
<p>ture and to where further information can be found.
</p>
<p>The second part of the book describes what we consider to be the core, design
</p>
<p>relevant characteristics of users. These chapters build up the foundations for
</p>
<p>describing users using what we refer to as the ABCS framework: A for
</p>
<p>anthropometrics, B for behavior, C for cognition, and S for social aspects that
</p>
<p>underlie human activity. Chapter 3 describes important aspects of users&rsquo; bodies,
</p>
<p>anthropometrics, including how they sit at terminals, how they type, and how they
</p>
<p>touch. Chapter 4 deals with the underpinnings of human behavior, describing the
</p>
<p>basic senses used to interact, particularly sight and hearing, as well as why indi-
</p>
<p>viduals are motivated to behave in particular ways. Chapters 5&ndash;7 address cogni-
</p>
<p>tion. Chapter 5 describes the foundations of cognition, that of memory, attention,
</p>
<p>and learning, particularly the aspects that apply to system design. Chapter 6
</p>
<p>describes higher level cognitive capabilities related to system design, that of
</p>
<p>mental representations influencing mental models, problem solving, and decision
</p>
<p>making. Chapter 7 examines communication between users and technology. These
</p>
<p>aspects include some fundamental factors of language related to interfaces, how
</p>
<p>users read, and typical information-seeking behaviors. Chapters 8 and 9 look at
</p>
<p>social aspects of users. Chapter 8 examines social effects on decision making and
</p>
<p>factors affecting teamwork. Chapter 9 looks at larger scale, network effects, and
</p>
<p>provides some models to summarize behavior in this area.
</p>
<p>Chapter 10 introduces the study of errors&mdash;errors are often a good source of
</p>
<p>information about human behavior when interacting with technologies. We can
</p>
<p>ask several questions. What went wrong? Why did it go wrong? How can we
</p>
<p>prevent the same thing happening again? Chapter 10 provides some background
</p>
<p>xxv</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1">http://dx.doi.org/10.1007/978-1-4471-5134-0_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2">http://dx.doi.org/10.1007/978-1-4471-5134-0_2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3">http://dx.doi.org/10.1007/978-1-4471-5134-0_3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4">http://dx.doi.org/10.1007/978-1-4471-5134-0_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5">http://dx.doi.org/10.1007/978-1-4471-5134-0_5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7">http://dx.doi.org/10.1007/978-1-4471-5134-0_7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5">http://dx.doi.org/10.1007/978-1-4471-5134-0_5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6">http://dx.doi.org/10.1007/978-1-4471-5134-0_6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7">http://dx.doi.org/10.1007/978-1-4471-5134-0_7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8">http://dx.doi.org/10.1007/978-1-4471-5134-0_8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9">http://dx.doi.org/10.1007/978-1-4471-5134-0_9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8">http://dx.doi.org/10.1007/978-1-4471-5134-0_8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9">http://dx.doi.org/10.1007/978-1-4471-5134-0_9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10">http://dx.doi.org/10.1007/978-1-4471-5134-0_10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10">http://dx.doi.org/10.1007/978-1-4471-5134-0_10</a></div>
</div>
<div class="page"><p/>
<p>knowledge on errors, including error rates and how technological and human
</p>
<p>factors interact to cause system errors. The chapter also provides some tools for
</p>
<p>studying and ameliorating the effects of errors.
</p>
<p>The third part of the book provides some methods for studying users in systems.
</p>
<p>Chapter 11 introduces task analysis. We note several uses for task analysis and
</p>
<p>illustrate how it can be a very cost-effective method. Worked examples are pro-
</p>
<p>vided for each method.
</p>
<p>Chapter 12 provides two additional methods for improving the design of sys-
</p>
<p>tems. These methods also help to summarize and apply what we know about users.
</p>
<p>Cognitive Dimensions (CDs) is a way to summarize how users interact with
</p>
<p>systems. CDs also offer a framework for making predictions about potential errors;
</p>
<p>these predictions can provide the groundwork for directed usability tests and for
</p>
<p>formal or informal quality testing. The chapter also describes Norman&rsquo;s Gulfs of
</p>
<p>Evaluation and Execution. The Gulfs offer a framework for understanding where
</p>
<p>users need to be helped to understand and to interact with systems.
</p>
<p>Chapter 13 describes empirical evaluation focusing on user studies. This
</p>
<p>chapter describes how to start to run a usability study, and provides suggestions
</p>
<p>about what to do and what to measure.
</p>
<p>Chapter 14 provides a summary of users and how to design user-centered
</p>
<p>systems. We first summarize the ABCS and then offer an introduction to user
</p>
<p>modeling as a way to encapsulate the detailed knowledge we have about users as a
</p>
<p>quick way to generate predictions. We conclude by describing the Risk-Driven
</p>
<p>Incremental Commitment model as a way to apply what we know about users to
</p>
<p>system design.
</p>
<p>The Appendix describes an air accident that occurred several years ago, known
</p>
<p>as the Kegworth accident because it took place near the small town of Kegworth in
</p>
<p>the midlands of the UK. Although a simple diagnosis of pilot error was offered as
</p>
<p>the cause of the accident, on closer analysis this accident resulted from multiple
</p>
<p>issues which transpired at a number of system levels. The Kegworth accident is
</p>
<p>used as an example in several places in the book to illustrate how many levels and
</p>
<p>aspects of a system can influence system performance&mdash;and to underscore the
</p>
<p>complexity of systems that are made up of people and of interactive and
</p>
<p>interacting technologies. This complexity means we often cannot and should not
</p>
<p>come up with simple assertions about errors, but rather look for weak points in the
</p>
<p>overall system and deal with those weak points systematically and in a grounded
</p>
<p>way.
</p>
<p>We believe knowing more about people will help you develop the kind of
</p>
<p>grounding you need. We also believe that developing a systems approach will
</p>
<p>protect you from erring toward simple design assumptions and narrow solutions.
</p>
<p>Each chapter includes an abstract, an introduction, and a summary to orient the
</p>
<p>reader and to increase understanding. We include consideration of what the
</p>
<p>implications are for system design at the end of each major section. There are also
</p>
<p>lists of other resources for those people who want to find out more.
</p>
<p>xxvi Overview of Book</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11">http://dx.doi.org/10.1007/978-1-4471-5134-0_11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12">http://dx.doi.org/10.1007/978-1-4471-5134-0_12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13">http://dx.doi.org/10.1007/978-1-4471-5134-0_13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14">http://dx.doi.org/10.1007/978-1-4471-5134-0_14</a></div>
</div>
<div class="page"><p/>
<p>Endorsements
</p>
<p>For all of us who have been &lsquo;put on hold,&rsquo; recorded for quality purposes, been
</p>
<p>forced to talk to a mindless, uncaring voice non-recognition system, or simply
</p>
<p>beaten at the computer keyboard in sheer frustration, hope and help are at hand.
</p>
<p>For Ritter and his colleagues are injecting rational, user-centered design into such
</p>
<p>systems development. It is a timely contribution, devoutly to be wished. Their text
</p>
<p>is a shining example of their advocated principles. Readable, informative, easy to
</p>
<p>use, and innovative, this works puts into practice what it preaches. It should be on
</p>
<p>the desk of everyone who looks to conceive, design, fabricate, and manufacture
</p>
<p>any modern technological system&mdash;no matter how hard, no matter how soft. Even
</p>
<p>if only a proportion of designers and users read this book we will be so much better
</p>
<p>off. If it gets the circulation it deserves it could change our world&mdash;and that very
</p>
<p>much for the better. If not, technorage will only grow and the Luddites will once
</p>
<p>again become a viable social Party!
</p>
<p>Peter Hancock
</p>
<p>Provost Distinguished Research Professor
</p>
<p>Pegasus Professor, and University Trustee Chair
</p>
<p>University of Central Florida
</p>
<p>As a software engineer, I&rsquo;ve been advocating for the past 20 years that we will
</p>
<p>only see real improvements in our software when we move away from a
</p>
<p>technocentric view and adopt a wider perspective that takes into account what
</p>
<p>users really do. Too many software engineers consider this to be a &lsquo;CHI issue&rsquo; and
</p>
<p>believe that they can focus on the technology and leave the &lsquo;soft stuff&rsquo; to designers
</p>
<p>of the user experience.
</p>
<p>Well, they are wrong. Not only is it the case that most companies don&rsquo;t employ
</p>
<p>specialist UX designers, all too often these designers don&rsquo;t understand the
</p>
<p>underlying technological issues that have to be taken into account if our software
</p>
<p>is to work effectively, efficiently, and securely. The only way forward in my view
</p>
<p>is for software engineering education to include education in the human, social,
</p>
<p>and organizational factors that influence the ways in which software is designed
</p>
<p>and used.
</p>
<p>Up till now, this has been very difficult. Conventional texts on CHI have a
</p>
<p>different audience and, all too often, focus on current technology rather than
</p>
<p>xxvii</p>
<p/>
</div>
<div class="page"><p/>
<p>underlying fundamentals. This book is different and it&rsquo;s one we&rsquo;ve been waiting
</p>
<p>for. It explains in depth fundamental human capabilities, cognitive strengths, and
</p>
<p>cognitive limitations that influence the way that we choose, understand, and use
</p>
<p>software systems. It explains how we communicate and how that affects the ways
</p>
<p>that interfaces are used; it discusses collaborative working, factors that support and
</p>
<p>inhibit collaboration, and methods that can be used to understand how people
</p>
<p>work.
</p>
<p>Most importantly, I think, it doesn&rsquo;t just present these fundamentals in isolation.
</p>
<p>Every chapter in the book has a section discussing the implications for design so
</p>
<p>that readers not only learn fundamentals but understand why these are important
</p>
<p>and how they might influence their work. These bring unfamiliar material to life
</p>
<p>for software engineers and clearly demonstrate why this is important for practical
</p>
<p>systems design.
</p>
<p>This is both a textbook and a reference book. It would be a great basis for a
</p>
<p>course in human-centered software engineering but, as well as this, practicing
</p>
<p>engineers can access and learn from the individual chapters and the follow-up
</p>
<p>material that is suggested. The lack of accessible and comprehensive material on
</p>
<p>human factors for software engineers has been an important barrier to more
</p>
<p>widespread acceptance of a human-centered approach to systems design. This
</p>
<p>book has broken down that barrier and I can thoroughly recommend it to all
</p>
<p>engineers.
</p>
<p>Ian Sommerville
</p>
<p>Professor of Computer Science
</p>
<p>University of St Andrews, and Author of Software Engineering
</p>
<p>This is the book I really needed when I developed a course on Applied Cognitive
</p>
<p>Science within our Master&rsquo;s program in HCI with Ergonomics at UCL. At the
</p>
<p>time, I had to improvise with a mix of texts on cognitive psychology, engineering
</p>
<p>psychology, and HCI. Foundations for Designing User-Centered Systems fills an
</p>
<p>important gap in the space of texts for students and practitioners of HCI, focusing,
</p>
<p>as it does, on understanding people and their interactions (both social and with
</p>
<p>technology). Critically, it also draws out the implications of this understanding for
</p>
<p>design. It manages to cover all the key topics in this space while also being
</p>
<p>engaging and, at times, quirky. A textbook that makes one smile and want to read
</p>
<p>more is a textbook that works.
</p>
<p>Ann Blandford
</p>
<p>Professor of Human&ndash;Computer Interaction
</p>
<p>University College London
</p>
<p>I really enjoyed the reading of this lively book that I believe can be appreciated by
</p>
<p>different kinds of readers. A useful publication written with wit, helping the reader
</p>
<p>to discover the human capabilities and limitations, the patterns of user&rsquo;s attention
</p>
<p>and the fundamental principles to adopt at the early stages of system design.
</p>
<p>xxviii Endorsements</p>
<p/>
</div>
<div class="page"><p/>
<p>The authors take into consideration not only the usefulness of the artifacts, but also
</p>
<p>the impact they have on safety. In fact, the main cause of accident nowadays in
</p>
<p>aviation is the loss of control of the aircraft, often induced by a poor human&ndash;
</p>
<p>machine interaction. This is due, mainly, by poorly conceived interfaces, as the
</p>
<p>result of a lack of understanding of who the final user is. The overall problem lies
</p>
<p>in the very fact that the one who produces the artifacts is not the one using them.
</p>
<p>Eventually, after many years, the study of the human factors as a discipline at the
</p>
<p>cross-road between medicine, psychology and engineering is addressing the design
</p>
<p>of the interfaces.
</p>
<p>As a human factor specialist, involved in flight operations, I think this book
</p>
<p>should become a &lsquo;must&rsquo; even in the flight safety domain.
</p>
<p>Antonio Chialastri
</p>
<p>Senior Captain and Independent Human Factors
</p>
<p>Consultant in Aviation and Medicine, Italy
</p>
<p>This broad ranging survey of user-centered design techniques provides an effective
</p>
<p>introduction for designers into what people do, why and when they do it, and what
</p>
<p>motivates those behaviors.
</p>
<p>If you ever wanted to know what a &lsquo;steep learning curve&rsquo; actually looks like and
</p>
<p>how the user will interact with your system at different points along this curve then
</p>
<p>this is the book for you!
</p>
<p>Through well-illustrated examples, it considers a wide range of topics from
</p>
<p>traditional ergonomics, through user behavior, cognitive models, and social
</p>
<p>factors. Many of the examples take off the traditional &lsquo;blinkers&rsquo; of user centred
</p>
<p>design and show how a human decision at the &lsquo;sharp end&rsquo; may well have its roots
</p>
<p>in a much wider and blunter context.
</p>
<p>As a chief architect for large programs, this book has given me access to a
</p>
<p>variety of new techniques and an extended vocabulary that I look forward to
</p>
<p>introducing my design teams to.
</p>
<p>Richard Hopkins
</p>
<p>Chief Architect and IBM Distinguished Engineer
</p>
<p>Co-author of Eating the IT Elephant
</p>
<p>The HCI profession emerged when psychologists teamed with developers. Design
</p>
<p>was missing. Today, good teams have strong designers and technologists&mdash;but
</p>
<p>psychological insight is often in short supply. This book fills that gap with a fresh
</p>
<p>look at established and new knowledge and approaches.
</p>
<p>Jonathan Grudin
</p>
<p>Principal Researcher at Microsoft Research
</p>
<p>ACM Fellow
</p>
<p>Endorsements xxix</p>
<p/>
</div>
<div class="page"><p/>
<p>If you want to design or build interactive systems that are both useful and usable,
</p>
<p>Foundations for Designing User-Centered Systems is an excellent place to begin.
</p>
<p>Philippe Palanque
</p>
<p>Head of Interactive Critical Systems Group
</p>
<p>Universite Paul Sabatier Toulouse
</p>
<p>Co-chair of CHI 2014
</p>
<p>The &lsquo;&lsquo;Who, What, When, Where and Why of Human-Systems Interaction&rsquo;&rsquo;&mdash;a
</p>
<p>practitioner&rsquo;s primer for Systems Designers looking to advance human computer
</p>
<p>symbiosis in their designs. The book provides a straightforward, easy-to-read
</p>
<p>introduction to the process of designing interactive technologies using human-
</p>
<p>centered approaches that avoid the cookie-cutter, simplistic recipes all too
</p>
<p>common in other publications. Also worth noting is that this guide not only covers
</p>
<p>foundations for beginners, but also includes practical, real-word examples, as well
</p>
<p>as emerging essential topics for the design of systems, for more advanced
</p>
<p>practitioners. The reader will quickly discover that this book provides essential,
</p>
<p>innovative, and targeted tools for designers who are focused on enabling seamless
</p>
<p>interactions between humans and technologies. For anyone looking to advance
</p>
<p>human-computer-symbiosis, this book will not gather dust on your shelf!
</p>
<p>Dylan Schmorrow, Ph.D.
</p>
<p>Chief Scientist, Soar Technology, Inc.
</p>
<p>Anything that helps software developers think more about the mental states of their
</p>
<p>users and how that affects the utility and usability of their software is a good thing.
</p>
<p>Even if you don&rsquo;t plan to become a human factors expert, you will find good ideas
</p>
<p>in this book to help make your applications more successful.
</p>
<p>William A. Woods
</p>
<p>Research Scientist and Software Engineer
</p>
<p>The foundations for designing user-centered systems really delivers on its title. The
</p>
<p>book succinctly captures the key anthropometric, behavioral, cognitive, and social
</p>
<p>concepts that are the foundations for designing user-centered systems. Further-
</p>
<p>more, the authors artfully imbedded human factors principles into the manner in
</p>
<p>which materials are presented, turning the book into a demonstration of good
</p>
<p>practices. I find the structure and layout of the book make it an excellent
</p>
<p>introductory text for a course in HCI as well as a useful initial reference source.
</p>
<p>Michael &lsquo;&lsquo;Q&rsquo;&rsquo; Qin
</p>
<p>Adjunct professor, WPI
</p>
<p>xxx Endorsements</p>
<p/>
</div>
<div class="page"><p/>
<p>Part I
</p>
<p>Introduction: Aims, Motivations, and
Introduction to Human-Centered Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 1
</p>
<p>Introducing User-Centered
</p>
<p>Systems Design
</p>
<p>Abstract If designers and developers want to design better technologies that are
</p>
<p>intended for human use they need to have a good understanding of the people who
</p>
<p>are or who will be using their systems. Understanding people, their characteristics,
</p>
<p>capabilities, commonalities, and differences allows designers to create more
</p>
<p>effective, safer, efficient, and enjoyable systems. This book provides readers with
</p>
<p>resources for thinking about people&mdash;commonly called &lsquo;&lsquo;users&rsquo;&rsquo;&mdash;their tasks and
</p>
<p>the context in which they perform those tasks. Our intention is to enable you to
</p>
<p>make more informed decisions when designing complex interactive systems. This
</p>
<p>chapter thus introduces this argument through example design problems. We then
</p>
<p>present the benefits and costs associated with understanding the user. Two
</p>
<p>approaches for understanding users are introduced. The first is a framework called
</p>
<p>the ABCS for understanding, in broad strokes, different aspects of users. The
</p>
<p>second is user knowledge and action simulation for developing and testing how
</p>
<p>users approach tasks in more detail. After reading this chapter you should be able
</p>
<p>to appreciate why it is important to understand users, and the associated benefits
</p>
<p>and costs of doing so.
</p>
<p>1.1 Introduction
</p>
<p>Most of us use interactive technologies every day&mdash;cell phones, TVs, alarm
</p>
<p>clocks, cars, vending machines, computers, cameras, microwaves, ovens, ticket
</p>
<p>machines&mdash;the list is endless.
</p>
<p>Technology can help us achieve what we desire to do or need to do, but it can
</p>
<p>also hinder us. When we cannot get something done, when our expectations are not
</p>
<p>met, or when technology is too hard to use, we get frustrated. When technologies
</p>
<p>and systems are unpredictable, delays and unforeseen problems can occur.
</p>
<p>This book is about designing technology and systems for use by people. We
</p>
<p>offer an introduction to what we know about why humans do what they do when
</p>
<p>they do it as users of technology. The book has one central premise:
</p>
<p>F. E. Ritter et al., Foundations for Designing User-Centered Systems,
DOI: 10.1007/978-1-4471-5134-0_1, ï¿½ Springer-Verlag London 2014
</p>
<p>3</p>
<p/>
</div>
<div class="page"><p/>
<p>Understanding people will help you build better interactive technologies and
</p>
<p>systems.
</p>
<p>When we say &lsquo;&lsquo;understanding people&rsquo;&rsquo; we mean:
</p>
<p>&bull; Knowing how to observe and document what people do
</p>
<p>&ndash; Using appropriate methods to get credible results and differentiate anecdotes
</p>
<p>from reliable data
</p>
<p>&bull; Understanding why people do what they do
</p>
<p>&ndash; Developing insights into people&rsquo;s conscious and unconscious motivations for
</p>
<p>doing things
</p>
<p>&bull; Understanding and predicting when people are likely do things
</p>
<p>&ndash; Understanding people&rsquo;s patterns of behavior
</p>
<p>&bull; Understanding how they choose to do things the way they do them
</p>
<p>&ndash; Understanding what options people actually have and/or perceive they have
</p>
<p>available to them, understanding the constraints they are under and assessing
</p>
<p>what the resources they have available to them.
</p>
<p>We propose that systems should be designed in a user-centered way. Being user-
</p>
<p>centered means considering human characteristics and capabilities during system
</p>
<p>design. It means explicitly asking: who is going to use the system/technology and
</p>
<p>why; what are they hoping to achieve in using the system/technology; how much
</p>
<p>effort are they willing to put into learning how to use the system/technology; whether
</p>
<p>they will be operating the system alone or with others&hellip;. Being user-centered means
</p>
<p>knowing why, as well as how, users do what they do when they do it. We propose
</p>
<p>that consideration of users&rsquo; basic human characteristics should be in place before
</p>
<p>system development begins. Reflection and experimentation with potential users of
</p>
<p>the system should take place throughout the design and development process using
</p>
<p>methods like brainstorming, storyboarding, low to high fidelity prototyping, and, as
</p>
<p>the system gets closer to full functionality, with more formal use testing.
</p>
<p>This book assumes no previous knowledge; it is designed to be accessible to those
</p>
<p>without a background in psychology or computer science; if you have already taken a
</p>
<p>traditional human&ndash;computer interaction (HCI) course, this material may be a quite
</p>
<p>easy read and help you organize your thoughts. If you have taken several psychology
</p>
<p>courses, you are likely to recognize much, but perhaps not all, of the material here.
</p>
<p>1.2 Starting to Understand Users
</p>
<p>Many designers and developers make two fundamental errors. They assume that
</p>
<p>understanding how a technology will be used can be derived from introspection:
</p>
<p>from imagining how it will be used. This assumption is based on a second
</p>
<p>4 1 Introducing User-Centered Systems Design</p>
<p/>
</div>
<div class="page"><p/>
<p>error&mdash;that everyone is the same. We know the second assumption is not true from
</p>
<p>simply observing that the world is made up of very different people with different
</p>
<p>motivations, different backgrounds, and different skill sets.
</p>
<p>To illustrate how our intuitions about people may be incorrect, and why it is
</p>
<p>always worth testing your designed system with people who will use that system,
</p>
<p>we offer the following examples.
</p>
<p>1.2.1 Designing Mappings Between Buttons and Lights
</p>
<p>It is generally claimed that the better designs are those that offer simple, clearer
</p>
<p>mappings between an action and a response. However, the question is: what is a
</p>
<p>clearer mapping? Consider Figs. 1.1 and 1.2 taken from a study by Payne (1995)
</p>
<p>on how well naive subjects could judge the quality of interface designs for a
</p>
<p>simple system. Payne&rsquo;s experiment assessed what design people predicted would
</p>
<p>rank best to worst on a very simple interface, where a number of different map-
</p>
<p>pings between the controls and resulting system state were compared (what is
</p>
<p>called &lsquo;&lsquo;stimulus-response compatibility&rsquo;&rsquo; in the scientific literature). In the fol-
</p>
<p>lowing example, study participants were able to rank order the designs in Fig. 1.1
</p>
<p>from best to worst. They were asked two questions: (1) what is the mapping of
</p>
<p>lights to switches that gives the fastest response time? and (2) can you give a
</p>
<p>prediction of how long they will take on average?
</p>
<p>Sixty out of 70 subjects got the top ranked one correct. However, only four out of
</p>
<p>70 got the complete order correct. The results of the study suggest that, when
</p>
<p>confronted with anything but the most obvious choices, designers without
</p>
<p>training may make poor design choices. Before going on, you may wish to try
</p>
<p>this task yourself. The correct order is given in the exercises at the end of this
</p>
<p>chapter.
</p>
<p>(a) 
</p>
<p>(d) (c) 
</p>
<p>(b) Fig. 1.1 a Rank order the
quality of these switch to
light mappings. b Note how
long, on average, it will take
to push a button on each
panel. (Adapted from Payne
1995)
</p>
<p>1.2 Starting to Understand Users 5</p>
<p/>
</div>
<div class="page"><p/>
<p>1.2.2 Designing Stove-Top Mappings
</p>
<p>For our second example, take a look at the stove-top designs in Fig. 1.2. Which is
</p>
<p>the best burner to control knob mapping? If you think you know the best mapping,
</p>
<p>can you provide a quantitative measure of how much better? If layout 1 has 100
</p>
<p>errors for a given amount of use, how many errors will the other two have?
</p>
<p>For the examples in Fig. 1.2, only four out of 53 subjects selected the correct
</p>
<p>order of layout to be layout 3 (76 errors per 1,200 trials), layout 2 (116 errors per
</p>
<p>1,200 trials), and then layout 1 (129 errors per 1,200 trials), and only 15 out of 53
</p>
<p>could correctly identify the best design.
</p>
<p>Layout 1
@
</p>
<p>@
</p>
<p>&pound;
</p>
<p>&pound;
</p>
<p>%
</p>
<p>%
</p>
<p>&amp;
</p>
<p>&amp;
</p>
<p>100
</p>
<p>Ratio of Errors
</p>
<p>Layout 2
@
</p>
<p>%
</p>
<p>&pound;
</p>
<p>&amp;
</p>
<p>%
</p>
<p>@
</p>
<p>&amp;
</p>
<p>&pound;
</p>
<p>Ratio of Errors
</p>
<p>Layout 3
@
</p>
<p>%
</p>
<p>&pound;
</p>
<p>&pound;
</p>
<p>%
</p>
<p>@
</p>
<p>&amp;
</p>
<p>&amp;
</p>
<p>Ratio of Errors
</p>
<p>Fig. 1.2 Rank order the
quality of these stove burner
to knob pairings. If layout
1 will give 100 errors, how
many errors will the other
pairings lead to? Adapted
from Chapanis and
Lindenbaum (1959)
</p>
<p>6 1 Introducing User-Centered Systems Design</p>
<p/>
</div>
<div class="page"><p/>
<p>1.2.3 Designing Coins
</p>
<p>For our third example, we would like to look at coins. Can you pick out which is a
</p>
<p>US penny in Fig. 1.3 without looking at a real one?
</p>
<p>Most Americans would think that they could recognize a US penny, but more
</p>
<p>than half of Nickerson and Adams&rsquo; (1979) American subjects shown the pennies in
</p>
<p>Fig. 1.3 could not pick out the penny from a set of 15 examples. The correct
</p>
<p>answer is given at the end of this chapter in Exercise 1.2.
</p>
<p>We all know well enough what a penny looks like&mdash;relative to the other coins
</p>
<p>we might encounter&mdash;but not in any more detail than is necessary. With the set of
</p>
<p>alternatives provided by Nickerson and Adams, the choice has to be based on
</p>
<p>recalling specific features of a penny, which most people have never memorized
</p>
<p>and have never needed to memorize. You can see similar effects in computer
</p>
<p>interfaces where users cannot recall which commands are located on which menus
</p>
<p>(Exercise 1.2 explores this question further).
</p>
<p>Although coinage systems may appear a long way removed from the design of
</p>
<p>user interfaces, they provide good examples of how and why we can benefit from
</p>
<p>considering the users&rsquo; perspective in design to avoid system failure. France and the
</p>
<p>Fig. 1.3 Possible views of a US penny. Without looking in your pocket choose the correct one.
Taken from a study by Nickerson and Adams (1979). (Used with permission of Elsevier)
</p>
<p>1.2 Starting to Understand Users 7</p>
<p/>
</div>
<div class="page"><p/>
<p>USA have both tried to introduce new coins (e.g., the Susan B. Anthony dollar) with
</p>
<p>little success, partly due to the lack of care in the design of the new coin. In contrast,
</p>
<p>when Britain got a new currency in 1971, switching to a systemwhere oneUK pound
</p>
<p>was equal to 100 pennies, the introduction of the new coinage was a resounding
</p>
<p>success. It turned out that one reason for the success was a substantial body of
</p>
<p>research on how people perceived the value of coins (e.g., Bruce et al. 1983) as well
</p>
<p>as attention to how the different proposed coins might be made least confusing to the
</p>
<p>elderly or sight impaired. During the research it was recognized that many people
</p>
<p>need to identify coins from touch alone (e.g., the coin in your pocket) and that
</p>
<p>designing for the blind user actually meant designing for everyone. The cost of this
</p>
<p>research was a very small component of the costs of introducing a new coinage
</p>
<p>system (e.g., all of the new vending machines to be developed), but it helped ensure
</p>
<p>the success of the whole enterprise. Subsequent changes to the coins have also
</p>
<p>followed these guidelines, with the two pound coin, for example, being the same
</p>
<p>basic shape as the one pound coin, but larger and heavier.
</p>
<p>In these examples we see one of the first universals of human behavior&mdash;people
</p>
<p>remember those details that they pay attention to but only in sufficient detail for the
</p>
<p>tasks they are performing. This is universal, but it does not enable us to predict fully
</p>
<p>what details someone will remember, because there are differences in how much
</p>
<p>attention people have to spare, what tasks they are performing, and thus what details
</p>
<p>they will remember. The first two problems in Figs. 1.1 and 1.2 are difficult because
</p>
<p>the differences in performance of the tasks are not particularly available to con-
</p>
<p>sciousness, and most people&rsquo;s representation of how they think they perform these
</p>
<p>tasks in this area do not reflect how people actually perform the task. The penny
</p>
<p>question (and the menu question) represent the difference between recognition and
</p>
<p>recall memory. Usually identifying a penny just requires being able to discriminate
</p>
<p>between it and other coins. With the set of alternatives provided by Nickerson and
</p>
<p>Adams, the choice has to be based on recalling the features of a penny, which most
</p>
<p>people have never bothered to commit to memory (why would they?).
</p>
<p>Another classic example is remembering your new cell phone number. It takes a
</p>
<p>long time to learn it because you, personally, never need to use it (unless you
</p>
<p>misplace your phone, in which case calling it is a good strategy for finding it!).
</p>
<p>However, if someone asks you for it, you either have to recall it or have to go
</p>
<p>through the menus on your phone to find it, eventually recognizing the steps that
</p>
<p>enabled you to find the number.
</p>
<p>This disconnection between how we think we behave and how users really
</p>
<p>behave is common and there are plenty of reasons for it. In most cases we are too
</p>
<p>busy doing a task to properly observe how we are doing it. When we can observe
</p>
<p>how we are doing it, it is rare that we can correctly and completely infer why we
</p>
<p>are doing the task&mdash;the observation of behavior is separate from the generation of
</p>
<p>it. Ericsson and Simon (1993) provide a full explanation of why it is hard for
</p>
<p>people to examine their own thinking processes. Their explanation includes that
</p>
<p>when we recognize how we behave, we rarely make written notes and thus any
</p>
<p>8 1 Introducing User-Centered Systems Design</p>
<p/>
</div>
<div class="page"><p/>
<p>memories of how we behaved are subject to the inherent frailties of human
</p>
<p>memory. We are also not very good at estimating time accurately and have trouble
</p>
<p>keeping track of successes and failures. Finally, there are some particular aspects
</p>
<p>of our own behavior that are very hard to observe, such as basic perception, and
</p>
<p>some that are hard to describe and reason about verbally, such as performing some
</p>
<p>spatial reasoning tasks.
</p>
<p>Table 1.1 Summary of some of the causal factors in the Kegworth air accident and lessons to
note
</p>
<p>&bull; The Engine Instrument System (EIS) used digital displays. A survey of the airline&rsquo;s pilots after
the Kegworth accident showed that nearly two-thirds of them believed that the new EIS was
not effective in drawing their attention to rapid changes in the engine parameters. If it had, the
accident might have been avoided. Thus, the design of the interface for the EIS did not present
data in a format that could easily be perceived by the pilots
</p>
<p>Lesson: You need to understand how people look at the user interface to extract information
which they then use to make decisions and take actions
</p>
<p>&bull; Neither pilot could recall having seen any indication of the abnormally high vibration levels on
the EIS. The Captain noted that he rarely scanned the vibration gauges because he had found
them to be unreliable in other aircraft in the past. Experts, such as pilots, have a highly
developed mental model of the world in which they normally operate, which helps them carry
out their tasks. The Captain appears to have excluded the vibration gauges from his mental
model because he believed the readings were unreliable
</p>
<p>Lesson: You need to understand how people create and use mental models to help them use a
system
</p>
<p>&bull; The B737-400 was a glass cockpit aircraft, in which the information is presented on digital
displays, rather than on analogue instruments and electro-mechanical displays. The airline
(BMA) did not have a glass cockpit flight training simulator for the B737-400, so pilots could
only gain experience through actually flying it (i.e., on the job). The only training the pilots
were given for the B737-400 was a 1-day audio-visual conversion course
</p>
<p>Lesson: You need to understand how people learn to use new and, particularly, complex
systems
</p>
<p>&bull; Three members of the cabin crew said they saw evidence of the fire in the #1 engine, but they
did not report this to the pilots. The flight crew believed that the problem was with the #2
engine. This seems to have been a failure in what is called Crew Resource Management, a
procedure designed to ensure that all the members of a flight crew (pilots and cabin crew)
communicate with one another and work together as a team
</p>
<p>Lesson: You need to understand how social issues, including communication, can affect how
people use a system
</p>
<p>&bull; The B737-400 was fitted with a new type of engine. The engine was thoroughly tested on the
ground before being certified by the appropriate authorities. The engine was not tested either
in an altitude test cell (which simulates the conditions of flying at high altitudes) or in flight,
however. This scenario illustrates how decisions that are made at remote distances from the
user interface in a system can have an impact on the way that the users behave. Emergency
events, like engine failures, are normally covered by checklists in the QRH (Quick Reference
Handbook) that is used by all pilots to deal with known situations
</p>
<p>Lesson: You need to understand that decisions taken at a place and time that are greatly
removed from where the system is used can affect the way the system will behave
</p>
<p>1.2 Starting to Understand Users 9</p>
<p/>
</div>
<div class="page"><p/>
<p>1.2.4 What Happens If You do not Take Proper Account
</p>
<p>of Users, Tasks, and Context?
</p>
<p>The Kegworth Air Accident (see the Appendix for a detailed account) was, like
</p>
<p>many air accidents, the result of several events. Many of these events happened in
</p>
<p>a short space of time, but some were more distant both in time and in space. From
</p>
<p>the point when a problem was detected with one of the engines, to the point at
</p>
<p>which the plane crashed took less than 8 min. Table 1.1 lists some examples of the
</p>
<p>types of things that went awry and contributed to the accident and the lessons you
</p>
<p>should note.
</p>
<p>This book will help you to understand the underlying issues, and show how you
</p>
<p>can analyze them. Once you understand that these issues arise at different levels,
</p>
<p>and how they can interact, you can start to take appropriate steps to make sure they
</p>
<p>are prevented (or their effects are at least mitigated) when designing systems.
</p>
<p>1.3 The Benefits and Costs of Understanding Users
</p>
<p>Assuming that your users are just like you can be described as a fundamental
</p>
<p>attribution error of design. This error is essentially the inverse of what is called the
</p>
<p>fundamental attribution error in social psychology (described in Chap. 8). In the
</p>
<p>fundamental attribution error you assume that people are not like you when, in
</p>
<p>fact, they are.
</p>
<p>In the fundamental attribution error of design, you assume that your users are
</p>
<p>like you when, in fact, they are not! Users often can&rsquo;t use the systems as well as the
</p>
<p>designers because they do not know as much. Sometimes the opposite is true.
</p>
<p>Users can to be quite resourceful and innovative, and will often use technology in
</p>
<p>ways that the designer had never fully contemplated; for example, spreadsheets
</p>
<p>were originally designed for use by accountants, but many people now use them
</p>
<p>for processing all forms of tabular data. Similarly, the short messaging system
</p>
<p>(SMS) was originally designed to help engineers debug mobile phone communi-
</p>
<p>cation systems, but now it is widely used by everyone with a mobile phone as a
</p>
<p>means of general communication.
</p>
<p>If you understand your users and take appropriate account of them when
</p>
<p>designing your system, there are three main types of benefits (or payoffs) that can
</p>
<p>result: more usable products (which can lead to wider adoption and more accel-
</p>
<p>erated adoption rates), cost savings, and safer systems. There are some caveats,
</p>
<p>however, which can be seen as costs: understanding and taking appropriate
</p>
<p>account of the user in your design does not necessarily guarantee success, and
</p>
<p>knowing how much you need to understand about your users is a hard question to
</p>
<p>answer. We discuss all of these below.
</p>
<p>10 1 Introducing User-Centered Systems Design</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8">http://dx.doi.org/10.1007/978-1-4471-5134-0_8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8">http://dx.doi.org/10.1007/978-1-4471-5134-0_8</a></div>
</div>
<div class="page"><p/>
<p>1.3.1 Benefit 1: More Usable Products
</p>
<p>Understanding people can help you design systems that are more usable, more
</p>
<p>learnable, and more efficient. For example, the adoption of email has become more
</p>
<p>widespread because of wider availability of devices and infrastructure but also
</p>
<p>because email interfaces have progressed from requiring in-depth computer sci-
</p>
<p>ence and systems administration knowledge to manage installation and use to
</p>
<p>relatively easy-to-use web interfaces with help documentation, message manage-
</p>
<p>ment and retrieval, directly usable features like formatting, and the ability to easily
</p>
<p>attach or embed multimedia.
</p>
<p>Web design provides another example. Changes in the costs of hardware and
</p>
<p>bandwidth have made it faster and cheaper to develop web pages, but many people
</p>
<p>and businesses would not be generating as many web pages if they still had to use
</p>
<p>raw HTML. The rise of special purpose, easy-to-use HTML editors (e.g., Webbly)
</p>
<p>is one reason for the massive uptake of the web (Holmes 2005). AOL and the
</p>
<p>initial Netscape browser were both successful products because they made an
</p>
<p>existing service more usable and more widely accessible. Work in eCommerce
</p>
<p>suggests that ease of use of existing products and the expected cost of learning to
</p>
<p>use a new interface can also lead to a type of brand recognition and later to loyalty
</p>
<p>(Johnson et al. 2003).
</p>
<p>Sometimes the usability of a tool does not increase directly through improving
</p>
<p>an interface but because its utility increases and its frequency of use increases. The
</p>
<p>decreasing weight (and size) of cell phones has made them easier to carry around,
</p>
<p>and thus always available. Part of the success of the web arises out of the creation
</p>
<p>of search engines: Bing, Google, DuckDuckGo, Ask, and the more specific search
</p>
<p>engines like Citeseer and DBLP (dblp.uni-trier.de) increase the usability of the
</p>
<p>web by helping users find information based on the topic they are looking for
</p>
<p>rather than by the location of the information. This increase of usability is not
</p>
<p>driven by the visual interface, but at a deeper level of supporting the user&rsquo;s tasks.
</p>
<p>Users sometimes have problems in understanding what they are looking at.
</p>
<p>Norman (2013) refers to this as the Gulf of Evaluation. Users also encounter
</p>
<p>problems in knowing or being able to discover what they have to do to execute
</p>
<p>their task using a particular interface. Norman describes this as the Gulf of Exe-
</p>
<p>cution. The Internet examples above are examples where the Gulf of Execution has
</p>
<p>been made smaller, and thus made more tractable for a wider range of users. We
</p>
<p>will return to Norman&rsquo;s Gulfs in Chap. 12.
</p>
<p>More often, lack of understanding of users leads to some groups of users being
</p>
<p>excluded. We have worked with web sites that now make sure that they have text
</p>
<p>versions available to support not only the visually impaired (through text readers
</p>
<p>and descriptions of pictures), but also two types of users that do not come to mind
</p>
<p>easily in a US college environment with ubiquitous broadband&mdash;those users sep-
</p>
<p>arated from the site via dialup lines or by vast distances (Ritter et al. 2005).
</p>
<p>1.3 The Benefits and Costs of Understanding Users 11</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12">http://dx.doi.org/10.1007/978-1-4471-5134-0_12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12">http://dx.doi.org/10.1007/978-1-4471-5134-0_12</a></div>
</div>
<div class="page"><p/>
<p>1.3.2 Benefit 2: Financial Savings
</p>
<p>Designing to support users can save companies money, even of the order of
</p>
<p>millions of dollars. One case is Nynex, the New York telephone company, in the
</p>
<p>early 1990s. The toll and assistance operators (TAO) are the people who help you
</p>
<p>when you dial &lsquo;&lsquo;0&rsquo;&rsquo;. They help customers with collect calls, billing, and other more
</p>
<p>complex calls. In the early 1990s Nynex was considering upgrading their TAO
</p>
<p>workstation. They had a room with about 100 of these operators; it was believed
</p>
<p>that new graphical user workstations could improve productivity. The cost of
</p>
<p>upgrading all the workstations was going to be about $500,000 (in 1990s dollars).
</p>
<p>The company engaged a team of applied psychologists to look at how much faster
</p>
<p>the new workstations would be. The results of a task analysis (using a form of
</p>
<p>GOMS which is described in more detail in Chap. 11) suggested that the new
</p>
<p>workstations would not be faster, but would, in fact, be 4% slower to operate. This
</p>
<p>may seem like a small difference, but a 4% reduction in productivity was going to
</p>
<p>cost Nynex $2.4 million a year&mdash;in addition to the cost of the workstations.
</p>
<p>Nynex ran a study to discover how much faster the new workstations would
</p>
<p>really be. After allowing time for the operators to learn to use the workstations, the
</p>
<p>operators&rsquo; performance plateaued about where it was predicted&mdash;4% slower.
</p>
<p>NYNEX now claims that this study saved them $2.4 million per year. The user
</p>
<p>study paid for itself in the first week (see Gray et al. 1992, 1993 for more details).
</p>
<p>The slowdown in operator performance was not caused by the fact that the new
</p>
<p>workstations simply required the user to take more steps to achieve the same goal.
</p>
<p>The reason was the new interface did not allow multi-tasking; the operators could
</p>
<p>not type while waiting for the caller to speak which they could with the old.
</p>
<p>Improved computer processor speed could not compensate for the loss in parallel
</p>
<p>activity the users had with the previous design.
</p>
<p>The NYNEX example reveals the benefits of considering people&mdash;in this case
</p>
<p>the operators&mdash;even when there does not appear to be a problem. In many
</p>
<p>instances the main advantage of studying people using systems&mdash;that is, con-
</p>
<p>ducting &lsquo;&lsquo;user studies&rsquo;&rsquo;&mdash;is to identify where people make errors, so that we can
</p>
<p>prevent them or mitigate their consequences in the final product. People often do
</p>
<p>not type what they want to type, and sometimes push buttons that they did not
</p>
<p>intend to push. Strangely enough, this problem can be more prevalent amongst
</p>
<p>highly-skilled expert users, than amongst beginners. Errors that occur when
</p>
<p>someone knows the right thing to do, but accidentally does something different, are
</p>
<p>commonly referred to as &lsquo;slips&rsquo; to distinguish them from mistakes, where the
</p>
<p>action is taken on the basis of an incorrect plan (Norman 1981; Reason 1990).
</p>
<p>These slips can also occur on well-practiced interfaces that do not attempt to
</p>
<p>catch such slips. These slips can also be very expensive. A local paper (Centre
</p>
<p>Daily Times, 15 Feb 2002, p. C38) reported that a financial services firm lost up to
</p>
<p>$100 million because it executed a sell order of 610,000 shares at 16 yen instead of
</p>
<p>the correct order of 16 shares at 610,000 yen (approximately 100 yen/US$).
</p>
<p>12 1 Introducing User-Centered Systems Design</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11">http://dx.doi.org/10.1007/978-1-4471-5134-0_11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11">http://dx.doi.org/10.1007/978-1-4471-5134-0_11</a></div>
</div>
<div class="page"><p/>
<p>In a review of the application of user models to evaluate Army systems, Booher
</p>
<p>and Minninger (2003) report many instances where millions of dollars over the
</p>
<p>course of a device&rsquo;s lifetime were saved by better interface design, through
</p>
<p>reduced training, for example. They also highlight several cases where systems
</p>
<p>had to be scrapped or modified at great expense because they were not usable.
</p>
<p>Use of machines that have different modes can often mislead users into making
</p>
<p>errors. Photocopier machines that can be used to send faxes have a common
</p>
<p>problem. The default mode of these machines is to copy, but users may not realize
</p>
<p>this. Users may type in the area code (say, the U.S. area code 415) as the starting
</p>
<p>point for sending a fax, but the copier interprets this as a request to make 415
</p>
<p>copies of the document that the user intended to send as a fax! More explicit
</p>
<p>displays and more intelligent systems might attempt to catch this type of error.
</p>
<p>Photocopies may be relatively cheap, but this type of problem with airline tickets,
</p>
<p>machine tools, or photographic films quickly become expensive.
</p>
<p>1.3.3 Benefit 3: Safer Systems
</p>
<p>Much of the work that has made airplanes the safest transportation per passenger
</p>
<p>mile (Gigerenzer 2004) has gone into supporting pilots and air traffic controllers to
</p>
<p>avoid and, more importantly, catch and recover from errors. This has led to a
</p>
<p>drastic decrease in accidents previously ascribed to &lsquo;pilot error&rsquo;. As the cause of
</p>
<p>these accidents were typically attributed to well-trained and alert pilots, it is fairer
</p>
<p>to diagnose these errors as poor fits between the pilot&rsquo;s capabilities and the
</p>
<p>machine at particular times and for particular sets of tasks. Improving this fit thus
</p>
<p>improved airplane safety.
</p>
<p>Medicine provides a rich source of examples too. For instance, interfaces that
</p>
<p>allow users (e.g., nurses) to type in the digits of a drug dose are inherently more
</p>
<p>dangerous than those that force users to dial them in using a wheel for each digit
</p>
<p>(Pew and Mavor 2007). When typing, a repeated digit can increase the dosage by a
</p>
<p>factor of ten. This type of mistake is not possible with a dial-based interface.
</p>
<p>Medical X-ray machines are powerful devices and often offer little margin for
</p>
<p>error. In addition to their technical requirements, they can have usability problems
</p>
<p>because their effects are not directly and immediately visible. In the case of radi-
</p>
<p>ation treatments for cancer, multiple professionals are involved in their use, from
</p>
<p>the oncologists and radiologists who specify the treatment, the technicians who
</p>
<p>administer it, to the physicists who maintain it. There are many examples of where
</p>
<p>interface design for treatment using X-ray machines and other medical devices
</p>
<p>have ignored the user&rsquo;s capabilities, tasks, context, or some combination of these,
</p>
<p>and this has led to loss of life. Perhaps the most famous case is the Therac 25
</p>
<p>(Leveson and Turner 1993). Between 1985 and 1987 there were six known acci-
</p>
<p>dents involving massive radiation overdoses with the Therac. Notably, such acci-
</p>
<p>dents rarely arise from a single cause. The user interface was only one of several
</p>
<p>1.3 The Benefits and Costs of Understanding Users 13</p>
<p/>
</div>
<div class="page"><p/>
<p>contributory factors. In addition to problems with the technology and safety
</p>
<p>interlocks, the system (including the technician) was poorly prepared to deal with
</p>
<p>typing mistakes by the technician, and in many installations the level of feedback
</p>
<p>from the Therac to the radiation technician was not sufficient to help them catch the
</p>
<p>mistakes sooner.
</p>
<p>1.3.4 Cost 1: Understanding the Users Does Not Guarantee
</p>
<p>Success
</p>
<p>Although improving the usability of a system can save lives, lead to product
</p>
<p>success, and save money, usability is neither a necessary nor sufficient condition
</p>
<p>for success, nor is it a protection against loss of money or life. Systems with poor
</p>
<p>usability can still be successful for a variety of reasons. For example, they may
</p>
<p>offer a functionality that is unique and useful. The earliest versions of planes,
</p>
<p>computers, printing presses, and satellite phones were all difficult to use, but
</p>
<p>successful because of their unique functionality.
</p>
<p>Products that are well designed with the user in mind may still not be successful.
</p>
<p>Most or all aspects must be right for a product or system to succeed. Making the
</p>
<p>usability right does not make the time to market right, it does not make the price
</p>
<p>appropriate, and other critical aspects such as reliability or marketing may fail.
</p>
<p>The system also has to be acceptable to the users. The interface may be well
</p>
<p>designed on a local level, but if it clashes too much with existing practice (even if
</p>
<p>the new system is correct) it can quickly fall into disuse (e.g., see Baxter et al.
</p>
<p>2005). Similarly, if management does not appropriately support the transition to
</p>
<p>the new system, it may also fall into disuse. Glashko and Tabas (2009) argue that
</p>
<p>to understand success you need to understand the user, the business model, and the
</p>
<p>technology.
</p>
<p>The lack of usability can be a sufficient reason for failure and this is sometimes
</p>
<p>overlooked. For some systems, however, usability is not the biggest risk to suc-
</p>
<p>cess. Indeed there are many factors that contribute to success, and none of them on
</p>
<p>their own are necessary or sufficient to guarantee success. Pew and Mavor (2007)
</p>
<p>suggest taking a risk driven spiral-based approach to development to deal with
</p>
<p>this; we describe this approach later in the book.
</p>
<p>1.3.5 Cost 2: Knowing When to Stop Analyzing the Users can
</p>
<p>be Difficult
</p>
<p>Knowing when you should stop analyzing the users and start building your system
</p>
<p>is a difficult problem to address. It is an ongoing issue for HCI (and system design
</p>
<p>14 1 Introducing User-Centered Systems Design</p>
<p/>
</div>
<div class="page"><p/>
<p>in general) that should be able to demonstrate a worthwhile return on investment.
</p>
<p>Nielsen (1993), for example, argues that many usability-related design problem
</p>
<p>issues can be identified by studying a small numbers of users (about five to eight).
</p>
<p>The caveats are that the results of this approach are highly dependent on the types
</p>
<p>of users involved and the particular interface. As yet there are no hard and fast
</p>
<p>rules that can be applied to all systems which will tell you when to stop the user
</p>
<p>analysis and start building.
</p>
<p>The traditional approach to systems deployment largely focused on making the
</p>
<p>users fit the system. In other words, companies employed the right people (selected
</p>
<p>using psychometric testing, qualifications, and so on) and, where necessary,
</p>
<p>trained them as a way to bridge any remaining gaps between the system and the
</p>
<p>users. This approach has become increasingly unacceptable as people have
</p>
<p>become better informed about technology and now expect to use it out of the box,
</p>
<p>In addition, there have been recent political changes which require that systems are
</p>
<p>accessible to more people (e.g., the Americans with Disabilities Act), rendering the
</p>
<p>idea of fitting the user to the system less unacceptable.
</p>
<p>It is now generally the case that you should design (or re-design) your system to
</p>
<p>make it fit your users. We would strongly argue that you need to think right from
</p>
<p>the very start of the project about your users, the tasks they will perform using your
</p>
<p>system, and the context in which your system will be used. In other words, when
</p>
<p>you are defining the system&rsquo;s functional requirements, you should also be defining
</p>
<p>the usability requirements.
</p>
<p>The level of detail required here should be guided by the associated risks
</p>
<p>involved. If you only talk to developers as proxy users to determine usability
</p>
<p>requirements, for example, there is a large risk that the delivered system will not
</p>
<p>be acceptable to the real end users because the proxy users will not understand
</p>
<p>how the real users will carry out their work using the system in a work context
</p>
<p>that may constrain how the system can be used. If your system will be used in
</p>
<p>extreme or safety critical environments (e.g., in space or aviation), for example,
</p>
<p>your users will be highly skilled practitioners making decisions and performing
</p>
<p>actions in a limited time frame, where the results may have life or death
</p>
<p>importance. These risks are increased if the designers are unlike the users (Casper
</p>
<p>and Murphy 2003 provides a nice case study). In these cases we recommend that
</p>
<p>you do some background work in the domain, looking at existing systems similar
</p>
<p>to the one you are designing and consulting appropriate resources such as books,
</p>
<p>as well meeting the users and seeing their context and tasks and running some
</p>
<p>studies to test out your ideas and develop your understanding of the system&rsquo;s
</p>
<p>context.
</p>
<p>For simple, straightforward systems developed for your own purposes (like
</p>
<p>many systems that are used in research, for example), you may not need to worry
</p>
<p>too much about the design of the user interface. Even for very small numbers of
</p>
<p>expert users it may not be worthwhile spending large amounts of time and effort on
</p>
<p>developing the user interface because the costs may well exceed the benefits.
</p>
<p>1.3 The Benefits and Costs of Understanding Users 15</p>
<p/>
</div>
<div class="page"><p/>
<p>Often your population of users will be heterogeneous, and if you are not aware
</p>
<p>of this heterogeneity you could end up disenfranchising large sections of your
</p>
<p>users. We have worked with web sites that now incorporate text versions so that
</p>
<p>they can also support the visually impaired (through screen readers and descrip-
</p>
<p>tions of pictures), and users that access the web via low speed connections, such as
</p>
<p>dialup lines or from very remote locations (Ritter et al. 2005). Neither of these
</p>
<p>types of users is likely to be the same as many designers.
</p>
<p>Although there is no general solution to the question of when to stop analyzing
</p>
<p>the user and start building the system, Pew and Mavor&rsquo;s (2007) approach provides
</p>
<p>a subjective answer. In their risk driven approach, the risks to success are
</p>
<p>re-evaluated as the design process progresses. In some cases, progress with the
</p>
<p>technology is the largest risk to success; in others, not knowing the user and their
</p>
<p>tasks will be the largest risk. So Pew and Mavor&rsquo;s answer is that you should study
</p>
<p>the user and their tasks until the risk of not knowing more about them is lower than
</p>
<p>the other risks to success. As noted above, we will return to describe this approach
</p>
<p>in more detail in the final chapter, Chap. 14.
</p>
<p>1.4 Summarizing Design Relevant User Characteristics:
</p>
<p>The ABCS Framework
</p>
<p>The purpose of this book is to help you to come up with principled opinions about
</p>
<p>what designs are most likely to be effective. We introduce the idea of design
</p>
<p>relevant user characteristics. Attempts to define a complete list of human char-
</p>
<p>acteristics stretch from hundreds (e.g., Brown 1988) to thousands of pages (Boff
</p>
<p>and Lincoln 1988; Salvendy 1997). Table 1.2 offers some examples that are often
</p>
<p>discussed, taken from Brown (1988).
</p>
<p>To help organize design relevant human characteristics, we offer a framework
</p>
<p>that we call the ABCS. The abbreviation represents four aspects of users that often
</p>
<p>need to be examined when designing systems:
</p>
<p>A Anthropometrics: the shape of the body and how it influences what is
</p>
<p>designed; consideration of the physical characteristics of intended users such
</p>
<p>as what size they are, what muscle strength they have, and so on
</p>
<p>B Behavior: perceptual and motivational characteristics, looking at what people
</p>
<p>can perceive and why they do what they do
</p>
<p>C Cognition: learning, attention, and other aspects of cognition and how these
</p>
<p>processes influence design; users defined by how they think and what they
</p>
<p>know and what knowledge they can acquire
</p>
<p>S Social factors: how groups of users behave, and how to support them through
</p>
<p>design; users defined by where they are&mdash;their context broadly defined
</p>
<p>including their relationships to other people.
</p>
<p>We now briefly explain each of these areas in more detail.
</p>
<p>16 1 Introducing User-Centered Systems Design</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14">http://dx.doi.org/10.1007/978-1-4471-5134-0_14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14">http://dx.doi.org/10.1007/978-1-4471-5134-0_14</a></div>
</div>
<div class="page"><p/>
<p>1.4.1 Anthropometrics Approach
</p>
<p>Anthropometrics is concerned with the physical aspects of the user and the system.
</p>
<p>For example, Fig. 1.4 shows an input glove. How do people use this? What are
</p>
<p>their natural movements in it, and do these movements change with a glove on?
</p>
<p>How long can they use it before becoming fatigued or hurt by it? The answers to
</p>
<p>questions like these would involve resolving the issues in Table 1.3.
</p>
<p>These physical aspects are often studied in the area of human factors and
</p>
<p>ergonomics and applied to standard office equipment like desks and chairs. A lot is
</p>
<p>known about how to improve the fit of the hardware to the user&rsquo;s body, including
</p>
<p>back, knees, waist, and arms (Pheasant and Haslegrave 2006). The optimal work
</p>
<p>surface height, for example, varies by the individual concerned but also by the task
</p>
<p>to be performed.
</p>
<p>It is also important that we consider whether we need to design for individuals
</p>
<p>(e.g., desk setups need to be specifically tailored to avoid upper limb disorders), for
</p>
<p>the average (e.g., seats in buses and trains are designed for averages), or for
</p>
<p>extremes (e.g., plane ejector seats). For example, Ted Williams, the famous
</p>
<p>American baseball player and fighter aircraft pilot, reportedly crash-landed a plane
</p>
<p>rather than eject so that he would be able to play baseball again after the Korean
</p>
<p>war&mdash;the design error was that ejector seats were designed for the average height
</p>
<p>of a pilot, which left those in the upper 5&ndash;10% of the height range in danger of
</p>
<p>damaged or removed kneecaps if they ejected.1
</p>
<p>In computer systems these problems include making sure that controls (knobs,
</p>
<p>dials, buttons, and so on) are of a size that can be manipulated by a wide range of
</p>
<p>users. Weight and button size are important for their usability and the perceived
</p>
<p>usability for their marketing. For example, the release of many different sizes of
</p>
<p>interactive tablet computers into the market over recent years suggests the physical
</p>
<p>sizes of these devices matter for different use scenarios. Early mobile phones were
</p>
<p>Table 1.2 Human characteristics relevant for system design
</p>
<p>&bull; Physical characteristics, limitations, and disabilities
</p>
<p>&bull; Perceptual abilities, strengths, and weaknesses
</p>
<p>&bull; Frequency of product use
</p>
<p>&bull; Past experience with same/similar product
</p>
<p>&bull; Activity &lsquo;&lsquo;mental set&rsquo;&rsquo; (the attitude toward and level of motivation you have for the activity)
</p>
<p>&bull; Tolerance for error
</p>
<p>&bull; Patience and motivation for learning
</p>
<p>&bull; Culture/language/population expectations and norms
</p>
<p>1 http://www.tedwilliams.com/index.php?page=burnjet
</p>
<p>1.4 Summarizing Design Relevant User Characteristics 17</p>
<p/>
<div class="annotation"><a href="http://www.tedwilliams.com/index.php?page=burnjet">http://www.tedwilliams.com/index.php?page=burnjet</a></div>
</div>
<div class="page"><p/>
<p>the size of briefcases, and laptops weighed 30 pounds; these failed to be as popular
</p>
<p>as expected partly because they were not small enough.
</p>
<p>These issues are equally important in the design of mobile devices. Weight and
</p>
<p>button size are important for their usability and the perceived usability for their
</p>
<p>marketing. These issues will be more important for reality-based interfaces, where
</p>
<p>computing is embedded into objects such as passports, children&rsquo;s toys, and objects
</p>
<p>that have RFID tags which allow them to be tracked. These interfaces include both
</p>
<p>computational aspects as well as the physical nature of the objects and the
</p>
<p>opportunities and constraints that physical realization provides.
</p>
<p>Fig. 1.4 An input glove.
(Photo taken by and used
with permission of Georgios
Christou)
</p>
<p>Table 1.3 Example usability issues arising from the anthropometric level
</p>
<p>&bull; Providing normative data on limb sizes, body weight/height, and so on
</p>
<p>&bull; Providing descriptions of how sensitive touch is for input and output, particularly for the hands
</p>
<p>&bull; Measurement of muscle strain (to assess length of time on a particular job)
</p>
<p>&bull; Measurement of posture during particular tasks (to facilitate redesign of equipment)
</p>
<p>18 1 Introducing User-Centered Systems Design</p>
<p/>
</div>
<div class="page"><p/>
<p>1.4.2 Behavioral Aspects
</p>
<p>When we discuss the behavioral aspects of the user, we refer to the basic behaviors
</p>
<p>users can produce. The behavioral level builds on the anthropometric level as the
</p>
<p>physical aspects of the body are used to produce simple behaviors. Table 1.4
</p>
<p>provides several examples, drawing on a wide range of application areas.
</p>
<p>Behavioral analysis has supported and led to the creation of checklists of those
</p>
<p>tasks best performed by humans and those best performed by machines. Table 1.5
</p>
<p>shows an example of such a list, where human and machine tasks could be
</p>
<p>assigned on the basis of better fit. Such lists have been critiqued for being too static
</p>
<p>(Sheridan 1992), but the exercise of making such lists, updated according to
</p>
<p>technological innovations and changes in human expectations and abilities through
</p>
<p>training, can be useful. An excellent example of the evolution of the way we think
</p>
<p>about task allocation is the recent success of IBM&rsquo;s Watson system. Historically,
</p>
<p>Table 1.4 Example usability issues arising from the behavioral level
</p>
<p>Car interfaces&mdash;questions of legibility of characters, avoidance of glare in bright sunlight,
avoiding parallax problems with different heights of drivers, and making sure that the dials are
not obscured by the steering wheel
</p>
<p>Making knobs and levers tactually discriminable to enable them to be used without looking to
check whether the correct control is being used (e.g., putting a wheel on the landing gear lever
in a plane)
</p>
<p>Problem of ascertaining the physical actions of how something is used, to see whether it can be
made quicker/safer/more productive, and so on
</p>
<p>Looking at simple errors (slips of action) that are made, to see how they can be mitigated or
prevented
</p>
<p>Table 1.5 The original Fitts (1951) list
</p>
<p>Humans appear to surpass present-day (i.e., 1951) machines with respect to:
</p>
<p>&bull; Ability to detect small amounts of visual or acoustic energy
</p>
<p>&bull; Ability to perceive patterns of light or sound
</p>
<p>&bull; Ability to improvise and use flexible procedures
</p>
<p>&bull; Ability to store very large amounts of information for long periods and to recall relevant facts at
the appropriate time
</p>
<p>&bull; Ability to reason inductively
</p>
<p>&bull; Ability to exercise judgment
</p>
<p>Present-day machines appear to surpass humans with respect to:
</p>
<p>&bull; Ability to respond quickly to control signals, and to apply great force smoothly and precisely
</p>
<p>&bull; Ability to perform repetitive, routine tasks
</p>
<p>&bull; Ability to store information briefly and then to erase it completely
</p>
<p>&bull; Ability to reason deductively, including computational ability
</p>
<p>&bull; Ability to handle highly complex operations, that is, to do many different things at once
</p>
<p>1.4 Summarizing Design Relevant User Characteristics 19</p>
<p/>
</div>
<div class="page"><p/>
<p>because humans reason creatively and inductively through association and using
</p>
<p>mnemonics, they could easily beat computers on standard general knowledge tests.
</p>
<p>However, since the advent of the Internet, which represents a massive database of
</p>
<p>general knowledge that has been supplied through untold hours of human content
</p>
<p>contribution and improvements in computational processing power and search
</p>
<p>algorithms, it is possible for a machine, Watson, to beat a human at such tests.
</p>
<p>What we see in this example is that the notion of even what a machine is can
</p>
<p>change over time. Therefore, when considering allocation of processing activities
</p>
<p>between humans and computational devices, we need to ensure we are using the
</p>
<p>most appropriate sense of the term machine.
</p>
<p>We also include simple interaction at the behavioral level. For example,
</p>
<p>Norman (2013) has written about &lsquo;&lsquo;forcing functions&rsquo;&rsquo;. These are aspects of
</p>
<p>devices that suggest particular uses or styles of interaction. In some cases, affor-
</p>
<p>dances force a particular style of interaction. One of Norman&rsquo;s favorite examples
</p>
<p>is door design. Doors with handles suggest that they should be pulled, while doors
</p>
<p>without handles suggest that they should be pushed. A forcing function would be
</p>
<p>where the door with the handle cannot be pushed, thus forcing that it be pulled.
</p>
<p>Violation of these affordances (doors that can only be pushed yet have handles)
</p>
<p>leads to confusion. Perceptual issues sit between the behavior and cognition. For
</p>
<p>example, PowerPoint presentations where the font is too small means people
</p>
<p>cannot read the content unless they move physically closer (Kosslyn 2007).
</p>
<p>In addition to noting the basic foundations that explain how people behave, we
</p>
<p>also have to consider why people behave in the way that they do. The motivation
</p>
<p>that people have for performing particular tasks will vary, partly depending on
</p>
<p>internal factors, but also partly on external factors (e.g., is it a work task, is it being
</p>
<p>carried out in an informal setting, and so on.)
</p>
<p>1.4.3 Cognition
</p>
<p>The cognitive level uses the previous two levels and builds upon them. On this
</p>
<p>level, how the user thinks about their task and the system is considered, as well as
</p>
<p>both basic and higher level cognitive capabilities. These capabilities include a
</p>
<p>variety of memory systems that the user has available, as well how these memories
</p>
<p>are organized and how they are used by a central processor. Higher level con-
</p>
<p>structs include how attention and learning affect these structures and processes.
</p>
<p>Some example cognitive issues are shown in Table 1.6.
</p>
<p>Work on the cognitive level will often involve observation of the tool/envi-
</p>
<p>ronment in use, asking the question of why and when is it used? This is necessary
</p>
<p>because users will vary more on this level of analysis than on the previous two
</p>
<p>levels. On this level, people will vary based on previous experience, which can
</p>
<p>include training, formal education, previous use, personal style, and strategy
</p>
<p>choice.
</p>
<p>20 1 Introducing User-Centered Systems Design</p>
<p/>
</div>
<div class="page"><p/>
<p>A better understanding of how users think and feel can be used to create better
</p>
<p>designs. An improved system can come from understanding the mental effort
</p>
<p>involved in tasks in terms of the information processing mechanisms (architecture)
</p>
<p>that support our thinking, including constraints such as how many arbitrary
</p>
<p>symbols users can remember. These issues may help us to understand how com-
</p>
<p>plex devices with high functionality (e.g., personal video recorders) can be made
</p>
<p>more accessible to non-expert users by providing information, by guiding the user,
</p>
<p>and by not asking them to perform difficult tasks (like remembering more than
</p>
<p>their short-term memory can hold).
</p>
<p>For example, consider the fairly common task of determining differences
</p>
<p>between two or more items. Imagine you had two dials to read, each with a
</p>
<p>different number, and these numbers varied randomly. Your task is to press a
</p>
<p>button when the difference between the two numbers exceeds 10. This task would
</p>
<p>require you to process the information from both dials, make a mental calculation
</p>
<p>and evaluate whether the difference exceeds 10. The existence of a third dial which
</p>
<p>just showed the difference would make your task easier and faster, removing the
</p>
<p>need for the mental calculation (the cognitive effort).
</p>
<p>1.4.4 Social Factors
</p>
<p>The final level is the social level. How do users interact with other people in
</p>
<p>relation to their task? In some cases this interaction will be to work on the task
</p>
<p>jointly with others using the computer to support and mediate their communica-
</p>
<p>tion. In other cases, users will ask other users for help in understanding systems, or
</p>
<p>will use the system for, or with others (such as bank tellers, loan officers, and
</p>
<p>airline pilots), or the interaction could be constrained by some regulatory authority
</p>
<p>(as in aviation and the nuclear power industry).
</p>
<p>Table 1.6 Example cognitive level issues
</p>
<p>How do users decide where to look for information?
</p>
<p>What information do users need to develop a strategy for performing a particular task? Do they
need absolute or relative values?
</p>
<p>How much experience do the users have with the task and with the interface?
</p>
<p>What is the user&rsquo;s mental model of the interface and task (which will often differ from the
designer&rsquo;s or the observer&rsquo;s mental model of the same interface and task)?
</p>
<p>Is there so much noise and interruption that users cannot process information, for example, the
interruptions in the Kegworth aircraft crash?
</p>
<p>How can users tell if things are not going well? What feedback do they get? What strategies are
available to the user when the system goes wrong?
</p>
<p>How can we ensure that users do not lose their ability to perform the task manually as a result of
automation?
</p>
<p>How can word processors be made more accessible to novice users or casual users? How do these
factors change when the systems considered are more complex?
</p>
<p>1.4 Summarizing Design Relevant User Characteristics 21</p>
<p/>
</div>
<div class="page"><p/>
<p>Like the previous levels, this level builds upon and uses the constructs and
</p>
<p>theories of the previous level. In this case, the cognitive level, including the mental
</p>
<p>models of others, is particularly important.
</p>
<p>The motivation that people have for performing particular tasks and working in
</p>
<p>teams will vary, partly depending on internal factors but also partly on external
</p>
<p>factors (e.g., is it a work task, is it being carried out in an informal setting, and so
</p>
<p>on).
</p>
<p>The social level can be very important. Many of the accidents in safety&ndash;critical
</p>
<p>systems, for example planes, have their roots in the dynamics of the social pro-
</p>
<p>cesses between people controlling various parts of the systems, and their social
</p>
<p>environment. Perhaps the most typical failure is for a subordinate not to tell a
</p>
<p>superior or not to tell them forcefully enough about an impending problem, which
</p>
<p>then becomes unmanageable because of the delay. Simple failures in inter-per-
</p>
<p>sonal communications can also cause accidents. Table 1.7 lists some further
</p>
<p>examples of issues on the social level.
</p>
<p>Flowers (1997) explains how the task of moving the London ambulance dis-
</p>
<p>patching system from paper to computer went wrong. The designers seriously
</p>
<p>misunderstood how the dispatchers worked, how the drivers worked, and how the
</p>
<p>two groups worked together. There were also software development and imple-
</p>
<p>mentation problems. While no loss of life was reported, ambulance response times
</p>
<p>were seriously compromised, the director was sacked, and about 3 million pounds
</p>
<p>($4.5 million) worth of development was written off. This is an example where
</p>
<p>social factors were ignored in system design.
</p>
<p>Organizational, professional, and national cultural issues&mdash;how users from
</p>
<p>different cultural backgrounds have different characteristics&mdash;are also grouped
</p>
<p>under this heading in this book. Examples of these differences include how colors
</p>
<p>can mean different things in different cultures: green does not always mean go, and
</p>
<p>white may be the traditional color for funeral dress rather than black. Other
</p>
<p>examples include how the most natural ordering of objects may be left to right in
</p>
<p>many cultures but right to left in others, and how some cultures encourage
</p>
<p>appropriate questioning of people in responsible positions (such as aircraft pilots),
</p>
<p>whilst others frown upon it.
</p>
<p>As can be seen from the Kegworth air disaster (described in the Appendix), the
</p>
<p>cabin crew (as well as the passengers) knew that the wrong engine may have been
</p>
<p>Table 1.7 Example issues on the social level
</p>
<p>&bull; A crew distracted by interruptions that failed to complete a safety checklist did not confirm that
the aeroplane&rsquo;s flaps were extended, causing the plane to crash on take-off
</p>
<p>&bull; A co-pilot failed to get the attention of a more senior captain about concerns that take-off thrust
was not properly set, causing the aircraft to crash into a river
</p>
<p>&bull; A communications breakdown between captain, co-pilot, and air traffic control on the amount
of fuel in the plane caused a crash when the fuel ran out
</p>
<p>&bull; You want to buy the same video game as your best friend so you can play him at your house,
and so you can practice to beat him!
</p>
<p>22 1 Introducing User-Centered Systems Design</p>
<p/>
</div>
<div class="page"><p/>
<p>turned off, but did not interrupt the pilots, possibly because of the high social status
</p>
<p>accorded to the pilots. This type of cultural issue, where someone knows some-
</p>
<p>thing that could help a team or a project and does not raise the issue, is a well
</p>
<p>documented problem. How to adjust appropriately the social dynamics to fix
</p>
<p>problems like this remains an important and interesting problem.
</p>
<p>Another example comes from a nuclear power plant in Europe. A reporting
</p>
<p>system was set up to allow staff to report incidents (near misses) so that the
</p>
<p>company could learn from them to try and prevent the same thing happening
</p>
<p>(Masson 1991). This was all working fine, and management and staff had settled
</p>
<p>into using the system. Staff were happy to report incidents and were not blamed
</p>
<p>when the incidents did occur. The management then decided that they would
</p>
<p>change the (negotiated) culture, in which the emphasis had been on reporting
</p>
<p>incidents, to one that focused on incidents as a measure of safety, and decided that
</p>
<p>the shift that reported the least incidents would be regarded as the safest shift and
</p>
<p>would receive some reward.
</p>
<p>The net effect was that staff stopped reporting incidents in a bid to make their
</p>
<p>shift appear to be the safest. In the end a new incident reporting system had to be
</p>
<p>developed, and all the data about the unreported incidents was lost because the
</p>
<p>management had unwittingly changed the culture from one that was designed to
</p>
<p>use reported problems as a way of learning and improving safety to one that was
</p>
<p>effectively designed to reward the lack of reporting of problems.
</p>
<p>1.5 Simulating User Characteristics: Cognitive
</p>
<p>Architectures
</p>
<p>One of the main aims of this book is to help you to develop a better understanding
</p>
<p>of why users do things the way they do. Understanding the way users think and
</p>
<p>behave will help you design systems that support users. The ABCS framework,
</p>
<p>described above, provides one way of organizing this information about user
</p>
<p>characteristics. It is also possible to encapsulate relevant details in a model. For
</p>
<p>example, if one is interested specifically in human information processing, cog-
</p>
<p>nitive architectures provide a convenient way of modeling human information
</p>
<p>processing under different conditions, because they include mechanisms that are
</p>
<p>specifically designed for modeling human cognition.
</p>
<p>Figure 1.5 is a schematic of the major components of a computer model of a
</p>
<p>user. The major components in this model are designed to mimic the major
</p>
<p>components of users. The top box, ACT-R, refers to a simplified form of the ACT-
</p>
<p>R cognitive architecture (Anderson and Lebiere 1998). (There are other archi-
</p>
<p>tectures, but they are similar for our purposes.) In this instance the architecture has
</p>
<p>been combined with an extension that allows it to interact effectively with the
</p>
<p>external world. So the combined cognitive architecture takes the bitmap from a
</p>
<p>computer screen and, in a process approximating vision, computes the objects and
</p>
<p>some of their features in the image and puts the results into a perceptual buffer.
</p>
<p>1.4 Summarizing Design Relevant User Characteristics 23</p>
<p/>
</div>
<div class="page"><p/>
<p>This perceptual buffer represents many of the aspects of the human vision system.
</p>
<p>Similar buffers should be created for hearing and the other senses.
</p>
<p>At the center of the architecture is a reasoning system that can access information
</p>
<p>in the perceptual buffer and access and modify information in the declarative
</p>
<p>memory and goal buffers. It uses the information in these buffers to guide its
</p>
<p>processing, using a process that mimics human behavior. Output actions to the
</p>
<p>external world are put into a motor buffer, where motor routines generate the results.
</p>
<p>This representation is somewhat generic and far from complete, but illustrates a
</p>
<p>theory of the major information processing components of the user. There are other
</p>
<p>theories of how users process information, and even the ACT-R theory has changed
</p>
<p>over time. Work is ongoing to apply this approach to create models of users that
</p>
<p>can be used to test interfaces (e.g., Byrne 2001; Freed and Remington 2000; Ki-
</p>
<p>eras et al. 1997), to serve as intelligent colleagues (Weiland et al. 2002) and
</p>
<p>opponents in computer-based games and simulations (e.g., Jones et al. 1999; Laird
</p>
<p>and van Lent 2001; Tambe et al. 1995), and to summarize our knowledge of human
</p>
<p>behavior (e.g., Anderson et al. 2004; Jones et al. 2000; Lovett et al. 2000).
</p>
<p>1.6 Summary
</p>
<p>This chapter has introduced the study of people who use artifacts (i.e., users),
</p>
<p>given you some definitions and useful terms, and provided an overview to organize
</p>
<p>your further reading. We have also highlighted some common (mistaken) pre-
</p>
<p>conceptions about what makes for good design and noted why studying users is
</p>
<p>important. In particular, we have introduced the concept of the fundamental
</p>
<p>attribution error of design, where designers think that users are like themselves,
</p>
<p>which is very often not the case.
</p>
<p>Computer Environment
</p>
<p>Production
Rule System
</p>
<p>Goal
Buffer
</p>
<p>Declarative
Buffer
</p>
<p>Motor
Buffer
</p>
<p>Perceptual
Buffer
</p>
<p>ACT-R
</p>
<p>Simulated Eyes 
</p>
<p>and Hands 
</p>
<p>Motor
Routines
</p>
<p>Image 
Processing 
Routines
</p>
<p>Fig. 1.5 A representation of
the ACT-R cognitive
architecture with the SegMan
extension to allow it to
interact with interfaces
through computer bitmaps
</p>
<p>24 1 Introducing User-Centered Systems Design</p>
<p/>
</div>
<div class="page"><p/>
<p>We believe that understanding users is fundamentally important and often leads
</p>
<p>to more usable systems. There are costs as well as benefits associated with
</p>
<p>studying and understanding users, however, and it is important to realize when you
</p>
<p>should decide to stop analyzing the users and start building your system. A risk-
</p>
<p>based approach to development can help inform this decision. We explain this
</p>
<p>more fully in the Chap. 14 that you might wish to preview.
</p>
<p>The information about users&rsquo; design related capabilities can be organized using
</p>
<p>the ABCS framework to encapsulate people&rsquo;s physical shape, how they perceive,
</p>
<p>how they think, and how they interact with other people. This simple abbreviation
</p>
<p>can be used to remember the information and to guide your considerations during
</p>
<p>system design. Chapters 3&ndash;10 cover these levels.
</p>
<p>We also introduced the idea of cognitive architectures, which can be used to
</p>
<p>develop models that simulate how people perceive, think, and act. Although we
</p>
<p>used the ACT-R architecture as an exemplar, other cognitive architectures could
</p>
<p>also be used to organize and apply knowledge about users. We take up this
</p>
<p>approach again in the Chap. 14.
</p>
<p>1.6.1 Structure of the Rest of the Book
</p>
<p>You can think of the book as being divided into four parts. The first two chapters
</p>
<p>introduce the notion of user centered design and examine the underlying history.
</p>
<p>The second part of the book (Chaps. 3&ndash;10) examines specific characteristics of
</p>
<p>the user. Our perspective draws heavily on psychology. We focus on the sensory
</p>
<p>and cognitive, information processing, aspects of the user, partly because this is
</p>
<p>where our expertise lies, but also because much interaction requires people to
</p>
<p>sense, understand, communicate, and learn. We limit our discussions to the topics
</p>
<p>that are most relevant to designers while also offering pointers to those people who
</p>
<p>want to read more about these topics.
</p>
<p>The third part of the book (Chaps. 11&ndash;13) introduces some methods that can be
</p>
<p>used to inform and evaluate design. This is an active area of application and
</p>
<p>research, and there are now so many different approaches that it would be
</p>
<p>impossible to cover them all here.
</p>
<p>The book concludes with a short summary (Chap. 14). This highlights how you
</p>
<p>can organize what you have learned about users and notes some possible directions
</p>
<p>that are currently being explored to apply it.
</p>
<p>On completing this book you will have acquired an understanding of humans
</p>
<p>and their behavior when interacting with complex, interactive systems. You will
</p>
<p>have sufficient grounding to be better able to design systems that take appropriate
</p>
<p>account of your users, their tasks, and the context in which they perform those
</p>
<p>tasks. You will be able to justify how (and why) a particular design is appropriate
</p>
<p>from a conceptual level down to a practical level, using the toolbox of methods
</p>
<p>and techniques that we have placed at your disposal.
</p>
<p>1.6 Summary 25</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14">http://dx.doi.org/10.1007/978-1-4471-5134-0_14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14">http://dx.doi.org/10.1007/978-1-4471-5134-0_14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3">http://dx.doi.org/10.1007/978-1-4471-5134-0_3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3">http://dx.doi.org/10.1007/978-1-4471-5134-0_3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10">http://dx.doi.org/10.1007/978-1-4471-5134-0_10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14">http://dx.doi.org/10.1007/978-1-4471-5134-0_14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14">http://dx.doi.org/10.1007/978-1-4471-5134-0_14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3">http://dx.doi.org/10.1007/978-1-4471-5134-0_3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3">http://dx.doi.org/10.1007/978-1-4471-5134-0_3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10">http://dx.doi.org/10.1007/978-1-4471-5134-0_10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11">http://dx.doi.org/10.1007/978-1-4471-5134-0_11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11">http://dx.doi.org/10.1007/978-1-4471-5134-0_11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13">http://dx.doi.org/10.1007/978-1-4471-5134-0_13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14">http://dx.doi.org/10.1007/978-1-4471-5134-0_14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14">http://dx.doi.org/10.1007/978-1-4471-5134-0_14</a></div>
</div>
<div class="page"><p/>
<p>1.6.2 Future Work
</p>
<p>You should now be aware that there is a lot to be learned about users. While
</p>
<p>technology can change rapidly basic user capabilities and characteristics change
</p>
<p>slowly, if at all. It is important to be aware of critical user characteristics, their
</p>
<p>relative importance for a design, and their likelihood of change over time.
</p>
<p>There is also much more that needs to be learned. As you read the rest of this
</p>
<p>book, you should become aware of the remaining problems, some of which are
</p>
<p>listed in Table 1.8.
</p>
<p>1.7 Other Resources
</p>
<p>Here we note some further books and online resources.
</p>
<p>The books by Christopher Wickens (Wickens et al. 1998; Wickens and
</p>
<p>Hollands 2000) provide more details than this book does. These books focus more
</p>
<p>on human factors and physical engineering of workplace.
</p>
<p>The books by Preece et al. (2002) and Dix, Finlay, Abowd, and Beale, both
</p>
<p>titled Human&ndash;Computer Interaction, and Interaction Design: Beyond Human&ndash;
</p>
<p>Table 1.8 Some remaining problems in contemporary system design
</p>
<p>&bull; The size of systems and diversity of users and tasks are increasing. How are we to find,
represent, and use this information?
</p>
<p>&bull; The complexity of the systems is increasing: users do not always get adequate feedback on what
is going on, and cannot see the internal state of the system. Norman (2013) provides further
examples. How are we to keep users informed without overwhelming them with information?
</p>
<p>&bull; The nuances of social and organization factors and the communication of these nuances through
computer supported communication are not fully understood and predictable. How can
designers get and use this information? How can it be represented?
</p>
<p>&bull; How can we improve the usability of designer&rsquo;s tools to help them improve usability for users?
</p>
<p>&bull; Studies of the user need to go beyond recommendations about the design of technology&mdash;can
we offer a conceptual basis for these recommendations? One approach is to create a unified
theory of how users behave, but this theory has not yet been fully created or made available
for automatic application
</p>
<p>&bull; With further understanding come questions about lower and higher levels. Once we know how
users work in small groups we can see that larger groups also have influence as do previous
groups who used the system. What is this information and how do we include this
information?
</p>
<p>&bull; Esthetics and emotions are difficult factors to explain and quantify. Users, particularly users of
personal and home technologies, generally care about how the system looks and what pleasure
it gives them, sometimes irrespective of how it works or how well it works. In these areas,
then, esthetics is closely related to acceptability, and there is some evidence of a high
correlation between esthetics and usability (e.g., Tractinsky 1997). The inter-relationship
between usability, functionality, emotional responses, and esthetics, however, still needs to be
worked out
</p>
<p>26 1 Introducing User-Centered Systems Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Computer Interaction, 3rd Edition, by Sharp, Rogers, and Preece are all worth a
</p>
<p>closer look. These books include more on technology and on designing interface
</p>
<p>technology rather than focusing in detail on the various aspects of the users that
</p>
<p>affect interaction. Clayton Lewis and John Rieman&rsquo;s shareware book: Task-
</p>
<p>Centered User Interface Design, hcibib.org/tcuid/ covers similar material but
</p>
<p>focuses more on design and task analyses, and does not include as much psy-
</p>
<p>chology. It helps put the material in this book into perspective for design purposes.
</p>
<p>Descriptions of design failures often make interesting reading, and their lesson
</p>
<p>can sometimes be generalized to other systems. For large systems, Petroski&rsquo;s
</p>
<p>(1985) book is one of the most popular. Petroski&rsquo;s observation that engineering has
</p>
<p>progressed over the centuries by learning from failure also applies to interface
</p>
<p>design. The ACM Committee on Computers and Public Policy&rsquo;s Risks Digest at
</p>
<p>catless.ncl.ac.uk/Risks/ provides numerous examples of where poor usability has
</p>
<p>led to problems.
</p>
<p>There are many online resources available on HCI and human factors. The HCI
</p>
<p>Bibliography Project, hcibib.org, provides an online bibliography of papers in
</p>
<p>journals and conferences related to HCI. The Computer&ndash;Human Interaction Spe-
</p>
<p>cial Interest Group of the Association for Computing Machinery (ACM-SIGCHI)
</p>
<p>has a very useful web site at www.acm.org/sigchi/ They organize the CHI con-
</p>
<p>ference every year, as well as producing a magazine, interactions.
</p>
<p>You can also examine the design and graphic design literature to understand
</p>
<p>esthetics better. There are books on the design of graphic information (e.g., Tufte
</p>
<p>1990), on the design of pages (e.g., White 2002), on the design of fonts, page
</p>
<p>layouts, graphics, and so on. If you are interested in this area, consider looking
</p>
<p>through libraries (personal, institutional, and public), using search engines, and
</p>
<p>consulting academic course catalogues, all of which can provide you with much
</p>
<p>more information.
</p>
<p>Don Norman&rsquo;s books, including the classic The design of everyday things2
</p>
<p>(1988/2013), provide a useful set of examples of why design matters. At times the
</p>
<p>examples may seem small, but in nearly every case their impact is magnified by
</p>
<p>the number of people affected, the possible severity of the consequences, or their
</p>
<p>clarity. Many people have been convinced of the importance of HCI as a result of
</p>
<p>reading this book.
</p>
<p>The importance of esthetics should not be underestimated, even though we do
</p>
<p>not cover it in any great detail here. Jordan (2000), for example, argues that
</p>
<p>esthetics of devices will increase over time. When systems are equivalent, it may
</p>
<p>be the case that their users differentiate between them on the basis of how pleasing
</p>
<p>their appearance is. Some researchers have found that pleasing interfaces work
</p>
<p>better (Helander and Tham 2003), and Norman (2006, 2009) argues this position
</p>
<p>repeatedly, including that esthetics and functionality should be considered equally
</p>
<p>important.
</p>
<p>2 Also published sometimes as The psychology of everyday things.
3 A millisecond is a thousandth of a second, and is abbreviated ms.
</p>
<p>1.7 Other Resources 27</p>
<p/>
<div class="annotation"><a href="http://hcibib.org/tcuid/">http://hcibib.org/tcuid/</a></div>
<div class="annotation"><a href="http://catless.ncl.ac.uk/Risks/">http://catless.ncl.ac.uk/Risks/</a></div>
<div class="annotation"><a href="http://www.acm.org/sigchi/">http://www.acm.org/sigchi/</a></div>
</div>
<div class="page"><p/>
<p>1.8 Exercises
</p>
<p>1.1 The correct ranked order for the buttons in Fig. 1.1 is as follows: (a)
</p>
<p>(411 ms3), (d) (469 ms), (b) and (c) (each 539 ms). The lights in D have a
</p>
<p>simple rule that users can follow&ndash; look to the diagonal. The lights in B and C
</p>
<p>have two rules (or at least a more complex rule): if the lights are in the
</p>
<p>middle, hit the button below; if the lights are on the end, hit the diagonal
</p>
<p>button. The extra conditions, or rules, take extra time to learn and extra time to
</p>
<p>perform. They would also lead to more errors.
</p>
<p>Ask some of your friends and or family to choose the best designs in
</p>
<p>Figs. 1.1 and 1.2. How do they compare to your performance and to Payne&rsquo;s
</p>
<p>subjects? If you have access to interface designers, ask them. How does your
</p>
<p>own stove compare to these mappings? What do your results mean for
</p>
<p>interface design?
</p>
<p>1.2 In Fig. 1.3 the correct coin is Penny A. The point is, most people do not
</p>
<p>memorize the features of objects in detail, they memorize just enough to
</p>
<p>recognize and differentiate the coin from typical distracters, like other legal
</p>
<p>coins, or to find the right menu item when it is in front of them. Try this simple
</p>
<p>test for the penny with your friends, and also ask computer users to identify
</p>
<p>the correct Word menu in Fig. 1.6.
</p>
<p>1.3 Consider a mobile device (such as a smartphone or tablet). What difficulties
</p>
<p>might people encounter in using the device for the first time? What difficulties
</p>
<p>might people have in understanding how to use it and what to do with it? How
</p>
<p>would they go about learning how to use it?
</p>
<p>File Home Insert Page Layout References Mailings Review View
</p>
<p>Word File Edit View Insert Font Tools Table Window Work Help
</p>
<p>FileHome Insert Page References Review View HelpLayout
</p>
<p>File Edit View Insert Font Tools Window HelpHome Review
</p>
<p>File Edit View Insert Font Tools Window HelpReview
</p>
<p>[OS Icon]
</p>
<p>[OS Icon]
</p>
<p>FileHome Insert LayoutReviewView Table Work[OS Icon]
</p>
<p>FileHome Insert Page Layout References Review ViewWord Help
</p>
<p>Home Insert Page Layout References Mailings Review View Add-Ins
</p>
<p>File Edit View Insert Format Tools Table Window Help
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>4
</p>
<p>5
</p>
<p>6
</p>
<p>7
</p>
<p>8
</p>
<p>9
</p>
<p>10 [OS Icon] File Edit Arrange StencilsFormat InspectorsView Window Help
</p>
<p>Format
</p>
<p>Fig. 1.6 Possible views of the top menu on MS Word. Without looking at Word, which of the
ten menus is the one you use?
</p>
<p>3 A millisecond is a thousandth of a second, and is abbreviated ms.
</p>
<p>28 1 Introducing User-Centered Systems Design</p>
<p/>
</div>
<div class="page"><p/>
<p>Write short notes (about one side of a page) on some of these issues you
</p>
<p>have identified, classifying them as anthropometric, behavioral, cognitive, or
</p>
<p>social. Think about what design changes you might make to the device to
</p>
<p>make it easier for novices to use.
</p>
<p>1.4 Consider an airplane crash like Kegworth, the Asiana in San Francisco, or
</p>
<p>another one where you can obtain some of the details. Classify the problems
</p>
<p>that led to the disaster with respect to the four levels introduced here. Sum-
</p>
<p>marize what level was the most important and could have stopped the disaster.
</p>
<p>1.5 Select something you use every day that you think is well designed. Think
</p>
<p>about why this is well designed. You may wish to consider esthetics, map-
</p>
<p>pings of actions to responses, how you learned to use it, and what kinds of
</p>
<p>mistakes or errors you still make.
</p>
<p>1.6 What are some other payoffs from studying the user? As ways to brainstorm,
</p>
<p>consider the types of outputs the various fields related to users would provide.
</p>
<p>As another hint, consider fields that study users or aspects of users, and
</p>
<p>consider what they might want from interfaces or from interactions with
</p>
<p>interfaces or systems.
</p>
<p>References
</p>
<p>Anderson, J. R., &amp; Lebiere, C. (1998). The atomic components of thought. Mahwah, NJ: Erlbaum.
Anderson, J. R., Bothell, D., Byrne, M. D., Douglass, S., Lebiere, C., &amp; Qin, Y. (2004). An
</p>
<p>integrated theory of the mind. Psychological Review, 111(4), 1036&ndash;1060.
Baxter, G. D., Monk, A. F., Tan, K., Dear, P. R. F., &amp; Newell, S. J. (2005). Using cognitive task
</p>
<p>analysis to facilitate the integration of decision support systems into the neonatal intensive
care unit. Artificial Intelligence in Medicine, 35, 243&ndash;257.
</p>
<p>Boff, K. R., &amp; Lincoln, J. E. (Eds.). (1988). Engineering data compendium (User&rsquo;s guide). Wright-
Patterson Air Force Base, OH: Harry G. Armstrong Aerospace Medical Research Laboratory.
</p>
<p>Booher, H. R., &amp; Minninger, J. (2003). Human systems integration in army systems acquisition.
In H. R. Booher (Ed.), Handbook of human systems integration (pp. 663&ndash;698). Hoboken, NJ:
John Wiley.
</p>
<p>Brown, C. M. L. (1988). Human-computer interface design guidelines. Norwood, NJ: Ablex.
Bruce, V., Gilmore, D., Mason, L., &amp; Mayhew, P. (1983). Factors affecting the perceived value of
</p>
<p>coins. Journal of Economic Psychology, 4(4), 335&ndash;347.
Byrne, M. D. (2001). ACT-R/PM and menu selection: Applying a cognitive architecture to HCI.
</p>
<p>International Journal of Human-Computer Studies, 55(1), 41&ndash;84.
Casper, J., &amp; Murphy, R. (2003). Human-robot interactions during the robot-assisted urban search
</p>
<p>and rescue response at the World Trade Center. IEEE Transactions on Systems, Man, and
Cybernetics Part B, 33(3), 367&ndash;385.
</p>
<p>Chapanis, A., &amp; Lindenbaum, L. E. (1959). A reaction time study of four control-display
linkages. Human Factors, 1(4), 1&ndash;7.
</p>
<p>Ericsson, K. A., &amp; Simon, H. A. (1993). Protocol analysis: Verbal reports as data (2nd ed.).
Cambridge, MA: MIT Press.
</p>
<p>Fitts, P. M. (1951). Engineering psychology and equipment design. In S. S. Stevens (Ed.),
Handbook of experimental psychology (pp. 1287&ndash;1340). New York, NY: John Wiley.
</p>
<p>Flowers, S. (1997). Software failure: Management failure&hellip; Amazing stories and cautionary
tales. New York, NY: Wiley.
</p>
<p>1.8 Exercises 29</p>
<p/>
</div>
<div class="page"><p/>
<p>Freed, M., &amp; Remington, R. (2000). Making human-machine system simulation a practical
engineering tool: An APEX overview. In Proceedings of the 3rd International Conference on
Cognitive Modelling (pp. 110&ndash;117). Veenendaal, The Netherlands: Universal Press.
</p>
<p>Gigerenzer, G. (2004). Dread risk, september 11, and fatal traffic accidents. Psychological
Science, 15(4), 286&ndash;287.
</p>
<p>Glushko, R. J., &amp; Tabas, L. (2009). Designing service systems by bridging the &lsquo;&lsquo;front stage&rsquo;&rsquo; and
&lsquo;&lsquo;back stage&rsquo;&rsquo;. Information Systems and e-Business Management, 7(4), 407&ndash;427.
</p>
<p>Gray, W. D., John, B. E., &amp; Atwood, M. E. (1992). The precis of project Ernestine or an overview
of a validation of GOMS. In Proceedings of the CHI&lsquo;92 Conference on Human Factors in
Computer Systems. New York, NY: ACM Press.
</p>
<p>Gray, W. D., John, B. E., &amp; Atwood, M. E. (1993). Project Ernestine: Validating a GOMS
analysis for predicting and explaining real-world task performance. Human-Computer
Interaction, 8(3), 237&ndash;309.
</p>
<p>Helander, M. G., &amp; Tham, M. P. (2003). Hedonomics: Affective human factors design.
Ergonomics, 46(13/14), 1269&ndash;1272.
</p>
<p>Holmes, N. (2005). The Internet, the Web, and the Chaos. IEEE Computer, 38(108), 106&ndash;107.
Johnson, E. J., Bellman, S., &amp; Lohse, G. L. (2003). Cognitive lock-in and the power law of
</p>
<p>practice. Journal of Marketing, 67, 62&ndash;75.
Jones, G., Ritter, F. E., &amp; Wood, D. J. (2000). Using a cognitive architecture to examine what
</p>
<p>develops. Psychological Science, 11(2), 93&ndash;100.
Jones, R. M., Laird, J. E., Nielsen, P. E., Coulter, K. J., Kenny, P., &amp; Koss, F. V. (1999).
</p>
<p>Automated intelligent pilots for combat flight simulation. AI Magazine, 20(1), 27&ndash;41.
Jordan, P. W. (2000). Designing pleasurable products. London: Taylor &amp; Francis.
Kieras, D. E., Wood, S. D., &amp; Meyer, D. E. (1997). Predictive engineering models based on the
</p>
<p>EPIC architecture for a multimodal high-performance human-computer interaction task.
Transactions on Computer-Human Interaction, 4(3), 230&ndash;275.
</p>
<p>Kosslyn, S. M. (2007). Clear and to the point: 8 psychological principles for creating compelling
Powerpoint presentations. New York, NY: Oxford University Press.
</p>
<p>Laird, J. E., &amp; van Lent, M. (2001). Human-level AI&rsquo;s killer application: Interactive computer
games. AI Magazine, 22(2), 15&ndash;26.
</p>
<p>Leveson, N. G., &amp; Turner, C. S. (1993). An investigation of the Therac-25 accidents. IEEE
Computer, 26(7), 18&ndash;41.
</p>
<p>Lovett, M. C., Daily, L. Z., &amp; Reder, L. M. (2000). A source activation theory of working
memory: Cross-task prediction of performance in ACT-R. Journal of Cognitive Systems
Research, 1, 99&ndash;118.
</p>
<p>Masson, M. (1991). Understanding, reporting and preventing human fixation errors. In T. W. v. d.
Schaaf, D. A. Lucas &amp; A. Hale (Eds.), Near miss reporting as a safety tool (pp. 35&ndash;50).
Oxford, UK: Butterworth-Heinemann.
</p>
<p>Nickerson, R. S., &amp; Adams, M. J. (1979). Long-term memory for a common object. Cognitive
Psychology, 11, 287&ndash;307.
</p>
<p>Nielsen, J. (1993). Usability engineering. Chestnut Hill, MA: AP Professional Press.
Norman, D. A. (1981). Categorization of action slips. Psychological Review, 88, 1&ndash;15.
Norman, D. A. (2006). Emotional design: Why we love (or hate) everyday things. New York, NY:
</p>
<p>Basic Books.
Norman, D. A. (2009). The design of future things. New York, NY: Basic Books.
Norman, D. A. (2013). The design of everyday things. NY: Basic Books.
Payne, S. J. (1995). Naive judgments of stimulus-response compatibility. Human Factors, 37,
</p>
<p>495&ndash;506.
Petroski, H. (1985/1992). To engineer is human: The role of failure in successful design. New
</p>
<p>York, NY: Vintage Books.
Pew, R. W., &amp; Mavor, A. S. (Eds.). (2007). Human-system integration in the system development
</p>
<p>process: A new look. Washington, DC: National Academies Press. http://books.nap.edu/
catalog.php?record_id=11893. Accessed 10 March 2014.
</p>
<p>30 1 Introducing User-Centered Systems Design</p>
<p/>
<div class="annotation"><a href="http://books.nap.edu/catalog.php?record_id=11893">http://books.nap.edu/catalog.php?record_id=11893</a></div>
<div class="annotation"><a href="http://books.nap.edu/catalog.php?record_id=11893">http://books.nap.edu/catalog.php?record_id=11893</a></div>
</div>
<div class="page"><p/>
<p>Pheasant, S., &amp; Haslegrave, C. M. (2006). Bodyspace: Anthropometry, ergonomics, and the
design of work (3rd ed.). Boca Raton, FL: Taylor &amp; Francis.
</p>
<p>Preece, J., Rogers, Y., &amp; Sharp, H. (2002). Interaction design. New York, NY: Wiley.
Reason, J. (1990). Human error. Cambridge, UK: Cambridge University Press.
Ritter, F. E., Freed, A. R., &amp; Haskett, O. L. (2005). User information needs: The case of
</p>
<p>university department web sites. ACM interactions, 12(5), 19&ndash;27. acs.ist.psu.edu/acs-lab/
reports/ritterFH02.pdf
</p>
<p>Salvendy, G. (Ed.). (1997). Handbook of human factors and ergonomics (2nd ed.). New York,
NY: Wiley.
</p>
<p>Sheridan, T. B. (1992). Telerobotics, automation, and human supervisory control. Cambridge,
MA: MIT Press.
</p>
<p>Tambe, M., Johnson, W. L., Jones, R. M., Koss, F., Laird, J. E., Rosenbloom, P. S., et al. (1995).
Intelligent agents for interactive simulation environments. AI Magazine, 16(1), 15&ndash;40.
</p>
<p>Tractinsky, N. (1997). Aesthetics and apparent usability: Empirically assessing cultural and
methodological issues. In CHI &lsquo;97 (pp. 115&ndash;122). New York, NY: ACM. http://sigchi.org/
chi97/proceedings/paper/nt.htm. Accessed 11 March 2014.
</p>
<p>Tufte, E. R. (1990). Envisioning information. Cheshire, CT: Graphics Press.
Weiland, W., Szczepkowski, M., Urban, G., Mitchell, T., Lyons, D., &amp; Soles, R. (2002). Reusing
</p>
<p>cognitive models: Leveraging SCOTT technology in an LCAC virtual training environment.
In Proceedings of the 11th Computer Generated Forces Conference, 02-CGF-115. Orlando,
FL: U. of Central Florida.
</p>
<p>White, A. W. (2002). The elements of graphic design: Space, unity, page architecture, and type.
New York, NY: Allworth Press.
</p>
<p>Wickens, C. D., Gordon, S. E., &amp; Liu, Y. (1998). An introduction to human factors engineering.
New York, NY: Addison-Wesley.
</p>
<p>Wickens, C. D., &amp; Hollands, J. G. (2000). Engineering psychology and human performance (3rd
ed.). Upper Saddle River, NJ: Prentice-Hall.
</p>
<p>References 31</p>
<p/>
<div class="annotation"><a href="http://acs.ist.psu.edu/acs-lab/reports/ritterFH02.pdf">http://acs.ist.psu.edu/acs-lab/reports/ritterFH02.pdf</a></div>
<div class="annotation"><a href="http://acs.ist.psu.edu/acs-lab/reports/ritterFH02.pdf">http://acs.ist.psu.edu/acs-lab/reports/ritterFH02.pdf</a></div>
<div class="annotation"><a href="http://sigchi.org/chi97/proceedings/paper/nt.htm">http://sigchi.org/chi97/proceedings/paper/nt.htm</a></div>
<div class="annotation"><a href="http://sigchi.org/chi97/proceedings/paper/nt.htm">http://sigchi.org/chi97/proceedings/paper/nt.htm</a></div>
</div>
<div class="page"><p/>
<p>Chapter 2
</p>
<p>User-Centered Systems Design: A Brief
</p>
<p>History
</p>
<p>Abstract The intention of this book is to help you think about design from a
</p>
<p>user-centered perspective. Our aim is to help you understand what questions to ask
</p>
<p>when designing a technology or a system or when you are evaluating a design that
</p>
<p>already exists. We focus on physiological, cognitive, and social aspects of the
</p>
<p>human user, aspects that will affect how someone will use what you design. This
</p>
<p>chapter introduces some historical background to the field of User Centered
</p>
<p>System Design, and introduces current themes.
</p>
<p>2.1 Introduction
</p>
<p>It has long been recognized that we need to consider human capabilities and
</p>
<p>characteristics when designing technologies and systems. As Nickerson summa-
</p>
<p>rized in 1969, when the potential for computer-based technologies was first being
</p>
<p>fully recognized: &lsquo;&lsquo;the need for the future is not so much computer oriented people
</p>
<p>as for people oriented computers&rsquo;&rsquo; (Nickerson 1969, p. 178 in the IEEE version).
</p>
<p>Since then a number of fields have grown up, expitly concerned with how to
</p>
<p>design effective technologies and systems that are intended for human use. User-
</p>
<p>Centered Systems Design (UCSD or HCSD or when the word &lsquo;&lsquo;human&rsquo;&rsquo; is used
</p>
<p>instead of &lsquo;&lsquo;user&rsquo;&rsquo;), User Experience (UX), User-Centered Design (UCD), Inter-
</p>
<p>action Design (IxD) and Human&ndash;Computer Interaction (HCI) are areas of research
</p>
<p>that have taken up that call and are concerned with improving how people interact
</p>
<p>with computers. Each of these has a slightly different focus and breadth, and each
</p>
<p>encompasses many different approaches. What they all have in common is that
</p>
<p>they grow their methods and deliverables in response to changes in the techno-
</p>
<p>logical landscape.
</p>
<p>In this chapter we offer an overview of the intellectual roots of these areas of
</p>
<p>research and development. Early work focused on the learning and use of com-
</p>
<p>mand-line interfaces and on programming languages. Following the development
</p>
<p>of now familiar) WIMP interfaces (Windows, Icons, Menus, Pointer) and
</p>
<p>F. E. Ritter et al., Foundations for Designing User-Centered Systems,
DOI: 10.1007/978-1-4471-5134-0_2, ï¿½ Springer-Verlag London 2014
</p>
<p>33</p>
<p/>
</div>
<div class="page"><p/>
<p>Graphical User Interfaces (GUIs), the focus shifted to understanding how to design
</p>
<p>visual layouts and the optimization of input devices. Developments in the tech-
</p>
<p>nology of the devices (e.g., mobile computing, embedded computation, and sensor
</p>
<p>technologies), and in input methods (e.g., sound, vision, and gesture), have led to a
</p>
<p>proliferation of design and evaluation methods and a focus on the effects of context
</p>
<p>on user&rsquo;s experiences of devices, applications, and services. Further, as the uses of
</p>
<p>technology have been ever more democratized&mdash;computers are no longer only
</p>
<p>available to a few expert users&mdash;the effects of individual differences or diver-
</p>
<p>gences in use by different user populations have also been increasingly of interest
</p>
<p>(e.g., differences between children and adults, cultural differences in uptake and
</p>
<p>use, gender differences in use). Research has also focused on much broader con-
</p>
<p>cerns, such as the effects of technology design and uptake in terms of social impact
</p>
<p>and cultural/global sustainability.
</p>
<p>2.2 Influential and Related Research Fields
</p>
<p>The intellectual roots of User-Centered Design (UCD, also sometimes called
</p>
<p>User-Centered System Design, UCSD) lie in several areas of basic and applied
</p>
<p>research. These include:
</p>
<p>&bull; Cognitive and social psychology
</p>
<p>&bull; Linguistics
</p>
<p>&bull; Mathematics
</p>
<p>&bull; Computer science
</p>
<p>&bull; Engineering
</p>
<p>&bull; Human factors and ergonomics
</p>
<p>&bull; Socio-technical systems design
</p>
<p>&bull; Scientific management
</p>
<p>&bull; Work, industrial, and occupational psychology
</p>
<p>&bull; Human relations
</p>
<p>&bull; Organizational behavior.
</p>
<p>User-centered systems designers also draw on basic research in anthropology,
</p>
<p>sociology, and information science, and in recent years there has been considerable
</p>
<p>overlap with ideas flowing between UCD researchers and practitioners and those
</p>
<p>in research areas such as user experience (UX), human&ndash;computer interaction,
</p>
<p>computer supported cooperative work, computer-mediated communication, and
</p>
<p>ubiquitous/pervasive computing.
</p>
<p>Figure 2.1 presents a simple summary of roots of UCD and how they are
</p>
<p>related. It is deliberately simplistic but should provide you with some insights into
</p>
<p>how UCD came about.
</p>
<p>34 2 User-Centered Systems Design: A Brief History</p>
<p/>
</div>
<div class="page"><p/>
<p>In this section we offer a brief introduction to the fields we consider to be most
</p>
<p>influential to our approach in this text. These include various branches of human
</p>
<p>factors and ergonomics, user-centered design, and human&ndash;computer interaction.
</p>
<p>2.2.1 Ergonomics and Human Factors
</p>
<p>Derived from the Greek word ergon for work and nomos for natural laws, ergo-
</p>
<p>nomics draws on a number of research areas including anatomy, engineering,
</p>
<p>physiology, and psychology. The purpose of ergonomics and human factors
</p>
<p>research and practice is to maximize the safety and healthiness of work environ-
</p>
<p>ments and work practices, and to ensure the usability of tools, devices, and arti-
</p>
<p>facts in general. More specifically, ergonomics and HF are concerned with
</p>
<p>providing a good fit between people and their work or leisure environments. There
</p>
<p>are a number of sub-fields in ergonomics that have arisen as a result of the
</p>
<p>increasing penetration of technology into everyday lives. We give a short overview
</p>
<p>of each of these below. First, however, it is worth considering the notion of &lsquo;&lsquo;fit.&rsquo;&rsquo;
</p>
<p>Many of us are familiar with ergonomic assessments in the workplace; these
</p>
<p>assessments are conducted to minimize the risk of hazards to health and to prevent
</p>
<p>ailments such as upper limb disorders. In the UK, however, human factors have
</p>
<p>embraced the broader context of work practices, going beyond physical environ-
</p>
<p>ment considerations and biomechanics to include selection and training. Thus,
</p>
<p>fitting the person to the environment is the responsibility of selection and training,
</p>
<p>whilst ergonomists fit the environment to the person. Although in this book we are
</p>
<p>not concerned with selection and training, it is worth noting that there is a com-
</p>
<p>plementary relationship between these activities&ndash;user groups may be selected or
</p>
<p>Users
</p>
<p>User- Cognition
</p>
<p>Users - Body
</p>
<p>Human Factors
</p>
<p>Cognitive Ergonomics
</p>
<p>HCI
</p>
<p>CHI
</p>
<p>Psychology
</p>
<p>Computer Interfaces
</p>
<p>CS
</p>
<p>Sociology
Social Psychology
</p>
<p>General Technology
</p>
<p>Fig. 2.1 A pictorial
summary of some of the
fields related to the user. The
major fields are shown with
solid lines
</p>
<p>2.2 Influential and Related Research Fields 35</p>
<p/>
</div>
<div class="page"><p/>
<p>required by the working environment and/or training and selection are employed to
</p>
<p>modify the user population to provide the most advantageous fit between the user
</p>
<p>and the technology.
</p>
<p>We can borrow from Rodger&rsquo;s (cited in Holloway 1991) encapsulation in the
</p>
<p>1950s which was summarized as &lsquo;&lsquo;fitting the man to the job and the job to the
</p>
<p>man&rsquo;&rsquo;1 (FMJ/FJM). This is broken down into:
</p>
<p>Fitting the man to the job through
</p>
<p>Occupational guidance
</p>
<p>Personnel selection
</p>
<p>Training and development
</p>
<p>and fitting the job to the man through
</p>
<p>Methods design
</p>
<p>Equipment design
</p>
<p>Negotiation of working conditions and (physical and social) rewards.
</p>
<p>Although Rodger&rsquo;s definition is limited, as it does not take into account the
</p>
<p>organization in which the person works, we can see this useful encapsulation for
</p>
<p>occupational psychology as extended by consideration of issues dealt with by
</p>
<p>human factors.
</p>
<p>The concept of &lsquo;fit&rsquo; is a useful one. For physical devices and designed envi-
</p>
<p>ronments, the term fit is used literally. For example, on amusement park rides there
</p>
<p>are height restrictions&mdash;children have to wait till they are a certain height and
</p>
<p>weight before they are allowed on rides. However, the concept of fit is also used
</p>
<p>when people need to conform the way they act and think to accommodate how
</p>
<p>tasks are laid out in interfaces. Sometimes this is appropriate, but sometimes
</p>
<p>alternative designs which modify themselves to accommodate human traits would
</p>
<p>be more effective. For example, Figs. 2.2 and 2.3 show two example web sites that
</p>
<p>invite the user to fit themselves to the interfaces, suggesting they modify their
</p>
<p>behavior to the interfaces. In Fig. 2.2 the web site can recognize that users often
</p>
<p>put their email address in (e.g., fer2@psu.edu), but rather than remove the domain
</p>
<p>for the user (@psu.edu), it instructs the user to do so. Figure 2.3 shows a low-cost
</p>
<p>airline web site where the user is trying to find a cheap flight from Edinburgh to
</p>
<p>Naples in the run up to Christmas. The results on the 3 day view and 3 week view
</p>
<p>tabs simply show there is nothing available. Even the Year view tab only shows the
</p>
<p>cheapest prices against the months when flights take place. The user then has to
</p>
<p>infer from the results on the Year view tab that the last flights take place in
</p>
<p>October. The problem arises because the user is thinking in terms of flight dates&mdash;
</p>
<p>1 We note that the language at the time used the word man to include both genders, a practice
that, appropriately, is no longer acceptable.
</p>
<p>36 2 User-Centered Systems Design: A Brief History</p>
<p/>
</div>
<div class="page"><p/>
<p>they do not care about dates when there are no flights&mdash;but the web site only works
</p>
<p>in terms of calendar dates.
</p>
<p>2.2.1.1 Classical Ergonomics
</p>
<p>Classical ergonomics has also been called interface ergonomics. The interface
</p>
<p>referred to is the person/machine interface of controls and displays, and the
</p>
<p>principle contribution of the designer is the improved design of dials and meters,
</p>
<p>control knobs, and panel layout. Notably people are usually referred to as users or
</p>
<p>operators in this literature. The expert&rsquo;s concerns can extend beyond the design of
</p>
<p>chairs, benches, and machinery to specify at least partly the optimum physical
</p>
<p>work environment, including temperature, humidity, and location of work
</p>
<p>surfaces.
</p>
<p>This classical approach started with the design of military equipment, but now
</p>
<p>considers the design of items and workspaces in civilian contexts. This approach
</p>
<p>often takes a consultancy mode, with advice usually being delivered in the form of
</p>
<p>principles, guidelines, and standards. This can cause problems for two reasons:
</p>
<p>(1) classical ergonomists are only called in at the end of development and asked to
</p>
<p>advise on the final product, rather than being involved throughout the development
</p>
<p>process&mdash;this means that ill-thought out design decisions with poor rationale may
</p>
<p>already be &lsquo;&lsquo;baked into&rsquo;&rsquo; the design, and no easy fix (or no fix at all) is possible;
</p>
<p>and (2) guidelines and prescriptions for design activity are usually generic, and
</p>
<p>lack context specific details. We return to this issue in Sect. 2.3.
</p>
<p>Fig. 2.2 An example interface that attempts to &lsquo;&lsquo;fit the user to the machine&rsquo;&rsquo;. In the top entry field
the user is expected to remove the domain rather than have the system do that (many sites, including
GMail, will let users login with either user-name or user-name@domain, this one does not)
</p>
<p>2.2 Influential and Related Research Fields 37</p>
<p/>
</div>
<div class="page"><p/>
<p>2.2.1.2 Error Ergonomics
</p>
<p>Error ergonomics is the study and explanation of human error in systems. The zero
</p>
<p>defects approach assumes that human error is the result of inadequate motivation, c.f.
</p>
<p>the examples of accidents and error attribution including the official report onKegworth
</p>
<p>noted in the Appendix. Reason (1997) describes this as the person model or person
</p>
<p>approach. This approach tends to result in campaigns for safety procedure training and
</p>
<p>for safety oriented materials. These drives attempt to raise awareness and incentives for
</p>
<p>the workers. Even during theWorldWar I, where the work force was highlymotivated,
</p>
<p>error ergonomists discovered that fatigue was a major cause of errors.
</p>
<p>Similarly, the error data store approach, which forms a part of methods like
</p>
<p>THERP (Technique for Human Error Rate Prediction, Swain &amp; Guttman, 1983)
</p>
<p>assumes that human error is inevitable (this is discussed further in Chap. 10). This
</p>
<p>approach produces data banks of error probabilities for a variety of tasks executed
</p>
<p>under various conditions. It is therefore necessary to predict the incidence and
</p>
<p>consequences of human errors in any given situation. The results inform the design
</p>
<p>of systems in a way that minimizes the occurrence and effects of errors.
</p>
<p>Fig. 2.3 In this interface the airline presents flight information using calendar dates. On the left
is the 3 day view, in the center is a 3 week view, and on the right is a year view. Whereas the user
most likely wants to view flight dates (with a pointer to the last, or next available flight, e.g.,
something like &lsquo;&lsquo;there are no flights available for the period you have selected, the nearest
available dates are October xx 2013 and April yy 2014&rsquo;&rsquo;). This interface offers hints and
encourages the user to search repeatedly rather than do the search for the user
</p>
<p>38 2 User-Centered Systems Design: A Brief History</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10">http://dx.doi.org/10.1007/978-1-4471-5134-0_10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10">http://dx.doi.org/10.1007/978-1-4471-5134-0_10</a></div>
</div>
<div class="page"><p/>
<p>2.2.1.3 Systems Ergonomics
</p>
<p>This approach was developed in the USA in the 1950s, and takes a more holistic
</p>
<p>approach to understanding users and systems as they work in concert. That is, the
</p>
<p>user and the system are seen as a single interacting system that is placed within a
</p>
<p>work context. Within this approach, system design involves parallel development
</p>
<p>of hardware and personnel issues, with training and selection issues considered.
</p>
<p>The ergonomist acts as an integral member of the design team, working throughout
</p>
<p>the life cycle to inform the system design. Therefore, in addition to the physical,
</p>
<p>behavioral and cognitive considerations of the finished product itself, the human
</p>
<p>factors expert (or &lsquo;&lsquo;ergonomist&rsquo;&rsquo;) is involved in: (1) determining the required task
</p>
<p>functions (by activity and task analysis in conjunction with the consideration of the
</p>
<p>task requirements) and allocating the functions between the user and the system
</p>
<p>(2) the design of personnel subsystems, and (3) the design of job descriptions and
</p>
<p>job support materials (e.g., manuals and training schemes).
</p>
<p>The approach differs from user-centered design as the designers and human
</p>
<p>factors experts still view the user as just one part of the system, whereas user-
</p>
<p>centered design focuses more on the user&rsquo;s needs and perspective than those of the
</p>
<p>system, tasks, and activities per se. In computer system development, for example,
</p>
<p>a systems approach would consider the task from a logical, syntactic perspective
</p>
<p>and then the computer system implementation issues with a view to allocating
</p>
<p>function between the user and the computer system. A user-centered approach
</p>
<p>would consider the processing capabilities of the human user and analyze tasks
</p>
<p>from the perspective of the user.
</p>
<p>2.2.1.4 Cognitive Ergonomics/Cognitive Systems Engineering
</p>
<p>Since the mid-1960s and the development of integrated circuits and third gener-
</p>
<p>ation computer systems, research has been carried out in user-centered aspects of
</p>
<p>data processing, management information systems, information systems, and
</p>
<p>information technology. The 1970s saw a rapid increase in the use of computer-
</p>
<p>based technologies, resulting in the body of knowledge about user-centered design
</p>
<p>methods in areas such as Office Information Systems, industrial process control
</p>
<p>systems, and transportation systems. The role of people changed from one of
</p>
<p>directly controlling machinery and equipment to one in which they were inter-
</p>
<p>acting with computer based technology. In industrial systems this was character-
</p>
<p>ized by a change in the operator&rsquo;s role from one of hands-on control to one of
</p>
<p>monitoring and supervisory control. This change from doing to thinking meant that
</p>
<p>it became more important to understand the way that people perceived problems,
</p>
<p>made decisions, and took actions. This led to the development of the field of
</p>
<p>cognitive ergonomics, which is nowadays more frequently described as cognitive
</p>
<p>systems engineering (CSE), or just cognitive engineering.
</p>
<p>Originally developed in the 1970s and early 1980s (Hollnagel and Woods
</p>
<p>1983), cognitive systems engineering has continued to evolve since that period
</p>
<p>2.2 Influential and Related Research Fields 39</p>
<p/>
</div>
<div class="page"><p/>
<p>(Hollnagel and Woods 2005; Woods and Hollnagel 2006). Cognitive ergonomics is
</p>
<p>concerned with human&ndash;machine systems. Here, machine is taken to represent any
</p>
<p>artifact that is designed for a specific purpose. There are technological aspects to
</p>
<p>these systems, which are investigated from the perspective of how they affect
</p>
<p>use. These systems are always embedded in a socio-technical context because
</p>
<p>people are involved in the design, construction, testing, and use of these systems.
</p>
<p>Although CSE practitioners regard all systems as socio-technical systems, they
</p>
<p>usually draw a distinction between the technological system, in which the tech-
</p>
<p>nology plays the central role in determining what happens, and the organizational
</p>
<p>system, in which people mainly determine what happens.
</p>
<p>CSE is concerned with applicable, approximate models of how people perceive,
</p>
<p>process, attend to, and use information to achieve their goals. Aimed at designers,
</p>
<p>instructors, and users, CSE draws on many areas of psychology that are often
</p>
<p>taught separately, such as planning, language, problem solving, learning, memory,
</p>
<p>and perception. However, CSE addresses how such processes work together. It is
</p>
<p>different to the direct application of cognitive psychology in that it does not look at
</p>
<p>cognitive processes in isolation, but at their integration and how they are involved
</p>
<p>in particular activities or situations. CSE also differs from cognitive psychology in
</p>
<p>focusing on theories which can predict behavior in what have been called real
</p>
<p>world settings, rather than laboratory settings, although results from laboratory
</p>
<p>settings are considered informative. Real world settings may require a more
</p>
<p>detailed treatment of, for example, individual differences, uncertainty, ad hoc
</p>
<p>problem solving, and so on, than many other branches of psychology. CSE also
</p>
<p>places greater emphasis on the co-agency of action between the user and the
</p>
<p>machine, but, again, this is a difference in emphasis and these fields overlap to a
</p>
<p>great extent.
</p>
<p>CSE is thus largely concerned with applications in complex dynamic domains,
</p>
<p>such as aviation, industrial process control, healthcare, and so on. It normally starts
</p>
<p>by attempting to understand the issue at hand, using observation to try to under-
</p>
<p>stand the patterns of work. It then uses this understanding to guide the search to
</p>
<p>identify what would be useful to support the types of work that have been
</p>
<p>observed. These insights are then used as a basis for (innovative) design, in par-
</p>
<p>ticipation with others, to support the work, the processes of change, and optimizing
</p>
<p>the process.
</p>
<p>2.2.2 Socio-Technical Systems Design
</p>
<p>The term socio-technical systemswas originally coined by Emery and Trist (1960) to
</p>
<p>describe systems that involve a complex interaction between humans, machines, and
</p>
<p>the environmental aspects of the work system&mdash;something that is true of most
</p>
<p>systems in the workplace. The corollary of this definition is that all of these factors&mdash;
</p>
<p>people, machines, and context&mdash;need to be taken into account when developing
</p>
<p>40 2 User-Centered Systems Design: A Brief History</p>
<p/>
</div>
<div class="page"><p/>
<p>socio-technical systems using so-called socio-technical system design (STSD)
</p>
<p>methods such as ETHICS (Effective Technical and Human Implementation of
</p>
<p>Computer-based Systems; Mumford 1983, 1995). In reality, these methods are more
</p>
<p>like guiding philosophies than design methods that are usually associated with
</p>
<p>systems engineering (Mumford 2006). In other words, the STSD methods tend to
</p>
<p>provide a process and a set of guiding principles (e.g., Cherns 1987; Clegg 2000)
</p>
<p>rather than a set of detailed steps that have to be followed.
</p>
<p>From its inception in the period immediately after World War II, by what is
</p>
<p>now called The Tavistock Institute, until the present day, there have been several
</p>
<p>attempts at applying the ideas of STSD, although these have not always been
</p>
<p>successful (e.g., see Mumford 2006 for a critical review of the history of STSD
</p>
<p>methods). Early work in STSD focused mostly on manufacturing and production
</p>
<p>industries such as coal, textiles, and petrochemicals. The general aim was to
</p>
<p>investigate the organization of work and to see whether it could be made more
</p>
<p>humanistic, incorporating aspects such as the quality of working life. In other
</p>
<p>words, the idea was a move away from the mechanistic view of work that is
</p>
<p>usually associated with Taylor&rsquo;s principles of scientific management, which lar-
</p>
<p>gely relied on the specialization of work and the division of labor.
</p>
<p>The heyday of STSD was probably the 1970s. This was a time when there were
</p>
<p>labor shortages, and companies were keen to use all means available to keep their
</p>
<p>existing staff. This was also the period where more and more computer systems
</p>
<p>were being introduced into the workplace. Apart from the usual cultural and social
</p>
<p>reasons, companies could also see good business reasons for adopting socio-
</p>
<p>technical ideas. As just one of many such examples, Digital Equipment Corpo-
</p>
<p>ration (DEC) had a family of expert systems that were developed using STSD
</p>
<p>(e.g., see Mumford and MacDonald 1989) to support the configuration and loca-
</p>
<p>tion of DEC VAX computers that saved the company tens of millions of dollars a
</p>
<p>year (Barker and O&rsquo;Connor 1989).
</p>
<p>There was a downturn in the use of STSD in the 1980s and 1990s as lean
</p>
<p>production techniques and business process re-engineering approaches dominated
</p>
<p>system development. STSD is, however, still widely advocated in the field of health
</p>
<p>informatics for the development of health care applications (e.g., Whetton 2005).
</p>
<p>Many medical systems are still never used because they introduce ways of working
</p>
<p>that conflict with other aspects of the user&rsquo;s job, or they require changes to pro-
</p>
<p>cedures that affect other people&rsquo;s responsibilities. By focusing on the underlying
</p>
<p>work structure, STSD approaches facilitate the development of medical systems
</p>
<p>that are acceptable to the users (Berg 1999, 2001; Berg and Toussaint 2003).
</p>
<p>Socio-technical ideas pervade a lot of thinking around information systems,
</p>
<p>although they may not always be explicitly referred to as such (Avgerou et al.
</p>
<p>2004). The ideas appear in areas such as participatory design methods, computer
</p>
<p>supported cooperative work (CSCW), and ethnographic approaches to design.
</p>
<p>Recently, Baxter and Sommerville (2011) have outlined the need for socio-tech-
</p>
<p>nical systems engineering, which integrates the ideas that have been developed in
</p>
<p>these different areas.
</p>
<p>2.2 Influential and Related Research Fields 41</p>
<p/>
</div>
<div class="page"><p/>
<p>2.2.3 Cognitive Modeling and Programmable User Models
</p>
<p>A cognitive model is an approximation of how people reason. The goal of a
</p>
<p>cognitive model is to explain scientifically very basic cognitive processes, explain
</p>
<p>how these processes interact, account for errors and breakdowns in these pro-
</p>
<p>cesses, and derive predictions about how those reasoning processes will proceed
</p>
<p>under different conditions.
</p>
<p>Cognitive modeling is a method developed from early work in the late 1950s
</p>
<p>when psychologists realized that computational processes may be a good analog of
</p>
<p>human reasoning processes: like humans, computers take input in the form of
</p>
<p>symbols, require memory for information storage, and manipulate those symbols
</p>
<p>with algorithms to produce output. It was therefore proposed not only that human
</p>
<p>reasoning could be an inspiration for thinking about computational processes but
</p>
<p>also that computers may be a good way for us to simulate human reasoning and
</p>
<p>therefore derive deeper understandings of how humans think (Newell et al. 1960;
</p>
<p>Newell and Simon 1972).
</p>
<p>Cognitive models in the late 1960s, the 1970s, and the 1980s focused on how
</p>
<p>people solved problems symbolically: humans take input in and form symbols,
</p>
<p>require memory for information storage, and use algorithms to manipulate those
</p>
<p>symbols to produce output. The models were usually limited to one task (or one
</p>
<p>type of task) and usually simulated reasoning in terms of what was going on in the
</p>
<p>user&rsquo;s mind. They addressed human information processing but did not address
</p>
<p>how information is taken in from the external world, how actions are performed in
</p>
<p>the world, and the ways in which real world settings impact the pace at which
</p>
<p>those processes take place. Each model was essentially a micro-theory of how
</p>
<p>some part of behavior occurred, and it was independent of other micro-theories.
</p>
<p>Over time, the need to integrate the micro-theories increased, which led to the idea
</p>
<p>of unified theories of cognition (UTCs; Newell 1990).
</p>
<p>These theories are implemented as cognitive architectures available as com-
</p>
<p>puter simulations that constrain how models (based on task knowledge) can per-
</p>
<p>form tasks in psychologically plausible ways. So, for example, often when humans
</p>
<p>perform two tasks simultaneously, the performance on one is affected by the
</p>
<p>performance on the other. Cognitive models are essentially programs written in a
</p>
<p>specific language to run on particular cognitive architectures. The models can
</p>
<p>perform complex tasks including perception, learning, reasoning, problem solving,
</p>
<p>remembering, decision making, proprioception (how people manage their bodies
</p>
<p>in space), and ambulation (how people move around physical spaces).
</p>
<p>There has long been an overlap between cognitive modeling and human&ndash;
</p>
<p>computer interaction. Drawing on these developments in psychological theory and
</p>
<p>in simulation modeling, design researchers started investigating the possibility of
</p>
<p>building models of how people reason and problem solve when using complex
</p>
<p>interfaces, so that predictions about the pros and cons of different interface and
</p>
<p>information representation choices could be tested prior to investing in any
</p>
<p>interface or interaction development (e.g., Pew and Mavor 2007). Models force the
</p>
<p>42 2 User-Centered Systems Design: A Brief History</p>
<p/>
</div>
<div class="page"><p/>
<p>designer to consider psychological factors systematically and explicitly as they
</p>
<p>make usability predictions. Examples of some influential approaches in the world
</p>
<p>of human&ndash;computer interaction are the Model Human Processor (MHP), GOMS
</p>
<p>(which stands for Goals, Operators, Methods, and Selection rules), the Keystroke
</p>
<p>Level Model (KLM) (see Card et al. 1983), and Programmable User Models
</p>
<p>(PUMs: Young et al. 1989).We will discuss this further in Chap. 11 on task analysis.
</p>
<p>In recent years we have become more and more familiar with concepts such
</p>
<p>as Artificial Intelligence (AI) and Machine Learning (ML). These fields share
</p>
<p>roots with these cognitive modeling efforts. It has also been more recently
</p>
<p>acknowledged that cognitive models can combine symbolic and sub-symbolic
</p>
<p>processes&ndash;such as neural net modeling, for example. These hybrid models allow us
</p>
<p>to consider the characteristics and constraints of the brain&rsquo;s architecture of neurons
</p>
<p>and how the neural underpinnings of cognition impact cognitive processes
</p>
<p>(Busemeyer and Dieterich 2010) on both a symbolic and sub-symbolic and also an
</p>
<p>emergence level.
</p>
<p>In the first part of the book we introduce several ideas and theories about the
</p>
<p>way that people behave. These ideas and theories are all encapsulated in cognitive
</p>
<p>architectures like ACT- R (Anderson 1993, 2007; Anderson et al. 2004) and Soar
</p>
<p>(Laird 2012; Newell 1990). There are still active research communities for both of
</p>
<p>these architectures. We introduced ACT-R in Chap. 1 and return to use it to help
</p>
<p>summarize design relevant user characteristics in Chap. 14.
</p>
<p>2.2.4 User-Centered and Human-Centered Design
</p>
<p>Through the 1980s, user-centered design (UCD, Norman and Draper 1986) came
</p>
<p>to the fore. User-centered design involves focusing on the user&rsquo;s needs, carrying
</p>
<p>out an activity/task analysis as well as a general requirements analysis, carrying
</p>
<p>out early testing and evaluation, and designing iteratively. As in the systems
</p>
<p>approach, this has a broader focus than the other approaches, but here there is a
</p>
<p>greater emphasis on the user and less of a focus on formal methods for require-
</p>
<p>ments gathering and specification, and a move from linear, rigid design processes
</p>
<p>to a more flexible iterative design methodology.
</p>
<p>A related movement, Human-Centered Design (HCD), expanded the focus from
</p>
<p>the user in interaction with the system to considering how human capabilities and
</p>
<p>characteristics are affected by the system beyond direct interaction with the
</p>
<p>interface or system itself. Humans should be seen as the most important element of
</p>
<p>information systems and should be designed in. The people context of information
</p>
<p>systems must be studied and understood. In more recent work, dimensions such as
</p>
<p>gender, race, class, and power are also being explicitly considered with respect to
</p>
<p>people&rsquo;s interactions with interactive technologies.
</p>
<p>This sensibility surfaces in three ways. First, consideration is given to the fact
</p>
<p>that the introduction of a new system engenders changes in the organization of
</p>
<p>2.2 Influential and Related Research Fields 43</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11">http://dx.doi.org/10.1007/978-1-4471-5134-0_11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1">http://dx.doi.org/10.1007/978-1-4471-5134-0_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1">http://dx.doi.org/10.1007/978-1-4471-5134-0_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14">http://dx.doi.org/10.1007/978-1-4471-5134-0_14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14">http://dx.doi.org/10.1007/978-1-4471-5134-0_14</a></div>
</div>
<div class="page"><p/>
<p>peoples&rsquo; behaviors and activities&mdash;that is in how people do things. These behav-
</p>
<p>ioral changes also affect others. So, user needs and demands, situational effects,
</p>
<p>and technological requirements are considered in tandem. The boundaries between
</p>
<p>which issues are defined as technical and which are organizational or social are
</p>
<p>considered to be malleable, not fixed, and need to be negotiated. This kind of
</p>
<p>approach is also prevalent in socio-technical systems design, described above.
</p>
<p>Second, human-centered design addresses the fact that more and more systems
</p>
<p>are being built where users do not interact directly with the technology as &lsquo;&lsquo;users.&rsquo;&rsquo;
</p>
<p>Examples may be telecare assistive technologies&mdash;bed sensors which are pro-
</p>
<p>grammed to track automatically when a person gets out of bed and to raise an
</p>
<p>alarm if they are not back in bed within a programmed time limit.
</p>
<p>Finally, human-centered design tends to look to the longer-term effects, as well
</p>
<p>as the immediate, task-related issues that occur at human-system &lsquo;&lsquo;touchpoint&rsquo;&rsquo;
</p>
<p>moments. New applications of technology should be seen as the development of
</p>
<p>permanent support systems and not one-off products that are complete once
</p>
<p>implemented and deployed. In other words, the way in which technological change
</p>
<p>alters the organization of activities, and what are likely ongoing interventions,
</p>
<p>need to be considered.
</p>
<p>User-centered (and human-centered) design methods tend to emphasize user
</p>
<p>participation in the design process for ideation and evaluation of design options. In
</p>
<p>this book, we have adopted the user-centered perspective, but we do not focus on
</p>
<p>the interaction with the interface; our intention is to broaden the scope of analysis
</p>
<p>to the user + technology system in the task context. Hence we have adopted the
</p>
<p>term &lsquo;&lsquo;user-centered system design&rsquo;&rsquo;.
</p>
<p>2.2.5 User Experience
</p>
<p>User experience has been described as &lsquo;&lsquo;a person&rsquo;s perceptions and responses that
</p>
<p>result from the use or anticipated use of a product, system, or service&rsquo;&rsquo; (ISO 9241-
</p>
<p>210). According to this definition, user experience goes beyond interface design to
</p>
<p>address a person&rsquo;s emotions, beliefs, preferences, perceptions, physical and psy-
</p>
<p>chological responses, behaviors, and accomplishments that occur before, during,
</p>
<p>and after use. Three factors that influence user experience are considered&mdash;the
</p>
<p>system, the user and their characteristics, and the context of use of the technology
</p>
<p>or system. User experience is often used interchangeably with usability but there is
</p>
<p>clearly a different focus that is signaled: usability and usability engineering focus
</p>
<p>on task related aspects (getting the job done); user experience and experience
</p>
<p>design focus on and foreground the users&rsquo; feelings, emotions, values, and their
</p>
<p>immediate and delayed responses.
</p>
<p>44 2 User-Centered Systems Design: A Brief History</p>
<p/>
</div>
<div class="page"><p/>
<p>2.2.6 Human&ndash;Computer Interaction
</p>
<p>Human&ndash;computer interaction (HCI) is the study of interaction between people
</p>
<p>(user) and computers. Although often confused with interface design, the remit of
</p>
<p>HCI is considerably broader. Further, while HCI draws insights from the foun-
</p>
<p>dations of interfaces design (design sciences and graphics), the roots of HCI lie in
</p>
<p>the social sciences.
</p>
<p>The Association for Computing Machinery (ACM), the major professional
</p>
<p>association for computer science, has a subgroup, a special interest group (SIG) on
</p>
<p>Computer&ndash;Human Interaction (full name SIGCHI). SIGCHI was fundamental in
</p>
<p>creating, nurturing, and defining HCI as a field. There are a number of excellent
</p>
<p>texts that summarize the history and current activities in HCI that are shown
</p>
<p>below. SIGCHI (Hewett et al. 1996) defined HCI as:
</p>
<p>&hellip; a discipline concerned with the design, evaluation and implementation of interactive
computing systems for human use and with the study of major phenomena surrounding them.
</p>
<p>It is worth noting that HCI as a field is constantly changing in response to
</p>
<p>technological innovations and consequent emerging user needs and demands, and
</p>
<p>this response is also updated in the ACM&rsquo;s recommended curriculum where HCI is
</p>
<p>a core area of computer science (http://www.acm.org//education/curricula/
</p>
<p>ComputerScience2008.pdf).
</p>
<p>In 2006, Suzanne B&oslash;dker (2006) outlined three &lsquo;&lsquo;waves&rsquo;&rsquo; in the development of
</p>
<p>HCI as a field. The first wave drew insights from cognitive theory and human
</p>
<p>factors predominantly (see also Bannon 1991). We believe this perspective is still
</p>
<p>relevant while the perspectives of the second and third waves broaden HCI&rsquo;s remit,
</p>
<p>increasing its influence. The second wave that developed through the late 1980s
</p>
<p>into the early 2000s focused on groups working with collections of applications,
</p>
<p>drawing on theories of &lsquo;&lsquo;situated action,&rsquo;&rsquo; &lsquo;&lsquo;distributed cognition,&rsquo;&rsquo; and &lsquo;&lsquo;activity
</p>
<p>theory.&rsquo;&rsquo; Scholars wrestled with how to capture the effects of context on activity.
</p>
<p>B&oslash;dker suggests that at this point &lsquo;&lsquo;rigid guidelines, formal methods, and sys-
</p>
<p>tematic testing&rsquo;&rsquo; were no longer the central focus as HCI researchers and practi-
</p>
<p>tioners moved to &lsquo;&lsquo;proactive methods such as a variety of participatory design
</p>
<p>workshops, prototyping, and contextual inquiries&hellip;&rsquo;&rsquo;. Finally, the third wave of
</p>
<p>HCI acknowledges that computers are increasingly being used in private and
</p>
<p>public spheres, moving out of workplace contexts and into everyday life for &lsquo;&lsquo;non-
</p>
<p>work, non-purpose, and non-rational&rsquo;&rsquo; uses. This third wave necessarily addresses
</p>
<p>the &lsquo;&lsquo;expansion of the cognitive&rsquo;&rsquo; to include emotional and esthetic aspects of
</p>
<p>experience, but also the pragmatic and cultural-historical.
</p>
<p>A recent report summarizes current and future teaching inHCI and documents some
</p>
<p>of the changes that have occurred in the field since its beginnings in the early 1980s
</p>
<p>(Churchill et al. 2013). It is also worth noting that the role and involvement of the HCI
</p>
<p>2.2 Influential and Related Research Fields 45</p>
<p/>
<div class="annotation"><a href="http://www.acm.org//education/curricula/ComputerScience2008.pdf">http://www.acm.org//education/curricula/ComputerScience2008.pdf</a></div>
<div class="annotation"><a href="http://www.acm.org//education/curricula/ComputerScience2008.pdf">http://www.acm.org//education/curricula/ComputerScience2008.pdf</a></div>
</div>
<div class="page"><p/>
<p>expert varies in design. The nature and level of involvement depends on the ethos of the
</p>
<p>design setting (the relative importance of usability issues and the degree of focus on
</p>
<p>supporting the user). We will deal with more HCI research in upcoming chapters.
</p>
<p>2.3 Standards, Principles, and Guidelines
</p>
<p>All of the disciplines mentioned above have a goal of answering specific research
</p>
<p>questions using experimental and observational methods. For example a research
</p>
<p>project may ask:
</p>
<p>&bull; Is this chair comfortable over an 8 h working day?
</p>
<p>&bull; Can the user get their task done with this application?
</p>
<p>&bull; Is the font used in this interface readable?
</p>
<p>&bull; Have we made the most important information in this interface stand out?
</p>
<p>&bull; Is this interface esthetically appealing to the user demographic I am interested
</p>
<p>in?
</p>
<p>&bull; Will the user get the information they need in a timely fashion if there is an
</p>
<p>emergency?
</p>
<p>It is not always possible to carry out this research to answer questions of this
</p>
<p>sort oneself, so researchers turn to lessons learned from previous studies that are
</p>
<p>codified as standards, principles, and guidelines that can be applied to the problem
</p>
<p>situations they encounter.
</p>
<p>Formal standards are generated by experts. They are intended to capture the
</p>
<p>agreed-upon wisdom and best practices of the field. Once created, they offer a
</p>
<p>common vocabulary for designers/developers and, ideally, result in systems that
</p>
<p>are more consistent for users, more easily inter-operable, and easier to integrate. In
</p>
<p>the design world, standards tend to be concerned with human adaptability and
</p>
<p>human variability. They are prescriptions for safe, acceptable designs, detailing the
</p>
<p>limits outside which the user may suffer from stress, and accidents may be caused.
</p>
<p>Standards are and can become part of the law. For example, British Standard BS
</p>
<p>5330 deals with the relationship between sound levels in the workplace and the
</p>
<p>incidence of hearing loss.
</p>
<p>Principles are prescriptive and specify general theoretical ideas that can underpin
</p>
<p>design decisions. They do not specify the limits of human capabilities like standards
</p>
<p>do and tend to be more general than guidelines. (Note that although we make this
</p>
<p>distinction between guidelines and principles, the ergonomics literature generally
</p>
<p>does not.) Ideally, such principles are encapsulations of theoretical insights that have
</p>
<p>been derived from extensive data gathering and testing. For example, Norman
</p>
<p>(1988, 2013) outlines a set of principles that designers should consider, e.g., making
</p>
<p>things visible and providing feedback. Norman&rsquo;s principles are based on his theory of
</p>
<p>action and interaction (noted further in Chap. 12). In particular, he emphasizes that
</p>
<p>the state of the system should be visible, that feedback on user&rsquo;s actions should be
</p>
<p>46 2 User-Centered Systems Design: A Brief History</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12">http://dx.doi.org/10.1007/978-1-4471-5134-0_12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12">http://dx.doi.org/10.1007/978-1-4471-5134-0_12</a></div>
</div>
<div class="page"><p/>
<p>provided, and that the system should be consistent across its subsystems. Similarly,
</p>
<p>Hedge (2003) offers the principles shown in Table 2.1.
</p>
<p>Guidelines are prescriptive and offer some general guidance for making design
</p>
<p>decisions. They tend to bemore specific than principles, but still relate existing theory
</p>
<p>and knowledge to either new design or established design problems (e.g., Brown
</p>
<p>1988; Mosier and Smith 1986; or the Apple design guidelines, available online).
</p>
<p>Belowwe offer a number of principles and guidelines that we have found useful in our
</p>
<p>own work. In designing and evaluating systems we ask questions about the design&rsquo;s
</p>
<p>functionality, usability, learnability, efficiency, reliability, maintainability, and utility
</p>
<p>or usefulness. These are all discussed below.
</p>
<p>(1) Functionality, what something does, is often the first thing to be considered
</p>
<p>while consideration of usability issues is sometimes tacked on at the end of
</p>
<p>development. This can lead to poorly designed artifacts that are hard to use but that
</p>
<p>offer new functionality. Sometimes this is enough. Sometimes it is not. Often, with
</p>
<p>more thoughtful design, one can have both (Pew and Mavor 2007).
</p>
<p>(2) Usability is a complex concept that can be defined in several ways. For
</p>
<p>example, Ravden and Johnson (1989) specify the following as all relevant to an
</p>
<p>assessment of whether a system or technology is usable or not:
</p>
<p>Visual clarity
</p>
<p>Consistency
</p>
<p>Informative feedback
</p>
<p>Explicitness
</p>
<p>Appropriate functionality
</p>
<p>Flexibility and control
</p>
<p>Error prevention and control
</p>
<p>User guidance and support.
</p>
<p>Eason (1984) offers the following definition of usability: the &lsquo;&lsquo;major indicator of
</p>
<p>usability is whether a system or facility is used.&rsquo;&rsquo; However, this is patently not the
</p>
<p>case as many devices that are used are hard to use. More usefully, Eason notes that
</p>
<p>usability is not determined by just one or two constituents, but is influenced by a
</p>
<p>Table 2.1 Principles for design to avoid exasperating users (Hedge 2003)
</p>
<p>&bull; Clearly define the system goals and identify potential undesirable system states
</p>
<p>&bull; Provide the user with appropriate procedural information at all times
</p>
<p>&bull; Do not provide the user with false, misleading, or incomplete information at any time
</p>
<p>&bull; Know thy user
</p>
<p>&bull; Build redundancy into the system
</p>
<p>&bull; Ensure that critical system conditions are recoverable
</p>
<p>&bull; Provide multiple possibilities for workarounds
</p>
<p>&bull; Ensure that critical systems personnel are fully trained
</p>
<p>&bull; Provide system users with all of the necessary tools
</p>
<p>&bull; Identify and eliminate system &lsquo;&lsquo;Gotchas!&rsquo;&rsquo;
</p>
<p>2.3 Standards, Principles, and Guidelines 47</p>
<p/>
</div>
<div class="page"><p/>
<p>number of factors. These factors do not simply and directly affect usability, but
</p>
<p>interact with one another in sometimes complex ways. He focuses on three ele-
</p>
<p>ments in particular that need to be taken account of explicitly: system function-
</p>
<p>task match, task characteristics, and user characteristics. Eason argues that these
</p>
<p>are independent variables that lead to changes in user reaction and scope of use
</p>
<p>that could be restricted, partial, distant, or constant.
</p>
<p>In 1991 the ETSI (European Telecommunications Standards Institute) proposed
</p>
<p>two kinds of usability dimensions, those linked to performance and those related to
</p>
<p>attitude, where performance is measured objectively and attitude represents sub-
</p>
<p>jective dimensions (see http://www.etsi.org).
</p>
<p>Although Shackel (1991) maintains the distinction between performance and
</p>
<p>attitudinal dimensions, he defines four distinguishable and quantifiable dimensions
</p>
<p>which can assume varying degrees of importance in different systems: effective-
</p>
<p>ness, learnability, flexibility, and attitude. These dimensions are not mutually
</p>
<p>exclusive in the sense that measures of effectiveness, for example, can at the same
</p>
<p>time also give some indication of system learnability. However, they provide a
</p>
<p>good starting point.
</p>
<p>Finally, Booth (1989) says that usability is usefulness, effectiveness, ease of
</p>
<p>use, learnability, attitude, and likeability. A useful system is one that helps users
</p>
<p>achieve their goals. This more pragmatic approach is also taken by the Interna-
</p>
<p>tional Standards Organisation (ISO) in their 9241 series of standards: &lsquo;&lsquo;the
</p>
<p>usability of a product is the degree to which specific users can achieve specific
</p>
<p>goals within a particular environment; effectively, efficiently, comfortably, and in
</p>
<p>an acceptable manner.&rsquo;&rsquo;
</p>
<p>(3) Learnability is how easy the system is to learn. This is affected by a number
</p>
<p>of factors: for example, how complex it is, how well the system behaviors are
</p>
<p>signaled in the form of feedback, how consistently the system behaves, how mode
</p>
<p>changes which may lead to different kinds of behavior are signaled to the user, and
</p>
<p>so on. Learnability can also be affected by how well the system is documented,
</p>
<p>either formally (though instructions) or informally through the availability of other
</p>
<p>users who may be more expert and can help the novice learner.
</p>
<p>Learnability is also affected by how similar the new system is to other systems
</p>
<p>that the users know, because there may be transfer of knowledge from previous
</p>
<p>system use. How similar it is to previous systems not known to the user can also be
</p>
<p>important because, if there are other users, they may be able to help novices with
</p>
<p>new systems if the new systems are similar to previous systems, and existing
</p>
<p>consultants and teachers may be available if the systems are similar.
</p>
<p>(4) Efficiency of a system can be measured through the use of resources such as
</p>
<p>processor time, memory, network access, system facilities, disk space, and so on.
</p>
<p>Programmers tend to focus mostly on efficiency, because it ensures that systems
</p>
<p>work fast and do not frustrate users by keeping them waiting. Note that this is a
</p>
<p>computer not a human centric view of efficiency. It is a relative concept in that one
</p>
<p>system can be evaluated as more efficient than another in terms of some parameter
</p>
<p>such as processor use, but there is no absolute scale on which to specify an
</p>
<p>optimum efficiency with regard to people&rsquo;s experience of a system when carrying
</p>
<p>48 2 User-Centered Systems Design: A Brief History</p>
<p/>
<div class="annotation"><a href="http://www.etsi.org">http://www.etsi.org</a></div>
</div>
<div class="page"><p/>
<p>out a task. Optimum efficiency from a human-centric perspective requires con-
</p>
<p>sideration of the task, the task-context, and the characteristics of the users. One
</p>
<p>needs to consider the users&rsquo; knowledge level and disposition, including their
</p>
<p>motivation. It is also important not to confuse efficiency with speed of execution;
</p>
<p>speed may be important, or it may also be ultimately inefficient.
</p>
<p>In the early days of computers, when programs were small and computer time
</p>
<p>was relatively expensive, efficiency of computer time was considered to be of
</p>
<p>paramount importance, and it probably was. With today&rsquo;s faster machines,
</p>
<p>designers need to consider the effects of choices upon all resources and the con-
</p>
<p>sequences of different kinds of efficiency. For example, when considering Internet
</p>
<p>sites, slow download times are an efficiency issue caused by site/application design
</p>
<p>and connectivity bandwidth. Users can get frustrated if they are in a hurry to
</p>
<p>complete a transaction. However, the opposite also occurs&mdash;when a transaction is
</p>
<p>too efficient, users can get disoriented and dissatisfied (e.g., one-click payments
</p>
<p>without asking the user to review orders before placement). Thus efficiency must
</p>
<p>be calculated in terms of technical efficiency that matches user efficiency expec-
</p>
<p>tations for the task at hand.
</p>
<p>(5) Reliability is concerned with the dynamic properties of the eventual system
</p>
<p>and involves the designer making predictions about behavioral issues. We need to
</p>
<p>know whether the system is going to be complete (in the sense that it will be able
</p>
<p>to handle all combinations of events and system states), consistent (in that its
</p>
<p>behavior will be as expected and will be repeatable, regardless of the overall
</p>
<p>system loading at any time, and across components of the system), and robust
</p>
<p>(when faced with component failure or some similar conflict, for example, if the
</p>
<p>printer used for logging data in a chemical process-control plant fails for some
</p>
<p>reason, the whole system should not crash, but should instead follow a policy of
</p>
<p>graceful degradation).
</p>
<p>As systems get larger the problems of ensuring reliability escalate. For safety
</p>
<p>critical systems where this factor is most important, various techniques have been
</p>
<p>developed to help overcome limitations in design and implementation techniques.
</p>
<p>For example, in a system used in a fly-by-wire aircraft in which the control
</p>
<p>surfaces are managed by computer links rather than by direct hydraulic controls,
</p>
<p>the implementation will be by means of multiple computers, with a strong like-
</p>
<p>lihood that each will have been programmed by a separate development team and
</p>
<p>tested independently. Any operational request to the control system will then be
</p>
<p>processed in parallel by all the computers and only if they concur with the
</p>
<p>requested operation will it be carried out.
</p>
<p>(6) Maintainability is how easy a system is to maintain and upgrade. As
</p>
<p>systems get larger and more costly, the need for a life-long time in service
</p>
<p>increases in parallel. To help achieve this, designs must allow for future modifi-
</p>
<p>cation. Designers need to provide future maintainers with mental models of the
</p>
<p>system and the design rationale so that future maintainers can gain a clear
</p>
<p>understanding of the system and how it is put together (Haynes et al. 2009).
</p>
<p>Development of modular designs helps, but larger systems present further prob-
</p>
<p>lems. While small systems can be modeled with a structural model (i.e., laying out
</p>
<p>2.3 Standards, Principles, and Guidelines 49</p>
<p/>
</div>
<div class="page"><p/>
<p>the component parts of the system), as systems get larger it is important to develop
</p>
<p>functional models that simulate what the component parts do themselves and in
</p>
<p>interaction with each other.
</p>
<p>(7) Utility/Usefulness is an important concept always to consider when
</p>
<p>designing systems. Is it ultimately useful for users and how long is its likely
</p>
<p>usefulness? Is this something that will become an everyday system or an infre-
</p>
<p>quently used system? When it is used, how useful do users find it or are there other
</p>
<p>workaround that users would rather engage with? Usefulness can be measured
</p>
<p>both in terms of how often and in what way something is used, but can also be
</p>
<p>measured with subjective scales like &lsquo;how much do you like this?&rsquo; People may find
</p>
<p>something useful because it makes them feel good about themselves rather than
</p>
<p>because it is an efficient, reliable system with a highly usable interface from our
</p>
<p>perspective as designers.
</p>
<p>2.4 Summary
</p>
<p>In this chapter we have provided an overview of research areas that have con-
</p>
<p>tributed to our understanding of user-centered design. User-centered design draws
</p>
<p>on multiple sources of knowledge to support creating systems that are based on
</p>
<p>users&rsquo; abilities, capabilities, and task. What all these approaches have in common
</p>
<p>is the perspective that when designing we need to consider variation and similarity
</p>
<p>in the contexts, people, and tasks that characterize different design situations and
</p>
<p>settings. A one-size-fits-all approach seldom works to achieve the most productive,
</p>
<p>safe, and enjoyable design solution. We summarize this perspective by inviting
</p>
<p>you to remember that design is about considering particular people doing par-
</p>
<p>ticular tasks in a particular context&mdash;our focus in this book is people doing tasks
</p>
<p>using technologies, but this perspective can be more generally applied.
</p>
<p>It is worth highlighting at this point that, in order to comply with ISO standard
</p>
<p>9241-210 (which now refers to Human-Centered Design, rather than User-Cen-
</p>
<p>tered), the following four activities are now requirements (previously they were
</p>
<p>recommendations):
</p>
<p>1. Understanding and specifying the context of use (including users, tasks,
</p>
<p>environments)
</p>
<p>2. Specifying the user requirements in sufficient detail to drive the design
</p>
<p>3. Producing design solutions that meet these requirements
</p>
<p>4. Conducting user-centered evaluations of these design solutions and modifying
</p>
<p>the design to take into account the results.
</p>
<p>Our aim in this book is to provide you with the foundations that will help you to
</p>
<p>meet these requirements. In the first part of the book we focus on the capabilities of
</p>
<p>users. We categorize these capabilities into anthropometric, behavioral, cognitive,
</p>
<p>and social aspects. Although we separate issues into these categories, we
</p>
<p>50 2 User-Centered Systems Design: A Brief History</p>
<p/>
</div>
<div class="page"><p/>
<p>acknowledge that the boundaries between them are somewhat blurred: our bodies
</p>
<p>affect how we act, and our behaviors affect how we participate socially. Thus, all
</p>
<p>these factors interact. A key skill for effective human-centered system design is to
</p>
<p>understand which factors are central or primary in any design situation and which
</p>
<p>are peripheral or secondary.
</p>
<p>In the latter part of the book we provide introductions to some methods that can
</p>
<p>be used to guide design and evaluation. These include task analysis, evaluation
</p>
<p>methods, and the notation of cognitive dimensions. These methods differ in terms
</p>
<p>of their preferred unit of analysis, the kinds of data collected, and the analyses that
</p>
<p>are conducted. We finish the book by providing a framework that will allow you to
</p>
<p>integrate your knowledge of the user with the methods in a systematic way.
</p>
<p>2.5 Other Resources
</p>
<p>There are a lot of helpful texts that can give you some background to the field of
</p>
<p>user-centered system design. Some of the texts that we have cited above are
</p>
<p>particularly helpful. For more on the history of this field read this book:
</p>
<p>Shachtman, T. (2002). Laboratory warriors: How Allied science and technology tipped the
balance in World War II. New York, NY: HarperCollins.
</p>
<p>A classic text that laid many of the basics out for the field of user-centered
</p>
<p>systems design is Don Norman and Steve Draper&rsquo;s 1986 text:
</p>
<p>Norman, D. A., &amp; Draper, S. W. (Eds) (1986). User centered system design: New
Perspectives on human&ndash;computer interaction. Hillsdale, NJ: Erlbaum.
</p>
<p>Jack Carroll&rsquo;s summary of Human Computer Interaction in the Encyclopedia of
</p>
<p>Human Computer Interaction is a great place to start if you want an overview:
</p>
<p>Carroll, J. M. (2009). Human computer interaction (HCI). In Encyclopedia of Human&ndash;
Computer Interaction. M. Soegaard &amp; R. F. Dam (Eds.). Aarhus, Denmark: The Inter-
action Design Foundation.
</p>
<p>Two good textbook style overviews are:
</p>
<p>Sharp, H., Rogers, Y., &amp; Preece, J. (2011). Interaction design: Beyond human&ndash;computer
interaction (3rd ed.). Chichester, UK: John Wiley and Sons Ltd.
</p>
<p>Shneiderman, B., &amp; Plaisant, C. (2009). Designing the user interface: Strategies for
effective human&ndash;computer interaction (5th ed.). Reading, MA: Addison Wesley.
</p>
<p>One of the best introductions to the practice, the how-to&rsquo;s, of user-centered design
</p>
<p>is by Elizabeth Goodman, Mike Kuniavsky, and Andrea Moed. They cover basic
</p>
<p>techniques and methods that will help you design better interactions. They also offer
</p>
<p>case studies and examples that you can compare to your own design situations:
</p>
<p>Goodman, E., Kuniavsky, M., &amp; Moed, A. (2012). Observing the user experience:
A practitioner&rsquo;s guide to user research. San Francisco, CA: Morgan Kaufman
</p>
<p>2.4 Summary 51</p>
<p/>
</div>
<div class="page"><p/>
<p>For more formal methods and models of interaction programming, read Harold
</p>
<p>Thimbleby&rsquo;s text Press On:
</p>
<p>Thimbleby, H. (2007). Press on&mdash;Principles of interaction programming. Cambridge,
MA: MIT Press.
</p>
<p>If you want to know more about field based and participatory requirements
</p>
<p>gathering, a well known method is Contextual Design. This is described in this text:
</p>
<p>Beyer, H., &amp; Holtzblatt, K. (1997) Contextual design: Defining customer-centered sys-
tems. San Francisco, CA: Morgan Kaufmann.
</p>
<p>Finally, cognitive modeling can offer enormous gains when you are thinking
</p>
<p>about how users think. An excellent introduction to this area of research and
</p>
<p>application is:
</p>
<p>Gray, W. D. (Ed.). (2007). Integrated models of cognitive systems. New York: Oxford
University Press.
</p>
<p>2.6 Exercises
</p>
<p>2.1 Consider a smartphone, either a specific one or a composite one, and consider
</p>
<p>the human factors of using it. What are the issues that each field of HCI,
</p>
<p>human factors, and cognitive ergonomics address?
</p>
<p>Write short notes (about one side of a page in total) noting the issues on
</p>
<p>these three types of analyses.
</p>
<p>2.2 Pick a company&rsquo;s web site or a university department&rsquo;s web site. Summarize
</p>
<p>in note form how each of the major fields noted in this chapter would analyze
</p>
<p>it and its users. Note what would be the outputs and typical recommendations.
</p>
<p>Which approach would you prefer to apply to the web site you choose? Note
</p>
<p>the relative value and the absolute value of each. That is, which gives the best
</p>
<p>results for the amount of inputs, and which gives the best value without regard
</p>
<p>to cost?
</p>
<p>2.3 When you go home tonight, take a look at your kitchen. Look at all the displays
</p>
<p>in the kitchen and summarize what information they contain and when you
</p>
<p>would use that information. Look at the layout of the kitchen and think about
</p>
<p>whether things are placed in the most convenient place to make your move-
</p>
<p>ments through the kitchen when you are cooking as efficiently as possible.
</p>
<p>Make your favorite snack and draw a picture of how you move through the
</p>
<p>kitchen. Note how the kitchen can be improved based on your analysis,
</p>
<p>including both no-cost and expensive changes. This exercise is designed to
</p>
<p>make you think more deeply about the physical, cognitive, behavioral, and
</p>
<p>information issues that go into how optimized your kitchen is for you to use.
</p>
<p>2.4 Analyze Hedge&rsquo;s (2003) set of design principles in Table 2.1. These principles
</p>
<p>arose out of installing a popular operating system.
</p>
<p>52 2 User-Centered Systems Design: A Brief History</p>
<p/>
</div>
<div class="page"><p/>
<p>(1) For each principle, note the support it has in general, when it would be
</p>
<p>true, and exceptions where it would not be true.
</p>
<p>(2) Comment on the usefulness and usability of the principles as a set.
</p>
<p>(3) Compare these principles with another set of HCI design principles that
</p>
<p>you find (and note and reference).
</p>
<p>References
</p>
<p>Anderson, J. R. (1993). Rules of the mind. Hillsdale, NJ: Erlbaum.
Anderson, J. R. (2007). How can the human mind exist in the physical universe?. New York, NY:
</p>
<p>Oxford University Press.
Anderson, J. R., Bothell, D., Byrne, M. D., Douglass, S., Lebiere, C., &amp; Qin, Y. (2004). An
</p>
<p>integrated theory of the mind. Psychological Review, 111(4), 1036&ndash;1060.
Avgerou, C., Ciborra, C., &amp; Land, F. (2004). The social study of information and communication
</p>
<p>technology. Oxford, UK: Oxford University Press.
Bannon, L. (1991). From human factors to human actors: The role of psychology and human&ndash;
</p>
<p>computer interaction studies in systems design. In J. Greenbaum &amp; M. Kyng (Eds.), Design at
work: Cooperative design of computer systems (Vol. 25&ndash;44). Hillsdale, NJ: Erlbaum.
</p>
<p>Barker, V. E., &amp; O&rsquo;Connor, D. E. (1989). Expert systems for configuration at Digital: XCON and
beyond. Communications of the ACM, 32(3), 298&ndash;318.
</p>
<p>Baxter, G., &amp; Sommerville, I. (2011). Socio-technical systems: From design methods to
engineering. Interacting with Computers, 23(1), 4&ndash;17.
</p>
<p>Berg, M. (1999). Patient care information systems and healthcare work: A sociotechnical
approach. International Journal of Medical Informatics, 55(2), 87&ndash;101.
</p>
<p>Berg, M. (2001). Implementing information systems in health care organizations: Myths and
challenges. International Journal of Medical Informatics, 64(2&ndash;3), 143&ndash;156.
</p>
<p>Berg, M., &amp; Toussaint, P. (2003). The mantra of modelling and the forgotten powers of paper: A
sociotechnical view on the development of process-oriented ICT in health care. International
Journal of Medical Informatics, 69(2&ndash;3), 223&ndash;234.
</p>
<p>B&oslash;dker, S. (2006). When second wave HCI meets third wave challenges. In A. M&oslash;rch,
K. Morgan, T. Bratteteig, G. Ghosh, &amp; D. Svanaes (Ed.), NordiCHI Nordic Conference on
Human-Computer Interaction October 14&ndash;18, (pp. 1&ndash;8). Oslo, Norway.
</p>
<p>Booth, P. (1989). An introduction to human-computer interaction. Hove, UK: Erlbaum.
Brown, C. M. L. (1988). Human-computer interface design guidelines. Norwood, NJ: Ablex.
Busemeyer, J. R., &amp; Dieterich, A. (2010). Cognitive modeling. Thousand Oaks, CA: Sage
</p>
<p>Publications.
Card, S. K., Moran, T., &amp; Newell, A. (1983). The psychology of human-computer interaction.
</p>
<p>Hillsdale, NJ: Erlbaum.
Cherns, A. (1987). Principles of socio-technical design revisited. Human Relations, 40(3),
</p>
<p>153&ndash;162.
Churchill, E., Bowser, A., &amp; Preece, J. (2013). Teaching and learning human-computer
</p>
<p>interaction: Past, present, and future. Interactions, 20(2), 44&ndash;53.
Clegg, C. (2000). Sociotechnical principles for system design. Applied Ergonomics, 31, 463&ndash;477.
Eason, K. (1984). Towards the experimental study of usability. Behaviour and Information
</p>
<p>Technology, 3(2), 133&ndash;143.
Emery, F. E., &amp; Trist, E. L. (1960). Socio-technical systems. In C. W. Churchman &amp; M. Verhulst
</p>
<p>(Eds.), Management science models and techniques (Vol. 2, pp. 83&ndash;97). Oxford, UK:
Pergamon.
</p>
<p>2.6 Exercises 53</p>
<p/>
</div>
<div class="page"><p/>
<p>Haynes, S. R., Cohen, M. A., &amp; Ritter, F. E. (2009). Designs for explaining intelligent agents.
International Journal of Human-Computer Studies, 67(1), 99&ndash;110.
</p>
<p>Hedge, A. (2003). 10 principles to avoid XP-asperation. Ergonomics in Design, 11(3), 4&ndash;9.
Hewett, T. T., Baecker, R., Card, S., Carey, T., Gasen, J., Mantei, M., et al. (1996). ACM SIGCHI
</p>
<p>curricula for human-computer interaction. New York, NY: Association for Computing
Machinery. http://sigchi.org/cdg/index.html
</p>
<p>Hollnagel, E., &amp; Woods, D. D. (1983). Cognitive systems engineering: New wine in new bottles.
International Journal of Man-Machine Studies, 18, 583&ndash;600.
</p>
<p>Hollnagel, E., &amp; Woods, D. D. (2005). Joint cognitive systems: Foundations of cognitive systems
engineering. Boca Raton, FL: CRC Press.
</p>
<p>Holloway, W. (1991). Work psychology and organizational behaviour: Managing the individual
at work Thousand Oaks. CA: Sage.
</p>
<p>Laird, J. E. (2012). The Soar cognitive architecture. Cambridge, MA: MIT Press.
Mosier, J. N., &amp; Smith, S. L. (1986). Application of guidelines for designing user interface
</p>
<p>software. Behaviour and Information Technology, 5, 39&ndash;46.
Mumford, E. (1983). Designing human systems for new technology&mdash;The ETHICS method.
</p>
<p>Retrieved March 10, 2014, from http://www.enid.u-net.com/C1book1.htm
Mumford, E. (1995). Effective systems design and requirements analysis: The ETHICS method.
</p>
<p>Basingstoke, UK: Macmillan Press.
Mumford, E. (2006). The story of socio-technical design: reflections in its successes, failures and
</p>
<p>potential. Information Systems Journal, 16, 317&ndash;342.
Mumford, E., &amp; MacDonald, W. B. (1989). XSEL&rsquo;s progress: The continuing journey of an
</p>
<p>expert system. New York, NY: Wiley.
Newell, A. (1990). Unified theories of cognition. Cambridge, MA: Harvard University Press.
Newell, A., Shaw, J. C., &amp; Simon, H. A. (1960). Report on a general problem-solving program
</p>
<p>for a computer. In International Conference on Information Processing, (pp. 256&ndash;264).
UNESCO: Paris.
</p>
<p>Newell, A., &amp; Simon, H. A. (1972). Human problem solving. Englewood Cliffs, NJ: Prentice-
Hall.
</p>
<p>Nickerson, R. (1969). Man-Computer interaction: A challenge for human factors research.
Ergonomics, 12: 501&ndash;517. (Reprinted from IEEE Transactions on Man-Machine Systems,
10(4), 164&ndash;180).
</p>
<p>Norman, D. A., &amp; Draper, S. W. (Eds.). (1986). User centred system design. Hillsdale, NJ:
Erlbaum.
</p>
<p>Norman, D. A. (1988). The psychology of everyday things. New York, NY: Basic Books.
Norman, D. A. (2013). The design of everyday things. New York, NY: Basic Books.
Pew, R. W., &amp; Mavor, A. S. (Eds.). (2007). Human-system integration in the system development
</p>
<p>process: A new look. Washington, DC: National Academies Press. http://books.nap.edu/
catalog.php?record_id=11893. Accessed 10 March 2014.
</p>
<p>Ravden, S., &amp; Johnson, G. (1989). Evaluating usability of human-computer interfaces: A
practical method. Chichester, UK: Ellis Horwood.
</p>
<p>Reason, J. (1997). Managing the risks of organizational accidents. Aldershot, UK: Ashgate.
Shackel, B. (1991). Human factors for informatics usability book contents. In B. Shackel &amp; S.
</p>
<p>J. Richardson (Eds.), Usability&mdash;context, framework, definition, design and evaluation (pp.
21&ndash;37). New York, NY: Cambridge University Press.
</p>
<p>Swain, A. D., &amp; Guttman, H. E. (1983). A handbook of human reliability analysis with emphasis
on nuclear power applications. Washington, DC: US Nuclear Regulatory Commission.
</p>
<p>Whetton, S. (2005). Health informatics: A socio-technical perspective. South Melbourne,
Australia: Oxford University Press.
</p>
<p>Woods, D. D., &amp; Hollnagel, E. (2006). Joint cognitive systems: Patterns in cognitive systems
engineering. Boca Raton, FL: CRC Press.
</p>
<p>Young, R. M., Green, T. R. G., &amp; Simon, T. (1989). Programmable user models for predictive
evaluation of interface designs. In Proceedings of CHI&rsquo;89 Conference on Human Factors in
Computing Systems, (pp. 15&ndash;19). ACM Press: New York, NY.
</p>
<p>54 2 User-Centered Systems Design: A Brief History</p>
<p/>
<div class="annotation"><a href="http://sigchi.org/cdg/index.html">http://sigchi.org/cdg/index.html</a></div>
<div class="annotation"><a href="http://www.enid.u-net.com/C1book1.htm">http://www.enid.u-net.com/C1book1.htm</a></div>
<div class="annotation"><a href="http://books.nap.edu/catalog.php?record_id=11893">http://books.nap.edu/catalog.php?record_id=11893</a></div>
<div class="annotation"><a href="http://books.nap.edu/catalog.php?record_id=11893">http://books.nap.edu/catalog.php?record_id=11893</a></div>
</div>
<div class="page"><p/>
<p>Part II
</p>
<p>Design Relevant User Characteristics:
The ABCS</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 3
</p>
<p>Anthropometrics: Important Aspects
</p>
<p>of Users&rsquo; Bodies
</p>
<p>Abstract This chapter addresses factors that arise from basic characteristics of the
</p>
<p>human body. While bodies vary in their size, shape, capabilities, and limitations,
</p>
<p>there are some common factors that are shared and some general guidance that
</p>
<p>we can apply to design better interfaces and systems. This is a broad topic: the
</p>
<p>influence of bodies on usability applies to all systems, and is illustrated with
</p>
<p>examples from desktop, laptop, mobile, and handheld systems. After briefly pro-
</p>
<p>viding an overview of the issues involved, this chapter covers the importance of
</p>
<p>the physical setup for computers. We also introduce and discuss the importance of
</p>
<p>touch and tactile feedback, better known as haptic perception. Haptic perception
</p>
<p>has become increasingly important with the widespread uptake of touch screen
</p>
<p>devices and gaming interfaces. We illustrate the importance of haptic perception
</p>
<p>by considering how people interact with a wide range of devices and systems. The
</p>
<p>chapter concludes with some implications of the need to consider anthropometric
</p>
<p>factors when designing interactive systems.
</p>
<p>3.1 Introduction
</p>
<p>People have bodies. Human bodies have certain characteristics and capabilities:
</p>
<p>they take up space and are designed to move in certain ways. This means that the
</p>
<p>extent of our reach when static and our range of motion are limited. Human bodies
</p>
<p>are designed for certain kinds of movement&mdash;we crawl, walk, run, and reach for
</p>
<p>things. Thanks to a complex sensorimotor system, we can perceive and manipulate
</p>
<p>objects, and to issue and sense tactile feedback. Human bodies also need certain
</p>
<p>forms of nourishment and can become fatigued. Understanding the characteristics
</p>
<p>and capabilities of the human body can both inspire and constrain design options.
</p>
<p>Obviously, users need their bodies to interact with interfaces. In some cases the
</p>
<p>path from the user&rsquo;s intention to the desired action appears effortless and error free.
</p>
<p>These situations encourage us to forget the situations where the user is tired, the
</p>
<p>timing of the task is demanding, or the user has difficulty performing the required
</p>
<p>F. E. Ritter et al., Foundations for Designing User-Centered Systems,
DOI: 10.1007/978-1-4471-5134-0_3, ï¿½ Springer-Verlag London 2014
</p>
<p>57</p>
<p/>
</div>
<div class="page"><p/>
<p>physical actions. Designers of interfaces and of larger systems need to give
</p>
<p>appropriate consideration to the user&rsquo;s body in order to take advantage of its
</p>
<p>capabilities and to mitigate against the limitations and constraints it imposes. The
</p>
<p>size of the cockpit in a Formula 1 racing car, for example, is limited for obvious
</p>
<p>reasons. This restricts the things that the driver can physically reach to control the
</p>
<p>car. The steering wheel in Formula 1 cars (like that of the Caterham 2012 For-
</p>
<p>mula 1 car shown in Fig. 3.1) has therefore evolved into an interface that brings
</p>
<p>within easy reach all of the systems that drivers need to interact with.
</p>
<p>People vary and their physical dimensions and capabilities also vary. Figure 3.2,
</p>
<p>for example, shows a suit designed to mimic the effects of age when worn by
</p>
<p>younger people. The suit leads users to modify how they walk, how they look
</p>
<p>around the environment, and how they see. Similarly, the gloves and goggles in
</p>
<p>Fig. 3.3 can be used to mimic the effects of arthritis and poor vision, which will
</p>
<p>affect how people interact with computer technology.
</p>
<p>The appearance or structure of a physical object can suggest how it should be
</p>
<p>used, or support a particular use. These physical affordances&mdash;after Gibson
</p>
<p>(1979)&mdash;are useful, because they make it easier for people to determine how to use
</p>
<p>the object: handles on doors, for example, afford pulling. Some affordances build
</p>
<p>Fig. 3.1 The steering wheel
from the Caterham 2012
Formula 1 car. The wheel
contains multiple controls to
adjust traction, suspension,
and aerodynamics
(reproduced with permission
of Caterham F1 Team, UK)
</p>
<p>Fig. 3.2 Outfits designed to
reproduce the effects of age
on younger users (reproduced
with permission from Nathan
Fried-Lipski and the MIT
AgeLab)
</p>
<p>58 3 Anthropometrics: Important Aspects of Users&rsquo; Bodies</p>
<p/>
</div>
<div class="page"><p/>
<p>on existing knowledge&mdash;you learn to double click using a mouse button, for
</p>
<p>example&mdash;but the most powerful and primitive affordances support direct inter-
</p>
<p>action with the object. Norman&rsquo;s (1988, 2013) book provides many examples of
</p>
<p>useful affordances, as well as several that are confusing or even useless, such as
</p>
<p>putting a pull handle on a door that you have to push open!
</p>
<p>The objects in computer interfaces that can be manipulated (clicked, dragged,
</p>
<p>rotated, and so on) by the user should also provide appropriate affordances. This is
</p>
<p>why buttons, for example, should look like they need to be pressed (or clicked on)
</p>
<p>even if they appear on a flat surface. Similarly, the use of a hand icon as a mouse
</p>
<p>cursor in applications such as Adobe&rsquo;s Acrobat Reader is designed to afford the
</p>
<p>action of scrolling through a document on the display.
</p>
<p>3.2 Physical Aspects of Interaction
</p>
<p>There are twomain anthropometric issues that need to be consideredwhen designing
</p>
<p>interactive systems. The first relates to how the users will interact with the system:
</p>
<p>will they be sitting (which is still most prevalent) or standing (which is becoming
</p>
<p>more prevalent)? Note, however, that as computational artifacts are increasingly
</p>
<p>embedded in our physical environment, the repertoire of possible body positions is
</p>
<p>correspondingly increasing. The second, which is becoming increasingly important,
</p>
<p>relates to how much weight the user can carry and support if the device or artifact is
</p>
<p>intended to be carried by the user, as with mobile and portable devices.
</p>
<p>3.2.1 Posture
</p>
<p>The posture adopted by users when they interact with systems is important. If users
</p>
<p>adopt an incorrect posture or stay still too long, this can lead to performance
</p>
<p>Fig. 3.3 Easy to create modified gloves (they have wooden popsicle sticks in the fingers) and
goggles (with paint on them) that give the user restricted hand mobility and restricted vision
respectively
</p>
<p>3.1 Introduction 59</p>
<p/>
</div>
<div class="page"><p/>
<p>problems, such as reduced attention to the task over time, or an increase in the
</p>
<p>number of errors. It can also lead to health issues including eye-strain, back pain,
</p>
<p>and upper limb disorders (ULDs).
</p>
<p>ULDs are quite common. Many people who use display screen equipment
</p>
<p>suffer from ULDs. ULDs include conditions such as repetitive strain injuries (RSI),
</p>
<p>cumulative trauma disorder, and occupational overuse syndrome. Although most
</p>
<p>of these conditions are not indicative of any serious ill health, it makes sense to try
</p>
<p>to avoid them as far as possible.
</p>
<p>ULDs are aches, pains, tension, and disorders that involve any part of the arm
</p>
<p>from the fingers to the shoulder, or the neck. They include problems with the soft
</p>
<p>tissues, muscles, tendons, and ligaments, as well as with the circulatory and nerve
</p>
<p>supply to the limbs. ULDs are often caused or exacerbated by work and particu-
</p>
<p>larly repetitive work.
</p>
<p>There are several risk factors that contribute to the chance of suffering from
</p>
<p>ULDs. These include task-related aspects, such as uncomfortable working pos-
</p>
<p>tures, continuous use of excessive force, and long tasks. Other risk factors include
</p>
<p>organizational aspects, such as a poor working environment (lack of temperature
</p>
<p>regulation, poor lighting, and so on) and job demands, such as time pressures, and
</p>
<p>a lack of rest breaks or task rotation. There are suggestions that lack of control of
</p>
<p>one&rsquo;s time or task exacerbates the situation, encourages reporting of the problem,
</p>
<p>or helps accelerate the process. In addition, some people are more susceptible to
</p>
<p>some of these risks than other people. It is now a legal requirement in most
</p>
<p>countries to make sure that workstations are appropriately set up for people who
</p>
<p>regularly use such equipment for extended periods of time, as shown in Fig. 3.4. It
</p>
<p>is important to make sure that the keyboard is placed appropriately with respect to
</p>
<p>the hands and the wrists, that the display is positioned correctly, that the display is
</p>
<p>appropriately illuminated, and that the angle of the head, neck, back, hips, and feet
</p>
<p>when using the workstation are considered.
</p>
<p>The recommended sitting posture is to be more upright and avoid pressure on
</p>
<p>wrists, hands, and elbows. Posture will naturally change across tasks, however,
</p>
<p>with some people leaning forward to type on a touch screen device, for example,
</p>
<p>but leaning back to read from the screen of the same device. English and Andre
</p>
<p>(1999) identified several postures that should generally be avoided; some of the at-
</p>
<p>risk postures observed during web browsing are shown in Fig. 3.5.
</p>
<p>There are situations where people deliberately choose to ignore the risks,
</p>
<p>however. Hand-held game consoles, for example, include information about the
</p>
<p>potential risks of extended use in their instruction manuals. In spite of this, some
</p>
<p>people persist in playing games for excessive periods of time without a break, and
</p>
<p>often hunched over the console.
</p>
<p>It is most important to be aware of the risks and to take appropriate steps to
</p>
<p>mitigate the effects of these risks. The UK&rsquo;s Health and Safety Executive devel-
</p>
<p>oped the Assessment of Repetitive Tasks (ART) tool to help in this area. ART is
</p>
<p>designed to assist health and safety inspectors in assessing those repetitive tasks
</p>
<p>60 3 Anthropometrics: Important Aspects of Users&rsquo; Bodies</p>
<p/>
</div>
<div class="page"><p/>
<p>Feet flat on foor or supported
</p>
<p>0o
</p>
<p>15o
</p>
<p>30 o
</p>
<p>Position display 
</p>
<p>about arm's length and 
</p>
<p>with line of sight shown
</p>
<p>D
is
</p>
<p>p
la
</p>
<p>y
 s
</p>
<p>q
u
</p>
<p>a
re
</p>
<p> 
to
</p>
<p> l
in
</p>
<p>e
 o
</p>
<p>f 
v
is
</p>
<p>io
n
</p>
<p> 
a
n
</p>
<p>d
 t
</p>
<p>o
 a
</p>
<p>v
o
</p>
<p>id
 g
</p>
<p>la
re
</p>
<p>Arms and legs 90
o
</p>
<p>from your spine
</p>
<p>G
o
</p>
<p>o
d
</p>
<p> c
h
</p>
<p>a
ir
</p>
<p> w
it
</p>
<p>h
o
</p>
<p>u
t 
</p>
<p>p
re
</p>
<p>s
s
</p>
<p>u
re
</p>
<p> p
o
</p>
<p>in
ts
</p>
<p> o
n
</p>
<p> 
</p>
<p>b
a
</p>
<p>c
k
</p>
<p> o
f 
</p>
<p>th
ig
</p>
<p>h
s
</p>
<p> a
n
</p>
<p>d
 l
</p>
<p>u
m
</p>
<p>b
a
</p>
<p>r 
s
</p>
<p>u
p
</p>
<p>p
o
</p>
<p>rt
</p>
<p>Avoid glare,
</p>
<p>direct and indirect
</p>
<p>Support wrists 
</p>
<p>when not typing
</p>
<p>Wrists in line with forearm (not bent)
</p>
<p>Shoulders relaxed
</p>
<p>Do not hold phone 
</p>
<p>with shoulder
</p>
<p>No lip 
</p>
<p>on chair
</p>
<p>18-24 inches
</p>
<p>Fig. 3.4 Useful information about how to arrange a computer display and work area to avoid
wrist and upper limb disorders (ULDs). Contains public sector information published by the
Health and Safety Executive and licensed under the Open Government Licence v1.0
</p>
<p>Fig. 3.5 Postures to be avoided when web browsing. Placement of non-mousing (e.g., left)
elbow on chair armrest or workstation desk, results in direct contact pressure (reproduced with
permission from English and Andre 1999)
</p>
<p>3.2 Physical Aspects of Interaction 61</p>
<p/>
</div>
<div class="page"><p/>
<p>that involve the use of upper limbs. It focuses on the common risk factors that
</p>
<p>contribute to the development of upper limb disorders in situations that involve
</p>
<p>repetitive work. The tool is freely available from the Health and Safety Execu-
</p>
<p>tive&rsquo;s website (http://www.hse.gov.uk/msd/art-tool.htm).
</p>
<p>3.2.2 Load Bearing
</p>
<p>More and more people are using portable and mobile devices (phones, tablets, and
</p>
<p>so on). With these devices the user often has to support the weight of the display
</p>
<p>(and hence the interface) during interaction. Normally the user will have to carry
</p>
<p>the device around with them too. The net result is that the user must be able to
</p>
<p>support both the weight of the device when using it and the weight of the device
</p>
<p>whilst carrying it around for extended periods of time.
</p>
<p>At this point, all we can encourage you to do is to note what the device weighs,
</p>
<p>to study existing standards and similar devices, and to observe and talk to users.
</p>
<p>Simply asking users to complete a survey about the device is unlikely to generate
</p>
<p>much useful data, because they may not be able to judge weights abstractly or to
</p>
<p>consider their desire to carry an object without knowing and understanding its
</p>
<p>functionality. It probably makes more sense to give the devices to the users and
</p>
<p>observe how they explore and use them. If the device is for regular, routine use,
</p>
<p>you should observe them over a realistic period of time that includes the variety of
</p>
<p>environments in which the device will be used. The technology and functionality is
</p>
<p>rapidly changing in this area, which may change what users think is an acceptable
</p>
<p>weight to carry.
</p>
<p>3.3 Interacting with Haptic Devices
</p>
<p>Touch is usually regarded as the third most important sense after vision and
</p>
<p>hearing (which are both covered in the next chapter). What most people refer to as
</p>
<p>the sense of touch, however, is really a combination of two senses: the skin (or
</p>
<p>cutaneous sense) and kinesthesis (Loomis and Lederman 1986). The cutaneous
</p>
<p>sense is responsible for creating the feeling that the outer surface of the human
</p>
<p>body has been stimulated, which it does using receptors in the skin together with
</p>
<p>the associated nervous system. Kinesthesis (or the kinesthetic sense) generates an
</p>
<p>awareness of static and dynamic body posture based on information coming from
</p>
<p>the muscles, joints, and skin (afferent information), along with a copy of the signal
</p>
<p>sent to the motor system (an efferent copy). The efference copy is used to help
</p>
<p>distinguish between information coming from within the body and information
</p>
<p>coming from outside the body, and helps to explain why you do not laugh when
</p>
<p>you tickle yourself (there is a match between the afferent information and the
</p>
<p>efference copy)!
</p>
<p>62 3 Anthropometrics: Important Aspects of Users&rsquo; Bodies</p>
<p/>
<div class="annotation"><a href="http://www.hse.gov.uk/msd/art-tool.htm">http://www.hse.gov.uk/msd/art-tool.htm</a></div>
</div>
<div class="page"><p/>
<p>The mechanisms for the two senses are separate, but functionally they are much
</p>
<p>more difficult to separate, and they usually operate in tandem. For this reason, the
</p>
<p>two senses are associated with three types of tactual perception:
</p>
<p>&bull; Tactile perception, which is solely mediated by changes in cutaneous stimula-
</p>
<p>tion. Tactile perception always occurs within the context of a particular static
</p>
<p>posture, and may depend on that posture.
</p>
<p>&bull; Kinesthetic perception, which is (mostly) mediated by variations in kinesthetic
</p>
<p>stimulation. This includes situations where the cutaneous sense only indicates
</p>
<p>contact with the stimulus, and does not provide any spatial or textural infor-
</p>
<p>mation about the stimulus.
</p>
<p>&bull; Haptic perception, which is the most common type of tactual perception. It
</p>
<p>involves using information from the cutaneous sense and kinesthesis to under-
</p>
<p>stand and interpret objects and events in the environment.
</p>
<p>In the rest of this section, when we refer to touch, we will be referring to haptic
</p>
<p>perception, unless otherwise specified. Most devices that are used to provide input to
</p>
<p>computer-based systems make use of haptic perception. In general, however, most
</p>
<p>haptic devices only support interaction using the hands or fingers, even though users
</p>
<p>could (theoretically, at least) use any part of their body. There is, however, a
</p>
<p>growing number of devices that support input using the feet, such as the highly
</p>
<p>sophisticated da Vinci surgical system1 which has been successfully used in cancer
</p>
<p>surgery. The feet are also used to move around in virtual reality systems. The mouth
</p>
<p>and other parts of the body tend to be supported somewhat less, but they can be
</p>
<p>critical in interfaces for people with disabilities who cannot use their limbs, and
</p>
<p>increasingly for the military in unusual situations or circumstances.
</p>
<p>In this section we will focus our discussions on how people use hands and
</p>
<p>fingers to interact with systems. These discussions will consider the most common
</p>
<p>types of haptic devices that support interaction with computer-based systems. The
</p>
<p>future may include other devices, such as pens (e.g., Tian et al. 2008), multi-touch
</p>
<p>interfaces on a wider variety of objects (e.g., Jiang et al. 2012), or gestures, but
</p>
<p>these could be analyzed in a similar way.
</p>
<p>3.3.1 Physical Keyboards
</p>
<p>Physical keyboards&mdash;we use the term here to distinguish them from the soft
</p>
<p>keyboards that are used on touch screen devices&mdash;have a haptic interface. The feel
</p>
<p>of the key clicks provides you with haptic feedback about whether a keypress has
</p>
<p>been detected (and hence whether the corresponding character will appear on the
</p>
<p>associated display screen). Sometimes people will complain about the feel of a
</p>
<p>particular keyboard. Usually they are referring to the position and shape of the
</p>
<p>1 http://www.intuitivesurgical.com/products/davinci_surgical_system/
</p>
<p>3.3 Interacting with Haptic Devices 63</p>
<p/>
<div class="annotation"><a href="http://www.intuitivesurgical.com/products/davinci_surgical_system/">http://www.intuitivesurgical.com/products/davinci_surgical_system/</a></div>
</div>
<div class="page"><p/>
<p>keys but they may also be describing a keyboard that requires too much or too little
</p>
<p>pressure to operate the keys. You may also hear users talk about a soggy feel to the
</p>
<p>key action, which means that they cannot clearly tell whether a particular key has
</p>
<p>been pressed or not, based on the key&rsquo;s motion.
</p>
<p>Typing is still the most common way of entering data into computer-based
</p>
<p>systems (including mobile devices). It is thus useful to briefly consider typing in
</p>
<p>more detail and to identify some of the regularities of behavior in this area. Card
</p>
<p>et al. (1980, 1983) provide a good overview of the general issues of human typing,
</p>
<p>whilst Salthouse (1986) focuses on transcription typing.
</p>
<p>Users&rsquo; typing speeds range from a few words per minute (wpm) to over
</p>
<p>100 wpm, although there is often a trade-off between speed and accuracy. It is
</p>
<p>sometimes said, for example, that expert typists achieve speeds of 90 wpm with
</p>
<p>90% accuracy. The differences in speed are primarily due to practice&mdash;those that
</p>
<p>type more tend to get faster at it, using two hands rather than single-finger or hunt-
</p>
<p>and-peck typing styles.
</p>
<p>Typical typing speeds tend to occupy relatively narrow ranges for different
</p>
<p>categories of typist: novices can generally type at least 10 wpm; good journeyman
</p>
<p>programmers are closer to 30&ndash;60 wpm; and users whose jobs includes large
</p>
<p>amounts of typing are more likely to achieve rates above 60 wpm. We can
</p>
<p>extrapolate from these numbers to find keystroke times of about 750 ms per
</p>
<p>keystroke for slow typists ranging down to 125 ms per keystroke for fast typists.
</p>
<p>These numbers are useful for predicting reaction times and for working out how
</p>
<p>fast the computer has to respond.
</p>
<p>Many users can type some keys faster than others. For example, the &lsquo;&lsquo;n&rsquo;&rsquo; key
</p>
<p>(average typing time 221 ms) takes longer to type than the space bar (155 ms), as
</p>
<p>shown in Fig. 3.6 (Card et al. 1983, p. 62). This result suggests that when you
</p>
<p>design interfaces you should consider associating keys that are faster to type with
</p>
<p>actions that have to be performed frequently. There are exceptions to this rule,
</p>
<p>however, which include situations where you deliberately want to slow down the
</p>
<p>user so that they have time to consider the effect of their actions (such as in safety
</p>
<p>critical systems), and where memorability is important.
</p>
<p>Keyboard users make errors. Salthouse&rsquo;s (1986) review of transcription typists
</p>
<p>reports error rates in the range 1&ndash;3.2%, noting four types of observable errors: (1)
</p>
<p>substitution of letters (&lsquo;&lsquo;work&rsquo;&rsquo; for &lsquo;&lsquo;word&rsquo;&rsquo;), (2) intrusions (&lsquo;&lsquo;worrd&rsquo;&rsquo; for &lsquo;&lsquo;word&rsquo;&rsquo;),
</p>
<p>(3) omissions (&lsquo;&lsquo;wod&rsquo;&rsquo; for &lsquo;&lsquo;word&rsquo;&rsquo;), and (4) transpositions (&lsquo;&lsquo;wodr&rsquo;&rsquo; for &lsquo;&lsquo;word&rsquo;&rsquo;).
</p>
<p>These categories are not exclusive, and sometimes may be mistaken for each other.
</p>
<p>Only about half (40&ndash;70%) of these errors are caught by the typist and can account
</p>
<p>for 35% of expert typists&rsquo; time (Landauer 1987b, p. 151).
</p>
<p>The Typist model (John 1996) summarizes many of the behavior regularities of
</p>
<p>typing noted above. Typist can be used to explain how typing occurs and how
</p>
<p>errors arise. Its structure and behavior can also be examined to identify where
</p>
<p>interfaces for typing could be improved, and where changes would not make a
</p>
<p>difference. In transcription typing, for example, providing the typists with an
</p>
<p>additional paragraph of material to be typed is not useful because transcription
</p>
<p>typists do not look that far ahead.
</p>
<p>64 3 Anthropometrics: Important Aspects of Users&rsquo; Bodies</p>
<p/>
</div>
<div class="page"><p/>
<p>3.3.2 Touch Screens
</p>
<p>Probably the best-known and most widely used devices that support haptic input
</p>
<p>are touch screens. These are now commonplace on many mobile devices (smart-
</p>
<p>phones, tablet computers, and so on) and in information and ticket sales kiosks.
</p>
<p>Feedback for these devices is mostly provided through visual and audio channels.
</p>
<p>Figure 3.7 shows two examples of touch screen applications, one of which is static
</p>
<p>(an e-voting system), and the other highly portable (a handheld GPS satellite
</p>
<p>navigation system).
</p>
<p>Touch screen displays are electronically more complicated than normal dis-
</p>
<p>plays because they use either pressure or electrical conductance to determine
</p>
<p>where the screen is being touched. If the interface is well designed, it will be very
</p>
<p>clear to the user what actions they have performed on the screen (selection,
</p>
<p>scrolling, and so on), and the interface will be easy to use, and easy to learn to use.
</p>
<p>There are many examples of videos online, for example, that show young children
</p>
<p>figuring out how to use touch screen devices without any instruction.
</p>
<p>The end of the finger is of the order of ten times the size of the normal
</p>
<p>arrowhead cursor that you see on most systems. You will need to take this, and
</p>
<p>individual variations in finger size, into account when designing touch screen
</p>
<p>interfaces to avoid fat finger problems. These occur when people touch more than
</p>
<p>one button at a time, or accidentally touch the wrong button. It has been calculated
</p>
<p>that about 9% of clicks on adverts on mobile devices are accidental!2 So, if you
</p>
<p>need to accommodate many buttons on a small touch screen, you will need to have
</p>
<p>a deeper understanding of how the technology works and the ways in which users
</p>
<p>use small buttons.
</p>
<p>213   188 186   149 162   128 149   136 149   136 164   140 164   140 155   129 151   124 131   156
</p>
<p>180   140 196   147 222   138 201  135 201   135 175   120 175   120 162   133 194   141
</p>
<p>      162 241      238   153 197   153 197   160 157   132 157   132 249   164 235   159
</p>
<p>155
</p>
<p>Key
</p>
<p>Same
</p>
<p>Hand
</p>
<p>Alternate
</p>
<p>Hand
</p>
<p>All keystrokes 
</p>
<p>average: 155 ms
</p>
<p>Q W E R T Y U I O P
</p>
<p>AS D F G H J K L
</p>
<p>XZ C V B N M , .
</p>
<p>Space Bar
</p>
<p>Fig. 3.6 The time (in milliseconds) to type different keys on the keyboard based on
155,000 keystrokes. Times taken from Kinkead (1975) cited in Card et al. (1983). Same hand
times are for keys typed with the same hand; alternate hand is for keys typed after a key typed by
the other hand
</p>
<p>2 http://econsultancy.com/uk/blog/10649-mobile-s-biggest-ad-challenge-fat-fingers
</p>
<p>3.3 Interacting with Haptic Devices 65</p>
<p/>
<div class="annotation"><a href="http://econsultancy.com/uk/blog/10649-mobile-s-biggest-ad-challenge-fat-fingers">http://econsultancy.com/uk/blog/10649-mobile-s-biggest-ad-challenge-fat-fingers</a></div>
</div>
<div class="page"><p/>
<p>Even when touch screen technology is both usable and acceptable to the users,
</p>
<p>there can be other risks that mitigate against its use in some situations. The touch
</p>
<p>screen voting system shown on the left side of Fig. 3.7, for example, was removed
</p>
<p>within a year of being introduced because it could not produce a voter-verifiable
</p>
<p>paper audit trail. In other words, there was no way for a voter to tell that their vote
</p>
<p>had been properly recorded rather than discarded after they had pressed the
</p>
<p>appropriate buttons. The public and public officials believed that the risk of
</p>
<p>potential corruption&mdash;the voter gets feedback from the device saying the vote has
</p>
<p>been cast, but the vote never gets processed to include it in the count&mdash;made the
</p>
<p>system unacceptable.
</p>
<p>3.3.3 Pointing Devices
</p>
<p>People still widely use mice as a way of interacting with systems and applications,
</p>
<p>although usage may decline as the uptake of touch screen technology continues to
</p>
<p>rise. Although the mouse is still the most common form of pointing device, there
</p>
<p>are others, such as trackpads, graphic tablets, tracker balls, and light pens.
</p>
<p>Recently released devices, such as Google Glass, are increasingly exploring the
</p>
<p>pros and cons of gaze as a means of pointing. However, for the time being, the
</p>
<p>dominant mode of interaction with desktop computers is still the mouse.
</p>
<p>The movement of on-screen cursors using pointing devices generally follows
</p>
<p>Fitts&rsquo; (1954) law. In its most general form, Fitts&rsquo; law states that the time to point to
</p>
<p>an object is related to the distance from the object and inversely related to the size
</p>
<p>of the object, as shown in Fig. 3.8.
</p>
<p>There are several variants of Fitts&rsquo; law. The simplest is shown in Eq. (3.1):
</p>
<p>time &frac14; intercept constant &thorn; slope constant ï¿½ log2&eth;2ï¿½ d=w&THORN; &eth;3:1&THORN;
</p>
<p>Card et al. (1983) variant shown in Eq. (3.2) is slightly easier to use:
</p>
<p>time &frac14; 70ms ï¿½ log2 d=w&thorn; 0:5&eth; &THORN; &eth;3:2&THORN;
</p>
<p>Fig. 3.7 A touch screen used
to provide voting without a
paper trail (left), and a GPS
navigation system (right)
</p>
<p>66 3 Anthropometrics: Important Aspects of Users&rsquo; Bodies</p>
<p/>
</div>
<div class="page"><p/>
<p>The argument to the log2 function in these equations is a measure of the difficulty
</p>
<p>of the move, measured in bits of information (Shannon 1948). It is sometimes called
</p>
<p>the index of difficulty. As shown in Fig. 3.8, the target distance, d, is measured from
</p>
<p>the point where the movement starts, X, and the target size, w, is the width of the
</p>
<p>target. If the movement was from above or below the target, the target size would be
</p>
<p>based on the height of the target (MacKenzie and Buxton 1992). The intercept
</p>
<p>constant and slope constant vary across tasks and across input modalities. Typical
</p>
<p>values for the intercept constant are about 100 ms. The slope constant varies from
</p>
<p>about 20 ms for very good input devices like using fingers directly, to 105 ms for
</p>
<p>using arms directly as well as for mice.
</p>
<p>Fitts&rsquo; law is less accurate where the size of the object, or the distance that has to
</p>
<p>be moved, are very large, for example, where the user&rsquo;s mouse reaches the edge of
</p>
<p>the desk before the mouse pointer has reached the edge of the screen, so the user
</p>
<p>has to pick up the mouse and move it back across the desk before the pointer can
</p>
<p>be moved any further. Some versions predict a negative reaction time for large or
</p>
<p>close objects (where d/w is 0, for example), and time to move to distant objects
</p>
<p>tends to be underestimated. Also note that the units are arbitrary, as it is the ratio of
</p>
<p>the target size to target distance that is used. Fitts&rsquo; law is, however, a fairly robust
</p>
<p>law, and has been usefully applied to many interfaces because it makes good
</p>
<p>suggestions for interface design.
</p>
<p>There are at least two implications for designing user interfaces that arise out of
</p>
<p>Fitts&rsquo; Law. The first is that larger objects lead to faster pointing times than smaller
</p>
<p>objects. The second is that shorter distances also lead to faster reaction times.
</p>
<p>Indeed, the fastest time is to move a very small distance towards an infinitely large
</p>
<p>target. Moving the cursor to the screen&rsquo;s edge (with effectively an infinite target
</p>
<p>size) is much faster than moving the cursor to a bounded (finite) box that is more
</p>
<p>centrally located. So, menu bars at the very top of the screen are much faster to
</p>
<p>access than menu bars that are offset from the edge. These implications have to be
</p>
<p>traded off against other factors though, such as the size of the other objects in a
</p>
<p>display, the size of the display itself, sequencing of tasks, and how often the
</p>
<p>objects and commands are used.
</p>
<p>Fig. 3.8 Description of the
variables in Fitts&rsquo; Law. X is
where the user starts to point
from, d is the distance to the
target, and w is the width of
the target
</p>
<p>3.3 Interacting with Haptic Devices 67</p>
<p/>
</div>
<div class="page"><p/>
<p>Figure 3.9 shows several example menu bars. The top menu (starting with the
</p>
<p>Apple and Word) will be the fastest because it is next to the screen edge. Being
</p>
<p>next to the edge makes the target size very large. The other menus below that will
</p>
<p>be slower to access. The icons on the far left (the dashed box with a pointer, the
</p>
<p>grid, the circular line, picture, etc.) will, however, be relatively fast to point to,
</p>
<p>because they are on an edge, if the user is approaching them from the center of the
</p>
<p>window. However, they are not because they are offset from the edge by Word.
</p>
<p>Figure 3.10 shows Word 2010&rsquo;s menu in Windows in which the menu items
</p>
<p>(File, Home, etc.) are offset from the top edge. The time to switch to a menu bar
</p>
<p>item in Fig. 3.9 is (assuming from the middle of the screen) limited by the constant
</p>
<p>time and time to click because the target size is infinite, so the user can move the
</p>
<p>mouse without regard to the target. So, about 100 ms + 1,100 ms or 1,200 ms. The
</p>
<p>time to switch to a menu bar item in Fig. 3.10 is about 100 ms + 100 ms 9 log2
(8 cm/1 cm) or 1,500 ms. In other words, at least 25% longer.
</p>
<p>Figure 3.11 shows the Eclipse integrated development environment (IDE),
</p>
<p>including some aspects for writing user models. In this interface the menus are also
</p>
<p>offset from the top of the window, which might not even be flush with the top of
</p>
<p>the display. Selecting buttons and panels will thus be slower and more error prone
</p>
<p>with this menu.
</p>
<p>Fitts&rsquo; law yields some more sophisticated suggestions when combined with
</p>
<p>Hick&rsquo;s law, which predicts how long it takes to choose one item from a list of
</p>
<p>several options (Landauer 1987a). When combined, these two laws suggest that
</p>
<p>Fig. 3.9 A screen shot of an application (Word11 for Macintosh) with several menus
</p>
<p>Fig. 3.10 Word 2010 for Window&rsquo;s menu bar with offset from display edge
</p>
<p>68 3 Anthropometrics: Important Aspects of Users&rsquo; Bodies</p>
<p/>
</div>
<div class="page"><p/>
<p>broader and shallower menus will be faster to use than narrower and deeper menus
</p>
<p>(multiple movements take more time than choosing), although the size of the
</p>
<p>effects are moderated by the naturalness of the categories of the menu items
</p>
<p>(Landauer 1987b, pp. 146&ndash;147).
</p>
<p>It is also worth noting that Fitts&rsquo; Law also applies to moving to a particular key
</p>
<p>on a keyboard, although the constants in the equation are different. The results here
</p>
<p>would advocate making frequently used keys bigger and possibly putting them
</p>
<p>close to the edge of the keyboard, depending on how they are used. The sequence
</p>
<p>in which keys are regularly used is also an important factor to consider in working
</p>
<p>out the layout of the keys.
</p>
<p>3.3.4 Mobile Phones
</p>
<p>Thumbing is an important area of interface interaction (see, for example, James
</p>
<p>and Reischel 2001; MacKenzie and Soukoreff 2002). Many mobile phone users
</p>
<p>interact using their thumbs rather than their fingers. In some cases they use one
</p>
<p>hand, particularly when using those parts of the screen that can be used more easily
</p>
<p>one handed. In other cases, they cradle the phone in the fingers of both hands, and
</p>
<p>then enter data using both thumbs. Phones that have full keyboards, rather than just
</p>
<p>numeric keypads, are particularly suited to using both thumbs for text input.
</p>
<p>Fig. 3.11 The Eclipse workspace
</p>
<p>3.3 Interacting with Haptic Devices 69</p>
<p/>
</div>
<div class="page"><p/>
<p>The use of thumbing is an important reminder that users will often use devices
</p>
<p>in ways other than those intended by the designers. Probably the most widespread
</p>
<p>example of this is the sending of SMS messages, a task that is performed by most
</p>
<p>people who own a mobile phone. SMS messages were originally included as a
</p>
<p>debugging feature to help telephone engineers; it is one of the things that HCI
</p>
<p>designers missed.
</p>
<p>We noted earlier that people&rsquo;s bodies change as they get older. Deterioration in
</p>
<p>eyesight, for example, can make it harder to read small buttons. This is one of the
</p>
<p>reasons why some people prefer phones that have bigger buttons, like the one
</p>
<p>shown in Fig. 3.12. Although the larger buttons mean that there is less space to
</p>
<p>include other features, it should make the existing features easier to access and use.
</p>
<p>It should also be noted that there is a delicate balance to be struck here between
</p>
<p>making the buttons easier to see on the one hand, and stigmatizing the user as
</p>
<p>someone who is old or has poor eyesight on the other.
</p>
<p>3.3.5 Video Games and Virtual Reality Systems
</p>
<p>In video games that use a vibrating controller, the physical motion of the controller
</p>
<p>(which vibrates as well as buzzing) is used as a primary source of (haptic) feed-
</p>
<p>back. In car driving games, for example, the vibration may indicate that the car has
</p>
<p>left the road surface (see also Fogtmann et al. 2008 and Bau and Poupyrev 2012
</p>
<p>for two examples of their use). Video games are becoming increasingly sophis-
</p>
<p>ticated in this area.
</p>
<p>Haptic feedback in virtual reality systems provides a useful way to help the user
</p>
<p>feel immersed in the virtual environment. In some cases it is easier to commu-
</p>
<p>nicate particular types of information in virtual environments, such as the forces
</p>
<p>that exist between objects and those that are needed to manipulate objects. Force
</p>
<p>has also been used, for example, in virtual surgery to represent different parts of
</p>
<p>the body, and to illustrate the forces involved in manipulating atoms within a
</p>
<p>molecule when designing drugs (e.g., Zonta et al. 2009).
</p>
<p>One way of providing haptic interaction is through a force feedback glove,
</p>
<p>which is instrumented and has force feedback pads in the fingers. The user wears
</p>
<p>the glove, and as they move their hand and fingers in the glove, the movements are
</p>
<p>applied to modify the relevant objects in the interface. If an object in the interface
</p>
<p>is not movable, or requires a significant force to move it, this is fed back to the user
</p>
<p>by providing a greater force on feedback pads and hence onto the user&rsquo;s fingers.
</p>
<p>Data gloves are often perceived as being quite cumbersome, however, which is an
</p>
<p>issue that is now starting to be addressed through the development of devices that
</p>
<p>support gesture-based interaction such as Microsoft&rsquo;s Digits3 which utilizes a
</p>
<p>wrist-worn gloveless sensor.
</p>
<p>3 http://research.microsoft.com/apps/video/dl.aspx?id=173838
</p>
<p>70 3 Anthropometrics: Important Aspects of Users&rsquo; Bodies</p>
<p/>
<div class="annotation"><a href="http://research.microsoft.com/apps/video/dl.aspx?id=173838">http://research.microsoft.com/apps/video/dl.aspx?id=173838</a></div>
</div>
<div class="page"><p/>
<p>In immersive environments users still receive most of their feedback on their
</p>
<p>actions and movements through the visual channel. Where there is a mismatch
</p>
<p>between the visual scene and the inner ear&rsquo;s movement, however, this can lead to
</p>
<p>nausea. Full motion simulators attempt to provide some of this information by
</p>
<p>providing initiating cues to the motion. How to provide this information to a user
</p>
<p>remains a technical problem that is informed by knowledge about the user.
</p>
<p>3.3.6 Other Devices
</p>
<p>Other devices have introduced some other novel methods of interaction. Apple&rsquo;s
</p>
<p>iPod, for example, incorporated the idea of using a dial which, when rotated,
</p>
<p>produces behavior similar to that of a scroll bar, as shown in Fig. 3.13. When it
</p>
<p>was introduced this was quite novel, and many users liked it.
</p>
<p>Fig. 3.12 An example phone
interface (Jitterbug Plus)
designed with larger buttons
and a simpler interface.
Taken from www.greatcall.
com (used with permission)
</p>
<p>3.3 Interacting with Haptic Devices 71</p>
<p/>
<div class="annotation"><a href="http://www.greatcall.com">http://www.greatcall.com</a></div>
<div class="annotation"><a href="http://www.greatcall.com">http://www.greatcall.com</a></div>
</div>
<div class="page"><p/>
<p>Another music player, the Samsung TicToc mp3 player (Fig. 3.14), takes a
</p>
<p>different approach to interaction. The TicToc has only one button, and feedback is
</p>
<p>obtained through a combination of three LEDs, which backlight the three icons on
</p>
<p>the body of the player, and speech. You press and hold the button (located on the
</p>
<p>end of the player) to turn the TicToc on. This causes all three LEDs to illuminate,
</p>
<p>and the player tells you how much battery capacity is left and then starts playing
</p>
<p>automatically. To increase the volume, you hold the player with the &lsquo;&lsquo;+&rsquo;&rsquo; icon
</p>
<p>uppermost and press the button several times until you get the desired level. To
</p>
<p>reduce the volume you turn the player the other way up and repeat the process. If
</p>
<p>you want to turn the player off you press and hold the button. Again, all the lights
</p>
<p>illuminate before the player switches off.
</p>
<p>Moving between tracks is relatively straightforward: you hold the player hor-
</p>
<p>izontally, and press the button once to skip to the next track, or twice if you want to
</p>
<p>skip to the previous track. If you want to skip to the next album, you press it three
</p>
<p>Fig. 3.13 Apple iPod,
showing the novel (at the
time) circular dial control
</p>
<p>Fig. 3.14 The Samsung
TicToc music player
</p>
<p>72 3 Anthropometrics: Important Aspects of Users&rsquo; Bodies</p>
<p/>
</div>
<div class="page"><p/>
<p>times. The novel interaction involves shaking the device. If you shake it once it
</p>
<p>tells you the artist name followed by the name of the track that is currently playing
</p>
<p>(as long as you have added the music using the TicToc program). You also shake
</p>
<p>the player (three times) if you want to change the mode, which cycles through
</p>
<p>Normal, Shuffle, Fast (tempo), and Slow (tempo): it then tells you which mode you
</p>
<p>have switched to.
</p>
<p>The Samsung TicToc may not be to everyone&rsquo;s tastes, but the interaction
</p>
<p>methods can actually be quite useful. If you listen to music when you go out
</p>
<p>exercising, for example, you can operate the TicToc without having to stop and
</p>
<p>look at the interface to locate the correct button, and read the display, as you would
</p>
<p>with other digital music players.
</p>
<p>3.3.7 Advantages and Disadvantages of Haptic Interfaces
</p>
<p>Touch-based interfaces are important for a wide range of users and will be par-
</p>
<p>ticularly important for users without sight as the technology to provide haptic
</p>
<p>interfaces improves. Explorations include: a computer mouse that can provide
</p>
<p>tactile feedback via a series of electric motors (G&ouml;bel et al. 1995); computers that
</p>
<p>let users feel the texture of, for example, a fabric on their screens (Dillon et al.
</p>
<p>2001); and mobile phones made with latex that enable people to communicate by
</p>
<p>touch as well as speech (Park et al. 2013). Table 3.1 notes the range of applications
</p>
<p>that are possible, and illustrates the range of users and tasks that can take
</p>
<p>advantage of haptic interfaces.
</p>
<p>Tactile feedback is already used by many interfaces to convey important
</p>
<p>information about the status of a system, particularly that a given operation has
</p>
<p>been accomplished. For example, using a switch is confusing if there is no obvious
</p>
<p>tactile or audible sensation that it has been operated. If there is no obvious visual
</p>
<p>or auditory indication of the switch being operated, then touch is the next most
</p>
<p>likely means of providing that feedback. Keyboards are designed to provide this
</p>
<p>type of feedback.
</p>
<p>Kaczmarek and Bach-y-Rita&rsquo;s (1995) list of advantages to using touch
</p>
<p>(Table 3.1), can be extended further:
</p>
<p>(1) Users have a lot of skin. Several parts of it are sensitive enough to provide a
</p>
<p>useful communication media.
</p>
<p>(2) Skin has several functional similarities to the eye, including the ability to map
</p>
<p>from a two-dimensional display of the environment to the user&rsquo;s skin, and to
</p>
<p>integrate the signal over time.
</p>
<p>(3) Representations learned visually can be recognized tactilely.
</p>
<p>(4) The inputs required can be quite low and easily achievable with current
</p>
<p>technology. In particular, the fingertips are very sensitive to changes in
</p>
<p>pressure.
</p>
<p>3.3 Interacting with Haptic Devices 73</p>
<p/>
</div>
<div class="page"><p/>
<p>(5) Touch provides another input modality. This is useful as primary modality for
</p>
<p>users without sight. For sighted users, communication through touch does not
</p>
<p>interfere materially with motor or other sensory functions.
</p>
<p>(6) For telepresence, such as virtual reality applications, tactile feedback is very
</p>
<p>important for obtaining the sense of immersion.
</p>
<p>Many of the barriers to using haptic interfaces such as cost, power require-
</p>
<p>ments, safety, and usefulness have now been overcome. This explains why there
</p>
<p>are now so pervasive in smartphones and tablet computers.
</p>
<p>3.4 Implications for System Design
</p>
<p>System performance is a result of particular users doing particular tasks (using a
</p>
<p>particular technology) in a particular context. When you are thinking about
</p>
<p>designing interactive systems, you will need to consider all of these aspects
</p>
<p>together.
</p>
<p>Your users may have limited vision or even no vision at all. This can be a
</p>
<p>permanent physical characteristic: they may be blind, for example. It may also be a
</p>
<p>constraint of the task environment, for example when operating motor transport at
</p>
<p>night or in foggy weather conditions. Currently, interfaces that make use of
</p>
<p>auditory information are most important to people with visual impairment, but
</p>
<p>haptic interfaces are becoming more important as the technology improves, and
</p>
<p>the associated costs fall.
</p>
<p>Table 3.1 Types of users and tasks that can use a haptic interface
</p>
<p>Users with poor vision
</p>
<p>Teleoperators in areas where vision is not possible or not clear, such as muddy sea floors or areas
with high radiation or poor light
</p>
<p>Drivers (cars, buses, tractors, miners) at night
</p>
<p>Aircraft pilots and car drivers in fog
</p>
<p>Users with poor or temporarily degraded sense of touch
</p>
<p>Astronauts (and others, such as first responders) wearing gloves
</p>
<p>People with insensate feet or hands (a common complication of diabetes) or who have reduced
sensitivity due to age
</p>
<p>Teleoperators who would like more feedback about what is in their gripper
</p>
<p>Users who need an additional input channel or need touch as the input channel
</p>
<p>Cellular phone users in situations where audio ringing is not acceptable
</p>
<p>Surgeons who need to know the elasticity and shape of organs during virtual surgery
</p>
<p>Game players who could feel that they are being hit or are bumping a wall
</p>
<p>Expanded from Kaczmarek and Bach-y-Rita (1995)
</p>
<p>74 3 Anthropometrics: Important Aspects of Users&rsquo; Bodies</p>
<p/>
</div>
<div class="page"><p/>
<p>If your users will include older people, you may need to give consideration to
</p>
<p>the type of technology that you will use. As people get older, or if they have
</p>
<p>diabetes, their skin loses its sensitivity. This means that if you are going to use a
</p>
<p>touch screen interface it may need to utilize resistive technology rather than
</p>
<p>capacitive technology.
</p>
<p>If the user&rsquo;s task has to be carried out remotely, or requires wearing gloves
</p>
<p>(ranging from those used outdoors to those used in space), then you may want to
</p>
<p>augment visual (and auditory) feedback with haptic feedback. Teleoperators, for
</p>
<p>example, often like to have feedback about what they are holding in their grippers,
</p>
<p>and surgeons performing operations remotely need to know about the shape and
</p>
<p>elasticity of the organs that they are dealing with.
</p>
<p>One aspect of haptics which we have not considered here, but which can be
</p>
<p>important, is the feel of a device and the materials it is made from, its esthetics. A
</p>
<p>smooth, shaped surface, for example, may help to lead to a positive emotional
</p>
<p>experience of using a particular device. This is one of the reasons why mice
</p>
<p>evolved from relatively square devices to something that is now much more
</p>
<p>rounded and better suited to the shape of the hand when using it.
</p>
<p>If your system will be installed in an environment where there is limited space,
</p>
<p>this may determine how the users can interact with the system. It is always worth
</p>
<p>going to look at the installation location beforehand. One of the authors was
</p>
<p>involved in putting in a system that normally used a mouse. The system was to be
</p>
<p>installed alongside another system which meant that there was very limited
</p>
<p>desktop space available. As a result, a trackerball interface was used instead of the
</p>
<p>mouse because it requires less space to operate.
</p>
<p>If your system includes manual controls, it is important to provide haptic
</p>
<p>feedback to indicate that these controls have been operated. This is particularly
</p>
<p>true when there is no obvious visual or auditory feedback when a button has been
</p>
<p>pressed or a switch has been activated, for example.
</p>
<p>If you are developing a mobile application or system, you will need to think
</p>
<p>about all the contexts in which it may be used. If it can be used in a situation where
</p>
<p>visual and auditory feedback are not allowed, for example, then you may want to
</p>
<p>give the device a haptic interaction capability. Most mobile phones, for example,
</p>
<p>provide a silent mode in which the phone vibrates rather than rings.
</p>
<p>3.5 Summary
</p>
<p>This chapter has introduced the fact that at least some aspects of users&rsquo; bodies are
</p>
<p>involved in interacting with devices and systems. Although the fields of human
</p>
<p>factors and ergonomics routinely consider this aspect of work, it tends to be less
</p>
<p>explicitly represented in HCI. Users&rsquo; bodies provide capabilities and constraints on
</p>
<p>3.4 Implications for System Design 75</p>
<p/>
</div>
<div class="page"><p/>
<p>what tasks they can perform, the loads that they can support and carry, and how
</p>
<p>quickly and accurately they can provide input to a system. Using this information
</p>
<p>can help us make effective choices about which input modality to use, and how to
</p>
<p>design menus and dialog boxes.
</p>
<p>Human capabilities and constraints vary between users, and within users they
</p>
<p>vary across time and across context. The best interfaces are those that take all of
</p>
<p>these differences into consideration so that they can support as wide a range of
</p>
<p>use&mdash;people, technology, and context&mdash;as possible.
</p>
<p>3.6 Other Resources
</p>
<p>There are many texts that are available for deepening understanding of design
</p>
<p>relevant aspects of the body. Although not explicitly focused on the human body
</p>
<p>nor on technology, we strongly recommend Don Norman&rsquo;s excellent text, The
</p>
<p>Psychology of Everyday Things, to get you into a way of thinking about people
</p>
<p>interacting with designed objects of all kinds. An extremely readable text, we think
</p>
<p>you will find many examples that relate to your everyday world (many related to
</p>
<p>anthropometrics) and that will get you thinking about design from a different
</p>
<p>perspective.
</p>
<p>Norman, D. A. (1988). The psychology of everyday things. NY: Basic Books. (2013 ed.
The design of everyday things)
</p>
<p>Further information on the range of users&rsquo; bodies and how they move can be
</p>
<p>found in engineering handbooks. We recommend looking at:
</p>
<p>Boff, K. R., Kaufman, L., and Thomas, J. P. (1986). Handbook of perception and human
performance (Vol. I, II, and III). New York: John Wiley &amp; Sons.
</p>
<p>Industrial engineering explores this area in much more depth, and knows about
</p>
<p>how best to support users that stand, squat, and assume a variety of other postures.
</p>
<p>Wickens et al. (1998, Chaps. 10 and 11) provide a useful introduction to these
</p>
<p>topics.
</p>
<p>The International Standards Organization (ISO, you may see this acronym on a
</p>
<p>variety of technical measures and standards) has been developing standards for
</p>
<p>usability for several years. The most relevant series here is ISO 9241, Ergonomics
</p>
<p>of Human System Interaction (http://en.wikipedia.org/wiki/ISO_9241).
</p>
<p>It is also worth thinking about new forms of interaction beyond the current
</p>
<p>keyboard layout. There are a number of research projects addressing new forms of
</p>
<p>input beyond the keyboard. This edited special issue gives some pointers to future
</p>
<p>thinking research work:
</p>
<p>Schmidt, A., and Churchill, E. F. (2012). Interaction beyond the keyboard, IEEE
Computer, 45(4). 21&ndash;24.
</p>
<p>76 3 Anthropometrics: Important Aspects of Users&rsquo; Bodies</p>
<p/>
<div class="annotation"><a href="http://en.wikipedia.org/wiki/ISO_9241">http://en.wikipedia.org/wiki/ISO_9241</a></div>
</div>
<div class="page"><p/>
<p>3.7 Exercises
</p>
<p>3.1 Consider a smartphone, either a specific one or a composite, general one.
</p>
<p>Attempt to come up with a trade-off function between a set of features (which
</p>
<p>you create) and weight. Describe how to choose a reasonable point on that
</p>
<p>curve. Is your smartphone more like a phone, tablet, or laptop?
</p>
<p>3.2 Choose an existing interface and make five suggestions how touch could
</p>
<p>change or improve its usability. Interfaces where this is easy to do include
</p>
<p>CAD/CAM systems and data mining systems. Interfaces that are more difficult
</p>
<p>include online learning environments and simple web sites.
</p>
<p>3.3 Describe five systems where anthropometrics make a difference. To get you
</p>
<p>started, consider small systems for playing music, and also consider how these
</p>
<p>systems can be integrated with other capabilities (e.g., cellular phones).
</p>
<p>3.4 Write a short report on the quality of your own desk and work area. Compare
</p>
<p>it with an ergonomically suggested design as well as with what is available in
</p>
<p>the place where you use a computer for study or work purposes.
</p>
<p>3.5 Compute the constants for Fitts&rsquo; law based on a thumb. This can be done by
</p>
<p>creating a set of targets for the thumb and measuring the time for the thumb to
</p>
<p>move to those targets. In the case where video analysis is not available, a
</p>
<p>useful approach is to have the thumb move to the target multiple times and
</p>
<p>then move back, or to type in a series of actions and then use linear regression
</p>
<p>to compute the best predicted time per action. The resulting constants and
</p>
<p>times can then be compared with other constants for pointing approaches.
</p>
<p>3.6 Compute the time it would take to select an Eclipse menu item from the
</p>
<p>application&rsquo;s top menu in Fig. 3.11, like &lsquo;&lsquo;Refactor,&rsquo;&rsquo; and a menu from the
</p>
<p>window&rsquo;s panels, like &lsquo;&lsquo;Target.java.&rsquo;&rsquo; You should compute this for the middle
</p>
<p>of the screen (as shown) and from the actual location of the mouse pointer.
</p>
<p>3.7 Given a 1500 diagonal touch screen, how many buttons could you put on it?
</p>
<p>(a) Note your assumptions.
</p>
<p>(b) Describe how many buttons you could fit on the screen.
</p>
<p>(c) Note any lessons you found while doing this task.
</p>
<p>3.8 On a Penn State online course system, similar to many online course systems,
</p>
<p>the web page shown on the top of Fig. 3.15 appears. If you click on the link
</p>
<p>next to the pointer (Template for the Team Contract), the page on the bottom
</p>
<p>comes up. This page notes that if you do not move the mouse over the target
</p>
<p>phrase (blank_team_contract.doc) in 5 s, the file will automatically download
</p>
<p>(presumably to your default download directory). It is often much better to
</p>
<p>download into your course directory, so you have to quickly move your mouse
</p>
<p>over the target phrase.
</p>
<p>Comment on what would be a reasonable default time to move the mouse
</p>
<p>using Fitts&rsquo; law. Is 5 s a reasonable time, or could it be much less, or should it
</p>
<p>be more?
</p>
<p>3.7 Exercises 77</p>
<p/>
</div>
<div class="page"><p/>
<p>Fig. 3.15 File downloading in the Angel course management system. How long should the user
have to move their mouse to stop a download?
</p>
<p>78 3 Anthropometrics: Important Aspects of Users&rsquo; Bodies</p>
<p/>
</div>
<div class="page"><p/>
<p>References
</p>
<p>Bau, O., &amp; Poupyrev, I. (2012). REVEL: Tactile feedback technology for augmented reality.
ACM Transactions on Graphics, 31(4), Article 89, 1&ndash;11.
</p>
<p>Card, S. K., Moran, T. P., &amp; Newell, A. (1980). The keystroke-level model for user performance
time with interactive systems. Communications of the ACM, 23(7), 396&ndash;410.
</p>
<p>Card, S. K., Moran, T., &amp; Newell, A. (1983). The psychology of human-computer interaction.
Hillsdale, NJ: Erlbaum.
</p>
<p>Dillon, P., Moody, W., Bartlett, R., Scully, P., Morgan, R., &amp; James, C. L. (2001). Sensing the
fabric: To simulate sensation through sensory evaluation and in response to standard
acceptable properties of specific materials when viewed as a digital image. In Haptic human-
computer interaction, First international workshop (pp. 205&ndash;218). Berlin: Springer.
</p>
<p>English, J., &amp; Andre, A. D. (1999). Posture and web browsing: An observational study. In
Proceedings of the 43rd annual meeting of the Human Factors and Ergonomics Society
</p>
<p>(pp. 945&ndash;949). Santa Monica, CA: Human Factors and Ergonomics Society.
Fitts, P. M. (1954). The information capacity of the human motor system in controlling amplitude
</p>
<p>of movement. Journal of Experimental Psychology, 47(6), 381&ndash;391.
Fogtmann, M. H., Fristch, J., &amp; Kortbek, K. J. (2008). Kinesthetic interaction&mdash;Revealing the
</p>
<p>bodily potential in interaction design. In OZCHI&rsquo;08: Proceedings of the 20th Australasian
conference on computer&ndash;human interaction: Designing for habitus and habitat (pp. 89&ndash;96).
New York, NY: ACM Press.
</p>
<p>Gibson, J. J. (1979). The ecological approach to visual perception. Boston, MA: Houghton Mifflin.
G&ouml;bel, M., Luczak, H., Springer, J., Hedicke, V., &amp; R&ouml;tting, M. (1995). Tactile feedback applied
</p>
<p>to computer mice. International Journal of Human-Computer Interaction, 7(1), 1&ndash;24.
James, C. L., &amp; Reischel, K. M. (2001). Text input for mobile devices: Comparing model
</p>
<p>prediction to actual performance. In CHI &lsquo;01 Proceedings of the SIGCHI conference on
human factors in computing systems (pp. 365&ndash;371). New York, NY: ACM.
</p>
<p>Jiang, Y., Tian, F., Zhang, X., Liu, W., Dai, G., &amp; Wang, H. (2012). Unistroke gestures on multi-
touch interaction: Supporting flexible touches with key stroke extraction. In ACM conference
on Intelligent User Interfaces (IUI) (pp. 61&ndash;70). New York, NY: ACM.
</p>
<p>John, B. E. (1996). TYPIST: A theory of performance in skilled typing. Human-Computer
Interaction, 11(4), 321&ndash;355.
</p>
<p>Kaczmarek, K. A., &amp; Bach-y-Rita, P. (1995). Tactile displays. In W. Barfield &amp; T. A. Furness III
(Eds.), Virtual environments and advanced interface design (pp. 349&ndash;414). Oxford: Oxford
University Press.
</p>
<p>Kinkead, R. (1975). Typing speed, keying rates, and optimal keyboard layouts. In Proceedings of
the Human Factors Society 19th annual meeting (pp. 159&ndash;161). Santa Monica, CA: Human
Factors Society.
</p>
<p>Landauer, T. K. (1987a). Relations between cognitive psychology and computer systems design.
In J. M. Carroll (Ed.), lnterfacing thought: Cognitive aspects of human- computer interaction
(pp. 1&ndash;25). Cambridge, MA: MIT Press.
</p>
<p>Landauer, T. K. (1987b). Relations between cognitive psychology and computer systems design.
In J. Preece &amp; L. Keller (Eds.), Human-computer interaction (pp. 141&ndash;159). Englewood
Cliffs, NJ: Prentice-Hall.
</p>
<p>Loomis, J. M., &amp; Lederman, S. J. (1986). Tactual perception. In K. Boff, L. Kaufman, &amp;
J. Thomas (Eds.), Handbook of perception and human performance (Vol. II, pp. 31-31&ndash;31-41).
New York, NY: Wiley.
</p>
<p>MacKenzie, I. S., &amp; Buxton, W. A. S. (1992). Extending Fitts&rsquo; law to two-dimensional tasks. In
Proceedings of ACM CHI 1992 conference on human factors in computing systems (pp.
219&ndash;226).
</p>
<p>MacKenzie, I. S., &amp; Soukoreff, R. W. (2002). Text entry for mobile computing: Models and
methods, theory and practice. Human-Computer Interaction, 17, 147&ndash;198.
</p>
<p>Norman, D. A. (1988). The psychology of everyday things. New York: Basic Books.
</p>
<p>References 79</p>
<p/>
</div>
<div class="page"><p/>
<p>Norman, D. A. (2013). The design of everyday things. New York: Basic Books.
Park, Y. W., Baek, K. M., &amp; Nam, T. J. (2013). The roles of touch during phone conversations:
</p>
<p>Long-distance couples&rsquo; use of POKE in their homes. In Proceedings of the 2013 ACM annual
conference on human factors in computing systems, (pp. 1679&ndash;1688). New York, NY: ACM.
</p>
<p>Salthouse, T. A. (1986). Perceptual, cognitive, and motoric aspects of transcription typing.
Psychological Bulletin, 3(3), 303&ndash;319.
</p>
<p>Shannon, C. E. (1948). A mathematical theory of communication. Bell System Technical Journal,
27, 379&ndash;423; 623&ndash;656.
</p>
<p>Tian, F., Xu, L., Wang, H., Zhang, X., Liu, Y., Setlur, V., et al. (2008). Tilt Menu: Using the 3D
orientation information of pen devices to extend the selection capability of pen-based user. In
ACM SIGCHI annual conference (CHI) 2008, (pp. 1371&ndash;1380). New York, NY: ACM.
</p>
<p>Wickens, C. D., Gordon, S. E., &amp; Liu, Y. (1998). An introduction to human factors engineering.
New York, NY: Addison-Wesley.
</p>
<p>Zonta, N., Grimstead, I. J., Avis, N. J., &amp; Brancale, A. (2009). Accessible haptic technology for
drug design applications. Journal of Molecular Modeling, 15(2), 193&ndash;196.
</p>
<p>80 3 Anthropometrics: Important Aspects of Users&rsquo; Bodies</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 4
</p>
<p>Behavior: Basic Psychology of the User
</p>
<p>Abstract This chapter examines what are described as user behavioral charac-
</p>
<p>teristics. These are characteristics that are related to perception in broad terms. The
</p>
<p>chapter starts by defining some behavioral terms and concepts that are used in this
</p>
<p>and subsequent chapters. We then describe in detail several aspects of the two
</p>
<p>main perceptual systems that are involved in interacting with computer-based
</p>
<p>systems: vision and hearing. For each of these aspects we consider some of the
</p>
<p>implications they have for system design. We finish by introducing the topic of
</p>
<p>motivation to help explain why individual users may behave in a particular way
</p>
<p>when carrying out a task.
</p>
<p>4.1 Introduction
</p>
<p>When we refer to behavioral characteristics we are really talking about things that
</p>
<p>are linked to sensation and perception, in general terms. We know that people have
</p>
<p>five basic senses: sight, hearing, touch, smell, and taste. Sensation occurs when the
</p>
<p>sense organs (eyes, ears, and so on) are stimulated, and they generate some form of
</p>
<p>coding of the stimuli. Perception occurs when this coded information is further
</p>
<p>interpreted using knowledge of the current context (physical, physiological, psy-
</p>
<p>chological, and so on) to add meaning. The process of perception is subjective:
</p>
<p>simply presenting designed stimuli in such a way that they will be sensed accu-
</p>
<p>rately does not necessarily mean that they will be perceived in the way that the
</p>
<p>designer intended.
</p>
<p>Sight, hearing, and smell all sense stimuli that appear at some distance from the
</p>
<p>body. In other words they detect distant (distal) stimuli. Touch and taste, however,
</p>
<p>rely on contact being made with the stimuli. This means that the stimuli have to be
</p>
<p>very close to the body, which is why they are described as proximal stimuli.
</p>
<p>We need to think about the user&rsquo;s behavioral characteristics when designing
</p>
<p>systems because we want to make sure that the system fits the user. A well-designed
</p>
<p>system will take into account the user&rsquo;s ability to detect changes in an interface, for
</p>
<p>example, and we can use this information to inform the design of screen layouts to
</p>
<p>F. E. Ritter et al., Foundations for Designing User-Centered Systems,
DOI: 10.1007/978-1-4471-5134-0_4, ï¿½ Springer-Verlag London 2014
</p>
<p>81</p>
<p/>
</div>
<div class="page"><p/>
<p>help the user make themost of that ability. It is also important to remember that these
</p>
<p>abilities will vary across users, tasks, and contexts. If your systemwill be deployed in
</p>
<p>a brightly lit office, for example, then reflected light and glare are likely to affect the
</p>
<p>user&rsquo;s ability to read what is displayed on the screen.
</p>
<p>In most computer-based systems we tend to privilege vision and hearing over
</p>
<p>the other senses, although the rapid uptake of smartphones and tablet computers
</p>
<p>has increased the importance of considering touch (described in Chap. 3). Often it
</p>
<p>is important to consider how the different sensory modalities can be used together
</p>
<p>to provide further useful information to the user. In dark, or dimly lit conditions,
</p>
<p>for example, using different shaped knobs and switches can be used to exploit the
</p>
<p>sense of touch to impart information to the user. Similarly, if a user has impaired
</p>
<p>vision, we may want to present information in such a way that it can be exploited
</p>
<p>by other senses, such as touch and hearing.
</p>
<p>Once we have an understanding of how people sense and perceive things, and
</p>
<p>how the different senses work together, we can start to think about broader design
</p>
<p>questions such as:
</p>
<p>&bull; What is the best way to present information to the user?
</p>
<p>&bull; Can the user detect the information that we are presenting to them?
</p>
<p>&bull; If we are presenting a lot of information to the user, should we be presenting it
</p>
<p>using more than one sensory channel (e.g., visual and auditory channels are
</p>
<p>often both used for alarm information).
</p>
<p>Next, we introduce some basic concepts from behavioral psychology that will
</p>
<p>help you to understand and interpret the rest of the chapter. We then provide quite
</p>
<p>detailed descriptions of the visual and auditory perceptual systems. There are
</p>
<p>many aspects of the visual and auditory systems that need to be considered when
</p>
<p>designing systems. For this reason, we consider the implications for system design
</p>
<p>at the end of each of the sections in this chapter. Note that we omit the senses of
</p>
<p>smell and taste here because their use is almost exclusively limited to systems that
</p>
<p>are dedicated to tasks that only involve detecting particular smells and tastes.
</p>
<p>4.2 Behavioral Psychology Terminology
</p>
<p>Within psychology many terms have been developed to describe different aspects of
</p>
<p>behavior, extending far beyond perception. Here we introduce some terms that may
</p>
<p>help you when thinking about the user and usability with respect to perception.
</p>
<p>4.2.1 Thresholds and Just Noticeable Differences (JNDs)
</p>
<p>Each sense has a threshold for detecting stimuli. Sounds that are too quiet or visual
</p>
<p>stimuli that are too faint cannot be sensed. Table 4.1 gives some representative
</p>
<p>82 4 Behavior: Basic Psychology of the User</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3">http://dx.doi.org/10.1007/978-1-4471-5134-0_3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3">http://dx.doi.org/10.1007/978-1-4471-5134-0_3</a></div>
</div>
<div class="page"><p/>
<p>thresholds under ideal conditions for the various senses (taken from Galanter 1962).
</p>
<p>It should be noted that thresholds can vary across tasks and contexts. In a room full of
</p>
<p>noisy machinery, for example, you may need to increase the volume of alarm
</p>
<p>warning sounds, so that they can be heard by users.
</p>
<p>The sensitivity of perception can be measured, based on how small a change
</p>
<p>can be detected. This difference is called a just noticeable difference, or JND. In
</p>
<p>vision, for example, it is how much brighter a scene has to be in order for someone
</p>
<p>to report it as being brighter; and in hearing it is how much louder a sound must be
</p>
<p>to be noticeably different. Although JNDs are objectively measured, their mag-
</p>
<p>nitude is subjective, varying across users, tasks, contexts, and modality.
</p>
<p>4.2.2 Habituation
</p>
<p>All living things react to stimuli. If a stimulus occurs repeatedly and is not
</p>
<p>regarded as salient they will habituate to it. People who live beside a railroad track,
</p>
<p>for example, grow accustomed to the noise of the trains to a point where they no
</p>
<p>longer notice it. In other words, people learn which stimuli are not salient (in the
</p>
<p>current context), and hence do not require further processing. Habituation effec-
</p>
<p>tively frees up cognitive resources, which allows people to use those resources to
</p>
<p>deal with new stimuli as they are presented. Constant &lsquo;&lsquo;confirm action&rsquo;&rsquo; boxes, for
</p>
<p>example, will become habituated to.
</p>
<p>4.2.3 Signal Detection Theory (SDT)
</p>
<p>Accuracy is an important aspect of performance. In many cases, simple measures of
</p>
<p>correctness, such as the number of targets that were recognized and the number that
</p>
<p>were missed, are sufficient. This is too simple a measure, however, when examining
</p>
<p>performance under conditions where the ability to be correct is difficult, and the
</p>
<p>types of mistakes are important. Table 4.2 provides a way of summarizing this more
</p>
<p>complex situation: if you report seeing something when it is there, it is called a hit;
</p>
<p>if you fail to report seeing something when it is there, it is called a miss. Similarly,
</p>
<p>Table 4.1 Some human sensory thresholds (under ideal conditions)
</p>
<p>Sight A candle flame seen from 50 km on a clear dark night (100 quanta to the eye, or
10 quanta absorbed by the rods)
</p>
<p>Sound The tick of a watch from 6 m in very quiet conditions (0.0002 dynes/cm2)
</p>
<p>Taste One gram of table salt in 500 L of water (0.0001 M)
</p>
<p>Smell One drop of perfume diffused throughout a three room apartment or 1 9 10-12 mol/L of
ethyl merchantman
</p>
<p>Touch The wing of a bee falling on your cheek from a height of 1 cm (10 mg force)
</p>
<p>4.2 Behavioral Psychology Terminology 83</p>
<p/>
</div>
<div class="page"><p/>
<p>reporting seeing nothing where there is nothing there is called a correct rejection,
</p>
<p>whilst reporting seeing something when it is not there is called a false alarm.
</p>
<p>Human visual behavior often includes searching, scanning, and monitoring.
</p>
<p>Vigilance tasks, which are a subset of these tasks, usually involve an extended time
</p>
<p>period between the signals that the user is supposed to recognize. While it should
</p>
<p>be possible to moderate the performance of these tasks based on the dimensions
</p>
<p>used in the table, it is often useful to analyze these situations using Signal
</p>
<p>Detection Theory (SDT) (Swets 1973; Swets et al. 1961; also see Wickens et al.
</p>
<p>2014 or Wickens 2002).
</p>
<p>SDT was developed to explain the task of identifying enemy planes on hard to
</p>
<p>read radar displays. It has been applied to a wide range of classification and
</p>
<p>decision making tasks. Swets (1973), for example, used SDT to summarize how
</p>
<p>well doctors could classify cancer tumors from X-ray films. It can also be applied
</p>
<p>within computer games to explain the potential problems when players search for
</p>
<p>enemies or resources.
</p>
<p>Figure 4.1 shows how the key parameters in SDT relate to the ability to dis-
</p>
<p>tinguish the object of interest (signal) from distracting items (noise). The set of
</p>
<p>signals is assumed to be normally distributed about a point some distance away
</p>
<p>from 0, whilst the set of noise is normally distributed around 0 (indicating no valid
</p>
<p>signal strength). d&rsquo; represents the distance between the mean of the noise and the
</p>
<p>mean of the signal, and is an inherent property of an observer and stimuli.
</p>
<p>Observers set a threshold (here, beta, b, some authors call this lambda, k, or yet
</p>
<p>another Greek character) as a parameter that is inherent in the observer. Obser-
</p>
<p>vations above the threshold are classified by the observer as signal and observa-
</p>
<p>tions below are classified as noise. Thus, the parts of the signal above the threshold
</p>
<p>are hits and the parts of the noise distribution are false alarms (FA). Observations
</p>
<p>below the threshold are either correct rejections (CRs) if they are noise or misses if
</p>
<p>they were part of the signal.
</p>
<p>Observers can often adjust the threshold to take account of the relative costs of
</p>
<p>the four responses in Table 4.2. The cost of false alarms and misses will influence
</p>
<p>where the threshold is set. Where misses are costly, the threshold will be to the left,
</p>
<p>classifying more signal and more noise as positive responses. Where false alarms
</p>
<p>are expensive compared to misses, the threshold will be moved to the right,
</p>
<p>eliminating more of the noise but also part of the signal.
</p>
<p>Signal detection theory is often described in terms of sensitivity and bias. The
</p>
<p>sensitivity (which is the same as d&rsquo;) refers to the separation between the signal and
</p>
<p>noise distributions. Where the separation is small, and the two distributions
</p>
<p>Table 4.2 Types of
responses to a signal
</p>
<p>Response Signal present
</p>
<p>Yes No
</p>
<p>Yes Hit False alarm (FA)
</p>
<p>No Miss Correct rejection (CR)
</p>
<p>84 4 Behavior: Basic Psychology of the User</p>
<p/>
</div>
<div class="page"><p/>
<p>overlap considerably, sensitivity is said to be low. Where the separation is large,
</p>
<p>sensitivity is said to be high. The response bias (which is the same as b) describes
</p>
<p>how conservative the user is in responding. If the user responds conservatively,
</p>
<p>this is because a lot of evidence is needed to be sure that what has been observed is
</p>
<p>really a signal (a true hit), and not just noise.
</p>
<p>4.2.4 Implications for System Design
</p>
<p>It is important to be aware of the context in which your system will be used. A data
</p>
<p>indicator on a display, for example, will be sensed differently in a brightly lit location
</p>
<p>and in a dimly lit location. Users also find it hard to differentiate between elements in
</p>
<p>an interface that use stimuli that are separated by less than a JND (such as two shades
</p>
<p>of the same color). If it is important that some elements on a display which are
</p>
<p>visually similar (such as same shape, but slightly different color) are processed
</p>
<p>differently, they should be made distinct by separating one or more dimensions of
</p>
<p>their appearance by several JNDs (several shades of color, for example).
</p>
<p>If a system generates lots of false alarms or interrupts, users may habituate to
</p>
<p>the alarm sounds, like in Aesop&rsquo;s Fable about the boy who cried wolf. Then, when
</p>
<p>a real emergency happens, users may ignore the alarm. It is therefore crucial to
</p>
<p>minimize the number of false alarms. Pay close attention to how and where alarm
</p>
<p>limits are set, and make sure that you take into account how noisy the data values
</p>
<p>being judged are. This may involve preventing the alarm from oscillating on and
</p>
<p>off when there are recurrent spikes in the values that are due to artifacts such as
</p>
<p>measurement error.
</p>
<p>For systems where the users have to perform vigilance tasks (like monitoring the
</p>
<p>screens of hand luggage scanners at airports to identify dangerous and prohibited
</p>
<p>items), you will need to calculate the costs of false alarms and misses. If the costs are
</p>
<p>high, there are some measures that you can employ to increase the users&rsquo; sensitivity,
</p>
<p>such as showing target examples that they can refer to for comparison, and to
</p>
<p>Threshold ( )
</p>
<p>Noise
Signal
</p>
<p>FAs
</p>
<p>Hits
</p>
<p>Misses
</p>
<p>d'
</p>
<p>Correct
Rejections
</p>
<p>Fig. 4.1 Signal and noise distributions in signal detection theory
</p>
<p>4.2 Behavioral Psychology Terminology 85</p>
<p/>
</div>
<div class="page"><p/>
<p>change their response bias, such as making clear to them the costs of false alarms
</p>
<p>and misses (see Wickens et al. 2014 and Wickens 2002 for more complete lists).
</p>
<p>4.3 The Physiology of Vision
</p>
<p>In the next few sections we examine the details of vision.We start by offering a high-
</p>
<p>level description of the physical structure of the eye. This should help you under-
</p>
<p>stand the basic idea of how vision works and what some of its important limitations
</p>
<p>are. Unlike a camera snapshot, for example, the eye does not capture everything in a
</p>
<p>scene equally, but selectively picks out salient objects and features from the current
</p>
<p>context, and focuses on them so they can be processed in more detail.
</p>
<p>4.3.1 Overview of Vision
</p>
<p>For normally sighted people, vision is by far the most widely used sense. Vision is
</p>
<p>important in everyday work because it allows us to use interfaces like those shown
</p>
<p>in Fig. 4.2. Understanding the basics of how human vision works, including its
</p>
<p>strengths and weaknesses, will help you to design systems that more closely match
</p>
<p>your user&rsquo;s visual capabilities.
</p>
<p>4.3.2 The Basic Structure of the Eye
</p>
<p>Figure 4.3 shows the basic structure of the eye. The important physiological
</p>
<p>features that you need to be aware of are the lens, the retina, the rod and cone cells
</p>
<p>(the sensory receptors in the eye which respond to different light waves), the fovea,
</p>
<p>and the optic nerve.
</p>
<p>When you look at an object, an image of it is projected onto the eye. The angle
</p>
<p>that is subtended by that object at the eye is described as the visual angle. The
</p>
<p>ability to discriminate between two objects that are close together is described as
</p>
<p>visual acuity. This is usually expressed in terms of the minimum visual angle that
</p>
<p>can be resolved, for which the standard is normally a gap subtending 1 min of arc
</p>
<p>(1/60 of a degree). Acuity is usually expressed as a fraction which expresses the
</p>
<p>ratio of the standard distance used in eye-tests (20 ft or 6 m) to the distance at
</p>
<p>which a gap subtends 1 min of arc. So when you hear someone described as having
</p>
<p>20/20 (or 6/6) vision, the numbers refer to their visual acuity.
</p>
<p>The light coming from an object is focused by the lens and projected onto the
</p>
<p>retina at the back of the eye. Muscles attached to the sides of the lens contract in
</p>
<p>order to thicken the lens and bend the light more to achieve a clear focus when the
</p>
<p>86 4 Behavior: Basic Psychology of the User</p>
<p/>
</div>
<div class="page"><p/>
<p>stimulus is near. These muscles relax when the object is further away. This process
</p>
<p>of contracting and relaxing is called accommodation. As people age, the lens
</p>
<p>stiffens, which makes it harder for the muscles to affect its curvature as much, so
</p>
<p>glasses are prescribed to compensate for the reduced level of accommodation.
</p>
<p>The fovea constitutes a small part of the retina, about 1&ndash;2ï¿½ of visual arc, which
</p>
<p>approximately equates to the angle covered by your thumbnail when viewed at
</p>
<p>arm&rsquo;s length. The receptor systems that permit visual acuity are concentrated only
</p>
<p>in the fovea, so we need to fixate on an object to have a clear image of it.
</p>
<p>Surrounding the fovea is the parafovea, which has a lower level of visual acuity
</p>
<p>than the fovea.
</p>
<p>You can demonstrate the existence of the fovea to yourself by staring at a dot in
</p>
<p>the center of a page. Only the area immediately surrounding it will appear in clear
</p>
<p>focus, so to clearly perceive a scene of any size the eyes must move around. These
</p>
<p>semi-conscious movements are called saccades and take approximately 200 ms to
</p>
<p>Fig. 4.2 An interface that has to be recognized quickly and accurately
</p>
<p>Optic Nerve To the brain
</p>
<p>Lens
</p>
<p>Pupil
</p>
<p>R
</p>
<p>R
</p>
<p>PF
</p>
<p>F
</p>
<p>BS
</p>
<p>F
PF
</p>
<p>Fig. 4.3 Basic structure of the eye (not to scale). The retina is the area (roughly circular) from R
to R. The parafovea is from PF to PF. The fovea is from F to F. The blind spot is at BS, where the
optic nerve leaves the eye and blood comes in
</p>
<p>4.3 The Physiology of Vision 87</p>
<p/>
</div>
<div class="page"><p/>
<p>program, and last 20&ndash;200 ms, which is just about the interval of the persistence
</p>
<p>of vision.
</p>
<p>The pupil of the eye reacts to the amount of light falling on the retina by
</p>
<p>expanding and contracting in such a way as to keep that amount approximately
</p>
<p>constant. This feedback mechanism operates within a certain fairly narrow range
</p>
<p>of illumination (about 16&ndash;1), but the enormously greater variation in retinal illu-
</p>
<p>mination (about 109&ndash;1) demands an intermediate mechanism to allow the eye to
</p>
<p>function over the whole range of illumination. This mechanism is called adap-
</p>
<p>tation. Adaptation is one of the most profound and pervasive sensory phenomena.
</p>
<p>Our eyes are prevented from adapting to what they are seeing by continually
</p>
<p>moving. These normal movements, which are normally unnoticeable, are faster
</p>
<p>and smaller than saccades, and described as micro-saccades.
</p>
<p>You may have had the experience of entering a theatre from the bright outdoors
</p>
<p>and stumbling to your seat in the darkness, tripping over the feet of people already
</p>
<p>seated. In a few moments you will have adapted to the darkness, that is, you have
</p>
<p>become more accustomed to the lack of light. This mechanism applies to the sense
</p>
<p>of smell too: when walking into a kitchen where someone is cooking you will
</p>
<p>notice the odors as very strong, but after a few minutes they become less
</p>
<p>noticeable. These examples illustrate that after exposure to a stimulus the sensi-
</p>
<p>tivity to that stimulus reduces; after removal of the stimulus, the sensitivity returns.
</p>
<p>4.3.3 Using Eye-Tracking to Measure Eye Movements
</p>
<p>A lot has been learned about how people read and use interfaces by using eye
</p>
<p>trackers (Duchowski 2007; Holmqvist et al. 2011). Eye trackers are electro-optical
</p>
<p>systems (typically cameras that can be automatically focused and adjusted) that
</p>
<p>record where a user has focused their eyes. Simple systems measure where a single
</p>
<p>eye is looking. Better versions of this simple system can do this without the user
</p>
<p>having their head fixed, and many can now measure this non-intrusively.
</p>
<p>Figure 4.4 shows a head-mounted eye-tracker and two example summaries of eye-
</p>
<p>tracking data. More complex systems can measure both eyes and note how the
</p>
<p>eyes work together (e.g., strabismus, a measure of how much the eyes have
</p>
<p>focused onto something near to the head by rotating).
</p>
<p>Simple eye-trackers can generally tell which line the user is looking at (to an
</p>
<p>accuracy of typically 0.5&ndash;1ï¿½ of angular measure, which is about a line of 12 point
</p>
<p>text on a display at 12 in.). Better eye trackers can tell which letter or which part of
</p>
<p>the letter the user is focusing on (down to 0.25ï¿½).
</p>
<p>A useful exercise that will help you to appreciate the accuracy of eye-trackers is
</p>
<p>to compute the size of a 10 point (1/7 in.) letter at 12 in. using trigonometry.
</p>
<p>When you have done this, you should see that the tolerance in eye-tracker accuracy
</p>
<p>is less than the size of the fovea. So although we may know where the center of the
</p>
<p>user&rsquo;s fovea is focused, there could be several other items that are also projecting
</p>
<p>onto it and to which the user is attending.
</p>
<p>88 4 Behavior: Basic Psychology of the User</p>
<p/>
</div>
<div class="page"><p/>
<p>In addition to being widely used in psycholinguistics to understand how people
</p>
<p>read text, eye-tracking is increasingly being used in other fields such as HCI and
</p>
<p>advertising (Moore and Churchill 2011; Navalpakkam and Churchill in press;
</p>
<p>Nielsen and Pernice 2010). The availability of relatively cheap, non-intrusive
</p>
<p>trackers has seen them being used more widely in exploring how people process the
</p>
<p>text on web pages. With the use of appropriate software you can quickly identify the
</p>
<p>hot spots on a page, which are areas that the users look at for most of the time.
</p>
<p>4.3.4 Rods and Cones
</p>
<p>The retina at the back of the eyeball is composed of two basic types of cells&mdash;rods
</p>
<p>and cones&mdash;organized in layers. The rods and cones sense light, and mark the start
</p>
<p>of the transition from sensation to perception with light energy being converted
</p>
<p>into electrical energy.
</p>
<p>According to duplicity theory, the differences between the rods and cones result
</p>
<p>in two different receptor systems in the eye: one that is best suited to daylight, and
</p>
<p>one best suited to twilight or moonlight. There are 6 million cones, mostly located
</p>
<p>in the fovea. These function in daylight conditions and are responsible for color
</p>
<p>vision. The 120 million rods are distributed across the retina beyond the fovea.
</p>
<p>Fig. 4.4 A head-mounted eye-tracker and an example analysis showing the order that a user
looked at the interface (top) and how long they looked at each part (bottom) (photo by Ritter, used
with permission of the analyst pictured; analyses courtesy of Maik Friedrich 2008)
</p>
<p>4.3 The Physiology of Vision 89</p>
<p/>
</div>
<div class="page"><p/>
<p>They are much more sensitive to light than the cones and are active in dark
</p>
<p>conditions; in bright conditions they become overloaded. The distributions of rods
</p>
<p>and cones overlap in the parafovea. The rods are mostly located beyond the
</p>
<p>parafovea, in the periphery of the retina, and are very sensitive to movement.
</p>
<p>The visual receptors respond to light waves. The term light is used to describe
</p>
<p>electromagnetic energy in the visible range of wavelengths approximately
</p>
<p>400&ndash;700 nm (see Fig. 4.5). The wavelengths that we see are determined by the
</p>
<p>physics of the eye and the chemistry of the photoreceptor pigments in the eye.
</p>
<p>Electromagnetic energy with wavelengths below the visible spectrum includes
</p>
<p>ultraviolet rays, X-rays, and gamma rays; electromagnetic energy with wavelengths
</p>
<p>above the visible spectrum includes infrared rays, microwaves, and radio waves.
</p>
<p>Our sensitivity to spectral radiation is not constant across the electromagnetic
</p>
<p>spectrum. Instead, we sample it through a pair offilters. The first filter is provided by
</p>
<p>the spectral sensitivity of the rods, which have a maximum sensitivity around
</p>
<p>500 nm (498 in Fig. 4.5). The second is provided by the pooled responses of the three
</p>
<p>types of cones (the leftmost and two rightmost curves in Fig. 4.5) and has maximum
</p>
<p>sensitivity around 555 nm. Below 380 nm (infrared) and above 700 nm (ultraviolet)
</p>
<p>we are effectively blind to electromagnetic waves. Therefore, there is a wide range of
</p>
<p>information that meets our eyes which falls outside our window of visibility.
</p>
<p>Although we sense infrared energy as heat, other wavelengths outside the
</p>
<p>visible spectrum are imperceptible without the aid of devices such as radios or
</p>
<p>infrared goggles. Ultraviolet energy is destructive to living tissue, so it is filtered
</p>
<p>out by the yellow pigment in the lens of the eye. People who have had their lenses
</p>
<p>removed because of cataracts, however, can see ultraviolet energy as light. Rather
</p>
<p>than experiencing it as a new color sensation, which would require another type of
</p>
<p>cone, they see it as the same color that people with normal vision would see violet.
</p>
<p>Fig. 4.5 Diagram of sensitivity in nanometers (nm) of rods and cones (reprinted with permission
from Bowmaker and Dartnall 1980)
</p>
<p>90 4 Behavior: Basic Psychology of the User</p>
<p/>
</div>
<div class="page"><p/>
<p>When you switch from looking at colored objects in bright light to looking at
</p>
<p>the same objects in dim light, all other things being equal you will notice that one
</p>
<p>object now seems brighter than the other. If you look at a blue flower and a red
</p>
<p>flower, for example, first in daylight and then at dusk, you will notice that under
</p>
<p>low illumination both appear faded, but the blue seems brighter than the red.
</p>
<p>Likewise, a piece of green paper and a piece of red paper which are matched for
</p>
<p>brightness in good light will not be matched in dim light. This effect is called the
</p>
<p>Purkinje Shift, and is based on the fact that long wavelength colors such as red
</p>
<p>appear duller under low illumination than shorter wavelength colors (such as blue).
</p>
<p>The effect occurs because of the shift from high illumination vision (cones) to low
</p>
<p>illumination vision (rods) under different light conditions. The rods are relatively
</p>
<p>more sensitive to light in the blue region than the cones, hence the apparent greater
</p>
<p>brightness of the blue flower in dim light. These relationships can be seen in
</p>
<p>spectral sensitivity curves that illustrate that maximum sensitivity goes from red to
</p>
<p>blue green (i.e., to shorter wavelengths) when we shift from bright to dim light and
</p>
<p>from the cones to the rods.
</p>
<p>One final point about rods and cones: there is one part of the retina where there
</p>
<p>are no receptors (rods or cones) present. This is where the optic nerve leaves the
</p>
<p>retina. When the image of an object falls on this blind spot, nothing is seen. You
</p>
<p>can use Fig. 4.6 to help you find your own blind spot. The blind spot is in a
</p>
<p>different place for each eye.
</p>
<p>4.3.5 Implications for System Design
</p>
<p>If your system is going to be deployed in an area where users experience large
</p>
<p>step changes in lighting conditions on entering that area (from light to dark or vice
</p>
<p>versa) you will need to take account of the fact that their eyes will need time to
</p>
<p>adapt to the new lighting conditions. You could consider having gradual changes
</p>
<p>in lighting levels as they enter the area, for example.
</p>
<p>People will often use a relatively large dialog box positioned in the center of the
</p>
<p>screen to get the user&rsquo;s attention for something that is important. This dialog box is
</p>
<p>usually large enough to project an image onto the retina that fills a significant
</p>
<p>portion of the fovea. It would be equally possible to capture the user&rsquo;s attention by
</p>
<p>make an item on the display screen move, or make it flash or blink, as long as
</p>
<p>Blind
spot 1 2 3 4 5 6 7 8 9 ba c
</p>
<p>Fig. 4.6 Cover your right eye and focus directly on a digit with your left eye. Then move the
page away from your head. At about a foot the word blind spot will disappear. The location of the
blind spot and screen sizes will vary, so you may have to try different focus points
</p>
<p>4.3 The Physiology of Vision 91</p>
<p/>
</div>
<div class="page"><p/>
<p>the item is located in a position that projects onto the periphery of the retina.
</p>
<p>In this way the movement or flashing gets detected by the rods in the eye. There is
</p>
<p>a negative implication here too: if your user is carrying out an important task that
</p>
<p>requires high levels of concentration using the display screen, you should try to
</p>
<p>avoid having items on the screen move or flash, particularly if they would project
</p>
<p>onto the periphery of the user&rsquo;s eye.
</p>
<p>If you are designing a system that has to be operated in light sensitive condi-
</p>
<p>tions, such as a photography dark room or a radar operations room, you need to
</p>
<p>consider how you can help the users see so that they can carry out their tasks in the
</p>
<p>dimly lit conditions. Usually in these situations, red light is used to illuminate
</p>
<p>the rooms, albeit at quite low levels. The rods are relatively less sensitive to light at
</p>
<p>the red end of the visible spectrum, which means that the rods start dark adapting
</p>
<p>even though there is still some light available.
</p>
<p>In most cases people using technology work at arm&rsquo;s length from their display
</p>
<p>screen. This means that the blind spot is usually not a problem, because the brain
</p>
<p>processes the images from both eyes together to perceive what is on the screen. If
</p>
<p>you have a system which requires the user to be much closer to the screen, and
</p>
<p>they are not detecting some items that are important, you should consider inves-
</p>
<p>tigating whether those items are in fact located in their blind spot.
</p>
<p>4.4 Low Level Visual Perception
</p>
<p>Here we consider the low level details of vision. These range from how light is
</p>
<p>detected, through various aspects associatedwith color, to flicker and pop-out effects.
</p>
<p>Several of these aspects of low-level vision have implications for system design.
</p>
<p>4.4.1 Vision and the Measurement of Light
</p>
<p>There are two important ways in which light gets from an object to the eye:
</p>
<p>incident light (light falling on an object) and reflected light (light reflected from an
</p>
<p>object). Incident light is referred to as illuminance whereas reflected light is termed
</p>
<p>luminance. White surfaces typically have reflectances of 80% and black surfaces
</p>
<p>around 10%.
</p>
<p>Luminance is measured in candelas per square meter (cd/m2). As the luminance
</p>
<p>of an object increases, so does the eye&rsquo;s visual acuity or ability to discern small
</p>
<p>details. The pupil&rsquo;s diameter decreases and therefore increases the depth of focus in
</p>
<p>the same way as a standard camera lens when the aperture is adjusted. An increase in
</p>
<p>luminance of an object or display will also make the eye more sensitive to flicker.
</p>
<p>Contrast describes the relationship between light emitted from an object and
</p>
<p>light emitted from the surrounding background. It is defined as the difference
</p>
<p>92 4 Behavior: Basic Psychology of the User</p>
<p/>
</div>
<div class="page"><p/>
<p>between the luminance of the object and its background divided by the luminance
</p>
<p>of the background, as shown in Eq. (4.1).
</p>
<p>Object Luminanceï¿½ Background luminance&eth; &THORN;=Background Luminance &eth;4:1&THORN;
</p>
<p>The contrast will be positive if the object is emitting more light than the
</p>
<p>background and negative if the background is emitting more light than the object.
</p>
<p>Objects can therefore be described as having positive or negative contrast.
</p>
<p>Brightness is a subjective response to light. There is no real means of measuring
</p>
<p>absolute levels of brightness but, in general, a high luminance from an object
</p>
<p>implies a high brightness. It is possible to experience odd effects at high-to-low
</p>
<p>brightness boundaries, as shown in the left part of Fig. 4.7, which is called a
</p>
<p>Hermann grid. Designers should be wary of creating effects like the Hermann grid
</p>
<p>(in the center of Fig. 4.7) because they can be distracting. Adding color or shading
</p>
<p>can remove this effect. Indeed, the design of folders on most modern desktops
</p>
<p>avoids this by increasing the spacing of the icons both vertically and horizontally,
</p>
<p>but this choice costs display space.
</p>
<p>Related to the Hermann grid are the concepts of figure and ground: figure refers
</p>
<p>to the objects that are to be attended to; ground refers to the background objects. In
</p>
<p>Fig. 4.7 the boxes and files are the figure and the white background is the ground.
</p>
<p>When the objects are placed too close together, however, the perceived gray fill
</p>
<p>that results can become more prominent and appear to be part of the figure. It is
</p>
<p>important to consider keeping objects that are figure prominent, and maintaining a
</p>
<p>useful ground.
</p>
<p>The interpretation of Fig. 4.8 is based on figure and ground. If the white is
</p>
<p>perceived as the figure, it appears to be a vase or a goblet; if the black is the figure,
</p>
<p>it appears to be two heads.
</p>
<p>The objects that you want the users to see or distinguish need to be appropri-
</p>
<p>ately sized. In good viewing conditions a minimal perceptible visual angle of about
</p>
<p>15 min of arc should be maintained and in poor viewing conditions this should be
</p>
<p>increased to 21 min. These correspond to a 4.3-mm object and a 6.1-mm object,
</p>
<p>respectively, viewed from 1 m.
</p>
<p>The full field of view for a stationary forward looking eye covers about 208ï¿½
</p>
<p>horizontally (although it is blocked by the head and the nose at certain points), and
</p>
<p>about 120ï¿½ vertically. This only refers to light falling on the eye, and does not
</p>
<p>File1 File2
</p>
<p>File5 File6
</p>
<p>File3 File4
</p>
<p>File7 File8
</p>
<p>File9 File10
</p>
<p>File13 File14
</p>
<p>File11 File12
</p>
<p>File15 File16
</p>
<p>File1 File2
</p>
<p>File5 File6
</p>
<p>File3 File4
</p>
<p>File7 File8
</p>
<p>File9 File10
</p>
<p>File13 File14
</p>
<p>File1 1 File12
</p>
<p>File15 File16
</p>
<p>Fig. 4.7 A Hermann grid on the far left. In the center a similar effect in a file system. Adding
shading and color removes the effect on the right
</p>
<p>4.4 Low Level Visual Perception 93</p>
<p/>
</div>
<div class="page"><p/>
<p>necessarily mean that something will be seen when the signals are further pro-
</p>
<p>cessed. The field of view is an important factor in determining the size of a
</p>
<p>particular display screen or the layout of displays and control equipment.
</p>
<p>4.4.2 Color Vision
</p>
<p>Color is the result of perception, and is not an intrinsic part of an object. The
</p>
<p>corollary of this is that, under different lighting or contrast conditions, the apparent
</p>
<p>color of an object will change. There are some terms that you should be aware of
</p>
<p>when thinking about color vision.
</p>
<p>Lightness is a measure on the black&ndash;white dimension of how close to white the
</p>
<p>color is (100% is white, or bright). The amount of color that there is in the light is
</p>
<p>described by its saturation, which refers to the purity of the sensation as opposed
</p>
<p>to grayness: the higher the saturation, the higher the purity of color. Hue is pri-
</p>
<p>marily dependent on wavelength; it is closest to the way that the term color is used
</p>
<p>in everyday language.
</p>
<p>If the wavelength of visible light is varied over its range (400&ndash;700 nm), with
</p>
<p>constant luminance and saturation, a person with normal color vision can distin-
</p>
<p>guish about 1,200 differences in color. If luminance and saturation are also varied,
</p>
<p>approximately 8,000 differences in color can be distinguished. When the viewing
</p>
<p>is carried out in isolation by a person with normal color vision, however, only 8&ndash;10
</p>
<p>Fig. 4.8 A Rubin vase that
can be interpreted as a vase or
two heads facing each other
</p>
<p>94 4 Behavior: Basic Psychology of the User</p>
<p/>
</div>
<div class="page"><p/>
<p>different colors can be identified accurately without training. If you need more than
</p>
<p>8&ndash;10 distinct colors you may need to use texture or text to provide features to
</p>
<p>assist the user in discriminating between them.
</p>
<p>People&rsquo;s sensitivity to color is not uniform across their field of view. The eye is
</p>
<p>not sensitive to color at the periphery of vision. Accurate discrimination of color is
</p>
<p>only possible to around 60ï¿½ from the straight ahead position (with the head and the
</p>
<p>eyes stationary) and the limit of color awareness (as opposed to discrimination) is
</p>
<p>approximately 90ï¿½ from the straight ahead position. The eye is best suited to the
</p>
<p>perception of yellow-green light, and color is only well perceived in foveal
</p>
<p>(central) vision. It is least sensitive to red, green, and yellow light at the periphery
</p>
<p>of color vision where it is most sensitive to blue light. This variation in sensitivity
</p>
<p>arises from the way that the rods and cones are distributed in the fovea.
</p>
<p>Perceptions of a particular color are affected by prolonged exposure to other
</p>
<p>colors&mdash;this is because different cones are responsive to different dimensions of
</p>
<p>color (e.g., red&ndash;green or yellow&ndash;blue). Looking at red light, for example, causes
</p>
<p>the red cones to become adapted, so the red light reduces in salience. This is often
</p>
<p>seen in color after effects, or afterimages. There are also several visual illusions
</p>
<p>you may have seen where you first stare at a picture or a display until the colors
</p>
<p>apparently disappear, and then when you look at another picture or a blank piece of
</p>
<p>paper the complementary colors appear.
</p>
<p>Color constancy refers to the situation in which we attempt to perceive colors as
</p>
<p>being the same even when they are different. Our clothes do not change color when
</p>
<p>we go indoors, for example. The wavelengths hitting the retina may have changed,
</p>
<p>however, and the reflected light will be different, although we will still perceive
</p>
<p>the colors to be the same. Vegetables and meat in supermarkets are one of the most
</p>
<p>compelling examples of constancy not working&mdash;stores tend to be lit so that
</p>
<p>objects give off particular wavelengths&mdash;when you get home with different
</p>
<p>lighting the colors are substantially duller.
</p>
<p>4.4.3 Color Blindness
</p>
<p>It is important to be aware of color blindness (or, more strictly color vision
</p>
<p>deficiency) because around 7% of Western men and 0.5% of Western women are
</p>
<p>red&ndash;green color deficient. In other words they are bichromats, because they can
</p>
<p>only distinguish two primary colors (typically they cannot tell red from green).
</p>
<p>Other cues, such as brightness, can be used to help distinguish red from green.
</p>
<p>Most of us can discriminate between all three primary colors (red, green, and
</p>
<p>blue), and are known as trichromats because we have three types of cones for
</p>
<p>seeing color. Quadchromats appear to have better color discrimination under
</p>
<p>different lighting conditions, but see the same colors. Many animals are mono-
</p>
<p>chromats: they cannot distinguish any colors because they have only one set of
</p>
<p>cones (or just rods). They hence perceive the world in monochrome.
</p>
<p>4.4 Low Level Visual Perception 95</p>
<p/>
</div>
<div class="page"><p/>
<p>4.4.4 Color Systems
</p>
<p>There are many theories of how we perceive color (Sekuler and Blake 2005).
</p>
<p>There are a lot of technical details and tools available which allow us to make
</p>
<p>quite strong predictions about color perception. For our purposes, the most
</p>
<p>important thing to remember is the high level distinction between the two ways
</p>
<p>that we perceive color: additive and subtractive.
</p>
<p>Computer displays use projected light (for the most part) and printed paper uses
</p>
<p>reflected light. Projected light uses a different set of primary colors, the additive
</p>
<p>colors of red, green, and blue (often referred to as RGB), while reflected light use
</p>
<p>the subtractive colors: cyan, magenta, and yellow (with black as the key color,
</p>
<p>which is why they are often referred to as CMYK). The additive colors start from
</p>
<p>black, no light, and then add colors to get other colors, and then, when all are
</p>
<p>added, white is produced. The subtractive colors remove colors from white,
</p>
<p>effectively reducing the amount of light that is reflected, and ending up at black.
</p>
<p>Thus, with current technology it is hard to get a pure black color on a display
</p>
<p>screen (at least some of the lights tend to stay on), although it is possible to get
</p>
<p>closer to pure black using subtractive colors.
</p>
<p>The colors from printed materials cannot completely match the colors from a
</p>
<p>screen because of the way the two different color systems work. There are some
</p>
<p>tools available that can help you make the two match more closely, however, but
</p>
<p>in the end the choice of how closely you make them match may be down to
</p>
<p>personal preference.
</p>
<p>4.4.5 Flicker
</p>
<p>People are sensitive to flickering lights. The flicker can be made imperceptible,
</p>
<p>however, by using rates that exceed the flicker fusion rate. In the early days of the
</p>
<p>movies, cinema films ran at a frame rate below the flicker fusion rate, which is why
</p>
<p>any movements appear jerky and you can still detect the flicker (which explains
</p>
<p>why they were often referred to as the flicks). In modern cinema, the flicker
</p>
<p>problems is overcome by typically showing films at 24 frames per second, with the
</p>
<p>image being presented twice per frame on two-blade shutter projectors, and three
</p>
<p>times per frame on three-blade shutter projectors.
</p>
<p>It should be noted, however, that lights which flicker at a rate of 7&ndash;10 cycles per
</p>
<p>second1 can trigger epileptic fits in some people. Series 500 of the ISO 9241
</p>
<p>standard on ergonomics of human&ndash;computer interaction is a guideline that
</p>
<p>addresses this issue for display screen equipment, and you sometimes hear
</p>
<p>warnings about flickering lights and images before they appear during a television
</p>
<p>1 You will also see this measure in Hertz: 1 Hz is 1 cycle per second.
</p>
<p>96 4 Behavior: Basic Psychology of the User</p>
<p/>
</div>
<div class="page"><p/>
<p>program. The effect of flicker in system design is decreasing as the refresh rate of
</p>
<p>most displays are so fast that flicker is becoming less of a problem.
</p>
<p>4.4.6 Pop-Out Effects
</p>
<p>One of the most useful applications of vision to interface design is to take
</p>
<p>advantage of how the eye searches. One of the most useful effects is that certain
</p>
<p>stimuli &lsquo;pop out&rsquo; from other stimuli. Figure 4.9 shows that with a bunch of Cs, Ts
</p>
<p>pop-out, and Os do not pop-out. Similar effects can be found for color, and a few
</p>
<p>other features (Treisman and Gelade 1980).
</p>
<p>Figure 4.10 shows an application of this and a few other effects. First, you have
</p>
<p>some object recognition that occurs&mdash;a car and building and perhaps some signs
</p>
<p>are recognized. Then you have some automatic processes occur, you are expert at
</p>
<p>reading so words appear as well, and these pop-out to a certain extent. You also
</p>
<p>have the ability to read words, and these appear. Expertise and previous experience
</p>
<p>also counts. If you have not heard of French Connection&mdash;UK (FCUK), your
</p>
<p>automatic processes may read it as something else. This result is not a true pop-out
</p>
<p>effect, but it is a related phenomenon, the word completion effect.
</p>
<p>Providing multiple encoding of search items also helps in a visual search
</p>
<p>(Garner 1974). In Fig. 4.11 targets are encoded in several ways using multiple
</p>
<p>features. Highlighting visual targets using just two discriminating features often
</p>
<p>helps users find them, particularly if the encoding is not taught to users but is just
</p>
<p>inherent in the interface.
</p>
<p>Some feature differences will pop-out to users (Treisman and Gelade 1980).
</p>
<p>Differences in color, when there is not much color, and straight line segments in a
</p>
<p>set of smooth curves will both pop-out. Partially open circles will not pop-out
</p>
<p>when mixed with circles and slight changes in size will not pop-out. Figure 4.11
</p>
<p>C  C  C  C  C  C  C  C  C  C C  C  C  C  C  C  C  C  C  C
</p>
<p>C  C  C  C  C  C  C  C  C  C C  C  O  C  C  C  C  C  C  C
</p>
<p>C  C  C  C  C  T  C  C  C  C C  C  C  C  C  C  C  C  C  C
</p>
<p>C  C  C  C  C  C  C  C  C  C C  C  C  C  C  C  C  C  C  C
</p>
<p>C  T  C  C  C  C  C  C  C  C C  C  C  C  C  C  O  C  C  C
</p>
<p>C  C  C  C  C  C  C  C  C  C C  C  C  C  C  C  C  C  C  C
</p>
<p>Fig. 4.9 The left half of the figure shows a bunch of Cs and Ts. The right half shows a bunch of
Cs and Os. You should be able to see that the Ts pop-out from the Cs whereas the Os do not
</p>
<p>4.4 Low Level Visual Perception 97</p>
<p/>
</div>
<div class="page"><p/>
<p>has the targets modified with some differences that will pop-out and some dif-
</p>
<p>ferences that will not pop-out.
</p>
<p>Pop-out effects can be used to highlight spelling mistakes (as shown in
</p>
<p>Fig. 4.12), to highlight a target file within a folder, and to highlight target words on
</p>
<p>web pages during a search.
</p>
<p>Fig. 4.10 Sign for French Connection-UK, taken in Bath, England. Note the effects of automatic
processing, the word completion effect, on multiple sets of letters in this picture
</p>
<p>C  C  C  C  C  C  C  C  C  C C  C  C  C  C  C  C  C  C  C
</p>
<p>C  C  C  C  C  C  C  C  C  C C  C  C  C  C  C  C  C  C  C
</p>
<p>C  C  C  C  C  C  C  C  C  C
</p>
<p>C  C  C  C  C  C  C  C  C  C C  C  C  C  C  C  C  C  C  C
</p>
<p>C  C  C  C  C  C  C  C  C  C C  C  C  C  C  C  O  C  C  C
</p>
<p>C  C  C  C  C  C  C  C  C  C C  C  C  C  C  C  C  C  C  C
</p>
<p>C  C  C  C  C  Z  C  C  C  C
</p>
<p>Fig. 4.11 A picture showing a bunch of Cs and a Z and an O with the Z and O in bold,
highlighted, slightly larger to provide three features that can pop-out. The Z has more features
different so it will pop-out more easily. The O without the shading would be harder to find
</p>
<p>98 4 Behavior: Basic Psychology of the User</p>
<p/>
</div>
<div class="page"><p/>
<p>Fig. 4.12 Example uses of visual encoding to highlight spelling mistakes. On the left, a mail
system underlines and makes the misspelled word appear in red; on the right, Microsoft Word
puts a wavy red line under the word
</p>
<p>Fig. 4.13 The use of color and luminance on aircraft displays facilitates the finding of particular
information (this will be less apparent in b/w versions of this figure!)
</p>
<p>4.4 Low Level Visual Perception 99</p>
<p/>
</div>
<div class="page"><p/>
<p>4.4.7 Implications for System Design
</p>
<p>It has long been a rule of thumb that you should use color sparingly on display
</p>
<p>screens. In other words, you just use color to emphasize the things that are
</p>
<p>important. If your system has displays that rely on widespread use of color, and
</p>
<p>there is meaning associated with the different colors, you should check to make
</p>
<p>sure that the exposure to the dominant color on the screen is not adversely
</p>
<p>affecting the perception of some of the other (possibly more important) colors.
</p>
<p>When you do use color to encode items on a display, you need to make sure that
</p>
<p>the users can perceive the colors that you are using. Figure 4.13, for example,
</p>
<p>shows how color can be used to help users find information. The artificial horizon
</p>
<p>display above the throttle levers has blue sky and brown ground. The center
</p>
<p>displays have green and yellow and orange text to help separate information. If
</p>
<p>you are designing safety critical systems or interfaces used by a wide range of
</p>
<p>users, you should consider using redundant information to help people with red-
</p>
<p>green color vision deficiency distinguish between these two colors on the screen.
</p>
<p>If you are developing a system which must produce color print-outs, and the
</p>
<p>colors and the differences between colors are important, you will have to take into
</p>
<p>account the fact that the colors on the screen and on the print-out will appear
</p>
<p>somewhat different. You will therefore need to find a way to make the two rep-
</p>
<p>resentations match as closely as possible, which may involve using third party
</p>
<p>software. This process may be further complicated by the fact that different makes
</p>
<p>of color printer can produce print-outs of the same screen image that look different.
</p>
<p>Nowadays the flicker rate of most display screens is high enough for the flicker
</p>
<p>to be imperceptible. There is some evidence, however, that the flicker rate can
</p>
<p>affect how people read, because it changes the size of the saccadic eye movements
</p>
<p>that take place during reading (e.g., see Kennedy and Baccino 1995). If you are
</p>
<p>developing a system which requires people to read large amounts of text from the
</p>
<p>display, you may want to make sure that you choose display screen hardware that
</p>
<p>has a flicker rate that minimizes the amount of interference on reading.
</p>
<p>If you are designing a system where you need the user to focus on one (or more)
</p>
<p>particular items on a densely populated screen, you should consider whether you
</p>
<p>can make those items pop-out from the display by appropriately changing some of
</p>
<p>the items&rsquo; features. There is a potential downside of working with densely pop-
</p>
<p>ulated displays too, in that there may be some items which pop-out of the display
</p>
<p>when you do not want them to. In these cases you would have to consider how you
</p>
<p>could make those items appear more similar to the surrounding items.
</p>
<p>4.5 Higher Level Visual Perception
</p>
<p>In addition to how low level aspects of the eye influence perception, there are
</p>
<p>several higher level aspects of vision that influence cognition. Several of the
</p>
<p>100 4 Behavior: Basic Psychology of the User</p>
<p/>
</div>
<div class="page"><p/>
<p>results here have different interpretations, as to whether they are the result of
</p>
<p>vision or the result of cognition. A comprehensive theory of the user would
</p>
<p>incorporate this interaction between vision and cognition. Being aware of the
</p>
<p>higher level perceptual issues can help you design better interfaces.
</p>
<p>4.5.1 Movement and Spatial Perception
</p>
<p>Movement can be detected either by moving ourselves (even though the image
</p>
<p>falls on the same part of the retina) or by staying still whilst the image moves
</p>
<p>across the retina. The processing of the stimuli related to body movements and
</p>
<p>visual stimuli are combined because we can track a still object with our eyes while
</p>
<p>moving our bodies and yet be sure that it is still.
</p>
<p>Above a certain speed of movement the eye can spontaneously track a moving
</p>
<p>object. Ask someone to slowly wave a small light (about as bright as a lit match)
</p>
<p>around in a darkened room and follow it with your eyes. The movement of the
</p>
<p>light will be seen even though no image is moving across the retina (because your
</p>
<p>eyes will keep it constantly on the retina). The periphery of the retina is the area
</p>
<p>most sensitive to movement, but it is very difficult to identify an object at the
</p>
<p>extreme periphery of the field of view. The detection of a moving object in the
</p>
<p>periphery of the eye is what usually initiates the movement of the eye in pursuit of
</p>
<p>that object so that it can be brought into focus on the fovea. Movement may also be
</p>
<p>perceived as afterimages when both the eye and the retinal image are stationary
</p>
<p>(this effect is due to adaptation of the motion detectors in the eye). Thus, the eye
</p>
<p>and the brain combine their results to get this apparent motion.
</p>
<p>4.5.2 Depth Cues
</p>
<p>Spatial perception is determined from the muscular activity of the two eyes and
</p>
<p>discrepancies between the two images that are formed. When we want to display a
</p>
<p>3D image on a screen, we have to represent the 3D image using just two
</p>
<p>dimensions, although better 3D displays continue to appear. We can simulate
</p>
<p>depth perception using the discrepancy between the two images, as well as the
</p>
<p>perceptual depth cues listed in Table 4.3.
</p>
<p>In the real world, motion parallax may be one of the most important cues that
</p>
<p>enable us to perceive distance and depth. It occurs when we move our heads from
</p>
<p>side to side and we see objects displaced at different rates. Objects that are further
</p>
<p>away appear to move more slowly than objects that are closer. In screen design,
</p>
<p>the trick is to move the viewpoint of the &lsquo;&lsquo;camera&rsquo;&rsquo; so that the image on the screen
</p>
<p>moves according to the principles of motion parallax. This is not used in most non-
</p>
<p>game interfaces, although virtual reality systems provide it, and video games
</p>
<p>provide it through motion of objects.
</p>
<p>4.5 Higher Level Visual Perception 101</p>
<p/>
</div>
<div class="page"><p/>
<p>4.5.3 Subitizing
</p>
<p>Figure 4.14 shows that the curve for counting objects presented visually in a psy-
</p>
<p>chology experiment (not that appear one at a time like train cars or a haptic situ-
</p>
<p>ation like counting coins in your pocket) has a bend on it at about between 3 and 4.
</p>
<p>Up to three objects, you recognize the number effectively, with about 50 ms dif-
</p>
<p>ference per object, above four and certainly at five, you have to count the objects, so
</p>
<p>the time to respond increases by about 250&ndash;300 ms/object. The first part of the
</p>
<p>curve is called subitizing, and is thought to be an effect of the architecture of the
</p>
<p>perceptual system.
</p>
<p>Given the effect of subitizing, if you are passing sets of information to a user, or
</p>
<p>giving them things to count, understand that smaller numbers are much faster to
</p>
<p>recognize and count than larger numbers. In a related effect, if you are counting
</p>
<p>Table 4.3 Perceptual depth cues
</p>
<p>Size The larger of two otherwise identical objects appears to be closer than
the smaller one
</p>
<p>Interposition If one object partially occludes a second object then the blocked object
is perceived to be behind and beyond the blocking object
</p>
<p>Contrast, clarity and
brightness
</p>
<p>Sharper and more distinct objects appear to be nearer, and duller objects
appear to be farther away
</p>
<p>Shadow Shadows cast by an object provide some cues about the relative position
of objects
</p>
<p>Texture As the apparent distance increases, the texture of a detailed surface
becomes less grainy
</p>
<p>Motion parallax When moving one&rsquo;s head from side to side the objects one sees are
displaced at different rates
</p>
<p>Stereoscopic depth Two images of the same object from slightly different angles are
presented separately to each eye. Perceived depth is induced through
the fusion of the two images. This is often used in virtual reality
</p>
<p>Fig. 4.14 The time to count
objects as the number of
objects varies from one to
eight. Counts from one to
three are substantially faster
per item than for five and
greater (reprinted with
permission from Peterson and
Simon 2000)
</p>
<p>102 4 Behavior: Basic Psychology of the User</p>
<p/>
</div>
<div class="page"><p/>
<p>based on a fixed number of objects you can track, then you cannot expect users to
</p>
<p>follow more than three or four objects on the screen.
</p>
<p>4.5.4 Gestalt Principles of Grouping
</p>
<p>The Gestalt principles of visual grouping (listed in Table 4.4) can be used to
</p>
<p>explain how groups of objects are interpreted. The principles were developed as a
</p>
<p>rebellion against the simplistic notion that perception could be structurally ana-
</p>
<p>lyzed into its component parts, and that complex ideas were the result of associ-
</p>
<p>ating together simpler ones. This simplistic view dominated psychology in the late
</p>
<p>nineteenth and early twentieth centuries. The Gestalt principles allow that the
</p>
<p>whole can be more than just the sum of the parts.
</p>
<p>Gestaltists focused on the fact that there are important aspects of form and
</p>
<p>structure. We see the world as composed of discrete objects of various sizes that
</p>
<p>are seen against a background comprised of textured surfaces. The spatial and
</p>
<p>temporal relationships between elements are as important as the absolute size,
</p>
<p>location, or nature of the elements themselves, and a sensation-based account of
</p>
<p>perception fails to capture this. Some of the principles of visual grouping are
</p>
<p>illustrated in Fig. 4.15.
</p>
<p>4.5.5 Other Theories of High Level Visual Perception
</p>
<p>There are several other views of visual perception apart from the psycho-physi-
</p>
<p>ological one we have described. These views tend to deal more with perception-as-
</p>
<p>phenomenological-experience or perception-in-information-processing rather than
</p>
<p>Table 4.4 The Gestalt principles of visual grouping
</p>
<p>Proximity Elements that are close together appear as groups rather than as a random
cluster of elements
</p>
<p>Similarity Elements with the same shape or color are seen as belonging together
</p>
<p>Common fate Elements which appear to move together are grouped together
</p>
<p>Good continuation,
continuity
</p>
<p>Elements that can be grouped into lines or shapes will be
</p>
<p>Closure Missing parts of the figure are filled into complete it, so that it appears as
a whole
</p>
<p>Symmetry Regions bounded by symmetrical borders tend to be perceived as
coherent figures
</p>
<p>Figure-ground The geometric organization that is perceived is the one with the best,
simplest, and most stable shape. For example, four dots arranged as if
they were at the corners of a square will be perceived as a square
rather than a triangle plus an extra dot
</p>
<p>4.5 Higher Level Visual Perception 103</p>
<p/>
</div>
<div class="page"><p/>
<p>perception-as-registering-and-coding-sensation. They include the Constructivist,
</p>
<p>the Ecological, and the Active Vision approaches.
</p>
<p>In the Constructivist approach, seeing is regarded as an active process in which
</p>
<p>our view of the world is constructed from a combination of information in the
</p>
<p>environment and previously stored knowledge. So, what we get from our eyes is
</p>
<p>not a 2D visual representation of the world like a photograph. Instead, the visual
</p>
<p>system constructs a model of the world by transforming, enhancing, distorting,
</p>
<p>seeking, and discarding information. In doing so, the visual system provides us
</p>
<p>with a much more constant view of the world than if we were simply to &lsquo;&lsquo;see&rsquo;&rsquo; the
</p>
<p>images produced on our retinas. So, when we move about (e.g., walk down a
</p>
<p>street), buildings appear stationary and people appear to be approximately the
</p>
<p>same size and shape&mdash;despite the fact that their actual relative images on the retina
</p>
<p>Proximity groups 
</p>
<p>the left hand dots
</p>
<p>Similarity makes the left hand
</p>
<p> dots belong together more
</p>
<p>Good continuation makes the line of 
</p>
<p>dots appear to continue through the rectangle
</p>
<p>Closure makes the circle appear whole
</p>
<p>Surrounded by a box,
</p>
<p> the dots look more like a group
</p>
<p>Symmetry and equal size make the dots 
</p>
<p>look more like a group (and helps the 
</p>
<p>illustrations and captions group in this figure)
</p>
<p>Orientation makes the dots on 
</p>
<p>the left look more like a group
</p>
<p>Fig. 4.15 Several illustrations of the Gestalt principles of visual grouping
</p>
<p>104 4 Behavior: Basic Psychology of the User</p>
<p/>
</div>
<div class="page"><p/>
<p>may be quite different. In the same way, our ability to perceive objects displayed
</p>
<p>on computer screens, for example, whether they are text or graphics, 2D or 3D
</p>
<p>representations, is a result of our prior knowledge or our expectations as to what
</p>
<p>should appear as well as what lands on our retinas.
</p>
<p>In the Ecological approach (e.g., Gibson 1979), the process of seeing is greatly
</p>
<p>influenced by what uses (affordances) the object perceptions suggest. This
</p>
<p>approach, which is also called direct perception, stems from work with aircraft
</p>
<p>pilots. It takes as its starting point not a retinal image that is passively sensed, but
</p>
<p>the ambient optical array that the observer samples. Perception and actions are
</p>
<p>seen as tightly interlocking and mutually constraining.
</p>
<p>In the Active Vision approach, Findlay and his colleagues (e.g., Findlay and
</p>
<p>Gilchrist 2003) build on the Ecological approach, but emphasize the role of
</p>
<p>cognition in controlling vision. This view opposes the idea of just taking scenes
</p>
<p>and analyzing them, and instead incorporates the notion of interacting with scenes.
</p>
<p>In interacting, the eye (and brain) chooses where to look next based on what has
</p>
<p>been focused on before and what was seen in those locations.
</p>
<p>4.5.6 Implications for System Design
</p>
<p>If you are designing a system where the three-dimensional positioning of items on
</p>
<p>the display is important, you will need to decide which perceptual depth cues you
</p>
<p>should use. The final choice is likely to depend on the context in which the display
</p>
<p>screen will be used, as different lighting conditions can affect the way that the
</p>
<p>displayed image is perceived, so if you only use narrow and quite pale shadows,
</p>
<p>for example, these may not be very obvious in brightly lit conditions.
</p>
<p>For critical systems, if the user has to undertake a task which involves
</p>
<p>responding to the number of target items that appear on the display screen, you
</p>
<p>will need to consider how to display those target items. If the number of items is
</p>
<p>very low, the users will be able to react very quickly. If the number is very large,
</p>
<p>however, you may need to think about organizing them in some way (using the
</p>
<p>Gestalt principles, perhaps), or even splitting them across displays to optimize the
</p>
<p>response time.
</p>
<p>At present, most display screens offer one level of resolution, such that all items
</p>
<p>on the display are presented with that resolution irrespective of their importance. If
</p>
<p>you are designing a system which requires an increased level of detail for items
</p>
<p>that are currently being used (perceived) then you may want to consider the
</p>
<p>possibility of using gaze-contingent multi-resolution displays (Reingold et al.
</p>
<p>2003). These displays maximize the resolution at the part of the screen where the
</p>
<p>user is currently looking. This approach can provide a much more detailed image
</p>
<p>for a given bandwidth because more pixels (and information) are allocated to what
</p>
<p>the user is currently looking at, rather than effectively wasting pixels by providing
</p>
<p>an unnecessary level of detail for items that the user is not currently looking at.
</p>
<p>4.5 Higher Level Visual Perception 105</p>
<p/>
</div>
<div class="page"><p/>
<p>When people are designing displays which involve items that need to be
</p>
<p>grouped together they often include them within some form of container (usually a
</p>
<p>box). The Gestalt principles suggest, however, that careful placement of the items
</p>
<p>will also be sufficient to determine how they are perceived by the user. The laws
</p>
<p>also suggest that careful attention needs to be paid to how you lay out items on a
</p>
<p>display, because you can, unwittingly, end up with unrelated items being perceived
</p>
<p>as being related simply because of their relative placement.
</p>
<p>4.6 The Auditory System
</p>
<p>For normally sighted and hearing people, hearing is the most important sense after
</p>
<p>vision in any interaction. Most people can hear sound in the frequency range
</p>
<p>20 Hz up to 20,000 Hz, but both the upper and lower frequency limits tend to
</p>
<p>deteriorate with age and health. Hearing is more sensitive within the range
</p>
<p>1,000&ndash;4,000 Hz, which in musical terms corresponds approximately to the top two
</p>
<p>octaves of the piano keyboard, and represents much of the range of the human
</p>
<p>voice.
</p>
<p>Thus, the stimulus for audition is any vibration that will set the ossicles (small
</p>
<p>bones) of the ear in motion between about 20 and 20,000 Hz. Ordinarily, this
</p>
<p>means vibrations of the air but vibrations transmitted through other bones (par-
</p>
<p>ticularly the skull) also contribute to auditory sensation. (Having a tooth extracted
</p>
<p>or drilled will almost convince you that the jaw was designed to transmit vibra-
</p>
<p>tions to the ear in the most efficient manner possible!) There are now headsets
</p>
<p>available that use direct bone conduction as a way to transmit sound in noisy
</p>
<p>environments.
</p>
<p>4.6.1 Theoretical Description of Sound
</p>
<p>It is convenient to consider the stimulus for sound to be made up of successive
</p>
<p>compressions and rarefactions (expansions) of air that follow a waveform over
</p>
<p>time. An example is shown in Fig. 4.16.
</p>
<p>Waveforms like that in Fig. 4.16 can be summarized as being made up of sine
</p>
<p>waves (they look a lot like the first part of the waveform in Fig. 4.16 but are
</p>
<p>smoother and follow the sine function used in trigonometry). There are at least two
</p>
<p>reasons for using the sine function. The first is that they are easy to create; a pure tone
</p>
<p>produced by an electronic oscillator or a tuning fork follows a sine wave. The second
</p>
<p>and more important reason is that theoretically a wave of any shape can be analyzed
</p>
<p>into component sine waves. This is known as Fourier analysis. Figure 4.17 provides
</p>
<p>a simple example. Work with sine waves thus provides a standard for comparison
</p>
<p>across different types of sounds.
</p>
<p>106 4 Behavior: Basic Psychology of the User</p>
<p/>
</div>
<div class="page"><p/>
<p>Waveforms with a single sine wave sound purer. Waveforms with different
</p>
<p>combinations of frequencies sound different. How many of these subwaves there
</p>
<p>are determine whether you are hearing a piano or an organ, or Frank or Gordon
</p>
<p>speaking.
</p>
<p>Loudness of the sensation is largely dependent on the amplitude of the wave.
</p>
<p>However, the ear is not equally sensitive to all frequencies, so sounds at different
</p>
<p>pitches will not have the same loudness. The pitch of the tone depends primarily
</p>
<p>on the frequency of the sine wave, but not completely. Pitch is also dependent on
</p>
<p>amplitude. The apparent pitch of high frequency tones will increase with
</p>
<p>increasing amplitude but the apparent pitch of low tones decreases with increasing
</p>
<p>intensity. The loudness of a tone will also depend on the phase relationships of the
</p>
<p>component frequencies of the stimulus (that is, do they all start at once or do they
</p>
<p>start after each other but offset in time). Timbre is a quality that depends on the
</p>
<p>Fig. 4.16 An example waveform from audacity
</p>
<p>0
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>4
</p>
<p>5
</p>
<p>6
</p>
<p>7
</p>
<p>8
</p>
<p>9
</p>
<p>10
</p>
<p>10 100 1,000 10,000
</p>
<p>Frequency (Hz)
</p>
<p>R
e
la
</p>
<p>ti
v
e
 A
</p>
<p>m
p
</p>
<p>li
tu
</p>
<p>d
e
</p>
<p>Fig. 4.17 Example,
simplistic, Fourier analysis
that might match the
waveform in Fig. 4.16
</p>
<p>4.6 The Auditory System 107</p>
<p/>
</div>
<div class="page"><p/>
<p>purity of the tone; is it made up of one single sine wave frequency or a broad
</p>
<p>mixture of frequencies? A tuning fork has a relatively pure tone and therefore little
</p>
<p>timbre. On the other hand, a piano or other musical instrument has timbre because
</p>
<p>of the other frequencies present in its sounds. Different timbres are often assigned
</p>
<p>different meanings by users, which may be important for your design.
</p>
<p>Low tones of equal loudness appear to occupy more space and thus are said to
</p>
<p>have more volume than high tones. On the other hand, high tones have a greater
</p>
<p>density than low tones of equal loudness. The volume and density of tones are each
</p>
<p>a joint function of intensity and frequency of the tones. However, they seem to be
</p>
<p>as real as pitch and loudness which have simpler bases. In other words, listeners
</p>
<p>have no difficulty making reliable judgments of volume or density of tones that
</p>
<p>differ in frequency and intensity.
</p>
<p>Hearing can be likened to carrying out a type of Fourier analysis of the auditory
</p>
<p>stimulus, separating a complex wave into its sine wave components. There are
</p>
<p>some situations where this analogy breaks down, such as when two stimuli of
</p>
<p>approximately equal intensity and frequency are simultaneously presented to the
</p>
<p>ear. Instead of hearing both tones, as a linear Fourier analysis would allow, a single
</p>
<p>tone is heard which varies in loudness in a periodic manner. You may have heard
</p>
<p>this when two people sing together or two instruments are played together. The
</p>
<p>effect can be pleasant or unpleasant depending on the frequency of the beats.
</p>
<p>The basis of beats is the following. If you have a pure tone of 256 Hz and another
</p>
<p>of 257 Hz, each one would produce a steady pitch that would be difficult to dis-
</p>
<p>tinguish from the other. When the two are played together the compressions and
</p>
<p>rarefactions (expansions) of the air produced by the two tones will at some point be
</p>
<p>in phase (synchronized) and the two tones will add together. However, because the
</p>
<p>frequency of one is slightly greater than the other, they will get out of phase after a
</p>
<p>while and their effects will cancel each other out. As this process repeats, they will
</p>
<p>go in and out of phase as many times per second as the difference between the tones
</p>
<p>in cycles per second. In this example, it would be once per second and so you will
</p>
<p>hear one beat per second. This provides a very accurate way of measuring the
</p>
<p>difference between two tones, far better than the ear could discriminate if the two
</p>
<p>tones were presented separately. This fact is used to good effect by piano tuners.
</p>
<p>They tune one note until it no longer beats with the standard tuning fork. Then the
</p>
<p>other notes are tuned until their harmonics do not beat with the first note.
</p>
<p>4.6.2 Measuring Sound
</p>
<p>Sound intensity is normally measured using the deciBel scale. This is a relative
</p>
<p>logarithmic scale where 10 decibels (dB) = 1 log unit ratio of energy, or a Bel
</p>
<p>(name after Alexander Graham Bell). To give some practical examples, the
</p>
<p>threshold of hearing is 0 dB, a whisper registers 20 dB, and normal conversation
</p>
<p>registers between 50 and 70 dB.
</p>
<p>108 4 Behavior: Basic Psychology of the User</p>
<p/>
</div>
<div class="page"><p/>
<p>The intensities of various common sounds are shown in Fig. 4.18. The sensi-
</p>
<p>tivity to both frequency and loudness varies from person to person. Generally,
</p>
<p>though, the ear is insensitive to frequency changes below about 20 dB (i.e., below
</p>
<p>a whisper). Once levels get above 90 dB (as shown by the line in the table),
</p>
<p>prolonged exposure can lead to permanent hearing loss. This level is often sur-
</p>
<p>passed by some industrial jobs, and by the iPods and MP3 players of those people
</p>
<p>who have the volume control turned up excessively high.
</p>
<p>This scale does not describe perceived loudness well. Increasing an auditory
</p>
<p>stimulus by equal ratios does not produce equal increments in sensation. It is
</p>
<p>obvious that the difference in loudness between a whisper and a normal conver-
</p>
<p>sation is less than the difference between a normal conversation and a subway
</p>
<p>train. What is said, the context, and background noise also influence perceived
</p>
<p>loudness. However, the ratio of the energy in a whisper to that in a conversation is
</p>
<p>about the same as the ratio in conversation to that of the noise of a subway train.
</p>
<p>This explains why a 100-W stereo is much louder than a 1-W pocket radio, and a
</p>
<p>200-W stereo is not much louder than a 100-W stereo. The corollary of this is that
</p>
<p>when measuring loudness, asking people to directly estimate apparent intensity of
</p>
<p>Fig. 4.18 Example sound levels (in decibels). a [140] Rock band (amplified) at close range;
b [120] Loud thunder or fireworks; c [100] Jet plane at 500 ft; d [100] Subway train at 20 ft; [90]
(not shown) Potential for permanent hearing loss; e [80] Busy street corner; f [60] Normal
conversation; g [40] Typical room; h [20] Whisper; [0] (not shown) Threshold of hearing
</p>
<p>4.6 The Auditory System 109</p>
<p/>
</div>
<div class="page"><p/>
<p>loudness (known as magnitude estimation) is often the best way to quantify
</p>
<p>sounds, at least for interface design.
</p>
<p>4.6.3 Localizing Sound
</p>
<p>People are generally poor at using spatial cues to successfully localize sounds
</p>
<p>(Catchpole et al. 2004; Kubovy and van Valkenburg 2001). The idea that locali-
</p>
<p>zation is based on inter-aural time differences at low frequencies and inter-aural
</p>
<p>intensity differences at high frequencies is called the &lsquo;duplex&rsquo; theory and dates
</p>
<p>back to Lord Rayleigh (1907), a pioneer in perception. This does not hold for
</p>
<p>complex sounds.
</p>
<p>We can identify the location of a sound from the time taken for waves to reach
</p>
<p>the ears, coupled with information from head and shoulder movements. Sound
</p>
<p>reaching the far ear will be delayed in time and will be less intense relative to that
</p>
<p>reaching the nearer ear. Thus, there are two possible cues as to the location of the
</p>
<p>sound source. Owing to the physical nature of the sounds, these cues are not
</p>
<p>equally effective at all frequencies.
</p>
<p>Low frequency sounds have a wave length that is long compared with the size
</p>
<p>of the head, and this &lsquo;&lsquo;bends&rsquo;&rsquo; the sound around the head very well. This process is
</p>
<p>known as diffraction, and the result is that little or no shadow is cast by the head.
</p>
<p>On the other hand, at high frequencies where the wavelength is short compared to
</p>
<p>the dimension of the head, little diffraction occurs. A &lsquo;&lsquo;shadow&rsquo;&rsquo; almost like that
</p>
<p>produced by a beam of light occurs.
</p>
<p>Inter-aural (between-ear) differences in intensity are negligible at low fre-
</p>
<p>quencies, but may be as large as 20 dB at high frequencies. This is easily illus-
</p>
<p>trated by placing a small transistor radio close to one ear. If that ear is then blocked
</p>
<p>with a finger, only the sound bending around the head and entering the other ear
</p>
<p>will be heard. The sound will be much less &lsquo;&lsquo;tinny&rsquo;&rsquo; because high frequencies will
</p>
<p>have been attenuated more than low; the head effectively acts like a low pass filter
</p>
<p>(allowing only low frequency sounds). Inter-aural intensity differences are thus
</p>
<p>more important at high frequencies than at low ones.
</p>
<p>If a tone is delayed at one ear relative to the other, there will be phase differences
</p>
<p>between the two ears (the peaks of the waves will arrive at different times). If nerve
</p>
<p>impulses occur at a particular phase of the stimulation waveform, the relative timing
</p>
<p>of the nerve impulses at the two ears will be related to the location of the sound
</p>
<p>source. This is used to locate &lsquo;&lsquo;wide&rsquo;&rsquo; sounds. However, for sounds whose wave-
</p>
<p>lengths are comparable with, or less than, the distance between the two ears there
</p>
<p>will be ambiguity. The maximum path difference between the two ears is about
</p>
<p>23 cm, which corresponds to a time delay of about 690 ls. Ambiguities occur when
</p>
<p>the half wavelength of the sound is about 23 cm, i.e., when the frequency of the
</p>
<p>sound is about 750 Hz. A sinusoid of this frequency lying to one side of the head
</p>
<p>produces waveforms at the two ears that are in opposite phase (phase difference
</p>
<p>110 4 Behavior: Basic Psychology of the User</p>
<p/>
</div>
<div class="page"><p/>
<p>between the two ears of 180ï¿½). From the observer&rsquo;s point of view, the location of the
</p>
<p>sound source is now ambiguous, because the waveform at the right ear might be
</p>
<p>either a half-cycle behind that at the left ear or a half-cycle ahead. Head movements
</p>
<p>or movement of the sound source may resolve this ambiguity, so that there is no
</p>
<p>abrupt upper limit in our ability to use phase differences between the two ears.
</p>
<p>However, when the wavelength of the sound is less than the path difference between
</p>
<p>the two ears, the ambiguities increase; the same phase difference could be produced
</p>
<p>by a number of different source locations.
</p>
<p>There are two different mechanisms for sound localization: one operates best at
</p>
<p>high frequencies and the other at low frequencies. For middle frequencies neither
</p>
<p>mechanism operates efficiently, and errors are at a maximum. Stevens and
</p>
<p>Newman (1936) investigated localization of single bursts with smooth onsets and
</p>
<p>offsets for observers on the roof of a building so that reflection was minimized.
</p>
<p>The listeners had to report the direction of the source in the horizontal plane, to the
</p>
<p>nearest 15ï¿½. Although left&ndash;right confusions were rare, low frequency sounds in
</p>
<p>front were often indistinguishable from their mirror location behind. If these front&ndash;
</p>
<p>back confusions were discounted, then the error rate was low at very low and very
</p>
<p>high frequencies and showed a maximum for mid-range frequencies (around
</p>
<p>3,000 Hz). Intensity differences are more important at high frequencies, and phase
</p>
<p>differences provide usable cues for frequencies below about 1,500 Hz.
</p>
<p>4.6.4 Discriminating Sounds
</p>
<p>Our abilities in discriminating sound depend upon whether we mean absolute dis-
</p>
<p>crimination or relative discrimination (this applies to vision too). Absolute dis-
</p>
<p>crimination is quite poor (e.g., systems should not rely on remembering a tone or
</p>
<p>sound), but relative discrimination is very good. With sounds we can remember no
</p>
<p>more than five to seven items for absolute discrimination unless we can attach
</p>
<p>meaning to them, such as pitch labels. Also, as we varymore of the dimensions of the
</p>
<p>stimulus (increasing its complexity), so we increase our ability to discriminate (up to
</p>
<p>150 sounds&mdash;varying in frequency, rhythm, location, duration, volume, etc.).
</p>
<p>4.6.5 Implications for System Design
</p>
<p>There are two ways in which sounds are used in current systems. The first is to
</p>
<p>provide voice output. The second is to provide audible alerts, such as telephone
</p>
<p>ring tones, and audible alarms.
</p>
<p>Voice outputs generally require more processing than plain sounds. They can
</p>
<p>convey much more information, however, and they are particularly important for
</p>
<p>people with impaired vision. Blind users, for example, use voice output with
</p>
<p>screen readers so they can process the text shown on a display screen.
</p>
<p>4.6 The Auditory System 111</p>
<p/>
</div>
<div class="page"><p/>
<p>In general it is said that automated female voice output is easier to understand.
</p>
<p>If you are designing a system that requires voice output, the rule of thumb is
</p>
<p>usually to prefer a clear, slightly high, female voice if you can only choose one. If
</p>
<p>you have a system that produces multiple voices in the same task context, how-
</p>
<p>ever, you will need to think more deeply about your choices. First, and foremost,
</p>
<p>however, you will need to choose voices that are easily discernible from each
</p>
<p>other. If your system has a sophisticated speaker system, you may also be able to
</p>
<p>separate the voices spatially.
</p>
<p>You will also need to take account of the geographical context in which your
</p>
<p>system will be used. If your system is being deployed in the UK, for example,
</p>
<p>users may prefer the system to use a voice that has a British accent. Personal
</p>
<p>preferences can play a role too, so you may want to allow your user to select which
</p>
<p>voice output should be used. Indeed, many motor vehicle satellite navigation
</p>
<p>(satnav) systems now allow you to choose the voice that will be used to offer you
</p>
<p>verbal directions on how to reach your travel destination.
</p>
<p>Like sight, hearing generally diminishes with age. If you are designing a system
</p>
<p>for a population that will include older users, you will need to take the possible
</p>
<p>reduced hearing levels into account when selecting voices and sounds to use as
</p>
<p>output. Some mobile phones by default include ring tones that can compensate for
</p>
<p>hearing loss in older people.
</p>
<p>Audible alarms are supposed to be designed to alert the user to abnormal or
</p>
<p>undesirable situations. In many cases the audible alert is used in addition to a
</p>
<p>visual alert. If you want to quickly attract your user&rsquo;s attention in an emergency
</p>
<p>situation, the easiest way is to use square-ended, sudden onset waveforms such as
</p>
<p>klaxons or bells to provide audible alarms. The problem is that they evoke a startle
</p>
<p>reaction, and if the sound is at high volume it can even cause panic. The design of
</p>
<p>audible alerts requires great skill because you want to make sure that your users
</p>
<p>process the meaning of the alert rather than focusing on trying to stop the loud,
</p>
<p>incessant noise. The alarm sound needs to be distinctive so that users can recog-
</p>
<p>nize it and recall its meaning. If you are trying to convey urgency, you should
</p>
<p>avoid high intensity sounds, and instead consider the speed of the alarm sound: a
</p>
<p>tri-tone alarm, for example, which doubles in speed, will suddenly sound very
</p>
<p>urgent.
</p>
<p>4.7 Motivation
</p>
<p>4.7.1 Introduction
</p>
<p>Now that you know some of the basics about how humans behave, it is also
</p>
<p>important to be aware of why they behave in particular ways. Generally there are
</p>
<p>two reasons why people act in a particular way. The first is governed by the central
</p>
<p>112 4 Behavior: Basic Psychology of the User</p>
<p/>
</div>
<div class="page"><p/>
<p>nervous system: if someone blows a puff of air into your eyes, for example, you
</p>
<p>automatically blink. We have no conscious control over these sorts of actions.
</p>
<p>The second reason is where people make a deliberate decision to perform a
</p>
<p>particular act. One of the influencing factors that determines not only their action,
</p>
<p>but how well they perform it is their motivation: motivation is something that drives
</p>
<p>behavior. It cannot be used as a singular explanation for why people do things,
</p>
<p>however, because behavior is also influenced by needs, incentives, expectations,
</p>
<p>and the presence of conflicting motivations, as well as unconscious factors.
</p>
<p>Motivation is usually considered from three aspects: the physiological, the
</p>
<p>behavioral, and the psycho-social. Here we provide a brief introductory overview,
</p>
<p>so that you can start to understand why an individual user behaves in a particular
</p>
<p>way. This may be particularly useful if you are designing gaming software, for
</p>
<p>example, where you want to keep the user engaged by providing the appropriate
</p>
<p>motivation for them to carry on playing. We will return to the topic of motivation
</p>
<p>in Chap. 8 to discuss how it plays out in team settings.
</p>
<p>4.7.2 Maslow&rsquo;s Hierarchical Theory
</p>
<p>Perhaps the best known theory of motivation is Abraham Maslow&rsquo;s (1943)
</p>
<p>Hierarchy of Needs. The simplest way to visualize the hierarchy is as a pyramid as
</p>
<p>shown in Fig. 4.19, although Maslow never presented a figure.
</p>
<p>At the bottom of the pyramid are the basic, physiological human needs like
</p>
<p>breathing, food, sleep, and excretion. These are fundamental to human existence.
</p>
<p>Above that, in order, are safety, love and belonging, and esteem, with self-actu-
</p>
<p>alization at the very top. Each level requires that the level below it be mostly
</p>
<p>satisfied. Maslow also believed in what he called metamotivation&mdash;the motivation
</p>
<p>of people for continual personal improvement.
</p>
<p>People are orienting towards, and try to satisfy, more than one of these levels at
</p>
<p>the same time. It is likely that motivations that appear lower in the pyramid will
</p>
<p>dominate those that appear at a higher level (e.g., eating when you are hungry or
</p>
<p>going to the bathroom when you feel the need would likely win out over doing
</p>
<p>something to improve your self-esteem). Whilst there have been many theories of
</p>
<p>motivation proposed since Maslow&rsquo;s, his basic ideas remain popular.
</p>
<p>4.7.3 Extrinsic and Intrinsic Motivation
</p>
<p>The basic needs&mdash;those towards the bottom of Fig. 4.19&mdash;are met for designers
</p>
<p>and many users, so the higher level needs are the focus of attention from our
</p>
<p>perspective. In his book, Drive, Pink (2009) presents a summary of motivational
</p>
<p>4.7 Motivation 113</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8">http://dx.doi.org/10.1007/978-1-4471-5134-0_8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8">http://dx.doi.org/10.1007/978-1-4471-5134-0_8</a></div>
</div>
<div class="page"><p/>
<p>psychology research, some of which can be applied to systems design. His work
</p>
<p>was influenced by that of Deci and others, on Self-Determination Theory (SDT,
</p>
<p>e.g., Ryan and Deci 2000).
</p>
<p>Pink (2009) identifies three versions of motivation:
</p>
<p>&bull; Motivation 1.0 is simply about doing what you have to do to survive.
</p>
<p>&bull; Motivation 2.0 is associated with the industrial revolution. The underlying
</p>
<p>assumption is that most people do not want to work, so pressure (both positive
</p>
<p>and negative) needs to be applied to encourage the right behavior. In other
</p>
<p>words, extrinsic motivation needs to be supplied, using a carrot and stick
</p>
<p>approach, such as encouraging work by paying bonuses.
</p>
<p>&bull; Motivation 3.0 acknowledges the existence of intrinsic work drives. For many
</p>
<p>important tasks people want to do the work: they are intrinsically motivated.
</p>
<p>This includes creative and non-routine work, such as system design, software
</p>
<p>engineering, and most tasks performed by knowledge workers.
</p>
<p>For tasks that are boring or onerous, Pink argues that Motivation 2.0 is still
</p>
<p>applicable. Where there is little room for creativity, work is generally performed
</p>
<p>better if the rationale for doing it is provided, the boringness is acknowledged, and
</p>
<p>people are given some autonomy in how the work is carried out.
</p>
<p>For creative and non-routine work, Pink (2009) argues that the keys to high
</p>
<p>performance are the drives to direct your own life, to extend your abilities, and to
</p>
<p>live a purposeful life. This sort of work can be hindered by extrinsic motivations.
</p>
<p>Deci (1971), for example, found that if you paid participants to do a simple puzzle,
</p>
<p>they were less likely to do it while waiting to take part in the experiment (and
</p>
<p>hence not being paid), whereas participants who were not paid were more likely to
</p>
<p>try to solve it while waiting. The argument is that the extrinsic reward focuses
</p>
<p>Type/Level of Needs
</p>
<p>Esteem
</p>
<p>Safety
</p>
<p>Physiological
</p>
<p>Love
</p>
<p>Self-actualization
</p>
<p>Hunger, water, salt, fatigue, sleep, sex 
</p>
<p>"To become 
everything that one
</p>
<p>is capable of becoming"
</p>
<p>Respect by others 
of achievements
</p>
<p>Affection, belonging, family
</p>
<p>Lack of physical threat &amp; pain, order, 
extreme temperature
</p>
<p>Fig. 4.19 Maslow&rsquo;s hierarchy of needs
</p>
<p>114 4 Behavior: Basic Psychology of the User</p>
<p/>
</div>
<div class="page"><p/>
<p>attention on that reward, which facilitates the behavior that the reward encourages,
</p>
<p>and generally damps other related behavior. Extrinsic rewards may work up to a
</p>
<p>point, but beyond that, performance can start to decrease. Similarly, if people are
</p>
<p>focused on the extrinsic reward and it is then withdrawn, this can also lead to a
</p>
<p>reduction in performance.
</p>
<p>The problem lies in achieving the right balance between extrinsic and intrinsic
</p>
<p>rewards. Pink suggests one way is to increase basic payments and reduce or even
</p>
<p>eliminate bonus payments. His claim is that people will continue to increase
</p>
<p>performance if they are intrinsically motivated. In other words, they do the task
</p>
<p>because they like doing it, or they feel a sense of altruism when they do it (Toms
</p>
<p>Shoes in California, for example, donates a pair of shoes to needy children for
</p>
<p>every pair that it sells), or they are given autonomy in what they do (Google, for
</p>
<p>example, allows employees to spend 20% of their work hours on something new).
</p>
<p>Based on his analysis of studies from psychology and behavioral economics,
</p>
<p>Pink identifies three elements of intrinsic motivation:
</p>
<p>&bull; Autonomy&mdash;the ability to choose what to work on, how to work on it, who to
</p>
<p>work with, and when to work on it. If you allow people to make these sorts of
</p>
<p>decisions they become more productive. Pink argues that autonomy leads to
</p>
<p>engagement, and engagement leads to mastery. It is not possible for every type
</p>
<p>of situation, however, so some of the attributes are less mutable than others. If
</p>
<p>someone is operating a safety critical system in a nuclear power plant, for
</p>
<p>example, you really do want them to follow the rules about how they work.
</p>
<p>&bull; Mastery&mdash;the desire to understand a process or task and to get better at per-
</p>
<p>forming it. Achieving mastery is most enjoyable when the task provides the right
</p>
<p>level of challenge: too easy and it can become boring; too hard and it can create
</p>
<p>anxiety. The balancing of knowledge to work requirements is what Vygotsky
</p>
<p>(e.g., Chaiklin 2003) calls appropriate scaffolding or the Zone of Proximal
</p>
<p>Development, and Cs&iacute;kszentmih&aacute;lyi (1990) calls flow. It is not always easy to
</p>
<p>operationalize these concepts, particularly in social settings, such as a classroom
</p>
<p>with multiple learners. The desire to achieve mastery can be a powerful drive,
</p>
<p>although it is not universal. Users who want to become experts will want to
</p>
<p>understand the task and develop the skills needed to do it well. This drive can also
</p>
<p>be exploited for boring and difficult tasks as long as the user understands the need
</p>
<p>for repeated drill exercises, or how the difficult tasks fit into the whole task.
</p>
<p>&bull; Purpose&mdash;this is really the desire to improve things; most people are at least
</p>
<p>partly purpose-driven. Under Pink&rsquo;s Motivation 2.0 the purpose is related to the
</p>
<p>extrinsic motivation. In Motivation 3.0, however, the purpose is related to
</p>
<p>intrinsic motivation: people know why the task is important, and may even do it
</p>
<p>free of charge. Emphasizing the goal of the task and its purpose can drastically
</p>
<p>influence performance. Working for the good of the company, your town, your
</p>
<p>nation, or the planet in this way can be more motivating than working for
</p>
<p>money.
</p>
<p>4.7 Motivation 115</p>
<p/>
</div>
<div class="page"><p/>
<p>4.7.4 Implications for System Design
</p>
<p>How much you need to consider motivation during system design will depend on
</p>
<p>three things: your particular users, the particular tasks they are doing, and the
</p>
<p>particular context in which they are working. It is probably best to consider these
</p>
<p>in reverse order, and think about the context first. If the context is a work setting,
</p>
<p>then there may be little or nothing that you can do to provide any motivation for
</p>
<p>your users to do their tasks over and above the motivation they already get from
</p>
<p>their company. If it is a leisure setting, however, then you will need to look at ways
</p>
<p>of engaging users in doing their tasks. You could offer virtual monetary rewards,
</p>
<p>for example, or badges of achievement to show that they had attained a particular
</p>
<p>level of proficiency at performing the task. Figure 4.20 summarizes this approach.
</p>
<p>In terms of the particular tasks they are performing, there are more ways in
</p>
<p>which you can contribute in work settings. Given what you know about how visual
</p>
<p>perception and aural perception work, you can now start to think about how to
</p>
<p>make important items stand out on a crowded screen (using pop-out effects), for
</p>
<p>example, and how to design audible alarms that can be used to quickly identify a
</p>
<p>problem (by making them distinctive). In this way you can help your users to
</p>
<p>improve their task performance, and help them to achieve mastery.
</p>
<p>In leisure settings your approach to dealing with the user&rsquo;s tasks may be more
</p>
<p>perverse, in that you do not want to make it too easy for your users to achieve
</p>
<p>mastery. You want to make them engage with the game, for example, and spend
</p>
<p>time and effort to attain any rewards, such as being able to progress to the next
</p>
<p>level of attainment, on the way to achieving mastery.
</p>
<p>Is the 
task
</p>
<p>mostly
routine?
</p>
<p>Yes
</p>
<p>No
</p>
<p>Can you make the 
task more 
</p>
<p>challenging, less 
routine, or tied to a 
higher purpose?
</p>
<p>Yes
</p>
<p>* Focus on healthy environment 
and fair pay. 
</p>
<p>* Foster autonomy, mastery, and 
purpose.
</p>
<p>* Avoid if-then rewards
* Consider unexpected rewards 
</p>
<p>that offer praise and feedback, 
* Provide useful information rather
</p>
<p>than control.
</p>
<p>No
</p>
<p>Use rewards, but:
1. Provide reason for task
2. Acknowledge it is boring
3. Allow multiple strategies
</p>
<p>Do so, 
and....
</p>
<p>Fig. 4.20 When and how to use rewards based on theories in Pink (2009)
</p>
<p>116 4 Behavior: Basic Psychology of the User</p>
<p/>
</div>
<div class="page"><p/>
<p>Finally, you need to think carefully about your users. People are different: some
</p>
<p>are driven mostly by extrinsic rewards (particularly money), whereas others may
</p>
<p>do things for intrinsic rewards, such as the enjoyment or satisfaction they get from
</p>
<p>doing them.
</p>
<p>4.8 Summary
</p>
<p>This chapter has provided a more detailed theory of what information users get
</p>
<p>from their primary perceptual systems. Nearly all users interact through vision and
</p>
<p>sound, and a deeper understanding of how users get information from these senses
</p>
<p>provides numerous suggestions for how to improve systems.
</p>
<p>Many designers start out with a theory that the eye is like a camera&mdash;and so it is
</p>
<p>in some ways, having a lens and a surface on which the image is registered (the
</p>
<p>retina). However, as with many metaphors and analogies, the use of the camera
</p>
<p>metaphor is problematic, and is often called &lsquo;naive realism&rsquo;. It is an inadequate
</p>
<p>theory of perception.
</p>
<p>There are some critical differences between cameras and photography and the
</p>
<p>eye and visual perception. These differences mean that there is not a simple one-to-
</p>
<p>one correspondence between the context of a scene and what we perceive. The
</p>
<p>most important point is that light sensitivity varies across the whole of the retina. It
</p>
<p>is best in the center of the retina, the fovea, and worst at the edges. The eye thus
</p>
<p>has to move (saccade) over the visual scene all the time to see the details. Users
</p>
<p>have to actively do this, and if they do not know where to look or do not know how
</p>
<p>to interpret an object, they will not see what the designer intends.
</p>
<p>If you want to view the eye as a camera, you have to view the eye as a very odd
</p>
<p>camera. It has a more variable speed film (or sensor) to support wide changes in
</p>
<p>light than you can buy. It has a poor focusing system (it has to be on the retina to
</p>
<p>be well developed), and poor quality film over much of the remaining negative
</p>
<p>(rods). The user has to move the camera to see details. If you view it this way, you
</p>
<p>probably have a reasonable model of the eye in mind, but a very odd camera.
</p>
<p>Hearing is more straightforward. The differences between how the ear works
</p>
<p>and folk psychology are less drastic. The ear is a little bit more sensitive than most
</p>
<p>might believe, and can distinguish a wide variety of sounds, but without attention
</p>
<p>or training some sounds will not be distinguished.
</p>
<p>In the future you will see (a) improved displays and (b) more attention given to
</p>
<p>the integration of types of perception and action. In the first area, of improved
</p>
<p>displays, you will see continued improvement in the quality of displays. Sound
</p>
<p>appears to stop improving around 44 kHz sample rates; above that, increasing the
</p>
<p>quality of the sound is not very noticeable&mdash;CDs do not sound a lot different from
</p>
<p>MP3 files, or so many consumers believe. A similar effect will be found as displays
</p>
<p>get better, in that the eye can still see more than a display can show. When a
</p>
<p>display provides the details that the fovea can see across its whole surface, or when
</p>
<p>4.7 Motivation 117</p>
<p/>
</div>
<div class="page"><p/>
<p>the display adapts to provide more details where the fovea is, the quality will reach
</p>
<p>a maximum.
</p>
<p>In the second area, users integrate their senses&mdash;motion, sound, and vision.
</p>
<p>Current displays are not well integrated with users&rsquo; movements. This integration
</p>
<p>will be important for virtual reality (VR). Head-mounted displays move with the
</p>
<p>user, and most do not compensate for this motion. The users feel their motion with
</p>
<p>their inner ear, and do not see this motion in the display (or, in some cases, see
</p>
<p>movement but do not feel it with their inner ear). Over periods of time, sometimes
</p>
<p>even short periods of times, this non-correspondence between eye and ear can lead
</p>
<p>to nausea. This mismatch can also appear when an interface is stationary and the
</p>
<p>user is inside a moving vehicle. Examples include reading books in cars as well as
</p>
<p>using displays in cars, trucks, and ships. The results are not directly dangerous but
</p>
<p>they are debilitating and dangerous if the display is necessary for the vehicle.
</p>
<p>Work is ongoing to understand and ameliorate these effects.
</p>
<p>Finally, you will need to think about how to motivate your users to do the tasks
</p>
<p>they need to do. This will involve balancing their individual needs and aspirations
</p>
<p>with an appropriate combination of extrinsic and intrinsic rewards if you want to
</p>
<p>get the best out of them.
</p>
<p>4.9 Other Resources
</p>
<p>For further descriptions of human perception and performance, it is worth con-
</p>
<p>sulting this text:
</p>
<p>Boff, K. R. and Lincoln, J. E. (1988). Engineering data compendium: Human perception
and performance. Wright-Patterson Air Force Base, OH: Harry G. Armstrong Aerospace
Medical Research Laboratory. This set of three volumes covers the breadth of what was
known about these areas of human behavior at that time. It remains useful because of its
breadth.
</p>
<p>There are several texts that will tell you more about visual perception. Two we
</p>
<p>recommend are:
</p>
<p>Bruce, V., Green, P. R., and Georgeson, M. A. (2003). Visual perception: Physiology,
psychology and ecology. Hove, UK: Psychology Press.
</p>
<p>Sekuler, R. and Blake, R. (2005). Perception. (5th ed). New York, NY: McGraw-Hill.
</p>
<p>An excellent introduction to eye movements and their relationship to attention
</p>
<p>if offered by Goldberg and colleagues:
</p>
<p>Goldberg, J. H. and Kotval, X. P. (1999). Computer interface evaluation using eye
movements: methods and constructs, International Journal of Industrial Ergonomics, 24,
631&ndash;645. This provides comparative assessment of measures of eye movement locations
and scan paths used for evaluation of interface quality.
</p>
<p>118 4 Behavior: Basic Psychology of the User</p>
<p/>
</div>
<div class="page"><p/>
<p>You can also get a broad overview of eye gaze and its relationship to attention
</p>
<p>by looking at Navalpakkam and Churchill&rsquo;s chapter available in a general textbook
</p>
<p>on HCI methods edited by Olson and Kellogg:
</p>
<p>Navalpakkam, V., and Churchill, E. F. (in press). Eyetracking: A brief introduction. In J.
S. Olson &amp; W. Kellogg (Eds.), Ways of knowing, HCI methods. Heidelberg, Germany:
Springer.
</p>
<p>To learn more about auditory perception, hearing, look at this text:
</p>
<p>Moore, B. C. J. (2013). An introduction to the psychology of hearing. (6th. Ed). Bingley,
England: Emerald Group Publishing.
</p>
<p>Also, a readable text by ex-leader of the band Talking Heads, David Byrne is
</p>
<p>&lsquo;&lsquo;How Music Works&rsquo;&rsquo;. It includes a very interesting, and very readable guide to the
</p>
<p>way that music (as an example of sound) works for the listener. It describes how
</p>
<p>both analog and digital technology affect the way that we hear sounds, in addition
</p>
<p>to the context in which the sounds are played.
</p>
<p>Byrne, D. (2012). How Music Works. Edinburgh, UK: Canongate Books.
</p>
<p>To better understand how these basic perceptual capabilities affect how we
</p>
<p>think, it is worth looking at John Anderson&rsquo;s book on cognitive psychology.
</p>
<p>Anderson, J. R. (2009). Cognitive psychology and its implications (7th ed.). New York,
NY: Worth Publishers. This book includes information about where perception and
cognition interact.
</p>
<p>The Poynter Institute (http://www.poynter.org) has online tutorials to help
</p>
<p>designers understand the complexities of color and its use in print and online
</p>
<p>journalism. These tutorials include page design exercises, which let you experi-
</p>
<p>ment with the use of color in magazines, newspapers, and web sites. See also
</p>
<p>Color, Contrast and Dimension in News Design, https://www.newsu.org/courses/
</p>
<p>color-news-design (requires free registration).
</p>
<p>Clayton Lewis and John Rieman&rsquo;s shareware book: Task-Centered User
</p>
<p>Interface Design, hcibib.org/tcuid, includes discussions about how to visually
</p>
<p>design an interface to support users. They are familiar with vision, visual cogni-
</p>
<p>tion, and the application of this knowledge to interface design. Their view helps
</p>
<p>extend how to apply this knowledge to interface design.
</p>
<p>4.10 Exercises
</p>
<p>4.1 To study the effects of color on perception you should generate 15&ndash;20 stimuli
</p>
<p>for people to look at on a smartphone. These all have to be items that they
</p>
<p>have to process in some way, so they could be short paragraphs to read, words
</p>
<p>4.9 Other Resources 119</p>
<p/>
<div class="annotation"><a href="http://www.poynter.org">http://www.poynter.org</a></div>
<div class="annotation"><a href="https://www.newsu.org/courses/color-news-design">https://www.newsu.org/courses/color-news-design</a></div>
<div class="annotation"><a href="https://www.newsu.org/courses/color-news-design">https://www.newsu.org/courses/color-news-design</a></div>
</div>
<div class="page"><p/>
<p>to say out loud or to categorize, or objects to name. The items should be
</p>
<p>prepared in both black and white and color.
</p>
<p>Have a group of users do the task with both the black and white and color
</p>
<p>objects. Record the time it takes them to do the tasks and how many errors
</p>
<p>they make. You may have to vary the size of the objects to get these measures
</p>
<p>to vary.
</p>
<p>In addition to reporting what you find, you should indicate what the find-
</p>
<p>ings mean about displays and the use of color.
</p>
<p>4.2 Choose six icons from popular or not so popular software packages. Also
</p>
<p>choose six menu items that are words (e.g., Format: Frame, File: Save, Insert:
</p>
<p>Date, Message: Reply, View: Master Document, Tools: Goal Seek, Edit:
</p>
<p>Copy) or choose icons from an online training system or training system such
</p>
<p>as Rosetta Stone.
</p>
<p>Ask six to ten people to tell you what they think each icon and each menu
</p>
<p>item will do or represents. Summarize your results in a table as well as a set of
</p>
<p>suggestions for how to design interfaces. If you have access to a different
</p>
<p>population of users, people from different cultures, physical abilities, or ages,
</p>
<p>run the study on that population as well and compare their responses to your
</p>
<p>classmates.
</p>
<p>4.3 Explain how signal detection theory can be used to analyze web site reading
</p>
<p>and searching. Based on this analysis, provide three suggestions for your
</p>
<p>favorite search engine or web site that includes search.
</p>
<p>4.4 Redraw the signal detection curve in a big format. Either make the curves big,
</p>
<p>or put the signal and noise on separate lines to that they are easy to work with.
</p>
<p>Label the parts of the curves that make up hits, misses, false alarms, and
</p>
<p>correct rejections.
</p>
<p>Redraw the curves with the signal being smaller. How does this affect the
</p>
<p>setting of the threshold, or how does it influence how to set the threshold for a
</p>
<p>given ratio of hits to false alarms?
</p>
<p>4.5 Choose an online, social web site, such as Facebook, YouTube, or Yelp. Sketch
</p>
<p>several tasks that can be done by users with the site. Describe the intrinsic and
</p>
<p>extrinsic motivation(s) for users to perform those tasks. Do the same for an
</p>
<p>online course site, and for an online game. Note some insights that arise.
</p>
<p>References
</p>
<p>Bowmaker, J. K., &amp; Dartnall, H. J. A. (1980). Visual pigments of rods and cones in a human
retina. Journal of Physiology, 298, 501&ndash;511.
</p>
<p>Catchpole, K., McKeown, J. D., &amp; Withington, D. J. (2004). Localizable auditory warning pulses.
Ergonomics, 47(7), 748&ndash;771.
</p>
<p>Chaiklin, S. (2003). The zone of proximal development in Vygotsky&rsquo;s analysis of learning and
instruction. In A. Kozulin, B. Gindis, V. Ageyev, &amp; S. Miller (Eds.), Vygotsky&rsquo;s educational
theory and practice in cultural context (pp. 39&ndash;64). Cambridge: Cambridge University.
</p>
<p>Cs&iacute;kszentmih&aacute;lyi, M. (1990). Flow: The psychology of optimal experience. New York, NY:
Harper and Row.
</p>
<p>120 4 Behavior: Basic Psychology of the User</p>
<p/>
</div>
<div class="page"><p/>
<p>Deci, E. L. (1971). Effects of externally mediated rewards on intrinsic motivation. Journal of
Personality and Social Psychology, 18(1), 105&ndash;115.
</p>
<p>Duchowski, A. T. (2007). Eye tracking methodology: Theory and practice. London: Springer.
Findlay, J. M., &amp; Gilchrist, I. D. (2003). Active vision: The psychology of looking and seeing.
</p>
<p>Oxford: Oxford University Press.
Friedrich, M. B. (2008). Implementierung von schematischen Denkstrategien in einer h&ouml;heren
</p>
<p>Programmiersprache: Erweitern und Testen der vorhandenen Resultate durch Erfassen von
</p>
<p>zus&auml;tzlichen Daten und das Erstellen von weiteren Strategien (Implementing diagrammatic
</p>
<p>reasoning strategies in a high level language: Extending and testing the existing model results
</p>
<p>by gathering additional data and creating additional strategies). Faculty of Information
Systems and Applied Computer Science, University of Bamberg, Germany.
</p>
<p>Galanter, E. (1962). Contemporary psychophysics. In R. Brown, E. Galanter, E. H. Hess, &amp; G.
Mandler (Eds.), New directions in psychology (pp. 87&ndash;156). New York: Holt, Rinehart &amp;
Winston.
</p>
<p>Garner, W. R. (1974). The processing of information and structure. Potomac, MD: Erlbaum.
Gibson, J. J. (1979). The ecological approach to visual perception. Boston: Houghton Mifflin.
Holmqvist, K., Nystr&ouml;m, M., Andersson, R., Dewhurst, R., Jarodzka, H., &amp; van de Weijer, J.
</p>
<p>(2011). Eye tracking: A comprehensive guide to methods and measures. New York, NY:
Oxford University Press.
</p>
<p>Kennedy, A., &amp; Baccino, T. (1995). The effects of screen refresh rate on editing operations using
a computer mouse pointing device. The Quarterly Journal of Experimental Psychology,
48A(1), 55&ndash;71.
</p>
<p>Kubovy, M., &amp; van Valkenburg, D. (2001). Auditory and visual objects. Cognition, 80, 97&ndash;126.
Maslow, A. H. (1943). A theory of human motivation. Psychological Review, 50(4), 370&ndash;396.
Moore, R. J., &amp; Churchill, E. F. (2011). Computer interaction analysis: Toward an empirical
</p>
<p>approach to understanding user practice and eye gaze in GUI-based interaction. Computer
Supported Cooperative Work, 20(6), 497&ndash;528.
</p>
<p>Navalpakkam, V., &amp; Churchill, E. F. (in press). Eyetracking: A brief introduction. In J. S. Olson
&amp; W. Kellogg (Eds.), Ways of knowing, HCI methods. Heidelberg: Springer.
</p>
<p>Nielsen, J., &amp; Pernice, K. (2010). Eyetracking web usability. Berkeley, CA: New Riders.
Peterson, S. A., &amp; Simon, T. J. (2000). Computational evidence for the subitizing phenomenon as
</p>
<p>an emergent property of the human cognitive architecture. Cognitive Science, 24(1), 93&ndash;122.
Pink, D. H. (2009). Drive. New York, NY: Riverhead Books.
Reingold, E. M., Loschky, L. C., McConkie, G. W., &amp; Stampe, D. M. (2003). Gaze-contingent
</p>
<p>multiresolution displays: An integrative review. Human Factors, 45(2), 307&ndash;328.
Ryan, R. M., &amp; Deci, E. L. (2000). Self-determination theory and the facilitation of intrinsic
</p>
<p>motivation, social development, and well-being. American Psychologist, 55, 68&ndash;78.
Sekuler, R., &amp; Blake, R. (2005). Perception (5th ed.). New York, NY: McGraw-Hill.
Stevens, S. S., &amp; Newman, E. B. (1936). The localization of actual sources of sound. American
</p>
<p>Journal of Psychology, 48, 297&ndash;306.
Strutt, J. W. (Lord Rayleigh, Third Baron of Rayleigh) (1907). On our perception of sound
</p>
<p>direction. Philosophical Magazine, 13, 214&ndash;232.
Swets, J. A. (1973). The relative operating characteristic in psychology. Science, 182, 990&ndash;1000.
Swets, J. A., Tanner, W. P., &amp; Birdsall, T. G. (1961). Decision processes in perception.
</p>
<p>Psychological Review, 68, 301&ndash;340.
Treisman, A. M., &amp; Gelade, G. (1980). A feature integration theory of attention. Cognitive
</p>
<p>Psychology, 12, 97&ndash;136.
Wickens, C. D., Hollands, J. G., Banbury, S., &amp; Parasuraman, R. (2014). Engineering psychology
</p>
<p>and human performance (4th ed.). Boston, MA: Pearson.
Wickens, T. D. (2002). Elementary signal detection theory. Oxford: Oxford University Press.
</p>
<p>References 121</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 5
</p>
<p>Cognition: Memory, Attention,
</p>
<p>and Learning
</p>
<p>Abstract Memory, attention, learning are intertwined in the user&rsquo;s cognitive
</p>
<p>processing. These are the basic mechanisms of the user&rsquo;s cognitive architecture
</p>
<p>and thus provide the basis for cognition. Users have several types of memory that
</p>
<p>are important for computer use. Attention can be seen as the set of items being
</p>
<p>processed at the same time and how they are being processed. If there are more
</p>
<p>items stored in memory or the items in memory are better organized these effects
</p>
<p>will improve performance and provide the appearance of more attention. Users
</p>
<p>also learn constantly. The effects of learning lead to more items being stored in
</p>
<p>memory and allow the user to attend to more aspects of a task.
</p>
<p>5.1 Introduction
</p>
<p>Memory and attention both play an important role in interaction. Complementing
</p>
<p>these two facilities is the user&rsquo;s ability to learn things in a variety of ways.
</p>
<p>Together, these three concepts form the basics of the information processing
</p>
<p>mechanisms of a user&rsquo;s cognitive architecture. We consider the three concepts
</p>
<p>together here because of their interdependencies, focusing on the most important
</p>
<p>aspects with respect to computer users, rather than covering everything that is
</p>
<p>known about them.
</p>
<p>It is worth noting at this point that the term memory is used in three different
</p>
<p>ways. The first refers to the mental function of retaining information about
</p>
<p>things&mdash;stimuli, events, images, ideas, and so on&mdash;when those things are no longer
</p>
<p>present. The second refers to the hypothesized storage system in the brain where
</p>
<p>this information is stored. The third refers to the information that is stored itself. In
</p>
<p>order to avoid ambiguities we refer to storage of items in and retrieval (or recall) of
</p>
<p>items from memory when we want the first meaning; we refer to memory when we
</p>
<p>want the second meaning; and we refer to items (or information) in memory when
</p>
<p>we want the third meaning.
</p>
<p>F. E. Ritter et al., Foundations for Designing User-Centered Systems,
DOI: 10.1007/978-1-4471-5134-0_5, ï¿½ Springer-Verlag London 2014
</p>
<p>123</p>
<p/>
</div>
<div class="page"><p/>
<p>Users&rsquo; initial perceptions of an interface will be influenced by how they store
</p>
<p>and process information in short-term memory, and by how the information in
</p>
<p>their long-term memory helps them interpret that interface. The way people use a
</p>
<p>system will be greatly influenced by how well they can retrieve commands and
</p>
<p>locations of objects from memory. Similarly, their feelings of success with a
</p>
<p>system will be influenced by their biases in retrieving information about past
</p>
<p>successes and failures with the system.
</p>
<p>Attention refers to the selective aspects of perception which function so that at
</p>
<p>any instant a user focuses on particular features of the environment to the relative
</p>
<p>exclusion of others. It plays a central role in interaction, where it often is not
</p>
<p>possible to interact with all aspects of the interface at the same time. Some
</p>
<p>interfaces require less attention from the user and this can be a good thing if it
</p>
<p>allows them to perform more than one task at a time efficiently.
</p>
<p>User performance improves through learning. Learning is the most important
</p>
<p>process for adapting the user to the machine. There are several ways of describing
</p>
<p>learning, but for users the most important aspects of learning are probably learning
</p>
<p>facts and learning skills (or procedures) to perform tasks, but there is also learning
</p>
<p>to recognize images and perceptual-motor behavior.
</p>
<p>5.2 Memory
</p>
<p>Memory is one of the most studied areas in psychology. Understanding memory
</p>
<p>will help you as a designer to make it easier for users to memorize and later
</p>
<p>remember what they want or need to know. We begin by dealing with the structure
</p>
<p>of memory, which should enable you to follow the rest of the chapter more easily
</p>
<p>(this approach of providing a way to organize what you will learn is itself a result
</p>
<p>of memory research).
</p>
<p>5.2.1 Types of Memory
</p>
<p>Memory can be categorized in several ways. We will first look at memory based
</p>
<p>on where it is stored. Then we will examine memories by their content, including
</p>
<p>memories about a particular time and place (episodic), about object types
</p>
<p>(semantic), about facts (declarative), and about how to do a task (procedural).
</p>
<p>While there are other ways to conceptually organize memory, for system design,
</p>
<p>the set of categories we present here will give you a broad overview of the issues.
</p>
<p>5.2.1.1 Iconic Memory
</p>
<p>We can start our discussion of memory with perceptual-based information, spe-
</p>
<p>cifically images. Perception, while fleeting, is not completely temporary. There is
</p>
<p>124 5 Cognition: Memory, Attention, and Learning</p>
<p/>
</div>
<div class="page"><p/>
<p>an image left when you close your eyes or after an image you have been looking at
</p>
<p>has disappeared. This is called iconic memory.
</p>
<p>Visual iconic memory holds only a few items. Some suggest a limit of two or
</p>
<p>three items (Zhang and Simon 1985); others suggest a few more. These items also
</p>
<p>decay (disappear) at a fairly fast rate. Sperling (1961) had subjects view a screen of
</p>
<p>numbers and then asked them to retrieve items after the items were no longer
</p>
<p>displayed. He determined that items exist in a temporary memory store for about
</p>
<p>500 ms, with an exponential decay rate. If items are not processed, about half of
</p>
<p>the records of these items disappear in each half second.
</p>
<p>Items can be put into short-term or long-term memory by processing them.
</p>
<p>However, as this takes time, the other items can decay and be lost from iconic
</p>
<p>memory. Thus items that appear on an interface for a short time have to be noticed
</p>
<p>and processed to be remembered.
</p>
<p>5.2.1.2 Short-Term Memory
</p>
<p>Short-term memory (STM) is a temporary memory store. Work by Atkinson and
</p>
<p>Shiffrin (1968) helped establish STM as a common concept in memory research. It
</p>
<p>can be considered analogous to the registers in a computer. Cognition writes
</p>
<p>information into short-term memory but, unlike the computer, the contents decay
</p>
<p>with time. You might start out across the room knowing the phone number you
</p>
<p>want to dial, or start to bring up a browser to type in a URL, but by the time you
</p>
<p>get there, physically or metaphorically, you may have forgotten the number or
</p>
<p>URL. This type of loss is one of the first ways that people get introduced to short-
</p>
<p>term memory.
</p>
<p>George Miller, in a famous study (Miller 1956) found that, for unrelated
</p>
<p>objects, users could remember around seven meaningful items (plus or minus two).
</p>
<p>The estimate of the rate of loss of these items varies somewhat based on who is
</p>
<p>studied and what they are trying to remember. Some authors have found that half
</p>
<p>the information disappears in about 5 s if it is not rehearsed (practiced).
</p>
<p>Short-term memory is often used to store lists or sets of items to work with.
</p>
<p>There are several interesting and immediate effects of memory of lists that are
</p>
<p>worth knowing about. The first effect, called primacy, is that items that appear at
</p>
<p>the start of a list are more easily retrieved from memory.
</p>
<p>The second is that distinctive items in a list are better retrieved (the Von
</p>
<p>Restorff effect). For example, if they are printed in red ink or a bell goes off when
</p>
<p>you read them, or they are in some other way distinct or important, they will be
</p>
<p>better retrieved. The improvement in memorability requires distinctiveness&mdash;
</p>
<p>highlighting a whole text and putting a box around it does not help because
</p>
<p>nothing stands out. Similarly, writing everything in red does not help, but writing
</p>
<p>only one word in ten in red will help. This effect is also illustrated later in this
</p>
<p>chapter by discussing Nepal and encoding.
</p>
<p>The third is that items in a list that make more sense, IBM, PDQ and XYZ, are
</p>
<p>better retrieved than items that do not have associations for everybody, such as
</p>
<p>5.2 Memory 125</p>
<p/>
</div>
<div class="page"><p/>
<p>SCE, ORD and PIA. If the user can group items into a meaningful item, to chunk
</p>
<p>it, the subitems are easier to recover because just the chunk has to be retrieved.
</p>
<p>These associations or chunks vary across people. We include a few examples in
</p>
<p>Table 5.1, including an item that would only make sense to a computing system.
</p>
<p>Finally, the last items presented in a list are better retrieved as well (the recency
</p>
<p>effect). The primacy effect and the recency effect can be combined to create a
</p>
<p>serial position curve, as shown in Fig. 5.1.
</p>
<p>These regularities suggest that you cannot increase your short-term memory by
</p>
<p>trying harder, but you can by presenting items in a particular order. Knowing more
</p>
<p>can also help. In air travel, for example, if you know that ORD is the airport code
</p>
<p>for O&rsquo;Hare Airport, FRA is Frankfurt Airport (am der Main), and PIA is Peoria
</p>
<p>International Airport, then you only have to retrieve three codes rather than nine
</p>
<p>letters if you are presented with FRAORDPIA. This process was used in early
</p>
<p>phone systems in the US where regions were given names from the associated
</p>
<p>numbers, for example, as immortalized in the song &lsquo;&lsquo;Pennsylvania 6-5000&rsquo;&rsquo;, which
</p>
<p>would have been 726-5000 (and would not have been as catchy).
</p>
<p>Later theories, such as that embodied in the ACT-R theory (Anderson 1993,
</p>
<p>2007), propose that short-term memory is just activated long-term memory. As
</p>
<p>processing occurs, objects are moved directly from perception into long-term
</p>
<p>memory. The observed effects for items in short-term memory are just the effects
</p>
<p>Table 5.1 Abbreviations that are more memorable in one culture than another. (Note that
German capitalizes differently compared to English)
</p>
<p>For German For English
</p>
<p>MfG = Mit freundlichen Gr&uuml;&szlig;en
with kind regards
</p>
<p>ABC = American or Australian
Broadcasting Company
</p>
<p>CDU = Christliche demokratische Union
a large German political party
</p>
<p>PDQ = Pretty darn quick
</p>
<p>SPD = Sozial demokratische Partei Deutschlands.
Another German political party
</p>
<p>ASAP = As soon as possible
</p>
<p>DRK = Deutsches Rotes Kreuz.
rescue service/ambulance/Red Cross
</p>
<p>PIA = Peoria International Airport
</p>
<p>ZDF = Zweites Deutsches Fernsehen. TV Station TLAs = Three Letter Abbreviations
or Acronyms
</p>
<p>GmbH = Gesellschaft mit beschraenkter
Haftung (Society with limited liability,
i.e., a limited company)
</p>
<p>CMU = Concrete Masonry Unit
</p>
<p>For neither culture: http://us.support.tomtom.com/cgi-bin/tomtom_us.cfg/php/enduser/std_adp.
php?p_faqid=2053&amp;p_created=1092921663&amp;p_sid=lXplZnAj&amp;prod_lvl1=141&amp;prod_lvl2=
2030&amp;cat_lvl1=2356&amp;p_accessibility=&amp;p_redirect=&amp;p_lva=&amp;p_sp=cF9zcmNoPSZwX3Nv
cnRfYnk9JnBfZ3JpZHNvcnQ9JnBfcm93X2NudD01NCw1NCZwX3Byb2RzPTE0MSwxO
DMsMTk1NCwyMDMwJnBfY2F0cz0yMzU2JnBfcHY9MS4xNDE7Mi4xODM7Mi4xOTU
0OzIuMjAzMCZwX2N2PTEuMjM1NiZwX3NlYXJjaF90eXBlPWFuc3dlcnMuc2VhcmNo
X2ZubCZwX3BhZ2U9MQ**&amp;p_li=&amp;p_topview=1
</p>
<p>126 5 Cognition: Memory, Attention, and Learning</p>
<p/>
</div>
<div class="page"><p/>
<p>you see with less strong long-term memories. The number of items held in long-
</p>
<p>term memory that can be worked with at once is working memory, which we cover
</p>
<p>next.
</p>
<p>5.2.1.3 Working Memory
</p>
<p>Working memory is considered a more dynamic concept than STM. It is
</p>
<p>hypothesized as a temporary memory store (an audio or semantic scratchpad) with
</p>
<p>associated mechanisms for rehearsing, refreshing, and using the stored informa-
</p>
<p>tion. It also includes a mechanism of central or executive attention that regulates
</p>
<p>the contents of that memory store based on performing a task. This view is based
</p>
<p>on the models and definitions of Baddeley (1976, 1986). Working memory is seen
</p>
<p>less as a scratch pad than short-term memory, but it is viewed more within the
</p>
<p>context of the processing that will use it, and how the scratch pad and processing
</p>
<p>interact. This view of working memory suggests that increases in working memory
</p>
<p>can have numerous effects, ranging from more directed attention to better per-
</p>
<p>formance in general (Engle 2002).
</p>
<p>These items in working memory are often rehearsed in what is called a pho-
</p>
<p>nological loop, where the material to be stored is repeated rapidly to oneself. This
</p>
<p>loop can hold about 2 s of verbal information. The direct implications are that
</p>
<p>items that are faster to pronounce take up less space. This has been found for
</p>
<p>numbers in different languages&mdash;languages with long names (in syllables) for
</p>
<p>numbers lead to fewer objects that can be retrieved. &lsquo;&lsquo;Seven,&rsquo;&rsquo; which is two syl-
</p>
<p>lables long, for example, will take up more space than &lsquo;&lsquo;one.&rsquo;&rsquo; Running through
</p>
<p>this loop only holds information; it does not alone increase memory for the items.
</p>
<p>Working memory for a task is influenced by several factors. Focusing on a
</p>
<p>single task directly improves the amount of working memory available for that
</p>
<p>task. There also appear to be individual differences in working memory, with some
</p>
<p>people having more working memory than others (Daneman and Carpenter 1980;
</p>
<p>Lovett et al. 2000). Talking while doing a task provides some additional memory
</p>
<p>(not more traditional working memory, but more memory through the acoustical
</p>
<p>loop, which is repeating information verbally to yourself and hearing it, tempo-
</p>
<p>rarily increasing your effective working memory), and in addition to slowing down
</p>
<p>performance can lead to more insights (Ericsson and Simon 1993). Further work
</p>
<p>suggests that extreme amounts of practice can lead to a type of increase in working
</p>
<p>memory (Ericsson and Kintsch 1995).
</p>
<p>Presentation Order
</p>
<p>A
m
</p>
<p>o
u
n
t 
</p>
<p>R
e
m
</p>
<p>e
m
</p>
<p>b
e
re
</p>
<p>dFig. 5.1 The Serial Position
curve. The primacy effect is
that earlier items are better
remembered and the recency
effect is that items more
recently encountered are
better remembered
</p>
<p>5.2 Memory 127</p>
<p/>
</div>
<div class="page"><p/>
<p>5.2.1.4 Long-Term Memory
</p>
<p>Long-term memory (LTM) contains items that that you have permanently enco-
</p>
<p>ded. If items are processed enough they are put into long-term memory. Examples
</p>
<p>of different types of items that are typically held in long term memory include your
</p>
<p>name, the name of your dog, and how to start up your computer.
</p>
<p>Items can be put into long-term memory from short-term memory. These items
</p>
<p>can be objects, associations, or procedures for doing a task. Studies in this area
</p>
<p>make various suggestions about the amount of time required to move items from
</p>
<p>short-term memory into long-term memory.
</p>
<p>Encoding is the storing of items in memory so that they can later be retrieved.
</p>
<p>Items are put into long-term memory by processing them. More meaningful pro-
</p>
<p>cessing at encoding, such as using rehearsal, seems to make it possible to retrieve
</p>
<p>items more reliably over a longer period of time (Tulving 2002).
</p>
<p>Declarative knowledge, like knowing the capital of Nepal, requires attention to
</p>
<p>put the items into long-term memory. This task is easier if the items are already
</p>
<p>known. Being able to retrieve the name of the capital of Nepal from memory
</p>
<p>would be harder if you did not know that Nepal was a country in South America.
</p>
<p>This fact may help you to be able to recall the role of encoding better.1
</p>
<p>Procedural skills, such as typing, can get put into long-term memory without
</p>
<p>attention to this process (through implicit learning), but are usually best done with
</p>
<p>attention and deliberate practice. Procedural skills initially will require attention to
</p>
<p>perform; with practice they can require less attention, like driving or typing. The
</p>
<p>amount of processing you have to do can also influence how well these memories
</p>
<p>get created, which we will cover shortly.
</p>
<p>Retention is the interval between encoding and retrieval. Activities during
</p>
<p>retention can cause forgetting, such as processing similar items; interruptions; and
</p>
<p>so on. Length of retention interval is important, too, which is covered in the section
</p>
<p>on learning.
</p>
<p>Retrieval depends upon the information available to cue recall. What is
</p>
<p>retrieved depends on having information on hand&mdash;a request&mdash;to start a retrieval.
</p>
<p>Retrieval is usually better (within about 10% in accuracy or response time) the
</p>
<p>more similar recall circumstances are to the internal and external encoding cir-
</p>
<p>cumstances (even down to temperature, lighting, mood, etc.).
</p>
<p>We can remember much more information when it is meaningful and when its
</p>
<p>meaning is processed at encoding time. Later discovery of its meaning does not
</p>
<p>especially help when trying to retrieve it. Failure to process meaningful infor-
</p>
<p>mation also makes it harder to later retrieve that information. Ability to recall is
</p>
<p>thus affected by success at each step&mdash;encoding, retention, and retrieval.
</p>
<p>1 This perverse statement is explained in a later section. Most students remember this part of the
book.
</p>
<p>128 5 Cognition: Memory, Attention, and Learning</p>
<p/>
</div>
<div class="page"><p/>
<p>There is some debate about how long items in long-termmemory are stored. Some
</p>
<p>theories propose that items decay to the point that they are no longer retrievable, and
</p>
<p>other theories propose that the items are still there, but no longer retrievable because
</p>
<p>they are no longer unique enough to be retrievable. The implications of these two
</p>
<p>different approaches may be basically the same for system design.
</p>
<p>5.2.1.5 Declarative Versus Procedural Memory
</p>
<p>Descriptions of memory often divide memory into two types to illustrate different
</p>
<p>effects. Perhaps the most common is the difference between declarative and pro-
</p>
<p>cedural memory, which is used to categorize their contents based on how they are
</p>
<p>used.
</p>
<p>The contents of declarative memory are facts or statements about the world,
</p>
<p>such as &lsquo;&lsquo;The hippy is in the park,&rsquo;&rsquo; &lsquo;&lsquo;the star is above the square,&rsquo;&rsquo; and &lsquo;&lsquo;Colleen&rsquo;s
</p>
<p>hair is auburn.&rsquo;&rsquo; Retrieval of items from declarative memory is improved by
</p>
<p>practice, and the items are intentionally generated for sharing and verbalizing. One
</p>
<p>study estimated that it takes about 6 s of processing to encode an item for sub-
</p>
<p>sequent retrieval (Simon 1974), although the time required is context dependent:
</p>
<p>more complex items may take longer.
</p>
<p>Declarative memory is used to store and retrieve information such as simple
</p>
<p>user instructions, user passwords, and to understand materials in interfaces.
</p>
<p>The contents of procedural memory are acts, or sequences of steps that describe
</p>
<p>how to do particular tasks. These items can be viewed as a type of programming
</p>
<p>language for cognition. Examples of items that would be stored in procedural
</p>
<p>memory include how to type, how to ride a bicycle, and many aspects of how to
</p>
<p>program or use an interface.
</p>
<p>Items in procedural memory are generally more robust against decay, and
</p>
<p>retrieval is often less context sensitive than items in declarative memory (Jensen
</p>
<p>and Healy 1998). Like declarative memory, retrieval and application gets faster
</p>
<p>with practice.
</p>
<p>The ACT-R theory (a unified theory of cognition, or &lsquo;&lsquo;UTC,&rsquo;&rsquo; realized as a
</p>
<p>computer program, and explained earlier in the introduction and used in the
</p>
<p>concluding chapter) uses these two types of memory explicitly, both procedural
</p>
<p>(rules) and declarative (chunks). The Soar theory (another UTC) represents
</p>
<p>declarative information as the result of a procedure to retrieve information from
</p>
<p>memory, and is thus a type of procedural memory.
</p>
<p>5.2.1.6 Implicit Versus Explicit Memory
</p>
<p>Memories can also be categorized as explicit or implicit: items stored in explicit
</p>
<p>memory are reportable, whereas items in implicit memory are not. Most declar-
</p>
<p>ative information is explicit in that it can be reported, whereas most procedural
</p>
<p>information is implicit in that the precise details are not reportable.
</p>
<p>5.2 Memory 129</p>
<p/>
</div>
<div class="page"><p/>
<p>Some procedural information, such as how to use the Emacs text editor, a
</p>
<p>keystroke driven editor, starts out fairly explicit in that the user can describe what
</p>
<p>they are doing and why. Over time procedural information, or skills learned
</p>
<p>through trial and error without explicit, declarative reflection, can become implicit.
</p>
<p>In this case, the user can recognize objects, can have a way of performing a task
</p>
<p>but without being able to note why or how, and in some cases cannot even be able
</p>
<p>to recognize that they can do the task well. If the information remains in explicit
</p>
<p>memory users can perform tasks more robustly and, because they can describe how
</p>
<p>to do the tasks, they can help others more readily.
</p>
<p>Users can be encouraged to store information in explicit memory by helping
</p>
<p>them develop a mental model of a task, and by providing them with time to reflect
</p>
<p>on their learning. Information gets put into implicit memory when the user works
</p>
<p>without a domain theory and learns through trial and error.
</p>
<p>Work with the 8-puzzle (see Fig. 5.2) has illustrated this effect in interfaces. In
</p>
<p>this puzzle there are eight tiles and nine spaces. The task is to arrange the tiles in
</p>
<p>numerical order (left to right, top to bottom). The interface in Fig. 5.2a requires
</p>
<p>users to note the tiles that had to be moved and where to move them to, as a way of
</p>
<p>encouraging users to plan and think ahead. It also provided them with an explicit
</p>
<p>representation of steps for their reflection. Users that saw the interface that
</p>
<p>required only clicking on the tile to move it into the adjacent blank space
</p>
<p>(Fig. 5.2b) needed less explicit input and appeared to encourage behavior that led
</p>
<p>to less information being stored in memory.
</p>
<p>In the first interface subjects reflected on their moves and developed an explicit
</p>
<p>representation of the problem. They took fewer moves to perform the task than those
</p>
<p>who used the second, direct manipulation, interface (although they took more time).
</p>
<p>1 32
</p>
<p>8
</p>
<p>4
</p>
<p>7
</p>
<p>5
</p>
<p>6
</p>
<p>Click on the tile to move 
into the empty space.
</p>
<p>1 32
</p>
<p>8
</p>
<p>4
</p>
<p>7
</p>
<p>5
</p>
<p>6
</p>
<p>Type in the tile to move [1-8]:    ____
</p>
<p>Type in direction to move [N/S/E/W]: ____
</p>
<p>(a) (b)
</p>
<p>Fig. 5.2 Two types of interfaces for the 8 puzzle that lead to different types of learning.
a Interface leading to more explicit representation. b Interface leading to more implicit
representation
</p>
<p>130 5 Cognition: Memory, Attention, and Learning</p>
<p/>
</div>
<div class="page"><p/>
<p>The subjects in the second interface were less able to describe how to solve the
</p>
<p>puzzle, but were slightly faster at solving it (Golightly et al. 1999; O&rsquo;Hara and
</p>
<p>Payne 1998). This effect, of increased response time leading to fewer, more
</p>
<p>thoughtful, commands has been seen before (in a study by Forgie cited in Nickerson
</p>
<p>1969, p. 171).
</p>
<p>These results raise interesting questions about interface design. If learning is an
</p>
<p>important feature of the system, then interfaces that encourage reflection and
</p>
<p>learning about the domain may be more suitable, even though it takes more time to
</p>
<p>do the task. Tutoring systems that support the development of more explicit rep-
</p>
<p>resentations, for example, will help learners be able to explain and later teach how
</p>
<p>to do a task.
</p>
<p>5.2.1.7 Prospective Memory
</p>
<p>Prospective memory is also important for users. It is a form of memory that
</p>
<p>involves remembering to do something at the appropriate time based on either
</p>
<p>events or absolute times. The storage of information for future activities (both in
</p>
<p>the short- and long-term) is prone to failure and appears limited. There have been
</p>
<p>tools for centuries to help with retrieving these items from memory (strings tied
</p>
<p>around fingers), but there are also now computational-based tools to support
</p>
<p>prospective memory, such as time schedulers, calendars, and To Do lists, partic-
</p>
<p>ularly on smartphones.
</p>
<p>5.2.2 Mnemonics and Aids to Memory
</p>
<p>There are several ways of improving memory performance&mdash;both storage and
</p>
<p>retrieval&mdash;which exploit the way that memory is arranged and operates. The use of
</p>
<p>mnemonics, for example, is a technique that helps to increase the amount or
</p>
<p>quality of information, or the speed at which it is retrieved.
</p>
<p>One of the first mnemonics is the method of loci (in Latin, &lsquo;places&rsquo;). In this
</p>
<p>mnemonic, a speaker (typically) would store in memory something familiar to
</p>
<p>them, like a set of locations in their house. They would then associate the items
</p>
<p>that they later wanted to with these locations. Retrieving a set of items in this way
</p>
<p>is much more robust than trying to recall each item individually without any
</p>
<p>associated, structured context. Users are not particularly likely to use this method,
</p>
<p>but you might when giving a talk, by placing the major points you want to make
</p>
<p>one per room in a familiar house. Expert memory demonstrations often use either
</p>
<p>this technique, or a similar one based on making up a story using the objects. One
</p>
<p>notable subject increased their memory span to 80 digits over a course of 230 h of
</p>
<p>practice by using athletics running times to group the digits (Ericsson et al. 1980).
</p>
<p>Another popular mnemonic is to have a phrase to cue the retrieval of a set of
</p>
<p>things. For example, &lsquo;&lsquo;Active Penguins Seek the Nearest Deep Pool&rsquo;&rsquo; is a mne-
</p>
<p>monic for the seven layers of the Open Systems Interconnection (OSI) model of
</p>
<p>5.2 Memory 131</p>
<p/>
</div>
<div class="page"><p/>
<p>networks, and &lsquo;&lsquo;Richard Of York Gave Battle In Vain&rsquo;&rsquo; is a mnemonic for the
</p>
<p>colors of the rainbow in sequence.
</p>
<p>Probably the most useful aid to recalling items for users is recognition. Rec-
</p>
<p>ognition memory is more robust than recall memory. It is easier to recognize
</p>
<p>something that you have previously seen than it is to recall what it was that you
</p>
<p>saw. Many interfaces take advantage of recognition memory by putting objects or
</p>
<p>actions in a place where they can be recognized instead of requiring the user to
</p>
<p>recall them. Dialogue boxes and explicit links in web pages are the most overt
</p>
<p>form of this. Menus hide the cues one level or more, but the same process is at
</p>
<p>work.
</p>
<p>The trade-off here is that for experts the recognition process and its application
</p>
<p>in an interface is often much slower than the recall process. For example, looking
</p>
<p>for and then recognizing objects on a menu to perform a file manipulation task is
</p>
<p>typically slower than recalling and using keystroke commands to do the same task.
</p>
<p>More expert users, or those doing a task quite often, will be able to use recall
</p>
<p>memory, and most likely will want to for greater efficiency. The use of recognition
</p>
<p>memory appears to require offering the user multiple, related items from which the
</p>
<p>user has to recognize (and select) the one they want. This represents a design trade-
</p>
<p>off, which will be best addressed if you know your user&rsquo;s tasks as well as the
</p>
<p>available technologies. A simple solution is to provide shortcuts of some kind, and
</p>
<p>provide the user with access to them as they use the interface, almost turning the
</p>
<p>interface into a tutor of itself.
</p>
<p>Anomalous or interesting things are better retrieved from memory. As noted
</p>
<p>earlier, the learning of declarative information is influenced by the content. For
</p>
<p>example, Nepal is not in South America, so if you knew this when you were
</p>
<p>reading a previous section of this chapter, you are likely to recall that section better
</p>
<p>because it stood out. This von Restorff effect was originally seen when looking at
</p>
<p>learning lists of words. If a bell was rung when a word was presented, that word
</p>
<p>was subsequently better recalled. This effect applies in general to things that are
</p>
<p>distinctive. For example, a word in red will be easier to recall if it appears in a list
</p>
<p>of words in black. (Putting all the words in red will not work nor will highlighting
</p>
<p>all of a section to memorize; the point is for objects to stand out from similar
</p>
<p>items, so highlighting the entire book does not work!)
</p>
<p>Finally, practice and repetition of the target task helps. This is another example
</p>
<p>of the Von Restorff effect. You should now be able to recall it better because you
</p>
<p>have seen it and, more importantly, processed it more often. Practice and repetition
</p>
<p>help to increase the amount of information stored for later retrieval from memory,
</p>
<p>but only if attention is paid to the stimuli and the stimuli are elaborated. A basic
</p>
<p>and early theory in memory research was about levels of processing. Greater
</p>
<p>processing of stimuli leads to better subsequent retrieval of those stimuli. Counting
</p>
<p>the number of vowels in a piece of text does not lead to very good retention of that
</p>
<p>text. Reading the text leads to better retention, and arguing with the text or another
</p>
<p>reader helps even more; rewriting in your own words is even better. This is one
</p>
<p>reason that teachers ask you about what you have read and encourage you to
</p>
<p>process it actively.
</p>
<p>132 5 Cognition: Memory, Attention, and Learning</p>
<p/>
</div>
<div class="page"><p/>
<p>These aids to improving memory performance are presented more formally in
</p>
<p>study guides. Another method, PQ4R, is described below.
</p>
<p>5.2.3 PQ4R: A Way to Improve Reading Comprehension
</p>
<p>A common question about memory is how to apply what we know about it to
</p>
<p>learning. One approach to integrate what we know about memory and learning into
</p>
<p>a study method is the PQ4R method (preview, question, read, reflect, recite,
</p>
<p>review). In this method, the learner first previews the material. This helps with
</p>
<p>distributing the learning, and it also starts to form a structure for learning, a type of
</p>
<p>elaboration (Thomas and Robinson 1972).
</p>
<p>The next step is to generate questions that the reading should answer. These can
</p>
<p>come from the preview, and from your goals and previous knowledge.
</p>
<p>The four Rs come quickly then. The reading is done with the preview and
</p>
<p>questions in mind. This should be a more situated experience in that the point of
</p>
<p>the reading and scope of the reading are clearer.
</p>
<p>After reading, the material is reflected upon. This is canonically done by writing
</p>
<p>up a short summary and explicitly writing out answers to the questions from the
</p>
<p>second set.
</p>
<p>Then the material is recited, that is, spoken out loud. This helps form different
</p>
<p>memories (verbal ones), and also adds to the distributed learning approach that has
</p>
<p>been set up.
</p>
<p>Finally, all the materials are later reviewed, or studied. This allows another pass
</p>
<p>and also allows any questions arising during the break to be answered.
</p>
<p>This book is designed to help support the use of PQ4R and similar learning
</p>
<p>methods that emphasize multiple passes and reflection during learning. On the
</p>
<p>book level, it does this by providing a detailed table of contents that can help with
</p>
<p>previews, introductory chapters that note why you may be interested in this
</p>
<p>material, and chapters providing structures (the ABCS, cognitive architectures)
</p>
<p>that can be used to organize the material. On the chapter level, it provides abstracts
</p>
<p>for each chapter that can serve as previews, and questions at the end of each
</p>
<p>chapter than can be used to guide learning.
</p>
<p>You may see this sort of behavior exhibited by users when they get multiple
</p>
<p>chances to learn in the same interface using multimodal output, or when the
</p>
<p>instructions on how to use the material provide help with these stages by providing
</p>
<p>an overview, for example.
</p>
<p>5.2.4 Memory Biases
</p>
<p>There are other aspects of memory that need to be considered when working with
</p>
<p>and designing for users. Poor decision making, for example, is often influenced as
</p>
<p>5.2 Memory 133</p>
<p/>
</div>
<div class="page"><p/>
<p>much by the way memory retrieval supports decision making as by how the
</p>
<p>choices themselves are made. The inherent biases associated with memory can
</p>
<p>often affect how well it operates.
</p>
<p>5.2.4.1 Interference
</p>
<p>The retrieval of items from memory can either be hindered or helped by other
</p>
<p>items in memory. If two items are very similar they can be confused for one other.
</p>
<p>For example, if you spend a long time knowing someone&rsquo;s name incorrectly, or
</p>
<p>you type in a command incorrectly a few times, it can take much longer to correct
</p>
<p>this error. This type of interference has been proposed as one of the primary
</p>
<p>aspects that makes learning arithmetic difficult (Siegler 1988). The intelligent
</p>
<p>tutoring systems based on ACT-R, therefore, do not allow the user to practice
</p>
<p>incorrect knowledge (Anderson et al. 1989). This is likely to be one of the ways
</p>
<p>that they can help students learn the same material in one-third of the typical time
</p>
<p>(Corbett and Anderson 1990). Interface designers should thus be mindful of errors
</p>
<p>and how interfaces help users to not remember them!
</p>
<p>5.2.4.2 Retrieval Biases
</p>
<p>Items presented towards the beginning of a sequence (primacy) or towards the end
</p>
<p>of a sequence (recency) are more successfully retrieved from memory. When it
</p>
<p>comes to reasoning about a situation or a set of activities, the items retrieved to
</p>
<p>support reasoning will be biased in those two directions. The use of an external
</p>
<p>memory aid and formal analysis can help.
</p>
<p>The von Restorff effect will also apply. Information that is stored in a context
</p>
<p>that is distinctive will be easier to retrieve. The relative amounts or numbers of
</p>
<p>items retrieved will thus not support appropriate reasoning, as the items will not be
</p>
<p>retrieved in proportion to their occurrence in the world.
</p>
<p>5.2.4.3 Encoding Effects
</p>
<p>The content of an item that is to be stored in memory can be influenced by its
</p>
<p>encoding. The location of the item, the location of the user, sights, smells, sounds,
</p>
<p>and mental state can all be included in the way the item is encoded for storage.
</p>
<p>Examples of this include certain smells bringing back childhood memories, and
</p>
<p>certain people only recognized well in certain contexts. For example, we find it
</p>
<p>much harder to recognize students outside the classroom environment in which we
</p>
<p>met them.
</p>
<p>Users will have these same effects. The information that they can retrieve for
</p>
<p>computer systems may in some cases be tied to aspects of the interface that you did
</p>
<p>not intend or may not even have control over. The particular terminal or computer
</p>
<p>134 5 Cognition: Memory, Attention, and Learning</p>
<p/>
</div>
<div class="page"><p/>
<p>they use, their home page, or where they put a manual on a bookshelf may all
</p>
<p>become part of their knowledge about how to use a system because these aspects
</p>
<p>can influence the retrieval of items from memory. This also suggests that, for more
</p>
<p>robust recall of items from memory, users should be supported in building up a
</p>
<p>variety of retrieval cues and have a chance to practice (i.e., rehearse) these items in
</p>
<p>a variety of situations before they have to retrieve them in earnest.
</p>
<p>5.2.4.4 Priming
</p>
<p>Priming refers to how presenting objects before their use, sometimes quite briefly,
</p>
<p>facilitates their use and the use of items related to them. Typically, primes are
</p>
<p>presented for short periods of time, under a second, but it applies to all time
</p>
<p>periods. For example, anything about Nepal or South America would be more
</p>
<p>recognized by readers of this text because they have been used previously.
</p>
<p>This approach can be used to facilitate the retrieval of items from memory.
</p>
<p>When presented with a list of words to remember, such as &lsquo;&lsquo;bed rest awake tired
</p>
<p>dream wake snooze blanket doze slumber snore nap peace yawn drowsy,&rsquo;&rsquo; many
</p>
<p>subjects will report that &lsquo;&lsquo;sleep&rsquo;&rsquo; was included as well. This effect can be explained
</p>
<p>by noting that many, if not all, of these words prime the word &lsquo;&lsquo;sleep.&rsquo;&rsquo; When it is
</p>
<p>time to recall the words, the word &lsquo;&lsquo;sleep&rsquo;&rsquo; is also very active, and this is (falsely)
</p>
<p>used as a cue that it appeared in the list as well. The book by Intons-Peterson and
</p>
<p>Best (1998) explores this and related topics of distortions in memory.
</p>
<p>Users will find it easier to retrieve items from memory that have been recently
</p>
<p>used. This is a possible mechanism to explain why consistency within a system or
</p>
<p>between a manual and a system is important. Names of items in the manual will be
</p>
<p>more quickly identified in the interface if the same name is used. Related concepts
</p>
<p>will also be helped, but to a lesser extent.
</p>
<p>This effect also can lead to retrieving information to support previously held
</p>
<p>beliefs, rather than generating new ones. It is important then to provide users with
</p>
<p>external memory aids to help in the retention and analyses of situations.
</p>
<p>5.2.4.5 The Loftus Effect
</p>
<p>The Loftus effect (e.g., Loftus 1975), also known as the misinformation effect,
</p>
<p>describes how people take on knowledge implicitly from questions. Asking
</p>
<p>someone a question often leads them to assume and later learn the facts implicit in
</p>
<p>the question. Asking someone &lsquo;&lsquo;What color hat was the suspect wearing?&rsquo;&rsquo; will
</p>
<p>lead many people to infer and later recall (without understanding that they just
</p>
<p>inferred and did not see) that the suspect was indeed wearing a hat. In one of their
</p>
<p>original studies Loftus and her colleagues asked subjects if they recalled meeting
</p>
<p>Bugs Bunny at Disney World as a child (Loftus 2003). Depending on the condi-
</p>
<p>tion, about a third could erroneously recall this (Bugs is with Warner Brothers, not
</p>
<p>Disney!). Instructions and manuals can suggest capabilities not generally
</p>
<p>5.2 Memory 135</p>
<p/>
</div>
<div class="page"><p/>
<p>available, or could help support users by noting the interconnected nature of most
</p>
<p>systems. Multiple choice exams can, with their questions, remind you of com-
</p>
<p>ponents of the answer. For example, a question that asked you &lsquo;&lsquo;Which of the
</p>
<p>following is a type of memory?&rsquo;&rsquo; implies that there are several types. This type of
</p>
<p>test could help create false memories.
</p>
<p>If used directly, this effect can help users. Queries to users that provide context
</p>
<p>to the question or even a default action can help users.
</p>
<p>5.2.5 Implications for System Design
</p>
<p>What we already know about human memory provides numerous implications for
</p>
<p>improving the lot of the user. Users will be able to learn interfaces that are similar
</p>
<p>to other interfaces or other knowledge structures more easily than completely new
</p>
<p>interfaces. Users are limited in the amount of new information that they can
</p>
<p>perceive, comprehend, and learn. A fairly direct implication is to use words that
</p>
<p>users know, and use the words consistently to strengthen the chances of later
</p>
<p>successfully retrieving these words from memory.
</p>
<p>It has long been known that retrieving names from memory is faster than
</p>
<p>naming objects. This suggests that, instead of displaying icons, we might be better
</p>
<p>served by displaying words (Chilton 1996). The approach, of using names instead
</p>
<p>of icons would also help the visually impaired, who rely on software to translate
</p>
<p>computer interfaces into verbal representations. Raskin (2000, Sect. 6.3), provides
</p>
<p>further interesting examples and arguments encouraging the use of words instead
</p>
<p>of icons. Figure 5.3 shows icons used for translation during international travel, as
</p>
<p>well as some icons from interfaces that are more difficult to interpret.
</p>
<p>Our understanding of memory can and should influence password choice. This
</p>
<p>knowledge can inform more than &lsquo;&lsquo;experience and common sense,&rsquo;&rsquo; which is
</p>
<p>sometimes used. Users will want to choose passwords that are hard to guess, and
</p>
<p>systems may enforce this. However, many passwords that are hard to guess are
</p>
<p>arbitrary (that is, not meaningful to users) strings of letters, digits, and punctuation,
</p>
<p>such as &lsquo;&lsquo;ouibou94!3&rsquo;&rsquo;). Thus, some strong passwords are hard to recall when users
</p>
<p>need them. There have been surveys on what passwords people use when they are
</p>
<p>not given any guidance (the results are pretty scary from a security standpoint).
</p>
<p>What needs to happen more is helping users generate mnemonics for remembering
</p>
<p>the passwords, rather than writing them down on paper or installing them in a
</p>
<p>computer-based passport (unless you trust the computer company selling the
</p>
<p>passport, which many state attorney generals do not). The issue of recallable yet
</p>
<p>strong passwords is one of the topics routinely dealt with under the auspices of the
</p>
<p>topic of usability of security. Some analysts have argued for word-based pass-
</p>
<p>words, such as &lsquo;islandcarekeyboard&rsquo;, which is long and thus hard to guess, but
</p>
<p>easier to recall as each chunk is several letters rather than a single letter.
</p>
<p>There are several poorly understood but important questions relating to the use
</p>
<p>of memory with respect to system design:
</p>
<p>136 5 Cognition: Memory, Attention, and Learning</p>
<p/>
</div>
<div class="page"><p/>
<p>&bull; The impact of interruptions. Many work environments include numerous
</p>
<p>interruptions. The effect of these on the way that items are stored in, and
</p>
<p>retrieved from, memory is just starting to be studied. What work exists suggests
</p>
<p>to us that the length of interruption is less important than the similarity of
</p>
<p>material processed.
</p>
<p>&bull; Other memory tasks. Most of the memory literature concerns simply learning a
</p>
<p>list and then recalling it sometime later. Many work-related memorial tasks
</p>
<p>involve retaining some piece of information for a short time, then replacing it
</p>
<p>with some similar piece of information (&lsquo;keeping track&rsquo; tasks). These have not
</p>
<p>been studied very often.
</p>
<p>&bull; Support for memory. Most of the literature is studies of processes and archi-
</p>
<p>tectures of memory&mdash;but our interest is in preventing the need for memory and
</p>
<p>providing support for tasks requiring the use of memory. This is an active area
</p>
<p>for design.
</p>
<p>5.3 Attention
</p>
<p>Everyone knows what attention is. It is the taking possession by the mind in clear and
vivid form, of one out of what seem several simultaneously possible objects or trains of
thought&hellip;It implies withdrawal from some things in order to deal effectively with others,
and is a condition which has a real opposite in the confused, dazed, scatterbrained state.
</p>
<p>William James
</p>
<p>Fig. 5.3 The top figure is taken from a Kwikpoint travel guide designed to help communicate in
a foreign language (you point at what you mean), used with permission. Icons on the bottom are
taken from Word 2011 (The icons in Fig. 5.3b mean, from right to left: view field codes, zoom
100%, online layout, page layout, and automatic change. Word is improving in that you can now
mouse over the icons to learn their names.)
</p>
<p>5.2 Memory 137</p>
<p/>
</div>
<div class="page"><p/>
<p>Designing systems to attract, manage, and maintain attention is important.
</p>
<p>Figure 5.4 shows a user with a task that requires attention (driving), who is also
</p>
<p>attempting to perform an additional task (talking on a cell phone). If you would
</p>
<p>like a short demonstration of attention, go to http://www.youtube.com/watch?v=
</p>
<p>-AffEV6QlyY, which takes advantage of your ability to pay attention. It takes
</p>
<p>some time to understand, and you should not be too easily shocked.
</p>
<p>Attention refers to the selective aspects of perception which function so that at
</p>
<p>any instant a user focuses on particular features of the environment to the relative
</p>
<p>(but not complete) exclusion of others. There are several useful metaphors for
</p>
<p>describing attention. It can be seen as a set of buffers that hold information for
</p>
<p>processing. It is directly related to that processing as well.
</p>
<p>You might imagine attention as the area and process of central cognition, such
</p>
<p>as work being done on a table. Tasks that take less attention need less of the table
</p>
<p>or less of the time of the person working at the table. Many processes in human
</p>
<p>cognition are thus closely tied to the concept of attention as a space for cognition,
</p>
<p>and various parts of a processor can support attention.
</p>
<p>Figure 5.5 shows two common and important uses of attention. Both situations
</p>
<p>involve aspects of motor control and cognition, and require monitoring the situ-
</p>
<p>ation and taking corrective action. In both cases performance suffers when the
</p>
<p>tasks are not given sufficient attention.
</p>
<p>There are also other aspects of human behavior that are not based on focal or
</p>
<p>conscious attention. We can still do some information processing without con-
</p>
<p>sciously attending to information&mdash;how else would we know to shift our attention
</p>
<p>Fig. 5.4 This picture shows someone (circled) doing more tasks than their system (both vehicle
and head) were designed for&mdash;driving in a crowded urban environment and talking on a hand-
held cell phone. The phone in this position takes both verbal and motor attention, and it causes an
additional planning load to operate the car one-handed, and leads to poor situation awareness
(i.e., they did not see the person on the street who took this picture). Also note the Gestalt effect
of the can and tree!
</p>
<p>138 5 Cognition: Memory, Attention, and Learning</p>
<p/>
<div class="annotation"><a href="http://www.youtube.com/watch?v=-AffEV6QlyY">http://www.youtube.com/watch?v=-AffEV6QlyY</a></div>
<div class="annotation"><a href="http://www.youtube.com/watch?v=-AffEV6QlyY">http://www.youtube.com/watch?v=-AffEV6QlyY</a></div>
</div>
<div class="page"><p/>
<p>to some new information? An example of this is the &lsquo;Cocktail-party effect&rsquo;, where
</p>
<p>you can hear your name in a different conversation even though you are not paying
</p>
<p>attention to that conversation in a crowded room.
</p>
<p>Many researchers believe that our ability to process information without focal
</p>
<p>attention is limited to surface features, syntactic properties, or similar shallow
</p>
<p>features. In this view we cannot process the meaning of something without con-
</p>
<p>scious attention. So we cannot remember something in the long-term without
</p>
<p>paying conscious attention to it. This is thus the difference between hearing and
</p>
<p>understanding, for example. Some evidence suggests that some meaning can be
</p>
<p>processed without attention, but not very much, and that any long-term memory
</p>
<p>that results will almost exclusively be of surface features.
</p>
<p>The study of skilled, procedural performance reveals that we can, after
</p>
<p>extensive practice, perform many things without paying much conscious attention
</p>
<p>to them. Some of these skills (e.g., driving) are very sophisticated. With practice
</p>
<p>we do not have to pay attention to as many subparts of the task. This allows us to
</p>
<p>do another task at the same time (such as talk while drive). It also means that less
</p>
<p>is actively processed, decreasing our memory for those aspects of the task. This
</p>
<p>perhaps explains why it is hard to give directions for familiar routes, as the features
</p>
<p>are no longer processed by attention.
</p>
<p>5.3.1 Wickens&rsquo; Theory of Attentional Resources
</p>
<p>There are somemore elaborate theories of attention. Perhaps the best known of these
</p>
<p>is the theory of attentional resources developed by Wickens (e.g., Wickens and
</p>
<p>Hollands 2000), illustrated in Fig. 5.6. In this theory,Wickens proposes the idea that
</p>
<p>users have multiple types of resources as a way of explaining how people time-share
</p>
<p>across tasks and variations across people. Resources affect which part of perception
</p>
<p>Fig. 5.5 A car dashboard at night (left) and a plane&rsquo;s cockpit during the day (right). Note
similarities and differences, including the use of luminance, color, and some similar interaction
devices
</p>
<p>5.3 Attention 139</p>
<p/>
</div>
<div class="page"><p/>
<p>is used (visual or auditory), response type (choice of response type, and execution of
</p>
<p>that response, spatial or verbal), and the stages of processing (perception, cognition,
</p>
<p>and responding). These define resources for processing and holding information,
</p>
<p>with some tasks using more of one type of resource than another.
</p>
<p>Most of the evidence to support Wickens&rsquo; model of attentional resources comes
</p>
<p>from studies of dual task performance. Evidence for two different types of
</p>
<p>resources, for example, can be found by varying the difficulty of responding to one
</p>
<p>task and looking at performance on a concurrent (more) perceptual task. The
</p>
<p>performance on the perceptual task is (more or less) constant, even though more
</p>
<p>resources are needed for the responding task.
</p>
<p>5.3.2 An Information Processing Model of Attention
</p>
<p>The ACT-R theory (Anderson and Lebiere 1998) incorporates a model of attention
</p>
<p>that summarizes one of the common theories in this area, that of attention as a
</p>
<p>spotlight in the mental world which is directed at what is being thought about.
</p>
<p>Attention in ACT-R is represented as activation of concepts in its declarative
</p>
<p>memories. People with more attention have more activation available (Lovett et al.
</p>
<p>2000). This activation of memory creates the spotlight that focuses on the mental
</p>
<p>objects that are being used in processing. These objects may include semantic
</p>
<p>memories and episodic memories, as well as current goals and processes.
</p>
<p>If more activation is available, this allows more objects to be manipulated at the
</p>
<p>same time. This saves time re-retrieving them from memory and allows larger,
</p>
<p>more complex objects to be created and used. Each of the objects has an associated
</p>
<p>strength. Objects that are more familiar have a higher associated strength and, as a
</p>
<p>result, need less activation to be matched against procedural knowledge than less
</p>
<p>familiar objects.
</p>
<p>Stages
</p>
<p>Perception         Cognition       Responding
</p>
<p>Spatial
</p>
<p>Verbal
</p>
<p>R
e
s
p
o
n
s
e
</p>
<p> ty
p
e
</p>
<p>Visual
</p>
<p>AuditoryM
o
</p>
<p>d
a
li
ti
</p>
<p>e
s
</p>
<p>Fig. 5.6 The conceptual
components of Wicken&rsquo;s
model of the user&rsquo;s
processing, modality, and
places for attention
</p>
<p>140 5 Cognition: Memory, Attention, and Learning</p>
<p/>
</div>
<div class="page"><p/>
<p>Objects in the various perceptual input buffers, such as vision and hearing, need
</p>
<p>to be brought into memory in central cognition by a transfer process. Moving
</p>
<p>objects into central cognition does not happen automatically, but has to done
</p>
<p>intentionally. The amount of time the new memories are processed and how they
</p>
<p>are processed will determine how strong the resulting memories are.
</p>
<p>5.3.3 Divided Attention
</p>
<p>Users who are attempting to do two tasks at the same time will have to move more
</p>
<p>information around. They will start doing one task, and during processing on that
</p>
<p>task they will have to notice when it is time to swap tasks and work on the second
</p>
<p>task. In other words, they will need to divide their focus of attention between the
</p>
<p>tasks they are performing.
</p>
<p>How the two tasks interact will depend on several things. Users will perform
</p>
<p>better if they can spend larger blocks of time on each task. Users that are more
</p>
<p>practiced with each task will be able to switch more smoothly and will be able to
</p>
<p>activate the necessary memories to assist in doing the new task faster. Practicing
</p>
<p>doing the tasks together will also lead to better overall performance. In this case,
</p>
<p>the user might be learning how to interleave subtasks.
</p>
<p>Attention is influenced by both the frequency of access and type of use of items,
</p>
<p>so dual tasks that use different perceptual buffers will interfere less with each
</p>
<p>other. People can learn to drive and talk at the same time in normal weather
</p>
<p>conditions, because driving does not use a lot of audio cues. That leads to the two
</p>
<p>tasks not using the same perceptual buffers very much. At least one theory in this
</p>
<p>area, EPIC, proposes that the only bottlenecks in performance are perception and
</p>
<p>action (Kieras et al. 1997; Meyer and Kieras 1997).
</p>
<p>Pairs of dual tasks, such as reading email and web browsing, based on a computer
</p>
<p>interface will almost certainly interfere with each other to some extent. The user will
</p>
<p>be using the same resources, including perception, aspects of cognition, and output,
</p>
<p>typically vision, memory, andmotor output, for each task. The perceptual buffer will
</p>
<p>have to be refocused or directed to a different part of the screen. These factors will
</p>
<p>make it harder to do each of the tasks when the other is present.
</p>
<p>5.3.4 Slips of Action
</p>
<p>Attention and skilled behavior have a critical role in the occurrence of slips of
</p>
<p>action, where people have the right intention but perform the wrong action
</p>
<p>(Norman 1981; Reason 1990). People essentially work in one of two modes:
</p>
<p>1. Using open loop control: behavior is based on anticipation and feedforward
</p>
<p>rather than feedback, so there is little or no need for them to monitor the result of
</p>
<p>their actions. Other activities can be performed at the same time&mdash;automatized
</p>
<p>driving and game play and typing are examples.
</p>
<p>5.3 Attention 141</p>
<p/>
</div>
<div class="page"><p/>
<p>2. Using closed loop control: performance is mediated using feedback on any
</p>
<p>actions carried out, so conscious monitoring of behavior is required. Only one
</p>
<p>activity can be carried out at one time. Learning how to drive, deliberate
</p>
<p>walking on a rock field, editing a manuscript are examples, or learning how to
</p>
<p>play a game by mapping commands to a controller.
</p>
<p>Very few tasks can be performed completely using open loop control. Slips of
</p>
<p>action typically occur when open loop control is being used instead of closed loop
</p>
<p>control, such as:
</p>
<p>&bull; When users overlook information that affects behavior. For example, users that
</p>
<p>do not note the mode of a word-processor or the location of the insertion point
</p>
<p>and input and modify text in ways that they did not intend.
</p>
<p>&bull; When users continue performing a familiar activity even though they intended
</p>
<p>to do something different. For example, clicking on the &lsquo;&lsquo;Yes&rsquo;&rsquo; button in
</p>
<p>response to the prompt &lsquo;&lsquo;Do you really want to delete this file?&rsquo;&rsquo;
</p>
<p>&bull; When users fail to correctly discriminate between relevant objects in the
</p>
<p>world&mdash;performing an action on unintended objects. For example, trying to
</p>
<p>click on an image icon on a web-based form.
</p>
<p>Although it is not clear that we can design to always pre-empt these slips, we
</p>
<p>can predict the kinds of circumstances when they occur. We can also recognize the
</p>
<p>power of open loop behavior that can foil &lsquo;&lsquo;Do you really want to&hellip;?&rsquo;&rsquo; dialogues.
</p>
<p>We will return to discuss slips of action and other types of erroneous behavior in
</p>
<p>Chap. 10.
</p>
<p>5.3.5 Interruptions
</p>
<p>Interruptions are becoming increasingly common in interfaces as systems become
</p>
<p>more advanced and can be given tasks to perform asynchronously. There are also
</p>
<p>other causes of interruptions, including colleagues, phones, and email systems that
</p>
<p>beep when you have new messages.
</p>
<p>In many ways interruptions can be seen as a secondary task, and hence the work
</p>
<p>in this area is effectively a subset of the work on dual task performance, where the
</p>
<p>user is trying to do two tasks at once. Interruptions are effectively the secondary
</p>
<p>task, which is much less important, generally not regarded as part of the user&rsquo;s
</p>
<p>main task, and is not under control of the user.
</p>
<p>Interruptions do appear to cause real decrements in performance (Bailey and
</p>
<p>Konstan 2001; McFarlane 1999) and users do not like them because they lead to
</p>
<p>changes in affect (Bailey and Konstan 2001). McFarlane (1997) has attempted to
</p>
<p>create a taxonomy of interruption types and their implications for design. His
</p>
<p>results indicate that the choice of how to deal with interruptions will depend on the
</p>
<p>importance and types of the main task and of the interruption. Dealing with
</p>
<p>142 5 Cognition: Memory, Attention, and Learning</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10">http://dx.doi.org/10.1007/978-1-4471-5134-0_10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10">http://dx.doi.org/10.1007/978-1-4471-5134-0_10</a></div>
</div>
<div class="page"><p/>
<p>interruptions immediately disrupts the main task more than taking the interruption
</p>
<p>between subtasks. Dealing with interruptions at scheduled times leads to better
</p>
<p>performance on the main task, but poorer performance on the interruptions.
</p>
<p>Intermediate strategies offered different trade-offs (McFarlane 1999).
</p>
<p>Sometimes interruptions are useful. It has been hypothesized that interruptions
</p>
<p>are useful for solving hard problems (where there is a so-called incubation effect).
</p>
<p>This effect has been noticed by programmers who get stuck on a problem&mdash;coming
</p>
<p>back to a hard problem later sometimes makes the problem easier. Being inter-
</p>
<p>rupted for minutes, hours, or days in these tasks allow the user to forget their
</p>
<p>mistakes and mis-starts, or to receive suggestions from the environment. Kaplan
</p>
<p>(1989) found that at least part of the incubation effect came from cues in the
</p>
<p>environment. One problem he gave subjects was &lsquo;&lsquo;What goes up a chimney down
</p>
<p>but not down a chimney up?&rsquo;&rsquo; Subjects who were called and asked by Kaplan if he
</p>
<p>had left an umbrella in their office were much more likely to solve the problem, but
</p>
<p>did not attribute the cause to his call.
</p>
<p>As you consider the larger context of your users&rsquo; tasks, you should keep in mind
</p>
<p>the possible effects of interruptions. Some interfaces will be less sensitive to the
</p>
<p>effects of interruptions. We are just starting to be able to predict and measure these
</p>
<p>effects.
</p>
<p>5.3.6 Automation Deficit: Keeping the Human in the Loop
</p>
<p>If you want to get funny looks, while you are driving a car, ask your passenger
</p>
<p>&lsquo;&lsquo;Do you ever wake up and find out you are driving and wonder where you are
</p>
<p>going and where the other cars are?&rsquo;&rsquo; Some find this humorous, and others, if they
</p>
<p>do not know you well, may be startled. This is similar to what happens when
</p>
<p>someone has to resume or take over a task at short notice when the system
</p>
<p>relinquishes control because it does not know what to do. This happens to people
</p>
<p>such as aircraft pilots and power plant operators who find themselves out of the
</p>
<p>loop, i.e., not being kept up to date by the systems about what it is doing. The user
</p>
<p>will then allocate their attention to dealing with the task, but they have to spend
</p>
<p>time and effort trying to understand the current situation before they can diagnose
</p>
<p>the problem and resolve it.
</p>
<p>Generally, the way to avoid this problem is to include more status information
</p>
<p>to keep the user continually informed before the situation requires their input. This
</p>
<p>allows one to develop and maintain a mental model of that situation and how it is
</p>
<p>unfolding, so that users can decide when they may need to take action.
</p>
<p>This whole argument about the need to keep the human involved in the control
</p>
<p>loop was first summarized by Bainbridge (1983), and it remains as an issue today
</p>
<p>(Baxter et al. 2012). Woods and Patterson (2001) explain some of the effects on
</p>
<p>users if the technology does not keep them kept informed about what it is doing.
</p>
<p>5.3 Attention 143</p>
<p/>
</div>
<div class="page"><p/>
<p>5.3.7 Implications for System Design
</p>
<p>Interfaces can help users do more than one task. Figure 5.7 shows a workplace
</p>
<p>where the user is doing multiple subtasks related to listening remotely to a talk
</p>
<p>(watching the talk, reading the talk slides, looking at the map of where the talk is,
</p>
<p>timing the talk, reading a paper about the talk, waiting for a snack). Typically, this
</p>
<p>is by helping them do each of the tasks more easily and by requiring less attention
</p>
<p>to do each of the tasks. More recent work is attempting to find the times and ways
</p>
<p>to interrupt the user at more appropriate moments.
</p>
<p>Knowing how attention and perception work can help create better indicators of
</p>
<p>the arrival of another task, such as a beep or flash, or a change in its priority.
</p>
<p>Knowing about attention also helps with design because you know that attention is
</p>
<p>not limitless, and is sometimes missing. How and when to best interrupt a task and
</p>
<p>how to best support various sets of dual tasks remain open problems.
</p>
<p>It is possible to increase the user&rsquo;s attention by including multiple modes of
</p>
<p>input and output. For example, when users need more attention, adding voice input
</p>
<p>and voice output as interaction modalities to supplant a visual display can provide
</p>
<p>users with the ability to watch their performance in a flight simulator. That way,
</p>
<p>they are receiving feedback on it at the same time (Ritter and Feurzeig 1988).
</p>
<p>In applied settings, where attention is paid tomultiple processes, some that are time
</p>
<p>critical, it can be important to pay attention to a process before it becomes necessary to
</p>
<p>control the process. The section on automation deficit explained this more fully.
</p>
<p>5.4 Learning and Skilled Behavior
</p>
<p>Learning is where performance changes with practice, typically getting faster,
</p>
<p>becoming less demanding, and generating fewer errors. Learning is important for
</p>
<p>users. They learn in several ways, including learning new information and new
</p>
<p>Fig. 5.7 This system shown
here included an instant
messenger (iChat) text and
video chat, a proprietary
video conferencing tool,
slides of the talk online and
printed, as well as paper-
based reminders and notes. In
this task, however, the
subtasks were integrated: to
watch the man in the suit talk
and ask him questions
</p>
<p>144 5 Cognition: Memory, Attention, and Learning</p>
<p/>
</div>
<div class="page"><p/>
<p>skills. Learning is the primary way for them to improve the strength of their
</p>
<p>memories. As they retrieve something more often, their memory strengths improve
</p>
<p>as well. Thus, retrieving a password is faster and more robust after 2 trials than 1,
</p>
<p>and after 100 trials than 99 (all else being equal), but with ever decreasing
</p>
<p>improvements with practice.
</p>
<p>Users also use learning to help with attention. As they learn more, they can
</p>
<p>recognize situations and generate responses faster. This gives them more time to
</p>
<p>pay attention to a task or to a secondary distracting task.
</p>
<p>Users can also learn to adjust their behavior to fit to the interface. If the
</p>
<p>interface does not describe an action the way the user would, the user typically has
</p>
<p>to learn the new name, which they can and will do. If the interface has steps or
</p>
<p>substeps to an action, the user has to learn these as well. If objects are not where
</p>
<p>the user expects, the user has to learn their location. The good news is that learning
</p>
<p>can often happen without much distress to the user, but woe to the interface that
</p>
<p>requires the user to learn everything!
</p>
<p>We will present here a theory of how users learn. This theory has many impli-
</p>
<p>cations, including how users&rsquo; behavior changes with learning, what extreme practice
</p>
<p>looks like, and what this can mean for interface design. For more information on
</p>
<p>learning, see Anderson (1982, 1995, 2004) and Lindsay and Norman (1977).
</p>
<p>5.4.1 The Process of Learning
</p>
<p>A description of the general process of learning (and types of task performance)
</p>
<p>has arisen in several areas, including behavioral psychology (Fitts 1964), cognitive
</p>
<p>ergonomics (Rasmussen 1983), and cognitive psychology (Anderson 1982). These
</p>
<p>theories all start with the learner acquiring declarative information about the
</p>
<p>domain. At this stage, problem solving is very difficult. The concepts are not
</p>
<p>always connected to each other. The learning might be seen as learning how to
</p>
<p>learn more about the task. What has been learned at this point might not be enough
</p>
<p>to be able to do the task yet. Basic declarative knowledge of the task is learned at
</p>
<p>this stage, such as the initial problem-solving state and the actions available for
</p>
<p>problem solving. Problem solving, when it is possible, requires considerable effort,
</p>
<p>and is not always correct. Problem solvers might not have much confidence in their
</p>
<p>performance. Anderson calls this the cognitive stage. Rasmussen calls this type of
</p>
<p>behavior knowledge based, as shown at the top of Fig. 5.8.
</p>
<p>When learners are at this first stage, behavior occurs at the most fundamental
</p>
<p>level, when there are no direct rules to inform the user what to do. Expert users may
</p>
<p>have to resort to this stage in emergencies or novel situations, such as when birds get
</p>
<p>ingested into an aircraft engine, or when trying to change Unix permissions on
</p>
<p>shared files. These conditions require deliberate thought and reasoning about the
</p>
<p>state of the situation or system based on the user&rsquo;s knowledge (i.e., mental model) of
</p>
<p>the system, and then about what action to perform next. As you might expect, work
</p>
<p>proceeds slowly because each step has to be deliberated over from first principles.
</p>
<p>5.4 Learning and Skilled Behavior 145</p>
<p/>
</div>
<div class="page"><p/>
<p>With learning and practice, the user progresses to the associative stage, or rule-
</p>
<p>based stage (as shown in the middle of Fig. 5.8). The learner can solve problems
</p>
<p>more routinely and with less effort. The declarative knowledge has been compiled
</p>
<p>into procedures relevant to the task domain that can be performed directly. At this
</p>
<p>stage users may often be able to just recognize what needs to be done. For users of
</p>
<p>complex systems, behavior becomes a conscious activity and is based on familiar
</p>
<p>rules, either dictated or acquired, such as changing lanes when driving a car, or
</p>
<p>formatting a paragraph in a Word document using styles.
</p>
<p>The final stage, called skills or tuning, tunes the knowledge that is applied. At
</p>
<p>this point the user still gets faster at a task, but the improvements are much smaller,
</p>
<p>as they are smaller adjustments. New declarative information is rarely learned, but
</p>
<p>small adjustments to rule priorities happen. At this point users consider them-
</p>
<p>selves, if not experts, to be real users. Rasmussen calls this level of performance
</p>
<p>skill-based. Anderson calls it the autonomous stage.
</p>
<p>At the skill-based level, performance is much more automatic, as shown at the
</p>
<p>bottom of Fig. 5.8. Skill-based performance usually occurs when users are per-
</p>
<p>forming routine functions in their normal operating environment. Much of their
</p>
<p>behavior is no longer available to conscious thought, or available for verbalization
</p>
<p>etc. Users not only perform the task faster, they may also appear to have more
</p>
<p>attention to provide to other tasks. Examples include changing gear in a car with a
</p>
<p>manual shift gearbox, and cutting and pasting text.
</p>
<p>These stages of learning have been noticed in several areas of formal reasoning.
</p>
<p>Formal reasoning involves problems with known goals (like solve for x), and
</p>
<p>equations or rules that can transform representations (such as adding 2 to each side
</p>
<p>of an equation). Formal reasoning is used in areas such as physics problem solving
</p>
<p>(Larkin 1981; Larkin et al. 1980a, b), geometrical proofs and solving algebraic
</p>
<p>problems.
</p>
<p>Analysis and 
identification
</p>
<p>Analysis of means 
and planning
</p>
<p>Evaluation and choice 
of goal and task
</p>
<p>Knowledge-based 
control
(model-based)
</p>
<p>Rule-based 
control
(know-how)
</p>
<p>Skill-based 
control
(automatic)
</p>
<p>Sy
m
</p>
<p>bo
ls
</p>
<p>Sensory information
(multiple channels)
</p>
<p>Signals
</p>
<p>Feature formation
</p>
<p>Goals and needs
</p>
<p>Recognition of cues Association cue / task Stored rules 
for activities
</p>
<p>Movements
</p>
<p>Automated sensorimotor 
movements and routines
</p>
<p>(signs)
</p>
<p>Seeing changes
</p>
<p>Looking for cues
</p>
<p>Reading symbols
</p>
<p>Fig. 5.8 A schematic of Rasmussen&rsquo;s theory of performance. (Adapted from Rasmussen 1983)
</p>
<p>146 5 Cognition: Memory, Attention, and Learning</p>
<p/>
</div>
<div class="page"><p/>
<p>In these types of problems the problem solvers (and computer models) start with
</p>
<p>domain knowledge and the goals for which they are trying to find answers. Novices
</p>
<p>work backward from the goal. In the case of physics problem solving, the task is to
</p>
<p>derive a value of a variable (like final speed) given some known variables (like
</p>
<p>mass, initial speed, and force) and some equations (like Force = Mass 9 Accel-
</p>
<p>eration). Novices tend to work back from what they are trying to solve for final
</p>
<p>speed, chaining inference rules together until they find known variables. If they
</p>
<p>need to compute the final speed then they look for an equation that computes speed.
</p>
<p>Then they look for more equations to find the variables in the first equation, until
</p>
<p>they bottom out with known variables. This is known as backward chaining or
</p>
<p>bottom-up reasoning.
</p>
<p>As the reasoning terminates in the answer, how to apply the rules in a forward
</p>
<p>sense, without search, is learned. More expert behavior is a mix of these
</p>
<p>approaches. With even more practice experts can reason in a forward sense. &lsquo;&lsquo;If I
</p>
<p>have speed and time then I have acceleration, then if I have acceleration I
</p>
<p>have&hellip;..&rsquo;&rsquo; The answer in this case is found more quickly and with less effort. This
</p>
<p>is known as forward chaining or top-down reasoning.
</p>
<p>This type of reasoning difference is seen in computer repair and trouble-
</p>
<p>shooting, software usage, and other domains where formal reasoning can be
</p>
<p>applied. Better interfaces will support the novice by providing the appropriate
</p>
<p>domain knowledge needed to learn the inferences, and support the novice and
</p>
<p>expert by providing the state information to reason from.
</p>
<p>Learning can also occur in the opposite direction, from (implicit) skills back to
</p>
<p>knowledge about these skills, but this learning is less well understood. Implicit
</p>
<p>learning can occur when the user is working at the skill level, with knowledge
</p>
<p>eventually being derived on the cognitive level through the observation of one&rsquo;s
</p>
<p>own behavior. This type of learning, which is an active area of research in psy-
</p>
<p>chology, often leads to or arises from strategy changes.
</p>
<p>Whichever way the user learns, some key phenomena survive:
</p>
<p>&bull; The ability to recognize correct/incorrect items comes before the ability to
</p>
<p>generate correct items.
</p>
<p>&bull; Knowledge is not acquired in an all-or-nothing way. Novices go through a stage
</p>
<p>of fragile knowledge, trusting that what has been acquired is correct, whereas
</p>
<p>sometimes it may be incorrect.
</p>
<p>&bull; Experts acquire a rich repertoire of representations of their knowledge. It is not
</p>
<p>only that experts know more than novices; what they know is much better
</p>
<p>organized, understood to a greater depth, and more readily available.
</p>
<p>5.4.2 Improvements from Learning
</p>
<p>Perhaps the biggest regularity of human behavior in general and users in particular
</p>
<p>is that the changes due to learning leads to them getting faster at performing a task
</p>
<p>the more they do it. Similar curves showing decreases in performance times have
</p>
<p>5.4 Learning and Skilled Behavior 147</p>
<p/>
</div>
<div class="page"><p/>
<p>been seen in tasks ranging from pushing buttons, reading unusual fonts or inverted
</p>
<p>text, doing arithmetic, typing, using a computer, generating factory schedules, all
</p>
<p>the way up to writing books (Ohlsson 1992). These improvement curves are also
</p>
<p>found when large groups work together, for example, building cars.
</p>
<p>There are huge improvements initially, although users rarely report satisfaction
</p>
<p>with these improvements. The improvements decrease with time, however, fol-
</p>
<p>lowing a monotonically decreasing curve. This is shown in Fig. 5.9 for the Seibel
</p>
<p>task, a task where you are presented with a pattern of ten lights and you push the
</p>
<p>buttons for the lights that are on. Each point represents the average for doing 1,000
</p>
<p>patterns. Notice that with extended practice, performance continues to improve,
</p>
<p>but by smaller and smaller increments. Over a wide variety of tasks and over more
</p>
<p>than seven orders of magnitude (hundreds of thousands of trials), people get faster
</p>
<p>at tasks.
</p>
<p>With data with changes this wide and with small changes becoming important
</p>
<p>later in the curve it becomes difficult to see the improvements. This is why the data
</p>
<p>are plotted using logarithmic axes: the difference between two points is based on
</p>
<p>their logarithms, as shown in Fig. 5.9. Typically, on these log&ndash;log plots, learning
</p>
<p>curves follow pretty much a straight line.
</p>
<p>The mathematical representation of this curve is currently somewhat disputed.
</p>
<p>Some believe that the learning curve is an exponential curve, and others think it is
</p>
<p>a power equation (thus, called the power law of learning) of the form shown in
</p>
<p>Eq. (5.1):
</p>
<p>Time of a trial &frac14; Constant1 &eth;Number of trial&thorn; PP&THORN;ï¿½a &thorn; Constant2 &eth;5:1&THORN;
</p>
<p>where Constant1 is the base time that decreases with practice, PP is previous
</p>
<p>practice on the task, a (alpha) is a small number typically from 0.1 to 0.5, and
</p>
<p>Constant2 is the limitation of the machinery or external environment (reviewed in
</p>
<p>Newell 1990, Chap. 1; see also Anderson 1995, Chap. 6).
</p>
<p>(a) (b)
</p>
<p>Fig. 5.9 Time to perform a simple task (pushing a combination of buttons) on a linear plot
(a) and log&ndash;log plot (b) as well as a power law fit to the data shown as the solid line on each plot
(adapted from Seibel 1963, and previously used in Ritter and Schooler 2001, reproduced here
with permission)
</p>
<p>148 5 Cognition: Memory, Attention, and Learning</p>
<p/>
</div>
<div class="page"><p/>
<p>PP is either estimated, measured directly, or ignored. In most cases it is ignored
</p>
<p>because the task is unique enough to the learner. In other cases, such as taking up a
</p>
<p>familiar task, the equation does not fit as well.
</p>
<p>Constant2, the minimum time due to the limitations of the environment, is
</p>
<p>computed from equations describing the world or using physical equipment. For
</p>
<p>example, you might measure how long it takes a ball to fall to the ground with a
</p>
<p>camera if the task involves catching a falling ball, or you might record how fast an
</p>
<p>interface can accept keystrokes when driven by a computer program.
</p>
<p>a is thus found typically by plotting the data on a log&ndash;log plot, and fitting a
</p>
<p>straight line. This fitting is typically done by fitting a linear equation (which has a
</p>
<p>known closed form solution) to the log of the trials and the log of the time. The
</p>
<p>more accurate but more computationally expensive approach is to fit the power
</p>
<p>law equation including the constants that are appropriate using an iterative
</p>
<p>algorithm.
</p>
<p>Having an equation to predict learning is important for several reasons. For
</p>
<p>science, it helps summarize learning, and comparison of the constants is a useful
</p>
<p>way to characterize tasks. It also has practical applications. For engineering,
</p>
<p>design, and manufacturing, it predicts how fast users will become with practice.
</p>
<p>These equations are used in manufacturing to predict factory output and
</p>
<p>profitability.
</p>
<p>Others believe that the match to a power law is an artifact of averaging the data
</p>
<p>from multiple people and multiple series, and that the curve is best described as an
</p>
<p>exponential when the data is examined in its purest form (Heathcote et al. 2000).
</p>
<p>Both cases have basically the same implications for users with limited lifetimes
</p>
<p>and physical equipment, but have different implications for the details of how the
</p>
<p>underlying cognitive architecture is implemented.
</p>
<p>The improvement in performance time itself does not appear to delineate the
</p>
<p>stages of learning noted earlier. This may be because the first stage of learning,
</p>
<p>where performance might be quite difficult, has to reach a nearly complete level
</p>
<p>before the task can even be performed. There are hints of this in Fig. 5.9b, where
</p>
<p>the initial slope is fairly shallow in the log&ndash;log plot, perhaps more shallow than
</p>
<p>would be expected. In complex tasks, the transition of rule learning and rule tuning
</p>
<p>within task might lead to steady improvement, and be masked by the large number
</p>
<p>of rules and sub-tasks. Looking at individual users working on well-measured
</p>
<p>tasks may allow these stages to be seen. When this has been done, strategy changes
</p>
<p>can be seen (Delaney et al. 1998).
</p>
<p>In addition to time reducing with practice, several other aspects of performance
</p>
<p>improve as well (Rabbitt and Banerji 1989). Errors decrease with practice. The
</p>
<p>variance in the time to do a task also decreases. That is, with practice the range of
</p>
<p>expected times decreases. Some think that this decrease in variability is what leads
</p>
<p>most to the speedup because the minimum time to perform a task generally does
</p>
<p>not decrease with practice (although there are clearly notable exceptions to this, for
</p>
<p>example, for tasks that cannot be completed by novices).
</p>
<p>There appear to be two places where learning does not get faster. Users cannot
</p>
<p>get faster when the machinery they are working with cannot keep up with them.
</p>
<p>5.4 Learning and Skilled Behavior 149</p>
<p/>
</div>
<div class="page"><p/>
<p>This was first noted when cigar rollers improved up to a point and then stopped. It
</p>
<p>was found that the users were rolling faster than the machine could pass materials
</p>
<p>to them (Snoddy 1926).
</p>
<p>The second place where users do not get faster is when they change strategies.
</p>
<p>As a user picks up a new strategy, they will often experience a slowdown, moving
</p>
<p>back on the practice curve for that strategy. However, with practice, performance
</p>
<p>on this curve with a lower intercept improves, usually to be much better than the
</p>
<p>previous strategy (Delaneyet al. 1998). Figure 5.10 illustrates this effect.
</p>
<p>If your system supports multiple learning strategies, you should consider
</p>
<p>helping the user transition between them. In text editors, for example, there are
</p>
<p>several ways to find a particular text string, including scrolling and searching line-
</p>
<p>by-line, scrolling and searching by paragraph, and using the inbuilt search func-
</p>
<p>tion. In one survey (Card et al. 1983), most users were not using the most efficient
</p>
<p>strategy (searching), but moving line-by-line. Experts use searching, which can be
</p>
<p>100 times faster than scrolling.
</p>
<p>5.4.3 Types of Learning
</p>
<p>Learning can be described in several ways. It can be organized by the types of
</p>
<p>memories that are created or practiced. One common way to distinguish types of
</p>
<p>learning is as declarative and procedural. Another common way is as implicit and
</p>
<p>explicit. The distinctions between these classifications are still being argued over,
</p>
<p>0 200 400 600 800 1000
</p>
<p>0
2
</p>
<p>0
4
</p>
<p>0
6
</p>
<p>0
8
</p>
<p>0
1
0
</p>
<p>0
</p>
<p>Trials
</p>
<p>P
e
</p>
<p>rf
o
</p>
<p>rm
a
</p>
<p>n
c
e
 T
</p>
<p>im
e
</p>
<p>Fig. 5.10 The learning curve
for a series of better
strategies, showing the initial
slow down and then savings
due to switching strategies
</p>
<p>150 5 Cognition: Memory, Attention, and Learning</p>
<p/>
</div>
<div class="page"><p/>
<p>but they represent useful and interesting differences about users that help with
</p>
<p>interface design.
</p>
<p>Declarative learning is learning facts (declarations). The &lsquo;&lsquo;power button is on
</p>
<p>the keyboard&rsquo;&rsquo; and &lsquo;&lsquo;the computer manager&rsquo;s office is in 004A&rsquo;&rsquo; are two examples.
</p>
<p>Declarative learning can be separated into two subtypes of recognition and recall.
</p>
<p>Recognition memories are easier to build than recall memories. That&rsquo;s why
</p>
<p>multiple choice tests seem easier&mdash;you just have to recognize the answer. This
</p>
<p>corresponds to the first stage of declarative learning.
</p>
<p>Procedural learning is learning how to do procedures. Using an interface, and
</p>
<p>playing a computer game are examples of this. Procedural memories are probably
</p>
<p>more complex than declarative memories in that they generally support the skill
</p>
<p>being performed in a wide variety of environments and slightly different situations,
</p>
<p>which thus represent more knowledge. These memories have to come after the
</p>
<p>declarative representations are available to create them.
</p>
<p>These two types of learning have different regularities associated with them.
</p>
<p>Declarative learning can, by definition, be described and reported. Procedural
</p>
<p>memories cannot be directly reported (Ericsson and Simon 1993). You cannot
</p>
<p>directly describe the knowledge you use to ride a bike. You can, however, accu-
</p>
<p>rately report the declarative knowledge that you use to generate your procedures
</p>
<p>(like keep your weight balanced) and what is in your working memory as you are
</p>
<p>doing the task (there is a parked car ahead). You can also watch yourself do a task
</p>
<p>and attempt to describe much of what you were paying attention to as you did it.
</p>
<p>What you think you were paying attention to when doing the task will, however,
</p>
<p>be dependent on your mental model of the task and how demanding the task is.
</p>
<p>This approach is called introspection.
</p>
<p>There are fundamental problems with introspecting like this. While introspec-
</p>
<p>tion can lead to useful and helpful insights, it does not lead to complete and valid
</p>
<p>theories of human thinking (Ericsson and Simon 1993). Just as you can&rsquo;t program
</p>
<p>a computer to write out the instructions as it does them (the instruction to write out
</p>
<p>replaces the instruction it copies), you can&rsquo;t think about thinking very accurately
</p>
<p>while thinking. Mainstream psychology has rejected introspection as a true rep-
</p>
<p>resentation of how people think, but you may find it useful for inspiration for ideas
</p>
<p>that can be later validated by other approaches. In our experience it is sometimes
</p>
<p>useful inspiration, but it is sometimes just way off because of our biases about how
</p>
<p>we would like to think we think.
</p>
<p>As an example of this, users think that they cannot learn new key bindings
</p>
<p>between keys and commands (e.g.,\Ctrl-s[to search vs.\Ctrl-f[to search).When
</p>
<p>key bindings in an editor were changed on users on the second day of a study about
</p>
<p>learning to use a text editor, for the first hour or two the users felt much,much slower.
</p>
<p>They were slower than they were at the end of the first day, but faster than when they
</p>
<p>started. They regained their skill level by the end of the second day (Singley and
</p>
<p>Anderson 1989). This study illustrates three important things about users. The first is
</p>
<p>that they are always learning. The second is that introspection often leads to incorrect
</p>
<p>conclusions. They rather disliked the new interface, but they adapted more quickly
</p>
<p>than they thought they did. The third is that the users were able to transfer much of
</p>
<p>5.4 Learning and Skilled Behavior 151</p>
<p/>
</div>
<div class="page"><p/>
<p>what they had learned from the old interface to the new interface. Only the key
</p>
<p>bindings changed; the underlying approach and the command structures did not, so
</p>
<p>the users were able to apply most of what they had learned. Another similar example
</p>
<p>is that users seem to prefer mice over light pens, even though the light pens were
</p>
<p>faster to use (Charness et al. 2004).
</p>
<p>Another way to represent learning is with the implicit/explicit distinction.
</p>
<p>Implicit learning seems to be automatic, is based on practice, is not improved by
</p>
<p>reflection, and produces knowledge that cannot be verbalized. This might be
</p>
<p>roughly equivalent to the rule tuning stage. If the rules are created based on a
</p>
<p>simple domain theory, but a more complex domain exists, then additional learning
</p>
<p>can occur.
</p>
<p>Explicit learning proceeds with full consciousness in a hypothesis testing way;
</p>
<p>it produces knowledge that can be verbalized. This is examined in more detail in a
</p>
<p>later section on problem solving.
</p>
<p>These distinctions become important when teaching users how to use an
</p>
<p>interface. Some information is reported to them as declarative knowledge to be
</p>
<p>learned (where things are, who other users are, and what are the objects), and some
</p>
<p>information consists of procedural skills such as how to do a task.
</p>
<p>Learning can be massed or distributed. Massed refers to learning that occurs at a
</p>
<p>single time, for example, cramming for a test. Distributed learning occurs with
</p>
<p>breaks in time between the learning episodes. Figure 5.11 shows how much better
</p>
<p>distributed learning can be. Distributed learning takes less total time (sometimes
</p>
<p>one-third of the time), and the retention is better, sometimes 50% better. Anything
</p>
<p>you can do to assist your users to learn in a distributed fashion will help their
</p>
<p>learning. Some interfaces now put up hints, which appears to be a way to support
</p>
<p>distributed learning.
</p>
<p>0
</p>
<p>1
</p>
<p>10
</p>
<p>0 1,000 2,000 3,000 4,000 5,000 6,000 7,000 8,000 9,000 10,000
</p>
<p>M
e
m
</p>
<p>o
ry
</p>
<p> S
tr
</p>
<p>e
n
g
th
</p>
<p> (
a
rb
</p>
<p>it
ra
</p>
<p>ry
 u
</p>
<p>n
it
s
)
</p>
<p>Time (arbitrary units) 
</p>
<p>Massed
</p>
<p>Distributed
</p>
<p>Fig. 5.11 Massed versus
distributed practice in relation
to time to learn a list. Given
exponential decay, which is
often assumed for memory,
the solid line shows a given
amount of practice as one
block, and the dashed line
shows the same amount
spread out over a longer
period. The distributed
practice has higher activation
after the second practice, and
will for the remainder of the
curve
</p>
<p>152 5 Cognition: Memory, Attention, and Learning</p>
<p/>
</div>
<div class="page"><p/>
<p>Finally, we should note again that learning is rarely complete. It is easy to think
</p>
<p>that if you have learned to operate a system your learning about that system is
</p>
<p>complete. This needn&rsquo;t be so; many users can sometimes perform very compe-
</p>
<p>tently with very little knowledge, and other systems, such as UNIX and the Emacs
</p>
<p>editor are complex enough that once competent, users can continue to learn new
</p>
<p>ways to use them and new components for several years.
</p>
<p>5.4.4 Skilled Behavior, Users in Complex Environments
</p>
<p>Real human skills are a complex mixture of these levels of learned behavior. In
</p>
<p>most cases, routine users will work with an open-loop behavior at the skilled level.
</p>
<p>That is, they will be able to perform most tasks in a routine way using existing,
</p>
<p>well-used knowledge and not check all of their steps. Their behavior will be open-
</p>
<p>loop, that is, they will not check all of their work. They will not close the loop by
</p>
<p>checking that things worked correctly because in most cases they no longer need
</p>
<p>to. If they do make mistakes, they will be able to recognize them quickly. They
</p>
<p>will continue to get faster with practice, but the improvement will be minor. There
</p>
<p>will also be some closed-loop behaviors for tasks that are less well practiced, and
</p>
<p>in these behaviors users will be more careful and check their work.
</p>
<p>For example, airplane pilots often operate at all three levels. Some aspects of
</p>
<p>their behavior are automatic; for others they refer to rules and procedures, whilst
</p>
<p>for others, particularly in non-routine emergencies, they reason on the basis of
</p>
<p>their knowledge about the plane and learn. (In routine emergencies they will use
</p>
<p>checklists.)
</p>
<p>Rasmussen&rsquo;s (1983) argument is that good design needs to support all three
</p>
<p>levels of operation, not just one. We can also note a social human factor here. If
</p>
<p>there are multiple operators, they may operate at different levels at different times
</p>
<p>because at the knowledge level they may have different knowledge, which may
</p>
<p>give rise to conflict or to strength, depending on how these differences in approach
</p>
<p>are resolved.
</p>
<p>The knowledge level implies a certain amount of planning activity, but you will
</p>
<p>find there are those who believe that people do not engage in planning&mdash;arguing
</p>
<p>that behavior is situated in a context (e.g., Suchman 1983). In other words, they
</p>
<p>argue that we perceive the situation and decide what to do then, not on the basis of
</p>
<p>some pre-formed plan.
</p>
<p>Two responses can be made to this.
</p>
<p>&bull; One can do both&mdash;have a plan and allow the situation to change it (e.g., per-
</p>
<p>forming actions in a different order from that planned).
</p>
<p>&bull; Planning seems best related to Rasmussen&rsquo;s knowledge-level, whereas situated
</p>
<p>action is &lsquo;rule-level&rsquo; behavior. Again, these are not exclusive options&mdash;some
</p>
<p>people in some skills may function exclusively at one level, whilst others may
</p>
<p>switch between levels at high speed.
</p>
<p>5.4 Learning and Skilled Behavior 153</p>
<p/>
</div>
<div class="page"><p/>
<p>Learning will also influence perception. It was not immediately apparent to the
</p>
<p>photographer from the photograph in Fig. 5.12 what was wrong with this scene
</p>
<p>(although it looked &lsquo;odd&rsquo;), but it would be apparent fairly quickly to a boat captain.
</p>
<p>This is a simple example of where knowledge or learning, can influence other
</p>
<p>processes, such as vision.
</p>
<p>5.4.5 Expertise
</p>
<p>With extended practice, users become experts at their task. Generally, to become
</p>
<p>world class, it takes about 10 years of practice as well as some deliberate reflection
</p>
<p>and declarative learning, either from extensive self-tutoring or from a coach
</p>
<p>(Ericsson 1996; Hayes 1981; Simon and Chase 1973; Simonton 1996). There are
</p>
<p>exceptions, but these researchers argue that exceptions are truly rare. Less time is
</p>
<p>required to attain local or national prominence in a particular field, or where a task
</p>
<p>or technology is new. While practice is a usual and necessary condition, simple
</p>
<p>practice is not enough to guarantee an expert level of performance: coaching and
</p>
<p>deliberate practice are needed (Ericsson 1996).
</p>
<p>This level of performance is interesting to people because it shows how good
</p>
<p>performance can be. When the practice is on a socially important task, such as
</p>
<p>flying planes or programming, it can also be quite rewarding to the practitioners.
</p>
<p>Some theories suggest that with practice the user gains more than just speed in
</p>
<p>the task. In some instances they appear to have greater memory for, and can pay
</p>
<p>more attention to the task at hand (Ericsson and Kintsch 1995). In all cases, they
</p>
<p>have more knowledge and better anticipation of what will happen in the task, and
</p>
<p>in nearly all cases they have more accurate perception for and of the task details.
</p>
<p>Fig. 5.12 A scene from a
fishing port in Massachusetts
where knowledge can
influence perception (There is
a boat that has sunk next to
the dock. Only its mast is
visible next to the boat on the
right. The book&rsquo;s web site
provides a more detailed
picture showing the missing
boat.)
</p>
<p>154 5 Cognition: Memory, Attention, and Learning</p>
<p/>
</div>
<div class="page"><p/>
<p>5.4.6 Transfer
</p>
<p>Transfer of learning is important. After a skill has been learned, the goal is often to
</p>
<p>reuse or apply the knowledge to a new situation. If no transfer occurred, then every
</p>
<p>situation would be a new situation. If transfer was perfect, then few situations
</p>
<p>would be novel. Studies have shown that transfer is usually far from perfect, that it
</p>
<p>can be underestimated, and that it is possible to predict transfer effects.
</p>
<p>Perhaps the earliest study on transfer had subjects read a story about how a king
</p>
<p>wished to invade a town, but his army was too big to come through a single gate in
</p>
<p>the town. So he split his troops up into smaller parties. Subjects then read about the
</p>
<p>use of lasers to attack cancer, but the problem was that the light was too intense to
</p>
<p>directly fire through the tissue at the cancer. What to do?
</p>
<p>A surprising number did not think to use multiple lasers, which is what the
</p>
<p>transfer of knowledge would suggest. This lack of obvious (to the experimenter)
</p>
<p>transfer effect has been repeated many times. Problem solvers have trouble
</p>
<p>transferring knowledge or strategies where there are structural but not surface
</p>
<p>similarities. Thus, users do not always transfer useful information.
</p>
<p>The second study to keep in mind is that of perverse Emacs. Singley and
</p>
<p>Anderson (1989) trained users for several hours with a powerful text editor called
</p>
<p>Emacs. Then, on day 2, some subjects were trained on Perverse Emacs, which was
</p>
<p>just like Emacs, but the keystroke commands were different. Subjects, we can
</p>
<p>imagine, did not like this at all, but at the end of the day, their performance was
</p>
<p>indistinguishable from the people who had used Emacs in day 1 and day 2. Thus,
</p>
<p>transfer can occur, but users do not always see it, and they do not like it when
</p>
<p>transfer leads to small mistakes (as would have often happened in the first hour for
</p>
<p>the users of Perverse Emacs). Thus, changing key bindings is likely to lead to
</p>
<p>frustration, but might not hurt users in the long run.
</p>
<p>Finally, there are some tools to measure potential transfer. Kieras and Polson
</p>
<p>(1985) created a simple language to express how to do a task, and many task
</p>
<p>analysis techniques can be used in a similar way. Each instruction in the language,
</p>
<p>such as how to push a button, takes time to learn. Thus, the number of differences
</p>
<p>between instruction sets indicate how much knowledge can be transferred and how
</p>
<p>much must be learned. Analyses of popular operating systems suggest that there
</p>
<p>are real differences between them, with one being a subset of the other (and one
</p>
<p>thus being easier to learn).
</p>
<p>5.4.7 Implications for System Design
</p>
<p>All users will learn and get faster at doing a task as they repeatedly do it. This is an
</p>
<p>important way that users fit themselves to a task, covering up errors in design or
</p>
<p>compensating for trade-offs made in interface design that do not favor the user.
</p>
<p>5.4 Learning and Skilled Behavior 155</p>
<p/>
</div>
<div class="page"><p/>
<p>Interfaces that are initially too slow will become faster, but will require training
</p>
<p>(to learn the task) and practice (to get faster), and may not end up fast enough.
</p>
<p>Time to perform a task can be roughly predicted by comparison with other tasks or
</p>
<p>after several initial trials to get the slope of the learning curve (this approach is
</p>
<p>used in industry to predict manufacturing times). There are theories that should
</p>
<p>provide this information in the future when the theories become more tractable
</p>
<p>(Anderson 2007; Christou et al. 2009).
</p>
<p>Theories also note what should be provided to users at different stages of their
</p>
<p>learning (Kim et al. 2013; Ohlsson 2008). Users must have some declarative
</p>
<p>information about a task before they can perform it. This means that interfaces and
</p>
<p>their associated system, including manuals, online help, web sites, and other users,
</p>
<p>should provide the new user with enough information to perform the task or at
</p>
<p>least to start to explore the environment. More generally, you should aim to
</p>
<p>support user task performance and learning at all levels, from knowledge-based to
</p>
<p>skill-based.
</p>
<p>How procedural and declarative memory are used will depend on how they are
</p>
<p>represented. If the user has a more general representation and declarative
</p>
<p>knowledge associated with it, through practice the user can create procedural
</p>
<p>memories (Kim et al. 2013). The procedural knowledge can transfer to new
</p>
<p>problems more easily. Interfaces and systems (including instructional materials)
</p>
<p>that support more general representations and more task-oriented representations
</p>
<p>(vs. tool specific representations) will allow users to transfer their knowledge both
</p>
<p>in and out of the interface more readily.
</p>
<p>The learning curve that can be created by observing learners can provide
</p>
<p>insights to system design directly. The start of the curve shows how difficult the
</p>
<p>interface is for novices. The amount of time to initially perform the task might be
</p>
<p>seen to be too high or at an acceptable level. Figure 5.13a shows a relatively
</p>
<p>shallow curve where novices are not so different from experts in performance.
</p>
<p>Figure 5.13b shows a curve where novices would be less happy, but which might
</p>
<p>be appropriate for a game. The slope of the curve can also provide insights. If the
</p>
<p>curve is very steep, and the system will be used often, the initial task times might
</p>
<p>not be an issue. If the interface is to be used only a few times, then the slope needs
</p>
<p>to get the user&rsquo;s task time to an acceptable level within that time frame. It can be
</p>
<p>the case that 150 s is an acceptable time, or it can be that 50 s is not and even the
</p>
<p>top curve is not fast enough&mdash;it will depend on the context.
</p>
<p>Some users like to learn. This is probably most often seen in games, which have
</p>
<p>their explicit goal to teach the user some procedural skill (like driving a racing
</p>
<p>car), or some declarative knowledge (like the way round a dungeon). Most other
</p>
<p>users prefer not to learn, but will if the task is important enough.
</p>
<p>If the users are likely to encounter situations where they may not have enough
</p>
<p>expertise to deal with the situation easily (e.g., plane malfunctions), you should
</p>
<p>consider providing them with instructions at that point (e.g., how to land when out
</p>
<p>of fuel). These instructions will not always help, but they often can. In computer
</p>
<p>systems these problems are often now being found on the Internet (e.g., how to
</p>
<p>repair a bad disk, how to clear a stuck keyboard).
</p>
<p>156 5 Cognition: Memory, Attention, and Learning</p>
<p/>
</div>
<div class="page"><p/>
<p>Systems that allow users to recognize actions they want to do will be easier
</p>
<p>initially to use than those that require users to recall commands. There is a trade-
</p>
<p>off, however, when the novices become experts. The experts will be able to recall
</p>
<p>the keystrokes or command names and will not wish to wade through the choices.
</p>
<p>For example, Linux experts like to use keystrokes in the command shell, while
</p>
<p>novices on Windows prefer a graphical user interface.
</p>
<p>Systems that encourage users to reflect on how to perform the task may lead to
</p>
<p>different types of learning. Where the learning is incidental and not tied to edu-
</p>
<p>cational intent or systems, this may not matter. On the other hand, tutoring systems
</p>
<p>should be careful that what users learn is what is intended. For example, the
</p>
<p>interface should not encourage users to just try key presses or button clicks to see
</p>
<p>what happens, which can lead to implicit learning that is tied to the representation
</p>
<p>of the interface and not to the domain.
</p>
<p>Learning in such a situation has been seen in solving the 8-puzzle. Figure 5.2
</p>
<p>shows such a puzzle. When users could directly click on the interface to indicate the
</p>
<p>tile to move, they took a larger number of moves and could verbalize their
</p>
<p>knowledge less well than users that had to work harder to interact with the interface,
</p>
<p>such as clicking on the tile and the direction to move, or using a speech interface.
</p>
<p>0
</p>
<p>50
</p>
<p>100
</p>
<p>150
</p>
<p>200
</p>
<p>250
</p>
<p>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
</p>
<p>T
im
</p>
<p>e
 o
</p>
<p>f 
e
a
c
h
</p>
<p> t
ri
</p>
<p>a
l 
(s
</p>
<p>e
c
)
</p>
<p>Trials
</p>
<p>0
</p>
<p>50
</p>
<p>100
</p>
<p>150
</p>
<p>200
</p>
<p>250
</p>
<p>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
</p>
<p>T
im
</p>
<p>e
 o
</p>
<p>f 
e
a
c
h
</p>
<p> t
ri
</p>
<p>a
l 
(s
</p>
<p>e
c
)
</p>
<p>Trials
</p>
<p>(a)
</p>
<p>(b)
</p>
<p>Fig. 5.13 Two learning curves with approximately the same final speed. a A relatively shallow
learning curve. b A relatively steep learning curve
</p>
<p>5.4 Learning and Skilled Behavior 157</p>
<p/>
</div>
<div class="page"><p/>
<p>The experimenters hypothesized that the increased cost of typing in the direction to
</p>
<p>move the tile lead users to think more and learn at a higher level. When users could
</p>
<p>just click, they created simple rules and learned implicitly (Golightly et al. 1999).
</p>
<p>5.5 Summary
</p>
<p>Memory, attention, and learning make up some of the core aspects of cognition of
</p>
<p>users. These are well studied and well understood areas in psychology, and their
</p>
<p>results are increasingly able to be packaged and applied to interface design.
</p>
<p>There remain interesting areas for basic and applied research in these areas as
</p>
<p>technology creates new opportunities. These areas include multi-tasking, pro-
</p>
<p>spective memory aids, how to help users learn from systems, how to avoid biases
</p>
<p>in memory, how to help users manage things they need to remember (like pass-
</p>
<p>words), and how to direct the user&rsquo;s attention appropriately across both short time
</p>
<p>spans (e.g., an hour) and long time spans (e.g., years of learning and working with
</p>
<p>a system like Unix). Knowledge of the details of these aspects of human behavior
</p>
<p>allow better interfaces to be built.
</p>
<p>5.6 Other Resources
</p>
<p>If you would like to learn more about the areas covered in this chapter, it is well
</p>
<p>worth reading the book by Alan Baddeley from 2004 on book on human memory.
</p>
<p>Baddeley is one of the pioneers of human memory research as we understand it
</p>
<p>today. This text renders his portfolio of scientific research accessible to a general
</p>
<p>audience, offering insights that will change the way you think about your own
</p>
<p>memory and attention:
</p>
<p>Baddeley, A. (2004). Your memory: A user&rsquo;s guide. Buffalo, NY: Firefly Books.
</p>
<p>You may well have heard of the magic number 7 about human memory before.
</p>
<p>If you&rsquo;d like to read a paper that shows how this number was demonstrated to
</p>
<p>apply to human memory, it is worth seeing if you can get a copy of Miller&rsquo;s classic
</p>
<p>paper, published in a key psychology journal, Psychological Review. We note,
</p>
<p>however, that while this finding is still cited in the popular press as a well-known
</p>
<p>feature of human memory, subsequent studies have added more nuance to the
</p>
<p>observation&ndash;familiarity with the domain, modality (visual, auditory), and memory
</p>
<p>enhancement tactics can contribute to how many items are remembered:
</p>
<p>Miller, G. A. (1956). The magic number seven, plus or minus two: Some limits on our
capacity for processing information. Psychological Review, 63, 81&ndash;97.
</p>
<p>158 5 Cognition: Memory, Attention, and Learning</p>
<p/>
</div>
<div class="page"><p/>
<p>John Anderson&rsquo;s texts on cognitive psychology provide an excellent intro-
</p>
<p>duction also. These are more directed at beginning scholars wishing to dive deeper
</p>
<p>into this area:
</p>
<p>Anderson, J. R. (1999). Learning and memory (2nd ed.). New York, NY: John Wiley and
Sons.
</p>
<p>Anderson, J. R. (2009). Cognitive psychology and its implications (7th ed.). New York,
NY: Worth Publishers.
</p>
<p>An excellent introduction to cognitive modeling is Allen Newell&rsquo;s Unified
</p>
<p>Theories of Cognition. Although written a while ago, the text offers a nice
</p>
<p>introduction to the thinking that launched this field of research, and to a particular
</p>
<p>cognitive modeling environment that we mention in passing, Soar:
</p>
<p>Newell, A. (1990). Unified Theories of Cognition. Cambridge, MA: Harvard University
Press.
</p>
<p>Elizabeth Styles&rsquo; text on attention, perception, and memory offers a very good
</p>
<p>starting point and highlights how they are interdependent and interact:
</p>
<p>Styles, E. H. (2005). Attention, perception and memory: An integrated introduction. Hove,
UK: Psychology Press.
</p>
<p>For an accessible book on how reflection and memory affect performance in a
</p>
<p>business setting, read Tom Demarco&rsquo;s Slack:
</p>
<p>Demarco, T. (2001). Slack: Getting past burnout, busywork, and the myth of total effi-
ciency. New York, NY: Broadway Books.
</p>
<p>There are alsomany online demonstrations and resources in this area on sites such
</p>
<p>as The Exploratorium (http://www.exploratorium.edu/memory) and the EPsych site
</p>
<p>(http://epsych.msstate.edu).
</p>
<p>5.7 Exercises
</p>
<p>5.1 Find a user of a smartphone. It may have to be someone from outside your
</p>
<p>class. Ask them to note as many of the menu items on the smartphone as they
</p>
<p>can, and the structure of these menus. Have them do it without access to their
</p>
<p>phone.
</p>
<p>Compare what they remember with the phone itself. It will be useful to do
</p>
<p>this for several people and compare the results. What does this tell you about
</p>
<p>phone usage and users&rsquo; memory?
</p>
<p>5.2 Find an online tutorial, perhaps from this class or another class, or an online
</p>
<p>tutorial to teach you Lisp or Java. Using an informal representation, break
</p>
<p>down what you learn from a sample lesson into these concepts: math, theory
</p>
<p>5.6 Other Resources 159</p>
<p/>
<div class="annotation"><a href="http://www.exploratorium.edu/memory">http://www.exploratorium.edu/memory</a></div>
<div class="annotation"><a href="http://epsych.msstate.edu">http://epsych.msstate.edu</a></div>
</div>
<div class="page"><p/>
<p>of programming, programming constructs, language syntax, programming
</p>
<p>interface, online tutorial interface.
</p>
<p>What are the results, and what do they suggest for the design of online
</p>
<p>tutorials?
</p>
<p>5.3 With respect to a web site for a university department (or your company&rsquo;s),
</p>
<p>create a list of tasks and information that a user of a university department&rsquo;s
</p>
<p>web site would be able to retrieve from memory and a similar list that users
</p>
<p>might not initially be able to recall, but would recognize. An example of the
</p>
<p>first could include the main phone number, and an example of the second
</p>
<p>could include special resources or accomplishments of the department.
</p>
<p>5.4 Recall of memories is more difficult than recognition. As an example of this,
</p>
<p>write down the 50 US states. You can adapt this task to your own country, for
</p>
<p>example, listing the UK counties, the Bundesl&auml;nder of Germany, or the
</p>
<p>number of member states in the European Union.
</p>
<p>This effect also works for computer interfaces. You could attempt to name
</p>
<p>the menu bar items for a menu driven interface that you use often.
</p>
<p>5.5 Usability of security remains an ongoing active research area. Memory
</p>
<p>influences the use of computer security. There are several ways that this can
</p>
<p>happen. One way is in the choice and memorizing strategies for passwords.
</p>
<p>Read https://www.cs.cmu.edu/*help/security/choosing_passwords.html or
</p>
<p>find a similar study on how people choose passwords. If you have time, write
</p>
<p>down your previous passwords, or ask people you know to fill out a small
</p>
<p>survey on what type of password they have, or have had. What do the results
</p>
<p>say about human memory and about computer interface design for passwords?
</p>
<p>5.6 The first step of this exercise is to prepare a task for users to perform. This task
</p>
<p>should take people about 2 min on their first attempt, and they should be
</p>
<p>successful nearly all of the time. Students have used such tasks as card sorting,
</p>
<p>shoe tying, word processing, paper airplane construction, typing a paragraph,
</p>
<p>and web navigation. You should prepare instructions, as you will be having
</p>
<p>someone else perform the task. If the task is longer than 2 min it gets hard to
</p>
<p>run the necessary number of trials. If it is less than 2 min it may get hard to
</p>
<p>time as the users get faster. Anywhere from 70 s to 210 s is likely to work
</p>
<p>easily, and greater or lesser amounts will work to a certain extent. Online tasks
</p>
<p>may be more appropriate for your course, but what&rsquo;s interesting is that it does
</p>
<p>not matter what task you choose or whether it is online or not.
</p>
<p>To get a good look at the learning curve, you should run 2&ndash;5 users on your
</p>
<p>task, and the subjects should each perform the task at least 15 times. Because of
</p>
<p>the logarithmic scale, 100 times is twice as good as 10, a 1000 times is three
</p>
<p>times as good. You may choose to run 5 subjects on the task 15 times (at most, 5
</p>
<p>subjects 9 2 min 9 15 times = 150 min, so you may want to have help), or
</p>
<p>you might choose to run 2 users over a longer series of trials.
</p>
<p>You should record the time taken to perform the task each time, and note
</p>
<p>whether the user made any minor errors, significant errors, or catastrophic
</p>
<p>160 5 Cognition: Memory, Attention, and Learning</p>
<p/>
<div class="annotation"><a href="https://www.cs.cmu.edu/~help/security/choosing_passwords.html">https://www.cs.cmu.edu/~help/security/choosing_passwords.html</a></div>
</div>
<div class="page"><p/>
<p>errors. Some of these suggest that something besides normal learning was
</p>
<p>going on, or that a trial was in some way unusual.
</p>
<p>When you graph your results, you should see a power curve or exponential
</p>
<p>curve. Both linear and log&ndash;log plots are interesting ways to plot this data.
</p>
<p>You should comment on how your results fit the predictions in this book,
</p>
<p>other resources, and what your results mean for your task and for related tasks.
</p>
<p>References
</p>
<p>Anderson, J. R. (1982). Acquisition of cognitive skill. Psychological Review, 89, 369&ndash;406.
Anderson, J. R. (1993). Rules of the mind. Hillsdale, NJ: Erlbaum.
Anderson, J. R. (1995). Learning and memory. New York, NY: Wiley.
Anderson, J. R. (2004). Cognitive psychology and its implications (5th ed.). New York, NY:
</p>
<p>Worth Publishers.
Anderson, J. R. (2007). How can the human mind exist in the physical universe?. New York, NY:
</p>
<p>Oxford University Press.
Anderson, J. R., Conrad, F. G., &amp; Corbett, A. T. (1989). Skill acquisition and the LISP tutor.
</p>
<p>Cognitive Science, 13(4), 467&ndash;505.
Anderson, J. R., &amp; Lebiere, C. (1998). The atomic components of thought. Mahwah, NJ: Erlbaum.
Atkinson, R. C., &amp; Shiffrin, R. M. (1968). Human memory: A proposed system and its control
</p>
<p>processes. In K. W. Spence &amp; J. T. Spence (Eds.), The psychology of learning and motivation
(Vol. 2). New York, NY: Academic Press.
</p>
<p>Baddeley, A. D. (1976). The psychology of memory. New York: Basic Books.
Baddeley, A. D. (1986). Working memory. Oxford, UK: Oxford University Press.
Bailey, B. P., &amp; Konstan, J. A. (2001). The effects of interruptions on task performance:
</p>
<p>Annoyance, and anxiety in the user interface. In Interact, 2001 (pp. 593&ndash;601).
Bainbridge, L. (1983). Ironies of automation. Automatica, 19(6), 770&ndash;775.
Baxter, G., Rooksby, J., Whang, Y., &amp; Kahajeh-Hosseine, A. (2012). The ironies of automation&hellip;
</p>
<p>still going strong at 30? In Proceedings of ECCE 2012 Conference (pp. 65&ndash;71). Edinburgh,
North Britain.
</p>
<p>Card, S. K., Moran, T., &amp; Newell, A. (1983). The psychology of human-computer interaction.
Hillsdale, NJ: Erlbaum.
</p>
<p>Charness, N., Holley, P., Feddon, J., &amp; Jastrzembski, T. (2004). Light pen use and practice
minimize age and hand performance differences in pointing tasks. Human Factors, 46(3),
373&ndash;384.
</p>
<p>Chilton, E. (1996). What was the subject of Titchner&rsquo;s doctoral thesis? SigCHI Bulletin, 28(2),
96.
</p>
<p>Christou, G., Ritter, F. E., &amp; Jacob, R. J. K. (2009). Knowledge-based usability evaluation for
reality-based interaction. In G. Christou, E. L.-C. Law, W. Green &amp; K. Hornbaek (Eds.),
Challenges in the evaluation of usability and user experience in reality-based interaction
(workshop proceedings). At CHI 2009 Conference on Human Factors in Computing Systems,
</p>
<p>Boston, MA, 2009. CHI 2009 Workshop: Challenges in Evaluating Usability and User
</p>
<p>Experience in Reality Based Interaction (pp. 36&ndash;39). Toulouse, France: IRIT Press.
Corbett, A. T., &amp; Anderson, J. R. (1990). The effect of feedback control on learning to program
</p>
<p>with the LISP tutor. In Proceedings of the 12th Annual Conference of the Cognitive Science
Society (pp. 796&ndash;803). Erlbaum: Hillsdale, NJ.
</p>
<p>Daneman, M., &amp; Carpenter, P. A. (1980). Individual differences in working memory and reading.
Journal of Verbal Learning and Verbal Behavior, 19, 450&ndash;466.
</p>
<p>5.7 Exercises 161</p>
<p/>
</div>
<div class="page"><p/>
<p>Delaney, P. F., Reder, L. M., Staszewski, J. J., &amp; Ritter, F. E. (1998). The strategy specific nature
of improvement: The power law applies by strategy within task. Psychological Science, 9(1),
1&ndash;8.
</p>
<p>Engle, R. W. (2002). Working memory capacity as executive attention. Current Directions in
Psychological Science, 11(1), 19&ndash;23.
</p>
<p>Ericsson, K. A. (Ed.). (1996). The road to excellence: The acquisition of expert performance in
the arts and sciences. Mahwah, NJ: Erlbaum.
</p>
<p>Ericsson, K. A., Chase, W. G., &amp; Faloon, S. (1980). Acquisition of a memory skill. Science, 208,
1181&ndash;1182.
</p>
<p>Ericsson, K. A., &amp; Kintsch, W. (1995). Long-term working memory. Psychological Review, 102,
211&ndash;245.
</p>
<p>Ericsson, K. A., &amp; Simon, H. A. (1993). Protocol analysis: Verbal reports as data (2nd ed.).
Cambridge, MA: MIT Press.
</p>
<p>Fitts, P. M. (1964). Perceptual-motor skill learning. In A. W. Melton (Ed.), Categories of human
learning (pp. 243&ndash;285). New York, NY: Academic Press.
</p>
<p>Golightly, D., Hone, K. S., &amp; Ritter, F. E. (1999). Speech interaction can support problem
solving. In Human-Computer Interaction&mdash;Interact &lsquo;99 (pp. 149&ndash;155). IOS Press.
</p>
<p>Hayes, J. R. (1981). The complete problem solver. Philadelphia: The Franklin Institute Press.
Heathcote, A., Brown, S., &amp; Mewhort, D. J. K. (2000). The power law repealed: The case for an
</p>
<p>exponential law of practice. Psychonomic Bulletin &amp; Review, 7(2), 185&ndash;207.
Intons-Peterson, M. J., &amp; Best, D. L. (1998). Introduction and brief history of memory distortions
</p>
<p>and their prevention. In M. J. Intons-Peterson &amp; D. L. Best (Eds.), Memory distortions and
their prevention. Mahwah, NJ: Erlbaum.
</p>
<p>Jensen, M. B., &amp; Healy, A. F. (1998). Retention of procedural and declarative information from
the Colorado Driver&rsquo;s Manual. In M. J. Intons-Peterson &amp; D. L. Best (Eds.), Memory
distortions and their prevention (pp. 113&ndash;124). Mahwah, NJ: Erlbaum.
</p>
<p>Kaplan, C. (1989). Hatching a Theory of Incubation: Does putting a problem aside really help? If
so, why?, Carnegie-Mellon University, University Microfilms International, Catalog
#9238813.
</p>
<p>Kieras, D. E., &amp; Polson, P. G. (1985). An approach to the formal analysis of user complexity.
International Journal of Man-Machine Studies, 22, 365&ndash;394.
</p>
<p>Kieras, D. E., Wood, S. D., &amp; Meyer, D. E. (1997). Predictive engineering models based on the
EPIC architecture for a multimodal high-performance human-computer interaction task.
Transactions on Computer-Human Interaction, 4(3), 230&ndash;275.
</p>
<p>Kim, J. W., Ritter, F. E., &amp; Koubek, R. J. (2013). An integrated theory for improved skill
acquisition and retention in the three stages of learning. Theoretical Issues in Ergonomics
Science, 14(1), 22&ndash;37.
</p>
<p>Larkin, J. H. (1981). Enriching formal knowledge: A model for learning to solve textbook physics
problems. In J. R. Anderson (Ed.), Cognitive skills and their acquisition (pp. 311&ndash;334).
Hillsdale, NJ: Erlbaum.
</p>
<p>Larkin, J. H., McDermott, J., Simon, D. P., &amp; Simon, H. A. (1980a). Expert and novice
performance in solving physics problems. Science, 208, 1335&ndash;1342.
</p>
<p>Larkin, J. H., McDermott, J., Simon, D. P., &amp; Simon, H. A. (1980b). Models of competence in
solving physics problems. Cognitive Science, 4, 317&ndash;345.
</p>
<p>Lindsay, P. H., &amp; Norman, D. A. (1977). Human information processing (2nd). San Diego, CA:
Harcourt Brace Jovanovich.
</p>
<p>Loftus, E. F. (1975). Leading questions and the eyewitness report. Cognitive Psychology, 7,
560&ndash;572.
</p>
<p>Loftus, E. F. (2003). Our changeable memories: Legal and practical implications. Nature Reviews
Neuroscience, 4, 231&ndash;234.
</p>
<p>Lovett, M. C., Daily, L. Z., &amp; Reder, L. M. (2000). A source activation theory of working
memory: Cross-task prediction of performance in ACT-R. Journal of Cognitive Systems
Research, 1, 99&ndash;118.
</p>
<p>162 5 Cognition: Memory, Attention, and Learning</p>
<p/>
</div>
<div class="page"><p/>
<p>McFarlane, D. C. (1997). Interruption of people in human-computer interaction: A general
unifying definition of human interruption and taxonomy (Tech Report No. NRL/FR/5510&ndash;97-
9870): Naval Research Laboratory. (also at infoweb.nrl.navy.mil/htbin/webcat).
</p>
<p>McFarlane, D. C. (1999). Coordinating the interruption of people in human-computer interaction.
In INTERACT &lsquo;99 (pp. 295&ndash;303). IOS Press.
</p>
<p>Meyer, D. E., &amp; Kieras, D. E. (1997). A computational theory of executive cognitive processes
and multiple-task performance: Part 1. Basic mechanisms. Psychological Review, 104(1),
3&ndash;65.
</p>
<p>Miller, G. A. (1956). The magic number seven, plus or minus two: Some limits on our capacity
for processing information. Psychological Review, 63, 81&ndash;97.
</p>
<p>Newell, A. (1990). Unified theories of cognition. Cambridge, MA: Harvard University Press.
Nickerson, R. (1969). Man-Computer interaction: A challenge for human factors research.
</p>
<p>Ergonomics, 12 (pp. 501&ndash;517). (Reprinted in 1969 in IEEE Transactions on Man-Machine
Systems, 10(4), 164&ndash;180).
</p>
<p>Norman, D. A. (1981). Categorization of action slips. Psychological Review, 88, 1&ndash;15.
O&rsquo;Hara, K., &amp; Payne, S. J. (1998). Effects of operator implementation cost on performance of
</p>
<p>problem solving and learning. Cognitive Psychology, 35, 34&ndash;70.
Ohlsson, S. (1992). The learning curve for writing books: Evidence from Professor Asimov.
</p>
<p>Psychological Science, 3(6), 380&ndash;382.
Ohlsson, S. (2008). Computational models of skill acquisition. In R. Sun (Ed.), The Cambridge
</p>
<p>handbook of computational psychology (pp. 359&ndash;395). Cambridge: Cambridge University
Press.
</p>
<p>Rabbitt, P., &amp; Banerji, N. (1989). How does very prolonged practice improve decision speed?
Journal of Experimental Psychology: General, 118, 338&ndash;345.
</p>
<p>Raskin, J. (2000). The humane interface. Boston, MA: Addison-Wesley.
Rasmussen, J. (1983). Skills, rules, knowledge: Signals, signs and symbols and other distinctions
</p>
<p>in human performance models. IEEE Transactions: Systems, Man, &amp; Cybernetics, SMC-13,
257&ndash;267.
</p>
<p>Reason, J. (1990). Human error. Cambridge, UK: Cambridge University Press.
Ritter, F. E., &amp; Feurzeig, W. (1988). Teaching real-time tactical thinking. In J. Psotka, L.
</p>
<p>D. Massey, &amp; S. A. Mutter (Eds.), Intelligent tutoring systems: Lessons learned (pp.
285&ndash;301). Hillsdale, NJ: Erlbaum.
</p>
<p>Ritter, F. E., &amp; Schooler, L. J. (2001). The learning curve. In W. Kintch, N. Smelser, &amp; P. Baltes
(Eds.), International encyclopedia of the social and behavioral sciences (Vol. 13,
pp. 8602&ndash;8605). Amsterdam: Pergamon.
</p>
<p>Seibel, R. (1963). Discrimination reaction time for a 1,023-alternative task. Journal of
Experimental Psychology, 66(3), 215&ndash;226.
</p>
<p>Siegler, R. S. (1988). Strategy choice procedures and the development of multiplication skill.
Journal of Experimental Psychology: General, 117(3), 258&ndash;275.
</p>
<p>Simon, H. A. (1974). How big is a chunk? Science, 183, 482&ndash;488.
Simon, H. A., &amp; Chase, W. G. (1973). Skill in chess. American Scientist, 61(393&ndash;403), FIND.
Simonton, D. K. (1996). Creative expertise: A life-span developmental perspective. In K.
</p>
<p>A. Ericsson (Ed.), The road to excellence: The acquisition of expert performance in the arts
and sciences (pp. 227&ndash;253). Mahwah, NJ: Erlbaum.
</p>
<p>Singley, M. K., &amp; Anderson, J. R. (1989). The transfer of cognitive skill. Cambridge, MA:
Harvard University Press.
</p>
<p>Snoddy, G. S. (1926). Learning and stability. Journal of Applied Psychology, 10, 1&ndash;36.
Sperling, G. A. (1961). The information available in brief visual presentations. Psychological
</p>
<p>Monographs, 74(whole No. 498).
Suchman, L. (1983). Office procedures as practical action: Models of work and system design.
</p>
<p>ACM Transactions on Office Information Systems, 1, 320&ndash;328.
Thomas, E. L., &amp; Robinson, H. A. (1972). Improving reading in every class: A sourcebook for
</p>
<p>teachers. Boston, MA: Allyn &amp; Bacon.
</p>
<p>References 163</p>
<p/>
</div>
<div class="page"><p/>
<p>Tulving, E. (2002). Episodic memory: From mind to brain. Annual Review of Psychology, 53,
1&ndash;25.
</p>
<p>Wickens, C. D., &amp; Hollands, J. G. (2000). Engineering psychology and human performance (3rd
ed.). Prentice-Hall: Upper Saddle River, NJ.
</p>
<p>Woods, D. D., &amp; Patterson, E. E. (2001). How unexpected events produce an escalation of
cognitive and coordinative demands. In P. A. Hancock &amp; P. A. Desmond (Eds.), Stress,
workload, and fatigue (pp. 290&ndash;302). Mahwah, NJ: Erlbaum.
</p>
<p>Zhang, G., &amp; Simon, H. A. (1985). STM capacity for Chinese words and idioms: Chunking and
acoustical loop hypotheses. Memory and Cognition, 13(3), 193&ndash;201.
</p>
<p>164 5 Cognition: Memory, Attention, and Learning</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 6
</p>
<p>Cognition: Mental Representations,
</p>
<p>Problem Solving, and Decision Making
</p>
<p>Abstract There are several higher level structures built upon the basic structures
</p>
<p>of memory, attention, and learning in the user&rsquo;s cognitive architecture. These
</p>
<p>representations and behaviors include mental models, problem solving, and
</p>
<p>decision making. These structures and processes form the basics of higher level
</p>
<p>cognition when interacting with technology, and describe some of the ways that
</p>
<p>users represent systems and interfaces, and how users interact with and use sys-
</p>
<p>tems. Mental models are used to understand systems and to interact with systems.
</p>
<p>When the user&rsquo;s mental models are inaccurate, systems are hard to use. Problem
</p>
<p>solving is used when it is not clear what to do next. Problem solving uses mental
</p>
<p>models, forms a basis for learning, and can be supported in a variety of ways.
</p>
<p>Decision making is a more punctuated form of problem solving, made about and
</p>
<p>with systems. It is not always as clear or accurate as one would like (or expect),
</p>
<p>and there are ways to support and improve it. There are some surprises in each of
</p>
<p>these areas where folk psychology concepts and theories are inaccurate.
</p>
<p>6.1 Introduction
</p>
<p>When people interact with artifacts, even for the first time, they usually have some
</p>
<p>idea of what to do. If it is a piece of electrical equipment, they may first look for
</p>
<p>the on/off switch, for example, and then press that. The way that people interact
</p>
<p>with artifacts is governed by their mental representation of that artifact. These
</p>
<p>mental models develop over time: as people use the artifact more and more, they
</p>
<p>learn more about how it works and refine their mental model accordingly. The
</p>
<p>mental models can be either structural (based on the structure of the artifact in
</p>
<p>terms of its components) or functional (based on the behavior of the artifact).
</p>
<p>As the complexity of artifacts increases, it becomes harder to develop a
</p>
<p>complete, accurate structural mental model of them. If you are someone who
</p>
<p>drives a car but takes it to someone else for maintenance, for example, the chances
</p>
<p>are that you have a relatively simple functional mental model of how the car
</p>
<p>F. E. Ritter et al., Foundations for Designing User-Centered Systems,
DOI: 10.1007/978-1-4471-5134-0_6, ï¿½ Springer-Verlag London 2014
</p>
<p>165</p>
<p/>
</div>
<div class="page"><p/>
<p>operates&mdash;when you turn the key, you expect the engine to start, and so on. This
</p>
<p>model will allow you to carry out limited troubleshooting if the car does not
</p>
<p>behave as you expect it to. If you are a car mechanic, however, you will have a
</p>
<p>much more developed structural model of how the car works, which will allow
</p>
<p>you to diagnose and remedy any problems.
</p>
<p>Designers have a functional mental model of how users behave. These models
</p>
<p>may be na&iuml;ve and contain several inaccuracies because they have created and
</p>
<p>refined these models based on their own experiences of how they themselves
</p>
<p>behave, rather than based on their experiences of how their users really behave.
</p>
<p>One of the main purposes of this book is to help designers to develop a more
</p>
<p>sophisticated and more accurate model of users. You should, at this point in the
</p>
<p>book, know that, while not all users are the same, they are similar in many ways.
</p>
<p>Users differ in terms of the knowledge they possess, their capabilities, and their
</p>
<p>attributes. They also share common structures in how they receive and process
</p>
<p>information, and interact with the world. Understanding how these differences and
</p>
<p>similarities influence their behaviors will help you to design systems that are better
</p>
<p>suited to a wider range of users.
</p>
<p>You should have learned by this point in the book that users behave unusually
</p>
<p>when they find themselves in novel or rarely encountered situations. This is
</p>
<p>because their mental models are not fully developed for those situations. In these
</p>
<p>situations, users often have to go back to basics, and use their mental model to
</p>
<p>carry out some problem solving. The way that they problem solve has associated
</p>
<p>biases, weaknesses, and strengths that you may be able to deal with in your design.
</p>
<p>As part of the problem solving process, users will often make decisions about
</p>
<p>what actions to take next. Decision making, like problem solving, has associated
</p>
<p>biases, weaknesses, and strengths that can be used to inform system design.
</p>
<p>Problem solving and decision making are probably the most widely observable
</p>
<p>and, arguably, the most important behaviors of users. Many fields of research study
</p>
<p>these topics, including psychology, economics, and statistics. Here we focus on
</p>
<p>how people make judgments and decisions, and how to support these processes in
</p>
<p>system design.
</p>
<p>6.2 Mental Representations
</p>
<p>Users can make use of several types of representations when they are problem
</p>
<p>solving or using an interface to perform a task. For example, users can understand
</p>
<p>an electronic circuit as a series of propositions (the secondary accumulator is
</p>
<p>connected to the laser bank), as a diagram (shown in Fig. 6.1), or implicitly as a
</p>
<p>series of steps to make the circuit work, such as &lsquo;&lsquo;First flip switch 1, and if that
</p>
<p>does not work&hellip;&rsquo;&rsquo; (Bibby and Payne 1996). Each of the representations has dif-
</p>
<p>ferent strengths and weaknesses. The propositions may be easier to learn, the
</p>
<p>schematic allows some types of problem solving, and the rules require less
</p>
<p>knowledge to be learned or stored for later use.
</p>
<p>166 6 Cognition: Mental Representations, Problem Solving, and Decision Making</p>
<p/>
</div>
<div class="page"><p/>
<p>6.2.1 Simple Representations
</p>
<p>Representations can be classified in many ways. Two types of simple represen-
</p>
<p>tations that occur repeatedly include semantic/propositional representations and
</p>
<p>visual/spatial representations.
</p>
<p>Consider the information in Table 6.1, and attempt to memorize it. Then
</p>
<p>consider the information in Fig. 6.2. The information represented is the same in
</p>
<p>both places, but the representations give rise to different behavior and support
</p>
<p>different types of tasks.
</p>
<p>The information about the sets of letters in Table 6.1 and Fig. 6.2 is probably
</p>
<p>better represented as a series rather than as a set of propositions&mdash;it is more
</p>
<p>succinct, easier to learn, and for most tasks it is easier to manipulate. The
</p>
<p>canonical series ABCD is particularly easy to memorize: it probably already exists
</p>
<p>as a series in your head. The other series is more difficult, but is probably easier to
</p>
<p>remember and use as a series than as a set of propositions.
</p>
<p>The best representation for the workshop expenses will vary. For most tasks,
</p>
<p>users will be better off with the numbers themselves. The graphical representation
</p>
<p>on the left in Fig. 6.2 (created using the default settings of a common spreadsheet
</p>
<p>program) is less clear than the bespoke graph on the right in the same figure. The
</p>
<p>relative values can be quickly judged, but the absolute numbers will be more dif-
</p>
<p>ficult to obtain. Both graphs are less useful than a table of numbers for many tasks.
</p>
<p>Sometimes users will use propositional representations. Sometimes they will
</p>
<p>use a more visual representation. Interfaces should support the representation that
</p>
<p>users have, as well as be mindful of supporting the representation that will be most
</p>
<p>helpful for a task. It is the job of the designer to find the representations that best
</p>
<p>support the task, and those that users already have, and to balance the design to
</p>
<p>support these representations.
</p>
<p>ENERGY
BOOSTER
</p>
<p>ONE
</p>
<p>MAIN
ACCUMULATOR
</p>
<p>POWER
SOURCE
</p>
<p>SECONDARY
ACCUMULATOR
</p>
<p>TWO
</p>
<p>SECONDARY
ACCUMULATOR
</p>
<p>ONE
</p>
<p>ENERGY
BOOSTER
</p>
<p>TWO
</p>
<p>LASER
BANK
</p>
<p>Off         On
</p>
<p>EB1       EB2
</p>
<p>SA1
</p>
<p>SA2
</p>
<p>MA
</p>
<p>SA
</p>
<p>Fig. 6.1 A type of circuit schematic (based on Ritter and Bibby 2008)
</p>
<p>6.2 Mental Representations 167</p>
<p/>
</div>
<div class="page"><p/>
<p>6.2.2 User&rsquo;s Mental Models
</p>
<p>The mental models that people use in performing tasks affect how they perceive
</p>
<p>and interact with the world. There are several different meanings of the term
</p>
<p>mental model, however, and the different ways in which it is used can be confusing
</p>
<p>(e.g., Gentner and Stevens 1983; Johnson-Laird 1983; Moray 1996, 1999; Norman
</p>
<p>1983; Wilson and Rutherford 1989). For our purposes we think of mental models
</p>
<p>as a representation of some part of the world that can include the structures of the
</p>
<p>world (the ontology of the relevant objects), how they interact, and how the user
</p>
<p>can interact with them.
</p>
<p>As an example, work out how many windows there are in the place where you
</p>
<p>live. The way that most people arrive at an answer is by referring to a structural
</p>
<p>mental model of their home. They then imagine walking around their model of the
</p>
<p>Table 6.1 Some propositional representations
</p>
<p>Letters example&mdash;canonical
</p>
<p>A is to the left of C
</p>
<p>C is to the left of D
</p>
<p>B is to the immediate right of A
</p>
<p>Letters example&mdash;non-canonical
</p>
<p>M is to the left of Y
</p>
<p>Y is to the left of S
</p>
<p>R is to the immediate right of M
</p>
<p>Workshop expenses
</p>
<p>Gross income was $3,500. Expenses for coffee breaks were $1,218; copying was $400, and
AV rental was $1,200. Net profit was $882
</p>
<p>Puzzle sequence
</p>
<p>A series of numbers is 8 5 4 9 1 3 2 7 6
</p>
<p>What comes next?
</p>
<p>0
</p>
<p>500
</p>
<p>1,000
</p>
<p>1,500
</p>
<p>2,000
</p>
<p>2,500
</p>
<p>3,000
</p>
<p>3,500
</p>
<p>Gross 
income
</p>
<p>Coffee 
breaks
</p>
<p>Copying AV rental Net profit
</p>
<p>0
</p>
<p>500
</p>
<p>1000
</p>
<p>1500
</p>
<p>2000
</p>
<p>2500
</p>
<p>3000
</p>
<p>3500
</p>
<p>Costs
</p>
<p>Gross income Coffee breaks Copying AV rental Net profit
</p>
<p>Series1
</p>
<p>Letters example&mdash;canonical:   A B C D
</p>
<p>Letters example&mdash;non-canonical: M R Y S
</p>
<p>Workshop expenses:   
</p>
<p>Fig. 6.2 Some graphical representations of the material in Table 6.1
</p>
<p>168 6 Cognition: Mental Representations, Problem Solving, and Decision Making</p>
<p/>
</div>
<div class="page"><p/>
<p>home and looking around the rooms at the walls to see where the windows are
</p>
<p>located.
</p>
<p>If you had to come up with a mental model of a printer, though, it may be more
</p>
<p>of a functional model. So it would include the notion that you feed paper into it,
</p>
<p>that the paper gets images and text written onto it, and that the paper comes out of
</p>
<p>the printer into some sort of hopper. The mental model might not specify what the
</p>
<p>something is that produces the images and text, but could include further
</p>
<p>knowledge about the paper path. Figure 6.1 is another example of possible mental
</p>
<p>model, this time of a Klingon laser bank.
</p>
<p>If the user&rsquo;s mental model accurately matches the device, the user can better use
</p>
<p>the mental model to perform their tasks, to troubleshoot the device, and to teach
</p>
<p>others about the task and device. If their mental model is inaccurate, however, the
</p>
<p>user will make poorer choices about what actions to take, may not be as happy, and
</p>
<p>may be less productive.
</p>
<p>The complexity of the mental model will vary by user, by system, and by
</p>
<p>context. If the structure of the system is relatively simple, we can think of the
</p>
<p>model as an isometric model, in which every feature of the artifact is represented
</p>
<p>by a corresponding feature in the model. As the structure increases, however,
</p>
<p>people try to manage the complexity by grouping together related features from
</p>
<p>the real artifact and representing them using a single point in the model. This is
</p>
<p>what is called a homomorphic model. For more complex systems, and systems of
</p>
<p>systems (e.g., the Internet, the Space Shuttle, power grids, and so on), these mental
</p>
<p>models are also more likely to be functional, based on the way that the system
</p>
<p>behaves in particular circumstances, rather than structural.
</p>
<p>Understanding users&rsquo; mental models is important for system designers (Carroll
</p>
<p>and Olson 1987; Revell and Stanton 2012). The model the user brings to the task
</p>
<p>will influence how they use the system, what strategies they will most likely
</p>
<p>employ, and what errors they are likely to make. It is, therefore, important to
</p>
<p>design the system in such a way that the user can develop an accurate mental
</p>
<p>model of it.
</p>
<p>While this is not a computer example, the design of Philadelphia airport&lsquo;s
</p>
<p>Concourse A violates most people&rsquo;s mental model and illustrates the role of
</p>
<p>mental models in using a system. A diagram of it is shown in Fig. 6.3. Users
</p>
<p>coming in on the left expect to see Gate A2 between A1 and A3. They might know
</p>
<p>that gates are sometimes numbered odd/even by side of concourse, but, in this
</p>
<p>case, the nearest gate on the other side is not even visible from most areas around
</p>
<p>A1. There are numerous informal signs taped up at A1 noting where A2 is that
</p>
<p>have been created by the airline ground staff, who clearly get asked where A2 is
</p>
<p>quite often. There are several ways to fix this. The numbers could run A1, A2 and
</p>
<p>wrap from A6 on the top to A7 and A8, or A2 and A4 could be A12 and A14.
</p>
<p>Figure 6.4 shows another example of how mental models can lead to ambig-
</p>
<p>uous and even misleading interfaces. The interface designer has created a default
</p>
<p>of &lsquo;Best&rsquo;, but it is not clear whether this is the faster 89 speed or the more careful
</p>
<p>19 speed. Which is best? (One of us always selects a slow speed.)
</p>
<p>6.2 Mental Representations 169</p>
<p/>
</div>
<div class="page"><p/>
<p>Therefore, when you design a system you need to have an accurate mental
</p>
<p>model of how people will use it. This requires understanding how people will use
</p>
<p>it, the tasks they will perform using the system, and their normal working context.
</p>
<p>The developer&rsquo;s mental model of the system is often different from the user&rsquo;s
</p>
<p>mental model of the system (this book is intended to help designers build a better
</p>
<p>mental model of users in their own heads). Systems should describe things using
</p>
<p>conventions that are consonant with the users&rsquo; mental models, for example, or be
</p>
<p>prepared to change either the users&rsquo; mental models or the designer&rsquo;s. Making the
</p>
<p>system compliant with the user&rsquo;s mental model will almost certainly help reduce
</p>
<p>the time it takes to perform tasks, reduce learning time, and improve the accept-
</p>
<p>ability of the system.
</p>
<p>An important area of consideration for you and your users&rsquo; mental model is
</p>
<p>processing speed and the complexity of the task. Computer programs and algo-
</p>
<p>rithms have a time to process an object that may be based on the number of objects
</p>
<p>(e.g., simply filing objects, or coloring them), or it may be based on their
</p>
<p>Fig. 6.3 Diagram of the Philadelphia airport concourse where the user&rsquo;s mental model does not
support finding Gates A2 and A4
</p>
<p>Fig. 6.4 Setting the speed for writing a CD. Which is best? Slow and careful, or faster but
slightly more likely to throw an error? Taken from Toast 10 Titanium
</p>
<p>170 6 Cognition: Mental Representations, Problem Solving, and Decision Making</p>
<p/>
</div>
<div class="page"><p/>
<p>relationship to other objects (e.g., sorting them, or looking for relationships). When
</p>
<p>the process is based on the number of objects, the algorithm is linear. When the
</p>
<p>process for each item is based on the number of other objects as well, the algorithm
</p>
<p>is nonlinear (e.g., based on the square of the number of objects which represents the
</p>
<p>number of possible comparisons). Sometimes there are algorithms that are not too
</p>
<p>bad with increasing numbers of objects, and other times the costs quickly expand
</p>
<p>beyond the capabilities of even modern computers. This area is addressed by
</p>
<p>algorithm complexity, and your users will not understand it well.
</p>
<p>Further illustrative examples of problems in interfaces caused by a mismatch
</p>
<p>from the designer&rsquo;s view of the task and the user&rsquo;s mental model (such as doors
</p>
<p>that open the wrong way, and buttons that are hard to find) can be found in books
</p>
<p>such as Norman (1988, 2013) and on web sites of interface bloopers.
</p>
<p>6.2.3 Feeling of Knowing and Confidence Judgments
</p>
<p>Users will vary in how confident they are in their representations. So they will ask
</p>
<p>themselves questions about objects such as &lsquo;&lsquo;Is this a clickable region?,&rsquo;&rsquo; about
</p>
<p>processes such as &lsquo;&lsquo;Is this the right way to do it?,&rsquo;&rsquo; and results such as &lsquo;&lsquo;Is this the
</p>
<p>right answer?.&rsquo;&rsquo;
</p>
<p>The way that confidence judgments are analyzed varies across contexts and
</p>
<p>research domains. Computer science and artificial intelligence (AI), for example,
</p>
<p>have tried to provide algorithms for computing a confidence level based on the
</p>
<p>available evidence. Psychology has studied feeling of knowing, about word
</p>
<p>retrieval, strategy selection, and how close you are to the answer. Business has
</p>
<p>studied confidence in decision making. In each of these cases, the measures of
</p>
<p>confidence form another part of a mental representation.
</p>
<p>Users will base their feeling of knowing on a wide range of information. This
</p>
<p>includes having successfully used the answer before, being familiar with the
</p>
<p>domain, social expectations from the person asking (do you know the way to&hellip;.?),
</p>
<p>and social comparison (others would know the answer, so I probably should also
</p>
<p>know it). Good interfaces will help users develop appropriate levels of confidence
</p>
<p>in their representations and decisions. Often, this means providing information to
</p>
<p>support learning, including feedback on task performance, and also providing
</p>
<p>information to build a mental model. If users do not get feedback, their calibration
</p>
<p>about how well they are doing will be poor to non-existent; this applies across
</p>
<p>many professions and businesses (Dawes 1994).
</p>
<p>6.2.4 Stimulus&ndash;Response Compatibility for Mental Models
</p>
<p>One aspect of mental models that can be applied to interface design is the idea of
</p>
<p>stimulus&ndash;response (S&ndash;R or SR) compatibility. This aspect of behavior is that the
</p>
<p>6.2 Mental Representations 171</p>
<p/>
</div>
<div class="page"><p/>
<p>stimulus and the response should be compatible. This is typically seen as having
</p>
<p>physical aspects of an interface (e.g., buttons) and displays (e.g., GUIs) match the
</p>
<p>world that they are representing. So the buttons to call an elevator to go up should
</p>
<p>be above the buttons that are used to call an elevator to go down. Systems where
</p>
<p>mappings like these are supported are faster to use and can lead to fewer errors.
</p>
<p>Payne&rsquo;s (1995) work, reported in Chap. 1, provides several examples of how
</p>
<p>S-R can influence the usability of interfaces. The better designs (shown in Chap. 1
</p>
<p>and explained further in the exercises) show that better S-R reduces errors by about
</p>
<p>70% compared to a poor mapping, and that response times can be up to 30%
</p>
<p>higher with a poor mapping.
</p>
<p>Another way to describe this aspect of behavior is making the task/action
</p>
<p>mappings appropriate. That is, the task the user is trying to perform should be easy
</p>
<p>to map to an action to perform. This is taken up in Chap. 12 as the Gulf of
</p>
<p>Execution.
</p>
<p>The effect of S&ndash;R compatibility can also play out in computer interface menus
</p>
<p>and interfaces. If the user is searching for a widget, then an interface that explicitly
</p>
<p>labels something as a widget is a clearer interface than one that calls the widgets
</p>
<p>thingamajigs. Figure 6.5 shows an example where the phrase &lsquo;&lsquo;Frequent flyer
</p>
<p>number&rsquo;&rsquo; was replaced with &lsquo;&lsquo;SkyMiles&rsquo;&rsquo; (a type of frequent flyer number). Making
</p>
<p>Fig. 6.5 An airport check-in kiosk. The phrase &lsquo;&lsquo;Add SkyMiles,&rsquo;&rsquo; on the bottom, refers to their
frequent flyer program account number which, if the interface is rarely used, can (and did) require
the user to do extra work by asking an agent what SkyMiles is, and how to enter a frequent flyer
number
</p>
<p>172 6 Cognition: Mental Representations, Problem Solving, and Decision Making</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1">http://dx.doi.org/10.1007/978-1-4471-5134-0_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1">http://dx.doi.org/10.1007/978-1-4471-5134-0_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1">http://dx.doi.org/10.1007/978-1-4471-5134-0_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1">http://dx.doi.org/10.1007/978-1-4471-5134-0_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12">http://dx.doi.org/10.1007/978-1-4471-5134-0_12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12">http://dx.doi.org/10.1007/978-1-4471-5134-0_12</a></div>
</div>
<div class="page"><p/>
<p>improvements like this to interfaces requires knowing the terms that the users will
</p>
<p>be using, which may require substantial work when the users are distant, and
</p>
<p>creating designs that can support multiple terms when different types of users
</p>
<p>search using different terms. In Fig. 6.5 changing &lsquo;&lsquo;SkyMiles&rsquo;&rsquo; to &lsquo;&lsquo;SkyMiles fre-
</p>
<p>quent flyer number&rsquo;&rsquo; would be appropriate.
</p>
<p>A related example of using multiple names for the same object leading to
</p>
<p>confusion happens with air travel from Dulles Airport. Its name is Dulles Inter-
</p>
<p>national Airport, and its code is IAD. It is located in the Washington, DC area
</p>
<p>about 25 miles west of Washington, DC; however, it is actually in Sterling, Vir-
</p>
<p>ginia, near the town of Dulles, VA. In other words, there are several ways that you
</p>
<p>could search to find the airport. Some users may use all of these terms, but some
</p>
<p>will not recognize some of them. This variety of naming conventions in the real
</p>
<p>world can make interface design complex. One way of simplifying things is to use
</p>
<p>multiple levels of naming. LON, for example, is the city code used to represent all
</p>
<p>the London airports. This helps users who are trying to fly to any London airport
</p>
<p>when searching for tickets, although they will not be able to fly into an airport with
</p>
<p>the code LON, and will have to select the specific destination airport, such as
</p>
<p>Heathrow (LHR), Gatwick (LGW), or Stansted (STN).
</p>
<p>6.2.5 Implications for System Design
</p>
<p>When designing systems, you need to think about the users (what types of users,
</p>
<p>the range of skill levels and attributes they may have, and so on), how they will
</p>
<p>carry out work using the system, and the context in which they will use the system.
</p>
<p>If you can talk with and observe users, this may provide you with a chance to learn
</p>
<p>how they represent themselves, their tasks, and the system.
</p>
<p>Mental models will often provide you with guidance about how to improve the
</p>
<p>usability of the system by matching the mental models the users have about
</p>
<p>themselves, their tasks, and the system (Krug 2005). Knowing about the users and
</p>
<p>their mental models will also help identify where you need to support them to
</p>
<p>develop an accurate mental model of the system. The areas where support is
</p>
<p>needed may not be obvious to you as a designer if you already understand&mdash;have a
</p>
<p>mental model appropriate to your purposes&mdash;the system, but your users are likely
</p>
<p>to have a different mental model of the system (based on beliefs, knowledge,
</p>
<p>capabilities, and attributes). Their models will differ between users and over time,
</p>
<p>so your design needs to take this into account.
</p>
<p>For example, photo manipulation software will have to teach the novice user
</p>
<p>about the concepts used to describe photos and manipulations to them. Cell phones
</p>
<p>may have to disambiguate cleanly what method is being used to make a call
</p>
<p>(phone or voice over IP), and what network the phone is connecting to (a phone
</p>
<p>company or a local wireless).
</p>
<p>6.2 Mental Representations 173</p>
<p/>
</div>
<div class="page"><p/>
<p>6.3 Problem Solving
</p>
<p>Figure 6.6 shows a set of puzzles. Solving the problem of how to complete the
</p>
<p>puzzles can be great fun. This general notion of problem solving also applies when
</p>
<p>users try to perform tasks using systems in a particular context.
</p>
<p>Problem solving essentially involves working out how to get from the current
</p>
<p>state of affairs to the goal that you are trying to achieve by taking appropriate
</p>
<p>actions. More formally, this can be described as applying operators to states to
</p>
<p>reach a goal. Problem solving is often studied by looking at how people solve
</p>
<p>puzzles, because the movement from one state to the next, and eventually to the
</p>
<p>goal, can be directly observed.
</p>
<p>In the Tower of Hanoi, shown in Fig. 6.7, the goal is to move all the disks from
</p>
<p>the left hand post to the right hand post. There are several constraints. The disks
</p>
<p>can only be moved one at a time. The discs have to go on a post, and a disc cannot
</p>
<p>be placed on top of a smaller disk.
</p>
<p>The first decision is therefore where to move the smallest disk? It can be moved
</p>
<p>to the middle or to the right post. The second decision is which disk to move, the
</p>
<p>smallest (probably not, but you could), and if you move the second smallest disk,
</p>
<p>there is only one post you can move it to. You continue in this way until all of the
</p>
<p>discs in the tower have been moved to another post. Although there are several
</p>
<p>ways to think about how to solve this puzzle, and several ways to solve it, there is
</p>
<p>only one correct minimal path.
</p>
<p>The Tower of Hanoi has been used for a long time as a useful illustration of
</p>
<p>problem solving. Because it is a relatively simple, clear, but non-trivial problem, it
</p>
<p>has been used to study problem solving. There is a clear starting state and a clear
</p>
<p>goal state; the operations (operators) that can be applied are fairly evident and easy
</p>
<p>Fig. 6.6 A set of puzzles
from a &lsquo;&lsquo;Sunday box&rsquo;&rsquo;,
designed for play (Copyright
ï¿½ 2006 James Dalgety,
Hordern-Dalgety Collection.
http://puzzlemuseum.com.
Used with permission)
</p>
<p>174 6 Cognition: Mental Representations, Problem Solving, and Decision Making</p>
<p/>
<div class="annotation"><a href="http://puzzlemuseum.com">http://puzzlemuseum.com</a></div>
</div>
<div class="page"><p/>
<p>to perform, and the constraints are relatively clear. It is easy to see the state of the
</p>
<p>disks, and it is basically easy to judge how close you are to the goal state. It takes
</p>
<p>effort to solve the puzzle, but people can generally solve it, particularly for three or
</p>
<p>four disks.
</p>
<p>6.3.1 The Importance of Problem Solving
</p>
<p>Problem solving occurs when users do not know what to do next. This happens
</p>
<p>when they are learning. Novice users will learn a lot, and expert users will learn in
</p>
<p>novel and unusual situations. When an expert sees a new type of fault or a novel
</p>
<p>combination of faults they will normally have to resort to problem solving. They
</p>
<p>have to function at Rasmussen&rsquo;s (1983) knowledge level, using knowledge in a
</p>
<p>problem solving manner, using strategies such as trial and error, for example. In
</p>
<p>the Tower of Hanoi, the user does not know the full sequence of moves, so they
</p>
<p>will have to do some problem solving. Some users will reason about the problem
</p>
<p>in their head, and consider what moves are possible and where this will take them.
</p>
<p>Other users will start by moving disks; it is a little easier to study how these users
</p>
<p>problem solve because their behavior is more visible. In both cases, their initial
</p>
<p>behavior will be slow and effortful. As they learn to do the task, however, their
</p>
<p>performance becomes faster.
</p>
<p>6.3.2 Examples of Problem Solving
</p>
<p>When you are installing software, you might know the goal state, and you might
</p>
<p>even think you know the starting state, but get into trouble because you don&rsquo;t have
</p>
<p>Fig. 6.7 The Tower of Hanoi puzzle. In this picture, two towers of disks are shown here, but
only one tower is normally used. The goal is to move a tower, disk-by-disk, to the far peg. The
tower on the left would be easier to work with because the disks are easier to tell apart than the
disks on the right, and because there are fewer disks (five vs. six). An example tower to play with
is on the book&rsquo;s web site
</p>
<p>6.3 Problem Solving 175</p>
<p/>
</div>
<div class="page"><p/>
<p>an accurate view of the actual starting state (you may have an old version installed)
</p>
<p>and you might not know the actual constraints on the installation process (e.g., you
</p>
<p>cannot install a new version correctly if the old version is still on the computer).
</p>
<p>Software can help with this, for example, noting the constraints for you.
</p>
<p>In many hardware configurations for PCs there are hidden constraints: some
</p>
<p>disks require particular drives and graphics cards may require specific pieces of
</p>
<p>software as well. These constraints are often hidden, and sometimes can only be
</p>
<p>found through applying expensive operators, that is, configuring the hardware and
</p>
<p>then testing.
</p>
<p>Problem solving is effortful and time consuming. In aviation they try to min-
</p>
<p>imize the amount of problem solving that flight crews have to perform by pro-
</p>
<p>viding a Quick Reference Handbook (QRH). This is essentially a set of procedures
</p>
<p>(checklists) that can be used to deal with known situations, both common and rare.
</p>
<p>In this way the pilots can operate at Rasmussen&rsquo;s rule-based level. In extreme
</p>
<p>situations, however, they may have to resort to problem solving. In the Sioux City
</p>
<p>air accident (NTSB 1990), for example, the aircraft lost all of its hydraulics
</p>
<p>systems whilst in the air, which basically meant that it could not be steered in the
</p>
<p>normal manner. The likelihood of such an event was so remote that there was no
</p>
<p>procedure to deal with it in the QRH, and even the aircraft manufacturer did not
</p>
<p>have a way to steer the aircraft. Fortunately there was another pilot on the aircraft
</p>
<p>who, together with the flight crew, worked out a way to steer the aircraft and get it
</p>
<p>down onto the ground.
</p>
<p>6.3.3 Known Influences on Problem Solving
</p>
<p>There are several known effects and influences on problem solving. These include
</p>
<p>ways that people like to problem solve and known ways that they are inefficient at
</p>
<p>problem solving. Knowing these effects can help build better interfaces and
</p>
<p>systems.
</p>
<p>6.3.3.1 Based on Mental Models
</p>
<p>Problem solving and decision making are thoroughly rooted in our world
</p>
<p>knowledge and world experiences. In trying to understand unfamiliar machines or
</p>
<p>unfamiliar behavior of common machines we try to construct a mental model
</p>
<p>(imagined world) in which we understand the device. This model enables us to
</p>
<p>operate the machine without having to recall what to do from memory. The
</p>
<p>correspondence between the imagined world and the real world is not important as
</p>
<p>long as the operations make sense in the imagined world, our mental model.
</p>
<p>Mental models are thus used to perform Means-Ends Analysis (MEA) when
</p>
<p>problem solving. This approach to problem solving examines the current state of
</p>
<p>the device and notices differences between it and the solution. Systems that
</p>
<p>176 6 Cognition: Mental Representations, Problem Solving, and Decision Making</p>
<p/>
</div>
<div class="page"><p/>
<p>support this type of analysis can help users. If a disk is full, the user will want to
</p>
<p>create a less full disk. What are the large files that can be deleted, or what are the
</p>
<p>files that are rarely used or that were temporary? Displays of this information
</p>
<p>provide the way for users to understand and apply operators to solve their problem.
</p>
<p>Metaphors for design exploit this process by prompting an appropriate mental
</p>
<p>model of the device. However, one needs to be careful. This type of problem
</p>
<p>solving fails when the mental model is wrong. Novice writers, for example, look at
</p>
<p>papers and notice that the paper is not long enough, and simply attempt to add
</p>
<p>more pages (this is not how good papers or textbooks are written).
</p>
<p>6.3.3.2 Avoids Apparent Backtracking
</p>
<p>Early work on problem solving found that problem solvers do not like to move
</p>
<p>away from the goal. This is sometimes called backtracking. This was found with
</p>
<p>problems like the Missionaries and Cannibals problem and the Goat, Cabbage, and
</p>
<p>Wolf problem, but occurs in many problems, and can include, for example,
</p>
<p>installing software that has to be then uninstalled to move on. These problems are
</p>
<p>shown in Table 6.2. In these problems you have to make some moves that appear
</p>
<p>to take you away from the goal. In each of these problems this means carrying
</p>
<p>something that you have already taken across the river back to the starting side.
</p>
<p>Problem solvers have particular difficulty finding and doing this move, pre-
</p>
<p>sumably because it looks like going away from the goal. These changes can be
</p>
<p>differentiated from simple undoing progress from a dead end.
</p>
<p>So, if you are building a system, you should be careful how you represent the
</p>
<p>goal and the state of the system. If an action is required that might look like it&rsquo;s
</p>
<p>going away from the goal, you might support the user by providing a display that
</p>
<p>shows that the move is in the right direction, or you might emphasize it in other
</p>
<p>ways or with other instructional materials. Or, if you are trying to make a game
</p>
<p>more difficult, you might require backtracking.
</p>
<p>6.3.3.3 Functional Fixedness, Einstellung, and Insight Problems
</p>
<p>Sometimes the ways we view objects and problems is biased by previous expe-
</p>
<p>rience. This leads to viewing objects and how to view problems not being done as
</p>
<p>well as they could be. Functional fixedness and Einstellung are two examples of
</p>
<p>this type of effect.
</p>
<p>Functional fixedness is where a person becomes fixated on a particular use of an
</p>
<p>object. Figure 6.8 provides an example. In this task, solving it requires not fixating
</p>
<p>on a common usage of the objects, and using them in a very reasonable but harder
</p>
<p>to think of way.
</p>
<p>Einstellung is related to Functional Fixedness but refers to the situation where a
</p>
<p>person gets fixated on a strategy to solve a problem. The most famous example is
</p>
<p>solving a puzzle using water jugs (Luchins 1942). In this task, people were given a
</p>
<p>6.3 Problem Solving 177</p>
<p/>
</div>
<div class="page"><p/>
<p>series of problems using water jugs. In these problems, there were three jugs and a
</p>
<p>target amount of water to get. For example, one problem was to get 3 gallons using
</p>
<p>1-, 4-, and 5-gallon buckets (fill the 4-gallon, empty into the 1-gallon, and be left
</p>
<p>with 3 gallons in the 4-gallon bucket). Over several trials they learned a strategy
</p>
<p>that worked (such as fill the first bucket, empty into the second bucket, fill the first
</p>
<p>bucket, empty into the third bucket, pour the second and third buckets together).
</p>
<p>When given a new problem that was solvable with a more efficient strategy (such
</p>
<p>as using 1-, 5-, and 7-gallon buckets, get 2 gallons by filling the 7-gallon, and
</p>
<p>emptying into the 5-gallon to get 2 gallons), they would continue to use the less
</p>
<p>efficient strategy (more pours), or if given a problem that required a different
</p>
<p>strategy, they would first try the old, unworkable strategy.
</p>
<p>Functional fixedness and Einstellung both arise when people do not make full
</p>
<p>use of their knowledge, but are influenced too much by previous successes. As you
</p>
<p>design systems you should be mindful of what previous knowledge and mental
</p>
<p>Table 6.2 Puzzles that require backtracking to solve
</p>
<p>Goat, cabbage, and wolf
</p>
<p>You have a goat, a cabbage, and a wolf that you have to carry across a river. Your boat can only
hold you and one other object. If you leave the goat with cabbage, it will eat the cabbage. If
you leave the wolf with the goat, it will eat the goat. How do you ferry them across the river
without anything getting eaten?
</p>
<p>Missionaries and cannibals
</p>
<p>There are three missionaries and three cannibals that have to cross a river. Their boat can only
hold two people. If there are more cannibals on a side of a river than missionaries, the
cannibals will eat the missionaries. How do they ferry themselves across the river without
anyone getting eaten?
</p>
<p>Fig. 6.8 You are in a room and have two strings to tie together (imagine you are MacGyver, a
US TV personality who has to solve odd problems using odd things). You have a hammer, some
tacks, a candle, and a box of matches. The two strings are too far apart for you to reach both of
them when they are hanging down, but close enough to tie together if you have each in a hand.
How do you tie them together?
</p>
<p>178 6 Cognition: Mental Representations, Problem Solving, and Decision Making</p>
<p/>
</div>
<div class="page"><p/>
<p>models they have encountered (functional fixedness) and what previous strategies
</p>
<p>they have used (Einstellung). Simply being aware that these effects can arise
</p>
<p>means that you can design systems that avoid them.
</p>
<p>Insight problems are problems where novel behavior or understanding is
</p>
<p>required. Figure 6.9 shows a typical example. Most problem solvers have trouble
</p>
<p>solving this problem the first time. Solving it requires a singular insight, in this
</p>
<p>case, that you can and have to go outside the implied box the dots make up.
</p>
<p>Similarly, the problem in Fig. 6.8 is often presented as an insight problem because
</p>
<p>the way problem solving proceeds is that you are frustrated for a while until you
</p>
<p>&lsquo;see&rsquo; the answer. While using Gimp to edit photos, for example, one of us has
</p>
<p>solved several insight problems.
</p>
<p>Insight problem solving can be seen as having several stages (Sternberg and
</p>
<p>Davidson 1995):
</p>
<p>Impasse: a point reached by an individual where they run out of ideas of operators
</p>
<p>or strategies to try that might solve the problem.
</p>
<p>Fixation: an individual repeats the same type of solution again and again, even
</p>
<p>when they sees that it does not seem to lead to a solution; they become fixated on a
</p>
<p>solution.
</p>
<p>Incubation: a pause or gap between attempts to solve a problem can sometimes appear
</p>
<p>to aid the finding of a solution, as if one is clearing one&rsquo;s mind of faulty ideas, or, as has
</p>
<p>been found, cues in the environment can help suggest solutions (Kaplan 1989).
</p>
<p>The &lsquo;Aha&rsquo; experience: the solutions to some insight problems can seem to appear
</p>
<p>from nowhere, like a Eureka moment.
</p>
<p>Unless you are providing puzzles to your user as part of a game, you generally
</p>
<p>do not want to provide them with insight problems. Insight problems are hard to
</p>
<p>solve, are characterized by a relatively long solution time per number of steps, and
</p>
<p>Fig. 6.9 Connect all the dots
with four line segments
without picking up your
pencil
</p>
<p>6.3 Problem Solving 179</p>
<p/>
</div>
<div class="page"><p/>
<p>unless you have an unusual set of users, they will not enjoy solving insight
</p>
<p>problems (although see the breakout box on &lsquo;&lsquo;Need for cognition&rsquo;&rsquo;).
</p>
<p>6.3.3.4 Post-completion Errors
</p>
<p>The post-completion error (Byrne and Bovair 1997) is an interesting and important
</p>
<p>effect between memory and problem solving. This error arises when the goal for
</p>
<p>the task has been completed but the goals for the subtasks have not. For example,
</p>
<p>when you go to an old fashioned ATM machine, you will get your money before
</p>
<p>you get your card when making a withdrawal. You are there to get the money, not
</p>
<p>to get your card back. Once you have your money, you may walk away, leaving
</p>
<p>your card behind. Newer machines return your card before dispensing your money.
</p>
<p>Figure 6.10 shows another answer, a machine that does not retain the card.
</p>
<p>Other examples of post-completion errors are available from email: when you
</p>
<p>write the email but do not send it, or when you mention an attachment but do not
</p>
<p>attach it. This error can also be seen in programming, where you allocate the
</p>
<p>memory for an array but do not release it when you have finished using it.
</p>
<p>Post-completion errors provide a few suggestions for design. They suggest that
</p>
<p>the system should discourage the user from believing that they have completed the
</p>
<p>task until all the important subparts are done, and to put the most important goal
</p>
<p>last where technology and the situation permit.
</p>
<p>Fig. 6.10 An ATM machine that helps avoid the post-completion error because it does not retain
the card. Another way is to return the card before giving money
</p>
<p>180 6 Cognition: Mental Representations, Problem Solving, and Decision Making</p>
<p/>
</div>
<div class="page"><p/>
<p>6.3.3.5 Breakout Box: Need for Cognition
</p>
<p>Many users do not want to do problem solving. They would prefer to perform the
</p>
<p>task directly. However, some users like to do problem solving; they like to think.
</p>
<p>These are people who do crosswords, solve Sudoku puzzles in meetings, like to
</p>
<p>build things, or debug systems. Cacioppo and Petty (1982), as well as previous
</p>
<p>researchers, describe this difference as a difference in the &lsquo;&lsquo;need for cognition.&rsquo;&rsquo;
</p>
<p>Users with a great need for cognition agree with statements like:
</p>
<p>I really enjoy a task that involves coming up with new solutions to problems.
</p>
<p>I would prefer a task that is intellectual, difficult, and important to one that is somewhat
important but does not require much thought.
</p>
<p>I would prefer complex to simple problems.
</p>
<p>Thus, users with a higher need for cognition will more likely find poor inter-
</p>
<p>faces a challenge rather than impossible. As you develop your system, you might
</p>
<p>consider how interested your users are in problem solving with it. While the
</p>
<p>literature on individual differences suggest that the need for cognition varies by
</p>
<p>individuals, it might also vary by task: for games, you can encourage more
</p>
<p>problem solving; for entertainment and informal use, there may be some problem
</p>
<p>solving involved; for high stake interfaces, such as health, transportation, or
</p>
<p>financial systems, most users will not want to solve problems.
</p>
<p>The need for cognition has also been used to study how people are persuaded
</p>
<p>and form opinions. Those with a high need for cognition focus on the arguments
</p>
<p>put forward. Those with a low need for cognition focus more on peripheral cues,
</p>
<p>such as body language, social status of the speaker, and fluency of the speaker.
</p>
<p>Your users may also be the judges of your system in the same way; and you may
</p>
<p>wish to make sure your system appeals to both types of users.
</p>
<p>6.3.4 Ill-Structured Problems
</p>
<p>Some problems appear harder than others. An important group of problems are
</p>
<p>more difficult because they are ill-structured. That is, they are not clearly defined.
</p>
<p>Writing, for example, is ill-structured. When you are writing the goal state is not
</p>
<p>clear&mdash;it is not clear when you are done. It is also less clear when writing what all
</p>
<p>the operators are (unless you examine everything on a character by character
</p>
<p>basis&mdash;then the problem is completely intractable!). Many aspects of design can
</p>
<p>also be seen as ill-structured problems. For example, when is the new phone or
</p>
<p>new interface finished being designed? These problems are also called ill-defined
</p>
<p>or messy problems. They often occur in the real world, and a major step forward is
</p>
<p>to make them more defined.
</p>
<p>Ill-structured problems can be ill-structured in several ways. They can have
</p>
<p>poorly defined operators or the operators can be unknown to the problem solver.
</p>
<p>6.3 Problem Solving 181</p>
<p/>
</div>
<div class="page"><p/>
<p>The Chinese Ring puzzles in Fig. 6.11 are like this. The puzzle on the top has the
</p>
<p>rings as actual rings, the puzzle on the bottom has a knob as a ring. The task is easy
</p>
<p>once you figure out what moves are possible and how close you are to the goal of
</p>
<p>removing the rings. A problem where you don&rsquo;t know or can&rsquo;t easily see the state
</p>
<p>of the system is also ill-defined. Most versions of the Chinese Ring puzzle also are
</p>
<p>difficult because you can&rsquo;t tell what the state is very easily; this is particularly true
</p>
<p>for the top puzzle in Fig. 6.11.
</p>
<p>Ill-structured problems can be difficult because you do not know what the goal
</p>
<p>is or how close you are to the goal. Knowing how close you are to a solution is a
</p>
<p>problem for both of these Chinese puzzle versions. Tetris is pretty well structured;
</p>
<p>Rubik&rsquo;s cube is well structured, but users have trouble judging the state because it
</p>
<p>is so complex. Installing software can become very ill structured quickly if the
</p>
<p>error messages are not clear. Learning where you are in Rubik&rsquo;s cube or what
</p>
<p>software is not installed and is causing the error both improve problem solving.
</p>
<p>Designers can help users with ill-structured problems in several ways. It is
</p>
<p>easier for users if the operators are clear. Thus, menus or lists of actions they can
</p>
<p>take help define the problem space. This list can also indicate what the constraints
</p>
<p>are on choosing operators. Having a clearly defined goal and good guidance
</p>
<p>towards the goal are also helpful. These distinctions can be modified or inverted
</p>
<p>for games and creative pursuits. Making problems less clear can make them more
</p>
<p>interesting and make the process of solving them a more creative experience.
</p>
<p>Fig. 6.11 The Chinese Ring puzzle. Top: classic version, provided by the Puzzle Museum (used
with permission) of a classic version. Bottom: plastic version with the same search space, and
slightly different state description and different operators (the knobs turn on a piece of plastic that
slides in a track)
</p>
<p>182 6 Cognition: Mental Representations, Problem Solving, and Decision Making</p>
<p/>
</div>
<div class="page"><p/>
<p>6.3.5 Summary of Problem Solving with Implications
</p>
<p>for System Design
</p>
<p>When you are creating systems, it is worth considering whether users will be
</p>
<p>problem solving and learning, or will they all be experts and be performing routine
</p>
<p>behavior all the time. In nearly every interface (although there are exceptions),
</p>
<p>some of the users some of the time will be problem solving. Small changes can
</p>
<p>often make it easier for them to problem solve.
</p>
<p>Users will have to resort to problem solving with systems upon occasion. To
</p>
<p>help the users, you should support them in their problem solving (unless you are
</p>
<p>building games, when you may wish to make it more difficult deliberately) by
</p>
<p>making it obvious which operations can be performed in the current context, for
</p>
<p>example.
</p>
<p>Making any aspect of problem solving more difficult will make an interface
</p>
<p>more difficult in several ways, as indicated by Table 6.3. You can make the user&rsquo;s
</p>
<p>life easier in several ways. These include making the state of the system visible,
</p>
<p>making the available operators known to the users (or enabling them to be learned
</p>
<p>easily), and having operators that can be applied physically or mentally. In some
</p>
<p>cases this may simply mean making the buttons bigger or the mouse-clickable
</p>
<p>regions easier to grab. The constraints on the application of operators should be
</p>
<p>consistent with the user&rsquo;s mental model, and the constraints should be visible or
</p>
<p>knowable. The results of applying the operators should be provided to the user.
</p>
<p>6.4 Decision Making
</p>
<p>Decision making is the result of problem solving. Where the amount of problem
</p>
<p>solving required is quite small, the problems solving and decision making may
</p>
<p>appear to blur together. Decisions can be small or quite large. They range from
</p>
<p>which button to push to which car to buy or where to land a failing airplane.
</p>
<p>Table 6.3 Problem solving requirements and several potential difficulties
</p>
<p>Starting goal state Can&rsquo;t tell if the system is at the starting state
</p>
<p>Goal state Can&rsquo;t tell directly what is a goal state
</p>
<p>Don&rsquo;t know the goal state
</p>
<p>Intermediate states Can&rsquo;t tell what state the system is in
</p>
<p>Can&rsquo;t tell distance to goal state
</p>
<p>Can&rsquo;t tell direction to goal state
</p>
<p>Operators Can&rsquo;t tell what are the operators
</p>
<p>Can&rsquo;t tell if operator had an effect
</p>
<p>Operators are difficult to perform (physically or mentally)
</p>
<p>Have to apply a lot of operators
</p>
<p>Can&rsquo;t tell which operators are safe/appropriate to use
</p>
<p>6.3 Problem Solving 183</p>
<p/>
</div>
<div class="page"><p/>
<p>They can be quite simple and isolated, or they can occur within a string of
</p>
<p>decisions, perhaps while problem solving.
</p>
<p>Decision making is studied by a wide range of disciplines, partly because there
</p>
<p>are many kinds of decisions, and partly because they affect all areas of human
</p>
<p>behavior. Interesting work on decisions are found in psychology (e.g., Gigerenzer
</p>
<p>et al. 1999; Kahneman et al. 1982; Evans 1990), business (e.g., Simon 1997),
</p>
<p>advertising (e.g., Ries and Trout 1986/2000), human factors (e.g., Cacciabue et al.
</p>
<p>1992; Hoffman et al. 1998; Lehto 1997), HCI/marketing (e.g., Fogg 2003), and
</p>
<p>economics (e.g., Levitt and Dubner 2005). Here we focus on some of the gener-
</p>
<p>alities that are applicable to designing systems.
</p>
<p>6.4.1 Decision Making is Often Not Rational
</p>
<p>One of the fundamental truths in this area, and the first to note, is that often the
</p>
<p>most rational choices to an outside observer or experimenter are not chosen.
</p>
<p>People making decisions do not always take account of a lot of potentially relevant
</p>
<p>information when making decisions, and their decision making processes have
</p>
<p>general, knowable biases. That is, there are systematic ways that decisions are
</p>
<p>badly made.
</p>
<p>Simon (1997) argues that, rather than trying to find the optimal answer, people
</p>
<p>typically satisfice. So, for example, if users were trying to find the cheapest price for
</p>
<p>something online they would choose a good enough price given the constraints of
</p>
<p>doing better which may involve looking at the price across 10 sites, rather than 500.
</p>
<p>In some sense, they are factoring in the price of further searching and the extra time
</p>
<p>needed to find a better price.
</p>
<p>There are other problems with the way that people make decisions as compared
</p>
<p>to the way computers typically make decisions. These problems can often be
</p>
<p>related back to the cognitive processing capabilities introduced in earlier chapters.
</p>
<p>The rest of this chapter describes some of these systematic limitations, starting
</p>
<p>with simple decisions (Kahneman 2013).
</p>
<p>6.4.2 Simple Decisions: Hicks Law and Speed&ndash;Accuracy
</p>
<p>Trade-Offs
</p>
<p>As noted earlier, signal detection theory provides a simple way to categorize
</p>
<p>decisions in terms of their likelihood of being correct. It is also important, how-
</p>
<p>ever, to know how long it takes to make a decision.
</p>
<p>Pressing the corresponding button when a particular light illuminates involves a
</p>
<p>simple decision. It takes around 150&ndash;400 ms, depending on factors such as the
</p>
<p>strength of the light and the distance to the button. These numbers are useful in
</p>
<p>system design, because factors such as the time to press the brake pedal in a car
</p>
<p>184 6 Cognition: Mental Representations, Problem Solving, and Decision Making</p>
<p/>
</div>
<div class="page"><p/>
<p>determines the safe following distance in driving, and the time to press a button
</p>
<p>determines useful speeds for agents in video games.
</p>
<p>The time to push a particular button also depends on the complexity of the
</p>
<p>decision. Adding more lights and buttons, for example, will make the task more
</p>
<p>difficult and will thus increase the time to perform the task.
</p>
<p>Hick&rsquo;s Law (or sometimes the Hick&ndash;Hyman Law) describes the time to make
</p>
<p>the decision in relation to the number of choices. When there are many choices the
</p>
<p>time to make a decision may be very long (e.g., deciding which car to purchase),
</p>
<p>but for simple light sets the relationship is as shown in Eq. (6.1), where the time to
</p>
<p>make a choice is related to the product of the number of available choices and a
</p>
<p>constant, b, which represents the time to make the choice and accommodates
</p>
<p>changes related to the task details. So, increasing the number of choices increases
</p>
<p>the response time, but in a logarithmic way, which means the rate of increase is
</p>
<p>slower than it would be if the relationship was linear.
</p>
<p>Time &frac14; b log2 n &thorn; 1&eth; &THORN; &eth;6:1&THORN;
</p>
<p>The equation can be extended to take account of non-equally likely choices,
</p>
<p>such as menus which include items that are rarely selected. If the choices get too
</p>
<p>large, however, or the user has to look through every item in the menu, they may
</p>
<p>have to scroll down the menu, and the relationship will become more linear with a
</p>
<p>larger constant cost per item. Where the user is a consumer, in an eCommerce
</p>
<p>situation, for example, they may not make a choice at all (Schwartz 2004).
</p>
<p>It has been argued that the law arises from a series of choices that subdivide the
</p>
<p>list in two with each decision. Having algorithmic explanations is useful because it
</p>
<p>helps apply this theory to other situations and to situate it in larger tasks.
</p>
<p>Hick&rsquo;s Law and signal detection theory (from Chap. 4) both suggest that
</p>
<p>errors and time can be traded off against each other: the so-called speed&ndash;accuracy
</p>
<p>trade-off. For any given task, the user&rsquo;s performance will often range between
</p>
<p>very careful and slow, to very fast but less accurate. Psychology researchers
</p>
<p>study both relatively accurate and relatively fast behavior, trying to find the bend
</p>
<p>in the curve shown in Fig. 6.12.
</p>
<p>When creating systems you may thus want to let users know how fast they are
</p>
<p>and how many errors they are making to let them adjust their performance (and
</p>
<p>hence change their position along the curve). For the purposes of design, though,
</p>
<p>you may want to know the time required to perform the task and what the
</p>
<p>acceptable error rates are so that you can help the user to meet these criteria.
</p>
<p>6.4.3 Stimulus&ndash;Response Compatibility for Decisions
</p>
<p>Stimulus-response compatibility, introduced earlier in this chapter, notes that
</p>
<p>responses that match stimuli are faster and more reliable. This is also true for
</p>
<p>mapping between a task and an action, and these two concepts are closely related.
</p>
<p>The classic example, perhaps, is that elevator buttons for the higher floors in a
</p>
<p>6.4 Decision Making 185</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4">http://dx.doi.org/10.1007/978-1-4471-5134-0_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4">http://dx.doi.org/10.1007/978-1-4471-5134-0_4</a></div>
</div>
<div class="page"><p/>
<p>building should be positioned above the buttons for the lower floors. Figure 6.13
</p>
<p>shows another problem in an elevator control panel. It has good S-R compatibility
</p>
<p>for the door opening and closing buttons (the open is near to the door, the close is
</p>
<p>nearer the wall). The layout of the buttons for the floors are done in a British style
</p>
<p>that may also be familiar in Canada (ground floor is where you enter, and the first
</p>
<p>floor is the floor above that), but the rooms are numbered in such a way that labels
</p>
<p>have to be attached to the panel to explain to users where they are (e.g., 200s are
</p>
<p>on the 3rd floor). This might also be the result of a cultural mismatch between an
</p>
<p>American company and a Canadian hotel, but, given the numbering scheme, one
</p>
<p>can only wonder.
</p>
<p>Time
E
</p>
<p>rr
o
rs
</p>
<p>Low speed, 
</p>
<p>Low Errors
</p>
<p>High speed, 
</p>
<p>High Errors
</p>
<p>Fig. 6.12 The speed
accuracy trade-off
</p>
<p>Fig. 6.13 An elevator that
has both good and bad SR
features. The open button is
closer to the doors (which are
to the left, not shown), but the
rooms do not map easily to
the buttons, 100-level rooms
are on floor 2, which does not
match many of the most
direct mental models, such as
100-numbered rooms being
on floor 1, or floor 3 being
above 2
</p>
<p>186 6 Cognition: Mental Representations, Problem Solving, and Decision Making</p>
<p/>
</div>
<div class="page"><p/>
<p>An old tale from Dick Pew (and documented in Norman&rsquo;s 1988 POET book) is
</p>
<p>that in a nuclear power plant the controls to raise and lower the rods were not clear,
</p>
<p>so the operators put beer taps on them to differentiate between them&mdash;with Loe-
</p>
<p>wenbrau on one (low) and Heineken on the other (high). This may be an urban
</p>
<p>myth, but it provides another clear illustration of what we mean by stimulus&ndash;
</p>
<p>response compatibility.
</p>
<p>Probably the most powerful version of compatibility is the spatial compatibility
</p>
<p>that exists in the elevator example (and in Payne&rsquo;s example in Fig. 1.1). This effect
</p>
<p>can influence computer interfaces in many other places that use spatial and met-
</p>
<p>aphorical content (e.g., that use relationships like up, down, left, right, higher,
</p>
<p>lower, more, less). Designs that violate this compatibility are likely to lead to a
</p>
<p>greater number of errors and take longer to use.
</p>
<p>Two major operating systems have both included actions that violate this
</p>
<p>principle and rightly have been criticized for doing so. The Macintosh operating
</p>
<p>system originally had users drag the floppy disc icon onto the trash can icon in
</p>
<p>order to eject the disc: users just wanted their disc back, they did not want to throw
</p>
<p>it into the trash can. Also, both Windows and the Macintosh operating systems
</p>
<p>have users press the start button to shut down the operating system.
</p>
<p>Finally, Fig. 6.14 gives an example of poor semantic mapping. OK normally
</p>
<p>means something is good. Cancel normally means stop doing something. In this
</p>
<p>example, OK means to cancel the email and cancel means do not cancel the email.
</p>
<p>A better design would be to have buttons that said &lsquo;cancel email&rsquo; and &lsquo;continue
</p>
<p>with email&rsquo;.
</p>
<p>6.4.4 Known Influences on Decision Making
</p>
<p>There are often differences between what people decide to do, and what an outside
</p>
<p>observer thinks that they rationally should decide to do. These differences are often
</p>
<p>predictable based on known biases and difficulties in reasoning. There are
</p>
<p>explanations for some of these effects showing how different assumptions by the
</p>
<p>user can lead to these effects. In other cases, these effects appear to be biases
</p>
<p>between otherwise equivalent choices, and sometimes they represent powerful
</p>
<p>tendencies that are not helpful most of the time.
</p>
<p>Understanding people&rsquo;s biases&mdash;both your own and your users&rsquo;&mdash;is important
</p>
<p>when designing software. It is important, albeit difficult, to counteract these biases
</p>
<p>when making decisions. Generally, these biases lead you to overestimate how
</p>
<p>good you are at something, and how much control you have over situations. You
</p>
<p>should design your system in such a way that it helps your users reason more
</p>
<p>accurately by highlighting information that they would otherwise naturally over-
</p>
<p>look or discount. The inherent biases described below are unique and have dif-
</p>
<p>ferent causes, although in real-world settings several may apply at once, and even
</p>
<p>combine to make reasoning more complicated.
</p>
<p>6.4 Decision Making 187</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1">http://dx.doi.org/10.1007/978-1-4471-5134-0_1</a></div>
</div>
<div class="page"><p/>
<p>6.4.4.1 Based on Mental Models
</p>
<p>Problem solving and decision making are rooted in our world knowledge and
</p>
<p>world experiences. Users employ mental models in making decisions: if the mental
</p>
<p>model is wrong, the decision is also likely to be wrong. For example, if the user
</p>
<p>thinks that one cup of coffee helps thinking, they may reason that four cups might
</p>
<p>be four times better (which it patently is not). When you watch people use com-
</p>
<p>puter systems, you can often find examples of incorrect models such as the
</p>
<p>apocryphal tale of the novice user who looks for an &lsquo;&lsquo;Any&rsquo;&rsquo; key when asked to
</p>
<p>&lsquo;&lsquo;Press any key to continue.&rsquo;&rsquo;
</p>
<p>It is important to understand how mental models develop and evolve, and how
</p>
<p>they are used, so that you can support their development, evolution, and use. The
</p>
<p>system should provide the appropriate information needed to make a decision
</p>
<p>through displays, or help, or even in the surrounding context. If the information is
</p>
<p>difficult to retrieve from memory or to manipulate mentally, you should consider
</p>
<p>how you can either avoid or at least mitigate these effects. On solution would be to
</p>
<p>remove information that does not contribute to the decision, for example
</p>
<p>(Smallman and St. John 2005).
</p>
<p>6.4.4.2 Confirmation Bias
</p>
<p>Users tend to take the line of least effort. They want to find support in the world for
</p>
<p>their actions and reasoning steps that shows they were right. They therefore look
</p>
<p>for information that confirms their understanding of the situation. The corollary of
</p>
<p>Fig. 6.14 A bad example of task-action mapping. Which button should you press to cancel the
email, and which button to cancel the canceling of the email, or to OK the sending of the email?
</p>
<p>188 6 Cognition: Mental Representations, Problem Solving, and Decision Making</p>
<p/>
</div>
<div class="page"><p/>
<p>this is that they have greater difficulty seeing things that conflict with their
</p>
<p>understanding of the world. This confirmation bias is pervasive.
</p>
<p>Confirmation bias is related to noticing the lack of objects or stimuli. We all
</p>
<p>seem to have difficulty seeing negative instances. That is, we have trouble noticing
</p>
<p>when something is not there that should be there. In software testing, for example,
</p>
<p>this can happen when a file is not written, or in project management it can happen
</p>
<p>when an email does not come from a colleague about a project update.
</p>
<p>6.4.4.3 Regression to the Mean/Sample Sizes
</p>
<p>Users tend to over-generalize. Given a single instance of a concept, they will
</p>
<p>assume that all such instances will have the same characteristics. This leads them
</p>
<p>to make assumptions that are unsupportable and which may turn out to be false.
</p>
<p>An argument can be presented as to why restaurants are not as good the second
</p>
<p>time round. On the first visit to what you perceive as a good restaurant, they may
</p>
<p>have been having a very good day, or you may have been very hungry, which
</p>
<p>made the food taste better. Thus, the results were a bit uncharacteristically good.
</p>
<p>On your second visit, they may be having an average day, or you were not as
</p>
<p>hungry. These factors will lead to more average ratings.
</p>
<p>These regression effects can be found with music on iPods by a band you are
</p>
<p>trying; they will occur when users use an application to do a task where the task
</p>
<p>types may vary, and in other situations where are you repeatedly evaluating
</p>
<p>something.
</p>
<p>6.4.4.4 Availability Bias (Representativeness)
</p>
<p>Users have an easier time remembering the first few items and the last few items in
</p>
<p>a list, as we noted when discussing memory. The primacy and recency effects
</p>
<p>apply across users. People will also remember some items such as those that stand
</p>
<p>out for a particular reason, such as being particularly anomalous, like an elephant
</p>
<p>in a list of candy bars.
</p>
<p>When users are asked to reason about and make decisions, they typically
</p>
<p>retrieve and use memories that are easy to retrieve. These memories are not
</p>
<p>necessarily representative nor do they cover the distribution of memories.
</p>
<p>It is true that users judge people and things fairly quickly. This applies in
</p>
<p>interviews and when opening a new gadget. These judgments are based on rela-
</p>
<p>tively little information, and will take longer to reverse if they are unfavorable or
</p>
<p>incorrect. These are the first memories.
</p>
<p>People also retrieve memories based on their experiences rather than the facts
</p>
<p>of the world. For example, if you ask people in America which of each of the
</p>
<p>following pairs of countries is larger by population: Ireland or Indonesia, Canada
</p>
<p>or Vietnam, Bangladesh or South Korea, and Iraq or Iran, you will often get
</p>
<p>6.4 Decision Making 189</p>
<p/>
</div>
<div class="page"><p/>
<p>astounding answers. The actual population sizes differ by a factor of at least two in
</p>
<p>all of these pairs.
</p>
<p>6.4.4.5 Framing Effects
</p>
<p>The way that outcomes are presented (framed) has a powerful influence on how
</p>
<p>users choose between alternatives. The framing effect (Tverksy and Kahneman
</p>
<p>1981, 1986) notes that decision makers are quite sensitive to the decision&rsquo;s frame
</p>
<p>of reference. Consider the choices shown in Table 6.4. Which would you choose?
</p>
<p>The most common answers are given in Exercise 6.2.
</p>
<p>Where the outcomes are noted in positive terms, lives are saved, money gained,
</p>
<p>and so on&mdash;people making decisions are risk aversive. They appear to act as if they
</p>
<p>wish to lock in their savings, choosing an outcome with certainty.
</p>
<p>Where the outcomes are noted in negative terms, lives are lost, money lost, and
</p>
<p>so on&mdash;people making decisions are risk seeking. They make decisions based on
</p>
<p>trying to avoid the loss.
</p>
<p>The choices in Table 6.4 have the same expected statistical values, but how you
</p>
<p>and your users will choose solutions will depend in some part on how the infor-
</p>
<p>mation is presented.
</p>
<p>For example, in an experiment, Kahneman gave students mugs in class. When
</p>
<p>they were asked to sell them back, they wanted $7.12 for them. When they just got
</p>
<p>to look at the mugs, and could either collect a mug or get paid, they valued the
</p>
<p>mug at $3.50. This process had the same outcomes, mug or money, but the people
</p>
<p>holding the mug valued it much higher than the people who could get the mug,
</p>
<p>showing that how information is presented and the order in which it is presented
</p>
<p>can influence cognition.
</p>
<p>This effect of order on having and valuing also plays out for users and software
</p>
<p>and software features. Losing a feature is seen by users as much more costly than
</p>
<p>not adding a feature. When a subscription to an online service is dropped it is
</p>
<p>likely to be valued higher than when adding it. This is useful to know for
</p>
<p>Table 6.4 Example problems illustrating the framing problem
</p>
<p>Assume that you are preparing a new manufacturing process that will cost $600,000 to create.
Two alternatives have been created to help save money implementing this system. Assume
that the exact scientific estimates of the alternatives are as follows
</p>
<p>Program A: $200,000 will be saved
</p>
<p>Program B: there is a 1/3 chance to save $600,000 will be saved, and a 2/3 chance that no
money will be saved
</p>
<p>Imagine that the Programs A and B are not available, but only C and D are
</p>
<p>Program C: $400,000 will still have to be spent
</p>
<p>Program D: There is a one in three chance that no money will have to be spent, and a two in
three chance that the original estimate will have to be spent
</p>
<p>190 6 Cognition: Mental Representations, Problem Solving, and Decision Making</p>
<p/>
</div>
<div class="page"><p/>
<p>marketing and for maintenance, although you are still likely to value the mug in
</p>
<p>hand more than the mug next to you.
</p>
<p>6.4.4.6 Learning and Feedback
</p>
<p>Dawes (1994) argues that decision making cannot improve without feedback. In
</p>
<p>his book, House of cards, he presents numerous examples of professionals some of
</p>
<p>whom do and some who do not get feedback about their decisions. Those that
</p>
<p>receive feedback have a chance of improving and usually do. Those that do not get
</p>
<p>feedback do not improve, although they do become more confident with practice,
</p>
<p>as they presumably get faster at it. He examines a wide range of tasks, but par-
</p>
<p>ticularly takes psychotherapists to task, as very often in the past they provided
</p>
<p>treatment without receiving feedback on the outcomes of their treatments.
</p>
<p>So, if you would like your users to improve their performance and to learn, you
</p>
<p>need to provide feedback. A failure to do so may only allow them to increase their
</p>
<p>confidence in their ability to do the task without increasing performance.
</p>
<p>6.4.5 Larger Scale Decision Making Process: Expertise
</p>
<p>and RPDM
</p>
<p>Decision making in the real world is also influenced by learning, mental models,
</p>
<p>and expertise. Work by Simon and his colleagues looked at how expertise influ-
</p>
<p>enced decision making. They showed that, in some cases, expertise led to faster
</p>
<p>decisions, but essentially the same decisions; for example, young business majors
</p>
<p>would make the same decisions for a business case, but would take longer (Simon
</p>
<p>1997).
</p>
<p>They also studied how people played chess as an analogue for other decision
</p>
<p>making tasks (Chase and Simon 1973; Gobet and Simon 1996b; Simon and Chase
</p>
<p>1973). They found good chess players would consider more reorganization of the
</p>
<p>positions and better possible moves than would novices, who would have to do
</p>
<p>more problem solving. This expertise would also allow good players to remember
</p>
<p>positions more readily because they were not remembering all the pieces indi-
</p>
<p>vidually, but recognizing groups of pieces as patterns in a way similar to how
</p>
<p>ABC, 747, and HFE (and others noted in Table 5.1) might be considered as single
</p>
<p>objects instead of three separate characters (Gobet and Simon 1996a).
</p>
<p>This approach has been implemented in computational models, including
</p>
<p>programs that solve problems (Ritter and Bibby 2008) and play chess (Gobet et al.
</p>
<p>1997). These models start out with effortful problem solving or problem solving-
</p>
<p>like behavior that, with practice, becomes faster and uses recognition to drive its
</p>
<p>behavior. Sometimes the strategy does not change with improved learning (it is
</p>
<p>just faster), and sometimes the ability to recognize what to do changes how the
</p>
<p>6.4 Decision Making 191</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5">http://dx.doi.org/10.1007/978-1-4471-5134-0_5</a></div>
</div>
<div class="page"><p/>
<p>models perform the task (Ritter et al. 1998), mirroring how behavior changes with
</p>
<p>expertise in the task (Larkin et al. 1980).
</p>
<p>Within human factors a body of work has developed that looks at decision
</p>
<p>making in the wild&mdash;naturalistic decision making&mdash;like fire-fighting, and search
</p>
<p>and rescue. Work on recognition-primed decision making (RPDM, Klein 1997),
</p>
<p>argues that experts do not do problem solving, but that they recognize the situation
</p>
<p>which directly leads them to the correct actions to take. This approach is consistent
</p>
<p>with previous work in psychology, and with Rasmussen&rsquo;s work on levels of
</p>
<p>expertise (Rasmussen 1983).
</p>
<p>The work on naturalistic decision making encourages designers to provide
</p>
<p>information to users to help them make decisions. They should also provide the
</p>
<p>information in a way that supports recognition of the correct decisions, and
</p>
<p>explicitly acknowledges that experts may move more quickly to a solution using
</p>
<p>cues that relate the current situation to previously encountered situations.
</p>
<p>6.4.6 Summary of Decision Making with Implications
</p>
<p>for System Design
</p>
<p>Many decision-support systems try to support the process of formalizing the
</p>
<p>information contributing to the solution/decision. However, human problem
</p>
<p>solving is not always based on logic and rationality in terms of using the infor-
</p>
<p>mation to the full. This makes good decision support systems helpful, but difficult
</p>
<p>to design because often the problem is not with the quality of the information
</p>
<p>being presented to users.
</p>
<p>Users do not make decisions the way you might think they will in several ways.
</p>
<p>They will take more time the more choices they have. With good design, these
</p>
<p>choices can help them and the choices can be made relatively quickly. With more
</p>
<p>choices, or worse design, the time to choose might become large. Users will be
</p>
<p>able to make more accurate and rapid choices if the choices (as described) match
</p>
<p>their mental models and the names of the tasks they are attempting to perform. So,
</p>
<p>provide time, reduce choices where appropriate, and have the choices match the
</p>
<p>mental model and terms that the user has.
</p>
<p>The decisions users make will be based on their mental models, and they will
</p>
<p>often have different mental models than you. The cognitive architecture they can
</p>
<p>bring to solve the problem will limit their ability to make rational choices. They
</p>
<p>will often make choices consistent with previous choices because these choices
</p>
<p>confirm their previous choices. They will base their decisions on what they can
</p>
<p>retrieve from memory, and what they can retrieve first and easiest from memory is
</p>
<p>not always the most useful information for making their decisions. So, if your
</p>
<p>users often have to modify their behavior, you might wish to make repetitive
</p>
<p>behavior less easy. If they choices are likely to be consistent, then options like
</p>
<p>&lsquo;&lsquo;Apply to all?&rsquo;&rsquo; are helpful.
</p>
<p>192 6 Cognition: Mental Representations, Problem Solving, and Decision Making</p>
<p/>
</div>
<div class="page"><p/>
<p>How they will make their decision will be influenced by their context and how
</p>
<p>the choices are framed. Decisions based on gains will be slightly risk-aversive;
</p>
<p>decisions to avoid a loss will lead to choosing riskier options. So be careful how
</p>
<p>you frame the options, either as a gain or a loss.
</p>
<p>If the users do not get feedback about their choices, their choice quality will
</p>
<p>remain the same, but they will become more confident in their choices. If they do
</p>
<p>get feedback, they can learn how to make decisions more accurately and quicker
</p>
<p>using a variety of knowledge sources including recognizing a situation as being
</p>
<p>like a previous situation, and also recalling a useful answer. So, provide feedback
</p>
<p>in your systems when you can.
</p>
<p>Finally, their choices can be situated within a large context, including geog-
</p>
<p>raphy and social relationships. Good designers will learn about these factors in a
</p>
<p>variety of ways. Good designs will take these multiple factors into account, and
</p>
<p>attempt to minimize the biases that will hurt the users, and take advantage of
</p>
<p>biases that can help users. The breakout box on biases in reasoning provides a set
</p>
<p>of examples applied to a simple task, and the breakout box on incompetence
</p>
<p>provides both serious and humorous insights into limitations of human reasoning.
</p>
<p>So when you can get context, use it to frame your interface&rsquo;s interactions.
</p>
<p>6.4.6.1 Breakout Box: Biases in Reasoning
</p>
<p>We can illustrate how biases affect reasoning using the classic Wason (1960)
</p>
<p>selection task. This is an example of an abstract deductive reasoning task that
</p>
<p>should be solved using rules of logic:
</p>
<p>Every card (shown in Fig. 6.15) has a letter on one side and a number on the other. Given
a set of four cards as shown below, which cards would you need to turn over in order to
prove or disprove the rule that &lsquo;&lsquo;If a card has a vowel on one side, then it has an even
number on the other side.&rsquo;&rsquo;
</p>
<p>Most people opt for the A card and the 4 card. Selecting only the A and the 4
</p>
<p>card only gathers evidence to prove the rule, however, and is an example of
</p>
<p>confirmation bias. In other words, often people only look for evidence that sup-
</p>
<p>ports (or confirms) their hypothesis. In this case, the hypothesis is the rule that they
</p>
<p>were given. The correct solution, however, is that the A card and the 7 card should
</p>
<p>be turned over. If the A card has an even number on the other side that is evidence
</p>
<p>to support the rule; if it has an odd number it disproves the rule. The 7 card has to
</p>
<p>be turned over because if it has a vowel on the other side, this also disproves the
</p>
<p>rule. The 4 card does not have to be turned over because if there is a vowel on the
</p>
<p>other side, the rule is satisfied and if there is a consonant then the rule would not
</p>
<p>apply.
</p>
<p>The way this and many problems are framed, however, has a major influence on
</p>
<p>people&rsquo;s performance. If the problem is made less abstract by using real objects
</p>
<p>that people are more likely to encounter in their daily lives, more people give the
</p>
<p>correct answer. Johnson-Laird et al. (1972), for example, framed the problem in a
</p>
<p>6.4 Decision Making 193</p>
<p/>
</div>
<div class="page"><p/>
<p>more concrete way, using sealed/unsealed envelopes (so the flap was open/closed)
</p>
<p>which had stamps of different denominations on the other side. They then asked
</p>
<p>participants to prove or disprove the rule: &lsquo;&lsquo;if an envelope is sealed then it has a 5p
</p>
<p>stamp on the other side.&rsquo;&rsquo; With a more concrete representation, 22 out of 24 people
</p>
<p>gave the correct answer. Making problems more concrete generally makes them
</p>
<p>easier.
</p>
<p>For a more detailed psychological description of the issues surrounding per-
</p>
<p>formance on various versions of the Wason reasoning task see, for example,
</p>
<p>Quinlan and Dyson (2008).
</p>
<p>6.4.6.2 Breakout Box: Why Don&rsquo;t Users Do What They Should?
</p>
<p>At this point in your reading you may have realized that users do not always do
</p>
<p>what they should, that they do not always act in their own interests. It is one thing
</p>
<p>to make mistakes, slips, and errors (covered in the chapter on errors, and which
</p>
<p>you can infer from the memory chapter); it is another to hold quite wrong beliefs
</p>
<p>continuously contradicted by the world, and to continue to perform poorly based
</p>
<p>on these beliefs. Why does this happen?
</p>
<p>Academics use other phrases, such as why smart people can be so foolish
</p>
<p>(Sternberg 2004) and how people cannot recognize their own incompetence
</p>
<p>(Dunning et al. 2003). Generally, this area can be examined as a type of meta-
</p>
<p>cognition&mdash;do you know what you know and can you judge your performance in
</p>
<p>quantitative ways (how good is it?) and qualitative ways (how is it good and how
</p>
<p>can it be improved?).
</p>
<p>Sternberg (2004) notes five factors that can lead to foolishness&mdash;poor decision
</p>
<p>making and problem solving in leaders. These are as follows: (a) Unrealistic
</p>
<p>optimism, assuming things will work out or strategies will work. (b) Egocentrism,
</p>
<p>focusing on your own goals rather than a broader set of goals. Sternberg notes
</p>
<p>cases where focusing on short-term goals hurts long-term goals, and where not
</p>
<p>looking after others leads to significant problems arising for the leader. (c) A sense
</p>
<p>of omniscience, assuming you know all you need to know to make the decision.
</p>
<p>(d) A sense of omnipotence, assuming that you are competent in one domain and
</p>
<p>thus in all, and that the plans you put into action will work. (e) A sense of
</p>
<p>A D 4 7
</p>
<p>Fig. 6.15 Which cards do
you need to turn over to
verify that if a card has a
vowel on one side then it has
an even number on the other
side? (Cards have a letter on
one side and a number on the
other)
</p>
<p>194 6 Cognition: Mental Representations, Problem Solving, and Decision Making</p>
<p/>
</div>
<div class="page"><p/>
<p>invulnerability, that plans cannot go badly wrong given the support you have.
</p>
<p>These biases in reasoning, however, are well known and occur in nearly everyone.
</p>
<p>They offer one set of reasons to explain why people are foolish at times.
</p>
<p>When they study, students can be affected by these factors, and thus users who
</p>
<p>study manuals or are learning how to use software or systems would be equally
</p>
<p>vulnerable. Typically, students think they have learned more than they have
</p>
<p>through studying (Dunning et al. 2003; Winne and Jamieson-Noel 2002). This
</p>
<p>miscalibration can be based on judgments of the wrong measures. For example,
</p>
<p>some students measure the ease of reading the material. The real test is different,
</p>
<p>however. The real test is not how fast you can read the material, but how well can
</p>
<p>you recall it and apply it. Thus, students who stop studying when they can repeat
</p>
<p>the material or who write about the material will be better calibrated than students
</p>
<p>who make this judgment on factors not related to the test.
</p>
<p>Figure 6.16 shows example results. Subjects who just took a sophomore psy-
</p>
<p>chology exam were asked how well they thought they had done. The subjects were
</p>
<p>grouped by quartiles by their exam score. The subjects who performed worst
</p>
<p>thought their scores were just above average (far left). The third quartile was
</p>
<p>relatively well calibrated in that their predictions matched their performance. The
</p>
<p>top quartile thought their performance would be a bit lower, showing modesty
</p>
<p>among the top performers.
</p>
<p>Another problem is that the poor performers simply do not know any better.
</p>
<p>They lack the knowledge to judge that their performance is inadequate. Dunning
</p>
<p>et al. (2003) call it a double curse:
</p>
<p>The skills needed to produce correct responses are virtually identical to those needed to
evaluate the accuracy of one&rsquo;s responses. The skills needed to produce logically sound
arguments, for instance, are the same skills that are necessary to recognize when a logi-
cally sound argument has been made. Thus, if people lack the skills to produce correct
answers, they are also cursed with an inability to know when their answers, or anyone
else&rsquo;s, are right or wrong. They cannot recognize their responses as mistaken, or other
people&rsquo;s responses as superior to their own. In short, incompetence means that people
cannot successfully complete the task of metacognition, which, among its many meanings,
refers to the ability to evaluate responses as correct or incorrect.
</p>
<p>Fig. 6.16 Perceived
percentile rankings for
mastery of course material
and test performance as a
function of actual
performance rank. Copied
from Dunning et al. (2003)
with permission
</p>
<p>6.4 Decision Making 195</p>
<p/>
</div>
<div class="page"><p/>
<p>Thus, it is a rare and unhappy individual who knows that their answers are
</p>
<p>inadequate. For example, the knowledge to judge whether a sentence is gram-
</p>
<p>matical, a word is correctly spelled, a diagram is well drawn, or program well
</p>
<p>written will be highly correlated with the ability to generate the correct behavior.
</p>
<p>So people who generate ungrammatical sentences or perform poorly on these other
</p>
<p>tasks are likely to be unable to know that they are ungrammatical.
</p>
<p>What does this mean for users and designing for users? It means, on average,
</p>
<p>users will think that they know more than they do. They will be overconfident
</p>
<p>when performing tasks, and they will not always use the right cues to judge their
</p>
<p>knowledge.
</p>
<p>Good design can help provide more feedback on performance, and could also
</p>
<p>provide education along the way about how to correct problems. Noting that
</p>
<p>&lsquo;&lsquo;Error 23 occurred&rsquo;&rsquo; does not help. Noting that &lsquo;&lsquo;Removing disks without un-
</p>
<p>mounting them can lead to disk errors&rsquo;&rsquo; is a step in the right direction because it
</p>
<p>provides a way for users to learn from their errors through feedback.
</p>
<p>6.5 Summary
</p>
<p>This chapter has given you a broad understanding of how users think by providing
</p>
<p>high level descriptions of user behavior. Mental models, problem solving, and
</p>
<p>decision making all depend on the simple architectural mechanisms introduced in
</p>
<p>earlier chapters. When users interact with technology they depend on the high
</p>
<p>level cognition we have described. By understanding the capabilities and limita-
</p>
<p>tions of high level cognition you should be better equipped to understand some of
</p>
<p>the ways that users can represent systems and interfaces and how they interact with
</p>
<p>and use them.
</p>
<p>Mental models are used to understand systems and to interact with systems.
</p>
<p>When the user&rsquo;s mental models are inaccurate, systems are hard to use. Designers
</p>
<p>can attempt to understand users&rsquo; initial mental models. Designers can then either
</p>
<p>design to support users with those models, or they can help educate users to
</p>
<p>acquire more appropriate mental models.
</p>
<p>Users problem solve when it is not clear what they should do next. Problem
</p>
<p>solving uses mental models, forms a basis for learning, and can be supported in a
</p>
<p>variety of ways. Systems that provide appropriate information to users can help
</p>
<p>with problem solving. When users are found to problem solve, it may be appro-
</p>
<p>priate to modify the interface to support behavior to make it include less problem
</p>
<p>solving, to provide feedback to support problem solving such as distance to the
</p>
<p>goal, or to perform the task for the user.
</p>
<p>Decision making is a more punctuated form of problem solving, made about
</p>
<p>and with systems. It is not always as accurate as outside observers would expect it
</p>
<p>to be. There are ways to support and improve decision making. Short-term, there
</p>
<p>are biases to avoid encouraging in the interface. Long term, providing feedback
</p>
<p>about past decisions and their accuracy can help users.
</p>
<p>196 6 Cognition: Mental Representations, Problem Solving, and Decision Making</p>
<p/>
</div>
<div class="page"><p/>
<p>There are surprises for designers in each of these area, where folk psychology
</p>
<p>concepts and theories are inaccurate. The most general result and the one with the
</p>
<p>largest import is that, in each of these areas, users are likely to have different mental
</p>
<p>models, different problem solving strategies, and make decisions in different ways
</p>
<p>than system designers, so designers should study the users when these aspects of
</p>
<p>behavior are important. There is a rich literature on each of these areas in psychology
</p>
<p>and other areas. When you start to design interfaces that touch on other aspects of
</p>
<p>these areas, you should have enough background to go and learn more.
</p>
<p>6.6 Other Resources
</p>
<p>A classic text on human reasoning using mental models is Philip Johnson-Laird&rsquo;s
</p>
<p>book, Mental Models:
</p>
<p>Johnson-Laird, P. N. (1989). Mental models. Cambridge, MA: The MIT Press.
</p>
<p>You will find much material online that details some of the reasoning biases we
</p>
<p>have discussed in this chapter, but it is also worth reading some of the original
</p>
<p>texts, especially those by Kahneman and Tversky:
</p>
<p>Kahneman, D. Slovic, P. and Tversky, A. eds. (1982). Judgment under uncertainty:
Heuristics and biases. Cambridge, UK: Cambridge University Press.
</p>
<p>A different approach to thinking about mental models is to think about the role
</p>
<p>of language in creating how we see the world. An interesting book to read for this
</p>
<p>approach is George Lakoff and Mark Johnson&rsquo;s 2008 book Metaphors We Live By.
</p>
<p>Lakoff, G. and Johnson, M. (2008). Metaphors we live by. Chicago, IL: University of
Chicago Press.
</p>
<p>Hayes&rsquo; (1981) book inspired parts of this book. It provides a good source for
</p>
<p>thinking about applied cognitive psychology and problem solving:
</p>
<p>Hayes, J. R. (1981). The complete problem solver. Philadelphia, PA: The Franklin Institute
Press.
</p>
<p>Another classic text is the 1972 book by Allen Newell and Herb Simon, and is
</p>
<p>worth reading for historical context as well as for their ideas about human problem
</p>
<p>solving specifically:
</p>
<p>Newell, A. and Simon, H. A. (1972). Human problem solving. Englewood Cliffs, NJ:
Prentice-Hall.
</p>
<p>The journal Psychological Science in the Public Interest publishes papers about
</p>
<p>how results in psychology have public policy implications. The series is worth
</p>
<p>reading because it examines important topics. It is available online, free, as PDF
</p>
<p>files. For example, a review paper by Dunning et al. (2004) summarizes why users
</p>
<p>are often poorly calibrated in their decision making and provides more examples
</p>
<p>6.5 Summary 197</p>
<p/>
</div>
<div class="page"><p/>
<p>and results. They have also published reviews on how to promote trust, how to
</p>
<p>improve learning in schools, and terrorism.
</p>
<p>6.7 Exercises
</p>
<p>6.1 Using a smartphone, explore it to find an ill-structured problem. This could be
</p>
<p>an application or function that has the features of an ill-structured problem.
</p>
<p>Discuss how you could improve this application, or note why the user would
</p>
<p>want it to be an ill-structured problem.
</p>
<p>6.2 Find another &lsquo;&lsquo;bias&rsquo;&rsquo; in human problem solving or in decision making with
</p>
<p>particular attention paid to business problems. You might find implications in
</p>
<p>an earlier chapter, or you might find useful information in a book or journal on
</p>
<p>decision making in business. Compare this known bias in reasoning to the list
</p>
<p>shown here. Consider which are the more important biases.
</p>
<p>6.3 Consider a web site that you know of medium complexity, such as your
</p>
<p>department&rsquo;s web site. Draw a map of it from memory (or, to be fairer, have
</p>
<p>some other people draw a map of it). Then, compare the maps with a map
</p>
<p>drawn from the web site. Compare the user&rsquo;s maps with the actual site, and
</p>
<p>draw conclusions about mental models.
</p>
<p>6.4 Have some friends choose between the choices in Table 6.4. If your friends
</p>
<p>are like Tversky and Kahneman&rsquo;s subjects (Kahneman et al. 1982), they will
</p>
<p>prefer program A over program B (72&ndash;28%) and program C over program D
</p>
<p>(22&ndash;78%).
</p>
<p>References
</p>
<p>Bibby, P. A., &amp; Payne, S. J. (1996). Instruction and practice in learning to use a device. Cognitive
Science, 20(4), 539&ndash;578.
</p>
<p>Byrne, M. D., &amp; Bovair, S. (1997). A working memory model of a common procedural error.
Cognitive Science, 21(1), 31&ndash;61.
</p>
<p>Cacciabue, P. C., Decortis, F., Drozdowicz, B., Masson, M., &amp; Nordvik, J. (1992). COSIMO: A
cognitive simulation model of human decision making and behavior in accident management
of complex plants. IEEE Transactions on Systems, Man, and Cybernetics, 22(5), 1058&ndash;1074.
</p>
<p>Cacioppo, J. T., &amp; Petty, R. E. (1982). The need for cognition. Journal of Personality and Social
Psychology, 42(1), 116&ndash;131.
</p>
<p>Carroll, J. M., &amp; Olson, J. (Eds.). (1987). Mental models in human-computer interaction:
Research issues about what the user of software knows. Washington, DC: National Academy
Press.
</p>
<p>Chase, W. G., &amp; Simon, H. A. (1973). Perception in chess. Cognitive Psychology, 4, 55&ndash;81.
Dawes, R. M. (1994). House of cards: Psychology and psychotherapy built on myth. New York,
</p>
<p>NY: The Free Press.
Dunning, D., Heath, C., &amp; Suls, J. M. (2004). Flawed self-assessment: Implications for health,
</p>
<p>education, and the workplace. Psychological Science in the Public Interest, 5(3), 69&ndash;106.
Dunning, D., Johnson, K., Ehrlinger, J., &amp; Kruger, J. (2003). Why people fail to recognize their
</p>
<p>own incompetence. Current Directions in Psychological Science, 12(3), 83&ndash;87.
</p>
<p>198 6 Cognition: Mental Representations, Problem Solving, and Decision Making</p>
<p/>
</div>
<div class="page"><p/>
<p>Evans, J. St. B. T. (1990). Biases in human reasoning. Hove, UK: Lawrence Erlbaum.
Fogg, B. J. (2003). Persuasive technology: Using computers to change what we think and do. San
</p>
<p>Francisco, CA: Morgan Kaufmann.
Gentner, D., &amp; Stevens, A. L. (Eds.). (1983). Mental models. Hillsdale, NJ: Erlbaum.
Gigerenzer, G., Todd, P. M., &amp; the ABC Research Group (1999). Simple heuristics that make us
</p>
<p>smart. New York, NY: Oxford University Press.
Gobet, F., Richman, H., Staszewski, J., &amp; Simon, H. A. (1997). Goals, representations, and
</p>
<p>strategies in a concept attainment task: The EPAM model. The Psychology of Learning and
Motivation, 37, 265&ndash;290.
</p>
<p>Gobet, F., &amp; Simon, H. A. (1996a). Templates in chess memory: A mechanism for recalling
several boards. Cognitive Psychology, 31, 1&ndash;40.
</p>
<p>Gobet, F., &amp; Simon, H. A. (1996b). The roles of recognition processes and look-ahead search in
time-constrained expert problem solving: Evidence from grandmaster level chess. Psycho-
logical Science, 7, 52&ndash;55.
</p>
<p>Hayes, J. R. (1981). The complete problem solver. Philadelphia: The Franklin Institute Press.
Hoffman, R. R., Crandall, B., &amp; Shadbolt, N. R. (1998). Use of the critical decision method to
</p>
<p>elicit expert knowledge: A case study in the methodology of cognitive task analysis. Human
Factors, 40, 254&ndash;276.
</p>
<p>Johnson-Laird, P. N. (1983). Mental models. Cambridge: Cambridge University Press.
Johnson-Laird, P. N., Legrenzi, P., &amp; Sonio Legrenzi, M. (1972). Reasoning and a sense of
</p>
<p>reality. British Journal of Psychology, 63, 395&ndash;400.
Kahneman, D. (2013). Thinking, fast and slow. New York, NY: Farrar, Straus and Giroux.
Kahneman, D., Slovic, P., &amp; Tversky, A. (Eds.). (1982). Judgment under uncertainty: Heuristics
</p>
<p>and biases. Cambridge: Cambridge, UK.
Kaplan, C. (1989). Hatching a theory of incubation: Does putting a problem aside really help? If
</p>
<p>so, why?, Carnegie-Mellon University, University Microfilms International, Catalog
#9238813.
</p>
<p>Klein, G. A. (1997). Recognition-primed decision making: Looking back, looking forward.
Hillsdale, NJ: Erlbaum.
</p>
<p>Krug, S. (2005). Don&rsquo;t make me think: A common sense approach to web usability (2nd ed.).
Berkeley, CA: New Riders Press.
</p>
<p>Larkin, J. H., McDermott, J., Simon, D. P., &amp; Simon, H. A. (1980). Expert and novice
performance in solving physics problems. Science, 208, 1335&ndash;1342.
</p>
<p>Lehto, M. R. (1997). Decision making. In G. Salvendy (Ed.), Handbook of human factors and
ergonomics (pp. 1201&ndash;1248). New York, NY: Wiley.
</p>
<p>Levitt, S., &amp; Dubner, S. J. (2005). Freakonomics: A rogue economist explores the hidden side of
everything. New York, NY: William Morrow/HarperCollins.
</p>
<p>Luchins, A. S. (1942). Mechanization in problem solving: The effect of Einstellung.
Psychological Monographs, 54(6), 1&ndash;95.
</p>
<p>Moray, N. (1996). A taxonomy and theory of mental models. In Proceedings of the Human
Factors and Ergonomics Society 40th Annual Meeting (Vol. 1, pp. 164&ndash;168).
</p>
<p>Moray, N. (1999). Mental models in theory and practice. In D. Gopher &amp; A. Koriat (Eds.),
Attention and performance XVII: Cognitive regulation of performance: Interaction of theory
</p>
<p>and application (pp. 223&ndash;258). Cambridge, MA: MIT Press.
Norman, D. A. (1983). Design rules based on analysis of human error. Communications of the
</p>
<p>ACM, 26(4), 254&ndash;258.
Norman, D. A. (1988). The psychology of everyday things. New York, NY: Basic Books.
Norman, D. A. (2013). The design of everyday things. New York, NY: Basic Books.
NTSB. (1990). Aircraft accident report. United Airlines flight 232. Mc Donnell Douglas DC-10-
</p>
<p>10. Sioux Gateway airport. Sioux City, Iowa, July 19, 1989. Washington DC: National
Transportation Safety Board.
</p>
<p>Payne, S. J. (1995). Naive judgments of stimulus-response compatibility. Human Factors, 37,
495&ndash;506.
</p>
<p>Quinlan, P., &amp; Dyson, B. (2008). Cognitive psychology. Harlow, UK: Pearson.
</p>
<p>References 199</p>
<p/>
</div>
<div class="page"><p/>
<p>Rasmussen, J. (1983). Skills, rules, knowledge: Signals, signs and symbols and other distinctions
in human performance models. IEEE Transactions: Systems, Man, and Cybernetics, SMC-13,
257&ndash;267.
</p>
<p>Revell, K. M. A., &amp; Stanton, N. A. (2012). Models of models: Filtering and bias rings in
depiction of knowledge structures and their implications for design. Ergonomics, 55(9),
1073&ndash;1092.
</p>
<p>Ries, A., &amp; Trout, J. (1986/2000). Positioning: The battle for your mind. New York, NY:
McGraw-Hill International.
</p>
<p>Ritter, F. E., &amp; Bibby, P. A. (2008). Modeling how, when, and what learning happens in a
diagrammatic reasoning task. Cognitive Science, 32, 862&ndash;892.
</p>
<p>Ritter, F. E., Jones, R. M., &amp; Baxter, G. D. (1998). Reusable models and graphical interfaces:
Realising the potential of a unified theory of cognition. In U. Schmid, J. Krems, &amp; F.
Wysotzki (Eds.), Mind modeling&mdash;a cognitive science approach to reasoning, learning and
discovery (pp. 83&ndash;109). Lengerich, Germany: Pabst Scientific Publishing.
</p>
<p>Schwartz, B. (2004). The paradox of choice: Why more is less. New York, NY: Harper Perennial.
Simon, H. A. (1997). Administrative behavior (4th ed.). New York, NY: The Free Press.
Simon, H. A., &amp; Chase, W. G. (1973). Skill in chess. American Scientist, 61, 393&ndash;403.
Smallman, H. S., &amp; St. John, M. (2005). Na&iuml;ve realism: Misplaced faith in the utility of realistic
</p>
<p>displays. Ergonomics in Design, 13(Summer), 6&ndash;13.
Sternberg, R. J. (2004). Why smart people can be so foolish. European Psychologist, 9(3),
</p>
<p>145&ndash;150.
Sternberg, R. J., &amp; Davidson, J. E. (1995). The nature of insight. Cambridge, MA: MIT Press.
Tverksy, A., &amp; Kahneman, D. (1981). The framing of decisions and the psychology of choice.
</p>
<p>Science, 211, 453&ndash;458.
Tverksy, A., &amp; Kahneman, D. (1986). Rational choice and the framing of decisions. Journal of
</p>
<p>Business, 59, 251&ndash;278.
Wason, P. C. (1960). On the failure to eliminate hypotheses in a conceptual task. Quarterly
</p>
<p>Journal of Experimental Psychology, 12, 129&ndash;140.
Wilson, J. R., &amp; Rutherford, A. (1989). Mental models: Theory and application in human factors.
</p>
<p>Human Factors, 31, 617&ndash;634.
Winne, P. H., &amp; Jamieson-Noel, D. (2002). Exploring students&rsquo; calibration of self reports about
</p>
<p>study tactics and achievement. Contemporary Educational Psychology, 27(4), 551&ndash;572.
</p>
<p>200 6 Cognition: Mental Representations, Problem Solving, and Decision Making</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 7
</p>
<p>Cognition: Human&ndash;Computer
</p>
<p>Communication
</p>
<p>Abstract This chapter addresses even higher level processes than the previous
</p>
<p>chapter. It discusses ways that users communicate with computers and other
</p>
<p>technological systems. The chapter starts by considering the role of language in
</p>
<p>communication and how the ideas can be applied to interface design. It then looks
</p>
<p>at factors that affect how users read both offline and online, and discusses the task
</p>
<p>of reading of menus. After considering the topic of information seeking behavior
</p>
<p>and the more general concept of how content is structured, this chapter looks at
</p>
<p>the broader implications for designing an interface that appropriately supports
</p>
<p>human&ndash;computer communication.
</p>
<p>7.1 Introduction
</p>
<p>Communication is a rich and complex area. When users communicate with each
</p>
<p>other and work together they need to coordinate their processes and manage the
</p>
<p>content that they are using. They rely on establishing a shared understanding or
</p>
<p>&lsquo;&lsquo;common ground&rsquo;&rsquo;, (Clark and Brennan 1991), based on knowledge, beliefs, and
</p>
<p>assumptions shared between the two people in the conversation. To stay coordi-
</p>
<p>nated, both parties must make sure that they maintain their common ground in
</p>
<p>order to collaborate effectively.
</p>
<p>In a similar way, when users work with computers, they also need to commu-
</p>
<p>nicate with the computer to get the computer to do what they want it to do. This may
</p>
<p>be as simple as entering some data, then pressing a key or button, and waiting for a
</p>
<p>result. As they wait for the results, though, it is useful to know what the computer is
</p>
<p>doing (how much of the task it has completed, for example). Results should also be
</p>
<p>delivered in an appropriate and comprehensible format. When designing a system
</p>
<p>you need to be aware of this communication process, and the fact that it is important
</p>
<p>to keep the user aware of what the computer is doing, and this maintain common
</p>
<p>ground between the user and the computer. Although common ground may not be
</p>
<p>explicitly observable, it will still exist and evolve as communication happens.
</p>
<p>F. E. Ritter et al., Foundations for Designing User-Centered Systems,
DOI: 10.1007/978-1-4471-5134-0_7, ï¿½ Springer-Verlag London 2014
</p>
<p>201</p>
<p/>
</div>
<div class="page"><p/>
<p>We focus here on the most important aspects of human&ndash;computer communi-
</p>
<p>cation. First, we provide a very brief overview of language. After discussing how
</p>
<p>to organize information, we then address the topic of reading&mdash;one of the most
</p>
<p>common tasks for users&mdash;before discussing menu scanning, which is really a
</p>
<p>stylized form of reading. We next consider information searching, which can also
</p>
<p>be regarded as a type of communication. Information searching can also be seen as
</p>
<p>a high level type of problem solving, because it is normally highly dependent on
</p>
<p>language; this is why we have included it in this chapter. Finally, we consider how
</p>
<p>content is organized in a more general way.
</p>
<p>7.2 Language
</p>
<p>There is some debate over what constitutes language. Some people argue that
</p>
<p>animals use language to communicate. Others, however, argue that humans are the
</p>
<p>only species that have language. What makes human language unique is that
</p>
<p>speakers can generate an infinite set of utterances from a finite set of language
</p>
<p>elements. Language allows us to refer to other objects symbolically, and to
</p>
<p>communicate concrete and abstract ideas.
</p>
<p>There are many sciences that study language, including psychology, linguistics,
</p>
<p>communication science, and computer science.We focus here on some of the results
</p>
<p>that are most directly related to providing and supporting human&ndash;computer com-
</p>
<p>munication. These results provide direct suggestions for how to construct interfaces,
</p>
<p>and will help ground further learning about language. First we introduce some basic
</p>
<p>concepts before describing Grice&rsquo;s maxims, which provide a way to view language.
</p>
<p>7.2.1 Symbols, Syntax, and Semantics
</p>
<p>Three high-level language concepts that are particularly useful are symbolism,
</p>
<p>syntax, and semantics. A symbol is a token or object that can be used to represent
</p>
<p>another object, token, or relationship. Words are symbolic in that they represent
</p>
<p>other things. Language uses symbols, as do nearly all interfaces. Keyboards use
</p>
<p>characters, dialogue boxes and menus use words. The Theremin, shown sche-
</p>
<p>matically in Fig. 7.1, is an early example of an electronic musical instrument. It is
</p>
<p>a relatively rare example of a system that does not use symbols because it plays
</p>
<p>continuous notes with continuous volume.1 To generate notes the Theremin senses
</p>
<p>the positions of the user&rsquo;s hands and uses that information to create sounds. Mouse
</p>
<p>movements might also not involve symbols, but their clicks generate symbols.
</p>
<p>1 If you want to know what one sounds like, listen to &lsquo;&lsquo;Good Vibrations&rsquo;&rsquo; by the Beach Boys.
You might also recognize its sound in sci-fi movies.
</p>
<p>202 7 Cognition: Human&ndash;Computer Communication</p>
<p/>
</div>
<div class="page"><p/>
<p>Language relies on both syntax and semantics, as do interfaces. Syntax refers to
</p>
<p>how words are organized to create meaning. The order in which objects are chosen
</p>
<p>and the order of interaction are both questions of syntax. Is it better to select an
</p>
<p>object (a noun) and then an action to apply to it (a verb)? Or is it better to select an
</p>
<p>action and then the object? Some systems use the noun&ndash;verb syntax, whilst others
</p>
<p>use the verb&ndash;noun syntax. The Macintosh OS has you select a file and then choose
</p>
<p>to compress it or duplicate it. Eudora and Gmail, two commonly used email
</p>
<p>interfaces, have you select that you wish to attach a file to an email, and then
</p>
<p>choose the file.
</p>
<p>Semantics refers to the meaning of words and symbols. How symbols are used in
</p>
<p>an interface is a question of semantics. The choice of type of symbols to use in an
</p>
<p>interface&mdash;usually words or icons&mdash;depends on their semantics. This is often a very
</p>
<p>difficult choice to make. The meaning that users ascribe to a particular word or the
</p>
<p>word that they first associate with an action is not uniform. Furnas et al. (1987), for
</p>
<p>example, found that there was a wide variability in the words users choose when
</p>
<p>asked to name actions: the users agreed on the same term for an action less than 20%
</p>
<p>of the time. The results suggest that designers should not just use the first word they
</p>
<p>think of, and that they should also support the use of aliases to help match the user&rsquo;s
</p>
<p>terms. (See Glushko 2013 and Kernighan and Plauger 1978 for more concrete
</p>
<p>suggestions.)
</p>
<p>7.2.2 Grice&rsquo;s Maxims of Conversation
</p>
<p>People routinely use language to converse and interact. Grice (1975) proposed that
</p>
<p>the way that they interact with one another can be described by the co-operative
</p>
<p>principle:
</p>
<p>Volume Pitch
</p>
<p>Hand Hand
</p>
<p>Fig. 7.1 A diagram of a Theremin. Users play it by moving one hand closer to or farther away
from the volume control and the other hand closer to or farther away from the pitch control. The
distance is measured through capacitance. There are no fixed volumes or pitches, unlike most
other instruments. It is sometimes used to make eerie sounds in science fiction movies
</p>
<p>7.2 Language 203</p>
<p/>
</div>
<div class="page"><p/>
<p>Make your conversational contribution such as is required, at the stage at which it occurs,
by the accepted purpose or direction of the talk exchange in which you are engaged. (p. 45)
</p>
<p>Although phrased prescriptively&mdash;it basically says try to say the right thing at
</p>
<p>the right time&mdash;the co-operative principle can also be seen as a description of the
</p>
<p>way that people normally converse. Grice suggested that there are four basic
</p>
<p>maxims underlying the co-operative principle as shown in Table 7.1. These
</p>
<p>maxims make strong suggestions about how people should communicate with
</p>
<p>other people. When these suggestions are followed, communication is more suc-
</p>
<p>cessful and more satisfying. When these maxims are not followed, you can often
</p>
<p>note humor, irony, mistakes, rudeness, and ill-feelings. As you read through these
</p>
<p>maxims, you should be able to think of examples (and counterexamples) of their
</p>
<p>use in interfaces.
</p>
<p>Although these maxims refer to conversation, they can also be applied to facil-
</p>
<p>itate better written communication as well. Help messages, manuals, and instruc-
</p>
<p>tions should be informative, and avoid telling the user things that they do not need to
</p>
<p>know. The system should not report errors where errors do not exist. Help from
</p>
<p>automatic aids should be relevant to the task the user is doing, not to another task or
</p>
<p>to a task that has already been completed. One of the exercises at the end of this
</p>
<p>chapter encourages you to consider the application of these principles in more depth.
</p>
<p>7.2.3 Implications for System Design
</p>
<p>The use of language is an important topic for interface design, because interfaces
</p>
<p>often provide a language&mdash;possibly an informal, specialized language&mdash;for com-
</p>
<p>munication. This language provides a way to understand the interaction elements
</p>
<p>and their structure, how users interact with the system, and how interfaces can be
</p>
<p>Table 7.1 Several of Grice&rsquo;s (1975) maxims of conversation
</p>
<p>Consider saving some examples as they come up
</p>
<p>Maxim of quantity
</p>
<p>Make your contribution as informative as is required (for the current purposes of the exchange)
</p>
<p>Do not make your contribution more informative than is required
</p>
<p>Maxim of quality
</p>
<p>Do not say what you believe to be false
</p>
<p>Do not say that for which you lack adequate evidence
</p>
<p>Maxim of relevance
</p>
<p>Be relevant
</p>
<p>Maxim of manner
</p>
<p>Avoid obscurity of expression
</p>
<p>Avoid ambiguity
</p>
<p>Be brief (avoid unnecessary prolixity)
</p>
<p>Be orderly
</p>
<p>204 7 Cognition: Human&ndash;Computer Communication</p>
<p/>
</div>
<div class="page"><p/>
<p>related to other knowledge structures. By considering the interaction between the
</p>
<p>human and the computer as a sort of conversation, you can use Grice&rsquo;s maxims to
</p>
<p>help optimize the interaction.
</p>
<p>7.3 How Users Read
</p>
<p>One of the most common activities users do is reading. They read pre-printed
</p>
<p>matter such as manuals and the documents that they print out. Increasingly
</p>
<p>material is read on devices screens like monitors, laptops, tablets and smartphones.
</p>
<p>Understanding how users read will help you design interfaces that are better suited
</p>
<p>to the way people read and work.
</p>
<p>We know enough about how people read (e.g., Just and Carpenter 1987; Rayner
</p>
<p>and Pollatsek 1989) to be able to develop computational models of the process (Just
</p>
<p>and Thibadeau 1984). The research in this area has identified several regularities of
</p>
<p>reading behavior that are useful for designing interfaces where written text is used.
</p>
<p>For example, we know that people typically read at a rate of about 150&ndash;230 words
</p>
<p>per minute when reading for comprehension, and that this rate varies with material
</p>
<p>and task. At this rate, it should take 2&ndash;3 min to read anA4 or 8.500 9 1100 page of text.
</p>
<p>Perhaps the three most important regularities of reading behavior, though, are the
</p>
<p>word length effect, the word frequency effect, and the difference in time between
</p>
<p>picture naming and reading. The word length effect arises out of the fact that longer
</p>
<p>words simply take longer to read (e.g., Rayner et al. 2011). Words like &lsquo;&lsquo;mouse&rsquo;&rsquo; and
</p>
<p>&lsquo;&lsquo;polo&rsquo;&rsquo; are faster to read (everything else being equal) than &lsquo;&lsquo;keyboard&rsquo;&rsquo; and
</p>
<p>&lsquo;&lsquo;autocratic&rsquo;&rsquo; because they are shorter.
</p>
<p>The word frequency effect arises because words that are commonly used are
</p>
<p>faster to read than words that are less commonly used (e.g., Liversedge et al. 2011;
</p>
<p>Rayner 1998). This effect can be seen as being related to the learning curve. The
</p>
<p>word frequency effect and the word length effect are independent, so they both
</p>
<p>apply to the same word. So, for example, while the word &lsquo;&lsquo;polo&rsquo;&rsquo; is short, it is also
</p>
<p>relatively rarely used and hence will take longer to read than other more frequently
</p>
<p>used words of the same length. It will, however, be read more quickly than equally
</p>
<p>rare words that are longer.
</p>
<p>Reading takes less time than picture naming (Chilton 1996). This explains why
</p>
<p>unfamiliar icons, which are accessed through picture naming, take longer to
</p>
<p>process than words that are used in the same place. Using icons instead of words
</p>
<p>for simple searching makes things slower. There is a trade-off, however, against
</p>
<p>generality and esthetics. An icon, once learned, is easier to recognize than a word
</p>
<p>irrespective of one&rsquo;s native language and literacy level. Icons are often created to
</p>
<p>be rectangular in shape, for example, and having consistent, regular shaped objects
</p>
<p>can make for a better, clearer design.
</p>
<p>There are other effects as well that influence reading speed. Several known
</p>
<p>factors that make reading more difficult are noted in Table 7.2, and some of these
</p>
<p>effects are illustrated in Tables 7.3 and 7.4.
</p>
<p>7.2 Language 205</p>
<p/>
</div>
<div class="page"><p/>
<p>Table 7.2 Factors that make reading more difficult
</p>
<p>Complex (such as Gothic fonts) or uncommon fonts, such as novelty fonts (wild west-like). They
are harder to read if they are unfamiliar or perceptually complex
</p>
<p>Fonts that have more detail than the display can provide, e.g., a small, serifed font on a mobile
device. They are harder to read if necessary details are not visible
</p>
<p>Long lines that make it difficult for the eye to jump back to the beginning of the next line. They
are harder to read because the eye has trouble jumping that far that precisely
</p>
<p>Small line spacing (spacing between lines). This also makes it more difficult for the reader&rsquo;s eye
to find the beginning of the next line. They are harder to read because the target line to jump
to is smaller
</p>
<p>Smaller fonts. They are harder to read because they are harder to perceive, and often come with
long lines and small line spacing
</p>
<p>Poor spacing between words. This makes reading harder because the eye cannot see words as
being distinct, and when it has to jump back the targets are not as clear
</p>
<p>Incorrect spelling. This is harder to read because the reader may use the wrong word, or take
longer to recognize the correct word
</p>
<p>Fully justified text (that is, even on the right and left edges versus natural spacing, flush on the left
but with a ragged right margin). This is harder to read because it causes uneven and too large
spaces between words
</p>
<p>The use of all upper case letters. These are harder to read because the reader will have less
practice recognizing the letters and words, and it will also influence line spacing
</p>
<p>Ambiguous and distal references, and pronouns (the use of &lsquo;it&rsquo; and &lsquo;that&rsquo;, vs nouns and proper
nouns). These are harder to read because the referent to the pronoun must be found and used
correctly
</p>
<p>Abstract words (vs concrete words). These are harder to read because the words are less common
and require more processing to understand
</p>
<p>Poor grammar. This is harder to read because the concepts&rsquo; relations may not be well specified
</p>
<p>Negative and double negative concepts (which can be particularly difficult to understand). These
are harder to read because more processing is required to understand them
</p>
<p>Table 7.3 Hard to read text. The following text contains examples of the factors that make
reading more difficult as listed in Table 7.2
</p>
<p>6 DOZEN, 12, AND SIX HALVES OF YEARS AGO OUR OWN PARENT'S GENETIC ORGINITORS PRODUCED HEREFORTH ON THIS 
COLLECTION OF TECTONIC PLATES A NOT OLD SOCIAL-POLITICAL ORGANIZATION, CO-NCEIVED IN LIBERTY AND AIMED 
TOWARD THE FACT TAHT ALL HUMANOIDS ARE CREATED EQUIVALENT. AT THIS POINT IN TIME WE ARE MORE THAN 
STARTED IN A PH-ENOMENAL CONFLAGRATION, TESTING AND VALIDATING WHETHER THE FACT THAT THAT OR-
GANIZATION OR ANY ORGANIZATION SO CONCEIVED AND SEW DEDICATED CAN WILL NOT FAIL SOON. WE ARE MET ON A
GREAT SPATIAL-TEMPORAL LOCATION OF THAT SPECIFIC LACK OF AMICABLE RELATIONS BETWEEN TO SOCIAL-
CULTURAL-PO-LITICAL ENTITIES.  WE HAVE COME IN ORDER TO DEDICATE A PROPER SUBSET OF THAT SPATIAL-
TEMPORAL LOCATION AS A FINAL RESTING-LOCATION FOUR THOSE WHO HERE GAVE THAT, THAT IT MIGHT PROGRESS. IT 
IS ALTOGETHER APPROPRIATE AND PROPER THAT WE SHOULD DO SOMETHING LIKE THIS. BUT IN A LARGER DE-
NOTATION, WE CAN NOT APPORTION, WE CANNOT MEMORIALISE, WE CANNOT HALLOW THIS.  
</p>
<p>THEY,  LIVING AND DEAD WHO STRUGGLED HERE HAVE BLESSED IT  FAR ABOVE OUR OWN IMPOVERISHED POWER FOR 
</p>
<p>ADDITON OR SUBBSTRACTION FROM THEIR OUVRE.  THE  TEMPORAL REALM WILL LITTLE NOTE NOR LONG REM-EMBER  
</p>
<p>WHAT     OUR OWN OPIONS PRESENTED HERE, BUT IT CAN NEVER FORGET WHAT THEY DIDIN THIS SPATIAL-TEMPORAL 
</p>
<p>LOCATION. IT IS  FOR US THE NOT YET DEAD  RATHER TO BE DED-ICATED HERE TO THE  UNFINISHED WORK WHICH 
</p>
<p>THEY WHO FOUGHT HERE HAVE THUS  FAR  SO NOBLY ADVANCED. IT IS RATHER FOR US TO BE HERE DE-DICATED TO
</p>
<p>THE NOT SMALL TASK REMAINING BEFORE US--THAT FROM THESE HONORED PEOPLE WE TAKE INCREASED CARE AND 
</p>
<p>CONCERN TO THAT CAUSE FOR WHICH THEY GAVE THE LAST FULL MEASURE   OF DEVOTION--THAT WE HERE HIGHLY 
</p>
<p>RESOLVE THAT THESE DEAD   MEN SHALL NOT HAVE DIED IN VAIN, THAT THIS AREA UNDER GOD  SHALL HAVE A NEW 
</p>
<p>BIRTH OF FREEDOM, AND THAT SOCIAL ORGANI ZATIONS RELATED TO POLITICAL STATES  OF, BY, AND FOR US ALL 
</p>
<p>SHALL NOT SEASE TO EXIST ON THIS RO-TATING CELSTIAL ORB.
</p>
<p>206 7 Cognition: Human&ndash;Computer Communication</p>
<p/>
</div>
<div class="page"><p/>
<p>7.3.1 The Effects of Fonts
</p>
<p>Reading also interacts with the choice of fonts. Figure 7.2 shows a menu from a
</p>
<p>web site (it is the links section on the left hand side of the page, a common design),
</p>
<p>where every item is in a different font, and one item even has different colors for
</p>
<p>each letter. While there may sometimes be good esthetic reasons for using several
</p>
<p>different fonts, that we do not think apply in this case, here it makes it harder to
</p>
<p>read the text in the interface. A good rule of is to use no more than three different
</p>
<p>fonts. If you are planning to use several different fonts, you should make sure that
</p>
<p>you have a very good reason for doing so.
</p>
<p>As another example of the significant effect of the use of fonts, Fig. 7.3 shows the
</p>
<p>Clearview (also referred to as Clearview Hwy) font (www.clearviewhwy.com).
</p>
<p>This font was designed to aid readability and legibility for older drivers and has
</p>
<p>been evaluated (Garvey et al. 1998). The design addressed each attribute of let-
</p>
<p>terforms including stroke width, letter shape, the resulting inside and outside of each
</p>
<p>letterform, and the proportional relationship of capital letter to lower case as well as
</p>
<p>letter spacing to optimize readability when viewed at a distance. It illustrates how
</p>
<p>the readability of fonts can differ. Research at Penn State has shown that the
</p>
<p>improved font is 20% easier to read, which means that drivers at 60 mph (miles per
</p>
<p>hour) can read the road signs 1&ndash;2 s earlier, which gives them more time to make
</p>
<p>decisions or to read more of the sign. Another major effect&mdash;not shown here&mdash;is
</p>
<p>that the font also works better at night, when the light used to read signs comes from
</p>
<p>reflected headlights, which changes the contrast between the letters and background
</p>
<p>(Garvey et al. 1998). Note, however, that the font works less well on negative
</p>
<p>contrast road signs (dark text on a light background).
</p>
<p>Table 7.4 Easier to read text. This is semantically the same text as in Table 7.3 but with most of
the features that cause reading difficulties eliminated, and with the paragraphs indented
</p>
<p>Fourscore and seven years ago our fathers brought forth on this continent a new nation, conceived
in liberty and dedicated to the proposition that all men are created equal. Now we are engaged
in a great civil war, testing whether that nation or any nation so conceived and so dedicated
can long endure
</p>
<p>We are met on a great battlefield of that war. We have come to dedicate a portion of that field as a
final resting-place for those who here gave their lives that that nation might live. It is
altogether fitting and proper that we should do this. But in a larger sense, we cannot dedicate,
we cannot consecrate, we cannot hallow this ground. The brave men, living and dead who
struggled here have consecrated it far above our poor power to add or detract
</p>
<p>The world will little note nor long remember what we say here, but it can never forget what they
did here. It is for us the living rather to be dedicated here to the unfinished work which they
who fought here have thus far so nobly advanced. It is rather for us to be here dedicated to the
great task remaining before us&ndash;that from these honored dead we take increased devotion to
that cause for which they gave the last full measure of devotion&ndash;that we here highly resolve
that these dead shall not have died in vain, that this nation under God shall have a new birth of
freedom, and that government of the people, by the people, for the people shall not perish
from the earth. &mdash;A. Lincoln, 1864
</p>
<p>7.3 How Users Read 207</p>
<p/>
<div class="annotation"><a href="http://www.clearviewhwy.com">http://www.clearviewhwy.com</a></div>
</div>
<div class="page"><p/>
<p>7.3.2 Graphic Design to Help Reading and Scanning
</p>
<p>The graphic design of textual material has evolved to support readers and the tasks
</p>
<p>they perform. Readers not only read&mdash;they also annotate, reread, search using the
</p>
<p>table of contents, headings, and the index, and refer to the references cited for
</p>
<p>further information. Specific graphic design elements have been created to support
</p>
<p>these activities, such as margins, headings, and citations. More information is
</p>
<p>available from graphic design books (Parker 2006; White 2002). If you are
</p>
<p>designing something for readers, like a book, or a brochure, or even technical
</p>
<p>reports, you should become a student of the tools, designs, and processes in this
</p>
<p>area as well as understanding how reading occurs in a variety of formats such as
</p>
<p>brochures and screens.
</p>
<p>7.3.3 Paper-Based Versus Screen-Based Reading
</p>
<p>Reading text on paper is not identical to reading the same text from a screen. There
</p>
<p>are some important differences that you need to be aware of because they can
</p>
<p>affect reading speeds and comprehension. Figure 7.4 shows an example of
</p>
<p>extensive material to read from the screen.
</p>
<p>Fig. 7.2 An example use of
multiple fonts that makes the
menu structure harder to read.
(taken from www.
woodburyskiarea.com/winter,
February 2012)
</p>
<p>208 7 Cognition: Human&ndash;Computer Communication</p>
<p/>
<div class="annotation"><a href="http://www.woodburyskiarea.com/winter">http://www.woodburyskiarea.com/winter</a></div>
<div class="annotation"><a href="http://www.woodburyskiarea.com/winter">http://www.woodburyskiarea.com/winter</a></div>
</div>
<div class="page"><p/>
<p>Fig. 7.3 The previous standard font, Highway Gothic (left) and in the ClearviewHwy font
(right). These signs are on I-78, near Allentown, PA. The Clearview has larger holes in letters like
e and o, and slightly more readable serifs on letters like l and t. The text is particularly more
readable at night when illuminated by headlights. (Photos ï¿½ Don Meeker and used with
permission)
</p>
<p>Fig. 7.4 A screen shot from Feb. 2008 that would be difficult to read because of font size and
line width. Indeed, if passengers did read this screen, it would greatly slow the check-in process,
which runs counter to the purpose of the kiosk, which is to make check-in faster (as opposed to
safer or more pleasurable). This page also shows a change in the service as a system moves
online. The original system, human check-in, did not pass as much information to users&mdash;but
perhaps it did not need to
</p>
<p>7.3 How Users Read 209</p>
<p/>
</div>
<div class="page"><p/>
<p>When reading text on paper, the print quality is usually quite high, often as high
</p>
<p>as 1,000 dpi (dots per inch) for a high-end or photo-quality printer, and usually at
</p>
<p>least 600 dpi for most laser and inkjet printers, with the light used to read it being
</p>
<p>reflected from the paper. When you read text from a screen, however, the reso-
</p>
<p>lution is typically much lower (at best, most laptops and display screens use not
</p>
<p>much more than 250 dpi), and the light to read comes from the display. Greater
</p>
<p>resolution of the text generally leads to faster, less fatiguing reading. Reflective
</p>
<p>light using printed inks generally provides greater contrast between light and dark
</p>
<p>than do luminance changes from a screen. So reflected light also tends to lead to
</p>
<p>faster, less fatiguing reading.
</p>
<p>Reading from the screen is generally slower, more error prone, and more
</p>
<p>fatiguing than reading from hardcopies. Researchers have frequently found that
</p>
<p>reading from the screen is 10&ndash;30% slower, with similar results reported for errors
</p>
<p>and for fatigue (Dillon 1992; Gould et al. 1987; Kurniawan and Zaphiris 2001). It
</p>
<p>is hard to ascribe the difference between these factors solely to the resolution and
</p>
<p>luminance sources. Some think there are other causes as well, such as the func-
</p>
<p>tionality of page turning and other aspects related to the text being on paper or on a
</p>
<p>screen (Dillon 1992).
</p>
<p>7.3.4 Scanning Displays and Menus
</p>
<p>Users typically scan displays, rather than read them, particularly for menus and
</p>
<p>web pages with links. This is an important skill related to reading. If you observe
</p>
<p>someone using a web page, particularly a complicated one, you should be able to
</p>
<p>observe this scanning behavior. Most (although perhaps not all) will not read every
</p>
<p>item on the page, but will scan the page, looking for, and being susceptible to, the
</p>
<p>visual factors explained in the chapter on vision.
</p>
<p>This scanning behavior is also seen when users read menus. Hornof and Kieras
</p>
<p>(1997) found that longer menus take about 120 ms/item longer to use. They also
</p>
<p>found that users read more than one menu item at a time. The physiological
</p>
<p>structure of the eye allows two items to be read within a single fixation. As users
</p>
<p>read, they scan menus in both systematic and random ways: they are systematic in
</p>
<p>that they mostly read top to bottom; they also sometimes randomly skip around the
</p>
<p>items on the menu.
</p>
<p>Further details of human behavior in this area and models to predict behavior in
</p>
<p>menu reading are available (Byrne 2001; Hornof and Halverson 2003; Rieman
</p>
<p>et al. 1996). The models can help explain parts of behavior in this area that are
</p>
<p>predictable (e.g., walking through the menu items) although the reasons for the
</p>
<p>random skipping around menu items are not yet well explained. Figure 7.5 shows
</p>
<p>two menus for a VPN client. The first menu has many more items than the second.
</p>
<p>If the targets are ISPtoPSU and ITS Wireless at University Park, the first menu
</p>
<p>definitely makes the items take longer to find.
</p>
<p>210 7 Cognition: Human&ndash;Computer Communication</p>
<p/>
</div>
<div class="page"><p/>
<p>7.3.5 Implications for System Design
</p>
<p>When you design menus, you need to understand how vision works and how users
</p>
<p>scan menus, so that you can use this knowledge to help guide their vision to find the
</p>
<p>items they are looking for. When you create a menu, include items that are nec-
</p>
<p>essary, and be wary about creating menus that are too long. Submenus should be
</p>
<p>structured around how the user represents the world (their mental model) or how
</p>
<p>experts represent the world. You can find out how their world is structured by asking
</p>
<p>them or using a card sorting method (noted in Exercise 7.2). Menus structured in
</p>
<p>these ways are more likely to be useful than those which reflect the company&rsquo;s
</p>
<p>organization, for example. Long menus will be skimmed, but short menus with
</p>
<p>submenus will require the user to take more actions to find the same item. The final
</p>
<p>choice in these design cases requires understanding the social context and more
</p>
<p>detailed knowledge about how often the tasks are performed. You can favor more
</p>
<p>common tasks using a variety of designs including split menus (Sears and
</p>
<p>Shneiderman 1994).
</p>
<p>When choosing menu items and button labels, or writing text to be displayed on
</p>
<p>a screen, it is important to consider the factors that influence readability and,
</p>
<p>hence, usability. These factors range from choices related to fonts (typeface, size,
</p>
<p>and so on) through to words (which words and how they should be laid out) and
</p>
<p>the context in which they will appear. There are inherent trade-offs between these
</p>
<p>different factors, and the results from research will tell you which is faster. They
</p>
<p>will not tell you, however, if the changes are worth the accompanying differences
</p>
<p>in estheticsor in the information, style, and tone.
</p>
<p>Fig. 7.5 The original menu for selecting a VPN client at Penn State, and a revised version
created by Ritter for his own use. The version on the left encourages scanning; the version on the
right is more easily read. Simon Robbie notes (personal communication) that hierarchical menus
could be particularly useful here. (Screenshot taken June 2009)
</p>
<p>7.3 How Users Read 211</p>
<p/>
</div>
<div class="page"><p/>
<p>7.4 Information Seeking Behavior
</p>
<p>The other main area where human&ndash;computer communication has made significant
</p>
<p>contributions is where users are seeking information. This can be regarded as an
</p>
<p>information retrieval problem&mdash;finding the information&mdash;but we consider human
</p>
<p>information behavior to be slightly broader. Here we focus mostly on the ubiquitous
</p>
<p>task of searching for information on the web, but the concepts we discuss can be
</p>
<p>generalized to other tasks, such as searching for information on a hard drive (which
</p>
<p>routinely have capacities of over 1 TB nowadays) and in help systems and intranets.
</p>
<p>7.4.1 Information
</p>
<p>Information appears to many to be an elusive concept that is hard to define but, like
</p>
<p>the Supreme Court justice said, &lsquo;&lsquo;&hellip;we know it when we see it.&rsquo;&rsquo; In general, though,
</p>
<p>information can be thought of as organized data. The extension of this is that
</p>
<p>knowledge and, ultimately, wisdom can be considered as organized information. It is
</p>
<p>also important to take into consideration the need for an entity to process the
</p>
<p>information, and the context, which can influence how the information is interpreted.
</p>
<p>7.4.2 Human Information Behavior
</p>
<p>Human information behavior is working with information. The ways that people
</p>
<p>work with information depends on several factors including the context in which
</p>
<p>they interact with information, which is sometime described as an information
</p>
<p>journey (Blandford and Attfield 2010).
</p>
<p>Broadly defined, human information behavior includes problem solving, but a
</p>
<p>more typical task is searching for information. Human information behavior thus
</p>
<p>includes how users process, use, and produce information. How users interact to
</p>
<p>get information, and their strategies and tactics for handling information can
</p>
<p>therefore also be seen as human information behavior. So, for example, the content
</p>
<p>of this book could have been cast as a summary of human information behavior if
</p>
<p>it had been designed for a different target audience.
</p>
<p>We know that users have inherent capabilities and limitations, and these con-
</p>
<p>strain human information behavior. How users can process information is deter-
</p>
<p>mined by their cognitive, perceptual, and motor capabilities, that is, their
</p>
<p>information processing architecture. There are other, external constraints too, such
</p>
<p>as the tools that they use to access and process the information: their databases,
</p>
<p>their interfaces, networks, and other forms of information delivery, presentation,
</p>
<p>and output capabilities. By some measures, the largest information processor in
</p>
<p>212 7 Cognition: Human&ndash;Computer Communication</p>
<p/>
</div>
<div class="page"><p/>
<p>many buildings is a large photocopier/printer, which can produce literally reams2
</p>
<p>of information. The photocopier/printer&rsquo;s output is important because the results&mdash;
</p>
<p>the information&mdash;are processed more deeply by people than most computers will
</p>
<p>process the information passed through them.
</p>
<p>7.4.3 Human Information Seeking Behavior
</p>
<p>Human information seeking behavior can be viewed in several ways. One way to
</p>
<p>approach it is to ask &lsquo;&lsquo;how do users search for information, particularly on the
</p>
<p>Internet?&rsquo;&rsquo; Spink and her colleagues in information science have studied this area
</p>
<p>extensively (e.g., Spink and Cole 2001). They found that users seek information
</p>
<p>often, and from multiple sources. Different types of users search for different types
</p>
<p>of information, which is not so surprising, but they also seek it in different ways,
</p>
<p>look in different places, and trust the sources in different ways. Trends in what
</p>
<p>users search for can be identified, typically by studying user logs (Jansen and
</p>
<p>Spink 2006). Important trends have been found in this way, such as a shift towards
</p>
<p>more eCommerce queries and a rise in non-English queries over the period
</p>
<p>1997&ndash;2001 (Spink et al. 2002). Work in this area has also examined how different
</p>
<p>types of groups use information (Barnes et al. 1996). The results have been used to
</p>
<p>make prescriptive statements about how to help groups.
</p>
<p>Observational studies have examined how users search, including how many
</p>
<p>errors they make, how well they use the search tools (such as using the connectors
</p>
<p>&lsquo;and&rsquo; and &lsquo;or&rsquo;), and how many searches they do in parallel (Jansen and Spink
</p>
<p>2006; Spink et al. 2002). Some researchers have argued that users do not search
</p>
<p>very deeply (Nielsen 1997), and others, with more detailed studies have found that
</p>
<p>some users will search quite deeply (Byrne et al. 1999). Byrne et al.&rsquo;s research
</p>
<p>involved analyzing the tasks users were performing, and how web browsing fitted
</p>
<p>into those tasks. They found that the task influenced how long and how deeply
</p>
<p>users searched. In particular, medical information, work-related, and certain hobby
</p>
<p>searches can go quite deep over hours or days, and some searches are shallow. To
</p>
<p>support a wide range of users it is therefore important to understand them and the
</p>
<p>tasks they are performing, because different users will have different capabilities
</p>
<p>and needs when searching for information at different times.
</p>
<p>7.4.4 Information Scent
</p>
<p>The concept of information scent (Pirolli 1997, 2007) can also be exploited in
</p>
<p>helping users find the information they are looking for. Information scent is what
</p>
<p>2 A ream is 500 sheets of paper. Most photocopy and printing paper is sold in reams; thus the
saying, reams of material.
</p>
<p>7.4 Information Seeking Behavior 213</p>
<p/>
</div>
<div class="page"><p/>
<p>leads a user to spend more time exploring a web page (or menu item) to find what
</p>
<p>they are looking for because the content, metaphorically, &lsquo;smells&rsquo; like the thing
</p>
<p>they are looking for. The idea is to make sure that objects and links appear to
</p>
<p>smell like what they contain and to not smell like what they do not. In this
</p>
<p>way, the user should be able to detect more readily when they are looking in the
</p>
<p>right area.
</p>
<p>This metaphor of information scent makes several suggestions for design. Thus,
</p>
<p>obtuse words or phrases on menus mask the scent; descriptions that are too general
</p>
<p>diffuse the scent; descriptions that mislead users have the wrong scent; content that
</p>
<p>is hard to find because, perhaps, it is at the bottom of a page, are hard to smell.
</p>
<p>7.4.5 Implications for System Design
</p>
<p>Understanding information and the ways that users search for and use information
</p>
<p>is important if you want to help users carry out their tasks. Research in this area
</p>
<p>has provided a perspective that focuses on the material that users are using and
</p>
<p>looking for, and gives us another way to think about users and to support design.
</p>
<p>If you can understand what users are looking for, it should help you understand
</p>
<p>how you can support them in the task of finding it. This can be done through better
</p>
<p>interface design to display the information in a way that allows the users to
</p>
<p>understand it, which includes providing details about objects to help users find the
</p>
<p>information they are looking for directly or by providing information scent trails
</p>
<p>through increasingly more specific scents.
</p>
<p>It is also worth briefly mentioning Search Engine Optimization (SEO) at this
</p>
<p>point. The algorithms that underpin the major Web search engines keep evolving,
</p>
<p>but the way that they generally work is quite well known. Web content writers
</p>
<p>should be aware of how they work, because they can construct their content in
</p>
<p>such a way that it promotes their page in the search results. The number of links
</p>
<p>into a page, and keywords, for example, are just two factors that have been used to
</p>
<p>increase the ranking of web pages.
</p>
<p>7.5 Designing Content
</p>
<p>As the web has grown and web pages have proliferated, designers have come to
</p>
<p>realize the full importance of content and the way it is structured and delivered.
</p>
<p>With so much information now available, users can be overwhelmed, and under-
</p>
<p>standably are unwilling to expend significant time and energy trawling through
</p>
<p>hundreds of pages of content to find information. The way that content is written,
</p>
<p>structured, and delivered is therefore critical to the success of a system. The type of
</p>
<p>content you will have, and how it should be structured, will be determined by your
</p>
<p>content strategy and information architecture.
</p>
<p>214 7 Cognition: Human&ndash;Computer Communication</p>
<p/>
</div>
<div class="page"><p/>
<p>7.5.1 Content Strategy
</p>
<p>A content strategy is a theory of what and how to create, update, and merge
</p>
<p>content in a system such as a web site. Halvorson (2010) suggests that there are
</p>
<p>several basic needs to take into account when developing a content strategy if you
</p>
<p>want it to be successful:
</p>
<p>&bull; The need to do less, not more. Content should support key objectives or help users
</p>
<p>complete the task they are trying to do, or both. It is also obviously cheaper and
</p>
<p>easier to write less content, which makes it easier to maintain and faster to use.
</p>
<p>&bull; The need to understand the existing content, and its provenance. You may need
</p>
<p>to do a content audit to address this.
</p>
<p>&bull; The need to be a good listener. Responsibility for content is not just down to the
</p>
<p>content creators, and customers are often the people who are best placed to
</p>
<p>understand what content they want or need.
</p>
<p>&bull; The need to have someone who is responsible for delivering content. A newspaper
</p>
<p>has an editorial executive who makes the final decisions about what goes into a
</p>
<p>particular edition of a newspaper; a web site should have someone in a similar role.
</p>
<p>&bull; The need to start asking questions. Always be prepared to ask &lsquo;&lsquo;why?&rsquo;&rsquo; when
</p>
<p>somebody says &lsquo;&lsquo;we have to include this,&rsquo;&rsquo; &lsquo;&lsquo;we need to do that,&rsquo;&rsquo; and so on.
</p>
<p>These needs should be incorporated into&mdash;and help drive&mdash;the three steps (or
</p>
<p>phases) within your content strategy:
</p>
<p>1. Auditing the existing content and documenting it.
</p>
<p>2. Analyzing the different aspects within an organization that affect the content.
</p>
<p>3. Creating the strategy for the creation, delivery, and governance of content.
</p>
<p>The web and content are inextricably intertwined. If you want to deliver content
</p>
<p>that is both usable and useful, you should make use of the wide range of available
</p>
<p>processes, tools, and resources that have been designed to help make it easier to
</p>
<p>create content.
</p>
<p>7.5.2 Information Architecture
</p>
<p>The term Information Architecture (IA) is used to describe how online information
</p>
<p>is structured to support usability by both creators and users. As such, information
</p>
<p>architecture is one of the components that is included as part of user experience
</p>
<p>design. It is information architecture that occupies the intersection of content,
</p>
<p>context, and users (Morville and Rosenfeld 2007).
</p>
<p>Developing an IA is not simply a matter of drawing container boxes around
</p>
<p>collections of related information and then moving them around. This process,
</p>
<p>sometimes called wire framing, is, however, often a large part of the development
</p>
<p>of an IA. Developing an IA does not just involve generating static content, but also
</p>
<p>includes developing the dynamic paths through a web site, for example.
</p>
<p>7.5 Designing Content 215</p>
<p/>
</div>
<div class="page"><p/>
<p>When developing the IA, it is important to consider the information at several
</p>
<p>levels of abstraction. At the lowest level, this may be as simple as the way that
</p>
<p>items are ordered on a page. At the highest level it could involve how to organize
</p>
<p>the content appropriately to support the user&rsquo;s tasks. At a strategic level it could
</p>
<p>involve making decisions about how articles and metadata are placed into a
</p>
<p>content management system.
</p>
<p>7.5.3 Creating Content
</p>
<p>Getting the content strategy and information architecture correct are both impor-
</p>
<p>tant, but it is equally important to make sure that your content is usable too.
</p>
<p>Writing for printed material is a skill in itself, but creating content for web pages is
</p>
<p>also an important skill in its own right and one which often involves more than just
</p>
<p>writing text. The way that users read web pages is usually not the same as the way
</p>
<p>that they read printed pages (unless they are reading an online text article from
</p>
<p>start to finish).
</p>
<p>In most cases, web content is written for a general-purpose audience, which
</p>
<p>means that it should be readable and understandable by a large proportion of the
</p>
<p>population. The usual guide rule is that you should try to write text that requires a
</p>
<p>reading age of around 12 years, and that can be understood by students in the
</p>
<p>eighth grade in the US (this equates to an age range of about 12&ndash;14 years). The
</p>
<p>readability of text can be assessed using the Flesch reading ease score (Flesch
</p>
<p>1948): generally, you should be aiming for a score of 60&ndash;70. Comprehensibility is
</p>
<p>assessed using the Flesch&ndash;Kincaid grade level score (Kincaid et al. 1975), and here
</p>
<p>you should generally be aiming for a score of 7.0&ndash;8.0. Many word processors
</p>
<p>include tools that will let you calculate both of these scores, and there are several
</p>
<p>online calculators that can be used too.
</p>
<p>These scores should be used as guidance, not as requirements that have to be
</p>
<p>pursued at all costs. The scores provide a relatively simple but useful assessment
</p>
<p>of the clarity and directness of the language that is used in the text.
</p>
<p>7.5.4 Structuring Content
</p>
<p>We know that users organize and associate concepts using something like a graph
</p>
<p>structure (e.g., Collins and Quillian 1969; Klahr, Chase, and Lovelace 1983;
</p>
<p>Woods 1975). This led to the suggestion that knowledge should therefore be
</p>
<p>presented to users as a hypergraph structure because if it goes into the eyes like a
</p>
<p>graph (like hypertext or the web) then it can simply be put into corresponding
</p>
<p>graph structure inside the user&rsquo;s head. This example of a homeopathic fallacy&mdash;
</p>
<p>that &lsquo;&lsquo;like causes like&rsquo;&rsquo;&mdash;may have arisen from a misinterpretation of Vannevar
</p>
<p>Bush&rsquo;s (1945, reprinted in numerous places) view of how information is organized
</p>
<p>by people and machines.
</p>
<p>216 7 Cognition: Human&ndash;Computer Communication</p>
<p/>
</div>
<div class="page"><p/>
<p>The fallacy has been debunked (McKendree et al. 1995). The user cannot simply
</p>
<p>lift material from the page and dump it straight into their memory without some
</p>
<p>processing. The material to be learned has to go through the serial processes of
</p>
<p>reading, understanding, and creating memories using the processes and capabilities
</p>
<p>noted in Chap. 6. The material that has to be read should be presented in a serial
</p>
<p>way so that it can be appropriately processed. Hypertext can be useful if the learner
</p>
<p>is expert enough to use self-directed learning, but, if the learner is a novice and does
</p>
<p>not fully understand what is supposed to be learned, it is better to provide them with
</p>
<p>appropriate guidance (Scheiter and Gerjets 2007; Swaak and de Jong 2007).
</p>
<p>When preparing material to be read it is important to take into consideration the
</p>
<p>users&rsquo; capabilities. These capabilities will differ, depending on the users&rsquo; level of
</p>
<p>expertise, which will influence how they perceive things, and their mental model
</p>
<p>of the situation, for example. The material therefore needs to be structured to
</p>
<p>accommodate both users&rsquo; capabilities and their previous knowledge.
</p>
<p>7.5.5 Delivering Content
</p>
<p>The medium that will be used to deliver content to users has to be carefully
</p>
<p>considered. The way the content of a message posted on Twitter (a &lsquo;&lsquo;tweet&rsquo;&rsquo;)
</p>
<p>(which has a maximum length of 140 characters) is designed, for example, will be
</p>
<p>different from the way that the content for a podcast is designed, even if they are
</p>
<p>both presenting the same message. It is important to think about attributes such as
</p>
<p>the temperature of the medium, which relates to how actively the medium draws
</p>
<p>users in (McLuhan and Fiore 1967). Books, for example, are seen as cold, because
</p>
<p>they require lots of effort to use them; radio (and email), however, are hot.
</p>
<p>Where and how content is read will influence how readers interpret the mes-
</p>
<p>sage. Material seen on a small screen on a mobile device, for example, may be
</p>
<p>received and understood differently from material on a larger screen or on paper
</p>
<p>prototypes and printouts. Advances in HTML and CSS have facilitated what is
</p>
<p>called responsive design of web pages where only one set of web-based content
</p>
<p>needs to created, rather than having to design separate content (and structure) for
</p>
<p>desktops, tablets, and mobile devices (e.g., see Kadlec 2013). The content is
</p>
<p>automatically re-displayed in the most appropriate format based on the size of the
</p>
<p>device that is being used to read it.
</p>
<p>7.6 Implications for System Design
</p>
<p>When you design a system you need to consider the context in which it will be
</p>
<p>used. You will need to understand the terminology and language that your users
</p>
<p>use to communicate and talk about their tasks. The language that describes how
</p>
<p>your users interact with your systems should be appropriate to the context and
</p>
<p>7.5 Designing Content 217</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6">http://dx.doi.org/10.1007/978-1-4471-5134-0_6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6">http://dx.doi.org/10.1007/978-1-4471-5134-0_6</a></div>
</div>
<div class="page"><p/>
<p>culture in which the system is used. This will make it easier for your users to carry
</p>
<p>out their tasks, and hence make the system more acceptable to them. More gen-
</p>
<p>erally, you should try to use simple, direct, and clear language.
</p>
<p>If your interface requires your users to read text, particularly large amounts of
</p>
<p>text, you need to take into consideration the factors that affect how users read. You
</p>
<p>should avoid using several fonts, for example, as this can adversely affect reading
</p>
<p>speed, and may also detract from the overall user experience. You should also lay
</p>
<p>out the text in a way that helps the user to comprehend it, making appropriate use
</p>
<p>of headings, subheadings, and white space between paragraphs, for example. If
</p>
<p>you are designing web pages, then you will need to be aware of how people scan
</p>
<p>web pages, rather than read them in depth, so that you can position your text so
</p>
<p>that they will see it.
</p>
<p>Irrespective of whether your display shows only text, only graphics (including
</p>
<p>icons), or some combination of the two, it should be clear and apparent to your
</p>
<p>users what all of the items mean. This also applies to menu items where, once
</p>
<p>again, you should use terms and language that are relevant to your users, their
</p>
<p>tasks, and the context in which they are carrying out those tasks.
</p>
<p>If your users need to seek information, you need to help them find the infor-
</p>
<p>mation they are looking for in an efficient and effective manner. Using information
</p>
<p>scent can help them to find out fairly quickly whether they are looking in the right
</p>
<p>area, so you should make similar information have the same sort of &lsquo;&lsquo;smell&rsquo;&rsquo; as the
</p>
<p>information they are looking for. When you return the information to them, you
</p>
<p>should present it in a way that makes it easy for them to interpret, understand, and
</p>
<p>learn. In other words, it needs to be appropriately structured, for example, using
</p>
<p>tables and charts to present numeric information.
</p>
<p>For web sites in particular, the way that you write, structure, and deliver content
</p>
<p>are all major contributors to the success of a system.Managing content is an ongoing
</p>
<p>task, so you will need to maintain the content after you have written it, to make sure
</p>
<p>that it stays up to date and grows and evolves along with your users. It is therefore
</p>
<p>important to define a content strategy and information architecture up front to help
</p>
<p>you manage and deliver the content in a systematic way. You also need to think
</p>
<p>about how your users will access that content. If they will be using a range of devices
</p>
<p>(smartphones, tablets, desktops, and so on) you should seriously consider using a
</p>
<p>responsive web design approach which automatically resizes the content based on
</p>
<p>the size of the user&rsquo;s display screen. In this way you can help to ensure that your
</p>
<p>users get a similar experience when accessing your system from different devices.
</p>
<p>7.7 Summary
</p>
<p>This chapter covers some key issues regarding communication between users
</p>
<p>and systems. There is much more that could be said about the related top-
</p>
<p>ics of computer-mediated communication, non-verbal communication, and
</p>
<p>218 7 Cognition: Human&ndash;Computer Communication</p>
<p/>
</div>
<div class="page"><p/>
<p>computer-supported cooperative work (CSCW). We have, however, provided
</p>
<p>some practical suggestions about how to support communication between users
</p>
<p>and systems.
</p>
<p>The most common way that people communicate with each other and with
</p>
<p>technology is through language. By considering language, concepts such as
</p>
<p>Grices&rsquo; maxims can be applied to help you optimize the way that users interact
</p>
<p>with your system.
</p>
<p>Most systems require the user to do some reading from the screen. The reading
</p>
<p>process will be affected by factors such as the legibility of the text, which is
</p>
<p>influenced by the font size and the way the text is laid out. The quality of reso-
</p>
<p>lution of the text is also important: printed text usually has a much higher reso-
</p>
<p>lution than text displayed on a screen. In addition, users tend to scan rather than
</p>
<p>read text on a display screen, particularly if they are looking at menus or web
</p>
<p>pages containing hyperlinks.
</p>
<p>One of the other main tasks that users do is seek information. The way they do
</p>
<p>this is based on their preliminary understanding of the information they are looking
</p>
<p>for, and how it is organized. How they will understand the information that they
</p>
<p>find depends on their previous knowledge and experience, and may be affected by
</p>
<p>the contexts in which the information is being sought and used.
</p>
<p>When it comes to interacting with the web, the structure and delivery of content
</p>
<p>is critical. Content is an active element that has to be designed, developed, and
</p>
<p>maintained over time, which requires the setting up of a content strategy. The way
</p>
<p>the content is organized will be determined by your information architecture.
</p>
<p>When you create content you need to make sure that it will be intelligible (as well
</p>
<p>as legible) to your readers, and to structure it in such a way that the user can
</p>
<p>understand and learn what it means. Finally, the medium through which the
</p>
<p>content is delivered is increasingly important, as more and more people access the
</p>
<p>same content using a wide range of devices.
</p>
<p>7.8 Other Resources
</p>
<p>Users read material on the screen as part of systems, so learning how to write is a
</p>
<p>part of interface design. Strunk and White&rsquo;s very famous Elements of Style is well
</p>
<p>worth looking at for this topic. This book provides advice about how to present
</p>
<p>information to readers in a format that they can most easily digest:
</p>
<p>Strunk, W., &amp; White, E. B. (1979). The elements of style. NY, NY: Macmillan
</p>
<p>Another skill worth picking up is how to structure documents. For this, Parker&rsquo;s
</p>
<p>Looking good in print is a good text. The advice is not specific to any word processor
</p>
<p>or page layout tool. It discusses the use of color, layout, white space, fonts, and other
</p>
<p>aspects of design. It is easy to read. It is a very gentle introduction to graphic design.
</p>
<p>While based on print, some of the guidance will apply to online materials:
</p>
<p>7.7 Summary 219</p>
<p/>
</div>
<div class="page"><p/>
<p>Parker, R. C. (2006). Looking good in print. Scottsdale, AZ: Paraglyph Press
</p>
<p>For further details on how to apply information foraging theory, see Nielsen&rsquo;s
</p>
<p>Alertbox on this: http://www.useit.com/alertbox/20030630.html
</p>
<p>For more on information seeking more generally, a key figure is Carol Kuhlthau.
</p>
<p>A 2005 online article gives a nice overview and introduces some useful concepts:
</p>
<p>Kuhlthau, C. C. (2005). Towards collaboration between information seeking and infor-
mation retrieval. Information Research 10(2). 10&ndash;2.
</p>
<p>Finally, a short magazine article by Churchill addresses some challenges in
</p>
<p>designing for human search behavior:
</p>
<p>Churchill, E. F. (2008). Ps and Qs of candied herbs and happy babies: Seeking and
searching on your own terms. Interactions. 15(6). 46&ndash;49.
</p>
<p>7.9 Exercises
</p>
<p>7.1. (a) Time how long it takes four people to read out loud (or silently)
</p>
<p>Tables 7.3 and 7.4. Time how long it takes four more people to read them on
</p>
<p>screen (a tablet, smartphone, computer, or all of them) vs on paper. (b) What
</p>
<p>are the differences? (There should be differences). Consider having the four
</p>
<p>people read the text in the tables in each of the four ways (two levels of font
</p>
<p>difficulty 9 two types of display, or 2 9 2). (c) Why would you want to have
</p>
<p>different people do each task, and how could you correct for having the same
</p>
<p>person do it each way?
</p>
<p>7.2. Card sorting is a useful method for finding out how people organize the world.
</p>
<p>In this simple method, you give people a set of objects noted one per card. They
</p>
<p>can be words or pictures. The people then sort the cards into piles. The number
</p>
<p>and size of piles can either be left to the sorters or, if there is a design constraint
</p>
<p>that will have to be applied, into a restricted set of piles or sizes.
</p>
<p>As an application of this method, examine a large application like Word,
</p>
<p>Pages, GIMP, Excel, or Numbers. (a) Draw a graph or a table showing the
</p>
<p>complete menu structure. Ask two people to look at the menu items on cards
</p>
<p>(not on a menu) and organize the cards into groups. (b) What are average or
</p>
<p>typical groupings? (c) Do these groupings match the application, or are
</p>
<p>there differences between the personal groupings and menu structure? (d)
</p>
<p>What does this tell you about the mental models of the designers and of
</p>
<p>the users?
</p>
<p>7.3. Create a web site or a document. Create five versions of it using different font
</p>
<p>types and sizes. Ask ten people to rate the documents on four different
</p>
<p>dimensions. You can choose dimensions, such as ease of use, trustworthiness,
</p>
<p>fun. Record how long they take to read several of the pages out loud (so you
</p>
<p>know they are reading them). You will need to present them in different
</p>
<p>orders to balance the effect of learning over multiple trials. Examine the time
</p>
<p>220 7 Cognition: Human&ndash;Computer Communication</p>
<p/>
<div class="annotation"><a href="http://www.useit.com/alertbox/20030630.html">http://www.useit.com/alertbox/20030630.html</a></div>
</div>
<div class="page"><p/>
<p>to read with respect to the measures to see if there are any correlations that
</p>
<p>predict readability as measured by reading time.
</p>
<p>7.4. Find a source of interfaces and of jokes (cartoons or written jokes). Find an
</p>
<p>example joke or cartoon where one of Grice&rsquo;s maxims is violated. Find an
</p>
<p>interface where the same maxim is violated. You can also use interfaces noted
</p>
<p>in this book. Note how the interfaces could be repaired.
</p>
<p>References
</p>
<p>Barnes, D. M., Spink, A. H., &amp; Yeatts, D. E. (1996). Effective information systems for high-
performing self-managed teams. In Information Seeking in Context: Proceedings of an
International Conference on Research in Information Needs, Seeking and Use in Different
</p>
<p>Contexts (pp.163&ndash;178). Taylor Graham: Tampere, Finland.
Blandford, A., &amp; Attfield, S. (2010). Interacting with information. Synthesis lectures on human-
</p>
<p>centered informatics. San Rafael, CA: Morgan &amp; Claypool.
Bush, V. (1945). As we may think. The Atlantic Monthly, 176(1), 101&ndash;108.
Byrne, M. D. (2001). ACT-R/PM and menu selection: Applying a cognitive architecture to HCI.
</p>
<p>International Journal of Human-Computer Studies, 55(1), 41&ndash;84.
Byrne, M. D., John, B. E., Wehrle, N. S., &amp; Crow, D. C. (1999). The tangled web we wove: A
</p>
<p>taskonomy of WWW use. In Proceedings of the CHI&lsquo;99 Conference on Human Factors in
Computer Systems (pp. 544&ndash;551). ACM: New York, NY.
</p>
<p>Chilton, E. (1996). What was the subject of Titchner&rsquo;s doctoral thesis? SigCHI Bulletin, 28(2), 96.
Clark, H. H., &amp; Brennan, S. E. (1991). Grounding in communication. In L. B. Resnick, J.
</p>
<p>M. Levine, &amp; S. D. Teasley (Eds.), Perspectives on socially shared cognition (pp. 127&ndash;149).
Washington, DC: American Psychological Association.
</p>
<p>Collins, A. M., &amp; Quillian, M. R. (1969). Retrieval time from semantic memory. Journal of
Verbal Learning and Verbal Behavior, 8, 240&ndash;247.
</p>
<p>Dillon, A. (1992). Reading from paper versus screens: A critical review of the empirical
literature. Ergonomics, 35(10), 1297&ndash;1326.
</p>
<p>Flesch, R. (1948). A new readability yardstick. Journal of Applied Psychology, 32, 221&ndash;233.
Furnas, G. W., Landauer, T. K., Gomez, L. M., &amp; Dumais, S. T. (1987). The vocabulary problem
</p>
<p>in human-system communication. Communications of the ACM, 30(Nov.) (pp. 964&ndash;971).
Garvey, P. M., Pietrucha, M. T., &amp; Meeker., D. T. (1998). Development of a new road sign
</p>
<p>alphabet. Ergonomics in Design, 6(3), 7&ndash;11.
Glushko, R. J. (2013). The discipline of organizing. Cambridge, MA: MIT.
Grice, H. P. (1975). Logic and conversation. In P. Cole &amp; J. L. Morgan (Eds.), Syntax and
</p>
<p>semantics III: Speech acts. New York, NY: Academic Press.
Gould, J. D., Alfaro, L., Barnes, V., Finn, R., Grischkowsky, N., &amp; Minuto, A. (1987). Reading is
</p>
<p>slower from CRT displays than from paper: Attempts to isolate a single variable explanation.
Human Factors, 29, 269&ndash;299.
</p>
<p>Halvorson, K. (2010). Content strategy for the Web. Berkley, CA: New Riders.
Hornof, A. J., &amp; Halverson, T. (2003). Cognitive strategies and eye movements for searching
</p>
<p>hierarchical computer displays. In Proceedings of CHI 2003: Conference on Human Factors
in Computing Systems (pp. 249&ndash;256). ACM: New York, NY.
</p>
<p>Hornof, A. J., &amp; Kieras, D. E. (1997). Cognitive modeling reveals menu search is both random
and systematic. In Proceedings of the CHI&lsquo;97 Conference on Human Factors in Computer
Systems (pp. 107&ndash;114). ACM: New York, NY.
</p>
<p>Jansen, B. J., &amp; Spink, A. H. (2006). How are we searching the World Wide Web? A comparison
of nine large search engine transaction logs. Information Processing and Management, 42(4),
248&ndash;263.
</p>
<p>7.9 Exercises 221</p>
<p/>
</div>
<div class="page"><p/>
<p>Just, M. A., &amp; Carpenter, P. A. (1987). The psychology of reading and language comprehension.
Newton, MA: Allyn &amp; Bacon.
</p>
<p>Just, M. A., &amp; Thibadeau, R. A. (1984). Developing a computer model of reading times. In
D. E. Kieras &amp; M. A. Just (Eds.), New methods in reading comprehension research
(pp. 349&ndash;364). Hillsdale, NJ: Erlbaum.
</p>
<p>Kadlec, T. (2013). Implementing responsive design: Building sites for an anywhere, everywhere
web. Berkeley, CA: New Riders.
</p>
<p>Kernighan, B. W., &amp; Plauger, P. J. (1978). The elements of programming style (2nd ed.). New
York, NY: McGraw-Hill.
</p>
<p>Kincaid, J. P., Fishburne Jr, R. P., Rogers, R. L., &amp; Chissom, B. S. (1975). Derivation of new
readability formulas (Automated Readability Index, Fog Count and Flesch Reading Ease
Formula) for Navy enlisted personnel. Research Branch Report 8&ndash;75, Millington, TN: Naval
Technical Training, U. S. Naval Air Station, Memphis, TN.
</p>
<p>Klahr, D., Chase, W. G., &amp; Lovelace, E. A. (1983). Structure and process in alphabetic retrieval.
Journal of Experimental Psychology, 9(3), 462&ndash;477.
</p>
<p>Kurniawan, S. H., &amp; Zaphiris, P. (2001). Reading online or on paper: Which is faster?. In
Abridged proceedings of HCI International 2001, Poster sessions (pp. 220&ndash;222). Mahwah,
NJ: Erlbaum
</p>
<p>Liversedge, S. P., Gilchrist, I. D., &amp; Everling, S. (2011). The Oxford handbook of eye movements.
Oxford, UK: Oxford University Press.
</p>
<p>McKendree, J., Reader, W., &amp; Hammond, N. (1995). The &lsquo;&lsquo;Homeopathic Fallacy&rsquo;&rsquo; in learning
from hypertext. Communications of the ACM, 2(3), 74&ndash;82.
</p>
<p>McLuhan, M., &amp; Fiore, Q. (1967). The medium is the massage: An inventory of effects: 1st Ed.:
Bantam Books, Random House; reissued by Gingko Press, 2001.
</p>
<p>Morville, P., &amp; Rosenfeld, L. (2007). Information architecture for the World Wide Web (3rd ed.).
Sebastopol, CA: O&rsquo;Reilly.
</p>
<p>Nielsen, J. (1997). How users read on the Web. http://www.useit.com/alertbox/9710a.html.
Retrieved from 10 March 2014.
</p>
<p>Parker, R. C. (2006). Looking good in print. Scottsdale, AZ: Paraglyph Press.
Pirolli, P. (1997). Computational models of information scent-following in a very large browsable
</p>
<p>text collection. In Proceedings of the SIGCHI Conference on Human Factors in Computing
Systems (pp. 3&ndash;10). ACM: New York, NY.
</p>
<p>Pirolli, P. L. T. (2007). Information foraging theory: Adaptive interaction with information.
Oxford: New York, NY.
</p>
<p>Rayner, K. (1998). Eye movements in reading and information processing: 20 years of research.
Psychological Bulletin, 124(3), 372&ndash;422.
</p>
<p>Rayner, K., &amp; Pollatsek, A. (1989). The psychology of reading. Englewood Cliffs, NJ: Prentice
Hall.
</p>
<p>Rayner, K., Slattery, T. J., Drieghe, D., &amp; Liversedge, S. P. (2011). Eye movements and word
skipping during reading: Effects of word length and predictability. Journal of Experimental
Psychology: Human Perception and Performance, 37(2), 514&ndash;528.
</p>
<p>Rieman, J., Young, R. M., &amp; Howes, A. (1996). A dual-space model of iteratively deepening
exploratory learning. International Journal of Human-Computer Studies, 44, 743&ndash;775.
</p>
<p>Scheiter, K., &amp; Gerjets, K. (2007). Making your own order: Order effects in system- and user-
controlled settings for learning and problem solving. In F. E. Ritter, J. Nerb, T. M. O&rsquo;Shea, &amp;
E. Lehtinen (Eds.), In order to learn: How the sequences of topics affect learning (pp.
181&ndash;194). Oxford: New York, NY.
</p>
<p>Sears, A., &amp; Shneiderman, B. (1994). Split Menus: Effectively using selection frequency to
organize menus. ACM Transactions on Computer-Human Interaction, 1(1), 27&ndash;51.
</p>
<p>Spink, A., &amp; Cole, C. (2001). Information and poverty: Information-seeking channels used by
African American low-income households. Library &amp; Information Science Research, 23,
45&ndash;65.
</p>
<p>222 7 Cognition: Human&ndash;Computer Communication</p>
<p/>
<div class="annotation"><a href="http://www.useit.com/alertbox/9710a.html">http://www.useit.com/alertbox/9710a.html</a></div>
</div>
<div class="page"><p/>
<p>Spink, A., Ozmutlu, H. C., &amp; Ozmutlu, S. (2002a). Multitasking information seeking and
searching processes. Journal of the American Society for Information Sciences and
Technology, 53(8), 639&ndash;652.
</p>
<p>Spink, A. H., Jansen, B. J., Wolfram, D., &amp; Saracevic, T. (2002b). From e-sex to e-commerce:
Web search changes. IEEE Computer,35(3), 133&ndash;135.
</p>
<p>Swaak, J., &amp; de Jong, T. (2007). Order or no order: System versus learner control in sequencing
simulation-based scientific discovery. In F. E. Ritter, J. Nerb, T. M. O&rsquo;Shea, &amp; E. Lehtinen
(Eds.), In order to learn: How the sequences of topics affect learning (pp. 181&ndash;194). New
York, NY: Oxford.
</p>
<p>White, A. W. (2002). The elements of graphic design: Space, unity, page architecture, and type.
New York, NY: Allworth Press.
</p>
<p>Woods, W. (1975). What&rsquo;s in a Link: Foundations for Semantic Networks. In D. G. Bobrow &amp;
A. Collins (Eds.), Representation and Understanding. New York, NY: Academic Press.
Reprinted in Brachman, R., &amp; Levesque, H. (1985). Readings in Knowledge Representation.
San Mateo: Morgan Kaufmann. Also reprinted in Collins, A., &amp; Smith, E. E. (1988). Readings
in Cognitive Science. San Mateo: Morgan Kaufmann.
</p>
<p>References 223</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 8
</p>
<p>Social: Social Cognition and Teamwork
</p>
<p>Abstract Most work is carried out by people working as part of a team. Even
</p>
<p>where work is carried out by one person it is likely to be in connection if not in
</p>
<p>collaboration with other people. This could be in a formal organization that has
</p>
<p>standard operating procedures or as part of a larger system, or it could be part of an
</p>
<p>informal group of loosely organized collaborators. Social processes&mdash;how people
</p>
<p>interact with each other&mdash;are important; they affect how systems interfaces are
</p>
<p>used. Any system that supports more than one person needs to take these phe-
</p>
<p>nomena into account along with the various factors that define the social context in
</p>
<p>which users especially user working in teams will make decisions take actions
</p>
<p>including extrinsic intrinsic motivation. In this chapter we introduce some con-
</p>
<p>cepts that have proven to be important for system adoption use.
</p>
<p>8.1 Introduction
</p>
<p>Much early work in HCI focused on single users because at that time most tasks
</p>
<p>were performed by individuals working on independent computers. However, even
</p>
<p>in the 1970s, as increased computer use came to the workplace, there was rec-
</p>
<p>ognition that we need to consider social aspects of system use:
</p>
<p>We believe that the engineer who deals with human performance should avoid two faults
that have made the &lsquo;&lsquo;efficiency expert&rsquo;&rsquo; one of the most hated in industry: (1) the neglect of
personal and of social variables, and (2) the use of people as means to ends they do not
share and do not determine. If a person is to design tasks for others, he has the respon-
sibility to attempt to see the tasks and their implications in a wider context and to attempt
to ensure that they are life-enhancing. This is not easy to do, nor are the criteria clear cut.
It requires that the designer himself close feedback loops with reality at several levels, not
only at the level of specific performance criteria of the given system or of the human task
which are part of it, but also at the level of his own personal values (Sheridan and Ferrell
1974, pp. 18&ndash;19).
</p>
<p>As distributed, networked computing systems have become the norm, team or
</p>
<p>group working has become routine, and the importance of social processes has
</p>
<p>risen (see, for example, Hinds and Kiesler 2002). We now have a much better
</p>
<p>F. E. Ritter et al., Foundations for Designing User-Centered Systems,
DOI: 10.1007/978-1-4471-5134-0_8, ï¿½ Springer-Verlag London 2014
</p>
<p>225</p>
<p/>
</div>
<div class="page"><p/>
<p>understanding of how the context in which the technological system is used sig-
</p>
<p>nificantly affects how it is used. Workplace systems are socio-technical systems
</p>
<p>(see Chap. 2); that is, technical systems that are designed for and shaped by people
</p>
<p>operating in social contexts. This means it is important to consider the interactions
</p>
<p>and interdependencies between the social and technical aspects of any system that
</p>
<p>is being developed or modified: How is it being used? How does it affect (trans-
</p>
<p>form, facilitate, impede) social processes?
</p>
<p>Social psychology and other disciplines draw a distinction between individuals
</p>
<p>acting alone, dyads (two people interacting), groups, teams, and communities. In
</p>
<p>the context of work tasks, dyads, groups, and teams tend to share more clearly
</p>
<p>defined goals. Here we use the term team to refer to a particular, formally defined
</p>
<p>and workplace oriented type of group. Whilst what applies to groups generally
</p>
<p>applies to teams, what applies to teams does not always apply to groups.
</p>
<p>A team comprises two or more individuals who have to carry out work (a set of
</p>
<p>related tasks) in pursuit of some common (specified) goal. Team performance, like
</p>
<p>individual performance, is still based on the notion of particular people doing
</p>
<p>particular tasks in a particular context. It is, however, complicated by the need to
</p>
<p>communicate and co-ordinate actions and decision making, and by having to con-
</p>
<p>sider the effects of the way that the team may be distributed in both space and time.
</p>
<p>When thinking about teams, it is important to remember that what counts as a
</p>
<p>team depends on where you draw the boundaries when conducting your analysis
</p>
<p>(Hollnagel 2007). In aviation, for example, if you draw your boundary at the
</p>
<p>aircraft cockpit level you might consider the pilots to be a team. If, however, you
</p>
<p>extend the boundary to cover the whole of the (interior of the) aircraft, then the
</p>
<p>team would include the flight attendants. You can keep extending the boundary
</p>
<p>outwards, which would bring more people into the team: ground crew; air traffic
</p>
<p>control; and so on.
</p>
<p>Social processes related to and mediated by technology also occur in other large
</p>
<p>systems of systems such as medicine, entertainment, defense, and increasingly in
</p>
<p>education. For example, in air transportation, many people&mdash;passengers, pilots,
</p>
<p>ground crew, and so on&mdash;come together (see Fig. 8.1). Where a number of social
</p>
<p>groups come together, as in this case, a large socio-technical system&mdash;a system of
</p>
<p>systems&mdash;is formed smaller socio-technical systems each of which has their own
</p>
<p>social rules and regulations, and often includes different technical systems. People
</p>
<p>frequently end up as the points at which these systems overlap. For example, think
</p>
<p>about the check-in agent at an airport who has to work with baggage handling
</p>
<p>systems to ensure your luggage gets on to the right plane. Here, the agent who
</p>
<p>prints and attaches the tag to your bag is the boundary point between the check-in
</p>
<p>system and the baggage handling system, and the tag determines how the bag
</p>
<p>moves into the baggage handling system.
</p>
<p>Working as a team can bring problems of co-ordination and communication.
</p>
<p>The aviation industry recognized this and developed the concept of cockpit
</p>
<p>resource management (Wiener et al. 1993) as a way of dealing with the issues on
</p>
<p>226 8 Social: Social Cognition and Teamwork</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2">http://dx.doi.org/10.1007/978-1-4471-5134-0_2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2">http://dx.doi.org/10.1007/978-1-4471-5134-0_2</a></div>
</div>
<div class="page"><p/>
<p>the flight deck. The concept was subsequently extended to cover the whole of the
</p>
<p>on-board flight crew, and was renamed crew resource management (Kanki et al.
</p>
<p>2010). When teams are in the same location, or co-located a great advantage is
</p>
<p>overhearing what others are doing, even if they are not collaborating actively at
</p>
<p>that moment. This allows people to be aware of where others are in a task. There is
</p>
<p>a body of work looking at what happens in control rooms, for example, where
</p>
<p>teams of operators work together (e.g., Heath and Luff 2000).
</p>
<p>Although teams may be co-located, teams nowadays are often distributed in
</p>
<p>space and time, even when working for the same organization. Teams may also be
</p>
<p>spread across different time zones and across different cultures. A lot of work has
</p>
<p>been done to understand the benefits and problems of distributed work and tele-
</p>
<p>commuting (see, for example, Hinds and Kiesler 2002; Ellison 2004). Research
</p>
<p>has also focused on the ways in which different technologies affect communication
</p>
<p>and coordination. Technologies that mediate communication between people in
</p>
<p>different locations are differentially suited to different kinds of tasks (Churchill and
</p>
<p>Bly 2000). Teams can also change dynamically, as they adapt to the situation at
</p>
<p>hand. In hospitals, for example, there is often a doctor that is on call. These doctors
</p>
<p>are usually only called up when the local team cannot resolve the case they are
</p>
<p>currently dealing with. This may result in the doctor acting as a remote team
</p>
<p>member to help diagnose and fix the situation, or it may result in the doctor
</p>
<p>physically attending in order to provide expertise and advice in situ.
</p>
<p>In the rest of this chapter we look at the impact of social factors on perfor-
</p>
<p>mance. We begin by examining at the impact of the social context on decision
</p>
<p>making. We then go on to consider the factors that define the social context in
</p>
<p>which teams operate. It is worth noting at this juncture that team performance
</p>
<p>involves more than just the sum of the performances of the individual team
</p>
<p>members.
</p>
<p>Fig. 8.1 The modern air transportation system includes many kinds of technology, including
computer systems, and many types of users, ranging from passengers to pilots to support staff and
including air traffic control
</p>
<p>8.1 Introduction 227</p>
<p/>
</div>
<div class="page"><p/>
<p>8.2 Social Effects on Decision Making
</p>
<p>8.2.1 Introduction
</p>
<p>Social psychology suggests that sometimes groups do not make better decisions than
</p>
<p>individuals. It is certainly true that groups often come to different decisions than
</p>
<p>individuals, and that groups are influenced by social factors. This section looks at
</p>
<p>some of the social influences on decision making, including the diffusion of social
</p>
<p>responsibility, the attribution of effects, and how groups make decisions differently.
</p>
<p>8.2.2 Social Responsibility Effects
</p>
<p>There are two effects related to decision making in social settings. The first of
</p>
<p>these is called diffusion of social responsibility. If a request for assistance is
</p>
<p>directed at a single person, that person must choose whether to respond or not.
</p>
<p>When many people are held jointly responsible for dealing with a situation,
</p>
<p>however, the responsibility diffuses across people: one person may choose not to
</p>
<p>do anything in the belief that someone else will. Figure 8.2 illustrates a version of
</p>
<p>this. It shows a fairly obvious typographical error in a local paper. While it can be
</p>
<p>argued that it is not the readers&rsquo; responsibility to report typos to a newspaper,
</p>
<p>many readers take great delight in doing so. In this case, both the paper and the
</p>
<p>fans ignored this glaring mistake for weeks.
</p>
<p>The second effect is pluralistic ignorance. When you are in a situation, you will
</p>
<p>often base your interpretation of the situation on how other people interpret it. Is
</p>
<p>that person ill or just acting strangely? Are they sleeping by the side of the road or
</p>
<p>have they had a heart attack? As Darley and Latan&eacute; (reported in Abelson et al.
</p>
<p>2004, p. 224) noted, &lsquo;&lsquo;emergencies do not come with signs on them saying that
</p>
<p>they are emergencies.&rsquo;&rsquo; The observer has to interpret the event before responding.
</p>
<p>If others are ignoring the apparently anomalous behavior or interpreting it in one
</p>
<p>way, then it provides evidence to suggest that you should too.
</p>
<p>Both of these effects apply in an early study designed to investigate how people
</p>
<p>choose to help. Darley and Batson (1973) had theological seminary (i.e., religious
</p>
<p>professional) students prepare a talk and then walk individually to the next
</p>
<p>building where they were supposed to give their talk to a panel. Some students
</p>
<p>prepared a talk on the tale of the Good Samaritan (a biblical story about a man who
</p>
<p>stopped and helped an injured man) and some prepared a talk on a topic that did
</p>
<p>not involve helping others. Some of the students were told to hurry to the next
</p>
<p>building because they were late, some were told they were somewhat late, and
</p>
<p>some had more time to make the trip. On the way to the next building each student
</p>
<p>passed a person slumped in a doorway. Unknown to the students, this person was a
</p>
<p>confederate of the experimenter. Data was collected on who stopped to help this
</p>
<p>person, and how much help they offered.
</p>
<p>228 8 Social: Social Cognition and Teamwork</p>
<p/>
</div>
<div class="page"><p/>
<p>The students who had the most time to get to the next building helped the most
</p>
<p>(63%); those in the greatest hurry helped the least (10%). The students who were
</p>
<p>somewhat late helped 45% of the time. Ironically, the amount of help they gave
</p>
<p>was not influenced by whether the student was going to give a talk on the Good
</p>
<p>Samaritan or not. This work starts to examine who chooses to participate, and
</p>
<p>shows that it not only depends on the individual, but also on the context.
</p>
<p>You can often see these effects in email. Some time ago we saw an email that
</p>
<p>was sent out about the potential closing down of an academic society. &lsquo;&lsquo;Unless this
</p>
<p>vote [to amend the constitution] is successful, the committee will [have] no
</p>
<p>alternative [sic] to dismantling the Society, prior to closing it down.&rsquo;&rsquo; The email
</p>
<p>called upon the members of the society to vote for a new set of bylaws. It was
</p>
<p>targeted at the group (of society members) as a whole rather than individuals
</p>
<p>within the group. (The society continued, but it took several more emails.)
</p>
<p>Fig. 8.2 This figure, which
appeared in a pre-game
(American football)
newspaper program, ran for
3 weeks (with different
opponents appropriately
inserted), with the labels
&lsquo;&lsquo;When Penn State has the
Ball&rsquo;&rsquo; for its defensive team
and for its offensive team
</p>
<p>8.2 Social Effects on Decision Making 229</p>
<p/>
</div>
<div class="page"><p/>
<p>Remember that the diffusion of social responsibility requires that others are
</p>
<p>involved&mdash;a person is less likely to take responsibility for action or inaction when
</p>
<p>they think someone else will take the action. Size of the group is critical, and it
</p>
<p>must be the case that no one person is singled out as responsible. So, not all
</p>
<p>situations involving many participants will result in social responsibility diffusion.
</p>
<p>For such diffusion to occur, the relationship of the individuals in the group to the
</p>
<p>requestor&mdash;whether they are individually likely to be held accountable or not&mdash;is
</p>
<p>key. Your supervisor asking you to put information on a web site to help others is
</p>
<p>more compelling than a company president asking everyone to participate in a
</p>
<p>knowledge repository.
</p>
<p>You do not always get diffusion of social responsibility. In a demo run as part of
</p>
<p>an HCI class we have repeatedly failed to achieve this effect. In this demo the class
</p>
<p>teaching assistant emails the students (some individually, and some in groups of 2,
</p>
<p>4, 8, 16, or 32 students) asking them to bring along an example book to the next
</p>
<p>class. The numbers of students who bring in a book is about the same for those
</p>
<p>students who are emailed individually as it is for those who are emailed in groups.
</p>
<p>If there was diffusion of responsibility, there would be more books brought along
</p>
<p>by those who received the individual email than those who received a group email,
</p>
<p>Subsequent class discussions usually note that most of the students feel that this
</p>
<p>request is not individual, that the teaching assistant will know them individually,
</p>
<p>and that the lecturer will be able to tell whether or not they brought along a book.
</p>
<p>Sometimes students also report that the bland wording in the request is somewhat
</p>
<p>unusual, which leads them to suspect that there is an ulterior motive behind the
</p>
<p>request.
</p>
<p>If you want to avoid diffusion of social responsibility, you should target par-
</p>
<p>ticular individuals. It helps to use first names in emails, use individual commu-
</p>
<p>nication, and to clearly note any possible consequences. In the case of bulletin
</p>
<p>boards and online forums, people asking for help have to be specific (which is
</p>
<p>possible with technical problems) and have to address individuals if possible. In
</p>
<p>the case of online forums this is difficult and thus it may be better in many cases to
</p>
<p>find help locally.
</p>
<p>Note that diffusion of responsibility and pluralistic ignorance are not inevitable,
</p>
<p>and can be avoided or prevented. Keltner and Marsh (2006&ndash;2007) suggest making
</p>
<p>the need clear, so that there is no pluralistic ignorance about the need for help, and
</p>
<p>to direct the request at specific individuals, so that the responsibility does not get
</p>
<p>diffused.
</p>
<p>8.2.3 Attributions and Attributional Style
</p>
<p>Understanding why other people do things is called attribution. Attribution is
</p>
<p>central to how we understand social situations. When we examine how people
</p>
<p>make these attributions, we can start to identify some regularities:
</p>
<p>230 8 Social: Social Cognition and Teamwork</p>
<p/>
</div>
<div class="page"><p/>
<p>&bull; Self versus others: attributions about ourselves are usually different from our
</p>
<p>attributions about others behaving in exactly the same way. We give ourselves
</p>
<p>credit for success based on our internal capabilities, but blame the environment
</p>
<p>or others for our failures. On the other hand, when making attributions about
</p>
<p>others, we are more likely to attribute their success to their environment, and
</p>
<p>their failures to their personal deficiencies. Even university presidents do this
</p>
<p>(Birnbaum 1988, p. 215), attributing their own successes to hard work and their
</p>
<p>failures to outside events.
</p>
<p>&bull; If something bad occurs to someone else, we will seek explanations that attri-
</p>
<p>bute cause to a circumstance that creates the most distance from our own cir-
</p>
<p>cumstances. The explanation is simple: we like to distance ourselves from the
</p>
<p>thought that the same thing could happen to us.
</p>
<p>Attribution theory is an important area of research in social psychology. Jones
</p>
<p>et al. (1972) noted the tendency of people to attribute their actions to external
</p>
<p>situational causes, whilst external observers attributed the same actions to causes
</p>
<p>that were internal to the person carrying out the actions (the actor). They called
</p>
<p>this tendency the actor-observer divergence. The term fundamental attribution
</p>
<p>error was later introduced to describe how observers underestimate the impact of
</p>
<p>situational forces and overestimate the importance of internal dispositional factors
</p>
<p>(Ross et al. 1977).
</p>
<p>One of the fundamental errors in design is for the designer to attribute their own
</p>
<p>feelings, needs, knowledge, goals, and so on, to users. In other words, for the
</p>
<p>designers to believe that other people, including their potential users, are exactly
</p>
<p>like them, and behave in exactly the same way. Good designers differentiate what
</p>
<p>they want, need, and can do from what their users want, need, and can do. From
</p>
<p>the user&rsquo;s perspective, the technology may not always behave as expected. In these
</p>
<p>situations, systems need to be designed to be transparent, to be effectively de-
</p>
<p>bugged, and thus to help the users make the appropriate attributions: is this an
</p>
<p>issue with the system or the device or did I do something wrong? Error messages
</p>
<p>should not be worded ambiguously, but should allow the user to attribute causes
</p>
<p>appropriately and learn from the error.
</p>
<p>Related to the notion of attribution is the concept of cognitivedissonance.
</p>
<p>Cognitive dissonance occurs when a person holds two or more beliefs that are in
</p>
<p>conflict at one time as in when people do not get what they want. People will
</p>
<p>rationalize their choice by devaluing the one that is not chosen or that becomes
</p>
<p>unavailable. It is similar to the moral in Aesop&rsquo;s fable about the fox and the sour
</p>
<p>grapes. The fox reasoned that the grapes that he could not reach were sour, and
</p>
<p>hence not worth getting. People sometimes adopt a similar line of reasoning when
</p>
<p>they do not get the rewards they were expecting (such as a promotion to a new
</p>
<p>post) by convincing themselves that they are currently in the best position.
</p>
<p>Similarly, when people do things for little reward, when they explain why they did
</p>
<p>that activity, it can increase their perceived value of it. This explains why it can be
</p>
<p>better to give small rewards where the impact can last longer.
</p>
<p>8.2 Social Effects on Decision Making 231</p>
<p/>
</div>
<div class="page"><p/>
<p>8.2.3.1 Breakout Box: Ways Email Has Gone Awry
</p>
<p>How can we apply attribution theory to system design? Email is an example where
</p>
<p>most people are using the same type of system, but other people appear to behave
</p>
<p>differently from us and differently from how we would like them to.
</p>
<p>Ritter has personally seen the following ways that email has been lost, misfiled,
</p>
<p>misdirected, or lost. Are these errors? In some ways they are. Are they the fault of
</p>
<p>the user or of the system or the system designer? It seems to vary. In all cases, the
</p>
<p>sender might want a response.
</p>
<p>This list (selected from more) can also be explained with reference to attri-
</p>
<p>bution. Do the reasons you do not reply to email vary from why you think others
</p>
<p>do not reply (starting with whether they got the email!)? Many users assume that
</p>
<p>email is perfect, that the receiver received it, and that lack of response is due to the
</p>
<p>receiver not being willing to respond. This list illustrates that this is not always the
</p>
<p>case. Further discussion is available in the chapter on errors.
</p>
<p>1. Date is off on the sending computer (by up to 5 years), so does not appear with
</p>
<p>today&rsquo;s email (mail to Ritter).
</p>
<p>2. Simple typo in &lsquo;&lsquo;To&rsquo;&rsquo; address (mail to Saor-bugs, not Soar-bugs).
</p>
<p>3. Extra letter(s) typed as an answer to another application, e.g., mail to &lsquo;&lsquo;yesyen&rsquo;&rsquo;
</p>
<p>instead of to &lsquo;&lsquo;yen&rsquo;&rsquo; (Ritter).
</p>
<p>4. Complex typo, e.g., in &lsquo;&lsquo;To&rsquo;&rsquo; address, mail sent to research group&rsquo;s name, not to
</p>
<p>research group&rsquo;s email alias (Ritter).
</p>
<p>5. &lsquo;&lsquo;From&rsquo;&rsquo; country (!) was on spam list (so not read by recipient) and not read by
</p>
<p>cc person (Ritter was cc).
</p>
<p>6. Typo in domain (Ritter).
</p>
<p>7. Local (university, government, hotel) mail server ate it and left no residue
</p>
<p>(Ritter, Spink).
</p>
<p>8. No known reason, found months later where it should be (Ritter).
</p>
<p>9. Reader meant to respond, but never got back to it or was waiting for &lsquo;the right
</p>
<p>time to send a really good and clear reply&rsquo; (Ritter, too many times).
</p>
<p>10. Admin assistant reading manager&rsquo;s email deleted it accidentally (multi-read-
</p>
<p>ers of account, anonymous).
</p>
<p>11. Admin assistant reading manager&rsquo;s email deleted it, perhaps on purpose
</p>
<p>(multi-readers of account, anonymous).
</p>
<p>12. Email came in batch of 500 messages after a break (Ritter, others).
</p>
<p>13. Reader or mailer accidentally deleted incoming mailbox (anonymous!).
</p>
<p>14. Filter misfiled it (Schooler, Ritter).
</p>
<p>15. Email sent to Ritter (and from Ritter, more recently) where sender&lsquo;s machine
</p>
<p>filled in remainder as @\localhost[. Ritter replied with ritter@\localhost[.
</p>
<p>Both bounced.
</p>
<p>16. RAID disk failure takes out department for 3 days (anonymous in UK).
</p>
<p>17. &lsquo;&lsquo;When I can&rsquo;t give someone the answer I want to give them, I don&rsquo;t give them
</p>
<p>an answer&rsquo;&rsquo; (a publisher).
</p>
<p>232 8 Social: Social Cognition and Teamwork</p>
<p/>
</div>
<div class="page"><p/>
<p>18. User was going through a life-changing event, such as moving, pneumonia,
</p>
<p>their own death, having a baby, losing a baby, loss of a relative, or several of
</p>
<p>these at the same time.
</p>
<p>19. User wrote email and, instead of sending it, filed it as if it was the email being
</p>
<p>replied to. (Ritter, September 2006; to Ritter, 2009).
</p>
<p>20. Print out of email was printed and deleted, and was then stapled to the back of
</p>
<p>another document printed before it. (Ritter, multiple times).
</p>
<p>21. Auto expansion from first name (e.g., Jacob) instead of from last name (e.g.,
</p>
<p>Jacob).
</p>
<p>22. Email sent from local conference hotel run by major research university never
</p>
<p>arrived or bounced.
</p>
<p>23. Emails included as attachments in the middle of the body of a message (rather
</p>
<p>than in the header or at the end of the body).
</p>
<p>24. Email software and anything in between (e.g., router, ISP, recipient) changes
</p>
<p>security level. (Ritter, Feb. 2009, and earlier).
</p>
<p>25. Students told/reminded to read their student email account (with clunky
</p>
<p>interface) by an email sent to that address.
</p>
<p>26. User replied to questions by answering them on the same line, not a separate
</p>
<p>line as the quoted questions. The reader only saw their original questions.
</p>
<p>27. Migration to MS Outlook server did not migrate all emails.
</p>
<p>8.2.4 Majority and Minority Effects
</p>
<p>The way that individuals behave when they are part of a group usually differs
</p>
<p>from how they would behave on their own. There is a strong tendency to be
</p>
<p>influenced by what the group says or does. If the majority of members of a group
</p>
<p>express a single opinion, it is much less likely that one individual will hold onto a
</p>
<p>different opinion, even if they know that they are correct. This effect derives from
</p>
<p>the desire in a group to maintain harmony or conformity, and minimizes conflict.
</p>
<p>This can result in incorrect or deviant decision making. This has been raised as a
</p>
<p>concern for juries, for example, where what is called group think can occur
</p>
<p>(McCauley 1989).
</p>
<p>These issues have been studied with experiments using a group where some of
</p>
<p>the group members were confederates of the experimenter, that is, people who
</p>
<p>were not really subjects in the study. With a stooge majority (i.e., in a room full of
</p>
<p>experimenters pretending to be other subjects in the study), individuals readily
</p>
<p>capitulated to the majority view, even when they were fully aware of the right
</p>
<p>answer. With a stooge minority, where the group in the experiment had a minority
</p>
<p>of confederates who held an incorrect opinion, many individuals do capitulate
</p>
<p>occasionally to their view.
</p>
<p>Another way in which this can play out is with what is called choice shift. Two
</p>
<p>good examples of this are the risky shift, where a group makes a riskier decision
</p>
<p>than an individual. Wallach et al. (1964) proposed that greater risk-taking results
</p>
<p>8.2 Social Effects on Decision Making 233</p>
<p/>
</div>
<div class="page"><p/>
<p>from diffusion of responsibility. Here, emotional bonds decrease anxiety and the
</p>
<p>risk is perceived as shared. Collins and Guetzkow (1964) suggested that high-risk-
</p>
<p>takers are more confident and hence may persuade others to take greater risks. This
</p>
<p>can result in those who tend toward less risky behavior becoming more risky; social
</p>
<p>pressure (I do not want to let my colleagues down) translates to moving to a riskier
</p>
<p>position. Familiarity and increased knowledge of a situation also leads people to
</p>
<p>feel that situations are less risky; more people may equate to more knowledge and
</p>
<p>deeper exploration of the issues, so perceived risk is diminished (Bateson 1966).
</p>
<p>However, sometimes the opposite can occur; this is called cautious shift (Stoner
</p>
<p>1968). Here the group moves to a more conservative, less risky position.
</p>
<p>8.2.5 Summary
</p>
<p>The effects of the social context on decisions are strong in situations that have
</p>
<p>social components. These effects arise when there are other parties to the decision
</p>
<p>and when there are other parties making the decision.
</p>
<p>Social effects occur in individuals when they are part of a team but also occur in
</p>
<p>individuals in social situations where there are no organized teams such as chat
</p>
<p>rooms and forums. Some of these effects can be anticipated and can be marshaled
</p>
<p>to help systems, and some can be avoided with forethought.
</p>
<p>There are further influences of decision making that arise from social effects. It
</p>
<p>is these social effects that keep life interesting. If you are interested, see the section
</p>
<p>on Other Resources.
</p>
<p>8.3 Factors Affecting Team Performance
</p>
<p>8.3.1 Introduction
</p>
<p>It is important to understand the factors that underpin good teamwork so that you
</p>
<p>can facilitate and support teams with any system you design or develop. A team&rsquo;s
</p>
<p>performance, and whether it achieves its desired goals, will depend on collabo-
</p>
<p>ration and communication between the team members. Teamwork is based upon
</p>
<p>multiple components, including the team&rsquo;s set of competencies&mdash;that is, knowl-
</p>
<p>edge, skills, and attitudes (or KSAs). The relationship between the KSAs and
</p>
<p>teamwork is shown in Fig. 8.3.
</p>
<p>Your system design should provide the appropriate levels and types of support
</p>
<p>to encourage team members to participate in team performance. Participation can
</p>
<p>range from simply making a comment on a bulletin board that can be seen by other
</p>
<p>members of a group, to interactively working with other people as part of a team to
</p>
<p>carry out a task. There are several situational factors that affect how users interact
</p>
<p>socially with others.
</p>
<p>234 8 Social: Social Cognition and Teamwork</p>
<p/>
</div>
<div class="page"><p/>
<p>Table 8.1 notes several factors that influence team performance based on a
</p>
<p>review of modeling teamwork (Morgan et al. 2010). The importance of each of the
</p>
<p>factors will depend on the task itself, and the context in which it is performed.
</p>
<p>Note that although we refer to team, these factors also apply to groups.
</p>
<p>An example of a team is shown in Fig. 8.4. Much of the research in this area
</p>
<p>has been carried out in critical dynamic domains, such as aviation or defense,
</p>
<p>where good teamwork has high payoffs (and, more importantly, poor teamwork
</p>
<p>can lead to great losses). In addition to the way that teams are made up, and how
</p>
<p>the individual members work together, team performance is also affected by the
</p>
<p>availability of resources to carry out the task at hand. These includes physical
</p>
<p>resources like space, computers, networks, and databases, as well as intellectual
</p>
<p>and administrative support above and below the team in the organization (see
</p>
<p>Booher and Minninger 2003; Brooks 1975 for overviews of resourcing issues).
</p>
<p>Achieving good teamwork is difficult. The situation is complicated because of the
</p>
<p>need to consider the interaction of multiple people, each with different backgrounds
</p>
<p>(knowledge, culture, and so on), which will influence their behavior. It is also
</p>
<p>important to take appropriate account of task-related factors, because the task
</p>
<p>structure, for example, may not readily map onto the team&rsquo;s structure. Here we draw
</p>
<p>on and extendKozlowski and Ilgen&rsquo;s (2006) review to highlight areas of importance.
</p>
<p>8.3.2 Team Size
</p>
<p>The size of a team affects performance. If the team is small and its size is constant,
</p>
<p>it may be possible for communication and collaboration to take place directly
</p>
<p>between members. The group&rsquo;s size has a strong effect on intra-group interaction,
</p>
<p>as well as inter-group perceptions. Group size seems not only to influence the
</p>
<p>Fig. 8.3 A theory of the components of teamwork (based on a diagram by Salas et al. 2005)
</p>
<p>8.3 Factors Affecting Team Performance 235</p>
<p/>
</div>
<div class="page"><p/>
<p>effectiveness of communication between group members (Cartwright 1968; Hare
</p>
<p>1952) and its tendency towards hierarchy (Bales et al. 1951) but also the rela-
</p>
<p>tionship dynamics existing within and between groups (Bales and Borgatta 1955;
</p>
<p>Benenson et al. 2000; Shalit 1988).
</p>
<p>As the size of the team grows, it changes the dynamics of interaction between
</p>
<p>members, and may make it harder for individual members to participate in team
</p>
<p>working. In such a situation you need to consider other factors that can be used to
</p>
<p>facilitate member participation. If the team is too large for effective participation,
</p>
<p>you may wish to encourage (or even mandate) the use of smaller teams.
</p>
<p>8.3.3 Team Competencies
</p>
<p>Good teams are usually made up of good team members. If the team members
</p>
<p>have good levels of KSAs, this will usually be positively reflected in team per-
</p>
<p>formance. It also helps if the goals of the team members are aligned with those of
</p>
<p>the organization in general, and with the task goals in particular. A multidisci-
</p>
<p>plinary team can benefit greatly from skill sharing between different team mem-
</p>
<p>bers, and a team can also be made stronger through appropriate education and
</p>
<p>training of the team and its members. It is worth noting that there are some tasks
</p>
<p>where team performance is determined by the performance of the worst team
</p>
<p>Table 8.1 Factors that influence team performance by defining the social context of the
members
</p>
<p>Factor Brief definition
</p>
<p>Team size The number of members in a team
</p>
<p>Team competencies An abstraction of the number of unique qualities possessed by
the members of a team
</p>
<p>Team structure and composition The way that the members of the team are structurally
organized, e.g., as a hierarchy, and how they relate to one
another
</p>
<p>Social distance The perceived distance between the goals and motivations of
any two team members
</p>
<p>Spatial distance The geophysical distance between any two members of a
team; this also has implications for temporal distance&ndash;that
is, differences in time zone
</p>
<p>Mutual support and surveillance Mechanisms for maintaining shared norms and coherence by
minimizing the expression of the diverse characteristics of
team members
</p>
<p>Presence or absence of
legitimate authority figures
</p>
<p>A measure of the perception of a leader&rsquo;s authority and
legitimacy by a team member; authority can be leaders or
monitors
</p>
<p>Task attractiveness A measure of the alignment of the leader&rsquo;s task with the team
members&rsquo; internal motivations
</p>
<p>Team processes and tasks The relationship between the teams and the tasks that they
have to perform
</p>
<p>236 8 Social: Social Cognition and Teamwork</p>
<p/>
</div>
<div class="page"><p/>
<p>member, such as in an obstacle course, and there are other tasks where coordi-
</p>
<p>nation is far more important than raw speed or talent (e.g., McNeese 2000), and yet
</p>
<p>other tasks where the best performances of individuals matter (e.g., gymnastics).
</p>
<p>Industrial and organizational psychology is an area that will provide more
</p>
<p>knowledge about how to improve teams through selection.
</p>
<p>Olson and Olson (2000) suggest that collaboration readiness and technology
</p>
<p>readiness are also important factors for teams interacting using technology. The
</p>
<p>former relates to the willingness and ability of team members to collaborate. The
</p>
<p>latter relates the technological know-how about the tools that will be used, including
</p>
<p>tools that support synchronous (real-time) and asynchronous communication (and
</p>
<p>collaboration) such as Skype, Twitter, Instant Messaging, video chat, and text
</p>
<p>SMS&mdash;notably, the suitability of the tool itself, the match of its affordances to the
</p>
<p>communication needs of the group, and the tasks (Bly and Churchill 1999).
</p>
<p>8.3.4 Team Structure and Composition
</p>
<p>As the size of the team increases, some sort of structure will be needed to manage
</p>
<p>communication and collaboration between members. This often takes the form of a
</p>
<p>Fig. 8.4 Teams are
important for many
processes. Here, two pilots
are working together as a
team to prepare a plane for
flight, and, not shown,
interacting with ground
control and ATC
</p>
<p>8.3 Factors Affecting Team Performance 237</p>
<p/>
</div>
<div class="page"><p/>
<p>hierarchy. For larger teams (and where the size of the team can increase over
</p>
<p>time), it may become necessary to provide system support for communication and
</p>
<p>collaboration. This can be done through facilities for sharing information, or for
</p>
<p>allowing close grained collaboration with version histories to enable task aware-
</p>
<p>ness (e.g., Churchill et al. 2000) or by enabling team members to maintain a more
</p>
<p>general current awareness of what other team members are doing, as in the
</p>
<p>example of the control room operators mentioned above (Heath and Luff 2000).
</p>
<p>This latter kind of awareness is sometimes called shared situation awareness.
</p>
<p>The optimal structure will depend on the team members, their relationships, the
</p>
<p>social context, and the task. In the ideal case, the team is balanced to the task, with
</p>
<p>appropriate KSAs to perform the task and the team coordination tasks. For com-
</p>
<p>plex, unpredictable tasks, or for situations where there is a broad range of tasks,
</p>
<p>flexible structures are better. For static tasks, static structures can help the teams to
</p>
<p>be more efficient. Thus in assembly line work, where tasks do not vary, structures
</p>
<p>tend to be more rigid. In academic research, and in creative pursuits such as
</p>
<p>design, where the tasks vary quite a bit, teams will have more varied and more
</p>
<p>variable structures. In Fig. 8.3 this would influence the factors of adaptability and,
</p>
<p>to a certain extent, the communication and team leadership.
</p>
<p>Within the field of system design, Brooks (1975), has famously explored the
</p>
<p>issue of team structure. He argues that having a single system design architect is
</p>
<p>the best approach. He also notes that adding more people to a project can slow
</p>
<p>down development at certain times. There are two main reasons for this: first, you
</p>
<p>need to spend time and effort bringing the new people up to speed, and second, you
</p>
<p>often also increase the communication overhead (based on size and structure).
</p>
<p>In addition to the structure, the composition of the team is also important: you
</p>
<p>need to have people who are capable of working together. Several researchers
</p>
<p>(Kozlowski and Ilgen 2006; Salas et al. 2002) note that teams work better when
</p>
<p>they leverage the knowledge of the team members, are cohesive and confident,
</p>
<p>allocate resources appropriately, coordinate well, and learn over time.
</p>
<p>There is significant evidence that differences between group members nega-
</p>
<p>tively affect group performance (Byrne 1971; McGrath 1984; Newcomb 1961).
</p>
<p>This literature generally describes the level of group performance as a function of
</p>
<p>the organization&rsquo;s level of social integration, or the degree to which group
</p>
<p>members are psychologically linked or attracted towards interacting with one
</p>
<p>another in pursuit of common objectives (O&rsquo;Reilly et al. 1989). Social integration
</p>
<p>constitutes a goal-driven process arising out of the daily interactions of team
</p>
<p>members, mediated by both the length of contact between members and their
</p>
<p>respective organizational roles.
</p>
<p>Promoting interaction between team members also helps. Birnbaum (1988,
</p>
<p>p. 94) and others, have noted that people who interact with each other in groups
</p>
<p>tend to like each other. The interaction and liking are related, in that liking leads to
</p>
<p>more interaction, which leads to more liking.
</p>
<p>The importance of diversity among team members is questioned by some,
</p>
<p>however. Mannix and Neale (2005), for example, have argued that the effect of
</p>
<p>diversity of team members is not as clear cut as some people say. They note that
</p>
<p>238 8 Social: Social Cognition and Teamwork</p>
<p/>
</div>
<div class="page"><p/>
<p>&lsquo;&lsquo;[s]imilarity on attributes such as attitudes, values, and beliefs will facilitate
</p>
<p>interpersonal attraction and liking.&rsquo;&rsquo; (p. 31), which will lead to more cohesion and
</p>
<p>integration within a team and hence to better teamwork performance. They note
</p>
<p>that diversity can help if it is task relevant, pointing out that &lsquo;&lsquo;underlying differ-
</p>
<p>ences, such as differences in functional background, education, or personality, are
</p>
<p>more often positively related to performance&mdash;for example by facilitating crea-
</p>
<p>tivity or group problem solving&mdash;but only when the group process is carefully
</p>
<p>controlled.&rsquo;&rsquo;
</p>
<p>The composition of a team will inevitably change over time as people change
</p>
<p>positions within the organization, change roles, or even move to other employ-
</p>
<p>ment. Studies suggest that group performance and cohesiveness correlate more
</p>
<p>strongly with similarities in attitudes and values than with phenological charac-
</p>
<p>teristics (Terborg et al. 1976; Turban and Jones 1988), and that negative outcomes
</p>
<p>associated with surface-level diversity&mdash;ethnicity, social status, and so on&mdash;
</p>
<p>decrease the longer a team remains together (Milliken and Martins 1996).
</p>
<p>These findings highlight how important organizational continuity is to organi-
</p>
<p>zational functioning. Large turnovers in personnel lead to a drop in overall group
</p>
<p>functioning as the members of the new team take time to acquire new deep
</p>
<p>knowledge about one another (Carley 1992; Carley and Hill 2001).
</p>
<p>8.3.5 Social Distance
</p>
<p>Social distance, a concept introduced by Park (1924), refers to the distance in
</p>
<p>social terms between two groups or between people. You may find it helpful to
</p>
<p>think of it in terms of a sense of belonging to a team. The scales for measuring
</p>
<p>social distance, such as Bogardus&rsquo; (1933) social distance scale for race, and Westie
</p>
<p>and Westie&rsquo;s (1956) social distance pyramid for caste and class, are somewhat
</p>
<p>informal. Table 8.2 shows an example of social distance measures. The table
</p>
<p>Table 8.2 Social distance measures from Ethington (1997)
</p>
<p>Distance Bogardus (1925) Bogardus (1933&ndash;1967)
&lsquo;&lsquo;Would willingly admit
members of each race&hellip;&rsquo;&rsquo;
</p>
<p>1. To close kinship by marriage Would marry
</p>
<p>2. To my club as personal chums Would have as regular friends
</p>
<p>3. To my street as neighbors Would work beside in an office
</p>
<p>4. To employment in my occupation
in my country
</p>
<p>Would have several families in my neighborhood
</p>
<p>5. To citizenship in my country Would have merely as speaking acquaintances
</p>
<p>6. As visitors only in my country Would have live outside my neighborhood
</p>
<p>7. Would exclude from my country Would have live outside my country
</p>
<p>His work looked at race using scales developed by Bogardus (1933) and later works cited by
Ethington, but it can also be applied to other social groups
</p>
<p>8.3 Factors Affecting Team Performance 239</p>
<p/>
</div>
<div class="page"><p/>
<p>shows that there are problems in these measures (i.e., units are unclear), that it is
</p>
<p>not an easy measure to create, and that even discussions about social distance can
</p>
<p>help us understand ourselves and users better.
</p>
<p>More recently, social distance has come to be regarded as a continuum rather
</p>
<p>than discrete levels, stretching from an in-group bias&mdash;people just like me&mdash;to an
</p>
<p>out-group bias&mdash;people not at all like me (Eveland et al. 1999; Perloff 1993).
</p>
<p>Developments in network theory (see Chap. 9) also suggest that social distance is
</p>
<p>a function of the ties between group members rather than just their individual
</p>
<p>characteristics (Ethington 1997; Granovetter 1973; Wetherell et al. 1994). Nev-
</p>
<p>ertheless, the concept of a social distance continuum is a useful way of capturing
</p>
<p>the influence of culture, particularly as it relates to the development of out-group
</p>
<p>biases. It is worth noting that many people draw a distinction between social
</p>
<p>distance and psychological distance (Ginges and Eyal 2009), arguing that there are
</p>
<p>salient differences between the interactions of individuals who may belong to
</p>
<p>particular groups (psychological distance), and group-level interactions, where
</p>
<p>group identity is primary (social distance).
</p>
<p>Smaller social distances are generally preferable because they make it easier for
</p>
<p>team members to both receive support from, and give support to each other,
</p>
<p>thereby making participation in the group more likely. Conversely, larger social
</p>
<p>distances increase the likelihood of team members acting against other team
</p>
<p>members or other groups.
</p>
<p>8.3.6 Spatial Distance
</p>
<p>Organizations are increasingly using teams that are distributed geographically and
</p>
<p>temporally. One part of the team can work on a task and, at the end of their day,
</p>
<p>pass it to a group in another time zone who are just starting their working day.
</p>
<p>Getting people to perform successfully in this way requires careful planning,
</p>
<p>because geographic distances between group members mediate the development of
</p>
<p>familiarity (Ethington 1997), and thus affect group cohesiveness. Notions of
</p>
<p>familiarity, in turn, act reciprocally to help create communities of practice (Seely
</p>
<p>Brown and Duguid 1991). Distortions to the perception of space, however, can
</p>
<p>also distort both the sense of accountability and attachment to others (Grossman
</p>
<p>1996).
</p>
<p>Spatial relationships influence decisions to participate. If group members are
</p>
<p>close to us this encourages participation in local activities. The scale of importance
</p>
<p>varies by task, but in collaboration by researchers, for example, 30 m is an
</p>
<p>important distance, above which much less collaboration happens (Kraut et al.
</p>
<p>1990). Increasing distance will also decrease participation because increased
</p>
<p>distance weakens our relationship to others. There are both short distance
</p>
<p>(10&ndash;100 m) and large distance (time zone) effects. This may change as ways of
</p>
<p>connecting change and network bandwidth increases.
</p>
<p>240 8 Social: Social Cognition and Teamwork</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9">http://dx.doi.org/10.1007/978-1-4471-5134-0_9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9">http://dx.doi.org/10.1007/978-1-4471-5134-0_9</a></div>
</div>
<div class="page"><p/>
<p>8.3.7 Mutual Support and Mutual Surveillance
</p>
<p>In addition to issues of social and spatial distance, the nature of the relationships
</p>
<p>between team members influences team performance. In particular, peer-to-peer
</p>
<p>and subordinate&ndash;superior relationships, which we discuss here, are important
</p>
<p>(Harrison et al. 1998; Terborg et al. 1976; Turban and Jones 1988). If these
</p>
<p>relationships change, this can lead to significant and divergent outcomes in team
</p>
<p>performance (e.g., Grossman 1996).
</p>
<p>Team membership offers several benefits. These include a sense of identity and
</p>
<p>belonging (group norms), guidelines for dealing with ambiguous situations,
</p>
<p>structuring of chaotic situations, and helping predict the actions of others (e.g.,
</p>
<p>Chekroun and Brauer 2002; Cialdini et al. 1990; Smith and Mackie 1995). Fur-
</p>
<p>thermore, social support can help to moderate the effects of stress by buffering
</p>
<p>members from negative events (e.g., Caplan 1974; Cobb 1976; Epley 1974). The
</p>
<p>relationship between social support and stress reduction is complex: Sandler and
</p>
<p>Lakey (1982) found that the benefits of group support varied across individuals in
</p>
<p>relation to the coping mechanisms used to deal with adverse situations.
</p>
<p>On a peer-to-peer level, teams can help regulate behavior. Viewed through the
</p>
<p>lens of appraisal theory (e.g., Cannon 1932; Festinger 1954; Lazarus and Folkman
</p>
<p>1984), for example, group support facilitates participation. Appraisal theory pro-
</p>
<p>poses that you judge a task looking at what resources the task requires and what
</p>
<p>resources you have. If the task requires more than you have, it is a threatening task.
</p>
<p>If not, it is a challenging task. If you are part of a team, you have more resources,
</p>
<p>so being in a team will make the task more likely to be seen as challenging rather
</p>
<p>than threatening.
</p>
<p>Where behavior is deviant, however, Chekroun and Brauer (2002) found that if
</p>
<p>the deviation could be clearly attributed to particular individuals, other team
</p>
<p>members offered larger and more rapid responses of disapproval of those acts.
</p>
<p>Contrary to expectations, larger deviations are typically met first with attempts to
</p>
<p>mediate actor behavior rather than expulsion (Festinger 1954; Liska 1997), as
</p>
<p>members try to eliminate the discrepancy. As the discrepancy narrows, the pressure
</p>
<p>for uniformity appears to increase and becomes even greater when either the rele-
</p>
<p>vance or the value of groupmembership increases (Festinger 1954). Simultaneously,
</p>
<p>however, the impulse to individuate oneself and, for many people, to increase one&rsquo;s
</p>
<p>relative status ensures a constant state of comparative surveillance, particularly for
</p>
<p>groups operating in risky situations for prolonged periods (Dinter 1985).
</p>
<p>8.3.8 Authority Figures
</p>
<p>Team leaders are often expected to exert authority as part of their role. Leadership,
</p>
<p>authority, and compliance have been extensively studied, most famously by
</p>
<p>Stanley Milgram (1963). In Milgram&rsquo;s study, participants gave increasingly
</p>
<p>8.3 Factors Affecting Team Performance 241</p>
<p/>
</div>
<div class="page"><p/>
<p>powerful electrical shocks to volunteer learners, based on commands from the
</p>
<p>experimenter (an authority figure)&mdash;notably, shocks were not in fact delivered but
</p>
<p>study participants believed they were. The power wielded by the experimenter in
</p>
<p>this study was not physically coercive or economic, but rather symbolic, in that
</p>
<p>they were an authority figure in a study. Milgram noted that the goal (the
</p>
<p>advancement of knowledge) and the location (Yale) influenced participants to
</p>
<p>acquiesce more readily to the experimenter&rsquo;s demands (Milgram 1963, p. 377). In
</p>
<p>the Milgram study and subsequent obedience studies (e.g., Haney et al. 1973),
</p>
<p>belief in the legitimacy and power of the leader led to the leader being granted
</p>
<p>actual power over the participant.
</p>
<p>The effects of authority are moderated by other factors, such as physical
</p>
<p>proximity. If the team leaders are physically located close to the team, they have
</p>
<p>more influence on team members. Distant leaders have less authority.
</p>
<p>Authority can be expressed in several different ways online, for example, by an
</p>
<p>email address (e.g., president@psu.edu), by having someone send an email on
</p>
<p>your behalf (e.g., this is an email for a vice president sent by an admin assistant),
</p>
<p>by privileges or special tools in a game, and by login names (e.g., admin, web-
</p>
<p>master, or root@company.com). How authority is implemented, used, and abused
</p>
<p>online is still not fully understood, however.
</p>
<p>8.3.9 Task Attractiveness
</p>
<p>The task that a team has to perform and, hence, its goals influence the behavior of
</p>
<p>the team. Frank&rsquo;s (1944) and Milgram&rsquo;s (1963) studies both note that obedience of
</p>
<p>authority depends on having legitimate goals that are related to the organization&rsquo;s
</p>
<p>mission. More legitimate goals lead to greater participation in systems. In addition,
</p>
<p>people often indicate in interviews and surveys that goals are a motivating factor in
</p>
<p>their behavior (Collins 2008; Frank 1944). Representing social goals poses a
</p>
<p>challenge, in that they emerge at the interface between cognitive and social
</p>
<p>activity, and hence tend to be more abstract. It can therefore be difficult to evaluate
</p>
<p>how successfully they have been achieved.
</p>
<p>Over time, legitimate goals tend to make group members more compliant,
</p>
<p>whereas illegitimate goals erode the ability of leaders to influence their subordi-
</p>
<p>nates. Making the goals clear, and the payoff for achieving them direct and
</p>
<p>immediate, are just some ways to make tasks more appealing. Online systems,
</p>
<p>including computer games, can be designed to take advantage of this. Carma
</p>
<p>(http://www.car.ma), for example, is an online car ride sharing site where the goal
</p>
<p>is attractive to users for multiple reasons. The Carma app runs on a smartphone
</p>
<p>and connects to a server. When you want to travel somewhere, you note where you
</p>
<p>want to be picked up and how much you are willing to pay. As you drive, or before
</p>
<p>you drive, you check to see if anyone is looking for a ride.
</p>
<p>The success of Carma&rsquo;s system appears to be more dependent on social factors
</p>
<p>than on technology. If there are not enough drivers and passengers, there will not
</p>
<p>242 8 Social: Social Cognition and Teamwork</p>
<p/>
<div class="annotation"><a href="http://www.car.ma">http://www.car.ma</a></div>
</div>
<div class="page"><p/>
<p>be enough matches to make its use worthwhile for either driver or passenger. In the
</p>
<p>past, these rides were arranged informally (e.g., by word of mouth) and using
</p>
<p>bulletin boards. So the group size, location, and destination will all have an effect.
</p>
<p>Group size is likely to be a negative factor in rural areas where the group and the
</p>
<p>population density are both likely to be smaller. On the other hand, group cohe-
</p>
<p>siveness may be greater, as the group members may know each other and be
</p>
<p>headed to the same destinations. The risks in developing this system do not appear
</p>
<p>to be technological, but more related to social engineering.
</p>
<p>8.3.10 Team Processes and Tasks
</p>
<p>It is important to understand the tasks the group is trying to perform. There may be
</p>
<p>different ways to do the task, and there may be different tasks that can be chosen.
</p>
<p>Within a volunteer organization, for example, some groups will perform better on
</p>
<p>activism tasks and some groups will perform better on outreach and education tasks.
</p>
<p>The way that tasks are divided between the team members and how the team
</p>
<p>members communicate will affect team performance. Olson and Olson (2000,
</p>
<p>2008) note the importance of the coupling of work, that is, how closely team
</p>
<p>members have to work together. For technical work and in discussions of risk, for
</p>
<p>example, the collaborators frequently need to be co-located so that they can
</p>
<p>communicate fully, whereas in other situations, such as open source software
</p>
<p>development, remote coupling may be possible.
</p>
<p>It is therefore important to adapt the processes to the team and to the tasks.
</p>
<p>Common ground is a shared set of knowledge, expectations, and understanding
</p>
<p>about the people on the team and the task. Establishing common ground is an
</p>
<p>important factor in team performance (Clark and Wilkes-Gibbs 1986; Olson and
</p>
<p>Olson 2000) and should therefore be encouraged by systems and system designers.
</p>
<p>You may also need to think about people&rsquo;s motivation for doing the task in the
</p>
<p>first place. Pink (2009) argues that boring and repetitive work still requires
</p>
<p>extrinsic motivation (Pink describes this as Motivation 2.0) to get people to do the
</p>
<p>tasks, and this was covered in Chap. 4. In those situations where people want to do
</p>
<p>the work, however, Pink argues that they are intrinsically motivated to do the tasks
</p>
<p>(he calls this Motivation 3.0). Pink suggests that Motivation 3.0 applies to creative
</p>
<p>work and leisure, most of design (including design of software, systems and
</p>
<p>interfaces), many engineering tasks, and most knowledge work.
</p>
<p>8.3.11 Implications for System Design
</p>
<p>These factors make numerous suggestions about how to design systems, and this
</p>
<p>section can only note a few for some common systems. For distributed users, like
</p>
<p>those on YouTube, these factors suggest that it is possible to encourage
</p>
<p>8.3 Factors Affecting Team Performance 243</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4">http://dx.doi.org/10.1007/978-1-4471-5134-0_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4">http://dx.doi.org/10.1007/978-1-4471-5134-0_4</a></div>
</div>
<div class="page"><p/>
<p>participation by helping the site seem smaller, perhaps by creating local regions
</p>
<p>like in Yelp where you search by a town or area. It is directly helpful to have
</p>
<p>friends identify each other on the site for mutual support; even to make moderate
</p>
<p>posts might need encouragement, and attempts to provide appropriate distance
</p>
<p>between people, both increasing it by calling someone Dr. Ritter, and decreasing it
</p>
<p>by calling him Frank. Allowing people to moderate interaction in online forums
</p>
<p>(moderators) as legitimate authority figures will help encourage pro-social
</p>
<p>behavior. Finally, making the goal attractive and noting the goal, payoffs, and
</p>
<p>value will help people choose to interact.
</p>
<p>For collaboration at a distance, as an aspect of system design that will not go
</p>
<p>away, these factors remain very important too. Each of these factors will help such
</p>
<p>groups work together. Not directly mentioned, but influenced by all these factors,
</p>
<p>is trust, and space and time are important factors, being able to meet face to face,
</p>
<p>in the same place at the same time will, according to these theories, encourage
</p>
<p>participation, as does the trust across interactions.
</p>
<p>8.3.12 Summary
</p>
<p>Successful team performance depends on the social context in which the team will
</p>
<p>operate. This social context is defined by a wide range of factors. The relative
</p>
<p>weights of these factors and how they should be balanced will vary across systems
</p>
<p>and settings. Where differences exist between theories in this area they often arise
</p>
<p>from different assumptions about the teams, their contexts, and the things that can
</p>
<p>be changed. In general, teams (1) that are more cohesive, (2) who have worked
</p>
<p>together longer, and (3) who share more values, will perform better and be more
</p>
<p>likely to achieve their collective goals. When you design your system you should
</p>
<p>try to support the factors that enable cohesion and the sharing of values. You
</p>
<p>should also consider whether there are ways in which you can support new team
</p>
<p>members to bring them up to speed as quickly as possible.
</p>
<p>8.4 Factors Affecting Performance in Community Settings
</p>
<p>Having considered the factors that affect performance (and behavior) in team
</p>
<p>settings, it is also important to take a brief look at what happens in less structured
</p>
<p>settings. There are an increasing number of communities developing (more or less)
</p>
<p>organically online. Sites such as Yelp, lastminute.com, YouTube, Tripadvisor, and
</p>
<p>Epicurious now support self-reported consumer ratings, and some comprise only
</p>
<p>user-generated content. In addition, there is an increasing number of open source
</p>
<p>communities in a wide range of areas: for software development (e.g., Linux), for
</p>
<p>knowledge (e.g., Wikipedia), for stock photography (e.g., Open Stock Photogra-
</p>
<p>phy), and for music (e.g., Open Source Music).
</p>
<p>244 8 Social: Social Cognition and Teamwork</p>
<p/>
</div>
<div class="page"><p/>
<p>Pink (2009) notes that many organizations still use extrinsic motivation theory,
</p>
<p>and argues that this approach frequently violates what psychological science is
</p>
<p>telling us. He suggests that what motivates people to participate without payment
</p>
<p>in these activities and communities is intrinsic motivation, noting that it is more
</p>
<p>important than extrinsic motivation for many tasks. It is not the perfect panacea,
</p>
<p>however, and he provides several counter examples of tasks where intrinsic
</p>
<p>motivation either fails or is not possible.
</p>
<p>In community settings, many people get involved in their own time, and without
</p>
<p>any form of payment. In many ways, although they comprise a community, their
</p>
<p>motivation is invariably individualistic. These people are intrinsically motivated by
</p>
<p>the drives of autonomy, mastery, and purpose, as noted in Chap. 4. The tasks that
</p>
<p>they are doing are intrinsically rewarding, so people should not be given extrinsic
</p>
<p>rewards for doing them. The intrinsic drives need to be supported through providing
</p>
<p>feedback (positive and negative to help with mastery), and now-that rewards which
</p>
<p>only occasionally happen. These should not be monetary in order to minimize the
</p>
<p>likelihood of discouraging or discounting the user&rsquo;s intrinsic motivations to perform
</p>
<p>the task. The rewards might provide further autonomy, notes, and recognition about
</p>
<p>mastery, or emphasize the purpose that was served. Alternatively, make any
</p>
<p>extrinsic rewards a token: many $1 payments for patents get framed and saved, for
</p>
<p>example, in recognition of a job well done.
</p>
<p>8.5 Implications for System Design
</p>
<p>Teamwork is highly dependent on communication and collaboration. The team
</p>
<p>will often need to share information, for example, so that team members can use it
</p>
<p>to make individual and collective decisions. It is therefore important that your
</p>
<p>system supports both communication&mdash;of both information and outcomes&mdash;and
</p>
<p>collaboration. This may require the use of tools and technologies that are not an
</p>
<p>inherent part of your designed system, such as video communication. We used
</p>
<p>Skype as well as email during the writing of this book, for example, to allow the
</p>
<p>three authors in three different time zones to communicate and share ideas both
</p>
<p>synchronously and asynchronously.
</p>
<p>Group decision making aids typically incorporate features to reduce bad effects
</p>
<p>and increase good effects of group decision making. These features often include a
</p>
<p>brain storming session, and anonymizing users counter the effects of hierarchy
</p>
<p>(organizational power) so that more ideas can be generated without the leader
</p>
<p>explicitly or implicitly affecting what people are willing to say.
</p>
<p>As we have noted throughout the chapters in this book, most systems nowadays
</p>
<p>are socio-technical systems. In other words, there is a social system that needs to be
</p>
<p>considered because the technology and the social system will be interdependent and
</p>
<p>interact. If you do not spend time and effort understanding the existing social system,
</p>
<p>you run the risk of adversely affecting it. For example, if staff have to spend more
</p>
<p>time on maintaining and interacting directly with the new technology rather than on
</p>
<p>8.4 Factors Affecting Performance in Community Settings 245</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4">http://dx.doi.org/10.1007/978-1-4471-5134-0_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4">http://dx.doi.org/10.1007/978-1-4471-5134-0_4</a></div>
</div>
<div class="page"><p/>
<p>the tasks they need to perform, or on communicating plans and results, this will have
</p>
<p>a detrimental effect on the work processes and outcomes. Ultimately, staff may
</p>
<p>simply stop using the new technology because it gets in the way of them doing their
</p>
<p>job.
</p>
<p>You should try to design your system in such a way that it minimizes the
</p>
<p>possibility of diffusion of social responsibility. Things that enable diffusion include
</p>
<p>getting aggregate rather than individual inputs, allowing people to be anonymous,
</p>
<p>and setting goals where no specific person is invited to contribute. Techniques that
</p>
<p>are widely used to help avoid diffusion of responsibility include providing rep-
</p>
<p>resentations of the people involved that can be seen by other users, by allowing
</p>
<p>reputations to be built according to system usage and expertise, and by making any
</p>
<p>requests for assistance appear more directed to individuals than to a group.
</p>
<p>The attribution of causality suggests that responsibility can be moderated.
</p>
<p>Partly this has to be done by the user, but the breakout box on email suggests that
</p>
<p>email systems might be more apologetic and clear about what went wrong, and
</p>
<p>email systems are getting better about noting how and why mail was not delivered.
</p>
<p>This knowledge can help the sender understand why the receiver might or might
</p>
<p>not receive an email. Similar effects and results can be imagined for phone calls,
</p>
<p>text messages, and IMs.
</p>
<p>If you are designing a very large system, of the scale of Yelp, for example, you
</p>
<p>may want to encourage participation by helping the users perceive the system as
</p>
<p>being smaller than it really is. To avoid overwhelming the user, Yelp does this by
</p>
<p>creating local regions where you search by town or area. It can also be helpful to
</p>
<p>have friendly faces available in the system to provide mutual support, and to
</p>
<p>provide moderators (in areas like online forums) as legitimate authority figures to
</p>
<p>help encourage pro-social behavior. You may also need to think about how you
</p>
<p>provide the appropriate social distance between people using the system (e.g.,
</p>
<p>increasing it by using formal titles, such as Dr. Smith, or reducing it by using first
</p>
<p>names such as John, or even nicknames).
</p>
<p>You will need to think about how and why people are motivated to use your
</p>
<p>system to carry out their particular tasks. Do they use it because they have to (are
</p>
<p>they paid to use it to do their job, for example)? Or do they use it because they
</p>
<p>want to use it (the classic example here being social networking systems)? Is their
</p>
<p>motivation extrinsic or intrinsic? That is, are they self-motivated because of their
</p>
<p>own interest, or because they will get a reward from an external source for doing
</p>
<p>it? Even in the case of developing a social networking system, there may be a need
</p>
<p>for extrinsic motivation to make sure that people keep the system active by pro-
</p>
<p>viding new content, although the rewards for doing this may not be financial. You
</p>
<p>could highlight how the system increases their mastery, gives them autonomy, and
</p>
<p>increases the importance of doing the task. The balance between motivations may
</p>
<p>not always be clear cut. Some learning tasks, for example, will require a coach
</p>
<p>who sets tasks (which may be necessary, but are not necessarily intrinsically
</p>
<p>rewarding) for people to complete as part of their learning experience. Any reward
</p>
<p>structure for task performance needs to be appropriately aligned to teams and to
</p>
<p>individuals. If the rewards are targeted at individuals, and individual performance,
</p>
<p>246 8 Social: Social Cognition and Teamwork</p>
<p/>
</div>
<div class="page"><p/>
<p>for example, then the likelihood is that the team members will behave as
</p>
<p>individuals.
</p>
<p>In addition to the team level issues, you may also need to think about orga-
</p>
<p>nizational issues (sometimes referred to as the blunt end of a system, as noted in
</p>
<p>Chap. 10). If an organization has procedures in place for how a particular job has
</p>
<p>to be done, for example, then you will need to think about whether these proce-
</p>
<p>dures will have to be changed. If the procedures are imposed by a regulatory
</p>
<p>authority (as in nuclear power, for example) then you may not be able to change
</p>
<p>those procedures, so you will have to design your system to support those pro-
</p>
<p>cedures. There can also be cultural effects (on several levels), so there may be a
</p>
<p>tradition for doing a task in a particular way, which is an effect of organizational
</p>
<p>culture; we cover this in Chap. 9.
</p>
<p>8.6 Summary
</p>
<p>Social factors are important. They affect the ways that teams operate, and hence
</p>
<p>affect system performance. If you are designing systems that will be operated by
</p>
<p>teams of people, you will need to understand that the ways that teams behave
</p>
<p>cannot simply be described by generalizing from individual behavior. Care needs
</p>
<p>to be exercised when generalizing from studies of different types of teams, or from
</p>
<p>teams doing different tasks in different contexts.
</p>
<p>You need to use the results from studies of how teams work intelligently.
</p>
<p>Teams and their tasks will vary widely. The results probably rely on more factors
</p>
<p>than are reported, and the type of tasks and types of group members will influence
</p>
<p>the results but are often assumed to apply to all groups or all tasks. So we should
</p>
<p>be cautious when generalizing or overgeneralizing from existing results. The
</p>
<p>results about how teams work may only apply to that type of team with that type of
</p>
<p>task, rather than all teams (larger and smaller, with different types of people)
</p>
<p>competing or working in different environments and doing more or less similar
</p>
<p>tasks. This reflects Clark&rsquo;s (1973) concern about overgeneralization in language
</p>
<p>research. He noted that it was difficult, and even inappropriate to generalize from a
</p>
<p>few nouns and verbs to all nouns and verbs&mdash;they come from different languages,
</p>
<p>take different parts of speech as helpers, have different frequencies, and can be
</p>
<p>radically different in many dimensions&mdash;as well as for teams and tasks..
</p>
<p>In addition to understanding how teams make decisions and take actions, the
</p>
<p>factors that influence team performance are important. In particular, the social
</p>
<p>context of the team your system will support needs to be understood. Often this
</p>
<p>context will not be static, but will change over time, so you need to understand
</p>
<p>how and when the various factors that define the social context can change.
</p>
<p>There are many examples of how a failure to give appropriate consideration to
</p>
<p>the social aspects of systems has led to accidents. Casey (1998) notes several
</p>
<p>including disasters with the Space Shuttle program because they ignored social and
</p>
<p>political aspects (Starbuck and Farjoun 2005; Vaughan 1997).
</p>
<p>8.5 Implications for System Design 247</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10">http://dx.doi.org/10.1007/978-1-4471-5134-0_10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10">http://dx.doi.org/10.1007/978-1-4471-5134-0_10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9">http://dx.doi.org/10.1007/978-1-4471-5134-0_9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9">http://dx.doi.org/10.1007/978-1-4471-5134-0_9</a></div>
</div>
<div class="page"><p/>
<p>8.7 Other Resources
</p>
<p>There are a number of general texts about social factors in collaboration and
</p>
<p>teamwork that are worth reading if you wish to know more about this area. We
</p>
<p>have cited some in the main body of the chapter (e.g., Ellison 2004; Hinds and
</p>
<p>Kiesler 2002; Olson and Olson 2008) but there are many more. See, for example,
</p>
<p>Intellectual teamwork: social and technological foundations of cooperative work
</p>
<p>edited by Galegher, Kraut, and Egido (1990, Hillsdale, NJ: Erlbaum).
</p>
<p>There is an extensive literature under the titles &lsquo;&lsquo;computer-supported coopera-
</p>
<p>tive work&rsquo;&rsquo; (CSCW) and &lsquo;&lsquo;computer mediated communication&rsquo;&rsquo; (CMC) where
</p>
<p>many of the topics we have covered are elaborated in more detail. Conference and
</p>
<p>journal publications in this area will provide more information and more current
</p>
<p>information. There are also a number of initiatives in trying to build systems that
</p>
<p>are smart about how people collaborate, employing computational agents to broker
</p>
<p>work task accomplishment in teams. See, for example, chapters in Ye and Chur-
</p>
<p>chill (eds.) (2003). Agent supported cooperative work. Boston, MA: Kluwer.
</p>
<p>If you are interested in how to design teams, rather than just how to design
</p>
<p>systems to support team performance, Vicente (1999) presents a useful approach.
</p>
<p>He argues for laying out all the tasks that the team will do, effectively a task
</p>
<p>analysis writ large. Then you group the tasks so that there are natural breaks
</p>
<p>between sets of tasks, taking into account communication and how tasks interact.
</p>
<p>He argues that this leads to better team performance because the tasks are more
</p>
<p>naturally divided.
</p>
<p>Work by Judy and Gary Olson are particularly relevant here. They have studied
</p>
<p>how computer-supported communication changes how teams work, and provide
</p>
<p>some design advice about how to support teams in such projects:
</p>
<p>Olson, G. M., &amp; Olson, J. S. (2007). Groupware and computer supported cooperative
work. In J. J. Jacko &amp; A. Sears (Eds.), Handbook of human-computer interaction (2nd
Ed.). Mahwah, NJ: Erlbaum.
</p>
<p>Olson, G. M., &amp; Olson, J. S. (2003). Mitigating the effects of distance on collaborative
intellectual work. Economics of Innovation and New Technologies, 12, 27&ndash;42.
</p>
<p>8.8 Exercises
</p>
<p>8.1 Look through the list of the ways that email has gone awry, See how many
</p>
<p>examples you can find of (a) diffusion of social responsibility, (b) pluralistic
</p>
<p>ignorance, (c) attribution errors, and (d) majority/minority effects.
</p>
<p>8.2 Imagine you are working on a project where the team is distributed across
</p>
<p>three locations, all in different time zones. You have been asked to identify
</p>
<p>videoconferencing tools that can be used to carry out monthly progress
</p>
<p>meetings and to select the best one for the job. List the factors that you would
</p>
<p>use to inform your decision, and explain why they are important.
</p>
<p>248 8 Social: Social Cognition and Teamwork</p>
<p/>
</div>
<div class="page"><p/>
<p>8.3 You are managing a soccer team, where daily training routines are partly
</p>
<p>determined by the combination of the players&rsquo; individual circumstances. The
</p>
<p>players are asked to record their weight, calorie intake, and exercises each
</p>
<p>morning using an app on their smartphone. Explain how you would motivate
</p>
<p>the players to provide this data every day before setting off for the training
</p>
<p>ground.
</p>
<p>8.4 Choose an online, social web site, such as Facebook, YouTube, or Yelp.
</p>
<p>Sketch several tasks that can be done by users with the site. Describe the
</p>
<p>intrinsic and extrinsic motivation(s) for users to perform those tasks. Do the
</p>
<p>same for an online course site, and for an online game. Note at least four
</p>
<p>insights that arise from doing this analysis.
</p>
<p>8.5 Consider the organization where you currently work (or are a student). Try to
</p>
<p>identify at least two people within that organization who are simultaneously
</p>
<p>members of several teams, and explain where the boundaries occur that
</p>
<p>delineate those teams.
</p>
<p>8.6 Find a game that is designed to help someone learn a complex skill, such as
</p>
<p>World of Warcraft. Examine what components of that game are training
</p>
<p>individual skills and what are training social skills. Also, note if the game has
</p>
<p>collaborative or competitive or educational elements across learners.
</p>
<p>8.7 Consider how forming, storming, norming, and performing can be done
</p>
<p>without technology and with technology for group class projects. Consider
</p>
<p>how these processes are done and could be done better in the workplace.
</p>
<p>8.8 Generate a job description with at least eight activities for an office job where
</p>
<p>telecommuting occurs (e.g., sales, professor, management, software engineer,
</p>
<p>student). Discuss how technology might replace or support doing each task
</p>
<p>and note how many of these tasks can and cannot be performed remotely and
</p>
<p>what social activities are included. Using this analysis, provide suggestions for
</p>
<p>teleworkers.
</p>
<p>References
</p>
<p>Abelson, R. P., Frey, K. P., &amp; Gregg, A. P. (2004). Experiments with people: Revelations from
social psychology. Mahwah, NJ: Erlbaum.
</p>
<p>Bales, R. F., &amp; Borgatta, E. F. (1955). Size of group as a factor in the interaction profile. In A.
P. Hare, E. F. Borgatta, &amp; R. F. Bales (Eds.), Small groups: Studies in social interaction (pp.
495&ndash;512). Toronto: Random House.
</p>
<p>Bales, R. F., Strodtbeck, F. L., Mills, T. M., &amp; Roseborough, M. E. (1951). Channels of
communication in small groups. American Sociological Review, 16, 461&ndash;468.
</p>
<p>Bateson, N. (1966). Familiarization, group discussion and risk taking. Journal of Experimental
Social Psychology, 2, 119&ndash;129.
</p>
<p>Benenson, J. F., Gordon, A. J., &amp; Roy, R. (2000). Children&rsquo;s evaluative appraisals of competition
in tetrads versus dyads. Small Group Research, 31(6), 635&ndash;652.
</p>
<p>Birnbaum, R. (1988). How colleges work. San Francisco: Jossey-Bass.
Bly, S., &amp; Churchill, E. F. (1999). Design through matchmaking: Technology in search of users.
</p>
<p>Interactions, 6(2), 23&ndash;31.
Bogardus, E. S. (1933). A social distance scale. Sociology and Social Research, 17, 265&ndash;271.
</p>
<p>8.8 Exercises 249</p>
<p/>
</div>
<div class="page"><p/>
<p>Bogardus, E. S. (1967). A forty year racial distance study. Los Angeles: University of Southern
California.
</p>
<p>Booher, H. R., &amp; Minninger, J. (2003). Human systems integration in army systems acquisition.
In H. R. Booher (Ed.), Handbook of human systems integration (pp. 663&ndash;698). Hoboken, NJ:
Wiley.
</p>
<p>Brooks, F. P. (1975). The mythical man-month: Essays on software engineering. Reading, MA:
Addison-Wesley.
</p>
<p>Byrne, D. (1971). The attraction paradigm. New York, NY: Academic Press.
Cannon, W. B. (1932). The wisdom of the body. New York, NY: Norton.
Caplan, G. (1974). Support systems and community mental health: Lectures on concept
</p>
<p>development. New York: Behavioral Publications.
Carley, K. M. (1992). Organizational learning and personnel turnover. Organizational Science,
</p>
<p>3(1), 20&ndash;46.
Carley, K. M., &amp; Hill, V. (2001). Structural change and learning within organizations. In A. Lomi
</p>
<p>&amp; E. R. Larsen (Eds.), Dynamics of organizations: Computational modeling and organiza-
tional theories (pp. Ch. 2. pp. 63&ndash;92). Live Oak: MIT Press/AAAI Press.
</p>
<p>Cartwright, D. (1968). The nature of group cohesiveness. In D. Cartwright &amp; A. Zander (Eds.),
Group dynamics: Research and theory (pp. 91&ndash;118). New York, NY: Harper &amp; Row.
</p>
<p>Casey, S. M. (1998). Set phasers on stun: And other true tales of design, technology, and human
error. Santa Barbara, CA: Aegean.
</p>
<p>Chekroun, P., &amp; Brauer, M. (2002). The bystander effect and social control behavior: The effect
of the presence of others on people&rsquo;s reactions to norm violations. European Journal of Social
Psychology, 32(6), 853&ndash;867.
</p>
<p>Churchill, E. F., &amp; Bly, S. (2000). Culture vultures: Considering culture and communication in
virtual environments. SIG Group Bulletin, 21(1), 6&ndash;11.
</p>
<p>Churchill, E. F., Trevor, J., Bly, S., Nelson, L., &amp; Cubranic, D. (2000). Anchored conversations.
Chatting in the context of a document. In CHI 2000 Conference Proceedings (pp. 454&ndash;461).
New York, NY: ACM Press.
</p>
<p>Cialdini, R. B., Reno, R. R., &amp; Kallgren, C. A. (1990). Focus theory of normative conduct:
Recycling the concept of norms to reduce littering in public places. Journal of Personality and
Social Psychology, 58(6), 1015&ndash;1026.
</p>
<p>Clark, H. H. (1973). The language-as-fixed-effect fallacy: A critique of language statistics in
psychological research. Journal of Verbal Learning and Verbal Behavior, 12, 335&ndash;359.
</p>
<p>Clark, H. H., &amp; Wilkes-Gibbs, D. (1986). Referring as a collaborative process. Cognition, 22,
1&ndash;39.
</p>
<p>Cobb, S. (1976). Social support as a moderator of life stress. Psychosomatic Medicine,38(5),
300&ndash;314.
</p>
<p>Collins, B. E., &amp; Guetzkow, H. (1964). A social psychology of group processes for decision-
making. New York, NY: Wiley.
</p>
<p>Collins, R. (2008). Violence: A micro-sociological theory. Princeton, NJ: Princeton University
Press.
</p>
<p>Darley, J. M., &amp; Batson, C. D. (1973). &lsquo;&lsquo;From Jerusalem to Jericho&rsquo;&rsquo;: A study of situational and
dispositional variables in helping behavior. Journal of Personality and Social Psychology, 27,
100&ndash;108.
</p>
<p>Dinter, E. (1985). Hero or coward: Pressures facing the soldier in battle. Totowa, NJ: Frank Cass
and Company Limited.
</p>
<p>Ellison, N. B. (2004). Telework and social change: How technology is reshaping the boundaries
between home and work. Westport, CT: Praeger.
</p>
<p>Epley, S. W. (1974). Reduction of the behavioral effects of aversive stimulation by the presence
of companions. Psychological Bulletin, 81(5), 271&ndash;283.
</p>
<p>Ethington, P. J. (1997). The intellectual construction of &lsquo;&lsquo;social distance&rsquo;&rsquo;: Toward a recovery of
Georg Simmel&rsquo;s social geometry. Cybergeo: European Journal of Geography, 30. http://
cybergeo.revues.org/index227.html
</p>
<p>250 8 Social: Social Cognition and Teamwork</p>
<p/>
<div class="annotation"><a href="http://cybergeo.revues.org/index227.html">http://cybergeo.revues.org/index227.html</a></div>
<div class="annotation"><a href="http://cybergeo.revues.org/index227.html">http://cybergeo.revues.org/index227.html</a></div>
</div>
<div class="page"><p/>
<p>Eveland, W, Jr, Nathanson, A. I., Detenber, B. H., &amp; McLeod, D. M. (1999). Rethinking the
social distance corollary: Perceived likelihood of exposure and the third-person perception.
Communication Research, 26(3), 275&ndash;302.
</p>
<p>Festinger, L. (1954). A theory of social comparison processes. Human Relations, 7(2), 117&ndash;140.
Frank, J. D. (1944). Experimental studies of personal pressure and resistance: I. Experimental
</p>
<p>production of resistance. Journal of General Psychology, 30, 23&ndash;41.
Ginges, J., &amp; Eyal, S. (2009). Psychological distance, group size and intergroup relations. In
</p>
<p>Proceedings of the 32nd International Society of Political Psychology (pp. 51&ndash;65). Dublin,
Ireland: ISSP.
</p>
<p>Granovetter, M. (1973). The strength of weak ties. American Journal of Sociology, 78,
1360&ndash;1380.
</p>
<p>Grossman, D. (1996). On killing: The psychological cost of learning to kill in war and society.
New York: Back Bay Books, Little Brown and Company.
</p>
<p>Haney, C., Banks, W. C., &amp; Zimbardo, P. G. (1973). Study of prisoners and guards in a simulated
prison. Washington, DC: Office of Naval Research (ONR).
</p>
<p>Hare, A. P. (1952). A study of interaction and consensus in different sized groups. American
Sociological Review, 17, 261&ndash;267.
</p>
<p>Harrison, D. A., Price, K. H., &amp; Bell, M. P. (1998). Beyond relational demography: Time and the
effects of surface and deep level diversity on work group cohesion. The Academy of
Management Journal, 41(1), 96&ndash;107.
</p>
<p>Heath, C., &amp; Luff, P. (2000). Technology in action. Cambridge, UK: Cambridge University Press.
Hinds, P., &amp; Kiesler, S. (Eds.). (2002). Distributed work. Cambridge, MA: MIT Press.
Hollnagel, E. (2007). Flight decks and free flight: Where are the system boundaries? Applied
</p>
<p>Ergonomics, 38(4), 409&ndash;416.
Jones, E. E., Kanouse, D. E., Kelley, H. H., Nisbett, R. E., Valins, S., &amp; Weiner, B. (1971/1972).
</p>
<p>Attribution: Perceiving the causes of behavior. New York: General Learning Press.
Kanki, B., Helmreich, R. L., &amp; Arca, J. (Eds.). (2010). Crew resource management (2nd ed.).
</p>
<p>London, UK: Academic Press.
Keltner, D., &amp; Marsh, J. (2006&ndash;2007). We are all bystanders. Greater Good, 3(2). http://
</p>
<p>greatergood.berkeley.edu/greatergood/archive/2006fallwinter/keltnermarsh.html
Kozlowski, S. W. J., &amp; Ilgen, D. R. (2006). Enhancing the effectiveness of work groups and
</p>
<p>teams. Psychological Science in the Public Interest, 7(3), 77&ndash;124.
Kraut, R. E., Egido, C., &amp; Galegher, J. (1990). Patterns of contact and communication in
</p>
<p>scientific research collaborations In J. Galegher, R. E. Kraut, &amp; C. Egido (Eds.), Intellectual
teamwork: Social and technological foundations of cooperative work (pp. 149&ndash;171).
Hillsdale, NJ: Erlbaum.
</p>
<p>Lazarus, R. S., &amp; Folkman, S. (1984). Stress, appraisal and coping. New York: Springer
Publishing.
</p>
<p>Liska, A. E. (1997). Modeling the relationships between macro forms of social control. Annual
Review of Sociology, 23(1), 39&ndash;61.
</p>
<p>Mannix, E., &amp; Neale, M. A. (2005). What differences make a difference? The promise and reality
of diverse teams in organizations. Psychological Science in the Public Interest, 6(2), 31&ndash;55.
</p>
<p>McCauley, C. (1989). The nature of social influence in groupthink: Compliance and
internalization. Journal of Personality and Social Psychology, 57, 250&ndash;260.
</p>
<p>McGrath, J. E. (1984). Groups: Interaction and process. Englewood Cliffs, NJ: Prentice-Hall.
McNeese, M. D. (2000). Socio-cognitive factors in the acquisition and transfer of knowledge.
</p>
<p>Cognition, Technology and Work, 2, 164&ndash;177.
Milgram, S. (1963). Behavioral study of obedience. Journal of Abnormal and Social Psychology,
</p>
<p>67(4), 371&ndash;378.
Milliken, F. J., &amp; Martins, L. L. (1996). Searching for common threads: Understanding the
</p>
<p>multiple effects of diversity in organizational groups. Academy of Management Journal, 25,
598&ndash;606.
</p>
<p>References 251</p>
<p/>
<div class="annotation"><a href="http://greatergood.berkeley.edu/greatergood/archive/2006fallwinter/keltnermarsh.html">http://greatergood.berkeley.edu/greatergood/archive/2006fallwinter/keltnermarsh.html</a></div>
<div class="annotation"><a href="http://greatergood.berkeley.edu/greatergood/archive/2006fallwinter/keltnermarsh.html">http://greatergood.berkeley.edu/greatergood/archive/2006fallwinter/keltnermarsh.html</a></div>
</div>
<div class="page"><p/>
<p>Morgan, J. H., Morgan, G. P., &amp; Ritter, F. E. (2010). A preliminary model of participation for
small groups. Computational and Mathematical Organization Science, 16, 246&ndash;270.
</p>
<p>Newcomb, T. M. (1961). The acquaintance process. New York: Holt, Rinehart, &amp; Winston.
O&rsquo;Reilly, C. A, I. I. I., Caldwell, D. F., &amp; Barnett, W. P. (1989). Work group demography, social
</p>
<p>integration, and turnover. Administrative Science Quarterly, 34, 21&ndash;37.
Olson, G. M., &amp; Olson, J. S. (2000). Distance matters. Human&ndash;Computer Interaction, 15,
</p>
<p>139&ndash;179.
Olson, G. M., &amp; Olson, J. S. (2008). Computer-supported cooperative work. New York: Wiley.
Park, R. E. (1924). The concept of social distance as applied to the study of racial attitudes and
</p>
<p>racial relations. Journal of Applied Sociology, 8, 339&ndash;344.
Perloff, R. M. (1993). Third-person effect research 1983&ndash;1992: A review and synthesis.
</p>
<p>International Journal of Public Opinion Research, 5, 167&ndash;184.
Pink, D. H. (2009). Drive. New York: Riverhead Books.
Ross, L., Amabile, T. M., &amp; Steinmetz, J. L. (1977). Social roles, social control, and biases in
</p>
<p>social-perception processes. Journal of Personality and Social Psychology, 35, 485&ndash;494.
Salas, E., Priest, H. A., &amp; Burke, C. S. (2005). Teamwork and team performance measurement. In
</p>
<p>J. Wilson &amp; N. Corlett (Eds.), Evaluation of human work (3rd ed., pp. 793&ndash;808). Boca Raton,
FL: CRC Press.
</p>
<p>Salas, E., Wilson, K. A., Burke, C. S., &amp; Bowers, C. A. (2002). Myths about crew resource
training. Ergonomics in Design, 10(4), 21&ndash;24.
</p>
<p>Sandler, I. R., &amp; Lakey, B. (1982). Locus of control as a stress moderator: The role of control
perceptions and social support. American Community Journal of Psychology, 10(1), 65&ndash;80.
</p>
<p>Seely Brown, J., &amp; Duguid, P. (1991). Organizational learning and communities-of-practice:
Toward a unified view of working, learning and innovation. Organization Science, 2(1),
40&ndash;57.
</p>
<p>Shalit, B. (1988). The psychology of conflict and combat. New York: Praeger Publishers.
Sheridan, T. B., &amp; Ferrell, W. R. (1974). Man&ndash;machine systems: Information, control, and
</p>
<p>decision models of human performance. Cambridge, MA: MIT Press.
Smith, E. R., &amp; Mackie, D. M. (1995). Social psychology. New York: Worth Publishers.
Starbuck, W. H., &amp; Farjoun, M. (Eds.). (2005). Organization at the limit: Lessons from the
</p>
<p>Columbia disaster. Malden, MA: Blackwell Publishing.
Stoner, J. A. F. (1968). Risky and cautious shifts in group decisions: The influence of widely held
</p>
<p>values. Journal of Experimental Social Psychology, 4, 442&ndash;459.
Terborg, J. R., Castore, C., &amp; DeNinno, J. A. (1976). A longitudinal field investigation of the
</p>
<p>impact of group composition on group performance and cohesion. Journal of Personality and
Social Psychology, 34, 782&ndash;790.
</p>
<p>Turban, D. B., &amp; Jones, A. P. (1988). Supervisor-subordinate similarity: Types, effects, and
mechanisms. Journal of Applied Psychology, 73, 228&ndash;234.
</p>
<p>Vaughan, D. (1997). The Challenger launch decision: Risky technology, culture, and deviance at
NASAw. Chicago: University of Chicago Press.
</p>
<p>Vicente, K. (1999). Cognitive work analysis. Mahwah, NJ: Erlbaum.
Wallach, M. A., Kogan, N., &amp; Bem, D. J. (1964). Diffusion of responsibility and level of risk
</p>
<p>taking in groups. Journal of Abnormal and Social Psychology, 68, 263&ndash;274.
Westie, F. R., &amp; Westie, M. L. (1956). The social-distance pyramid: Relationships between caste
</p>
<p>and class. American Journal of Sociology, 63, 190&ndash;196.
Wetherell, C., Plakans, A., &amp; Wellman, B. (1994). Networks, neighborhoods, and communities:
</p>
<p>Approaches to the study of the community question. Urban Affairs Quarterly, 14(3), 363&ndash;390.
Wiener, E., Kanki, B., &amp; Helmreich, R. L. (Eds.). (1993). Cockpit Resource Management.
</p>
<p>London, UK: Academic Press.
</p>
<p>252 8 Social: Social Cognition and Teamwork</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 9
</p>
<p>Social: Theories and Models
</p>
<p>Abstract In the previous chapter we introduced concepts related to teams and
</p>
<p>teamwork. This chapter provides concepts for analyzing, interpreting, and modeling
</p>
<p>how teams work. We turn to models of social communication and coordination that
</p>
<p>have gained prominence as we think about people in technical and social networks
</p>
<p>and at higher levels of organization. This chapter introduces some of the many
</p>
<p>concepts, theories, and results related to social processes that can influence system
</p>
<p>design, and also notes how to model social processes for use as theories and for
</p>
<p>applications.
</p>
<p>9.1 Introduction
</p>
<p>As distributed, networked computing systems have become increasingly part of
</p>
<p>our everyday lives, new models for understanding group and team communication
</p>
<p>have arisen. Kang (2000, p. 1150) has noted that for the Internet, at least, the killer
</p>
<p>app is other people. It is certainly the case that our understanding of human&ndash;human
</p>
<p>interaction has evolved since the introduction of rich media connections. In part
</p>
<p>this is due to the fact that so many new forms of interaction have arisen since the
</p>
<p>development of the Internet. Thirty years ago, the idea that we would be able to
</p>
<p>videoconference in real time with colleagues and friends on the other side of the
</p>
<p>planet from a mobile phone was considered science fiction. Now it is a frequent if
</p>
<p>not commonplace occurrence.
</p>
<p>In addition to making use of these innovations, we are also able to mine and
</p>
<p>analyze behavioral data at fine-grained levels of detail. All transactions online can
</p>
<p>be recorded and studied for interaction patterns at various levels of abstraction.
</p>
<p>Studies have combined observational and logged, transaction and activity data to
</p>
<p>look at email use in organizations (e.g., Desanctis and Monge 1998) and across
</p>
<p>national and cultural boundaries (Rutkowski et al. 2002), to study the use of text-
</p>
<p>based virtual environments for work coordination and collaboration (Churchill and
</p>
<p>Bly 1999), to consider how graphical virtual environments enable collaborative
</p>
<p>F. E. Ritter et al., Foundations for Designing User-Centered Systems,
DOI: 10.1007/978-1-4471-5134-0_9, ï¿½ Springer-Verlag London 2014
</p>
<p>253</p>
<p/>
</div>
<div class="page"><p/>
<p>activity (Fig. 9.1; also see Churchill et al. 2001), to address how real-time ren-
</p>
<p>dering and manipulation of data visualizations affect mediated collaborations
</p>
<p>(Snowdon et al. 2003), and to understand more deeply the impact of networked
</p>
<p>mobile devices on ongoing work and recreational practices (e.g., Brown et al.
</p>
<p>2001). Research is turning to consideration of how tools like LinkedIn, Facebook,
</p>
<p>and Twitter play into organizational information sharing (e.g., Zhao and Rosson
</p>
<p>2009), and how enterprises are using their own internal bookmark sharing tools to
</p>
<p>foster deeper collaboration between their staff (e.g., Millen et al. 2006).
</p>
<p>Figure 9.2 reminds us that social aspects of systems, like other aspects of
</p>
<p>interfaces noted earlier, do not guarantee success. They are just another factor to
</p>
<p>consider&mdash;another cause of risks, or another way to ameliorate risks in systems.
</p>
<p>In this chapter we complement content in Chap. 8, introducing concepts, the-
</p>
<p>ory, and data related to social aspects of face-to-face and mediated communication
</p>
<p>and collaboration in our current world of pervasive, networked connectivity.
</p>
<p>9.2 Analyzing How People Work Together
</p>
<p>9.2.1 Introduction
</p>
<p>As discussed in Chap. 8, people work together in different ways. Ideally you want
</p>
<p>them to collaborate and cooperate to carry out any shared tasks that they may have.
</p>
<p>When designing a system this means that you want to support collaboration and
</p>
<p>cooperation where it is appropriate, and avoid having people spend time inter-
</p>
<p>acting with the system when they should be more concerned with carrying out the
</p>
<p>task at hand. It is, therefore, important to understand how people collaborate and
</p>
<p>cooperate.
</p>
<p>There are several ways in which social interactions can be analyzed. Here we
</p>
<p>consider three types of analysis that are quite widely used. The first type is fairly
</p>
<p>informal and is often used to analyze pairwise interactions, as happens in con-
</p>
<p>versation, for example. The second analyzes interactions in terms of costs and
</p>
<p>benefits, and is sometimes described as a payoff approach. The third involves
</p>
<p>applying network theory to emphasize the inter-relationships between actors
</p>
<p>across interactions.
</p>
<p>9.2.2 Informal, Pairwise Analyses
</p>
<p>The simplest way of analyzing social interactions is fairly informal. It simply notes
</p>
<p>results and regularities that appear in social behavior. This is a type of framework
</p>
<p>in that it provides some common terms across analyses, and some basic
</p>
<p>assumptions, but does not provide or require that the results across analyses fit
</p>
<p>254 9 Social: Theories and Models</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8">http://dx.doi.org/10.1007/978-1-4471-5134-0_8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8">http://dx.doi.org/10.1007/978-1-4471-5134-0_8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8">http://dx.doi.org/10.1007/978-1-4471-5134-0_8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8">http://dx.doi.org/10.1007/978-1-4471-5134-0_8</a></div>
</div>
<div class="page"><p/>
<p>together, and it is not organized on a higher level. This level of analysis is often
</p>
<p>used to look at how pairs of actors interact in a local manner, for example, during
</p>
<p>conversation and turn-taking in conversation. The framework varies widely
</p>
<p>between researchers, and is not extensively covered here because it varies so
</p>
<p>widely and is difficult to build a model from. However, it is often used, and
</p>
<p>provides some insights to help build systems.
</p>
<p>Fig. 9.1 View of an author&rsquo;s avatar in second life watching another avatar give a talk to a live
audience that was also broadcast into second life. This set-up, which was used to support remote
viewing at a workshop on social modeling, shows how social interactions can occur
simultaneously at multiple levels
</p>
<p>Fig. 9.2 Including social
aspects in your computer
application (i.e., Zune),
however, does not guarantee
success compared to systems
with less social aspects.
(Photo taken at Circuit City in
February 2009, as Circuit
City was having a going-out-
of-business sale)
</p>
<p>9.2 Analyzing How People Work Together 255</p>
<p/>
</div>
<div class="page"><p/>
<p>When people work together on a one-to-one basis (in dyads or pairs), the way
</p>
<p>they communicate can be understood using techniques such as conversation
</p>
<p>analysis and linguistic analyses of the creation of a shared model or common
</p>
<p>ground (e.g., Clark and Brennan 1991a, b; Gottman et al. 2005; Sacks 1992; ten
</p>
<p>Have 1999). The notion of common ground also applies to communication among
</p>
<p>larger groups.
</p>
<p>If you analyze how people talk to one another you will quickly see that it is rare
</p>
<p>for them to speak in full sentences and to always wait politely for the other person
</p>
<p>to finish before starting to speak themselves. The overall aim of this level of
</p>
<p>analysis is usually to generate a shared mutual understanding of the situation at
</p>
<p>hand. This can provide insights of how to support computer-supported commu-
</p>
<p>nication (see, for example, Brennan 1998). For example, if the length of a pause in
</p>
<p>conversation is 1s, then if there are lags in the network approaching 1s, some users
</p>
<p>will start talking too soon (Ruhleder and Jordan 1999). If the task is computer-
</p>
<p>based (or at least requires information from the system), you will need to under-
</p>
<p>stand what sort of information is needed and used, and present it in such a way that
</p>
<p>it helps to facilitate a shared mental model of the situation between those com-
</p>
<p>municating. Conversational analysis and the concept of common ground also are
</p>
<p>useful for analyzing larger groups.
</p>
<p>9.2.3 Exchange Costs and Benefits
</p>
<p>The second type of analysis involves looking at the costs and benefits of social
</p>
<p>interactions, a so-called payoff approach. In this approach, each interaction has
</p>
<p>associated with it a cost, a benefit (sometimes called a payoff), or both. Work in
</p>
<p>game theory will often lump costs and benefits together and call them payoffs. This
</p>
<p>approach has been used in many fields, but it is probably most closely associated
</p>
<p>with economics where it is extensively used (e.g., Levitt and Dubner 2005).
</p>
<p>There are situations where people who are supposed to work together to achieve
</p>
<p>a particular goal, or perform a particular task, do not do so. Instead, they may pursue
</p>
<p>individual goals and decide what is best for themselves on the basis of the costs and
</p>
<p>benefits involved. In many cases, the payoffs are not financial rewards, but can be
</p>
<p>things like improved social status, for example, which is how companies entice
</p>
<p>people to provide useful content for their internal social networking applications.
</p>
<p>The problems that can arise when people pursue individual goals (and payoffs)
</p>
<p>are highlighted by the classical Prisoner&rsquo;s Dilemma (PD) problem (Axelrod 1984).
</p>
<p>The central dilemma is whether to think about the costs and payoffs altruistically
</p>
<p>(as they affect the pair jointly), or as they affect each prisoner individually. You
</p>
<p>can see the costs and payoffs by drawing a matrix for all of the actors involved,
</p>
<p>like that shown in Table 9.1 for a Prisoner&rsquo;s Dilemma problem with two prisoners.
</p>
<p>In the Prisoner&rsquo;s Dilemma, two prisoners have been caught doing something
</p>
<p>illegal, and can either plead not guilty or plead guilty giving state&rsquo;s evidence
</p>
<p>256 9 Social: Theories and Models</p>
<p/>
</div>
<div class="page"><p/>
<p>against the other. These two decisions or strategies are usually called cooperate
</p>
<p>(with the other prisoner) or defect (on the other prisoner). The payoff if the two
</p>
<p>prisoners cooperate with each other and plead not-guilty is that they both go to
</p>
<p>prison for 1 year. If one prisoner defects and testifies against the other, they walk
</p>
<p>free but the other prisoner serves 10 years. If both prisoners defect, they share the
</p>
<p>full blame and get 8 years each.
</p>
<p>Where there are costs and benefits involved in carrying out shared tasks, the
</p>
<p>costs should be kept as low as possible (not necessarily minimized), and the
</p>
<p>benefits should be kept as high as possible (not necessarily maximized). In any
</p>
<p>trade-off the benefits should be designed to outweigh the costs. If you think of
</p>
<p>online file sharing and email, for example, these have both radically reduced the
</p>
<p>costs of sharing information, sometimes with unanticipated effects, such as too
</p>
<p>much sharing.
</p>
<p>Using a payoff matrix approach can be helpful in representing tasks where
</p>
<p>social interaction is involved, even if there is no dilemma involved. Thus a matrix
</p>
<p>can be used to show the payoff for asking questions in class, for responding to
</p>
<p>emails, and so on. The payoff matrix approach can be applied to situations that
</p>
<p>involved more than two strategies, more payoffs, and more players, although it
</p>
<p>becomes harder to draw the matrix as the numbers involved increase. You should
</p>
<p>also note that the players do not need to have equivalent payoffs: for example, the
</p>
<p>payoffs for teachers and for students in a class are different.
</p>
<p>Note that some matrices do not have a single best choice (when there is a stable
</p>
<p>choice that maximizes the payoff for both parties, it is known as a Nash equilib-
</p>
<p>rium point). If you have played Paper Rock Scissors, you know that paper covers
</p>
<p>rock, that rock breaks scissors, and that scissors cuts paper&mdash;there is not a choice
</p>
<p>that beats all the others. Similarly, if you play video games, you can create payoff
</p>
<p>matrices for different pieces playing against each other, for example, in Command
</p>
<p>and Conquer, for tanks vs tanks, tanks vs infantry, and tanks vs planes, etc. In each
</p>
<p>case, there may not be a dominant decision or choice that is better than all others.
</p>
<p>Axelrod (1984) studied what happens when the PD game is played multiple
</p>
<p>times, also called an iterated Prisoner&rsquo;s Dilemma game. When the game is played
</p>
<p>repeatedly there is a chance for cooperation to emerge. If you defect early, your
</p>
<p>colleague may stop trusting you. If you cooperate longer, some opponents may not
</p>
<p>defect. If the game is ongoing, the promise of cooperation with a positive payoff
</p>
<p>Table 9.1 A typical prisoner&rsquo;s dilemma payoff matrix
</p>
<p>Prisoner 1 Prisoner 2
</p>
<p>Cooperate
(with prisoner 1)
</p>
<p>Defect
(on prisoner 1)
</p>
<p>Cooperate (with prisoner 2) Both prisoners get 1 year
in jail
</p>
<p>10 years for prisoner 1
Prisoner 2 goes free
</p>
<p>Defect (on prisoner 2) 10 years for prisoner 2
Prisoner 1 goes free
</p>
<p>Both prisoners get 8 years in jail
</p>
<p>9.2 Analyzing How People Work Together 257</p>
<p/>
</div>
<div class="page"><p/>
<p>for cooperation can lead to the best behavior for both participants. Overall,
</p>
<p>Axelrod found that a very good&mdash;and perhaps the best&mdash;strategy was to play tit-
</p>
<p>for-tat, which involves starting by cooperating, then if an opponent defects, you
</p>
<p>defect once, and then cooperate again.
</p>
<p>There are several practical suggestions for improving social situations arising
</p>
<p>out of Axelrod&rsquo;s work. These suggestions, some of which are noted in Table 9.2,
</p>
<p>can be applied to system design, and you can see them play out on eBay, on
</p>
<p>YouTube, and in Second Life. These suggestions apply to teamwork across a wide
</p>
<p>range of domains. When they are applied across companies, however, they can
</p>
<p>give rise to cartels and price fixing.
</p>
<p>One thing that you will need to consider when designing systems that support
</p>
<p>teamworking is that it will often take time for people to learn how to work
</p>
<p>together. In other words, the strategies that they start with may change over time as
</p>
<p>they learn how each other operates, and how they can work together to perform the
</p>
<p>task at hand. In repeated iterations of the Prisoner&rsquo;s Dilemma game, for example,
</p>
<p>Axelrod (1984) found that people can move towards a strategy of mutual coop-
</p>
<p>eration over time. So you should try to support cooperation, and Axelrod suggested
</p>
<p>five ways in which this can be achieved, as shown in Table 9.3.
</p>
<p>These suggestions apply to many situations, including classrooms, work envi-
</p>
<p>ronments (including knowledge sharing tools), web site maintenance, online
</p>
<p>auction sites, and public discussion forums.
</p>
<p>To enlarge the shadow of the future you need to have people look beyond the
</p>
<p>current iteration of the task. They need to see that there is a bigger picture in that
</p>
<p>there may be higher level, longer term goals that need to be achieved, and that this
</p>
<p>Table 9.2 Suggestions for how to do well in iterated PD games (Axelrod 1984)
</p>
<p>1. Do not be envious: if you are envious in a situation where the payoffs are not symmetrical&mdash;the
other player gains more when you both cooperate&mdash;you may be tempted to defect, but in
doing so you may hurt yourself as well as the other player
</p>
<p>2. Do not be the first to defect: this will allow you the chance to make a series of cooperative turns
</p>
<p>3. Reciprocate both cooperation and defection: if the other person is choosing to defect and to
cooperate, modifying your strategies reminds them of the potential payoff, and encourages
them to choose a long-term strategy
</p>
<p>4. Do not be too clever: you may be tempted to defect more often to take a little payoff now and
then. This may be possible in some games against some players, but Axelrod showed that this
strategy rarely ever works. In the real world, it appears to work sometimes, but often it does not
</p>
<p>Table 9.3 Suggestions for how to promote cooperation between actors (Axelrod 1984)
</p>
<p>1. Enlarge the shadow of the future
</p>
<p>2. Change the payoffs
</p>
<p>3. Teach people to care about each other
</p>
<p>4. Teach reciprocity
</p>
<p>5. Improve recognition abilities
</p>
<p>258 9 Social: Theories and Models</p>
<p/>
</div>
<div class="page"><p/>
<p>task will be repeated, usually by the same people. This should help to change the
</p>
<p>perspective of the team members from one that may be initially oriented towards
</p>
<p>competition to one that supports cooperation.
</p>
<p>The second suggestion, change the payoffs, is perhaps the easiest to influence.
</p>
<p>In the case of online communities this can be done by noting which people
</p>
<p>contribute the most. The form of the payoffs needs to be carefully worked out.
</p>
<p>They need not necessarily be financial. In social networks, prestige and recognition
</p>
<p>(which raise an individual&rsquo;s perceived status) are often valued more highly as
</p>
<p>rewards than monetary incentives.
</p>
<p>To teach people to care about each other requires including other people&rsquo;s
</p>
<p>payoffs in your own matrix. This may be purely altruistic, when team members
</p>
<p>care about other team members. In some cases, such as the prisoner&rsquo;s dilemma,
</p>
<p>other people&rsquo;s payoffs may influence your own payoff (positively or negatively).
</p>
<p>The fourth suggestion is to teach reciprocity. Participants should be taught to
</p>
<p>use tit-for-tat strategies. In social situations some people will always adopt a
</p>
<p>straight cooperation strategy, whilst others will adopt a defection strategy. Having
</p>
<p>some participants play tit-for-tat (reciprocity) and change strategy based on what
</p>
<p>others do helps to police the environment and protect those who cannot or will not
</p>
<p>follow a more aggressive strategy.
</p>
<p>Finally, the need to improve recognition abilities relates to the issue of trust. Most
</p>
<p>web sites with forums require you to register to make comments. When you buy
</p>
<p>online you want to know who you are interacting with. Companies, both real and
</p>
<p>online, tell you how long they have existed, how to find and contact them, and what
</p>
<p>organizations they belong to (like chambers of commerce). By making themselves
</p>
<p>more recognizable (and establishing their credentials), others can tell who they are
</p>
<p>working with, and can expect to find them again if they return later to the same place.
</p>
<p>Note that cooperation is not necessarily always a good thing. In regulation, rule
</p>
<p>enforcement, and auditing situations, for example, you do not want the inspectors
</p>
<p>to have a long-term relationship with the party being inspected. Long-term rela-
</p>
<p>tionships in these cases lead to cooperation, not enforcement.
</p>
<p>You should also be aware that supporting teamwork with team goals may lead
</p>
<p>to social loafing. This is where team members get a payoff based on the team&rsquo;s
</p>
<p>overall performance, rather than on their individual performance. Some team
</p>
<p>members may decide that this means that they can achieve their payoff without
</p>
<p>pulling their weight and contributing as much as the other members.
</p>
<p>All these suggestions can be used to improve social interactions in large,
</p>
<p>complex systems where social factors are at play. Consider as an example eBay.
</p>
<p>On an individual level it implements many or all of these suggestions: eBay does
</p>
<p>not publish the profits of individuals (it cannot, but it would not). It does not
</p>
<p>defect; it cooperates and prosecutes (or drops sellers). It does not have a complex
</p>
<p>set of rules. On the level of its community, it encourages through its page design
</p>
<p>future sales. It takes steps to make the payoffs better with cooperation between
</p>
<p>buyer and seller and with eBay. We do not know whether it teaches about caring
</p>
<p>9.2 Analyzing How People Work Together 259</p>
<p/>
</div>
<div class="page"><p/>
<p>about one another, but eBay itself will help teach reciprocity&mdash;if you violate their
</p>
<p>rules they will remove you from the system. And, finally, it certainly cares about
</p>
<p>and works towards improving the ability to recognize buyers and sellers, serving as
</p>
<p>a type of recognition for sellers.
</p>
<p>9.2.4 Networks
</p>
<p>Another way to analyze social interactions is by using network theory (see, for
</p>
<p>example, Rainie et al. 2012; Watts 2003). This approach emphasizes how the
</p>
<p>actors are associated across multiple interactions, including how well connected
</p>
<p>they are, and who they are connected to.
</p>
<p>People are linked to other people in many different ways. They can have family
</p>
<p>connections, or they may be work colleagues, for example. These relationships are
</p>
<p>a type of social capital. They can be represented using networks, which can be
</p>
<p>drawn graphically, showing people as nodes, and the relationships as links. An
</p>
<p>example of a network is shown in Fig. 9.3. Node 13 is the least well connected;
</p>
<p>node 14 has the most connections; nodes 6, 7, and 14 have the strongest
</p>
<p>connections. A more complex example is included as Sect. 9.2.5. The way that
</p>
<p>networks function can have some implications for the system that you are
</p>
<p>designing.
</p>
<p>Leadership in networks. It is often useful to be aware of which nodes in a
</p>
<p>network are the most important, because all the nodes may not be equally
</p>
<p>important. If you know which nodes link groups within the network, you can make
</p>
<p>use of them to beneficial effect. This is what advertisers attempt to do when they
</p>
<p>plan campaigns. If they target the nodes (people, locations, etc.) which link groups
</p>
<p>together, this can lead to campaigns going viral, rather than just being of interest to
</p>
<p>a local group in a network. A more complex example is included in the breakout
</p>
<p>box explaining how connections influence work in an electronics firm.
</p>
<p>The distance between two nodes can be calculated by identifying all the other
</p>
<p>nodes you need to pass through to get from the start node to the end node, and then
</p>
<p>adding up all the pairwise path lengths (between the adjacent nodes). If the two
</p>
<p>nodes are important (to the operation of the network, or the organization, and so
</p>
<p>on), then you may want to make sure there is more than one way to get from the
</p>
<p>start node to the end node, so that you can cope with failures of nodes or links. It
</p>
<p>turns out that the number of links that you need to get from one person to another
</p>
<p>can be quite small. This so-called small world problem is the basis for the film The
</p>
<p>Six Degrees of Kevin Bacon. Essentially, you know somebody who knows
</p>
<p>somebody who&hellip; who knows somebody who knows Kevin Bacon.
</p>
<p>The small world phenomena. Perhaps the most common idea is based on
</p>
<p>connectivity between nodes, that is, what is the shortest path between two nodes?
</p>
<p>How many people would a letter from one person to another have to pass through,
</p>
<p>or how many introductions would you have to have to meet Brad Pitt? In a
</p>
<p>company or even the world, what is the longest path between any two people?
</p>
<p>260 9 Social: Theories and Models</p>
<p/>
</div>
<div class="page"><p/>
<p>Mathematically, this problem is well defined. The answer is the maximum
</p>
<p>length of a path between every pair of nodes in a network. A more complete
</p>
<p>answer is the distribution of path lengths, that is, what are all the paths lengths for
</p>
<p>the network. Some networks, linearly connected, would have the longest average.
</p>
<p>These would be like telegraph stations in the old west. Networks that are com-
</p>
<p>pletely connected, where every node knows every other node, like a grade school
</p>
<p>classroom, would have a maximum length of 1. Unconnected nodes would have
</p>
<p>either an undefined answer or infinity as their path length. If you were looking at
</p>
<p>this in a more applied context, you might also examine the cost of the links (e.g.,
</p>
<p>the distance between people, and how much information can pass between them).
</p>
<p>This question has been studied a few times, and the answers are less clear for
</p>
<p>people in more interesting situations. Milgram (1967) performed the first experi-
</p>
<p>ment. In this experiment he handed out a folder to be sent to someone the initiating
</p>
<p>agent did not know. He recorded how many people the folder passed through
</p>
<p>before it reached the target. The results were reported as between two and ten, with
</p>
<p>five as the median. The study, while intriguing, is deeply flawed. Most of the
</p>
<p>folders were not successfully returned, but we do not really know why. It could be
</p>
<p>that the world is large, or that the subjects were not motivated or the task was too
</p>
<p>hard. The minimum was not six, but ten, and it was a distribution. Numerous
</p>
<p>attempts have been made to duplicate this work. Later work with the real world
</p>
<p>(e.g., Travers and Milgram 1969) and with email (e.g., Dodds et al. 2003) has had
</p>
<p>the same problems, that of not having every package delivered (sometimes around
</p>
<p>1%). On the other hand, work with closed worlds&mdash;for example, how well sci-
</p>
<p>entific authors are connected&mdash;does not find a minimum, because there are lots of
</p>
<p>unconnected nodes that only publish one paper. The averages, however, seem to
</p>
<p>suggest that those that are connected are not so far apart.
</p>
<p>What does this mean for system design? It suggests that providing referrals can
</p>
<p>be worthwhile but not guaranteed. It suggests that most&mdash;but probably not all&mdash;
</p>
<p>people are well connected, that pairs of people who are long strings of connections
</p>
<p>apart are somewhat rare. It remains an interesting theory and empirical problem that
</p>
<p>is difficult to study completely because of the difficulty in obtaining complete data.
</p>
<p>The Dunbar number. Some people may only have a single connection (they
</p>
<p>would have to have at least one connection to be part of a network), whilst others
</p>
<p>may have lots of connections. The maximum number of connections, or the largest
</p>
<p>degree that a node can have in a social network, is called the Dunbar number
</p>
<p>7
</p>
<p>14
</p>
<p>6
</p>
<p>13
Fig. 9.3 An example small
network. Nodes are agents.
Solid lines are solid
connections. Dashed lines are
weaker connections
</p>
<p>9.2 Analyzing How People Work Together 261</p>
<p/>
</div>
<div class="page"><p/>
<p>(Dunbar 1992). He related the maximum productive group size to the size of the
</p>
<p>neocortex in primates, and in reference to strong social relationships, not distant or
</p>
<p>distal ones. The number is related to the question &lsquo;&lsquo;how much time do you have to
</p>
<p>maintain close social ties&rsquo;&rsquo;? Some of his ideas do not fully apply to the online
</p>
<p>world, and some of the data he presents seem anecdotal. Further writers and
</p>
<p>researchers have had a hard time coming to grips with the question; for example, it
</p>
<p>has been speculated that the scientific subspecialties can&rsquo;t be more than 150 sci-
</p>
<p>entists because of this effect (but this then implies that either the scientists have no
</p>
<p>other friends, or that they can handle exactly twice as many as other people!). How
</p>
<p>do you measure relationship strength? What counts as a strong relationship? Does
</p>
<p>improved communication media improve the ability to have a larger number of
</p>
<p>ties? Nevertheless, it remains a useful question, and has implications for system
</p>
<p>design, and limits are being applied in some systems.
</p>
<p>What is perhaps most important from a system design point of view is the active
</p>
<p>connections. In other words, the connections that are used rather than dormant. If
</p>
<p>you think about Facebook, for example, some people will boast about having, say,
</p>
<p>352 Facebook friends, but when you analyze how many people they really interact
</p>
<p>with, the number is much smaller, by a factor of between 10 and 100. If all of the
</p>
<p>Facebook friend connections were active, it would be a full time job for an
</p>
<p>individual just to monitor their friend&rsquo;s ongoing activity.
</p>
<p>The concept of the Dunbar number provides suggestions of how many social
</p>
<p>connections systems should support. For example, how many email aliases should
</p>
<p>you support in an email program, or how many names can be on an email alias?
</p>
<p>What are optimal sized online groups? Can a classroom of 150 students (online or
</p>
<p>in a building) be a group, or can it only be a group of groups?
</p>
<p>9.2.5 Good Personal Social Networks Lead to Better Work1
</p>
<p>Burt (2004) examined how well the managers in an electronics company were
</p>
<p>connected to other parts of the company. This work serves as a good example of what
</p>
<p>implications there are for and from networks for designing teams and systems to
</p>
<p>support them, as well as how social networks influence systems. Burt computed how
</p>
<p>connectedness correlated with objective measures of job performance (i.e., salary
</p>
<p>and promotions) and howwell connectedness correlated with subjective measures of
</p>
<p>performance (i.e., job evaluations and evaluations of their ideas by supervisors).
</p>
<p>This is a type of network analysis, in that Burt examined how the managers
</p>
<p>were connected to groups in the company, and to whom. A summary is shown in
</p>
<p>Fig. 9.4. He also used the term structural holes, which occur when two groups that
</p>
<p>should be connected are not. For example, if two groups working on related,
</p>
<p>1 Umer Farooq brought this work to our attention as part of a talk by Peter Pirolli. We thank
Umer and Peter for their help.
</p>
<p>262 9 Social: Theories and Models</p>
<p/>
</div>
<div class="page"><p/>
<p>but different, topics should know about each other&rsquo;s work, but do not, then a
</p>
<p>structural hole is said to exist. Management works hard to avoid such a lack of
</p>
<p>connections, but there are often more holes than management can know about and
</p>
<p>fill. (Informal connections, family connections, and company sports teams are
</p>
<p>ways that such holes are sometimes filled). Figure 9.4 shows a structural hole
</p>
<p>between groups A and C&mdash;there is no direct connection between the two groups.
</p>
<p>Burt&rsquo;s results showed the importance of social networks in work settings.
</p>
<p>Managers that were better connected (had less network constraints on having
</p>
<p>people to talk with) had greater compensation, better evaluations, more promo-
</p>
<p>tions, and better ideas as judged by their peers. Some of these results are shown in
</p>
<p>Fig. 9.5, which shows that being better connected (lower network constraints) led
</p>
<p>to higher salaries and better ratings of ideas by a neutral party. Overall, being
</p>
<p>better connected led to better performance in this type of job.
</p>
<p>This work makes several suggestions. It shows the utility of social network
</p>
<p>analyses. It suggests that good workers will attempt to be well connected, and that
</p>
<p>managers should attempt to fill in the gaps between groups.
</p>
<p>9.2.6 Summary
</p>
<p>This section has laid out several ways to organize social behavior, several
</p>
<p>frameworks for organizing the information in this chapter and from later
</p>
<p>Group A
</p>
<p>Robert
</p>
<p>1
</p>
<p>3
</p>
<p>2
</p>
<p>Michael
</p>
<p>5
</p>
<p>4
</p>
<p>Group C 
</p>
<p>Group B
</p>
<p>7
</p>
<p>8
</p>
<p>9
</p>
<p>10
</p>
<p>11
</p>
<p>12
</p>
<p>6
</p>
<p>13
</p>
<p>Fig. 9.4 A picture of a network of relationships. The people are the represented by the nodes,
and the relationships by the links between nodes (based on data from Burt 2004, Fig. 1,
simplified)
</p>
<p>9.2 Analyzing How People Work Together 263</p>
<p/>
</div>
<div class="page"><p/>
<p>readings. These frameworks use a high level of abstraction. They provide you
</p>
<p>with a way to organize what you learn. It is also worth noting that these
</p>
<p>frameworks need not be mutually exclusive. There are systems where multiple
</p>
<p>frameworks provide useful insights, and in any analysis of a large system both an
</p>
<p>exchange cost and a network view (or multiple network views) will be
</p>
<p>applicable.
</p>
<p>One example of the application of these theoretical approaches to keep in mind
</p>
<p>regarding the network representation is that a network&rsquo;s value for communication
</p>
<p>is approximately equal to the square of the number of people in the network. A
</p>
<p>telephone system, or a social web site, with two people has only one connection.
</p>
<p>With 4 people there are 12 potential connections, and with 10 people, 90 potential
</p>
<p>connections. This is typically called a network effect, and applies when networks
</p>
<p>are used for communication or social interaction.
</p>
<p>9.3 Higher Social Levels: Organizational and Cultural
</p>
<p>There are higher social levels than small groups. These higher levels are focused
</p>
<p>less on the user and more on the user&rsquo;s context. They can influence what happens
</p>
<p>at the interface between the user and the technology, however, so we describe
</p>
<p>them, albeit briefly.
</p>
<p>-4
</p>
<p>-3
</p>
<p>-2
</p>
<p>-1
</p>
<p>0
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>4
</p>
<p>5
</p>
<p>10 30 50 70 90
</p>
<p> Inverse Connectedness to Others 
(computed variable)
</p>
<p>c
</p>
<p>1.0
</p>
<p>1.5
</p>
<p>2.0
</p>
<p>2.5
</p>
<p>3.0
</p>
<p>3.5
</p>
<p>10 20 30 40 50 60 70 80 90 100
</p>
<p> Inverse Connectedness to Others  
</p>
<p>(a) (b)
</p>
<p>M
a
</p>
<p>n
a
</p>
<p>g
e
</p>
<p>m
e
</p>
<p>n
t 
</p>
<p>E
v
</p>
<p>a
lu
</p>
<p>a
ti
</p>
<p>o
n
</p>
<p> o
f 
</p>
<p>Id
e
</p>
<p>a
s
</p>
<p>S
a
</p>
<p>la
ry
</p>
<p> R
e
</p>
<p>la
ti
</p>
<p>v
e
 t
o
</p>
<p> P
e
</p>
<p>e
rs
</p>
<p>Fig. 9.5 Network constraint is a measure of how large, how close, and relative ranks of a
manager&rsquo;s connections. Low constraint indicates a well-connected manager. a Salary versus
inverse network size shows that better connected managers had higher salaries, and
b Ratings of ideas versus inverse network size shows that when two senior managers were
asked to rate ideas the better connected managers had more highly rated ideas (based on
Burt 2004, Fig. 4 and 5, but drawn with a spreadsheet available on the book website to
explore this topic)
</p>
<p>264 9 Social: Theories and Models</p>
<p/>
</div>
<div class="page"><p/>
<p>9.3.1 Organizational Effects
</p>
<p>Users working in teams are often part of organizations. These organizations will
</p>
<p>influence the team climate and provide both resources and obligations to teams.
</p>
<p>There is a separate area of research that studies how organizations work, as
</p>
<p>opposed to teams (e.g., Simon 1997).
</p>
<p>The network structures used to describe teams can be applied again to an
</p>
<p>organization, and indeed the figures of networks are typically scaled not for small
</p>
<p>teams but for organizations.
</p>
<p>The comments about small teams also apply to organizations in many ways.
</p>
<p>Organizations are better if they are made up of better people and if these people
</p>
<p>have the knowledge, skills, and abilities to perform their tasks. They work better if
</p>
<p>their structure is adapted to the task, and so on.
</p>
<p>As for teams, work is on going to provide computer support for organizations,
</p>
<p>perhaps even more so than for teams. It is clear that this computer support&mdash;if it is
</p>
<p>done mindlessly or without enough knowledge of the task, task distribution, and
</p>
<p>people&mdash;does not always help (e.g., see examples in Landauer 1995, or noted
</p>
<p>earlier in the book). However, there remain great possibilities for supporting teams
</p>
<p>with technology.
</p>
<p>The way organizations work is usually heavily based on procedures that describe
</p>
<p>the way things should be done. This can be called a normative (or prescriptive)
</p>
<p>view. These procedures are invariably different from reality, which can be called a
</p>
<p>descriptive view. Many organizations have suffered disastrous effects from com-
</p>
<p>puterization of processes because the official procedures were computerized with-
</p>
<p>out recognizing that the reality was different. Often the users are not themselves
</p>
<p>fully aware of the differences, and these can be quite extensive, and even when they
</p>
<p>are aware they may be reluctant to tell a manager or a consultant who will be
</p>
<p>reporting back to management about the shortcuts and common procedure viola-
</p>
<p>tions. The breach of procedures may only be that procedures are written as though
</p>
<p>they are performed by one person when they are, in fact, shared amongst a number
</p>
<p>of team members&mdash;or they may be written down as though they occur at one time
</p>
<p>without interruption when, in fact, they are always interleaved with numerous other
</p>
<p>similar tasks and problem solving. It might also be the case, and you can see this for
</p>
<p>yourself, that the forms and procedures ask for extensive information, and this is
</p>
<p>routinely not requested, not used, or does not have to be provided.
</p>
<p>9.3.2 Cultural Effects
</p>
<p>System behavior is the result of people interacting with technology in a context.
</p>
<p>That context includes the physical environment, as well as aspects such as the
</p>
<p>organizational structure, the culture of that organization, and possibly even
</p>
<p>9.3 Higher Social Levels: Organizational and Cultural 265</p>
<p/>
</div>
<div class="page"><p/>
<p>national cultural factors. When you are designing systems you need to study the
</p>
<p>environment in which the system will be deployed to make sure that it will be
</p>
<p>acceptable to the users and to reduce the risk that any assumptions or misunder-
</p>
<p>standings will lead to an unusable or unsafe system. There are numerous examples
</p>
<p>of lessons learned in this area (e.g., Olson and Olson 2003&ndash;2004).
</p>
<p>There is no magic bullet for avoiding these risks. There are several steps you
</p>
<p>can take. You can study the culture and laws by visiting the environment the
</p>
<p>system will be in, something that is advocated by techniques such as contextual
</p>
<p>design (Beyer and Holtzblatt 1999). You can read about the culture or have your
</p>
<p>own team members visit and work in the culture. You can include members of the
</p>
<p>culture in your design team. These members will not be perfect representatives,
</p>
<p>but will help avoid some problems and decrease the risk of system problems. You
</p>
<p>can also include time to pilot test and get feedback from users in that culture using
</p>
<p>a spiral design process (Boehm and Hansen 2001; Pew and Mavor 2007).
</p>
<p>9.3.3 Summary
</p>
<p>This section reminds us that, in addition to the users and their teams, there are
</p>
<p>higher social levels that will influence system design. These levels are important,
</p>
<p>but vary much more than users and even teams. As you start to design systems you
</p>
<p>should also consider that differences between your understanding and the actual
</p>
<p>levels can pose a risk to the success of your system.
</p>
<p>You should study these levels for a system to the point where you understand
</p>
<p>whether they pose risks and, if they do, reduce the risks through appropriate
</p>
<p>actions. Some of these may be done by changing the organization (difficult, but
</p>
<p>worthwhile where appropriate), or by changing the system to reflect the organi-
</p>
<p>zation, laws, and cultural reality.
</p>
<p>9.4 Models of Social Processes
</p>
<p>9.4.1 Introduction
</p>
<p>Models of social processes can serve as more concrete theories and they also
</p>
<p>&lsquo;&lsquo;have enormous potential to resolve the problem of system-team design&rsquo;&rsquo;
</p>
<p>(Kozlowski and Ilgen 2006). There is a range of models of social processes that
</p>
<p>can be created using existing tools and methods. These range from less formal
</p>
<p>representations that are not computer-supported that can help system design on the
</p>
<p>ground to computer-supported models of social processes that help provide policy
</p>
<p>guidance for governments (Fan and Yen 2004). This section introduces the range
</p>
<p>of these models by providing examples at several levels.
</p>
<p>266 9 Social: Theories and Models</p>
<p/>
</div>
<div class="page"><p/>
<p>As theories, these models provide a way to summarize behavior. That is, they
</p>
<p>provide a way to organize the results we have obtained about how people behave
</p>
<p>in groups into a single representation. The results can be used in system design and
</p>
<p>also as agents in video games and simulations. As theories they also provide
</p>
<p>suggestions about what we do not know and what we would like to know. As a
</p>
<p>simple example, some of these models work with small groups, but not with large
</p>
<p>groups. This difference suggests questions about how small and large groups work
</p>
<p>in different ways.
</p>
<p>We start here with descriptive theories that describe in declarative terms the
</p>
<p>structures and relationships of groups. A more complex model is a model that
</p>
<p>describes not only the structures but also how the structures are created and how
</p>
<p>they interact. We also describe two approaches to creating these models, the Soft
</p>
<p>Systems Methodology and Rich Pictures.
</p>
<p>9.4.2 Descriptive Social Models
</p>
<p>Descriptive models provide a description of the components of interest. These can
</p>
<p>be grouped into static and dynamic models. Both of these have been seen earlier in
</p>
<p>this chapter in the descriptions of networks.
</p>
<p>9.4.2.1 Ethnographic Descriptions of Social Processes
</p>
<p>Ethnography is studying the users in their environments, including the physical
</p>
<p>location and objects, who and what they interact with and how, why, and when,
</p>
<p>and what they think their interactions mean. Ethnography provides a way to
</p>
<p>summarize and discover how social factors interact with systems. This approach
</p>
<p>thus provides a way to reduce risks to systems because it helps the designer
</p>
<p>understand the context of how the system will be used. It is also really important to
</p>
<p>conduct observations of people in their normal settings because it reminds us that
</p>
<p>not all users are like us. Notably, many Internet companies have experienced
</p>
<p>failures in developing social experiences because they have not taken their users&rsquo;
</p>
<p>perspectives into account (Churchill 2010). Ethnographic studies can be started by
</p>
<p>reading about the culture of your users (e.g., military biographies if your users are
</p>
<p>in the military, about astronauts if they are astronauts, and about insurance claim
</p>
<p>adjusters if they are insurance claim adjusters). This work can also involve
</p>
<p>watching users do their work, or even participating in it (e.g., Coleman 1974
</p>
<p>studied ditch digging, restaurants, and garbage men; Suchman 1983 studied office
</p>
<p>work; see also Crabtree 2003; Plowman et al. 1995; Viller and Sommerville 2000).
</p>
<p>The take-away message here is that you need to study the social situation more the
</p>
<p>further it is from your own background.
</p>
<p>9.4 Models of Social Processes 267</p>
<p/>
</div>
<div class="page"><p/>
<p>9.4.2.2 Communities of Practice
</p>
<p>Another way is to view a set of people working with the same topic or task and
</p>
<p>their social connections as a community of practice (e.g., Wenger 1998). These
</p>
<p>communities can be seen in informal, recreational situations, such as party fishing
</p>
<p>boats (personal observation), to formal work situations such as in Japanese
</p>
<p>industry (Nonaka and Takeuchi 1995), and the wide range in between. Work on
</p>
<p>knowledge management and knowledge management systems has similar lessons
</p>
<p>on how groups work to help each other.
</p>
<p>This view of a community of practice encourages viewing the users as a
</p>
<p>community rather than as a set of individuals. Thus, individual users might have a
</p>
<p>problem, but the community may, as a group, have solved the problem.
</p>
<p>This view suggests that it is important to encourage users to communicate and
</p>
<p>to provide them with ways for them to interact over time, and to provide ways to
</p>
<p>acknowledge contributions and expertise. This approach is increasingly being used
</p>
<p>to help users help each other to solve a wide range of needs (e.g., Carroll et al.
</p>
<p>2006; El Helou et al. 2008). Further comments and suggestions on how to apply
</p>
<p>this approach are in the references and in the literature on communities of practice
</p>
<p>and on knowledge management systems.
</p>
<p>9.4.2.3 Static Models of Social Processes
</p>
<p>Some of the most influential, interesting, and easily approachable models appear to
</p>
<p>be network models of social processes. The earliest work in this area noted how
</p>
<p>everyone was &lsquo;&lsquo;connected to everyone else by only six degrees&rsquo;&rsquo; (Travers and
</p>
<p>Milgram 1969). That is, for every pair of people in the world, only five friendships
</p>
<p>were necessary to connect them. This work has been perhaps discredited now (with
</p>
<p>the answer that we do not actually know how well connected people are, but it
</p>
<p>might be that close for most but not all people), but the idea of how people are
</p>
<p>connected into a network remains a useful concept. It has been used to explain, for
</p>
<p>example, why Silicon Valley is successful, because there are multiple connections
</p>
<p>between people (Castilla et al. 2000). It has also been used to analyze the con-
</p>
<p>nectivity within groups (Carley 1996).
</p>
<p>These models are useful for system design in that they encourage you to keep in
</p>
<p>mind the connections between people, and to support connections and appropriate
</p>
<p>connections.
</p>
<p>9.4.2.4 Dynamic Models of Social Processes
</p>
<p>A more complex view of groups examines how the connections are formed and
</p>
<p>used, and the processes within the groups. These descriptive theories provide
</p>
<p>insights into how groups work and how to support them.
</p>
<p>268 9 Social: Theories and Models</p>
<p/>
</div>
<div class="page"><p/>
<p>A view of the stages that groups go through by Tuckman (1965) and then picked
</p>
<p>up by everyone (partly because it is useful and we think partly because the stages
</p>
<p>have fun names) notes that groups go through forming (orientation/testing/depen-
</p>
<p>dence), storming (conflict), norming (group cohesion), and performing (functional
</p>
<p>role-relatedness). This type of stage theory of group formation helps with defining
</p>
<p>group behavior, but more importantly makes predictions about how to help groups
</p>
<p>work better together. For example, it would be useful for teachers, managers, and
</p>
<p>group members to encourage activities that help groups transition through the early
</p>
<p>stages more productively and quickly. There are multiple ways to help groups form,
</p>
<p>from helping people meet to helping the groups know their tasks. Norming, for
</p>
<p>example, can be assisted by providing standards and behavior to compare.
</p>
<p>9.4.3 Soft Systems Methodology
</p>
<p>Soft Systems Methodology (SSM, Checkland 1981; Checkland and Scholes, 1999)
</p>
<p>has its roots in systems engineering, and builds on ideas from action research. It
</p>
<p>was developed as a move away from thinking about systems in hard engineering
</p>
<p>terms. So, instead of talking about social systems and technical systems, SSM
</p>
<p>treats purposeful action as a system: logically linked activities are connected
</p>
<p>together as a whole, and the emergent property of the whole is its purposefulness.
</p>
<p>SSM is based around a cycle of four activities:
</p>
<p>1. The problematic situation that requires action to improve it is identified
</p>
<p>2. Models of purposeful activity that are judged to be relevant to the identified
</p>
<p>situation are developed. Each of these models is built on the particular
</p>
<p>worldview of the different stakeholders
</p>
<p>3. The models are used for structuring discussions about the problematic situation.
</p>
<p>The goal is to find changes that are desirable and culturally feasible in that
</p>
<p>situation
</p>
<p>4. The actions that are needed to improve the situation are defined and, perhaps,
</p>
<p>implemented.
</p>
<p>Systems development usually starts with activity 1, although the other activities
</p>
<p>will often be carried out in parallel, and these can feed back into the other activities
</p>
<p>in the process. The discussions in activity 3, for example, may lead to an improved
</p>
<p>understanding of some of the more subtle aspects of the problematic situation
</p>
<p>(activity 1), which may lead to changes in the set of models developed in activity 2.
</p>
<p>One of the key features of SSM is its focus on developing an understanding of
</p>
<p>the problem (SSM uses the term problematic situation, which is more general).
</p>
<p>This understanding takes into account the roles, responsibilities, and concerns of
</p>
<p>the stakeholders that are associated with the particular problem. The understanding
</p>
<p>of the problem provides the basis for the solution, which again takes into account
</p>
<p>stakeholders&rsquo; differing viewpoints. SSM explicitly acknowledges that the final
</p>
<p>9.4 Models of Social Processes 269</p>
<p/>
</div>
<div class="page"><p/>
<p>solution is based on attempting to accommodate the views (and needs) of the
</p>
<p>various stakeholders.
</p>
<p>SSM is essentially an analytical approach, mostly focusing on organizational
</p>
<p>aspects of the system. It does not purport to support systems design. Although
</p>
<p>SSM does not deal explicitly with the technical system, it is possible to transform
</p>
<p>an activity model into an information model, by considering the sorts of infor-
</p>
<p>mation that are: (1) required to perform the activity and (2) generated by the
</p>
<p>activity. In this way an information system can be developed that supports the
</p>
<p>purposeful activity. SSM has also been used in the evaluation of existing infor-
</p>
<p>mation systems (Checkland and Poulter 2006).
</p>
<p>9.4.4 Rich Pictures
</p>
<p>Before designing any system, it is important to understand the environment (or
</p>
<p>context) in which that system will be embedded. There are several aspects to the
</p>
<p>environment that are critical to the system being acceptable to the end users. Some
</p>
<p>of these may seem trivial, such as the need for an available power supply to
</p>
<p>operate the system, and the need for space to house the required technology. Just
</p>
<p>walking around the working context can help you to identify the physical aspects
</p>
<p>of the environment that need to be considered.
</p>
<p>In addition to the physical aspects, there are social aspects too, which are often
</p>
<p>more subtle, and much harder to identify. Most work nowadays is a social activity,
</p>
<p>carried out by teams of people with a range of skills, who have to communicate
</p>
<p>and collaborate to make systems work, and to deliver services. There are some
</p>
<p>methods available to help you understand and take appropriate account of the work
</p>
<p>context when designing a system. One of the best known of these is Checkland&rsquo;s
</p>
<p>(1981) Rich Pictures, which are part of the Soft Systems Methodology described
</p>
<p>above. An example Rich Picture for the work context in a hospital neonatal
</p>
<p>intensive care unit is shown in Fig. 9.6 (Baxter et al. 2005). Rich pictures have
</p>
<p>been used to help analyze pubs, a web design consulting firm, and a cold storage
</p>
<p>warehouse (Monk and Howard 1998).
</p>
<p>The rich pictures are generated from semi-structured interviews that are carried
</p>
<p>out with representatives of each of the groups of system stakeholders. Interviewees
</p>
<p>are asked about their roles, responsibilities, and concerns. One typical way of
</p>
<p>identifying these is to ask the interviewee to talk you through what they would do
</p>
<p>in a typical day (or shift). That way, they tell you about the sort of jobs that they do
</p>
<p>and the people they have to work with, so you can go on to probe the issues
</p>
<p>further. The roles, responsibilities, and concerns are typically represented in
</p>
<p>simple pictures that show how the groups of stakeholders are linked.
</p>
<p>The rich pictures are annotated with text as appropriate, and supplemented by
</p>
<p>extended textual descriptions of how work is carried out. When you have created a
</p>
<p>draft of the rich pictures, you take them back to each of the interviewees to make
</p>
<p>sure that you have correctly captured what they told you.
</p>
<p>270 9 Social: Theories and Models</p>
<p/>
</div>
<div class="page"><p/>
<p>The problem with many design methods, however, including Rich Pictures, is
</p>
<p>that they require a lot of time and effort to carry them out properly. Nielsen (1993),
</p>
<p>Monk (1998), and Lewis and his colleagues (Blackmon et al. 2002; Lewis and
</p>
<p>Reiman 1998) have all proposed a range of lightweight or discounted methods that
</p>
<p>can inform design in a timely manner, without a massive investment in time, effort,
</p>
<p>and other resources. These lightweight methods are simplified versions of the
</p>
<p>larger methods.
</p>
<p>Lightweight rich pictures provide a useful way of showing the roles and
</p>
<p>responsibilities of the various system stakeholders along with any concerns they
</p>
<p>may have about the work system. To get a complete picture of the social and work
</p>
<p>contexts, it is useful to supplement rich pictures with background reading and,
</p>
<p>where possible, informal visits and meetings to the place where the system will be
</p>
<p>deployed; this is sometimes referred to as bootstrapping into the domain.
</p>
<p>As befits most pragmatic methods, lightweight rich pictures should be thought
</p>
<p>of as a framework rather than as a set of rules that have to be rigidly followed and
</p>
<p>applied. When carrying out a case study of a neonatal intensive care unit, for
</p>
<p>example, Baxter and his colleagues (Baxter et al. 2005) found that staff did not
</p>
<p>report any concerns. The rich pictures for the work context were drawn as two
</p>
<p>separate diagrams, highlighting the two most important aspects of the work con-
</p>
<p>text: communication and the use of written records. Both of these are social
</p>
<p>activities, and carrying out a rich picture analysis made it much quicker to see the
</p>
<p>importance of communication. Because communication is very much a social
</p>
<p>activity, and was central to the operation of the unit, it was important that the
</p>
<p>proposed new system did not detract from the existing levels of communication or
</p>
<p>block any communication channels.
</p>
<p>CLINICAL SERVICES 
</p>
<p>MANAGER
</p>
<p>LEAD 
</p>
<p>NURSE
</p>
<p>WARD 
</p>
<p>CLERKS
</p>
<p>PORTERS
</p>
<p>PARENTS
</p>
<p>PATIENTS
</p>
<p>SENIOR NURSES
</p>
<p>NURSES
</p>
<p>PHARMACIST
</p>
<p>CONSULTANTS
</p>
<p>REGISTRARS
</p>
<p>JNR DOCTORS (SHOs)
</p>
<p>Outside world: 
</p>
<p>labs, other depts., 
</p>
<p>specialist staff, 
</p>
<p>other hospitals 
</p>
<p>etc.
</p>
<p>OUTREACH 
</p>
<p>NURSES
</p>
<p>Communication Frequency:
</p>
<p>High 
</p>
<p>Medium
</p>
<p>Low 
</p>
<p>Fig. 9.6 A Rich picture for
the work context in a hospital
neonatal intensive care unit
(adapted from Baxter et al.
2005)
</p>
<p>9.4 Models of Social Processes 271</p>
<p/>
</div>
<div class="page"><p/>
<p>9.4.5 Computational Models of Social Behavior
</p>
<p>As social models get more complex, it becomes necessary to use computers to
</p>
<p>implement them and their predictions. Analytic models simulate the social pro-
</p>
<p>cesses but without modeling the individual transactions in detail. Process models
</p>
<p>model the information processing that is performed and they will typically also
</p>
<p>model the interactions between agents.
</p>
<p>9.4.5.1 Analytic Models
</p>
<p>Analytic models provide a description of a social process. They may include
</p>
<p>equations for how often people meet, or how often and what they communicate.
</p>
<p>These equations are used to simulate how the social process unfolds.
</p>
<p>As an example, a group of researchers modeled the transmission of a possible
</p>
<p>influenza pandemic (Halloran et al. 2008). It can be viewed as a social model (as
</p>
<p>well as a epidemiological model) because it primarily models social interactions
</p>
<p>between people at schools, work, home, and neighborhoods. It uses equations to
</p>
<p>model how often people interact, how often a disease would be transmitted, and
</p>
<p>the impact of medical interventions to stop the transmission of the disease.
</p>
<p>Importantly, these simulations explore how well public health interventions would
</p>
<p>be followed and what would be the impact of these interventions on the spread of
</p>
<p>the disease. The authors argue that the results are not accurate enough to be
</p>
<p>predictions, but are useful for framing the discussion of how to handle pandemics,
</p>
<p>and which interventions to consider. For example, closing schools is one that is
</p>
<p>both easy to follow and greatly helps reduce the spread of disease. These simu-
</p>
<p>lations do not cover the details, but they present a broad description of a large
</p>
<p>social system. The Halloran et al. (2008) work modeled the population of greater
</p>
<p>Chicago of 8.6 million people. This is one of the largest social simulation models
</p>
<p>we know.
</p>
<p>9.4.5.2 Process Models
</p>
<p>As social processes are being better formulated, there has been an increase in
</p>
<p>modeling them using information processing models. These models simulate
</p>
<p>smaller groups, ranging from 2 to 100 people.
</p>
<p>Current examples include work on optimizing the structures of groups to
</p>
<p>increase performance (e.g., Levchuk et al. 2002), creating models for use as col-
</p>
<p>leagues and adversaries (Jones et al. 1999; Tambe et al. 1995; Zachary et al. 2001),
</p>
<p>and fundamental work on understanding how changes in group processes and
</p>
<p>individual behavior lead to changes in group performance (e.g., Carley 1996). This
</p>
<p>is an exciting emerging field, and further examples are available from conferences
</p>
<p>272 9 Social: Theories and Models</p>
<p/>
</div>
<div class="page"><p/>
<p>in AI and in organizational process, and in the Journal of Mathematical Sociology
</p>
<p>and Computational and Mathematical Organization Theory. Search engines can
</p>
<p>provide further references.
</p>
<p>9.4.6 Summary
</p>
<p>These approaches to modeling social processes offer different advantages and
</p>
<p>disadvantages. The analytic models can represent large systems, over millions of
</p>
<p>entities. They can be used to provide useful suggestions for public policy. On the
</p>
<p>other hand, their details get applied millions of times and their assumptions can
</p>
<p>become very important but at the same time hard to know.
</p>
<p>The process models work harder to get the details right on a more fine-grained
</p>
<p>level but have difficulty scaling. Process models can be used to provide useful
</p>
<p>suggestions on smaller scale systems, but they cannot provide as many suggestions
</p>
<p>on large scale systems because they cannot simulate very large systems because
</p>
<p>they require so much computational power. They are useful, however, in simu-
</p>
<p>lations and games because they can live in an environment.
</p>
<p>9.5 General Implications for System Design
</p>
<p>Whenever you design a new system, it will almost invariably be a socio-technical
</p>
<p>system (the main exceptions are some deeply embedded systems that speak only to
</p>
<p>other pieces of technology). In other words, there will be a social system involved.
</p>
<p>You will need to take account of that social system, because the technology and
</p>
<p>the social system will be interdependent and interact. If you do not spend time and
</p>
<p>effort understanding the existing social system, you run the risk of adversely
</p>
<p>affecting it&mdash;if staff have to spend more time on interacting with the new tech-
</p>
<p>nology that takes away time from communication or learning, for example&mdash;and
</p>
<p>can end up in the situation where staff will simply stop using the new technology
</p>
<p>because it gets in the way of them doing their job.
</p>
<p>Many of the implications for system design require you to think about the
</p>
<p>impact of the system that you are designing. In some cases there will be aspects of
</p>
<p>interaction that you can build into your system, but in others it will be a case of
</p>
<p>making sure that what you have designed does not take anything away from what
</p>
<p>already exists (or if it does, it improves the overall socio-technical system). The
</p>
<p>modeling tools and techniques described in Sect. 9.8 should help.
</p>
<p>The first thing you need to consider is how people work together in the envi-
</p>
<p>ronment where your system will be deployed. If you are putting a global system in
</p>
<p>place, along the lines of YouTube for example, which has distributed users, you
</p>
<p>may want to create local regions within the system that will help to encourage use
</p>
<p>and participation. You will also need to think about creating the most appropriate
</p>
<p>9.4 Models of Social Processes 273</p>
<p/>
</div>
<div class="page"><p/>
<p>social distances between people, either increasing it, through the use of formal
</p>
<p>titles (e.g., Dr. Ritter), or reducing it by just using first names (e.g., Frank) or
</p>
<p>nicknames (Killer-ace).
</p>
<p>The way that people interact will be affected by the goals, costs, and payoffs
</p>
<p>(benefits) involved, so you should make them clear and attractive. If goals are
</p>
<p>shared, then you need to think about how people make decisions about those goals,
</p>
<p>and the actions that need to be taken to achieve those goals. If the decisions are
</p>
<p>shared, then you have to think about how you will share information between the
</p>
<p>people involved. Although the team may self-support and self-regulate, you should
</p>
<p>consider the need for an authority figure to moderate behavior, where appropriate.
</p>
<p>Remember that the make-up of the team is likely to change over time, so you need
</p>
<p>to consider how to deal with experienced people leaving the team and new people
</p>
<p>joining the team, which will affect overall system performance.
</p>
<p>You will need to think about how and why people are motivated to use your
</p>
<p>system. Do they use it because they have to (are they paid to use it to do their job,
</p>
<p>for example)? Or do they use it because they want to use it (the classic example
</p>
<p>here being social networking systems). Even in the case of developing a social
</p>
<p>networking system, there may be a need for extrinsic motivation to make sure that
</p>
<p>people keep the system active by providing new content, although the rewards for
</p>
<p>doing this may not be financial. You could highlight how the system increases
</p>
<p>their mastery, gives them autonomy, and increases the importance of doing the
</p>
<p>task. The balance between motivations may not always be clear cut, so some
</p>
<p>learning tasks, for example, will require a coach who sets tasks (which may be
</p>
<p>necessary, but are not necessarily intrinsically rewarding) for people to complete
</p>
<p>as part of their learning experience.
</p>
<p>If your system will support many users working together as a team, you will
</p>
<p>need to be aware of the potential diffusion of responsibility and how you can guard
</p>
<p>against this. One way of doing so is to make sure that any requests are directed at
</p>
<p>specific people rather than general groups. You can also make the requester appear
</p>
<p>more human by associating personal images or details with their request, because
</p>
<p>people are more likely to respond to real requests from real people!
</p>
<p>The factors that influence team performance may be relatively well known, but
</p>
<p>it may not always be possible to ensure that all the factors are optimal. As noted
</p>
<p>above, teams that are (1) more cohesive, (2) who have worked together longer, and
</p>
<p>(3) who share more values will perform better. You need to be able to support
</p>
<p>teams with these attributes, but also help teams that do not have all of the attributes
</p>
<p>to achieve them. Reducing social distance may help to make the team more
</p>
<p>cohesive, and sharing information can lead to the sharing of values.
</p>
<p>In addition to the team level issues, you will also need to think about organiza-
</p>
<p>tional issues. If an organization has procedures in place for how a particular job has
</p>
<p>to be done, for example, then you will need to think about whether these procedures
</p>
<p>will have to be changed. If the procedures are imposed by a regulatory authority
</p>
<p>(as in nuclear power, for example) then you may not be able to change those
</p>
<p>procedures, so you will have to design your system to support those procedures.
</p>
<p>274 9 Social: Theories and Models</p>
<p/>
</div>
<div class="page"><p/>
<p>There can also be cultural effects (on several levels), so there may be a tradition for
</p>
<p>doing a task in a particular way, which is an effect of organizational culture.
</p>
<p>The main message to take away is that all systems are deployed in an envi-
</p>
<p>ronment that includes social elements that you need to take into account. If you
</p>
<p>ignore them, you increase the risk of your system being unacceptable, because it is
</p>
<p>less likely that it will fit in with their way of working. The other important thing to
</p>
<p>remember is that the social environment is likely to change, so you should at least
</p>
<p>be aware of this, and design your system to take account of this, where possible.
</p>
<p>9.6 Summary
</p>
<p>We hope that this chapter has convinced you that social aspects of users are
</p>
<p>important. We and many designers certainly did not think so 20 years ago when a
</p>
<p>lot of systems were created. Increasingly, the individual aspects are either well
</p>
<p>supported or in some cases less important, so social aspects are becoming more
</p>
<p>important, or at least can be paid attention to.
</p>
<p>Social factors appear to be complex, and currently it appears to be difficult to
</p>
<p>combine them a priori. Social factors include the group members (which are
</p>
<p>complex), their organization (which can be complex), their mutual and individual
</p>
<p>tasks (which can be complex), and the task distributions (how often each task has
</p>
<p>to be performed). This makes the social factors not reducible to a single number or
</p>
<p>summary because the construct is a group, a set of individuals and their rela-
</p>
<p>tionships to each other, and their ability to perform a range of tasks that might not
</p>
<p>be equivalent. These factors are also moderated by the task environment, including
</p>
<p>other groups and other members of the team&rsquo;s family, culture, and nation.
</p>
<p>Designers will need to keep in mind during design the social aspects of the
</p>
<p>system, sometimes on a par with the technical system. There are more examples
</p>
<p>where ignoring social aspects of systems lead to risks that can cause systems to
</p>
<p>fail. Casey (1998) notes several, and Goolsby (2005) starts her paper with an
</p>
<p>example of a system that failed immediately because it ignored social and political
</p>
<p>aspects.
</p>
<p>9.7 Other Resources
</p>
<p>Cheyne and Ritter (2001) argue that there are right ways and wrong ways to
</p>
<p>contact people on the Internet. Their position has been upheld by most responsible
</p>
<p>organizations, but is consistently being violated by less responsible organizations
</p>
<p>(e.g., spammers). They offer an application of some of the theories in this area to
</p>
<p>how to make announcements using email, bulletin boards, and through search
</p>
<p>engines, rather than unsolicited direct email, which pushes the cost on the receiver.
</p>
<p>9.5 General Implications for System Design 275</p>
<p/>
</div>
<div class="page"><p/>
<p>For more on networked sociality see Rainie et al. (2012). Networked. The new
</p>
<p>social operating system. Cambridge, MA: MIT Press.
</p>
<p>A short article by Churchill cautions us to remember as designers we may not
</p>
<p>be like the users we are designing for, and to think carefully when designing social
</p>
<p>systems. This is of course a general point, but when it comes to social commu-
</p>
<p>nication tools, it is particularly important.
</p>
<p>Churchill (2010). The (anti) social net. interactions. 17(5). 22&ndash;25.
</p>
<p>Generally, the question of how to support teams using technology is considered by
</p>
<p>human factors and computer-supported cooperative work (CSCW). Conferences
</p>
<p>and journals in this area will provide more information and more current infor-
</p>
<p>mation. An early collection of readings is still useful: Baecker (1993).
</p>
<p>For more on collaborative virtual environments, Churchill, Snowdon, and
</p>
<p>Munro&rsquo;s book contains articles on the topic:
</p>
<p>E. F. Churchill, D. Snowdon and A. Munro (Eds). (2001). Collaborative virtual envi-
ronments. Digital places and spaces for interaction. London, UK: Springer Verlag.
</p>
<p>There are several places where work on computational models of social
</p>
<p>behavior can be found. In addition to the Journal of Mathematical Sociology, there
</p>
<p>is a society focused on this, NAACSOS&mdash;The North American Association for
</p>
<p>Computational Social and Organizational Science (www.dis.anl.gov/naacsos).
</p>
<p>Their conference is associated with the Computational and Mathematical Orga-
</p>
<p>nization Theory Conference (CASOS) (www.casos.ece.cmu.edu). The National
</p>
<p>Research Council, an independent agency that gives independent scientific advice
</p>
<p>to the government, has written a report that lays out a summary of work that can
</p>
<p>and should be done: (Committee on Organizational Modeling from Individuals to
</p>
<p>Societies 2007).
</p>
<p>9.8 Exercises
</p>
<p>9.1 Spam regularly appears in our email and now battles for our attention and our
</p>
<p>resources alongside legitimate emails. In some cases the spam is non-trivial in
</p>
<p>that the author is serious, genuine, and locatable. The rest are often removed
</p>
<p>automatically using spam filters.
</p>
<p>(a) Use the frameworks from informal groups, transaction costs, and net-
</p>
<p>works, to explain the incentives and impact of spam. Generate an
</p>
<p>equation to compute the transaction costs of spam. Generate an equation
</p>
<p>to compute how many email addresses are visible on the Internet.
</p>
<p>(b) Discuss, using costs and benefits, how much it would cost to ask people
</p>
<p>to donate to charity on your campus using email, and the wisdom and
</p>
<p>practical matters of this approach. (You might be able to use information
</p>
<p>from Cheyne and Ritter 2001).
</p>
<p>276 9 Social: Theories and Models</p>
<p/>
<div class="annotation"><a href="http://www.dis.anl.gov/naacsos">http://www.dis.anl.gov/naacsos</a></div>
<div class="annotation"><a href="http://www.casos.ece.cmu.edu">http://www.casos.ece.cmu.edu</a></div>
</div>
<div class="page"><p/>
<p>9.2 Second Life is a web site/application that puts you into a virtual world. It has a
</p>
<p>set of commands for moving around the environment and manipulating
</p>
<p>objects in it. It has an interface for following yourself and for recording orally
</p>
<p>as well as textually. If you have read any of Gibson&rsquo;s (1988) or Vinge&rsquo;s (2006)
</p>
<p>books, it may seem familiar in that it realizes some of the important aspects of
</p>
<p>these virtual worlds including social interaction, and Second Life may even
</p>
<p>have been inspired by these books.
Discuss Second Life with respect to the ABCS, particularly the social
</p>
<p>aspects. Note where it is better than (first) life and where it is worse. Try to
</p>
<p>summarize when and where it will be important.
</p>
<p>9.3 Examine eBay or another online site with social aspects using the represen-
</p>
<p>tations and frameworks in this chapter. Choose a framework from this chapter,
</p>
<p>e.g., network analysis. Map the concepts onto the social web site. Note
</p>
<p>whether there are any concepts missing on the web site, and also whether there
</p>
<p>are any concepts in the web site that are missing in the theory.
</p>
<p>References
</p>
<p>Axelrod, R. (1984). The evolution of cooperation. New York, NY: Basic Books.
Baxter, G. D., Monk, A. F., Tan, K., Dear, P. R. F., &amp; Newell, S. J. (2005). Using cognitive task
</p>
<p>analysis to facilitate the integration of decision support systems into the neonatal intensive
care unit. Artificial Intelligence in Medicine, 35, 243&ndash;257.
</p>
<p>Baecker, R. M. (Ed.). (1993). Readings in groupware and computer-supported cooperative work:
Assisting human&ndash;human collaboration. San Mateo, CA: Morgan Kaufmann.
</p>
<p>Beyer, H., &amp; Holtzblatt, K. (1999). Contextual design. interactions, 6(1), 32&ndash;42.
Blackmon, M. H., Polson, P. G., Kitajima, M., &amp; Lewis, C. (2002). Cognitive walk through for
</p>
<p>the Web. In Proceedings of CHI&rsquo;02 Conference on Human Factors in Computing Systems,
463-470. ACM: New York, NY.
</p>
<p>Boehm, B., &amp; Hansen, W. (2001). The spiral model as a tool for evolutionary acquisition.
Crosstalk: The Journal of Defense Software Engineering, 14(5), 4&ndash;11.
</p>
<p>Brennan, S. E. (1998). The grounding problem in conversations with and through computers. In
S. R. Fussell &amp; R. J. Kreuz (Eds.), Social and cognitive psychological approaches to
interpersonal communication (pp. 201&ndash;225). Hillsdale, NJ: Erlbaum.
</p>
<p>Brown, B., Green, N., &amp; Harper, R. (2001). Wireless world: Social and interactional aspects of
wireless technology. London, UK: Springer-Verlag.
</p>
<p>Burt, R. S. (2004). Structural holes and good ideas. American Journal of Sociology, 110(2),
349&ndash;399.
</p>
<p>Carley, K. M. (1996). A comparison of artificial and human organizations. Journal of Economic
Behavior &amp; Organization, 31, 175&ndash;191.
</p>
<p>Carroll, J. M., Rosson, M. B., Convertino, G., &amp; Ganoe, C. H. (2006). Awareness and teamwork
in computer-supported collaborations. Interacting with Computers, 18(1), 21&ndash;46.
</p>
<p>Casey, S. M. (1998). Set phasers on stun: And other true tales of design, technology, and human
error. Santa Barbara, CA: Aegean.
</p>
<p>Castilla, E. J., Hwang, H., Granovetter, E., &amp; Granovetter, M. (2000). Social networks in Silicon
Valley. In C.-M. Lee, W. F. Miller, M. G. Hancock &amp; H. S. Rowen (Eds.), The Silicon Valley
edge (pp. 218&ndash;247). Stanford, CA: Stanford University Press.
</p>
<p>Checkland, P. (1981). Systems thinking, systems practice. Chichester, UK: Wiley.
Checkland, P., &amp; Scholes, J. (1999). Soft systems in action (2nd ed.). Chichester, UK: Wiley.
</p>
<p>9.8 Exercises 277</p>
<p/>
</div>
<div class="page"><p/>
<p>Checkland, P., &amp; Poulter, J. (2006). Learning for action: A short definitive account of soft systems
methodology and its use for practitioners, teachers and students. Chichester, UK: Wiley.
</p>
<p>Cheyne, T., &amp; Ritter, F. E. (2001). Targeting respondents on the Internet successfully and
responsibly. Communications of the ACM, 44(4), 94&ndash;98.
</p>
<p>Churchill, E. F. (2010). The (Anti) Social Net. interactions, 17(5), 22&ndash;25.
Churchill, E. F., &amp; Bly, S. (1999). Virtual environments at work: Ongoing use of MUDs in the
</p>
<p>workplace. In Proceedings of the International Joint Conference on Work Activities
Coordination and Collaboration, 99&ndash;108. ACM: New York, NY.
</p>
<p>Churchill, E. F., Snowdon, D., &amp; Munro, A. (Eds.). (2001). Collaborative virtual environments.
Digital places and spaces for interaction. London, UK: Springer Verlag.
</p>
<p>Clark, H. H., &amp; Brennan, S. E. (1991a). Grounding in communication. In L. B. Resnick, J.
M. Levine, &amp; S. D. Teasley (Eds.), Perspectives on socially shared cognition (pp. 127&ndash;149).
Washington, DC: American Psychological Association.
</p>
<p>Clark, H. H., &amp; Brennan, S. E. (1991b). Perspectives on socially shared cognition. In L.
B. Resnick &amp; J. M. Levine (Eds.), Washington. DC: American Psychological Association.
</p>
<p>Coleman, J. R. (1974). Blue-Collar journal: A college president&rsquo;s sabbatical. Philadelphia, PA:
Lippincott Williams &amp; Wilkins.
</p>
<p>Committee on Organizational Modeling from Individuals to Societies, &amp; G. L. Zacharias, J.
MacMillan, and Susan B. Van Hemel (Eds). (2007). Behavioral modeling and simulation:
From individuals to societies. Washington, DC: National Academies Press. http://www.nap.
edu/catalog/12169.html.
</p>
<p>Crabtree, A. (2003). Designing collaborative systems: A practical guide to ethnography. London,
UK: Springer.
</p>
<p>Desanctis, G., &amp; Monge, P. (1998). Communication processes for virtual organizations. Journal
of Computer-Mediated Communication, 3(4), [online file].
</p>
<p>Dodds, P. S., Muhamad, R., &amp; Watts, D. J. (2003). An experimental study of search in global
social networks. Science, 301(5634), 827&ndash;829.
</p>
<p>Dunbar, R. I. M. (1992). Neocortex size as a constraint on group size in primates. Journal of
Human Evolution, 22(6), 469&ndash;493.
</p>
<p>El Helou, S., Tzagarakis, M., Gillet, D., Karacapilidis, N., &amp; Yu Man, C. (2008). Participatory
design for awareness features: Enhancing interaction in communities of practice. In
Proceedings of the 6th International Conference on Networked Learning, 523&ndash;530.
Networked Learning Conference Office, Lancaster University: Lancaster, LANCS.
</p>
<p>Fan, X., &amp; Yen, J. (2004). Modeling and simulating human teamwork behaviors using intelligent
agents. Physics of Life Reviews, 1(3), 173&ndash;201.
</p>
<p>Gibson, W. (1988). Mona Lisa overdrive. New York, NY: Bantam Books.
Goolsby, R. (2005). Ethics and defense agency funding: Some considerations. Social Networks,
</p>
<p>27, 95&ndash;106.
Gottman, J. M., Murray, J. D., Swanson, C., Tyson, R., &amp; Swanson, K. R. (2005). The
</p>
<p>mathematics of marriage: Dynamic nonlinear models. Cambridge, MA: MIT Press.
Halloran, M. E., Ferguson, N. M., Eubank, S., Longini, I. M. J., Cummings, D. A., Lewis, B.,
</p>
<p>et al. (2008). Modeling targeted layered containment of an influenza pandemic in the United
States. Proceedings of the National Academy of Sciences, 105(12), 4639&ndash;4644.
</p>
<p>Jones, R. M., Laird, J. E., Nielsen, P. E., Coulter, K. J., Kenny, P., &amp; Koss, F. V. (1999).
Automated intelligent pilots for combat flight simulation. AI Magazine, 20(1), 27&ndash;41.
</p>
<p>Kang, J. (2000). Cyber-race. Harvard Law Review, 113, 1130&ndash;1208.
Kozlowski, S. W. J., &amp; Ilgen, D. R. (2006). Enhancing the effectiveness of work groups and
</p>
<p>teams. Psychological Science in the Public Interest, 7(3), 77&ndash;124.
Landauer, T. K. (1995). The trouble with computers: Usefulness, usability and productivity.
</p>
<p>Cambridge, MA: MIT Press.
Levchuk, G. M., Levchuk, Y. N., Luo, J., Pattipati, K. R., &amp; Kleinman, D. L. (2002). Normative
</p>
<p>design of organizations&mdash;Part I: Mission planning. IEEE Transactions on Systems, Man, and
Cybernetics&mdash;Part A: Systems and Humans, 32(3), 346&ndash;359.
</p>
<p>278 9 Social: Theories and Models</p>
<p/>
<div class="annotation"><a href="http://www.nap.edu/catalog/12169.html">http://www.nap.edu/catalog/12169.html</a></div>
<div class="annotation"><a href="http://www.nap.edu/catalog/12169.html">http://www.nap.edu/catalog/12169.html</a></div>
</div>
<div class="page"><p/>
<p>Levitt, S., &amp; Dubner, S. J. (2005). Freakonomics: A rogue economist explores the hidden side of
everything New York. NY: William Morrow/HarperCollins.
</p>
<p>Lewis, C., &amp; Reiman, J. (1998). Task-centered user interface design. hcibib.org/tcuid/.
Milgram, S. (1967). The Small-World Problem. Psychology Today, 1, 61&ndash;67.
Millen, D. R., Feinberg, J., &amp; Kerr, B. (2006). Dogear: Social bookmarking in the enterprise. In
</p>
<p>Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, 111&ndash;120.
ACM: New York, NY.
</p>
<p>Monk, A., &amp; Howard, S. (1998). The rich picture: A tool for reasoning about work context.
interactions [sic], 5(2), 21&ndash;30.
</p>
<p>Monk, A. F. (1998). Lightweight techniques to encourage innovative user interface design. In
L. Wood (Ed.), User interface design: Bridging the gap between user requirements and
design (pp. 109&ndash;129). Boca Raton, FL: CRC Press.
</p>
<p>Nielsen, J. (1993). Usability engineering. Chestnut Hill, MA: AP Professional Press.
Nonaka, I., &amp; Takeuchi, H. (1995). The knowledge creating company: How Japanese companies
</p>
<p>create the dynamics of innovation. New York, NY: Oxford University Press.
Olson, J. S., &amp; Olson, G. M. (2003&ndash;2004). Culture surprises in remote software development
</p>
<p>teams. ACM. Queue, 1(9), 52&ndash;59.
Pew, R. W., &amp; Mavor, A. S. (Eds.). (2007). Human-system integration in the system development
</p>
<p>process: A new look. Washington, DC: National Academies Press. http://books.nap.edu/
catalog.php?record_id=11893. Accessed 10 March 2014.
</p>
<p>Plowman, L., Rogers, Y., &amp; Ramage, M. (1995). What are workplace studies for? In Proceedings
of the Fourth European Conference on Computer-Supported Cooperative Work ECSCW&rsquo;95,
309&ndash;324. Kluwer: Dordrecht, The Netherlands.
</p>
<p>Rainie, H., Rainie, L., &amp; Wellman, B. (2012). Networked. The new social operating system.
Cambridge, MA: MIT Press.
</p>
<p>Ruhleder, K., &amp; Jordan, B. (1999). Meaning-making across remote sites: How delays in
transmission affect interaction. In Proceedings of the Sixth European Conference on
Computer Supported Cooperative Work (ECSCW&rsquo;99), 411&ndash;429. Kluwer: Norwell, MA.
</p>
<p>Rutkowski, A. F., Vogel, D. R., Van Genuchten, M., Bemelmans, T. M., &amp; Favier, M. (2002). E-
collaboration: The reality of virtuality. IEEE Transactions on Professional Communication,
45(4), 219&ndash;230.
</p>
<p>Sacks, H. (1992). Lectures on Conversation, Volumes I and II. Edited by G. Jefferson with
Introduction by E.A. Schegloff. Oxford, UK: Blackwell.
</p>
<p>Simon, H. A. (1997). Administrative behavior (4th ed.). New York, NY: The Free Press.
Snowdon, D., Churchill, E. F., &amp; Frecon, E. (Eds.). (2003). Inhabited information spaces: Living
</p>
<p>with your data. London, UK: Springer Verlag.
Suchman, L. (1983). Office procedures as practical action: Models of work and system design.
</p>
<p>ACM Transactions on Office Information Systems, 1(4), 320&ndash;328.
Tambe, M., Johnson, W. L., Jones, R. M., Koss, F., Laird, J. E., Rosenbloom, P. S., et al. (1995).
</p>
<p>Intelligent agents for interactive simulation environments. AI Magazine, 16(1), 15&ndash;40.
ten Have, P. (1999). Doing conversation analysis. London: Sage Publications.
Travers, J., &amp; Milgram, S. (1969). An experimental study of the small world problem.
</p>
<p>Sociometry, 32(4), 425&ndash;443.
Tuckman, B. W. (1965). Developmental sequence in small groups. Psychological Bulletin, 63,
</p>
<p>384&ndash;399.
Viller, S., &amp; Sommerville, I. (2000). Ethnographically informed analysis for software engineers.
</p>
<p>International Journal of Human-Computer Studies, 53(1), 169&ndash;196.
Vinge, V. (2006). Rainbows End. New York, NY: Tor Books.
Watts, D. (2003). Six degrees: The science of a connected age. New York, NY: W. W. Norton.
Wenger, E. (1998). Communities of Practice: Learning, meaning, and identity. Cambridge, UK:
</p>
<p>Cambridge University Press.
Zachary, W., Santarelli, T., Lyons, D., Bergondy, M., &amp; Johnston, J. (2001). Using a community
</p>
<p>of intelligent synthetic entities to support operational team training. In Proceedings of the
</p>
<p>References 279</p>
<p/>
<div class="annotation"><a href="http://books.nap.edu/catalog.php?record_id=11893">http://books.nap.edu/catalog.php?record_id=11893</a></div>
<div class="annotation"><a href="http://books.nap.edu/catalog.php?record_id=11893">http://books.nap.edu/catalog.php?record_id=11893</a></div>
</div>
<div class="page"><p/>
<p>Tenth Conference on Computer Generated Forces and Behavioral Representation, 215&ndash;224.
Institute for Simulation and Training, University of Central Florida: Orlando, FL.
</p>
<p>Zhao, D., &amp; Rosson, M. B. (2009). How and why people Twitter: The role that micro-blogging
plays in informal communication at work. In Proceedings of the ACM 2009 International
Conference on Supporting Group Work, 243&ndash;252. ACM: New York, NY.
</p>
<p>280 9 Social: Theories and Models</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 10
</p>
<p>Errors: An Inherent Part
</p>
<p>of Human-System Performance
</p>
<p>Abstract In this chapter we consider how errors contribute to accidents, large and
</p>
<p>small, and what we can do about them. We discuss the problem of post-hoc
</p>
<p>analyses, the types of human error that can occur, and how to design systems in
</p>
<p>such a way that the errors can be appropriately managed. The examples illustrate
</p>
<p>how user&rsquo;s characteristics in terms of psycho-physiology, fatigue, cognitive pro-
</p>
<p>cessing, and social situations can all contribute to failures. We especially note the
</p>
<p>importance of Norman&rsquo;s (and others&rsquo;) main guideline about needing to design for
</p>
<p>error.
</p>
<p>10.1 Introduction to Errors
</p>
<p>In this chapter we provide an introduction to the topic of what is often called
</p>
<p>human error. As Reason (1990) notes, &lsquo;&lsquo;human error is a very large subject, quite
</p>
<p>as extensive as that covered by the term human performance,&rsquo;&rsquo; so we can only
</p>
<p>really provide a selective overview of some of the major issues.
</p>
<p>We have deliberately separated the discussion of errors into a separate chapter.
</p>
<p>This is because errors are an inherent part of system performance. In other words,
</p>
<p>they often arise as a combination of factors at the anthropomorphic, behavioral,
</p>
<p>cognitive, and social levels in the ABCS framework. If you look again at the
</p>
<p>example of the Kegworth air accident (see the Appendix), you should be able to
</p>
<p>appreciate this more fully at this point in the book.
</p>
<p>Our purpose here is to highlight the need to think about your users in context,
</p>
<p>and to determine what kinds of factors can give rise to erroneous performance. By
</p>
<p>highlighting the relationship between system performance and error, we hope to
</p>
<p>show you why it is important to think about designing for error (Norman 1988,
</p>
<p>2013). One way of designing for error is to identify the situations that can lead to
</p>
<p>erroneous performance, and then put in place appropriate mechanisms to either
</p>
<p>prevent the errors, or at least mitigate the adverse consequences arising from those
</p>
<p>errors.
</p>
<p>F. E. Ritter et al., Foundations for Designing User-Centered Systems,
DOI: 10.1007/978-1-4471-5134-0_10, ï¿½ Springer-Verlag London 2014
</p>
<p>281</p>
<p/>
</div>
<div class="page"><p/>
<p>We will illustrate our points using examples taken from a range of incidents and
</p>
<p>accidents, large and small. In doing so, we hope to show how errors do not just
</p>
<p>arise because of any inherent error-proneness or maliciousness of the users.
</p>
<p>Instead, errors are usually the result of an interaction of several contributing
</p>
<p>factors (people, technological, and contextual). Once we accept this state of affairs
</p>
<p>we can begin to move away from the need to find someone to blame, and start to
</p>
<p>learn from erroneous performance as a way of improving future system
</p>
<p>performance.
</p>
<p>10.1.1 What is Error?
</p>
<p>Errors are generally regarded as precursors to accidents. The error triggers a set of
</p>
<p>events&mdash;often referred to as a chain or sequence, although it is not always a linear
</p>
<p>set of events&mdash;ultimately leading to an outcome that has serious consequences
</p>
<p>involving significant loss of life, money, or machinery. Causal analyses of acci-
</p>
<p>dents usually highlight the fact that there were many contributory factors. There
</p>
<p>are obviously exceptions, where a single catastrophic failure leads directly to an
</p>
<p>accident, but generally accidents involve a series of several individually minor
</p>
<p>events. This process is sometimes described as a domino effect, or represented by
</p>
<p>the Reason&rsquo;s (1990) Swiss cheese model in which there are holes in the various
</p>
<p>layers of the system, and an accident only occurs when the holes line up across all
</p>
<p>the layers.
</p>
<p>A similar idea is encapsulated in Randell&rsquo;s (2000) fault-error-failure model that
</p>
<p>comes from the field of dependability. A failure is defined as something that occurs
</p>
<p>when the service that is delivered is judged to have deviated from its specification.
</p>
<p>An error is taken to be the part of the system state that may lead to a subsequent
</p>
<p>failure, and the adjudged cause of the error is defined as a fault.
</p>
<p>It is very important to note that identifying whether something is a fault, error,
</p>
<p>or failure involves making judgments. The fault-error-failure triples can link up so
</p>
<p>that you effectively end up with a chain of triples. This is possible because a failure
</p>
<p>at one level in the system may constitute a fault at another level. This does not
</p>
<p>mean that errors inevitably lead to failures, however. The link between an error
</p>
<p>and a failure can be broken either by chance or by taking appropriate design steps
</p>
<p>to contain the errors and their effects.
</p>
<p>Those errors that have immediate (or near-immediate) effects on system per-
</p>
<p>formance are sometimes called active errors (Reason 1990). This is to distinguish
</p>
<p>them from latent errors, which can lie dormant within a system for some con-
</p>
<p>siderable time without having any adverse effect on system performance. The
</p>
<p>commission that investigated the nuclear accident at Three Mile Island, for
</p>
<p>example, found that an error that had occurred during maintenance (and hence was
</p>
<p>latent in the system) led to the emergency feed water system being unavailable
</p>
<p>(Kemeny (chairman) 1979). Similarly, the vulnerability of the O-ring seals on the
</p>
<p>Challenger Space Shuttle was known about beforehand and hence latent in the
</p>
<p>282 10 Errors: An Inherent Part of Human-System Performance</p>
<p/>
</div>
<div class="page"><p/>
<p>system (Vaughan 1997). The vulnerability was only exploited after the decision
</p>
<p>was made to launch the shuttle in very cold weather.
</p>
<p>The general approach used to study errors focuses on how to understand errors
</p>
<p>so that we can take appropriate steps to manage them before things get out of hand.
</p>
<p>When, rather than if, things go wrong, the aim is to learn from what happened to
</p>
<p>help prevent a repeat performance.
</p>
<p>Immediately after a major accident of any kind the press coverage almost
</p>
<p>invariably attributes the cause of the accident to human error. The problem is that
</p>
<p>the term human error is ambiguous and has three subtly different meanings
</p>
<p>(Hollnagel 1998), which are often confused by the press. It is therefore worth
</p>
<p>spelling out these different meanings, using examples from the field of aviation:
</p>
<p>1. Human error is the cause of the event or action. An example of this would be if
</p>
<p>an aircraft deviated from its assigned flight altitude to a different flight altitude
</p>
<p>(either higher or lower than the one that the flight crew had been given by Air
</p>
<p>Traffic Control) due to the actions of the flight crew.
</p>
<p>2. Human error is the event or action itself. An example of this would be if an
</p>
<p>aircraft pilot did not change the altimeter setting when they were supposed to.
</p>
<p>Note that in this case the action is really a deliberate non-action.
</p>
<p>3. Human error is the consequence of the event or action. An example of this
</p>
<p>would be if an aircraft collided with another aircraft because the pilot started to
</p>
<p>taxi before receiving clearance to taxi by air traffic control.
</p>
<p>The differences between the meanings are quite subtle, but it is important to
</p>
<p>ensure that you understand them. In most cases the press combines the first two
</p>
<p>meanings, even though they may not intend that the primary attribution of blame
</p>
<p>should fall on the human.
</p>
<p>The interpretation of human error is further complicated by the fact that an
</p>
<p>action can only be judged as erroneous in hindsight (Woods et al. 1994). People
</p>
<p>will generally do what they think is the right thing in that particular context at the
</p>
<p>right time. So an action can only be judged as being erroneous after the fact, based
</p>
<p>on:
</p>
<p>&bull; A comparison with some expected level of performance
</p>
<p>&bull; A degradation in performance
</p>
<p>&bull; The person who performed the act having been unable to choose to act in a way
</p>
<p>that would not have been considered as erroneous.
</p>
<p>There is one exception to this notion of erroneous actions being judgments
</p>
<p>made in hindsight: violations. If a person deliberately decides to do the wrong
</p>
<p>thing&mdash;to sabotage the system, for example&mdash;then this can be determined at the
</p>
<p>point when the action occurs, rather than afterwards. In some cases, however, it
</p>
<p>may be necessary to violate the established rules or procedures to keep a system
</p>
<p>in a safe state, or to get it out of an unsafe one. The Federal Aviation Authority
</p>
<p>(FAA) in the US acknowledges this type of violation&mdash;sometimes called
</p>
<p>safe violations&mdash;and explicitly allows them under its regulations in certain
</p>
<p>situations.
</p>
<p>10.1 Introduction to Errors 283</p>
<p/>
</div>
<div class="page"><p/>
<p>Erroneous actions, then, can be seen generally as the result of one of two things:
</p>
<p>1. Performing the right action in the wrong circumstances. This is what Reason
</p>
<p>(1990) calls a mistake, or a failure in planning.
</p>
<p>2. Performing the wrong action in the right circumstances. This is often referred to
</p>
<p>as a slip (Norman 1981; Reason 1990), or failure in action execution.
</p>
<p>In either case the action could have been deemed correct if the circumstances
</p>
<p>had been slightly different. This helps to explain Rasmussen&rsquo;s (1988) description
</p>
<p>of erroneous actions as being the results of carrying unsuccessful experiments in
</p>
<p>unfriendly environments.
</p>
<p>It is also important to take into account different perceptions when trying to
</p>
<p>interpret what people mean by error. Rasmussen et al. (1994) suggest that the
</p>
<p>following perspectives can be identified:
</p>
<p>&bull; Common sense: to explain an unusual event
</p>
<p>&bull; The lawyer: to find somebody to blame and/or punish
</p>
<p>&bull; The therapist: to improve human performance
</p>
<p>&bull; The scientist: to understand human behavior
</p>
<p>&bull; The reliability analyst: to evaluate human performance
</p>
<p>&bull; The designer: to improve system configuration.
</p>
<p>As interactive system designers, our perspective tends to be mostly a combi-
</p>
<p>nation of the scientist&rsquo;s and the designer&rsquo;s perspectives. The two are somewhat
</p>
<p>related, because by understanding the human behavior, we can provide appropriate
</p>
<p>support to prevent errors happening or to mitigate the consequences of any errors
</p>
<p>that may not be preventable. In most cases this will be by changing the design of
</p>
<p>the system.
</p>
<p>10.1.2 The Fine Line Between Success and Failure
</p>
<p>As long as there have been people, there have been errors. Getting things right is
</p>
<p>not always easy, and often requires knowledge and skills that have to be acquired
</p>
<p>over an extended period of time: you cannot become an expert overnight. One of
</p>
<p>the ways in which people learn is through practice, by reflecting on their perfor-
</p>
<p>mance, using feedback, and then trying to do it better next time. This approach is
</p>
<p>nicely illustrated in the works of Henry Petroski (e.g., Petroski 1985/1992, 1994,
</p>
<p>2006), who has shown how the development of engineering has progressed over
</p>
<p>the centuries by learning from past errors.
</p>
<p>The study of errors has fascinated psychologists for over a century. It received
</p>
<p>renewed impetus from the end of the 1970s with major events like the Three Mile
</p>
<p>Island disaster in 1979, the runway collision at Tenerife in 1977, and a range of
</p>
<p>catastrophes in medical care (e.g., Bogner 2004), when the gauntlet was picked up
</p>
<p>by the human factors and ergonomics community. The focus of study has changed
</p>
<p>somewhat, however, and there is now recognition that it is important to think about
</p>
<p>284 10 Errors: An Inherent Part of Human-System Performance</p>
<p/>
</div>
<div class="page"><p/>
<p>success as much as failure because there is often only a fine line dividing the two,
</p>
<p>and there are many more instances of success than of failure (e.g., Hollnagel et al.
</p>
<p>2006). This changed emphasis is a reflection of Ernst Mach&rsquo;s (1905) prescient
</p>
<p>view that &lsquo;&lsquo;Knowledge and error flow from the same mental sources, only success
</p>
<p>can tell one from the other&hellip;&hellip;the same mental functions, operating under the
</p>
<p>same rules, in one case lead to knowledge, and in another, to error&hellip;.&rsquo;&rsquo;. Although
</p>
<p>couched in slightly different terms, it is a view that others have concurred with and
</p>
<p>reiterated, such as Reason (1990, p.1):
</p>
<p>Not only must more effective methods of predicting and reducing dangerous errors emerge
from a better understanding of mental processes, it has also become increasingly apparent
that such theorizing, if it is to provide an adequate picture of cognitive control processes,
must explain not only correct performance but also the more predictable varieties of
human fallibility. Far from being rooted in irrational or maladaptive tendencies, these
recurrent error forms have their origins in fundamentally useful psychological processes.
</p>
<p>The consequences of errors have also increased over the years. Or perhaps that
</p>
<p>should be the consequences are perceived to have increased. The mass media these
</p>
<p>days are often very quick to report on air accidents, for example, where a single
</p>
<p>accident may give rise to hundreds of casualties. The fact that more people get
</p>
<p>killed on the roads, however, goes largely unreported, mostly because each fatal
</p>
<p>road accident often only involves a few deaths (Gigerenzer 2004).
</p>
<p>10.1.3 The Accident was Caused by Human Error, Right?
</p>
<p>Most accidents could naively be attributed to human error because the systems that
</p>
<p>fail, leading to the accident, are designed by humans. This is an over-simplistic
</p>
<p>view, however, and would lead to an equally simplistic solution, i.e., that removing
</p>
<p>the human would remove a major source of failures, and hence eliminate many
</p>
<p>accidents. The idea of humans being accident prone in a volitional way (i.e., of
</p>
<p>their own free will) dominated early thinking in human error research.
</p>
<p>The cause of an accident is often attributed to human error (pilot error, driver
</p>
<p>error, operator error, and so on). This is a judgment that is built on several
</p>
<p>underlying assumptions that, at best, usually only represent a partial view of the
</p>
<p>true situation. There are many examples of such a view. Arnstein (1997), for
</p>
<p>example, found that the number of problems that could be attributed to human
</p>
<p>error in anesthetics ranged from 64 to 83%, whilst in aviation the range was
</p>
<p>40&ndash;88%. Johnson and Holloway (2007) also noted the tendency to over-emphasize
</p>
<p>human error as the reported cause in transportation accidents for the years
</p>
<p>1996&ndash;2003. Whilst it was still found to be the main attributed cause, the levels
</p>
<p>were somewhat lower at 37% for the US National Transportation Safety Board
</p>
<p>(NTSB), and 50% for the Canadian TSB.
</p>
<p>One of the main reasons that accidents end up being attributed to human error is
</p>
<p>because of the limitations of causal analysis. It is difficult to continue the analysis
</p>
<p>through the human when we do not have direct access to what was going on in the
</p>
<p>10.1 Introduction to Errors 285</p>
<p/>
</div>
<div class="page"><p/>
<p>operators&rsquo; heads when the accident happened. So once the human is reached in the
</p>
<p>sequence of attributable causes, the analysis frequently gets terminated, and we are
</p>
<p>left with human error as the result.
</p>
<p>As we have noted several times, system performance is the result of people
</p>
<p>interacting with technology in a particular context (organizational and physical
</p>
<p>environment). The importance of context should never be underestimated. Very
</p>
<p>often, when we look at accidents we find that the users were working in a context
</p>
<p>constrained by time pressures and limited resources.
</p>
<p>Nowadays, there is a greater awareness of the influence of the context in which
</p>
<p>work takes place, and the fact that human attentional resources are limited (see
</p>
<p>Chap. 5). Many events that previously were typically attributed to humans being
</p>
<p>accident prone would now be analyzed and categorized differently.
</p>
<p>In aviation, for example, where multitasking is an inherent part of flying a
</p>
<p>plane, distractions are recognized as being a particular problem. Dismukes et al.
</p>
<p>(1998) noted that nearly half the reported NTSB accidents attributed to crew error
</p>
<p>involved lapses of attention associated with interruptions, distractions, or an
</p>
<p>excessive preoccupation with one task to the exclusion of another that had to be
</p>
<p>performed within a similar time frame. The vast majority (90%) of competing
</p>
<p>activities that distracted or preoccupied pilots fell into four categories: commu-
</p>
<p>nication; head-down work; searching for other traffic in good weather (visual
</p>
<p>meteorological conditions or VMC); or responding to abnormal situations. Flight
</p>
<p>crews have to work as a team, but this has to be done in such a way that it does not
</p>
<p>detract from the individual tasks that have to be performed as the following
</p>
<p>excerpt from incident report #360761 from NASA&rsquo;s Aviation Safety Reporting
</p>
<p>System (ASRS) illustrates:
</p>
<p>Copilot was a new hire and new in type: first line flight out of training IOE. Copilot was
hand-flying the aircraft on CIVET arrival to LAX. I was talking to him about the arrival
and overloaded him. As we approached 12,000 feet (our next assigned altitude) he did not
level off even under direction from me. We descended 400 feet before he could recover. I
did not realize that the speed brakes were extended, which contributed to the slow altitude
recovery.
</p>
<p>Here the Pilot Not Flying (PNF) was trying to help the co-pilot (the Pilot Flying
</p>
<p>or PF), which led to problems on two levels. First, the combination of flying the
</p>
<p>plane and trying to heed the PNF&rsquo;s advice simply overloaded the PF. Second, the
</p>
<p>fact that the PNF was focused on making sure that he gave the PF appropriate
</p>
<p>assistance meant that he was distracted from his task of monitoring the ongoing
</p>
<p>status of the plane. Both flight crew members were trying to do the right thing, but
</p>
<p>they did not have enough resources to accomplish everything they needed to do.
</p>
<p>The distractions in this case were at least partly self-created; such distractions
</p>
<p>often lead to incidents in many domains (Baxter 2000). This incident would tra-
</p>
<p>ditionally have been attributed to pilot error, but a closer examination of the
</p>
<p>context suggests that this is an over-simplification.
</p>
<p>We noted earlier that there is a fine line between success and failure. In the
</p>
<p>aviation incident described above, where the plane descended too far, it seems
</p>
<p>286 10 Errors: An Inherent Part of Human-System Performance</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5">http://dx.doi.org/10.1007/978-1-4471-5134-0_5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5">http://dx.doi.org/10.1007/978-1-4471-5134-0_5</a></div>
</div>
<div class="page"><p/>
<p>obvious that there were time pressures involved. The PF knew that he had to
</p>
<p>respond relatively quickly whilst still listening to the PNF&rsquo;s advice. Perhaps if the
</p>
<p>PF had been more experienced, and the PNF had not felt the need to talk the PF
</p>
<p>through the arrival route, neither of them would have been distracted from the task
</p>
<p>at hand: the PF would have been more likely to level off at the appropriate altitude,
</p>
<p>and the PNF more likely to detect any anomalies in the plane&rsquo;s status.
</p>
<p>The air accident at Kegworth in the UK (Air Accidents Investigation Branch
</p>
<p>1989), described in the Appendix offers another example of a failure that was
</p>
<p>officially attributed to pilot (human) error. One of the problems was the fact that
</p>
<p>when the crew shut down the good engine, this coincided with a reduction in
</p>
<p>vibration, and a cessation of the smoke and fumes from the faulty engine. This led
</p>
<p>the crew to believe that they had taken the correct action, which can be at least
</p>
<p>partly attributed to the use of a flawed mental model (Besnard et al. 2004).
</p>
<p>It is also important to ensure that appropriate account is taken of the physio-
</p>
<p>logical limitations of users as well as their psychological limitations. A simple
</p>
<p>example is the original design of packaging for medication tablets (and some other
</p>
<p>potentially hazardous household items such as domestic bleach). It used to be quite
</p>
<p>easy for a young child to unscrew the cap from a medicine bottle and then eat the
</p>
<p>contents because they looked like sweets. The solution was the child-proof safety
</p>
<p>cap. Although children could not open them in tests, older people also found it
</p>
<p>difficult to open the cap, particularly if they suffered from arthritis. In complex
</p>
<p>situations, such as flying an airplane (and particularly smaller ones), the issues
</p>
<p>involved may be more subtle. Here it is important that the pilot is not asked to do
</p>
<p>things like move their head in one direction whilst the aircraft is moving in
</p>
<p>another, because this can lead to severe disorientation.
</p>
<p>The design limitations of the system also need to be taken into account. What
</p>
<p>often happens is that there is a general expectation that the human operator should
</p>
<p>compensate for any inadequacies in system design. Usually training is used to
</p>
<p>bridge the gap, but sometimes users are simply left to work it out for themselves.
</p>
<p>The technique of Crew&mdash;originally Cockpit&mdash;Resource Management (CRM)
</p>
<p>was developed (Wiener et al. 1993) to anticipate some potential problems that can
</p>
<p>arise from the interactions between people, technology, and context within avia-
</p>
<p>tion. CRM aims to minimize the potential for failures in interpersonal commu-
</p>
<p>nications at crucial times during a flight, for example, which can lead to real
</p>
<p>accidents such as:
</p>
<p>&bull; A plane crashing on take-off because the distracted crew failed to complete a
</p>
<p>safety checklist that would have confirmed that the aircraft&rsquo;s flaps had not been
</p>
<p>extended.
</p>
<p>&bull; A plane crashing into a river when the co-pilot failed to get the attention of the
</p>
<p>Captain about concerns that the take-off thrust had not been properly set. The
</p>
<p>co-pilot felt that he could not tell his superior what to do.
</p>
<p>&bull; A plane crashing when it ran out of fuel due to a communications breakdown
</p>
<p>between the Captain, the co-pilot, and air traffic control about the amount of fuel
</p>
<p>onboard.
</p>
<p>10.1 Introduction to Errors 287</p>
<p/>
</div>
<div class="page"><p/>
<p>It is only when you start to give deeper consideration to the circumstances in
</p>
<p>which the error occurred that you really appreciate how hard it is to decide who (or
</p>
<p>what) is really to blame. If a doctor makes a medication error after having worked
</p>
<p>for 24 h continuously, for example, can we really blame the doctor? We know that
</p>
<p>fatigue adversely affects cognitive performance, yet the system still put the doctor
</p>
<p>in a situation where they were likely to suffer from fatigue. Similarly, we know
</p>
<p>that the way that system controls are laid out can either help or hinder perfor-
</p>
<p>mance. If a design is inappropriate, can we really blame the users?
</p>
<p>In fact, the actions that are performed at the lowest level (usually where the user
</p>
<p>interacts with the technology) are only a small part of the picture. This level of
</p>
<p>interaction is often referred to as the sharp end of the system. Actions at the sharp
</p>
<p>end are often influenced by what happens at the so-called blunt end of the system,
</p>
<p>as shown in Fig. 10.1. The idea of a sharp end and a blunt end comes from Woods
</p>
<p>et al. (1994). This figure illustrates that final users are often seen as causes at where
</p>
<p>users meet the task, but that there is a lot of structure behind them that influences
</p>
<p>the situation as well; structure that is harder to change but that has a large amount
</p>
<p>of influence.
</p>
<p>Decisions and actions taken at the regulatory level can affect what the operators
</p>
<p>do. In theUSA, for example, the FAA&rsquo;s regulations state that pilots must not perform
</p>
<p>deliberate violations, unless the violation is needed to put the aircraft into a safe
</p>
<p>state. Similarly, standard operational procedures (which are generally defined at the
</p>
<p>organizational level) usually define what the operators can (or cannot) do.
</p>
<p>10.2 Studying Error
</p>
<p>The issue of data collection is fundamental to the study of human error. If we could
</p>
<p>reliably predict exactly when an error was going to occur, it would be a simple
</p>
<p>matter to warn the person or people involved so that they could avoid it.
</p>
<p>Regulatory
</p>
<p>Organizational
</p>
<p>Teams
</p>
<p>Operators/
</p>
<p>Users
</p>
<p>Technology
</p>
<p>Blunt End
</p>
<p>Sharp End
</p>
<p>Fig. 10.1 The influence of
the blunt end on the sharp end
of an incident
</p>
<p>288 10 Errors: An Inherent Part of Human-System Performance</p>
<p/>
</div>
<div class="page"><p/>
<p>Alternatively, we could design the system so that it would prevent the error
</p>
<p>occurring, or at least mitigate the consequences of the error.
</p>
<p>There is a standard set of questions that applies to the collection of human
</p>
<p>performance data:
</p>
<p>&bull; Why gather data?
</p>
<p>&bull; What sort of data to gather?
</p>
<p>&bull; Where (and when) to gather data?
</p>
<p>&bull; How much data to gather?
</p>
<p>&bull; How to gather data?
</p>
<p>These questions provide a basic framework for the discussion of the various
</p>
<p>issues involved. The issues interact and overlap, so it is not possible to answer each
</p>
<p>of the questions in isolation.
</p>
<p>It is worth re-emphasizing at this point that erroneous behavior is an inherent
</p>
<p>part of human performance, i.e., there is a close link between knowledge and error
</p>
<p>(Mach 1905). The corollary of this is that knowledge or data relating to correct
</p>
<p>performance are also needed to make an informed judgment regarding each
</p>
<p>potential instance of state misinterpretation.
</p>
<p>Here we only address the question of how to gather data, focusing on complex
</p>
<p>domains where the system can change dynamically without human intervention
</p>
<p>(such as aircraft, cars, and power plants). There are three basic data collection
</p>
<p>methods that can be used: laboratory-based experiments; field-based observation;
</p>
<p>and archive data. Each has its own set of strengths and weaknesses, as discussed
</p>
<p>below. The final choice of method depends on the particular situation at hand.
</p>
<p>10.2.1 Laboratory-Based Experiments
</p>
<p>The first method is the standard behavioral science method of using laboratory-
</p>
<p>based experiments. The main advantage of this method is that it allows for the
</p>
<p>independent variables associated with a particular phenomenon to be experimen-
</p>
<p>tally controlled. By varying one (or more) independent variables, the effect on the
</p>
<p>dependent variable can be observed.
</p>
<p>The main drawback is the lack of face validity between laboratory-based
</p>
<p>experiments and the real world situation. This lack of validity makes it inappropriate
</p>
<p>at best, and impossible at worst, to generalize from the results obtained in the
</p>
<p>laboratory to the situation in the real world. The use of laboratory-based experiments
</p>
<p>largely ignores the current consensus of opinion on the importance of context in
</p>
<p>shaping human performance (Hollnagel 1993a; Hutchins 1995; Nardi 1996).
</p>
<p>It is a long and difficult task to develop and conduct laboratory experiments that
</p>
<p>would meet all the requirements of a situation that would definitely lead to a
</p>
<p>human error. This is partly because of the problems of availability and selection of
</p>
<p>appropriate experimental subjects. The subjects would need lengthy experience of
</p>
<p>10.2 Studying Error 289</p>
<p/>
</div>
<div class="page"><p/>
<p>operating the system being used. Whilst it might be possible to use operators from
</p>
<p>the relevant domain, their experience is liable to be biased towards the particular
</p>
<p>system they normally work with (as opposed to your new system). The practicality
</p>
<p>of getting access to operators for the length of time needed to conduct the
</p>
<p>experiments also mitigates against using this approach. In addition, if subjects can
</p>
<p>identify the purpose of the experiment they may behave more cautiously, to guard
</p>
<p>against performing erroneous actions.
</p>
<p>It can also be difficult to choose an appropriate experimental task and setting.
</p>
<p>Complex systems often require operators to perform multiple tasks, sometimes
</p>
<p>simultaneously. The difficulty is to find a complex system (or an appropriate
</p>
<p>simulation) that can be readily deployed under laboratory conditions. The system
</p>
<p>would also need to be familiar to the subjects to fulfill the criterion regarding
</p>
<p>expertise. Unfortunately, laboratories that have their own high fidelity simulations,
</p>
<p>such as Halden&rsquo;s nuclear power plant simulator (Hollnagel et al. 1996) are still the
</p>
<p>exception rather than the rule.
</p>
<p>10.2.2 Field-Based Observation
</p>
<p>The second method is to carry out longitudinal observation of experienced oper-
</p>
<p>ators. The main advantage of this method is that it guarantees the ecological
</p>
<p>validity of the data. In general, observation is a valid technique, particularly if the
</p>
<p>aim is to investigate human reliability per se. In light of Mach&rsquo;s (1905) observation
</p>
<p>about the relationship between knowledge and error, there is a lot to be learned
</p>
<p>about operator performance under abnormal system operating conditions from
</p>
<p>observing performance under normal operating conditions.
</p>
<p>Observational research tends to focus on one specific aspect of operator
</p>
<p>behavior, however, rather than on operator behavior per se. The observational
</p>
<p>method, therefore, has a number of drawbacks. The first is the relatively low
</p>
<p>frequency of occurrence of human error. Although there may be a deterministic
</p>
<p>element to the occurrence of human error, it is very difficult to predict precisely
</p>
<p>when a set of events or actions giving rise to an observable error will occur. So
</p>
<p>there is no guarantee that human error will occur, even during extended periods of
</p>
<p>observation.
</p>
<p>The second drawback is the high costs associated with extended observation
</p>
<p>and the subsequent data analysis. Even if it could be guaranteed that human error
</p>
<p>would occur once in every 24 h period, for example, then gathering enough data
</p>
<p>for 100 errors would require 2,400 h of recordings. Because analysis of recorded
</p>
<p>data takes an order (or two) of magnitude longer than the recording, the time to
</p>
<p>gather and to analyze such a large amount of data quickly becomes prohibitive.
</p>
<p>The third drawback is the inherent adaptability of human behavior. One of the
</p>
<p>characteristics of experienced operators is their ability to detect and recover from
</p>
<p>potential erroneous actions. In other words, recovery is performed before
</p>
<p>unwanted consequences arise. Unless verbal reports are also recorded, which can
</p>
<p>290 10 Errors: An Inherent Part of Human-System Performance</p>
<p/>
</div>
<div class="page"><p/>
<p>be used to try and identify these recoveries, it can be difficult to detect where a
</p>
<p>recovery has taken place.
</p>
<p>The fourth drawback is that the presence of an outside observer may affect the
</p>
<p>operator&rsquo;s behavior. In particular, operators may be more careful than usual if they
</p>
<p>know their performance will be recorded for subsequent analysis. This may reduce
</p>
<p>the frequency of occurrence of human error, thereby requiring even longer periods
</p>
<p>of observation to gather enough data.
</p>
<p>10.2.3 Archive Data
</p>
<p>The third method is to use existing available data. Archive accident and incident
</p>
<p>reports, for example, have been successfully used within human error research
</p>
<p>(e.g., Pew et al. 1981; Rasmussen 1980; Wagenaar and Groeneweg 1987; Woods
</p>
<p>1984). As with the other data collection methods, there are several pros and cons to
</p>
<p>using archive data (Chappell 1994).
</p>
<p>The first advantage of archive data is that the data are real in that they are
</p>
<p>typically provided by participants in the incident. The second is that there are large
</p>
<p>numbers of observations available (in contrast to accident data). The third is that
</p>
<p>the data have high ecological validity because it relates to real incidents that
</p>
<p>occurred under normal operating conditions. Finally, the cost of collecting the data
</p>
<p>is generally low, because the data already exist.
</p>
<p>The main disadvantage of using archive data is that they usually have not been
</p>
<p>gathered for the specific purpose of the investigation at hand. The data therefore
</p>
<p>often have to be re-ordered and possibly re-represented before it can be appro-
</p>
<p>priately analyzed. The second disadvantage is that the detail in the reports may not
</p>
<p>have been validated. The third is that the data may be subject to reporter biases, in
</p>
<p>terms of who reports, and the information that gets reported which may be biased
</p>
<p>by selective retrieval and rational reconstruction (Ericsson and Simon 1993).
</p>
<p>10.2.4 Selecting the Most Appropriate Data Collection
</p>
<p>Method
</p>
<p>The aim of each of the methods described above is to generate data that can be
</p>
<p>used to develop theories and models of human performance. Over the last
</p>
<p>20 years, since the earliest work there has been a shift towards an increased use of
</p>
<p>real world data (e.g., Hutchins 1995), especially when studying expert perfor-
</p>
<p>mance in dynamic environments. The ideal method, however, would combine the
</p>
<p>contextual richness of real world situations with some of the experimental control
</p>
<p>of laboratory conditions. The work on the HEAP (Hollnagel et al. 1996) comes
</p>
<p>close to this ideal. The HEAP involved observing teams of operators running a
</p>
<p>high fidelity nuclear power plant simulator. Even with the HEAP work, however,
</p>
<p>10.2 Studying Error 291</p>
<p/>
</div>
<div class="page"><p/>
<p>there were problems. The operators either knew or could guess the purpose of the
</p>
<p>study. As a result they had a higher than normal expectation that an abnormal
</p>
<p>situation would arise during a simulator session. The sessions were also usually
</p>
<p>limited to 1 h rather than the duration of a normal shift.
</p>
<p>If you are designing an interface for a nuclear power plant control system, for
</p>
<p>example, you may regard ecological validity as being of paramount importance,
</p>
<p>and therefore decide against the use of laboratory experiments. Similarly, the hit
</p>
<p>and miss nature of using field observation for relatively infrequent events mitigates
</p>
<p>against its use, except perhaps in longitudinal studies or where unusual resources
</p>
<p>are available. Archive data, on the other hand, naturally have high ecological
</p>
<p>validity&mdash;a judicious choice of data source should make it possible to gain access
</p>
<p>to the hundreds of instances of human error required for analysis (Baxter 2000).
</p>
<p>Ultimately your choice of method will depend on the weights you give to the
</p>
<p>pros and cons of the individual methods. In addition, however, you should make
</p>
<p>sure that you take into account the availability and access to the resources you will
</p>
<p>need to carry out your study.
</p>
<p>10.3 Error Taxonomies
</p>
<p>Most scientific study is underpinned by a well-defined classification system or
</p>
<p>taxonomy of the relevant phenomena. The taxonomy provides a frame of reference
</p>
<p>for the study, and enables other researchers to evaluate the results of that study.
</p>
<p>Although several human error taxonomies have been developed, there is no uni-
</p>
<p>versal taxonomy that serves all the various purposes of error research (Senders and
</p>
<p>Moray 1991). Below we consider three well known examples.
</p>
<p>The critical factor in generating a taxonomy of erroneous behavior is the choice
</p>
<p>of level of abstraction to use for categorization. Determining an appropriate level
</p>
<p>of abstraction requires that the purpose of the research be clearly defined. A useful
</p>
<p>rule of thumb is to model behavior at a level that allows remedies to be generated
</p>
<p>to facilitate the avoidance of a repetition of the same type of error in similar
</p>
<p>circumstances in the future.
</p>
<p>10.3.1 The Technique for Human Error Rate Prediction
</p>
<p>The taxonomy used in the Technique for Human Error Rate Prediction (THERP,
</p>
<p>Swain and Guttman 1983) is based around the commonly used notions of errors of
</p>
<p>omission and commission. In this taxonomy, actions can either be:
</p>
<p>&bull; Correct.
</p>
<p>&bull; Errors of omission: actions that are omitted. It may be difficult, however, to
</p>
<p>determine whether an action has been omitted or has just been delayed for a long
</p>
<p>time.
</p>
<p>292 10 Errors: An Inherent Part of Human-System Performance</p>
<p/>
</div>
<div class="page"><p/>
<p>&bull; Errors of commission: actions that are performed inadequately, out of sequence,
</p>
<p>or at the wrong time (too early/late); or are qualitatively incorrect (too much/too
</p>
<p>little/wrong direction).
</p>
<p>&bull; Extraneous actions: actions that would not normally be expected at that par-
</p>
<p>ticular time and place.
</p>
<p>In THERP the probabilities of the different errors occurring are conditioned by
</p>
<p>performance shaping factors (PSFs). The PSFs are intended to take some account
</p>
<p>of the context in which the error occurs, to improve the accuracy of the individual
</p>
<p>error probability estimates. They are usually divided into external PSFs (such as
</p>
<p>situational characteristics), stressor PSFs (such as psychological stressors), and
</p>
<p>internal PSFs (such as organismic factors like previous training).
</p>
<p>10.3.2 Generic Error Modeling System
</p>
<p>Rasmussen&rsquo;s (1976) SRK model of behavior (see Chap. 5) has been used as the
</p>
<p>basis for several taxonomies that describe human performance in the operation of
</p>
<p>complex control systems, including Reason&rsquo;s (1990) Generic Error Modelling
</p>
<p>System (GEMS). Reason distinguishes between three types of errors: slips, lapses,
</p>
<p>and mistakes (see also Norman 1981). Slips (execution failures) occur when the
</p>
<p>person has the right intention but performs the wrong action. Lapses (memory
</p>
<p>storage failures) occur between the formulation of an intention and the execution
</p>
<p>of some action. Mistakes (intention failures) occur when the person initiates the
</p>
<p>wrong plan of action for the task at hand. Within the GEMS taxonomy, errors can
</p>
<p>be associated with planning, with storage, or with execution of actions (see
</p>
<p>Table 10.1).
</p>
<p>Skill-based errors (slips and lapses) are normally attributable to monitoring
</p>
<p>failures. In particular, they are often linked to a lack of attention, whether delib-
</p>
<p>erate or unintentional.
</p>
<p>The rule- and knowledge-based errors (mistakes) are usually associated with
</p>
<p>problem solving activities. At the rule-based level, mistakes can arise when good
</p>
<p>rules are misapplied, or bad rules are applied. At the knowledge-based level,
</p>
<p>mistakes usually arise due to a lack of expertise, because people do not have all the
</p>
<p>knowledge required to perform the task at hand. Figure 10.2 shows the relation-
</p>
<p>ship between the different types of errors in GEMS and a typical stage model of
</p>
<p>human information processing.
</p>
<p>Table 10.1 GEMS
taxonomy
</p>
<p>Planning Knowledge-based mistakes
</p>
<p>Rule-based mistakes
</p>
<p>Storage Skill-based lapses
</p>
<p>Execution Skill-based slips
</p>
<p>10.3 Error Taxonomies 293</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5">http://dx.doi.org/10.1007/978-1-4471-5134-0_5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5">http://dx.doi.org/10.1007/978-1-4471-5134-0_5</a></div>
</div>
<div class="page"><p/>
<p>10.3.3 The Cognitive Reliability and Error Analysis Method
</p>
<p>Hollnagel&rsquo;s (1998) Cognitive Reliability and Error Analysis Method (CREAM)
</p>
<p>tacitly acknowledges the fact that there is no single ideal taxonomy. Instead, the
</p>
<p>CREAM provides a generic framework for developing a domain specific taxon-
</p>
<p>omy of causes and effects of erroneous actions.
</p>
<p>In the CREAM, performance takes place in a context that is defined by the
</p>
<p>interaction between three high level factors:
</p>
<p>1. The human operator
</p>
<p>2. The technology (usually the system being operated by the human)
</p>
<p>3. The wider organization (including the environment in which the system is
</p>
<p>located).
</p>
<p>Each of these factors is explicitly accounted for in the CREAM that includes a
</p>
<p>scheme for classifying actions and events. The CREAM also takes account of the
</p>
<p>current consensus view that there is not a separate uniquely identifiable part of the
</p>
<p>human physiology that can be conveniently labeled error generator. As noted
</p>
<p>earlier, in many cases erroneous behavior occurs when the user takes what appears
</p>
<p>to be the appropriate action in conditions that are similar to, but not quite the same
</p>
<p>as what the operator believes them to be.
</p>
<p>Any erroneous actions that can be detected can be categorized as belonging to
</p>
<p>one or more of eight possible error modes or effects&mdash;Hollnagel (1993b) also
</p>
<p>Stimulus
</p>
<p>Evidence
</p>
<p>Mistakes
</p>
<p>Slips
</p>
<p>Action
Execution
</p>
<p>Planning
</p>
<p>Intention of
Action
</p>
<p>Situation 
Assessment
</p>
<p>Interpretation
</p>
<p>Memory
</p>
<p>Lapses and
Mode Errors
</p>
<p>Acting
</p>
<p>Knowledge-based
</p>
<p>Rule-based
</p>
<p>Fig. 10.2 Reason&rsquo;s Generic Error Modelling System (GEMS) error types related to a simple
stage model of human information processing (adapted from Wickens and Holland 2000)
</p>
<p>294 10 Errors: An Inherent Part of Human-System Performance</p>
<p/>
</div>
<div class="page"><p/>
<p>refers to these as the logical phenotypes of human error&mdash;each of which can
</p>
<p>manifest itself in several ways (shown in italics):
</p>
<p>&bull; Timing: the action is too early/too late/omitted.
</p>
<p>&bull; Duration: the action is too long/too short.
</p>
<p>&bull; Force: the action uses too much/too little force.
</p>
<p>&bull; Distance: the action is carried on too far/too short.
</p>
<p>&bull; Speed: the action is too fast/too slow.
</p>
<p>&bull; Direction: the action is performed in the wrong direction or involves the wrong
</p>
<p>type of movement.
</p>
<p>&bull; Object: the action was carried out on a proximal object/similar object/unrelated
</p>
<p>object rather than the required object.
</p>
<p>&bull; Sequence: in a sequence of actions there was an omission/skip forward/skip
</p>
<p>backward/repetition/reversal or the wrong action was performed.
</p>
<p>In addition, the CREAM makes provision for the inclusion of correct actions.
</p>
<p>Hollnagel (1998) suggests that a category labeled no erroneous action should be
</p>
<p>incorporated, either by adding it to each of the classification groups or by keeping
</p>
<p>it as a separate group.
</p>
<p>The category of error mode to which a particular instance of an erroneous
</p>
<p>action belongs may not always be immediately obvious. In such cases, the par-
</p>
<p>ticular situation at hand has to be carefully considered before any judgment can be
</p>
<p>made. This need for considered judgments is critical to the field of human error
</p>
<p>research, because the labeling of a particular action as being erroneous is invari-
</p>
<p>ably a judgment made in hindsight (Woods et al. 1994).
</p>
<p>The other part of the CREAM taxonomy is made up of the possible causes, or
</p>
<p>genotypes. These are divided into three main categories as shown in Table 10.2.
</p>
<p>There is one category for each of the main factors that contribute to system
</p>
<p>performance: people, technology, and context (described as organization-related in
</p>
<p>the CREAM).
</p>
<p>Table 10.2 The CREAM
genotypes of human error
</p>
<p>Person-related Observation
</p>
<p>Interpretation
</p>
<p>Planning
</p>
<p>Temporary
</p>
<p>Permanent
</p>
<p>Organization-related Communication
</p>
<p>Training
</p>
<p>Ambient conditions
</p>
<p>Working conditions
</p>
<p>Technology-related Equipment failure
</p>
<p>Procedures
</p>
<p>Temporary interface problems
</p>
<p>Permanent interface problems
</p>
<p>10.3 Error Taxonomies 295</p>
<p/>
</div>
<div class="page"><p/>
<p>10.4 Analyzing Errors
</p>
<p>There are many techniques available for analyzing errors, and any of them will
</p>
<p>usually provide some useful insights to help you understand what happened. Here
</p>
<p>we briefly discuss four techniques. Two have been widely used for several years in
</p>
<p>the safety systems engineering community. The others are more recent, and are
</p>
<p>less widely used, but offer interesting (and useful) perspectives for analyzing
</p>
<p>errors. Irrespective of which technique you choose (including those not covered
</p>
<p>here), you should make sure that it can be applied systematically.
</p>
<p>10.4.1 Event Trees
</p>
<p>Event trees are a bottom-up (inductive) technique for analyzing errors. They show
</p>
<p>the sequences of events that lead to all the possible outcomes. The trees are based
</p>
<p>on simple binary logic: at each node in the tree there are two possible branches
</p>
<p>based on whether an event does or does not happen (or whether a component failed
</p>
<p>or did not fail). The trees start with an initiating event, and are generated by thinking
</p>
<p>of all the possible consequences at each node in the tree. Each of the events can be
</p>
<p>assigned a probability (the sum of the probabilities for each of the two branches for
</p>
<p>a single node must add up to 1). The probability of all the identified outcomes can
</p>
<p>be calculated by multiplying together (ANDing) all the event probabilities along the
</p>
<p>path that leads from the initiating event to the outcome.
</p>
<p>Figure 10.3 shows a quantified event tree for the case where a fire breaks out in
</p>
<p>an office block. The initiating event (shown at the left of the tree) is the fact that
</p>
<p>the fire starts, and the estimated frequency of this occurrence is one per year. The
</p>
<p>likelihood of the various resultant events (outcomes) is calculated by multiplying
</p>
<p>the appropriate probabilities together. The probability of multiple fatalities for this
</p>
<p>scenario, for example, is 0.015 (i.e., 0.1 9 0.3 9 0.5).
</p>
<p>10.4.2 Fault Trees
</p>
<p>Fault trees are similar to event trees, although they are generated in a top down
</p>
<p>(deductive) manner, starting with the outcome and working backwards in time to
</p>
<p>try to find all the things that could have caused that particular outcome. Fault trees
</p>
<p>do not have to be binary trees, and an outcome can be determined by ANDing and
</p>
<p>ORing together a set of causal factors, as appropriate. Fault trees are normally only
</p>
<p>concerned with immediate effects, rather than the creation of latent conditions that
</p>
<p>can lie dormant within a system until some particular trigger activates them.
</p>
<p>Fault trees can be either qualitative or quantified. To quantify a fault tree, a
</p>
<p>probability of occurrence is allocated to each of the lowest level leaf nodes in the
</p>
<p>296 10 Errors: An Inherent Part of Human-System Performance</p>
<p/>
</div>
<div class="page"><p/>
<p>tree. Fault trees can also be modified to include recovery actions; the resultant trees
</p>
<p>are usually called recovery trees (van der Schaaf 1991).
</p>
<p>Figure 10.4 shows an example of a quantified fault tree for accidents at a
</p>
<p>particular road junction. The legend at the left of the figure describes the proba-
</p>
<p>bilities used in the figure. Cars driving too fast at this road junction, for example,
</p>
<p>occur frequently, so it is given a probability of 0.1.
</p>
<p>10.4.3 CREAM
</p>
<p>The CREAM can be used both for the retrospective analysis of accidents and the
</p>
<p>prospective analysis of possible errors in a system that is being designed. In both
</p>
<p>cases, the method that is followed is essentially the same.
</p>
<p>Here we will only focus on the simple retrospective use of the CREAM (as
</p>
<p>shown in Fig. 10.5). The process starts with the description of the initiating event
</p>
<p>(which could be an accident or incident). This description needs to provide enough
</p>
<p>detail to form the basis for the analysis. From this description it should be possible
</p>
<p>to identify the error mode(s) (or phenotypes) associated with the event. The next
</p>
<p>step is to try and identify the possible antecedents for that error mode, using the set
</p>
<p>of tables of antecedents and consequents that lie at the heart of the CREAMmethod.
</p>
<p>If a specific antecedent is found, or there are no general antecedents for the error
</p>
<p>mode, then the analysis is complete. If a general antecedent is found then the next
</p>
<p>step is to find the general consequent associated with that antecedent. If none can be
</p>
<p>found, the analysis terminates, otherwise we use the general consequent as a spe-
</p>
<p>cific consequent, and go through the loop again, this time trying to find a matching
</p>
<p>Y
</p>
<p>Y
</p>
<p>Y
</p>
<p>N
</p>
<p>N
</p>
<p>NP = 0.1
</p>
<p>P = 0.9
</p>
<p>P = 0.7
</p>
<p>P = 0.3
</p>
<p>P = 0.5
</p>
<p>P = 0.5
</p>
<p>Fire Starts
</p>
<p>Frequency 
</p>
<p>= 1/yr
</p>
<p>Initiating 
</p>
<p>Event
</p>
<p>Fire Spreads 
</p>
<p>Quickly?
</p>
<p>Sprinkler Fails 
</p>
<p>To Work?
</p>
<p>People Cannot 
</p>
<p>Escape?
</p>
<p>Resultant 
</p>
<p>Event
</p>
<p>Scenario
</p>
<p>Multiple Fatalities
</p>
<p>Loss / Damage
</p>
<p>Fire Controlled
</p>
<p>Fire Contained
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>4
</p>
<p>Fig. 10.3 Example quantification of event tree for a building protected by a sprinkler system
(reproduced with permission from the Institution for Engineering and Technology)
</p>
<p>10.4 Analyzing Errors 297</p>
<p/>
</div>
<div class="page"><p/>
<p>antecedent for the specific consequent (rather than the error mode). As the process
</p>
<p>continues, a structure that looks like a tree of antecedents and consequents is built
</p>
<p>up. Note that these are really the possible antecedents and possible consequents.
</p>
<p>Some of them may be ruled out by what really happened during the event.
</p>
<p>Using the CREAM to analyze errors can become quite involved, and is beyond
</p>
<p>the scope of this book. Hollnagel&rsquo;s (1998) book includes a good example of an
</p>
<p>analysis of a railway accident that occurred in New York in 1995 which is worth
</p>
<p>looking at, for those who are interested. Although the CREAM has not been
</p>
<p>widely adopted&mdash;partly because of a lack of tool support1&mdash;it does offer a nice
</p>
<p>illustration of how taking a different view of errors can generate new insights.
</p>
<p>10.4.4 THEA
</p>
<p>The Technique for Human Error Assessment (Pocock et al. 2001) assumes, like the
</p>
<p>CREAM, that the context in which actions are performed is one of the major
</p>
<p>influences on human performance. Like the CREAM, THEA is an iterative
</p>
<p>Crash at
</p>
<p>T-junction
Top 
</p>
<p>Event p = .001
</p>
<p>AND
</p>
<p>Car on 
</p>
<p>main road
</p>
<p>p = .01
</p>
<p>Car on side road fails 
</p>
<p>to stop
</p>
<p>OR
</p>
<p>Car on side road 
</p>
<p>did not stop
Car on side road 
</p>
<p>could not stop
</p>
<p>ORp = .12 ORp = .011
</p>
<p>Driving 
too fast
</p>
<p>Driver 
too ill
</p>
<p>Driver's 
vision 
</p>
<p>blocked 
</p>
<p>p = .01p = .1 p = .01
</p>
<p>Road
too 
</p>
<p>slippery
</p>
<p>Car
brakes
failed
</p>
<p>Car 
tyres 
worn
</p>
<p>p = .001p = .01 p = .0001
</p>
<p>1 in 10
</p>
<p>1 in 100
</p>
<p>1 in 1,000
</p>
<p>1 in 10,000
</p>
<p>1 in 100,000
</p>
<p>1 in 1M
</p>
<p>Frequent
</p>
<p>Probable
</p>
<p>Occasional
</p>
<p>Remote
</p>
<p>Improbable
</p>
<p>Extremely 
Remote
</p>
<p>p = .131
</p>
<p>Fig. 10.4 A quantified fault tree showing the likelihood of a crash occurring at a given road
junction (reproduced with permission from the Institution for Engineering and Technology)
</p>
<p>1 Although there is a browser based tool at http://www.ews.uiuc.edu/*serwy/cream/.
</p>
<p>298 10 Errors: An Inherent Part of Human-System Performance</p>
<p/>
<div class="annotation"><a href="http://www.ews.uiuc.edu/~serwy/cream/">http://www.ews.uiuc.edu/~serwy/cream/</a></div>
</div>
<div class="page"><p/>
<p>process, although the iterations take place at a higher level, i.e., the level of the
</p>
<p>design of the system or device.
</p>
<p>The THEA process (see Fig. 10.6) starts with a description of the system in
</p>
<p>terms of its functional behavior, its interface, and how it communicates with other
</p>
<p>systems. This description is accompanied by a corresponding description of the
</p>
<p>work performed by the system. This comprises one (or more) descriptive sce-
</p>
<p>narios, particularly focusing on the potential vulnerabilities of the system, and a
</p>
<p>description of the sorts of tasks that will be performed in terms of goals, actions,
</p>
<p>and plans.
</p>
<p>The system description and work descriptions are used to structure the scenario.
</p>
<p>Any appropriate method that can be used to decompose goals, such as hierarchical
</p>
<p>task analysis (described in Chap. 11), can be used.
</p>
<p>Once you have a structured scenario, you can do the error analysis. The analysis
</p>
<p>is based on a set of questions and a model of human information processing.
</p>
<p>Although the THEA reference guide uses Norman&rsquo;s (1988/2013) cyclic model of
</p>
<p>interaction, the process is model independent.
</p>
<p>The final step is to consider the probability of the occurrence of the identified
</p>
<p>errors, and then make suggestions about changes to the design to deal with them.
</p>
<p>The process then iterates until some stopping point is determined, which will
</p>
<p>usually be down to the judgment of the designer.
</p>
<p>As with the CREAM, THEA&rsquo;s uptake has been somewhat limited but, like the
</p>
<p>CREAM, it also shows how a systematic approach to analyzing errors can be used
</p>
<p>to inform design. Those who want more information should consult the THEA
</p>
<p>reference guide. THEA was originally designed to analyze situations involving a
</p>
<p>single person using a single artifact, whereas nowadays most work is performed by
</p>
<p>Description
of initiating
</p>
<p>event
(e.g., accident)
</p>
<p>Determine
error mode
</p>
<p>(general
consequent)
</p>
<p>Add specific 
consequent
</p>
<p>Specific
antecedent
</p>
<p>No general
antecedent
</p>
<p>General
antecedent
</p>
<p>Any
match?
</p>
<p>Match with
general
</p>
<p>consequent
</p>
<p>Analysis
complete
</p>
<p>No
</p>
<p>Yes
</p>
<p>Fig. 10.5 CREAM. The basic CREAM analysis process (redrawn by the authors)
</p>
<p>10.4 Analyzing Errors 299</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11">http://dx.doi.org/10.1007/978-1-4471-5134-0_11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11">http://dx.doi.org/10.1007/978-1-4471-5134-0_11</a></div>
</div>
<div class="page"><p/>
<p>teams of people. THEA was therefore adapted and extended to create a new
</p>
<p>method, CHLOE. CHLOE takes into account how people collaborate to get work
</p>
<p>done, and has been used to analyze errors in Air Traffic Control (Miguel and
</p>
<p>Wright 2003).
</p>
<p>10.5 Implications for System Design
</p>
<p>We need to consider how people interact with technology in a particular context
</p>
<p>when designing systems. Each of the components (people, technology, and con-
</p>
<p>text) can give rise to errors, so we need to design systems to take account of this,
</p>
<p>and try either to prevent the errors or at least to mitigate their consequences. It is
</p>
<p>also vital that we consider the interdependencies between people, technology, and
</p>
<p>context, because these can also give rise to errors.
</p>
<p>We know that most systems can be described as socio-technical systems, in that
</p>
<p>they have social (people-related) components and technological components.
</p>
<p>Unfortunately, however, many designers think this means that the system can be
</p>
<p>decomposed into a social subsystem and a technical subsystem. In reality, such an
</p>
<p>atomistic decomposition is inappropriate, because of the interactions and inter-
</p>
<p>dependencies between the system&rsquo;s social and technical components. If these
</p>
<p>interactions and interdependencies are ignored, the emergent system behaviors
</p>
<p>(including errors) that they give rise to may be overlooked. Many system devel-
</p>
<p>opers who claim that they use a socio-technical approach often decompose the
</p>
<p>system into social and technical subsystems, and focus most of their attention on
</p>
<p>the technical subsystem.
</p>
<p>Allied to the decomposition into human and technical components is a tech-
</p>
<p>nique called function allocation. When designing a system, you will need to
</p>
<p>Analyse
Scenario
</p>
<p>(e.g., HTA)
</p>
<p>System
Description
</p>
<p>Work 
Description
</p>
<p>Error
Analysis
</p>
<p>(using human 
IP model)
</p>
<p>Suggested
changes
</p>
<p>(requirement
s &amp; design)
</p>
<p>Fig. 10.6 The THEA process
</p>
<p>300 10 Errors: An Inherent Part of Human-System Performance</p>
<p/>
</div>
<div class="page"><p/>
<p>identify the list of functions that the system has to perform. These functions are
</p>
<p>then allocated to either the human or the machine using a static approach that is
</p>
<p>often based on Fitts&rsquo; (1951) list, which is also referred to as the MABA-MABA
</p>
<p>(Men Are Better At&ndash;Machines Are Better At) approach. The problem with this
</p>
<p>approach is that designers often allocate all the tasks that they know how to
</p>
<p>automate to the technology, and then leave the human to carry out all the others. If
</p>
<p>we want to allocate functions effectively we need to consider the processing
</p>
<p>characteristics of both the humans and the technology so that we can reduce the
</p>
<p>chances of errors whilst performing a particular function.
</p>
<p>If your system requires a lot of functions to be carried out in the same time
</p>
<p>frame, you may overload the operator (and the technology), thereby increasing the
</p>
<p>chances of an error occurring. In this case you may want to consider whether you
</p>
<p>can allocate functions dynamically, allowing tasks to be shed, and reallocated as
</p>
<p>workloads change. So, if operators get really busy, it should be possible for them
</p>
<p>to hand off tasks to the automation to reduce their workload, thereby improving
</p>
<p>overall system performance, and vice versa.
</p>
<p>One of the ironies of automation (Bainbridge 1987) is that the more complex
</p>
<p>socio-technical systems become, the more we rely on people to intervene to fix
</p>
<p>them when errors occur. You will therefore often hear people talking about the
</p>
<p>need to keep people in the loop. It is important that the users are kept aware of
</p>
<p>what the system is doing, by providing them with feedback about the system&rsquo;s
</p>
<p>state. They can use this to detect errors, and to update their own mental model of
</p>
<p>how the system is working. It is also important that users are given the opportunity
</p>
<p>to practice their skills, so they do not forget how to carry out particular tasks,
</p>
<p>especially those that they perform infrequently. This is one of the reasons why
</p>
<p>aircraft pilots have to undergo recurrent training, and are expected to hand fly their
</p>
<p>aircraft on a fairly regular basis.
</p>
<p>10.6 Summary
</p>
<p>Human error is a complex subject, for several reasons:
</p>
<p>&bull; Confusion over the term itself, which gets used to describe the action, the cause
</p>
<p>of that action, and the consequence of that action too.
</p>
<p>&bull; The same factors govern the expression of both expertise and error.
</p>
<p>&bull; Some of the contributors are latent, and lie hidden, waiting for other triggering
</p>
<p>or potentiating factors.
</p>
<p>&bull; Errors are judgments made in hindsight and require some measure of expected
</p>
<p>human performance for comparison.
</p>
<p>&bull; Human performance involves a distributed system of people interacting with
</p>
<p>technology at the sharp end and organizational elements at the blunt end.
</p>
<p>&bull; Decisions made at the blunt end of the system can constrain the way that work is
</p>
<p>carried out at the sharp end.
</p>
<p>10.5 Implications for System Design 301</p>
<p/>
</div>
<div class="page"><p/>
<p>&bull; The way technology is deployed shapes human performance, creating the
</p>
<p>potential for new forms of error and failure.
</p>
<p>Errors will happen. You may be able to get some idea of the sorts of errors that
</p>
<p>may occur with your system by looking at archive data, where it exists. Alter-
</p>
<p>natively, you may be able to collect data by running experiments using your
</p>
<p>system or an appropriate simulator.
</p>
<p>You can take appropriate account of potential errors by carefully considering
</p>
<p>the type of system that you are designing, the people who will use it, and the
</p>
<p>context in which they will operate it. There are several methods that will help you
</p>
<p>analyze your system for potential errors, including Event Trees, Fault Trees, the
</p>
<p>CREAM, and THEA, even at design time.
</p>
<p>10.7 Other Resources
</p>
<p>It is worth looking at Sidney Dekker&rsquo;s books to get a fuller understanding of the
</p>
<p>new (some would say more enlightened) view of human error. Ten Questions
</p>
<p>About Human Error (Dekker 2005) is an easy and entertaining read, whilst also
</p>
<p>being thought provoking. In it he addresses the issue of human error by posing the
</p>
<p>following questions, and then going on to explain and to answer them at length:
</p>
<p>1. Was it mechanical failure or human error?
</p>
<p>2. Why do safe systems fail?
</p>
<p>3. Why are doctors more dangerous than gun owners?
</p>
<p>4. Don&rsquo;t errors exist?
</p>
<p>5. If you lose situation awareness, what replaces it?
</p>
<p>6. Why do operators become complacent?
</p>
<p>7. Why don&rsquo;t they follow procedures?
</p>
<p>8. Can we automate error out of the system?
</p>
<p>9. Will the system be safe?
</p>
<p>10. Should we hold people accountable for their mistakes?
</p>
<p>You should be able to start to answer at least some of these questions for
</p>
<p>yourself at this point.
</p>
<p>The problems of dealing with blame, and how to establish a just (i.e., fair) culture,
</p>
<p>form the content of Dekker&rsquo;s book, Just Culture (Dekker 2007). In it he gives
</p>
<p>several examples of the sorts of problems that can occur when trying to make sure
</p>
<p>that justice (in the widest sense of the word, rather than just the legalistic view) is
</p>
<p>served. The main focus of the book is on trying to balance safety and accountability
</p>
<p>so that people who make honest mistakes are not necessarily held to be culpable. He
</p>
<p>dispels the simplistic idea about needing to punish those that cross the line, by
</p>
<p>showing that who gets to draw the line, and where they get to draw it, are major
</p>
<p>determinants in deciding whether someone will be regarded as culpable or not.
</p>
<p>302 10 Errors: An Inherent Part of Human-System Performance</p>
<p/>
</div>
<div class="page"><p/>
<p>10.8 Exercises
</p>
<p>10.1 Redraw Fig. 10.3, the event tree, for errors when entering a purchase on a
</p>
<p>smartphone or other mobile device. You can make (and may need to make)
</p>
<p>assumptions about the application and about people. Note these assumptions,
</p>
<p>and note briefly what studies or references you would need to read to find out
</p>
<p>more accurate answers.
</p>
<p>10.2 Interact through several transactions with an online commerce site, such as
</p>
<p>abebooks.com, or an online library, or other online service that delivers
</p>
<p>information. Keep a log of errors you make using a keystroke logger, an
</p>
<p>observer, or video. Analyze these errors for frequency and type using two
</p>
<p>different taxonomies.
</p>
<p>10.3 What are the error rates while typing? When you read a finished document,
</p>
<p>it looks like there are none. In this exercise, gather some data on error rates
</p>
<p>while typing. You can do this in several ways. You could ask people to type
</p>
<p>without looking at what they are typing. This would give an uncorrected
</p>
<p>error rate. You could show them a paper to type, and check how many letters
</p>
<p>are different between the source and their typing (using the Unix &lsquo;diff&rsquo; tool,
</p>
<p>or using Word&rsquo;s compare documents). You could also set up a web page and
</p>
<p>see how many times a user clicks on the correct link when asked. In your
</p>
<p>analyses you should consider what errors are more common, and what may
</p>
<p>lead to increased errors.
</p>
<p>10.4 In 2009 a man drove his $1 million Bugatti Veyron car into a lake. He blamed
</p>
<p>it on dropping his cell phone. Extend the fault tree in Fig. 10.4 to include the
</p>
<p>effect of cell phones on accidents. To do this, you will have to note where cell
</p>
<p>phones will interact with driving, and you will have to attempt to provide
</p>
<p>quantitative measures of how often events happen with a cell phone.
</p>
<p>References
</p>
<p>Air Accidents Investigation Branch. (1989). Report on the accident to Boeing 737-400- G-OBME
near Kegworth, Leicestershire. Retrieved 8 March 2014, from http://www.aaib.gov.uk/
publications/formal_reports/4_1990_g_obme.cfm
</p>
<p>Arnstein, F. (1997). Catalogue of human error. British Journal of Anaesthesia, 79, 645&ndash;656.
Bainbridge, L. (1987). Ironies of automation. In J. Rasmussen, K. Duncan, &amp; J. Leplat (Eds.),
</p>
<p>New technology and human error (pp. 271&ndash;283). Chicester: John Wiley.
Baxter, G. D. (2000). State misinterpretation in flight crew behaviour: An incident-based
</p>
<p>analysis. Unpublished PhD Thesis, University of Nottingham.
Besnard, D., Greathead, D., &amp; Baxter, G. (2004). When mental models go wrong. Co-occurrences
</p>
<p>in dynamic, critical systems. International Journal of Human-Computer Studies, 60(60),
117&ndash;128.
</p>
<p>Bogner, M. S. (Ed.). (2004). Misadventures in health care. Mahwah, NJ: Erlbaum.
Chappell, S. L. (1994). Using voluntary incident reports for human factors evaluations. In N.
</p>
<p>Johnston, N. McDonald, &amp; R. Fuller (Eds.), Aviation psychology in practice (pp. 149&ndash;169).
Aldershot, UK: Avebury.
</p>
<p>10.8 Exercises 303</p>
<p/>
<div class="annotation"><a href="http://www.aaib.gov.uk/publications/formal_reports/4_1990_g_obme.cfm">http://www.aaib.gov.uk/publications/formal_reports/4_1990_g_obme.cfm</a></div>
<div class="annotation"><a href="http://www.aaib.gov.uk/publications/formal_reports/4_1990_g_obme.cfm">http://www.aaib.gov.uk/publications/formal_reports/4_1990_g_obme.cfm</a></div>
</div>
<div class="page"><p/>
<p>Dekker, S. (2005). Ten questions about human error: A new view of human factors and system
safety. Mahwah, NJ: Erlbaum.
</p>
<p>Dekker, S. (2007). Just culture: Balancing safety and accountability. Aldershot, Hampshire,
England: Ashgate Publishing.
</p>
<p>Dismukes, K., Young, G., &amp; Sumwalt, R. (1998). Cockpit interruptions and distractions:
Effective management requires a careful balancing act. ASRS Directline, 10, 4&ndash;9.
</p>
<p>Ericsson, K. A., &amp; Simon, H. A. (1993). Protocol analysis: Verbal reports as data (2nd ed.).
Cambridge, MA: MIT Press.
</p>
<p>Fitts, P. M. (1951). Human engineering for an effective air navigation and traffic control system.
Washington, DC: National Research Council.
</p>
<p>Gigerenzer, G. (2004). Dread risk, September 11, and fatal traffic accidents. Psychological
Science, 15(4), 286&ndash;287.
</p>
<p>Hollnagel, E. (1993a). Human reliability analysis: Context and control. London: Academic Press.
Hollnagel, E. (1993b). The phenotypes of erroneous actions. International Journal of Man-
</p>
<p>Machine Studies, 39, 1&ndash;32.
Hollnagel, E. (1998). Cognitive reliability and error assessment method. Oxford, UK: Elsevier
</p>
<p>Science.
Hollnagel, E., Dr&oslash;ivoldsmo, A., &amp; Kirwan, B. (1996). Practical insights from studies of operator
</p>
<p>diagnosis. In Proceedings of ECCE-8. Eighth European Conference on Cognitive Ergonomics
(pp. 133&ndash;137). Granada, 8&ndash;12 Sept, 1996. Rocquencourt, France: European Association of
Cognitive Ergonomics.
</p>
<p>Hollnagel, E., Woods, D. D., &amp; Leveson, N. (Eds.). (2006). Resilience engineering: Concepts and
precepts. Aldershot, UK: Ashton Press.
</p>
<p>Hutchins, E. (1995). Cognition in the wild. Cambridge, MA: MIT Press.
Johnson, C. W., &amp; Holloway, C. M. (2007). A longitudinal analysis of the causal factors in major
</p>
<p>maritime accidents in the USA and Canada (1996&ndash;2006). In The Safety of Systems: Proceedings
of the 15th Safety-Critical Systems Symposium (pp. 85&ndash;104). London, UK: Springer.
</p>
<p>Kemeny (chairman), J. G. (1979). The need for change: The Legacy of TMI. Washington, DC:
The President&rsquo;s Commission on the accident at TMI.
</p>
<p>Mach, E. (1905). Knowledge and error (English Trans., D. Reidel, 1976). Dordrecht,
Netherlands: Reidel.
</p>
<p>Miguel, A., &amp; Wright, P. (2003). CHLOE: A technique for analysing collaborative systems. In
Proceedings of 9th Conference on Cognitive Science Approaches to Process Control (pp.
53&ndash;60). New York, NY: ACM Press.
</p>
<p>Nardi, B. A. (1996). Context and consciousness: Activity theory and human-computer
interaction. Cambridge, MA: MIT Press.
</p>
<p>Norman, D. A. (1981). Categorization of action slips. Psychological Review, 88, 1&ndash;15.
Norman, D. A. (1988). The psychology of everyday things. New York, NY: Basic Books.
Norman, D. A. (2013). The design of everyday things. New York, NY: Basic Books.
Petroski, H. (1985/1992). To engineer is human: The role of failure in successful design. New
</p>
<p>York, NY: Vintage Books.
Petroski, H. (1994). Design paradigms: Case histories of error and judgment in engineering.
</p>
<p>Cambridge, UK: Cambridge University Press.
Petroski, H. (2006). Success through failure: The paradox of design. Princeton, NJ: Princeton
</p>
<p>University Press.
Pew, R. W., Miller, D. C., &amp; Feeher, C. E. (1981). Evaluation of proposed control room
</p>
<p>improvements through analysis of critical operator decisions (EPRI-NP-1982). Cambridge,
MA: Bolt, Beranek &amp; Newman.
</p>
<p>Pocock, S., Harrison, M., Wright, P., &amp; Johnson, P. (2001). THEA: A technique for human error
assessment early in design. In Proceedings of Human-Computer Interaction: INTERACT&rsquo;01
(pp. 247&ndash;254). Amsterdam, The Netherlands: IOS Press.
</p>
<p>Randell, B. (2000). Facing up to faults. The Computer Journal, 43, 95&ndash;106.
</p>
<p>304 10 Errors: An Inherent Part of Human-System Performance</p>
<p/>
</div>
<div class="page"><p/>
<p>Rasmussen, J. (1976). Outlines of a hybrid model of the process operator. In T. G. Sheridan &amp;
G. Johannsen (Eds.), Monitoring behavior and supervisory control (pp. 371&ndash;383). New York,
NY: Plenum.
</p>
<p>Rasmussen, J. (1980). What can be learned from human error reports? In K. Duncan,
M. Gruneberg, &amp; D. Wallis (Eds.), Changes in working life (pp. 97&ndash;113). Chichester, UK:
Wiley.
</p>
<p>Rasmussen, J. (1988). Human error mechanisms in complex work environments. Reliability
Engineering and System Safety, 22, 155&ndash;167.
</p>
<p>Rasmussen, J., Pejtersen, A.-M., &amp; Goodstein, L. P. (1994). Cognitive systems engineering.
Chichester, UK: Wiley.
</p>
<p>Reason, J. (1990). Human error. Cambridge, UK: Cambridge University Press.
Senders, J. W., &amp; Moray, N. P. (1991). Human error: Cause, prediction, and reduction. Hillsdale,
</p>
<p>NJ: Erlbaum.
Swain, A. D., &amp; Guttman, H. E. (1983). A handbook of human reliability analysis with emphasis
</p>
<p>on nuclear power applications. Washington, DC: US Nuclear Regulatory Commission.
van der Schaaf, T. W. (1991). A framework for designing near miss management systems. In
</p>
<p>T. W. v. d. Schaaf, D. A. Lucas &amp; A. Hale (Eds.), Near miss reporting as a safety tool
(pp. 27&ndash;35). Oxford, UK: Butterworth-Heinemann.
</p>
<p>Vaughan, D. (1997). The Challenger launch decision. Chicago, IL: University of Chicago Press.
Wagenaar, W. A., &amp; Groeneweg, J. (1987). Accidents at sea: Multiple causes and impossible
</p>
<p>consequences. International Journal of Man-Machine Studies, 27, 587&ndash;598.
Wickens, C. D., &amp; Hollands, J. G. (2000). Engineering psychology and human performance
</p>
<p>(3rd ed.). Upper Saddle River, NJ: Prentice-Hall.
Wiener, E., Kanki, B., &amp; Helmreich, R. L. (Eds.). (1993). Cockpit resource management.
</p>
<p>London, UK: Academic Press.
Woods, D. D. (1984). Some results on operator performance in emergency events. Institution of
</p>
<p>Chemical Engineers Symposium Series (Vol. 90, pp. 21&ndash;31).
Woods, D. D., Johannesen, L. J., Cook, R. I., &amp; Sarter, N. B. (1994). Behind human error:
</p>
<p>Cognitive systems, computers, and hindsight. Wright-Patterson Air Force Base, OH:
CSERIAC.
</p>
<p>References 305</p>
<p/>
</div>
<div class="page"><p/>
<p>Part III
</p>
<p>Methods</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 11
</p>
<p>Methodology I: Task Analysis
</p>
<p>Abstract Task analysis (TA) is a useful tool for describing and understanding
</p>
<p>how people perform particular tasks. Task analyses can be used for several pur-
</p>
<p>poses ranging from describing behavior to helping decide how to allocate tasks to a
</p>
<p>team. There are several methods of TA that can be used to describe the user&rsquo;s tasks
</p>
<p>at different levels of abstraction. We describe some of the most commonly used
</p>
<p>methods and illustrate the use of TA with some example applications of TA. TA is
</p>
<p>widely used but when using TA there are considerations to keep in mind such as
</p>
<p>the fact that many approaches require an initial interface or specification, and that
</p>
<p>many do not include context multiple users or ranges of users. These consider-
</p>
<p>ations help describe where and when TA can be successfully applied and where
</p>
<p>TA will be extended in the future.
</p>
<p>11.1 Introduction
</p>
<p>You should by now be familiar with the idea that when we are designing user-
</p>
<p>centered systems we are thinking about particular people doing particular tasks in
</p>
<p>a particular context. So far in this book we have looked in some detail at people-
</p>
<p>related aspects, and at some of the context-related aspects. In this chapter we focus
</p>
<p>more on task-related issues.
</p>
<p>To understand what people do when they perform a task we use a technique
</p>
<p>called task analysis (TA). TA provides a way to describe the users&rsquo; tasks and
</p>
<p>subtasks, the structure and hierarchy of these tasks, and the knowledge they
</p>
<p>already have or need to acquire to perform the tasks. Using these descriptions it
</p>
<p>becomes possible to predict how long users will take to learn a task, and how long
</p>
<p>they will take to perform a task. In this chapter we will mostly focus on the sorts of
</p>
<p>tasks that are nowadays carried out using some form of computer-based system.
</p>
<p>TA can be used in most stages of system development. Before carrying out a
</p>
<p>TA, however, Diaper (2004) suggests that you first identify the stages of
</p>
<p>F. E. Ritter et al., Foundations for Designing User-Centered Systems,
DOI: 10.1007/978-1-4471-5134-0_11, ï¿½ Springer-Verlag London 2014
</p>
<p>309</p>
<p/>
</div>
<div class="page"><p/>
<p>development when TA will be used, and then ask four interrelated questions for
</p>
<p>each of the identified stages:
</p>
<p>1. What knowledge do you want the TA to provide? Frequently this is not an easy
</p>
<p>question to answer and your answer may need to be refined as you start to learn
</p>
<p>more and uncover interesting issues.
</p>
<p>2. What format should the output of the TA take? The output from a TA may not
</p>
<p>map directly onto software engineering representations, so the contribution of a
</p>
<p>TA may sometimes be indirect, e.g., building models of the world through TA
</p>
<p>can improve the models that are used in software engineering.
</p>
<p>3. What data can be collected? Data can be collected using several methods such
</p>
<p>as observing performance, interviews, document analysis, training program
</p>
<p>analysis, and analysis of existing systems.
</p>
<p>4. Which method should be used? The choice should be based on knowledge
</p>
<p>about the input data and the desired output data, rather than familiarity with a
</p>
<p>particular method.
</p>
<p>The results of a TA can be prescriptive or descriptive, depending on the aims of
</p>
<p>the analyst. Prescriptive analyses show how the user should carry out the task, and
</p>
<p>hence are associated with normative behavior. Prescriptive analyses can be used to
</p>
<p>help create safety procedures, and standard operating procedures, which prescribe
</p>
<p>how the user should carry out particular tasks. In contrast, descriptive analyses
</p>
<p>show how users really carry out the task, and are hence associated with actual
</p>
<p>behavior. Descriptive analyses are usually more situation specific than prescriptive
</p>
<p>analyses. It is important to be able to distinguish between the two, however. A
</p>
<p>prescriptive analysis of car driving, for example, would not include anything about
</p>
<p>driving above the speed limit; a descriptive analysis would be more likely to
</p>
<p>include details about people driving faster than the speed limit (perhaps only for
</p>
<p>particular sections of the road network).
</p>
<p>When thinking about the different types of TA that are available, it is important
</p>
<p>to remember that there may be some slight differences in the way they use terms
</p>
<p>such as goals, tasks, and actions. In general, goals are achieved by carrying out
</p>
<p>tasks. These tasks are usually performed as a series of actions on some object.
</p>
<p>In the rest of the chapter we first provide some examples of how task analysis
</p>
<p>can be used before describing four approaches to TA. The different approaches
</p>
<p>should be seen as complementary, as each has its own particular strengths and
</p>
<p>weaknesses. Although the approaches are similar in several respects, such as the
</p>
<p>need to apply them systematically, they also differ in many respects, such as the
</p>
<p>types of development activities they can support, and the level of detail that they
</p>
<p>can provide. For each of the different TA approaches we provide examples of how
</p>
<p>they can be used, and note some of their strengths and weaknesses. We finish by
</p>
<p>noting some of the limitations of TA.
</p>
<p>310 11 Methodology I: Task Analysis</p>
<p/>
</div>
<div class="page"><p/>
<p>11.2 The Uses of Task Analysis
</p>
<p>TA can be used for many different purposes. Kirwan and Ainsworth (1992), for
</p>
<p>example, identify six areas where TA can be applied, which are noted in
</p>
<p>Table 11.1.
</p>
<p>It should be noted that these areas are not all independent and sometimes
</p>
<p>overlap. Here we focus our discussions on the last three items, because these are
</p>
<p>the ones that are most closely associated with the process of designing user-
</p>
<p>centered systems.
</p>
<p>11.2.1 Allocation of Function
</p>
<p>The traditional way of allocating functions to users has been to use a Fitts&rsquo; (1951)
</p>
<p>list approach, based on whether the associated tasks are better carried out by
</p>
<p>people or by computers. In the original formulation there was often only one
</p>
<p>person, and one machine to think about. Nowadays, however, there may be several
</p>
<p>people, working together as a team, and several computer-based systems to con-
</p>
<p>sider. A task analysis helps you identify the knowledge that is needed to carry out
</p>
<p>the functions, and so can be used to inform how the functions are allocated. At the
</p>
<p>highest level it also lets you lay out a list of all the tasks that will need to be
</p>
<p>allocated. As part of Cognitive Work Analysis, Vicente (1999) has developed an
</p>
<p>approach to take large descriptions of tasks and use the complete set of tasks
</p>
<p>across a team of users to allocate sets of tasks to users that make sense to the users
</p>
<p>based on the large set rather than traditional job descriptions or existing interfaces.
</p>
<p>11.2.2 Performance Assurance
</p>
<p>The way that systems are used often changes over time. This is due partly to the
</p>
<p>way the system evolves, partly to the way people learn to use the system over time,
</p>
<p>and partly to changes in the context in which the system is deployed. The net effect
</p>
<p>is that there will often be a change in the tasks that the user carries out. It is
</p>
<p>Table 11.1 Areas where TA
can be applied, adapted from
Kirwan and Ainsworth (1992)
</p>
<p>1. Person specification
</p>
<p>2. Staffing and job organization
</p>
<p>3. Skills and knowledge acquisition
</p>
<p>4. Allocation of function
</p>
<p>5. Performance assurance
</p>
<p>6. Task and interface design
</p>
<p>11.2 The Uses of Task Analysis 311</p>
<p/>
</div>
<div class="page"><p/>
<p>therefore important to continually check that the system still supports the user in
</p>
<p>carrying out those tasks that have changed. When there are large numbers of tasks,
</p>
<p>this can be both particularly daunting and important.
</p>
<p>For example, university department web sites have a large number of tasks or
</p>
<p>information content types that users look for. Figure 11.1 notes the mismatch that
</p>
<p>has happened on some sites. The list for a department or college consists of over
</p>
<p>100 types of information (Ritter et al. 2002). Sites can use that list to investigate
</p>
<p>whether a site supports all the anticipated information needs of their users. Ritter
</p>
<p>and colleagues&rsquo; list has been used to make specific suggestions about how these
</p>
<p>sites should be updated, including putting up more information, and distributing
</p>
<p>the updating across members of the college because it is too much for a single
</p>
<p>person to update.
</p>
<p>Another use of TA is to find out more about how a task is done. When you
</p>
<p>compare the way that people are supposed to perform tasks, and the way they
</p>
<p>actually carry them out, there are often several noticeable differences. Creating a
</p>
<p>TA can help you to understand what the user is doing because you have a better
</p>
<p>understanding of the task, and often discussion based on a TA with users to update
</p>
<p>the TA provides further insights into why they are behaving in a particular way, for
</p>
<p>example, because of their particular knowledge or the context in which they
</p>
<p>perform the task.
</p>
<p>Campus 
slideshow
</p>
<p>Letter from 
the president
</p>
<p>Alumni in 
the news
</p>
<p>Press
releases
</p>
<p>Statement of the 
university's philosophy
</p>
<p>Virtual tour
</p>
<p>Picture of 
president
</p>
<p>Welcome from
the president
</p>
<p>Promotions
for alumni
</p>
<p> events
</p>
<p>Mascot 
pictures
</p>
<p>Things on the front page 
of a university website
</p>
<p>Things users look for 
on the web site
</p>
<p>Full name 
of the 
</p>
<p>university
</p>
<p>List of faculty phone
numbers and emails
</p>
<p>Campus
addresses
</p>
<p>Academic
calendar
</p>
<p>Parking
information
</p>
<p>Departments
Course lists
</p>
<p>Campus police 
phone number
</p>
<p>Campus map
by location
</p>
<p>Campus map
by building name
</p>
<p>How to obtain
transcripts
</p>
<p>Faculty 
publications
</p>
<p>Fig. 11.1 The potential mismatch between university department web sites built without a
thoughtful task analysis and what users want from university department web sites. Inspired by a
cartoon from xkcd.com
</p>
<p>312 11 Methodology I: Task Analysis</p>
<p/>
<div class="annotation"><a href="http://www.xkcd.com">http://www.xkcd.com</a></div>
</div>
<div class="page"><p/>
<p>11.2.3 Task and Interface Design
</p>
<p>TA can be used in several ways to guide task and interface design as listed below.
</p>
<p>1. To predict user task performance. These predictions of time, errors, or work-
</p>
<p>load can be used to compute whether an interface can be used to perform a
</p>
<p>time-sensitive task (e.g., interact with a video game), or how many copies of an
</p>
<p>interface are needed to support a number of users (e.g., the minimum and the
</p>
<p>optimal number of ATMs or ticket machines in an airport), or when a system
</p>
<p>needs to be speeded up to keep pace with the user. This approach has been and
</p>
<p>is being used to guide the requirements of how many sailors are needed to run a
</p>
<p>ship (Chipman and Kieras 2004).
</p>
<p>2. To suggest where users will make mistakes. Furthermore, we can take two
</p>
<p>types of task analysis and look at their relationship&mdash;for example, is the rela-
</p>
<p>tionship between goals/subgoals and the chronology of actions simple or
</p>
<p>complex? Are similar tasks similar? Are common safe tasks easy to do and
</p>
<p>expensive or dangerous tasks harder to do? Where there is a complex rela-
</p>
<p>tionship between the users&rsquo; goal structure and the interface&rsquo;s action structure,
</p>
<p>then an interface may be hard to use and may lead to more errors than it should
</p>
<p>or could. This approach has been applied to tasks in aviation. Models are built
</p>
<p>of how ATC interacts with pilots (Freed and Remington 1998) or how ground
</p>
<p>control navigates planes (Byrne and Kirlik 2005). The results suggest ways to
</p>
<p>avoid errors and ways to mitigate the effects of errors.
</p>
<p>3. To understand the relationship between old and new versions of a system.
</p>
<p>Given a task analysis of how people currently do a task, or would conceive of
</p>
<p>doing the task, we can ask how much that process and knowledge overlaps with
</p>
<p>the formal analysis of how it should be done in the new system. Increased
</p>
<p>similarity of how to use both systems can help with efficiency of learning, use,
</p>
<p>and comfort, and can lead to greater acceptance of the new system. The original
</p>
<p>work in this area (Bovair et al. 1990; Kieras and Polson 1985) noted the
</p>
<p>knowledge to use an initial editor, and then compared that to the knowledge to
</p>
<p>use a new editor. The results provide several suggestions, including: that
</p>
<p>ignoring old knowledge is easy; that modifying existing knowledge is, of
</p>
<p>course, slower; and that learning new knowledge slows the user down the most.
</p>
<p>4. To compare different designs. A task analysis of two interfaces can predict
</p>
<p>which interface will be faster and easier to use, as long as the two designs are
</p>
<p>reasonably distinctive. In most cases, however, the comparisons are accurate
</p>
<p>and useful. Gray et al. (1992), for example, used TA to compare the interface
</p>
<p>for a new system that was to be used by telephone toll operators&mdash;the people
</p>
<p>who used to respond when you dialed 0&mdash;against the old system&rsquo;s interface.
</p>
<p>The new interface was predicted to be slower, and an empirical test confirmed
</p>
<p>this. It also showed that the effect of the difference in performance would cost
</p>
<p>the telephone company about $2 million per year.
</p>
<p>TA has been used to investigate the design of menus using real and simulated
</p>
<p>cell phones (St. Amant et al. 2004, 2007). In this project a user model was
</p>
<p>11.2 The Uses of Task Analysis 313</p>
<p/>
</div>
<div class="page"><p/>
<p>created to perform a set of five tasks using a particular cell phone. The tasks
</p>
<p>were to adjust the ringer volume, access the tip calculator, view all contacts,
</p>
<p>view the date, and access the web browser. The resulting model was used to
</p>
<p>predict how long it would take to perform the five tasks with a cell phone and
</p>
<p>its initial menu structure. When compared with data from five practiced users
</p>
<p>the predictions turned out to be fairly accurate, but also showed where there was
</p>
<p>room for improvement in the design of the menus. The model suggested that
</p>
<p>reordering the menus to put the most often used menu items first would save
</p>
<p>about 30% of the total interaction time.
</p>
<p>5. To create user manuals. The results of the TA show in detail the steps that are
</p>
<p>involved in carrying out a task. User manuals can be created by translating this
</p>
<p>into text and elaborating, where appropriate. Basing the manual on a task
</p>
<p>analysis helps to make the manual more accurate, and more acceptable to the
</p>
<p>users, particularly if the TA was used to analyze how users really did the tasks.
</p>
<p>Closely related to the idea of user manuals is the notion of training people to do
</p>
<p>the task. In safety critical systems, for example, you want all the users to do the
</p>
<p>same task in (more or less) the same way. A TA can be used as the basis for
</p>
<p>developing standard operating procedures (which are used in domains other than
</p>
<p>safety critical systems too). In addition, because the TA shows the knowledge that
</p>
<p>is required to carry out particular tasks, it becomes possible to compare what the
</p>
<p>users know with what they need to know. Where any gaps are identified, this
</p>
<p>suggests where training could be useful to increase the users&rsquo; knowledge to the
</p>
<p>appropriate levels.
</p>
<p>11.3 Hierarchical Task Analysis
</p>
<p>Hierarchical Task Analysis (HTA) is probably the most widely used method in
</p>
<p>human factors and ergonomics. An initial HTA is often a precursor to the use of
</p>
<p>other methods, largely because it provides details about task activity. The precise
</p>
<p>level of detail depends on the depth of the analysis, which is determined by the
</p>
<p>original purpose of the analysis. Like most methods of task analysis, HTA takes a
</p>
<p>decompositional approach.
</p>
<p>11.3.1 HTA Components
</p>
<p>HTA involves decomposing goals into subgoals (Annett 2005), although it is often
</p>
<p>described in terms of decomposing tasks into subtasks. The order and structure of
</p>
<p>these goals and subgoals is represented visually. The analysis is usually presented
</p>
<p>either as a hierarchical graph structure, or in a tabular textual format. Each goal
</p>
<p>(and subsequent subgoals) will be accompanied by a plan. These plans, which
</p>
<p>314 11 Methodology I: Task Analysis</p>
<p/>
</div>
<div class="page"><p/>
<p>describe how goals and subgoals are achieved, cover aspects such as the (possibly
</p>
<p>conditional) sequencing of subgoals, the need for concurrency, and how cued
</p>
<p>actions can direct performance.
</p>
<p>11.3.2 Example Application of HTA
</p>
<p>Table 11.2 shows a simple HTA for making an online purchase. It is not complete,
</p>
<p>but illustrates the major steps, and would be useful when talking about how to
</p>
<p>perform the task, and how to help users perform the task. It is complete enough
</p>
<p>that it could be used to start a design. The plan at the bottom of the table is an
</p>
<p>example, high-level plan. The plan&mdash;plans are usually numbered, with plan 0
</p>
<p>being the plan associated with the top level goal&mdash;suggests that 1 must be com-
</p>
<p>pleted before 2. There would also be plans for the subgoals, and sub-subgoals as
</p>
<p>necessary. There might also be other plans for different users and uses.
</p>
<p>Examining the HTA in Table 11.2, we can start to identify some suggestions
</p>
<p>for design. If you wanted to provide your users with the option of browsing the
</p>
<p>listing before logging in, for example, you would have to change the plan to allow
</p>
<p>task 2 to happen before task 1, as well as afterwards, so the revised plan would
</p>
<p>look something like:
</p>
<p>Plan 0: 1 or 2, then 2 as needed, then 1 if needed, then 3.
</p>
<p>Figure 11.2 shows the HTA (this time drawn as a graph) for getting a file from a
</p>
<p>web-based email system. A plan for downloading the first file would include all the
</p>
<p>sub-tasks (1.1&ndash;1.4). A plan to download a second file could skip sub-tasks 1.1 and 1.2.
</p>
<p>The analysis in Fig. 11.2 can also suggest changes to the design of the way
</p>
<p>that the task is performed. Sub-task 1.2.2, for example, could be made more
</p>
<p>general, allowing that users might move and click, and that CR might be
</p>
<p>accepted as a way to move between fields. Further, it may be possible to skip
</p>
<p>some sub-tasks in particular circumstances. If the browser remembers the user&rsquo;s
</p>
<p>details then sub-task 1.2 could be skipped. Similarly, if the mail client downloads
</p>
<p>the files automatically (like many mail clients), sub-task 1.4 can be skipped. The
</p>
<p>details about skipping sub-tasks would normally be described in the associated
</p>
<p>plans.
</p>
<p>Performing an HTA can be a time-consuming process involving many
</p>
<p>choices. Although it yields a useful representational description, the technique
</p>
<p>does not specify how to go about gathering the task information that you wish to
</p>
<p>represent.
</p>
<p>There is no hard and fast rule about the lowest level at which you should
</p>
<p>terminate the analysis. In general you should consider stopping at a natural level,
</p>
<p>where further analysis would not contribute any more to your understanding of the
</p>
<p>situation. Usually it is fairly obvious when to do this. More formally, you can
</p>
<p>consider using the so-called stopping rule. For this you need to assess the prob-
</p>
<p>ability, P, of inadequate performance and the cost, C, of inadequate performance if
</p>
<p>11.3 Hierarchical Task Analysis 315</p>
<p/>
</div>
<div class="page"><p/>
<p>Table 11.2 An example hierarchical task analysis for making an online purchase
</p>
<p>0 Perform online purchase
</p>
<p>1. Login
</p>
<p>1.1. Select login screen
</p>
<p>1.2. Enter ID
</p>
<p>1.3. Enter password
</p>
<p>2. Choose object
</p>
<p>2.1. Browse listing
</p>
<p>2.2. Select item
</p>
<p>3. Pay
</p>
<p>3.1. Choose pay screen
</p>
<p>3.2. Select payment method
</p>
<p>3.3. Enter payment method details
</p>
<p>Plan 0: 1, then 2 as many times as needed, then 3
</p>
<p>Login to 
Webmail
</p>
<p>Type 
name
</p>
<p>Type 
"Tab"
</p>
<p>Bring up
browser
</p>
<p>Scroll 
to email
</p>
<p>Download
</p>
<p>file
</p>
<p>Move 
mouse
</p>
<p>Click
on file
</p>
<p>Select 
download 
location
</p>
<p>Download
email file
</p>
<p>Enter 
name
</p>
<p>Enter
password
</p>
<p>Click
mouse
</p>
<p>Move 
mouse
</p>
<p>Hand to
mouse
</p>
<p>Move
hand
</p>
<p>1.
</p>
<p>.4.1.3.1.2.1.1.1
</p>
<p>1.4.1. 1.4.2 1.4.31.2.1. 1.2.2. 1.2.3.
</p>
<p>1.2.1.1
</p>
<p>To download an email file,
</p>
<p>do steps 1.1, 1.2, 1.3, and 1.4
</p>
<p>Fig. 11.2 Hierarchical task analysis of downloading an email attachment. (Further subtasks
shown as three small boxes.)
</p>
<p>316 11 Methodology I: Task Analysis</p>
<p/>
</div>
<div class="page"><p/>
<p>you did not expand the hierarchy down a level. You then multiply these together to
</p>
<p>get the stopping value: if this is acceptable, then you terminate the analysis
</p>
<p>(Kirwan and Ainsworth 1992).
</p>
<p>11.3.3 Summary
</p>
<p>The main advantage of HTA is that, when carried out correctly by a skilled
</p>
<p>analyst, it can provide useful information to inform design relatively quickly. It
</p>
<p>does not require the interface or the interface details to be fully specified, so it can
</p>
<p>be used during the early stages of system development. Once created, the analysis
</p>
<p>can be extended, using appropriate methods to provide further details on the
</p>
<p>cognitive aspects of the task. HTA&rsquo;s main disadvantage is that the way in which its
</p>
<p>results are usually presented do not map readily onto the representations used by
</p>
<p>software engineers. Either the task analyst or the system developer will probably
</p>
<p>have to carry out further work to translate the results of the HTA into something
</p>
<p>that can be used during development.
</p>
<p>11.4 Cognitive Task Analysis
</p>
<p>As the nature of work in many domains moved from mostly manual control to
</p>
<p>mostly monitoring and supervisory control&mdash;sometimes described as a change
</p>
<p>from doing to thinking&mdash;it became increasingly important to take account of the
</p>
<p>cognitive aspects of work. Rather than pulling levers, opening and closing valves,
</p>
<p>the users now spent most of their time tracking the behaviour of a computer-based
</p>
<p>system on a display screen, making decisions and interacting with the system using
</p>
<p>the relevant input devices (e.g., in aviation many aircraft now employ a joystick
</p>
<p>device rather than a control yoke to help fly it).
</p>
<p>Cognitive Task Analysis (CTA; e.g., see Schraagen et al. 2000 for an overview)
</p>
<p>extends more traditional task analysis techniques to facilitate the collection of
</p>
<p>information about the mental processes that underpin observable task performance.
</p>
<p>It should be noted that this does not mean that CTA and HTA are mutually
</p>
<p>exclusive: normally they should be used to complement one another.
</p>
<p>11.4.1 CTA Components
</p>
<p>A CTA will usually comprise the application of a set of methods (e.g., Seamster
</p>
<p>et al. 1997 discuss a range of methods that can be used in the aviation domain).
</p>
<p>One of the first steps in carrying out a CTA is therefore to choose the methods and
</p>
<p>tools that are appropriate to the particular situation that is being studied. The
</p>
<p>methods that can be used include:
</p>
<p>11.3 Hierarchical Task Analysis 317</p>
<p/>
</div>
<div class="page"><p/>
<p>1. Interviews
</p>
<p>2. Concept (or card) sorting
</p>
<p>3. Verbal reports
</p>
<p>4. Cognitive walkthroughs
</p>
<p>5. GOMS (described in more detail below).
</p>
<p>The choice of methods is influenced by factors such as the objectives of the
</p>
<p>CTA, the available resources, the types of tasks involved, and the skills of the
</p>
<p>person doing the CTA.
</p>
<p>Once the data for a CTA has been collected, the results from the various
</p>
<p>methods have to be compiled and interpreted. The results of the CTA should
</p>
<p>provide details about the cognitive aspects of how tasks are performed, as well as
</p>
<p>details of the information and knowledge needed to perform those tasks and how
</p>
<p>that information and knowledge are used.
</p>
<p>11.4.2 Example Application of CTA
</p>
<p>Baxter et al. (2005) carried out a case study of work in a neonatal intensive care
</p>
<p>unit where a new decision support system (Fuzzy Logic Respiratory Neonatal Care
</p>
<p>Expert, FLORENCE) was being developed. FLORENCE was intended to help
</p>
<p>clinical staff make decisions about changes to the mechanical ventilator that is
</p>
<p>used to treat respiratory distress syndrome (RDS) in premature babies. It was
</p>
<p>important that the introduction of FLORENCE did not adversely affect the
</p>
<p>dependability of the delivery of care in the unit, and that it was acceptable to users.
</p>
<p>A CTA was therefore carried out using lightweight rich pictures analysis (Monk
</p>
<p>1998), the critical decision method (CDM; Klein et al. 1989), and observation.
</p>
<p>Task analysis methods, in general, pay little attention to the context in which
</p>
<p>the tasks are carried out; rich pictures analysis provides a way to take account of
</p>
<p>that context, although it is quite novel for it to be included as part of a CTA. In this
</p>
<p>case study, a rich pictures analysis was carried out to capture details about the
</p>
<p>context in which FLORENCE was to be deployed. Data was collected using semi-
</p>
<p>structured interviews to identify the roles, responsibilities, and concerns of eight
</p>
<p>members of staff working in the unit, including the staff that provide adminis-
</p>
<p>trative support in the unit. The analysis also showed how staff communicate and
</p>
<p>interact with members of staff who work in other parts of the hospital, such as the
</p>
<p>test laboratories. The importance of communication within the unit was also
</p>
<p>identified, since it forms the basis for clinical care of the babies. Furthermore, the
</p>
<p>central role of the various patient records was highlighted: FLORENCE would
</p>
<p>have to find some way to produce appropriate records.
</p>
<p>The CDM was used to analyze how clinical staff make decisions about any
</p>
<p>changes that need to be made to the settings of the mechanical ventilators used to
</p>
<p>treat the babies. It is critical that these decisions are correct and timely, otherwise
</p>
<p>they can seriously adversely affect the babies&rsquo; health. The basic steps of the CDM
</p>
<p>318 11 Methodology I: Task Analysis</p>
<p/>
</div>
<div class="page"><p/>
<p>were followed for the incidents selected by each of the eight participants, and a
</p>
<p>critical cue inventory&mdash;highlighting the cues that clinical staff paid attention to&mdash;
</p>
<p>and situation assessment records&mdash;which describe how the incident unfolded in
</p>
<p>terms of cues, goals, expectations, and decisions&mdash;were developed for each inci-
</p>
<p>dent. These highlighted aspects such as the importance of having a distinctive
</p>
<p>alarm for FLORENCE because the unit already has several alarms sounding on a
</p>
<p>fairly regular basis, and the hierarchy of decision making which flattens when
</p>
<p>dealing with acute incidents.
</p>
<p>Finally, observation was used to capture details of how clinical staff work
</p>
<p>in situ to treat babies with RDS. RDS is self-regulating, and usually lasts around
</p>
<p>72 h. The treatment of two babies was recorded using timed note taking&mdash;the unit
</p>
<p>is a high stress situation, so video recording was not a viable option&mdash;over a 2-h
</p>
<p>period. The first baby was moved off the unit after 1 day; the second baby was
</p>
<p>observed on three consecutive days all at the same time of day. The results showed
</p>
<p>how often staff interacted with the equipment around the babies&rsquo; cots under normal
</p>
<p>conditions and when an alarm sounded.
</p>
<p>The results of the CTA were analyzed and used to inform the development of
</p>
<p>FLORENCE. These included decisions about the interface (e.g., the need for
</p>
<p>instructions about changes to ventilator settings to be precise and unambiguous,
</p>
<p>such as &lsquo;&lsquo;increase PIP by 2&ndash;16&rsquo;&rsquo;), as well as training (e.g., staff need to learn how
</p>
<p>to prioritize their response to FLORENCE&rsquo;s alarm) and more general physical
</p>
<p>ergonomics concerns (e.g., space is needed around the baby&rsquo;s cot to accommodate
</p>
<p>the PC running FLORENCE).
</p>
<p>11.4.3 Summary
</p>
<p>As its name suggests, CTA is particularly suited to analyzing the cognitive pro-
</p>
<p>cesses and products that people use when performing tasks. It is not so good at
</p>
<p>dealing with the work context in which performance takes place (although using
</p>
<p>rich pictures analysis does provide at least a partial solution, e.g., see Baxter et al.
</p>
<p>2005). Carrying out a CTA can be quite time consuming, particularly when the
</p>
<p>selected methods require access to experts. CTA also requires that the analyst(s)
</p>
<p>are competent in carrying out a range of methods. Furthermore, it requires a high
</p>
<p>level of skill to be able to interpret the results of several methods in a holistic way
</p>
<p>so that they can be presented to the system developers.
</p>
<p>11.5 GOMS
</p>
<p>GOMS is an acronym for Goals, Operations, Methods, and Selection rules (Card
</p>
<p>et al. 1980, 1983). It is a method that can be used as part of a CTA, but we include
</p>
<p>it in its own right because of its close relationship with the field of HCI.
</p>
<p>11.4 Cognitive Task Analysis 319</p>
<p/>
</div>
<div class="page"><p/>
<p>The focus of GOMS is on specifying the details of error-free, expert behavior,
</p>
<p>and using the resulting specification to predict learnability, usability, and task
</p>
<p>execution times, allowing that there may be multiple strategies available for
</p>
<p>similar tasks. GOMS tends to be used when designing interactive technology like
</p>
<p>phones and GPS systems, where milliseconds can matter, where consistency in the
</p>
<p>users&rsquo; knowledge and in the interface matters, and where operators may be expert
</p>
<p>but not trained to do things in a single way.
</p>
<p>The four GOMS techniques:
</p>
<p>&bull; GOMS: sometimes referred to as CMN-GOMS, using its authors&rsquo; initials to
</p>
<p>distinguish it from the generic name
</p>
<p>&bull; NGOMSL: Natural GOMS Language
</p>
<p>&bull; CPM-GOMS: Cognitive Perceptual Motor GOMS, which supports concurrent
</p>
<p>actions
</p>
<p>&bull; The Keystroke Level Model (KLM) which is described in more detail below
</p>
<p>are sometimes described as a family (John and Kieras 1996a). They vary in how
</p>
<p>easy they are to apply and use.
</p>
<p>11.5.1 GOMS Components
</p>
<p>The components of GOMS are listed in Table 11.3. With GOMS models, the
</p>
<p>cognitive structure is represented in the concept of starting from Goals, and also
</p>
<p>from the explicit use of Selection rules to indicate how Methods&mdash;comprising sub-
</p>
<p>goals and Operators&mdash;are chosen to accomplish those Goals.
</p>
<p>11.5.2 Example Application of GOMS
</p>
<p>Table 11.4 provides an example GOMS model for editing text. This model con-
</p>
<p>sists of two parts. The main task (which comes second in the table) is to perform
</p>
<p>all the edits. This is a cyclical task, and represents starting with a marked up
</p>
<p>manuscript and then performing the edits marked on the paper (or highlighted in
</p>
<p>the electronic file). Each of the edits are unit tasks which define a single edit. A full
</p>
<p>model would have multiple types of unit tasks for editing. The first part of the
</p>
<p>model notes a declarative memory chunk about the Cut command, a unit task,
</p>
<p>including how to find it and what the keystroke accelerator is. A more complete
</p>
<p>model would have further unit tasks defined.
</p>
<p>The method for editing a document is shown as a looping algorithm of working
</p>
<p>through a set of tasks to edit a document. This algorithm represents how people
</p>
<p>work through editing a document with changes to be made in the document,
</p>
<p>stopping when there are no more edits. This remains a relatively common task, for
</p>
<p>320 11 Methodology I: Task Analysis</p>
<p/>
</div>
<div class="page"><p/>
<p>Table 11.3 The components of GOMS
</p>
<p>Goals are the desired states of affairs. They are brought about by the application of methods and
operators
</p>
<p>Operators are elementary perceptual, motor, or cognitive actions. Intended either to change the
world (a normal key-press) or to change our knowledge about the world (e.g., reading). In
practice, operators are really those subgoals whose methods of solution we have decided not
to analyze any further. The choice of appropriate operators is critical to a GOMS analysis.
Some critics note that there are no clear guidelines for doing so, although it is often a fairly
straightforward decision
</p>
<p>Methods describe procedures for achieving goals. They contain a sequence of subgoals and/or
operators, with conditions potentially attached to each part of the method. These conditions
relate to the current task environment (e.g., repeat until no tasks left)
</p>
<p>Selection rules augment the basic control structure of the model. Where multiple methods are
available the selection rules indicate how to choose between the methods. These include, for
example, when scrolling a document: if you want to scroll a long distance, use the search
function; if you want to scroll a short distance, use the scroll bar; and if you want to scroll a
very short distance, use the arrow keys
</p>
<p>Table 11.4 Example GOMS model for text editing (reprinted from St. Amant
et al. 2005). This model is written using NGOMSL notation
</p>
<p>LTM [long term memory] item: Cut Command [a unit task] 
</p>
<p> Name is Cut. 
</p>
<p> Containing Menu is Edit. 
</p>
<p> Menu Item Label is Cut. 
</p>
<p>Accelerator Key is &ldquo;Control-X&rdquo;.
</p>
<p>[[There would be more types of commands here in a complete model.]] 
</p>
<p>Method for goal: Edit Document 
</p>
<p> Step. Store First under &lt;current task name&gt;. 
</p>
<p> Step. Check for done. 
</p>
<p> Decide: If &lt;current task name&gt; is None, Then 
</p>
<p>  Delete &lt;current task&gt;; 
</p>
<p>  Delete &lt;current task name&gt;; 
</p>
<p>  Return with goal accomplished. 
</p>
<p> Step. Get task item whose 
</p>
<p>  Name is &lt;current task name&gt; 
</p>
<p>  and store under &lt;current task&gt;. 
</p>
<p> Step. Accomplish goal: Perform Unit task. 
</p>
<p> Step. Store Next of &lt;current task&gt; 
</p>
<p>  under &lt;current task name&gt;; 
</p>
<p>  Goto Check for done. 
</p>
<p>11.5 GOMS 321</p>
<p/>
</div>
<div class="page"><p/>
<p>example, how an author right now is working through this chapter making changes
</p>
<p>to improve the text and how students revise lab reports.
</p>
<p>The loop has several types of substeps. These steps can store state (e.g., what
</p>
<p>the current task is); they can perform conditionals (if); and they can subgoal
</p>
<p>(Perform unit task). Within the unit tasks (not fully shown), information can be
</p>
<p>obtained from the display and mental and physical actions performed. GOMS
</p>
<p>manuals provide a full list of the actions (e.g., Kieras 1999) and when to include
</p>
<p>mental operators to retrieve task structure, but in practice these lists can be
</p>
<p>extended to include unusual devices such as joysticks or different types of manual
</p>
<p>controls (such as different knobs or toggle switches). The analysis in Table 11.4
</p>
<p>does not include all the details of all the subtasks that can be performed, and not all
</p>
<p>the details of how to do a unit task.
</p>
<p>Table 11.5 shows a model for dialing a cell phone. In this example the tasks are
</p>
<p>slightly smaller and the interaction and memory aspects are more prominent.
</p>
<p>11.5.3 Summary
</p>
<p>GOMS models sometimes appear structurally quite similar to other hierarchical
</p>
<p>task analyses of goals/subgoals. The main difference is that GOMS has formalized
</p>
<p>its components to a greater level of detail. It is assumed that the methods are
</p>
<p>known before the GOMS analysis is carried out, and that they are not developed
</p>
<p>during task performance. The particular strengths of GOMS lie in assessing how to
</p>
<p>make interfaces easier to use by comparing alternative models, or methods, for a
</p>
<p>particular task.
</p>
<p>Many people question the utility of GOMS analyses, arguing that there is no
</p>
<p>such thing as error-free, expert performance. This limitation can be somewhat
</p>
<p>ameliorated by incorporating the error correction strategies in the analysis.
</p>
<p>Probably the biggest limitation of GOMS, however, is that the interface has to be
</p>
<p>implemented or at least described in enough detail to be able to identify the actions
</p>
<p>for a particular task. There is also a lack of a clear specification of what can be
</p>
<p>used in Selection rules&mdash;there is an implication that it should be the current task
</p>
<p>context, but real behavior, for example, undoubtedly allows choices to be based on
</p>
<p>previous selections. It is also difficult to do a vanilla GOMS analysis when mul-
</p>
<p>titasking or task interleaving is involved. CPM-GOMS was developed to address
</p>
<p>this, but at the expense of making it more difficult to create models.
</p>
<p>11.6 The Keystroke Level Model
</p>
<p>A simplified version of GOMS is the keystroke level model (KLM) of Card et al.
</p>
<p>(1983). Like GOMS, it is a method that can be used as part of a CTA, but we include
</p>
<p>it here in its own right because of its close relationship with the field of HCI.
</p>
<p>322 11 Methodology I: Task Analysis</p>
<p/>
</div>
<div class="page"><p/>
<p>The KLM is usually applied where there is just one person interacting with a
</p>
<p>computer-based system. It is a fast and approximate way to compute how long
</p>
<p>users will take to perform a unit task. A unit task is essentially a small cognitively
</p>
<p>manageable task. Large tasks can be decomposed into several unit tasks, although
</p>
<p>Table 11.5 Example GOMS model, written using NGOMSL notation, for telephone
dialing taken from St. Amant et al. (2005)
</p>
<p>Task item: T1             [[ tasks will go from T1 to T11 to dial (814) 865-3528 ]] 
Name is T1. 
Digit is "8". 
Next is T2. 
</p>
<p>Visual object: first digit 
Content is "8". 
</p>
<p>Task item: T2 
Name is T2. 
Digit is "1". 
Next is T3. 
</p>
<p>Visual object: second digit 
Content is "8". 
</p>
<p>. . . 
Task item: T11 
</p>
<p>Name is T11. 
Digit is "8". 
Next is NONE. 
</p>
<p>Visual object: second digit 
Content is "1". 
</p>
<p>Method for goal: Dial Number 
Step. Store T1 under &lt;current task name&gt;. 
Step Check for done. 
</p>
<p>Decide: If &lt;current task name&gt; is T11, Then 
Delete &lt;current task&gt;; 
Delete &lt;current task name&gt;; 
Return with goal accomplished. 
</p>
<p>Step. Get task item whose Name is &lt;current task name&gt; 
and store under &lt;current task&gt;. 
</p>
<p>Step. Accomplish goal: Dial Digit. 
Step. Store Next of &lt;current task&gt; under &lt;current task name&gt;. 
Goto Check for done. 
</p>
<p>Method for goal: Dial Digit 
Step. Look for object whose Content is Digit of &lt;current task&gt; 
</p>
<p>and store under &lt;target&gt;. 
Step. Point to &lt;target&gt;; Delete &lt;target&gt;. 
Step. Click mouse button. 
Step. Verify "Correct digit pressed". 
Step. Return with goal accomplished. 
</p>
<p>11.6 The Keystroke Level Model 323</p>
<p/>
</div>
<div class="page"><p/>
<p>not all tasks will have a unit task substructure. The time to do the whole task is
</p>
<p>calculated by simply adding up the calculated times for all the component unit
</p>
<p>tasks. It should be noted that you also need to include the time it takes to acquire
</p>
<p>the task, i.e., the time it takes for the user to work out what to do. The KLM does
</p>
<p>not provide a way of calculating this but Card et al. (1980) suggest that the time
</p>
<p>needed for each unit task when manipulating a manuscript is 2&ndash;3 s if the
</p>
<p>instructions are written down, 5&ndash;30 s if it is a routine design situation, and even
</p>
<p>longer for creative composition situations.
</p>
<p>To calculate the time for a unit action involves analyzing the operations into
</p>
<p>their elemental perceptual, motor, and cognitive actions (e.g., keystrokes). Then
</p>
<p>by adding together the times for these individual actions it can be possible to make
</p>
<p>time predictions for expert, error-free performance of that task.
</p>
<p>11.6.1 Description of KLM Components
</p>
<p>The execution of a unit-task requires operators of (basically) four types:
</p>
<p>1. Keystrokes (K): unit time based on typing speeds (0.08&ndash;1.2 s/keystroke, mouse
</p>
<p>click, or button press)
</p>
<p>2. Pointing (P): moving mouse to target (clicking is a keystroke) (approximately
</p>
<p>1.1 s, but Fitts&rsquo; law can also be used)
</p>
<p>3. Homing (H(mouse) or H(keyboard)): moving hand to/from mouse and key-
</p>
<p>board (approximately 0.4 s)
</p>
<p>4. Drawing (D): dragging mouse in straight-line segments (0.9 n + 0.16 l where n
</p>
<p>= number of segments and l = length of segments).
</p>
<p>To these should be added some number of mental operators (M or Mop, 1.35 s).
</p>
<p>Well practiced tasks with a simpler structure will require less mental operators.
</p>
<p>Getting the number of mental operators correct is a difficulty in using this method,
</p>
<p>but if it is done consistently across applications it is less of a problem. Finally, the
</p>
<p>system&rsquo;s response time (Sys), if it limits the user&rsquo;s task performance, also has to be
</p>
<p>included. This can be estimated, or, again, if the estimate can be assumed to be
</p>
<p>consistent across interfaces, is less important than you might fear.
</p>
<p>The number of mental operators is computed using a set of rules&mdash;basically
</p>
<p>between all operators, except those linked through knowledge or skill (e.g., the
</p>
<p>keystrokes in a single word, or a set such as point and click a mouse).
</p>
<p>Where there are selection rules governing the choice of methods then it is up to
</p>
<p>the analyst to decide whether to go for best or worst case time predictions.
</p>
<p>The time to perform these operators as noted above can be done in an approxi-
</p>
<p>mate style. There are several ways to improve the predictions of KLM models.
</p>
<p>(1) Keystroke times vary. Card et al. (1983) include tables that provide different
</p>
<p>times for different keystrokes. These tables do not differentiate different typist
</p>
<p>speeds, but do show that different keys take different times. This suggests that
</p>
<p>324 11 Methodology I: Task Analysis</p>
<p/>
</div>
<div class="page"><p/>
<p>interfaces should choose keys that are fast (and presumably easy to type). This
</p>
<p>suggestion includes choosing words that use both hands for touch typists and
</p>
<p>avoiding punctuation characters (which are slower to press).
</p>
<p>(2) The gross predictions of mouse moves and drags can be made more accurate
</p>
<p>by using Fitts&rsquo; law to make predictions based on the target size and distance.
</p>
<p>When the initial location of the mouse is not known, it can be approximated.
</p>
<p>(3) The system response time can be computed using tools to analyze key press
</p>
<p>times. The response times are still important in devices such as ATMs, and in
</p>
<p>systems which may be required to present the same data simultaneously on
</p>
<p>different continents, within a multinational company, for example.
</p>
<p>11.6.2 Example Application of the KLM
</p>
<p>Table 11.6 shows an example KLM analysis worked out for a simple text editing
</p>
<p>task of cutting a phrase (Step 1), inserting it (Step 2), changing the case of two
</p>
<p>letters (Steps 3 and 4), and taking up the next task (Step 5). The analysis suggests
</p>
<p>that the time to perform this task is not so long (24 s). Thus, if this edit takes
</p>
<p>longer, it is not the interface that is restraining the user&rsquo;s progress, it is the
</p>
<p>cognition to come up with the letters or to think about other changes. It is the
</p>
<p>writing, essentially, to come up with the changes that takes so long!
</p>
<p>11.6.3 Summary
</p>
<p>Although closely related to GOMS, note how keystroke-level analysis is closer to
</p>
<p>time-and-motion (chronological) analysis than goal/subgoal analysis. It assumes a
</p>
<p>simple world: concentration on one task at a time, a fully specified interface, no
</p>
<p>Table 11.6 Example application of the KLM to a simple editing task
</p>
<p>Method
</p>
<p>1. Delete 3rd clause. H[mouse] K[mouse down] P K[mouse up] M K[D]
</p>
<p>2. Insert it in front of 1st clause. P M K[l] K[ESC]
</p>
<p>3. Replace &lsquo;&lsquo;: o&rsquo;&rsquo; with &lsquo;&lsquo;O&rsquo;&rsquo;. P M 2 K[SHIFT R] H[keyboard] 2 K[O ESC]
</p>
<p>4. Replace &lsquo;&lsquo;T&rsquo;&rsquo; by &lsquo;&lsquo;: t&rsquo;&rsquo;. H[mouse] K[mouse down] M K[R] H[keyboard] 4 K[: SPACE t ESC]
</p>
<p>5. Delete 3rd clause. H[mouse] P K[mouse] M K[D]
</p>
<p>6. Insert it in front of 2nd clause. K M K[l] K[ESC]
</p>
<p>7. Find next task. M K[F]
</p>
<p>Time Predictions
</p>
<p>Texecute = [23 tK + 4 tP + 5 tH] + 7 tM
= 22 (0.15) + 4 (1.1) + 5 (0.4)] + 7(1.35)
</p>
<p>= 19.15 s
</p>
<p>Note that in this example the same average time is used for each keystroke
</p>
<p>11.6 The Keystroke Level Model 325</p>
<p/>
</div>
<div class="page"><p/>
<p>interleaving of goals, no interruptions, a single method, error-free, expert perfor-
</p>
<p>mance, and so on. Indeed, KLMs can be developed without worrying about goals
</p>
<p>and selection rules. These limitations make the KLM easier to use, but they also
</p>
<p>highlight the types of tasks that cannot easily be modeled using the KLM and
</p>
<p>where it will not give accurate results.
</p>
<p>Quite a considerable effort has gone into trying to make KLMs more usable&mdash;
</p>
<p>particularly by building computer tools to apply them (Beard et al. 1996; Nichols
</p>
<p>and Ritter 1995; Williams 2000) and to extend them to new types of interfaces
</p>
<p>such as mobile GPS systems (Pettitt et al. 2007). These tools provide a language
</p>
<p>for defining KLM and GOMS models and computing the task time based on the
</p>
<p>analyses, although sometimes it may be just as easy to use a spreadsheet.
</p>
<p>11.7 Considerations When Choosing a TA Method
</p>
<p>There are some general issues that you need to be aware of when deciding whether
</p>
<p>to carry out a TA to inform system design, as they will influence how successful
</p>
<p>the TA is. Superficially it appears quite an easy technique to use, but to carry out a
</p>
<p>TA that produces useful results that can inform system design is an acquired skill.
</p>
<p>It requires skills in collecting the appropriate data or task specifications, analyzing
</p>
<p>that material, and then interpreting it.
</p>
<p>It may seem obvious, but to perform a TA, you need to have access to a detailed
</p>
<p>enough task description. This can either be written (documentation) or captured
</p>
<p>through interviews and observation. If you are using interviews and observation,
</p>
<p>you need to make sure that you can get access to the appropriate people in a timely
</p>
<p>manner. For new or unimplemented interfaces you can often base your analyses on
</p>
<p>existing interfaces and extrapolations. If you are analyzing an unbuilt interface you
</p>
<p>should note your assumptions very clearly.
</p>
<p>Different types of TA place emphasis on different aspects of task performance.
</p>
<p>You need to be aware of this. If you are interested in the work context, for
</p>
<p>example, then HTA will help; if you are more interested in the cognitive aspects of
</p>
<p>the task, you will be better off using some form of CTA. The different methods are
</p>
<p>not mutually exclusive.
</p>
<p>In general, TA cannot easily simultaneously represent users with different
</p>
<p>levels of knowledge, skills, and abilities. Novice users and the way a task is
</p>
<p>learned, for example, are not well represented by most of these techniques. TA
</p>
<p>techniques, when applied sympathetically, can help support novice users, but this
</p>
<p>has to be done by the analyst. Most methods can deal with some aspects of task
</p>
<p>learning, such as how much knowledge has to be learned in order to do the task. To
</p>
<p>model the time course of learning you may need to develop a more detailed
</p>
<p>cognitive model (e.g., see Paik et al. 2010; Ritter and Bibby 2008).
</p>
<p>Most methods of TA are strongly goal-oriented. These methods cannot gen-
</p>
<p>erally be applied to situations that have little structure or only very abstract goals,
</p>
<p>such as play, conversation, and team building. All TA should be done with an
</p>
<p>326 11 Methodology I: Task Analysis</p>
<p/>
</div>
<div class="page"><p/>
<p>understanding of the general context in relation to work and activities. Methods
</p>
<p>like activity theory address these issues (e.g., see Bertelsen and B&oslash;dker 2003 for an
</p>
<p>introductory review). Activity theory is a very high level method that analyses the
</p>
<p>types of user activities, generally using a very informal representation. It uses these
</p>
<p>descriptions to suggest how to design the context in which the activities take place.
</p>
<p>For example, identifying children&rsquo;s activities (play activities, painting, block
</p>
<p>stacking, and doll-house play, for example), would inform the design of a kin-
</p>
<p>dergarten room. Similar analyses make strong suggestions about the design of
</p>
<p>research labs (collaboration spaces, mailing rooms, teaching rooms) and interfaces
</p>
<p>where goals are less important than activities such as drawing, designing, inter-
</p>
<p>acting, team-building, exploring, or enjoying.
</p>
<p>Most TA methods do not note and are not sensitive to context, including
</p>
<p>physical context such as lighting and heating, social norms such as doing what
</p>
<p>helps others in the environment, and not using others space or resources. It is
</p>
<p>especially common in work places to discover that the physical or social context
</p>
<p>produces changes in the way people do tasks from how they would ideally do
</p>
<p>them, or from the way they are supposed to do them. Casey (1998, 2006) provides
</p>
<p>numerous examples where not understanding the context on task analyses and on
</p>
<p>design led to problems, such as where other people are when the user is doing a
</p>
<p>task (not in the path of the rocket!), or the effect of weather on how to do tasks and
</p>
<p>which tasks to do on a ship.
</p>
<p>11.8 Summary
</p>
<p>Task analysis in all its various guises is a very useful technique, and usually fairly
</p>
<p>easy to perform when designing systems, which may help explain why it is so
</p>
<p>widely used. The results of a task analysis can be used to help designers create
</p>
<p>easier to use interfaces by highlighting the structure of tasks, and the time it takes
</p>
<p>to perform tasks, as well as making it easier to compare alternative methods for
</p>
<p>carrying out those tasks. Task analysis can also be used to represent the trade-offs
</p>
<p>in designs, helping designers to make informed decisions. TA can also be used
</p>
<p>directly to improve interfaces, and Table 11.7 notes a few common ways in which
</p>
<p>TA can help improve interfaces.
</p>
<p>There are many different uses for task analysis, and the method that you choose
</p>
<p>will depend to some extent on how you intend to use the results. Choosing any one
</p>
<p>is better than none, that you should choose one that is easy for you to use because
</p>
<p>you are a user as well. The choice will also be affected by the context in which you
</p>
<p>will use the method, the limitations, and possibly the experience of the analyst(s)
</p>
<p>(several of the methods work at similar levels of abstraction, so they can be used
</p>
<p>somewhat interchangeably).
</p>
<p>Using task analyses to guide system design has a good return on investment
</p>
<p>(RoI), ranging from 7 to 20 to 100 in one survey (Booher and Minninger 2003) to
</p>
<p>1,000 in another more focused HCI study (Nielsen and Phillips 1993). Given the
</p>
<p>11.7 Considerations When Choosing a TA Method 327</p>
<p/>
</div>
<div class="page"><p/>
<p>multiple ways that task analyses can be used and the savings they suggest, these
</p>
<p>numbers are quite plausible.
</p>
<p>The various forms of task analysis can be ordered by how much detail they
</p>
<p>include. A preliminary classification can be into declarative and procedural rep-
</p>
<p>resentations. The declarative representations merely denote the actions or tasks the
</p>
<p>users will perform. The simplest of these are HTA and CTA. The KLM is a
</p>
<p>slightly more complex example of this because it attributes time to each action.
</p>
<p>Procedural task descriptions, such as advanced versions of GOMS (John and
</p>
<p>Kieras 1996b) and models in cognitive architectures (noted in the final chapter),
</p>
<p>can include enough procedural knowledge of how to perform the task such that
</p>
<p>they can also perform the task in some way, perhaps with a simplified version of
</p>
<p>the interface. Declarative representations of behavior, like the KLM, for example,
</p>
<p>will note that the result of a mathematical task is &lsquo;&lsquo;a number,&rsquo;&rsquo; whereas a fully
</p>
<p>procedural task analysis will be able to compute the actual number. This chapter
</p>
<p>discusses several examples of each type. There is a wide range of approaches, and
</p>
<p>descriptions of them are available in surveys (Adams et al. 2012; Beevis 1999;
</p>
<p>Schraagen et al. 2000), as well as in manuals and tutorials on these other TA
</p>
<p>approaches.
</p>
<p>As you use TA in a wider range of situations, you should become more skilled
</p>
<p>in applying it. For specific situations you may want to look at some of the more
</p>
<p>specialized forms of task analysis. For example, if you have many novice users,
</p>
<p>you might create a situation where the user has to read the documentation to find
</p>
<p>the commands, which means that your design should ensure that the knowledge of
</p>
<p>how to use the interface is findable or transmitted to the novice through instruc-
</p>
<p>tions, conventions, and other design elements. When you need to do more complex
</p>
<p>analyses, for example, where error recovery or multi-tasking is important, you may
</p>
<p>need to consult further material to find the most appropriate technique, as well as
</p>
<p>investigate supplementary techniques such as knowledge elicitation (e.g., Ericsson
</p>
<p>and Simon 1993; Kirwan and Ainsworth 1992; Schraagen et al. 2000; Shadbolt
</p>
<p>2005; Shadbolt and Burton 1995).
</p>
<p>Table 11.7 Ways to use TA to improve interfaces
</p>
<p>1. Modify the interface to support all the tasks in the TA
</p>
<p>2. Modify the interface to not support tasks not required by the task analysis
</p>
<p>3. Modify the interface to do steps for the user where choices are not required
</p>
<p>4. Modify the interface to use fewer actions
</p>
<p>5. Modify the interface to use a simpler task structure
</p>
<p>6. Modify the interface to provide more regular knowledge/interactions to perform related tasks
</p>
<p>7. Modify the interface to not require holding state variables in the task analysis or user&rsquo;s head
</p>
<p>8. Modify the interface to make common tasks faster
</p>
<p>9. Modify the interface to make expensive tasks slower/harder to initiate
</p>
<p>10. Teach any alternative methods through and in the interface
</p>
<p>328 11 Methodology I: Task Analysis</p>
<p/>
</div>
<div class="page"><p/>
<p>The results of a task analysis on their own will not tell you whether a particular
</p>
<p>system or interface is acceptable or not. It just shows how well the system or
</p>
<p>interface will work for particular tasks for particular people (in a particular con-
</p>
<p>text). Decisions about modifications to the system or interface will often require
</p>
<p>consideration of other factors, such as the resources that are available for further
</p>
<p>development, other systems or interfaces (to cater for consistency and interoper-
</p>
<p>ability, for example), and assumptions about the target users. Task analysis cannot
</p>
<p>suggest whether novices should be served preferentially by the system, or whether
</p>
<p>experts should be supported in an interface design, but TA can help compute the
</p>
<p>costs and represent the trade-offs involved in making such decisions.
</p>
<p>11.9 Other Resources
</p>
<p>The Handbook of task analysis for human-computer interaction, edited by Dan
</p>
<p>Diaper and Neville Stanton (2003), although 10 years old, still provides a fairly
</p>
<p>comprehensive overview of TA. It makes a useful reference book, rather than
</p>
<p>being something that you should read from cover to cover. A more general, but
</p>
<p>still useful overview of the many types of TA and their application is Kirwan and
</p>
<p>Ainsworth&rsquo;s A Guide to Task Analysis (1992) even though it is now over 20 years
</p>
<p>old.
</p>
<p>Clayton Lewis and John Rieman&rsquo;s shareware book, Task-Centered User
</p>
<p>Interface Design (1994), www.hcibib.org/tcuid/ provides a useful expansion of the
</p>
<p>material in this chapter, particularly on the role of task analysis in system design.
</p>
<p>Shepherd&rsquo;s book, Hierarchical Task Analysis (2004), provides a detailed dis-
</p>
<p>cussion of HTA. It illustrates how it can be applied to a wide range of tasks, and
</p>
<p>how the results can generate a wide range of benefits.
</p>
<p>For a practical guide to using CTA it is worth looking at Working Minds: A
</p>
<p>practitioner&rsquo;s guide to Cognitive Task Analysis by Crandall et al. (2006). For
</p>
<p>details about the sorts of methods that can be used in a CTA, it is worth consulting
</p>
<p>Applied Cognitive Task Analysis in aviation by Thomas Seamster et al. (1997), and
</p>
<p>Human factors methods by Neville Stanton et al. (2005).
</p>
<p>David Kieras has papers, manuals, and tools covering the KLM, GOMS, and
</p>
<p>task analyses available via his web site: www.ai.eecs.umich.edu/people/kieras/
</p>
<p>kieras.html. You can also find several KLM calculators online. With these you
</p>
<p>simply enter the KLM operators that are used to do the task, and the total time is
</p>
<p>automatically calculated for you.
</p>
<p>Kim Vicente&rsquo;s book Cognitive Work Analysis (1999) describes a broader,
</p>
<p>integrated framework which includes models of the work domain, control tasks,
</p>
<p>strategies social-organizational factors, and worker competencies. This framework
</p>
<p>builds on the body of work called cognitive (systems) engineering which focuses
</p>
<p>on the analysis, design, and evaluation of complex socio-technical systems.
</p>
<p>The book&rsquo;s web site has additional information on task analysis including some
</p>
<p>tools.
</p>
<p>11.8 Summary 329</p>
<p/>
<div class="annotation"><a href="http://www.hcibib.org/tcuid/">http://www.hcibib.org/tcuid/</a></div>
<div class="annotation"><a href="http://www.ai.eecs.umich.edu/people/kieras/kieras.html">http://www.ai.eecs.umich.edu/people/kieras/kieras.html</a></div>
<div class="annotation"><a href="http://www.ai.eecs.umich.edu/people/kieras/kieras.html">http://www.ai.eecs.umich.edu/people/kieras/kieras.html</a></div>
</div>
<div class="page"><p/>
<p>11.10 Exercises
</p>
<p>11.1 Create a table showing each type of task analysis. Note (a) the focus of the
</p>
<p>approach (work, the task, what the user knows, etc.); (b) what they are typi-
</p>
<p>cally used for, for example, what predictions they can provide; (c) an example
</p>
<p>snippet of analysis; (d) how time intensive you believe they will be (easy to do,
</p>
<p>hard to do); and (e) the advantages and disadvantages of each type.
</p>
<p>11.2 Choose an existing interface and list the tasks it can or should be used for.
</p>
<p>Perform a task analysis. From this task analysis make five suggestions how it
</p>
<p>could be improved. Interfaces to consider include word processors, spread-
</p>
<p>sheets, online libraries, and email clients.
</p>
<p>11.3 Write a short report on tasks you or a study partner do at your desk, and the
</p>
<p>quality of the desk and work area to support those tasks. Compare it with the
</p>
<p>non-work related tasks that you do indulge in (e.g., play with a pencil, line up
</p>
<p>your toy cars, doodle, drink coffee) at your desk. Make suggestions for
</p>
<p>improving the workspace in question. Then, do the same thing for your
</p>
<p>computer display.
</p>
<p>11.4 List ten ways that the KLM or GOMS methods could be made more accurate.
</p>
<p>You should be able to do this using this book. For example, the section on
</p>
<p>reading makes several suggestions for making these models more accurate
</p>
<p>with respect to adjusting for users&rsquo; reading speed and the material being read.
</p>
<p>11.5 Consider a smartphone or tablet computer, either a specific one or a com-
</p>
<p>posite one. Devise a trade-off function between a set of features (which you
</p>
<p>specify) and weight. Describe how to choose a reasonable point on that
</p>
<p>curve. Use a task analysis that provides estimates of task time to represent
</p>
<p>this design trade-off.
</p>
<p>11.6 Use a task analysis methodology to examine two related online systems, such
</p>
<p>as bookstores. You should choose three to five important tasks, and explain
</p>
<p>why these are important tasks for this analysis. How do their assumptions
</p>
<p>differ as represented in the task analysis? For example, does one assume that
</p>
<p>you log in before browsing, or does one assume that you read recommen-
</p>
<p>dations before purchasing?
</p>
<p>11.7 Use a task analysis methodology that you choose to calculate how long it
</p>
<p>takes to perform the following tasks using a spreadsheet program, using a
</p>
<p>calculator, and using your cell phone: (a) a tip on a $13.28 restaurant bill;
</p>
<p>(b) your salary raise as a percentage from $8.50 to $8.85/h (c) your hourly
</p>
<p>rate if you work 40 h per week and 48 weeks per year and make $45,000 per
</p>
<p>year, and (d) your hourly rate from the previous problem, but starting from
</p>
<p>scratch, if you had a 3% raise. Comment on at what point in time you should
</p>
<p>switch between these three tools.
</p>
<p>11.8 Use a task analysis methodology to calculate how long it takes to select and to
</p>
<p>delete an automatic signature to your email, using your signature rather than
</p>
<p>the one in Sect. 11.8. Is it faster to insert the signature manually when you
</p>
<p>need it, or to included it automatically and delete it when you do not need it?
</p>
<p>330 11 Methodology I: Task Analysis</p>
<p/>
</div>
<div class="page"><p/>
<p>Draw a curve representing the time to use both strategies as the frequency
</p>
<p>of need to sign an email changes from 0 to 100% in 10% increments.
</p>
<p>11.9 In 2003 the University of Denver (noted in the Chronicle of Higher Edu-
</p>
<p>cation, 19 December, p. A35) decided to require all applicants to be inter-
</p>
<p>viewed by college officials. The question on the interviewers&rsquo; minds,
</p>
<p>according to the assistant vice chancellor for enrollment management, is
</p>
<p>&lsquo;&lsquo;Will the kid graduate?&rsquo;&rsquo; The retention rate has gone from 82 to 86%
</p>
<p>because (or despite) the college starting using the system 2 years ago.
</p>
<p>(a) Based on your experience as a college student, come up with a task
</p>
<p>analysis of what you have to do to be (i) successful in college and
</p>
<p>(ii) graduate. Include multiple strategies and allow tasks you need to
</p>
<p>terminate or avoid. (This integrates results from several chapters.) Do
</p>
<p>keep in mind that GPA is an important but surely not the only measure of
</p>
<p>success in college, and you might note other successes besides
</p>
<p>graduation.
</p>
<p>(b) Discuss how you would interview someone to find out whether they can
</p>
<p>do these tasks.
</p>
<p>(c) Can you provide any alternative hypotheses about why retention might
</p>
<p>have gone up besides the interview process?
</p>
<p>References
</p>
<p>Adams, A. E., Rogers, W. A., &amp; Fisk, A. D. (2012). Choosing the right task analysis tool.
Ergonomics in Design: The Quarterly of Human Factors Applications, 20(4), 4&ndash;10.
</p>
<p>Annett, J. (2005). Hierarchical task analysis (HTA). In N. Stanton, A. Hedge, K. Brookhuis, E.
Salas &amp; H. Hendrick (Eds.), Handbook of human factors and ergonomics methods (pp. 33-
31&ndash;33-37). Boca Raton, FL: CRC Press.
</p>
<p>Baxter, G. D., Monk, A. F., Tan, K., Dear, P. R. F., &amp; Newell, S. J. (2005). Using cognitive task
analysis to facilitate the integration of decision support systems into the neonatal intensive
care unit. Artificial Intelligence in Medicine, 35, 243&ndash;257.
</p>
<p>Beard, D. V., Smith, D. K., &amp; Denelsbeck, K. M. (1996). Quick and dirty GOMS: A case study of
computed tomography interpretation. Human-Computer Interaction, 11, 157&ndash;180.
</p>
<p>Beevis, D. (Ed.). (1999). Analysis techniques for human-machine systems design: A report
produced under the auspices of NATO Defence Research Group Panel 8. Wright-Patterson
Air Force Base, OH: Crew Systems Ergonomics/Human Systems Technology Information
Analysis Center.
</p>
<p>Bertelsen, O. W., &amp; B&oslash;dker, S. (2003). Activity theory. In J. M. Carroll (Ed.), HCI models,
theories and frameworks: Toward a multi-disciplinary science. San Francisco, CA: Morgan
Kaufmann.
</p>
<p>Booher, H. R., &amp; Minninger, J. (2003). Human systems integration in Army systems acquisition.
In H. R. Booher (Ed.), Handbook of human systems integration (pp. 663&ndash;698). Hoboken, NJ:
Wiley.
</p>
<p>Bovair, S., Kieras, D. E., &amp; Polson, P. G. (1990). The acquisition and performance of text-editing
skill: A cognitive complexity analysis. Human-Computer Interaction, 5, 1&ndash;48.
</p>
<p>Byrne, M. D., &amp; Kirlik, A. (2005). Using computational cognitive modeling to diagnose possible
sources of aviation error. International Journal of Aviation Psychology, 15(2), 135&ndash;155.
</p>
<p>11.10 Exercises 331</p>
<p/>
</div>
<div class="page"><p/>
<p>Card, S. K., Moran, T. P., &amp; Newell, A. (1980). The keystroke-level model for user performance
time with interactive systems. Communications of the ACM, 23(7), 396&ndash;410.
</p>
<p>Card, S. K., Moran, T. P., &amp; Newell, A. (1983). The psychology of human-computer interaction.
Hillsdale, NJ: Erlbaum.
</p>
<p>Casey, S. M. (1998). Set phasers on stun: And other true tales of design, technology, and human
error. Santa Barbara, CA: Aegean.
</p>
<p>Casey, S. M. (2006). The Atomic Chef: And other true tales of design, technology, and human
error. Santa Barbara, CA: Aegean.
</p>
<p>Chipman, S. F., &amp; Kieras, D. E. (2004). Operator centered design of ship systems. In Engineering
the Total Ship Symposium. NIST, Gaithersburg, MD. American Society of Naval Engineers.
Retrieved March 10, 2014, from http://handle.dtic.mil/100.2/ADA422107
</p>
<p>Crandall, B., Klein, G., &amp; Hoffman, R. R. (2006). Working minds: A practitioner&rsquo;s guide to
cognitive task analysis. Cambridge, MA: MIT Press.
</p>
<p>Diaper, D. (2004). Understanding task analysis. In D. Diaper &amp; N. Stanton (Eds.), The handbook
of task analysis for human-computer interaction (pp. 5&ndash;47). Mahwah, NJ: LEA.
</p>
<p>Ericsson, K. A., &amp; Simon, H. A. (1993). Protocol analysis: Verbal reports as data (2nd ed.).
Cambridge, MA: MIT Press.
</p>
<p>Fitts, P. M. (1951). Human engineering for an effective air navigation and traffic control system.
Washington, DC: National Research Council.
</p>
<p>Freed, M., &amp; Remington, R. (1998). A conceptual framework for predicting error in complex
human-machine environments. In Proceedings of the 20th Annual Conference of the
Cognitive Science Society (pp. 356&ndash;361). Mahwah, NJ: Erlbaum.
</p>
<p>Gray, W. D., John, B. E., &amp; Atwood, M. E. (1992). The precis of project ernestine or an overview
of a validation of GOMS. In Proceedings of the CHI&lsquo;92 Conference on Human Factors in
Computer Systems. New York, NY: ACM Press.
</p>
<p>John, B. E., &amp; Kieras, D. E. (1996a). The GOMS family of user interface analysis techniques:
Comparison and contrast. ACM Transactions on Computer-Human Interaction, 3(4),
320&ndash;351.
</p>
<p>John, B. E., &amp; Kieras, D. E. (1996b). Using GOMS for user interface design and evaluation:
Which technique? ACM Transactions on Computer-Human Interaction, 3(4), 287&ndash;319.
</p>
<p>Kieras, D. E. (1999). A guide to GOMS model usability evaluation using GOMSL and GLEAN3:
AI Lab, University of Michigan. Available from www.ftp.eecs.umich.edu/people/kieras
</p>
<p>Kieras, D. E., &amp; Polson, P. G. (1985). An approach to the formal analysis of user complexity.
International Journal of Man-Machine Studies, 22, 365&ndash;394.
</p>
<p>Kirwan, B., &amp; Ainsworth, L. K. (1992). A guide to task analysis. London, UK: Taylor &amp; Francis.
Klein, G., Calderwood, R., &amp; MacGregor, D. (1989). Critical decision method for eliciting
</p>
<p>knowledge. IEEE Transactions on Systems, Man, and Cybernetics, 19, 462&ndash;472.
Monk, A. F. (1998). Lightweight techniques to encourage innovative user interface design. In L.
</p>
<p>Wood (Ed.), User interface design: Bridging the gap between user requirements and design
(pp. 109&ndash;129). Boca Raton, FL: CRC Press.
</p>
<p>Nichols, S., &amp; Ritter, F. E. (1995). A theoretically motivated tool for automatically generating
command aliases. In Proceedings of the CHI&lsquo;95 Conference on Human Factors in Computer
Systems (pp. 393&ndash;400). New York, NY: ACM.
</p>
<p>Nielsen, J., &amp; Phillips, V. L. (1993). Estimating the relative usability of two interfaces: Heuristic,
formal, and empirical methods compared. In Proceedings of InterCHI &lsquo;93 (pp. 214&ndash;221).
New York, NY: ACM.
</p>
<p>Paik, J., Kim, J. W., Ritter, F. E., Morgan, J. H., Haynes, S. R., &amp; Cohen, M. A. (2010). Building
large learning models with Herbal. In D. D. Salvucci &amp; G. Gunzelmann (Eds.), Proceedings
of ICCM: 2010- Tenth International Conference on Cognitive Modeling (pp. 187&ndash;191).
</p>
<p>Pettitt, M., Burnett, G., &amp; Stevens, A. (2007). An extended keystroke level model (KLM) for
predicting the visual demand of in-vehicle information systems. In Proceedings of the
SIGCHI Conference on Human Factors in Computing Systems (pp. 1515&ndash;1524). ACM.
</p>
<p>Ritter, F. E., &amp; Bibby, P. A. (2008). Modeling how, when, and what learning happens in a
diagrammatic reasoning task. Cognitive Science, 32, 862&ndash;892.
</p>
<p>332 11 Methodology I: Task Analysis</p>
<p/>
<div class="annotation"><a href="http://handle.dtic.mil/100.2/ADA422107">http://handle.dtic.mil/100.2/ADA422107</a></div>
<div class="annotation"><a href="http://www.ftp.eecs.umich.edu/people/kieras">http://www.ftp.eecs.umich.edu/people/kieras</a></div>
</div>
<div class="page"><p/>
<p>Ritter, F. E., Freed, A. R., &amp; Haskett, O. L. (2002). Discovering user information needs: The case
of university department websites (Tech. Report No. 2002-3): Applied Cognitive Science Lab,
School of Information Sciences and Technology, Penn State. www.acs.ist.psu.edu/acs-lab/
reports/ritterFH02.pdf
</p>
<p>Schraagen, J. M., Chipman, S. F., &amp; Shalin, V. L. (Eds.). (2000). Cognitive task analysis.
Mahwah, NJ: Erlbaum.
</p>
<p>Seamster, T. L., Redding, R. E., &amp; Kaempf, G. L. (1997). Applied cognitive task analysis in
aviation. Aldershot, UK: Avebury Aviation.
</p>
<p>Shadbolt, N. R. (2005). Eliciting expertise. In J. R. Wilson &amp; E. Corlett (Eds.), Evaluation of
human work (3rd Edition, pp. 185&ndash;218). London: Taylor and Francis.
</p>
<p>Shadbolt, N. R., &amp; Burton, A. M. (1995). Knowledge elicitation: A systematic approach. In
J. R. Wilson &amp; E. N. Corlett (Eds.), Evaluation of human work: A practical ergonomics
methodology (pp. 406&ndash;440). London: Taylor and Francis.
</p>
<p>St. Amant, R., Freed, A. R., &amp; Ritter, F. E. (2005). Specifying ACT-R models of user interaction
with a GOMS language. Cognitive Systems Research, 6(1), 71&ndash;88.
</p>
<p>St. Amant, R., Horton, T. E., &amp; Ritter, F. E. (2004). Model-based evaluation of cell phone menu
interaction. In Proceedings of the CHI&lsquo;04 Conference on Human Factors in Computer
Systems (pp. 343&ndash;350). New York, NY: ACM.
</p>
<p>St. Amant, R., Horton, T. E., &amp; Ritter, F. E. (2007). Model-based evaluation of expert cell phone
menu interaction. ACM Transactions on Computer-Human Interaction, 14(1), 24.
</p>
<p>Vicente, K. (1999). Cognitive work analysis. Mahwah, NJ: Erlbaum.
</p>
<p>References 333</p>
<p/>
<div class="annotation"><a href="http://www.acs.ist.psu.edu/acs-lab/reports/ritterFH02.pdf">http://www.acs.ist.psu.edu/acs-lab/reports/ritterFH02.pdf</a></div>
<div class="annotation"><a href="http://www.acs.ist.psu.edu/acs-lab/reports/ritterFH02.pdf">http://www.acs.ist.psu.edu/acs-lab/reports/ritterFH02.pdf</a></div>
</div>
<div class="page"><p/>
<p>Chapter 12
</p>
<p>Methodology II: Cognitive Dimensions
</p>
<p>and the Gulfs
</p>
<p>Abstract This chapter introduces two useful high-level approaches that summa-
</p>
<p>rize a wide range of aspects of users: how users interact with artifacts and how
</p>
<p>users perform tasks. A type of analysis, Cognitive Dimension/dimensions, pro-
</p>
<p>vides a way to represent common and important aspects of interface design. The
</p>
<p>dimensions are used to describe and then evaluate interfaces. Norman has a similar
</p>
<p>description of user behavior based on how hard it is to understand the state of the
</p>
<p>interface (the Gulf of Understanding) and how hard it is to perform an action in an
</p>
<p>interface (the Gulf of Execution). Both approaches are useful techniques for
</p>
<p>thinking about, planning, and performing interface design.
</p>
<p>12.1 Introduction
</p>
<p>So far we have presented several methods and techniques for analyzing Human-
</p>
<p>System Interaction, including task analysis as a general tool, and GOMS and the
</p>
<p>KLM as more detailed formal approaches for use prior to user testing. Most of the
</p>
<p>methods we have presented are applied at a low level of abstraction. In contrast,
</p>
<p>the Cognitive Dimensions (of Notations), usually just referred to as Cognitive
</p>
<p>Dimensions or CDs (e.g., Blackwell and Green 2003; Green 1989), was developed
</p>
<p>as a mechanism for discussing and analyzing systems at a higher level of
</p>
<p>abstraction.
</p>
<p>The CDs are based on the assumption that it is useful to have a language for
</p>
<p>discussing design. One way of trying to understand design is to describe the object
</p>
<p>that is being designed, and the trade-offs that the designer faces using a small
</p>
<p>number of fundamental dimensions. These dimensions can then provide a common
</p>
<p>language (sometimes called an ontology) for discussing usability problems, as well
</p>
<p>as a means of comparing aspects of interface and system design, and for com-
</p>
<p>paring whole designs. Thus, the CDs can be seen as a way of providing a common
</p>
<p>ontology for naming aspects of design as well as for naming design trade-offs.
</p>
<p>F. E. Ritter et al., Foundations for Designing User-Centered Systems,
DOI: 10.1007/978-1-4471-5134-0_12, ï¿½ Springer-Verlag London 2014
</p>
<p>335</p>
<p/>
</div>
<div class="page"><p/>
<p>The goal of the CDs is to provide a fairly small, representative set of labeled
</p>
<p>dimensions that describe critical ways in which interfaces, systems, and envi-
</p>
<p>ronments can vary from the perspective of usability. Once the dimensions have
</p>
<p>been labeled the designers can more easily discuss alternative designs.
</p>
<p>In this chapter we will outline some of the dimensions and illustrate them with
</p>
<p>examples. The complete set of dimensions, however, does not yet exist&mdash;this is
</p>
<p>still a research issue and the set of dimensions for a given design is probably tied to
</p>
<p>the context of the design. Research in this area is proceeding in two directions:
</p>
<p>trying to find ways of formalizing and measuring the dimensions currently pro-
</p>
<p>posed, and trying to explore the completeness and redundancy of the current set of
</p>
<p>dimensions.
</p>
<p>We will also describe an alternative viewpoint on dimensions, based on the
</p>
<p>work of Norman (1988, 2013). Norman&rsquo;s dimensions describe how users interact
</p>
<p>with devices, focusing on the relationship between actions and intentions, and
</p>
<p>between the results of actions and the way they are interpreted.
</p>
<p>12.2 The Cognitive Dimensions
</p>
<p>Table 12.1 notes the (current) set of 14 Cognitive Dimensions. Research into the
</p>
<p>CDs is ongoing, so the list should not be regarded as finalized or complete. The
</p>
<p>CDs can be extended to make them more appropriate to your own situation.
</p>
<p>Below we describe the first five CDs in more detail. Our main purpose here is to
</p>
<p>illustrate what the CDs are, and how they can be used.
</p>
<p>12.2.1 Hidden Dependencies
</p>
<p>Dependencies are the number and direction of relationships between objects. For
</p>
<p>example, spreadsheets show you formulae in one direction only, that is, which
</p>
<p>cells are used to compute the value in a cell, but not which cells use a given cell&rsquo;s
</p>
<p>value; similarly, variable declarations in programming languages like Java or
</p>
<p>Pascal show you which variable type a structure is made from, but not the other
</p>
<p>way around; and the Microsoft Word Styles dialogue box (Fig. 12.1) shows you
</p>
<p>the parent of a style but not its children.
</p>
<p>In all of these examples there are two hidden (or invisible) types of dependency:
</p>
<p>ancestors and children. Only the parents are visible, and finding the ancestors
</p>
<p>involves following a chain of parents. Working in the opposite direction, finding
</p>
<p>the children involves checking every entity for its parent, which creates a high
</p>
<p>memory and work load. Another example of the problem of hidden dependencies
</p>
<p>occurs in variable initialization and use: in many procedural and production sys-
</p>
<p>tem languages you need to use a combination of tools and deep knowledge to find
</p>
<p>out what the dependencies are.
</p>
<p>336 12 Methodology II: Cognitive Dimensions and the Gulfs</p>
<p/>
</div>
<div class="page"><p/>
<p>The implications of considering hidden dependencies are that all dependencies
</p>
<p>that may be relevant to the user&rsquo;s tasks should be represented. Or, as a minimum,
</p>
<p>tools should be provided which enable them to be represented. This is consistent
</p>
<p>with the notion we saw earlier in the book of recognition being easier than recall.
</p>
<p>For example, spreadsheets would be easier to use (for certain tasks anyway) if they
</p>
<p>could show forward relationships (e.g., this cell&rsquo;s value is used in all these other
</p>
<p>places). Recognizing this fact (the need for visibility) is quite separate from
</p>
<p>designing a solution to the problem&mdash;one option would be to use color coding
</p>
<p>(e.g., child cells could be shown in the same color; ancestor cells could be shown
</p>
<p>Table 12.1 The Cognitive Dimensions
</p>
<p>1. Hidden dependencies: how visible the relationships between components are
</p>
<p>2. Viscosity: how easy it is to change objects in the interface
</p>
<p>3. Role-expressiveness: how clear the mapping of the objects are to their functions
</p>
<p>4. Premature commitment: how soon the user has to decide something
</p>
<p>5. Hard mental operations: how hard are the mental operations to use the interface
</p>
<p>6. Secondary notation: the ability to add extra semantics
</p>
<p>7. Abstraction: how abstract the operations and system are
</p>
<p>8. Error-proneness susceptibility: how easy it is to err
</p>
<p>9. Consistency: how uniform the system is (in various ways, including action mapping)
</p>
<p>10. Visibility: whether required information is accessible without work by the user
</p>
<p>11. Progressive evaluation: whether you can stop in the middle of creating some notation and
check what you have done so far
</p>
<p>12. Provisionality: whether you can sketch out ideas without being too exact
</p>
<p>13. Diffuseness: how verbose the language is
</p>
<p>14. Closeness of mapping: how close the representation in the interface (also called notation) is to
the end results being described
</p>
<p>Fig. 12.1 The Word Style editor (left) shows the parent of the ref style, but cannot show the
children of the Normal style. The spreadsheet (right) shows what cells the formula is dependent
on (and can show those that appear as the line on the graph), but does not show where a given cell
is used
</p>
<p>12.2 The Cognitive Dimensions 337</p>
<p/>
</div>
<div class="page"><p/>
<p>in ever paler shades of the same color). Some spreadsheets now provide the
</p>
<p>capability to show child cells, thus making the dependencies less hidden.
</p>
<p>A much richer form of hidden dependency occurs in many modern operating
</p>
<p>systems, where several files are both generated and used. Applications other than
</p>
<p>those that created them may be dependent upon these files, such as a pictorial
</p>
<p>figure in a spreadsheet file, a graphics file used in a report, or a preferences file
</p>
<p>stored somewhere away from its application and labeled with the name of the
</p>
<p>company or user rather than the application. These dependencies are not visible&mdash;
</p>
<p>deleting files from system and user preferences directories therefore becomes a
</p>
<p>hazardous task. The corollary is that people&rsquo;s file stores get filled up with old,
</p>
<p>unused files and you cannot easily tell whether or not they are used. The normal
</p>
<p>solution, albeit one that strictly ignores the problem rather than solves it, is to
</p>
<p>never delete any files from these directories. The reason this works as a solution is
</p>
<p>that storage space is so cheap!
</p>
<p>12.2.2 Viscosity
</p>
<p>A viscous system is one that is resistant to change&mdash;even small changes can
</p>
<p>require substantial effort. A classic example would be a word-processed document
</p>
<p>in which the numbers used in the figure captions, such as &lsquo;&lsquo;Fig. 12.1,&rsquo;&rsquo; have been
</p>
<p>typed explicitly by hand (rather than using the word processor&rsquo;s built in numbering
</p>
<p>facilities). If you decide to introduce another figure before this in the document,
</p>
<p>then all the existing figure numbers need to be changed manually too. Whilst this
</p>
<p>may not be too difficult for the figures themselves, ensuring that all the references
</p>
<p>to the figures in the text are updated to match the updated numbering can require
</p>
<p>significant effort. If you introduce several figures in this way, one at a time, you
</p>
<p>may decide to skip doing the updating of the numbering every time, and in the end
</p>
<p>may forget to do it at all. TeX and LaTeX avoid this problem by doing it auto-
</p>
<p>matically, and Word also provides tools for doing this, although these tools are
</p>
<p>somewhat viscous and error prone.
</p>
<p>In some circumstances viscosity can be beneficial for users. If things are hard to
</p>
<p>change this encourages reflective action and explicit learning. Learning in some
</p>
<p>puzzles (noted in Chap. 6) is more explicit if the user has to work harder to make
</p>
<p>moves in the puzzle. Deleting files is also made somewhat more viscous by many
</p>
<p>operating system interfaces (&lsquo;&lsquo;Are you sure you want to delete this file?&rsquo;&rsquo;). In
</p>
<p>contrast, if things are easy to change this encourages tinkering, which leads to
</p>
<p>implicit learning. When it is very easy to make small changes this can often lead to
</p>
<p>many small, unnecessary changes being made.
</p>
<p>On the other hand, visualprogramming languages, one of the original analyses
</p>
<p>that led to the CD approach, can have changes that are difficult to implement and
</p>
<p>change. For example, it is most productive in most cases to vary fonts uniformly
</p>
<p>and to have them vary by several points. It is not as productive to have them vary
</p>
<p>338 12 Methodology II: Cognitive Dimensions and the Gulfs</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6">http://dx.doi.org/10.1007/978-1-4471-5134-0_6</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_6">http://dx.doi.org/10.1007/978-1-4471-5134-0_6</a></div>
</div>
<div class="page"><p/>
<p>by only one point. If you want to modify the fonts in a PowerPoint presentation by
</p>
<p>one point, then you have to use more detailed tools and it takes longer. You can do
</p>
<p>it, but it is more viscous. As another example, iTunes makes it relatively easy to
</p>
<p>add a new playlist or to modify a playlist. It makes it more difficult (viscous) to
</p>
<p>erase songs.
</p>
<p>Two types of viscosity can be differentiated:
</p>
<p>&bull; Repetitive viscosity&mdash;where what appears to be a single goal has to be carried
</p>
<p>out as lots of small, repetitive actions. For example, if you want to change in a
</p>
<p>document every number followed by a tab into the same numbers followed by a
</p>
<p>space, this has to be done by hand in Word because, while the number can be
</p>
<p>found, it cannot be included in the replace, thus increasing the viscosity of
</p>
<p>editing Word documents. Similar effects can be found in many systems when
</p>
<p>renaming files within a graphical user interface.
</p>
<p>&bull; Knock-on viscosity&mdash;where what appears to be a single goal requires several
</p>
<p>more small changes to restore consistency (e.g., adding a sentence at the
</p>
<p>beginning of a document and having to redo all the work involved in ensuring
</p>
<p>that appropriate page breaks occur).
</p>
<p>Solutions to the problems of inappropriate amounts of viscosity can involve
</p>
<p>either redesigning the system or providing tools to help manage the difficulties.
</p>
<p>The latter is more likely to be useful where viscosity may be desirable, as a way of
</p>
<p>promoting reflective action and encouraging learning. In some cases there may be
</p>
<p>a trade-off, however, and making some actions less viscous may lead to others
</p>
<p>becoming more viscous. It is also worth noting that it can be useful to deliberately
</p>
<p>make some actions viscous, e.g., if there are safety critical elements, or an action
</p>
<p>may be dangerous if carried out incorrectly, or they are expensive in time or
</p>
<p>money. On the other hand, simple, routine actions should normally be made as
</p>
<p>non-viscous as possible.
</p>
<p>12.2.3 Role-Expressiveness
</p>
<p>Role-expressiveness describes the extent to which a system reveals the goals of the
</p>
<p>system&rsquo;s author/designer to the reader/user. It should be easy, for example, for a
</p>
<p>reader to see what each component in a program does, and how each component
</p>
<p>relates to the whole. This need to infer the other agent&rsquo;s goals and plans is
</p>
<p>important, as we noted earlier in Chap. 7, with particular reference to how Grice&rsquo;s
</p>
<p>maxims describe successful communication.
</p>
<p>One obvious example of role-expressiveness is that the buttons on an interface
</p>
<p>should be clearly recognizable as buttons that the user can press. In some inter-
</p>
<p>faces, however, role-expressiveness is poor because interface objects that are
</p>
<p>clickable are not easily recognizable as being clickable&mdash;&lsquo;&lsquo;But how was I meant to
</p>
<p>12.2 The Cognitive Dimensions 339</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7">http://dx.doi.org/10.1007/978-1-4471-5134-0_7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7">http://dx.doi.org/10.1007/978-1-4471-5134-0_7</a></div>
</div>
<div class="page"><p/>
<p>know that it would do something if I clicked there?&rsquo;&rsquo; This effect is particularly
</p>
<p>found on those web pages where banners and logos are designed as clickable
</p>
<p>images, but users more commonly (and more naturally based on their experience)
</p>
<p>perceive them as just being graphical images.
</p>
<p>A piece of program code with well-chosen variable names can be very role-
</p>
<p>expressive. The goals of the programmer in each statement can be made readily
</p>
<p>apparent to the reader if the functions and variables are given names that clearly
</p>
<p>indicate their purpose.1
</p>
<p>The Microsoft Excel spreadsheet application also supports role expressiveness.
</p>
<p>When you add a formula to a particular cell, for example, it color codes the cells
</p>
<p>that are referenced by that formula. Note that the color coding only happens as the
</p>
<p>formula is created, and disappears when you calculate the result of evaluating that
</p>
<p>formula.
</p>
<p>Classic problems of role-expressiveness occur where two similar looking fea-
</p>
<p>tures achieve different functions or where two different looking functions achieve
</p>
<p>similar effects. That is, where the role-expressiveness for two similar looking
</p>
<p>objects is different, or where the function of two different looking objects appears
</p>
<p>the same. For example, the Border and shadings functions in some older versions
</p>
<p>of Microsoft Word can be accessed using the top level menu but also appear in
</p>
<p>three other places in the interface, with different sets of functions available to the
</p>
<p>user in each place with differing effects. This can confuse users who fail to dis-
</p>
<p>tinguish between paragraph borders and table cell borders because Word displays
</p>
<p>them in apparently unpredictable ways.
</p>
<p>There may sometimes be a conflict between role-expressiveness and consis-
</p>
<p>tency. Designing a system to be role-expressive will usually mean using a richer
</p>
<p>vocabulary with less (apparent) uniformity. A good way to resolve this conflict is
</p>
<p>to carry out a clear and effective analysis of the users&rsquo; tasks and the importance of
</p>
<p>learning versus other measures of usability rather than focusing solely on con-
</p>
<p>sistency (Grudin 1989). Role expressiveness might also be poor on purpose to
</p>
<p>encourage exploration. This may occur in games or educational software and
</p>
<p>hardware (Yeh et al. 2010).
</p>
<p>12.2.4 Premature Commitment
</p>
<p>The point at which users have to commit to taking a particular action varies across
</p>
<p>environments and systems. For example, when you go into a caf&eacute; you sometimes
</p>
<p>find that you have to select which cutlery you need before you have seen what food
</p>
<p>is on offer that day. Until you know this you will not know whether you will need a
</p>
<p>1 Jonah Gregory (personal communication, 2008) notes that programmer&rsquo;s comments can be
helpful in these situations, and we agree. However, comments can also be a nightmare because
they often do not get updated when the code changes. So, there are design decisions about when
to update and how to update such documentation.
</p>
<p>340 12 Methodology II: Cognitive Dimensions and the Gulfs</p>
<p/>
</div>
<div class="page"><p/>
<p>soup spoon or a dessert spoon (or both). Similarly, many database systems require
</p>
<p>that you plan and commit to particular record structures and size limits before
</p>
<p>entering any data or actually using the system. Until you know how the system will
</p>
<p>be used, however, it is often difficult to finalize these decisions.
</p>
<p>These limitations are examples of Premature Commitment. Computer pro-
</p>
<p>gramming environments often require premature commitment such as declaration
</p>
<p>of variables before working out how they will be used, and developing the system
</p>
<p>in sequential order. Like many of the CDs, premature commitment will interact
</p>
<p>with other dimensions. Premature commitment can contribute to viscosity, for
</p>
<p>example, because the effect of the commitment is to make future changes very
</p>
<p>hard to make.
</p>
<p>The solution to the problem of premature commitment is usually to allow (and
</p>
<p>provide support for) users to perform tasks in many orders (e.g., outlining tools in
</p>
<p>many word processors allow the user to develop the outline and write the text in
</p>
<p>any order). This support comes at a cost, however. Allowing users more freedom
</p>
<p>often makes the system more complex to design and to build, and may contribute
</p>
<p>to errors in program code. Paying attention to this trade-off, however, is com-
</p>
<p>pletely consistent with the Risk-Driven Incremental Commitment Model that we
</p>
<p>will discuss in Chap. 14.
</p>
<p>12.2.5 Hard Mental Operations
</p>
<p>The final CD that we will examine here is the number of hard mental operations
</p>
<p>involved, which will vary across systems. In GOMS, KLM modeling, and several
</p>
<p>other task analysis methods, the mental operations are all assumed to be equiva-
</p>
<p>lent, for convenience&rsquo;s sake. Psychology and human factors work show us that
</p>
<p>some kinds of problems (and operations) are substantially harder for users to
</p>
<p>perform, and that users thus prefer easier mental operations (although harder does
</p>
<p>not necessarily mean slower).
</p>
<p>The issue of hard mental operations can be illustrated by the isomorph of the
</p>
<p>Towers of Hanoi problem, in which monsters manipulate balls according to a
</p>
<p>formal monster protocol for swapping balls. The subjects in Kotovsky and Simon&rsquo;s
</p>
<p>(1990) study had monsters either follow a complex protocol to swap balls around
</p>
<p>based on which size monster could hold which size ball, or a protocol that required
</p>
<p>monsters to change size to swap balls around. Subjects found the latter protocol to
</p>
<p>be much more difficult, possibly because we tend to think of size as a relatively
</p>
<p>constant aspect of an object, so having to mentally change the size of an object is
</p>
<p>more strenuous and error prone than applying simple rules to behavior. Similar
</p>
<p>effects have also been found in mentally rotating objects, with larger objects being
</p>
<p>rotated more slowly.
</p>
<p>As another example, multiple negative facts can be very hard to disentangle
</p>
<p>(e.g., the packet that was not lost, was not put out on the Ethernet). The concepts of
</p>
<p>pointers and indirection in C and other programming languages also prove very
</p>
<p>12.2 The Cognitive Dimensions 341</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14">http://dx.doi.org/10.1007/978-1-4471-5134-0_14</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_14">http://dx.doi.org/10.1007/978-1-4471-5134-0_14</a></div>
</div>
<div class="page"><p/>
<p>difficult&mdash;most people can usually handle one level of indirection, but multiple
</p>
<p>levels of pointers tend to be more difficult to follow. Another type of hard mental
</p>
<p>operation is boundary problems, for example, counting fence posts&mdash;If you have a
</p>
<p>ten-foot fence to put up, and fence pieces are one foot long, how many posts do
</p>
<p>you require? In this situation, the boundaries of an object have to be explicitly and
</p>
<p>carefully represented and manipulated. If you thought there should be 10 posts,
</p>
<p>you have left out the first post, because there needs to be 11 (you can see this much
</p>
<p>more easily if you actually draw the fence).
</p>
<p>An important thing to remember about these kinds of hard mental operations is
</p>
<p>that they can be easy to implement computationally, but can be especially trou-
</p>
<p>blesome for users. Again, these problems can be solved at several levels, including
</p>
<p>either by avoiding the problem by understanding the relative difficulty of opera-
</p>
<p>tions, or by providing tools to assist in these operations (e.g., graphic displays of
</p>
<p>indirection in C programs) and providing representations designed to be shared
</p>
<p>between types of system implementers.
</p>
<p>12.3 Turning Cognitive Dimensions into a Methodology
</p>
<p>The CDs can be used as a method for informing design during the early or middle
</p>
<p>stages of development (e.g., Cohen et al. 2012). The designer can ask questions
</p>
<p>based on the appropriate dimensions for the system, such as:
</p>
<p>1. Are there hidden dependencies and one-way links in the structure?
</p>
<p>2. Is the system viscous, or can users and designers reconstruct structures easily
</p>
<p>and fluidly?
</p>
<p>3. Is the order of generation and action the same as the order in which users will
</p>
<p>want to do things and have the appropriate information? Are there multiple,
</p>
<p>appropriate orders of behavior and strategies supported?
</p>
<p>4. Is the system role-expressive? Are the functions of the components obvious and
</p>
<p>discriminable?
</p>
<p>5. Does the system require any hard mental operations?
</p>
<p>6. Are there conceptual gaps between the user and the system? (Blandford et al.
</p>
<p>2008)
</p>
<p>The answers to these questions are shared among the design team. They can
</p>
<p>then be used to moderate the design of the system, or may lead to other design
</p>
<p>activities such as studying the relative costs of mental operations or other tasks that
</p>
<p>help reduce the risks associated with the design.
</p>
<p>Designers might wish to order the dimensions they use, and they may also wish
</p>
<p>to add other dimensions. A new dimension could be added, for example, to con-
</p>
<p>sider the role of cognitive load (Sweller 1988) describing how much the user has to
</p>
<p>know, do, and learn at any given point in a task.
</p>
<p>The CDs have been used to develop extensions to the Microsoft Excel
</p>
<p>spreadsheet that integrate user defined functions into the worksheet grid (Peyton
</p>
<p>342 12 Methodology II: Cognitive Dimensions and the Gulfs</p>
<p/>
</div>
<div class="page"><p/>
<p>Jones et al. 2003). This was done by initially focusing on the cognitive require-
</p>
<p>ments of the user, using the CDs and the Attention Investment model of
</p>
<p>abstraction use (Blackwell 2002). The Cognitive Dimensions approach has also
</p>
<p>been used to understand issues that arise for programmers when solving complex
</p>
<p>systems integration problems and with contemporary, mash-upprogramming
</p>
<p>practices with APIs (application programming interfaces) (see Jones et al. 2010 for
</p>
<p>an example).
</p>
<p>12.4 What is Omitted by the Cognitive Dimensions?
</p>
<p>The CDs do have some limitations. This approach does not offer a complete way to
</p>
<p>create an interface design, and it may not always be applicable. Those aspects of a
</p>
<p>system that are of particular interest may not be covered by the dimensions noted,
</p>
<p>for example.
</p>
<p>Even for the existing CDs, there are areas where they could be expanded. The
</p>
<p>current list includes error proneness, for example, but does not directly address the
</p>
<p>quality of feedback and support for error recovery. The CDs also focus on usability
</p>
<p>issues, and do not currently address issues related to user acceptability&mdash;does the
</p>
<p>system fit in with the way users do the task or want to do the task, and so on.
</p>
<p>The CDs are an attempt to provide a way for designers to discuss issues related
</p>
<p>to usability. If we had a rich enough vocabulary to adequately describe the sources
</p>
<p>of poor usability, then the problems could be solved simply by reducing or
</p>
<p>eliminating each of these sources. The real benefit of the CDs is as a tool that can
</p>
<p>highlight the trade-offs inherent in interface design in a way that can be easily
</p>
<p>understood by designers.
</p>
<p>As their name suggests, the CDs focus on the cognitive aspects of interfaces.
</p>
<p>They do not address design trade-offs related to the other aspects of users that we
</p>
<p>have introduced&mdash;anthropometric, behavioral, and social aspects&mdash;in any great
</p>
<p>depth. The CDs approach, however, suggests that a similar approach to under-
</p>
<p>standing design trade-offs could be used for these other aspects of usability. The
</p>
<p>physical dimensions of a device will typically be related to the features that can be
</p>
<p>provided, for example, iPods versus iPads. Similarly, other aspects can be put into
</p>
<p>this framework. For example, social aspects could be included such as how the size
</p>
<p>of a social network will influence the usability of devices designed for commu-
</p>
<p>nicating with others.
</p>
<p>12.5 Norman&rsquo;s Seven Stages of Action
</p>
<p>In his book The Design of Everyday Things, Norman (1988, 2013) describes the
</p>
<p>process of how users interact with systems to achieve their goals as a series of
</p>
<p>activities (see Table 12.2). This process is an approximate theory of action: all of
</p>
<p>12.3 Turning Cognitive Dimensions into a Methodology 343</p>
<p/>
</div>
<div class="page"><p/>
<p>the stages may not always be used, and they may not always be applied in the same
</p>
<p>order. The stages are done in a cycle (thus, the last stage, Evaluate, also occurs
</p>
<p>before the first stage, Establish the goal). The process does, however, capture the
</p>
<p>essential aspects of how users perform tasks, and is therefore useful for analyzing
</p>
<p>and guiding the design of systems. The process should be seen as cyclic rather than
</p>
<p>a single shot linear sequence of activities. Activities may also overlap, and there
</p>
<p>can be feedback loops between activities.
</p>
<p>There may be not be a direct correspondence between the user&rsquo;s psychologi-
</p>
<p>cally expressed goals and the physical controls and variables that have to be used
</p>
<p>to carry out the task to achieve those goals. In many cases the goals and intentions
</p>
<p>are highly context dependent, and often opportunistic rather than planned. The
</p>
<p>goals and intentions may also be rather vague or ill-defined. Generally the user will
</p>
<p>set up some goal that they want to accomplish, and then formulate an intention to
</p>
<p>carry out some actions to ensure that the goal is achieved. Goals and intentions are
</p>
<p>psychological concepts&mdash;they exist in the mind of the user and relate directly to
</p>
<p>the user&rsquo;s needs and concerns. In most cases, however, the actions have to be
</p>
<p>performed on a physical artifact or system, manipulating some physical mecha-
</p>
<p>nisms to produce changes in the physical variables and the state of the system or
</p>
<p>environment. The user must, therefore, turn psychological intentions into actions
</p>
<p>that can be physically carried out upon the system or environment. The user then
</p>
<p>has to look for the effects of those actions, and interpret those effects in terms of
</p>
<p>the psychological goals to decide what to do next.
</p>
<p>You do not want your users to have to resort to effortful problem solving just to
</p>
<p>interpret the effects of any actions. If they do, this usually means that they have not
</p>
<p>found the interface easy to use. This situation should normally only occur when
</p>
<p>something goes wrong with the system, or where the purpose of the interface is to
</p>
<p>deliberately force the user to resort to problem solving, such as in a game. Pro-
</p>
<p>viding some level of built in redundancy will help users when they have to perform
</p>
<p>problem solving. You could provide them with multiple email accounts, for
</p>
<p>example, in case one is down, or provide multiple ways to get email, e.g., POP and
</p>
<p>webmail; similarly, you could provide multiple ways to print with multiple
</p>
<p>printers. These are usefully redundant rather than just duplicates.
</p>
<p>When you design systems you should think about how to support users in ways
</p>
<p>that help them to achieve their goals, and reduce the need for them to resort to
</p>
<p>problem solving. You can provide users with some means to access commands, for
</p>
<p>example, using keystrokes, menus, buttons, and so on, as a way of helping them
</p>
<p>Table 12.2 Stages of user activities
</p>
<p>&bull; Establish the goal
</p>
<p>&bull; Form the intention to take some action
</p>
<p>&bull; Specify the action sequence
</p>
<p>&bull; Execute the action
</p>
<p>&bull; Perceive the system state
</p>
<p>&bull; Interpret the system state
</p>
<p>&bull; Evaluate the system state with respect to the goals and intentions
</p>
<p>344 12 Methodology II: Cognitive Dimensions and the Gulfs</p>
<p/>
</div>
<div class="page"><p/>
<p>perform their tasks to achieve their goals. You should also try to anticipate potential
</p>
<p>problems, and understand how your users will use problem solving to resolve them.
</p>
<p>By doing so you should be able to identify redundancies that you can build into the
</p>
<p>system to allow (and help) users to work around the problem until it can be fixed.
</p>
<p>12.5.1 The Gulfs of Evaluation and Execution
</p>
<p>In Norman&rsquo;s seven stages of action he explicitly talks about the need tomap between
</p>
<p>psychological and physical concepts. Often there is not a direct correspondence
</p>
<p>between the two. If we think about behavior in terms of Neisser&rsquo;s (1976) perceive-
</p>
<p>decide-act cycle we can identify two areas where the mapping occurs.
</p>
<p>When the user perceives the state of the system (or more generally, the envi-
</p>
<p>ronment) this will be in terms of physical concepts (usually variables and values)
</p>
<p>that the user will have to translate into a form that is compatible with their mental
</p>
<p>model of how the system operates. Norman describes the gap between the physical
</p>
<p>concepts and the psychological concepts as the Gulf of Evaluation (see Fig. 12.2).
</p>
<p>The user will normally have to do some (cognitive) work to bridge this Gulf. If the
</p>
<p>user cannot interpret the effects in terms of the original goals and intentions, this
</p>
<p>may mean that they have to resort to problem solving to determine whether the
</p>
<p>effects of their actions indicate that the goal has been achieved.
</p>
<p>When the user formulates a goal, this usually leads to the intention to perform
</p>
<p>some actions to attain that goal. The user then has to translate these psychological
</p>
<p>concepts into physical concepts, which are usually actions that can be executed on
</p>
<p>the system (or, more generally, the environment). Norman describes the gap
</p>
<p>between the (psychological) goals and intentions and the physical actions as the
</p>
<p>Gulf of Execution (see Fig. 12.2). If the user cannot readily work out how to
</p>
<p>translate the goals and intentions into the available actions that can be performed
</p>
<p>on the system, they may end up not knowing what to do, or how to do it. In such
</p>
<p>cases they will often have to resort to problem solving to determine what actions to
</p>
<p>take and how to execute them.
</p>
<p>When designing systems you should normally try to minimize the size of the
</p>
<p>Gulfs of execution and evaluation. Often it may not be possible to eliminate them
</p>
<p>completely, but you should try to make it obvious what the user needs to do to
</p>
<p>bridge the Gulfs.
</p>
<p>12.5.2 The Gulfs in Practice
</p>
<p>A couple of examples should help to illustrate the two Gulfs more clearly, and show
</p>
<p>how serious the effect of largeGulfs can be. In theKegworth air crash (seeAppendix)
</p>
<p>and in many other air disasters a large Gulf of Evaluation can be identified. The true
</p>
<p>state of the aircraft was not very clear from the instruments in the cockpit, and there
</p>
<p>12.5 Norman&rsquo;s Seven Stages of Action 345</p>
<p/>
</div>
<div class="page"><p/>
<p>was little directly observable feedback about the effects of the pilots&rsquo; actions. There
</p>
<p>were also some apparent discrepancies between the pilots&rsquo; mental model of the state
</p>
<p>of the aircraft and the state of the physical aircraft, and the instrumentation in the
</p>
<p>cockpit did not make it easy to identify and rectify these discrepancies. In the
</p>
<p>Kegworth disaster the air traffic control operatorsasked a lot of questions. These
</p>
<p>questions may also have contributed to the Gulf of Evaluation for the pilots because
</p>
<p>they would have taken time away from understanding their situation.
</p>
<p>The situation in the Kegworth disaster was further exacerbated by coincidental
</p>
<p>effects that led the pilots to falsely believe that they had attained some goals
</p>
<p>(Besnard et al. 2004). There was an identifiable Gulf of Execution in that the
</p>
<p>actions that the pilots took did not have the effects they thought they would. While
</p>
<p>they had removed the vibration by shutting down one of the engines, they had not
</p>
<p>shut down the failing engine.
</p>
<p>As you look at other interfaces, you will encounter further examples where
</p>
<p>details and feedback on the state of the system can be difficult to interpret, and
</p>
<p>where it can be difficult to work out what actions are available and how to execute
</p>
<p>them. These sorts of problems provide an indication of where the usability of the
</p>
<p>system can be increased by improving the interface.
</p>
<p>12.6 Implications of the Gulfs for Design
</p>
<p>Norman uses the Gulfs to highlight the central importance of visibility in design.
</p>
<p>Good design involves making sure that information that is crucial to task evalu-
</p>
<p>ation and performance are made clearly visible to the user. In this way you can
</p>
<p>Gulf of Execution
</p>
<p>Gulf of Evaluation
</p>
<p>?
</p>
<p>?
</p>
<p>Fig. 12.2 Norman&rsquo;s Gulf of
Evaluation and Gulf of
Execution
</p>
<p>346 12 Methodology II: Cognitive Dimensions and the Gulfs</p>
<p/>
</div>
<div class="page"><p/>
<p>reduce the size of the Gulf of Execution and the Gulf of Evaluation. Table 12.3
</p>
<p>provides some general guidance on how you can try to narrow the Gulfs during
</p>
<p>design.
</p>
<p>Visibility is not an adequate guideline on its own, however, and making too
</p>
<p>much information visible can be a bad thing. Norman uses the example of a
</p>
<p>washer/drier that had multiple controls and several symbols displayed on the front
</p>
<p>of it. There was no easy way to discern what each control did and what all the
</p>
<p>symbols meant without looking at the instructions or undergoing extensive
</p>
<p>training. (This example assumes that the designer was not trying to drive the user
</p>
<p>to the manual to learn these symbols, a type of controlled viscosity.)
</p>
<p>There is often a design trade-off between presenting too much information and
</p>
<p>overloading controls to allow them to perform several different actions using
</p>
<p>modes. In moded systems, the way that you interpret the displays and feedback
</p>
<p>depends on which mode the system is currently in. This can be problematic,
</p>
<p>particularly if it is not immediately obvious which mode the system is in.
</p>
<p>The visibility guideline, like most guidelines, needs to be adapted to the user&rsquo;s
</p>
<p>particular situation. You should think of it in terms of:
</p>
<p>&lsquo;&lsquo;Visibility of the appropriate information for carrying out relevant tasks,&rsquo;&rsquo; or
</p>
<p>&lsquo;&lsquo;So viel wie n&ouml;tig, so wenig wie m&ouml;glich.&rsquo;&rsquo; ? &lsquo;&lsquo;as much as necessary, as little as
possible,&rsquo;&rsquo; is a neat way of phrasing it, taken from a German aphorism.
</p>
<p>What counts as appropriate information will vary across tasks, and sometimes
</p>
<p>across users, and even across contexts of use (e.g., same driver, same task, dif-
</p>
<p>ferent road conditions).
</p>
<p>When you think about visibility you should make sure that you give appropriate
</p>
<p>consideration to feedback, consistency, and the user&rsquo;s mental model of the system.
</p>
<p>These factors can all be used to help reduce the size of the Gulfs. Feedback is
</p>
<p>obviously important in helping to reduce the Gulf of Evaluation, because it shows
</p>
<p>the effect of performing a particular action.
</p>
<p>Users often rely on consistency within and across systems and applications.
</p>
<p>They expect interface layouts to be consistent, for example, with particular con-
</p>
<p>trols always being located in the same place and always behaving in the same way.
</p>
<p>This can be particularly important when it comes to new systems, because users
</p>
<p>will often try to apply their knowledge of other interfaces to the new interface.
</p>
<p>Consistency is important because it will help the users to help themselves.
</p>
<p>We know that users rely on mental models to help them perform tasks. These
</p>
<p>mental models develop over time, so your design should facilitate the development
</p>
<p>of appropriate mental models, and support the use of those mental models by
</p>
<p>making the appropriate information visible to users at the right time and in the
</p>
<p>right place.
</p>
<p>In many cases you want it to be easy to use the system you are designing, so
</p>
<p>that you can get to the point where people can use it with little or no conscious
</p>
<p>control. In other words, they will be operating at a point close to Rasmussen&rsquo;s
</p>
<p>(1983) skill-based level of behavior.In critical systems, however, you often want
</p>
<p>people to pay close attention to the actions that they are taking, and for behavior to
</p>
<p>12.6 Implications of the Gulfs for Design 347</p>
<p/>
</div>
<div class="page"><p/>
<p>be more deliberate (closer to Rasmussen&rsquo;s rule-based level of behavior). Making
</p>
<p>interaction harder can be useful for safety critical systems (e.g., nuclear power,
</p>
<p>aviation, and so on), security critical systems, and more generally as a way of
</p>
<p>preventing inappropriate, costly, and illegal actions in any interface. If you want to
</p>
<p>make the Gulfs wider, you should apply the inverse of these principles; some are
</p>
<p>noted in Table 12.4. Figure 12.3, for example, shows a picture of an electrical
</p>
<p>outlet designed, one can only presume, to be difficult for travelers to use.
</p>
<p>At this point it should be clear to you that you are not simply designing to make
</p>
<p>the system fit the user in isolation. At the same time, you need to consider how to
</p>
<p>mold the task environment to fit the user. In other words, you need to fit the
</p>
<p>environment to the tasks, goals, knowledge, and expectations of the user.
</p>
<p>12.7 Limitations of the Gulfs
</p>
<p>While Norman&rsquo;s approach has been very useful as a metaphor and approach for
</p>
<p>improving interface design over the years, it has some limitations that should be
</p>
<p>noted. The most obvious limitation is that it is intentionally simplistic. The sug-
</p>
<p>gestions that it makes are context independent. The sizes of the Gulfs are not
</p>
<p>measurable, and this makes it difficult to apply this approach to choose between
</p>
<p>alternative designs.
</p>
<p>Table 12.3 Design principles derived from Norman&rsquo;s analysis to make the Gulfs narrower
where appropriate
</p>
<p>1. Use both the knowledge in the world and the knowledge in the head. Provide information in the
environment to help the user determine the system state and to perform actions, such as
explicit displays of system state, and affordances on the system controls
</p>
<p>2. Simplify the structure of tasks. Require less of the user by automating subtasks, or using
displays to describe information without being asked, or provide common actions more
directly. However, do not reduce this below their natural level of abstraction
</p>
<p>3. Make the relevant objects and feedback on actions visible. Bridge the Gulf of Evaluation.
Make the state of the system easier to interpret
</p>
<p>4. Make the available actions visible. Bridge the Gulf of Execution. Make the actions the user can
(and should) perform easier to see and to do
</p>
<p>5. Get the mappings correct from objects to actions. Make the actions that the user can apply
natural
</p>
<p>6. Exploit the power of constraints, both natural and artificial, to support bridging each Gulf.
Make interpretations of the state and of possible actions easier by removing actions that are
not possible in the current state and reducing the complexity of the display for objects that are
not active or available
</p>
<p>7. Design for error. Users will make errors, so you should expect them and be aware of their
effects. Where errors cannot be prevented, try to mitigate their effects. Help the user see errors
and provide support for correcting them
</p>
<p>8. When all else fails, standardize. If the user does not know what to do, allow them to apply their
knowledge of existing standards and interfaces
</p>
<p>348 12 Methodology II: Cognitive Dimensions and the Gulfs</p>
<p/>
</div>
<div class="page"><p/>
<p>To fully understand the Gulfs, designers need to understand perceptual and
</p>
<p>cognitive psychology fairly well (which is partly why we have included lots of
</p>
<p>information on cognition and perception in this book). To apply this approach the
</p>
<p>designer has to be able to accurately judge the Gulf of Evaluation, which implies
</p>
<p>understanding how the user perceives and interacts with the display. It also
</p>
<p>Fig. 12.3 An electrical
outlet (circled) on a column
designed to be difficult to
use?
</p>
<p>Table 12.4 Design principles derived from Norman&rsquo;s analysis to make the Gulfs wider where
appropriate
</p>
<p>1. Hide components: Make things invisible to help make the visible easier to see, and what should
be hard to find (because it is uncommon or unhelpful or dangerous), is hard to find
</p>
<p>2. Avoid natural mappings for the execution side of the action cycle, so that the relationship of the
controls to the things being controlled are inappropriate
</p>
<p>3. Make the unavailable action physically impossible or difficult to do
</p>
<p>4. Require precise timing and difficult physical manipulation
</p>
<p>5. Do not give any feedback
</p>
<p>6. Use unnatural mappings for the evaluation side of the action cycle, so that the system state is
difficult to interpret
</p>
<p>12.7 Limitations of the Gulfs 349</p>
<p/>
</div>
<div class="page"><p/>
<p>assumes that the designer either understands motor output fairly well, or that the
</p>
<p>details of motor output do not matter. When the interface is either simple, or has
</p>
<p>been poorly designed, it will be relatively easy to make judgments about where it
</p>
<p>can be improved. For more complex interfaces, where there are realistic design
</p>
<p>trade-offs that need to be made, it will be more difficult to make these judgments
</p>
<p>accurately and for a wide range of users.
</p>
<p>12.8 Summary
</p>
<p>The Cognitive Dimensions and the Gulfs of Evaluation and Execution both pro-
</p>
<p>vide a less formal and much lighter weight approach than task analyses and user
</p>
<p>modeling techniques. They provide useful heuristics about interface design, and a
</p>
<p>way to describe interface trade-offs, but they cannot always be used to compute the
</p>
<p>quality of alternative designs.
</p>
<p>The Cognitive Dimensions provide a way to discuss particular aspects of
</p>
<p>interface design. They are not a complete method, but do provide a useful way to
</p>
<p>carry out an early sanity check on a particular interface design. It is useful to have
</p>
<p>such techniques that can be used early on and with little effort.
</p>
<p>The Gulfs of Evaluation and Execution remind us how users interact with a
</p>
<p>system. Nearly all users have some common tasks related to interaction, including
</p>
<p>evaluating the system state and executing actions. Bridging these gaps (Gulfs) will
</p>
<p>mean creating the system to support these two fundamental aspects of task per-
</p>
<p>formance. Thinking about the Gulfs can yield practical suggestions for improving
</p>
<p>designs, such as making things more visible but avoiding clutter.
</p>
<p>12.9 Other Resources
</p>
<p>There are many resources related to Blackwell and Green&rsquo;s Cognitive Dimensions
</p>
<p>available at their web site. These include papers, reports, and tools.
</p>
<p>http://www.cl.cam.ac.uk/*afb21/CognitiveDimensions/
</p>
<p>Don Norman&rsquo;s book The Design of Everyday Things (originally published as
</p>
<p>ThePsychologyof Everyday Things) includes several examples of the Gulfs of
</p>
<p>Evaluation and Execution arising out of poor design. These include a fridge
</p>
<p>freezer, doors on buildings, and a slide projector where how to evaluate or how to
</p>
<p>use the devices were not clear. He also discusses how the designs could be
</p>
<p>improved to reduce or eliminate the Gulfs:
</p>
<p>Norman, D. A. (1988). The psychology of everyday things. NY: Basic Books. (2013 ed.,
The design of everyday things).
</p>
<p>350 12 Methodology II: Cognitive Dimensions and the Gulfs</p>
<p/>
<div class="annotation"><a href="http://www.cl.cam.ac.uk/~afb21/CognitiveDimensions/">http://www.cl.cam.ac.uk/~afb21/CognitiveDimensions/</a></div>
</div>
<div class="page"><p/>
<p>Norman&rsquo;s (2009) text is also worth reading. This book covers technologies like
</p>
<p>self driving cars, and applies the basic philosophy laid out in the earlier Design of
</p>
<p>Everyday Things:
</p>
<p>Norman, Donald A. The design of future things. Basic Books, 2009.
</p>
<p>12.10 Exercises
</p>
<p>12.1 Consider a smartphone, either a specific one or a composite one. Attempt to
</p>
<p>come up with a set of trade-offs based on Cognitive Dimensions. Describe
</p>
<p>how to choose a reasonable point in these trade-offs.
</p>
<p>12.2 Choose an existing interface, find five similar interfaces, and note how they are
</p>
<p>related as different positions on Cognitive Dimensions. For example, there are
</p>
<p>puzzle interfaces where you directly manipulate pieces and others where you
</p>
<p>type in the piece number. These differ in viscosity and hard mental operations.
</p>
<p>The more viscous interface encourages more hard mental operations and
</p>
<p>learning. Find similar trade-offs within a single type of interface.
</p>
<p>12.3 Look at your work desk, and consider where you can note three trade-offs or
</p>
<p>effects in its design with respect to the Cognitive Dimensions. For example,
</p>
<p>some desks have printouts pasted to walls near the desk. These can be seen to
</p>
<p>reduce the viscosity of the information on them.
</p>
<p>12.3 Discuss how an online training system and a safety critical system can
</p>
<p>encourage different behaviors (e.g., learning, avoiding errors) by using
</p>
<p>Cognitive Dimensions.
</p>
<p>12.5 Considerways that theWord, PowerPoint, or other help system can help reduce
</p>
<p>the Gulf of Evaluation, and the Gulf of Execution. For example, try to create
</p>
<p>multiple lines in an Excel file, or to create a string (like &lsquo;&lsquo;1 2&rsquo;&rsquo; or &lsquo;&lsquo;p\ .05&rsquo;&rsquo;)
</p>
<p>where the 1 and 2 and the &lsquo;&lsquo;p&rsquo;&rsquo; and &lsquo;&lsquo;5&rsquo;&rsquo; always stay on the same line.
</p>
<p>12.6 Create six design dimensions related to anthropometric, behavioral, and
</p>
<p>social trade-offs. Provide an argument in each case as to why these are
</p>
<p>fundamental dimensions. The dimensions should cross the areas (i.e., note
</p>
<p>how they are related), or you should note why you think they are not
</p>
<p>relatable onto a single dimension
</p>
<p>References
</p>
<p>Besnard, D., Greathead, D., &amp; Baxter, G. (2004). When mental models go wrong. Co-occurrences
in dynamic, critical systems. International Journal of Human-Computer Studies, 60, 117&ndash;128.
</p>
<p>Blackwell, A. (2002). First steps in programming: A rationale for attention investment models. In
Proceedings of the IEEE Symposium on Human-Centric Computing Languages and
Environments, 2&ndash;10. Arlington, VA: IEEE Press.
</p>
<p>12.9 Other Resources 351</p>
<p/>
</div>
<div class="page"><p/>
<p>Blackwell, A., &amp; Green, T. (2003). Notational systems&mdash;The cognitive dimensions of notations
framework. In J. M. Carroll (Ed.), HCI models, theories, and frameworks (pp. 103&ndash;133). San
Francisco: Morgan Kaufmann.
</p>
<p>Blandford, A., Green, T. R. G., Furniss, D., &amp; Makri, S. (2008). Evaluating system utility and
conceptual fit using CASSM. International Journal of Human-Computer Studies, 66,
393&ndash;409.
</p>
<p>Cohen, M. A., Ritter, F. E., &amp; Haynes, S. R. (2012). Discovering and analyzing usability
dimensions of concern. ACM Transactions on CHI, 19(2), Article 9. 18 pages.
</p>
<p>Green, T. R. G. (1989). Cognitive dimensions of notations. In People and Computers V (pp.
443&ndash;460). Cambridge, UK: Cambridge University Press.
</p>
<p>Grudin, J. (1989). The case against user interface consistency. Communications of the
ACM, 32(10), 1164&ndash;1173.
</p>
<p>Jones, M. C., Churchill, E. F., &amp; Nelson, L. (2010). Mashed layers and muddled models:
Debugging mashup applications. In A. Cypher, M. Dontcheva, T. Lau &amp; J. Nichols (Eds.), No
Code Required: Giving Users Tools to Transform the Web: Burlington, MA: Morgan
Kaufman.
</p>
<p>Kotovsky, K., &amp; Simon, H. A. (1990). What makes some problems really hard: Explorations in
the problem space of difficulty. Cognitive Psychology, 22, 143&ndash;183.
</p>
<p>Neisser, U. (1976). Cognition and reality. San Francisco, CA: W. H. Freeman.
Norman, D. A. (1988). The psychology of everyday things. NY: Basic Books.
Norman, D. A. (2009). The design of future things. NY: Basic Books
Norman, D. A. (2013). The design of everyday things. NY: Basic Books.
Peyton Jones, S., Blackwell, A., &amp; Burnett, M. (2003). A user-centred approach to functions in
</p>
<p>Excel. In ICFP&rsquo;03: Proceedings of the eighth ACM SIGPLAN International Conference on
Functional Programming (pp. 165&ndash;176). ACM Press: New York, NY.
</p>
<p>Rasmussen, J. (1983). Skills, rules, knowledge: Signals, signs and symbols and other distinctions
in human performance models. IEEE Transactions: Systems, Man, and Cybernetics, SMC-13,
257&ndash;267.
</p>
<p>Sweller, J. (1988). Cognitive load during problem solving: Effects on learning. Cognitive Science,
12, 257&ndash;285.
</p>
<p>Yeh, K.-C., Gregory, J. P., &amp; Ritter, F. E. (2010). One laptop per child: Polishing up the XO
laptop user experience. Ergonomics in Design, 18(3), 8&ndash;13.
</p>
<p>352 12 Methodology II: Cognitive Dimensions and the Gulfs</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 13
</p>
<p>Methodology III: Empirical Evaluation
</p>
<p>Abstract Evaluation is an essential part of development. There are several good
</p>
<p>reasons for carrying out user testing in particular. A successful evaluation requires
</p>
<p>careful planning. Here we describe the issues that you need to take into account
</p>
<p>and discuss several effective methods that can be used to collect data. User testing
</p>
<p>reduces the risk that you will deliver a system to your users that is unusable and is
</p>
<p>therefore ineffective. We also touch briefly on the need make sure that any
</p>
<p>evaluation that you carry out is conducted according to appropriate ethical
</p>
<p>guidelines.
</p>
<p>13.1 Introduction
</p>
<p>Evaluation should be a routine and regular part of system development. Attitudes
</p>
<p>to evaluation continue to vary widely, however, with many people still mistakenly
</p>
<p>believing that testing only happens at the end of development. The main problem
</p>
<p>with such an approach is that if development overruns while the delivery deadline
</p>
<p>remains fixed, it is usually testing that gets cut (because it is the last thing to
</p>
<p>happen). The net result is that the delivered system ends up being tested inade-
</p>
<p>quately and, as a result, does not work as expected.
</p>
<p>There are two statements that are worth remembering when it comes to eval-
</p>
<p>uation. The first is &lsquo;&lsquo;Test early, test often.&rsquo;&rsquo; The second is &lsquo;&lsquo;Quick and dirty is better
</p>
<p>than nothing.&rsquo;&rsquo; Any evaluation program should deliver something informative for
</p>
<p>the system design and development. Testing can be expensive, but need not be.
</p>
<p>Lightweight methods that offer a proportionately larger return on investment are
</p>
<p>also available (Monk 1998; Nielsen 1993).
</p>
<p>It is also worth remembering that when software engineers, in particular, talk
</p>
<p>about evaluation they will often refer to V &amp; V, or verification and validation.
</p>
<p>Verification is about making sure that you are building the product right, and it is a
</p>
<p>process that is often carried out within the developer company. In contrast, vali-
</p>
<p>dation is about making sure that you are building the right product, and usually
</p>
<p>F. E. Ritter et al., Foundations for Designing User-Centered Systems,
DOI: 10.1007/978-1-4471-5134-0_13, ï¿½ Springer-Verlag London 2014
</p>
<p>353</p>
<p/>
</div>
<div class="page"><p/>
<p>involves some sort of acceptance test with the customer to make sure that the
</p>
<p>requirements have been met. You should make sure that you have the distinction
</p>
<p>between these two clear in your own head.
</p>
<p>In this chapter we provide an introduction to the topic of evaluation and the
</p>
<p>methods that can be used to collect data. For a much fuller discussion about which
</p>
<p>analytical methods to use, you should consult an appropriate textbook such as
</p>
<p>Lazar et al.&rsquo;s (2010) book Research methods in human&ndash;computer interaction. We
</p>
<p>do not go into the details of the methods you need to use to analyze your data. The
</p>
<p>way that you analyze the data is important, but is highly dependent on the type of
</p>
<p>data that you collect, and the overall purpose of the evaluation. More information
</p>
<p>about how to analyze your data can be found in statistics books, such as Howell
</p>
<p>(2010) or, for qualitative data Miles et al. (2013) and Todd (2004).
</p>
<p>13.1.1 Why Do We Need User Testing?
</p>
<p>If we could always guarantee that systems would be built correctly, based on a
</p>
<p>complete and accurate analysis of user requirements, then there would not (the-
</p>
<p>oretically, at least) be a need for user testing. There are several reasons why we
</p>
<p>cannot give such guarantees, however. Perhaps the most pertinent one here is what
</p>
<p>has been called the envisioned world problem (Carroll and Rosson 1992; Woods
</p>
<p>and Dekker 2000), which is based on the fact that the world will inevitably change
</p>
<p>between the time when the user requirements are analyzed and the time when the
</p>
<p>final system is delivered. Often the changes are in ways that cannot be (fully)
</p>
<p>controlled by the users. So, when the requirements analysis is carried out, the users
</p>
<p>are effectively being asked to define what the system will need to do to work
</p>
<p>acceptably in some future context which they cannot fully predict or envision.
</p>
<p>There are still some system developers who believe that as long as a system
</p>
<p>does what they consider to be the right thing, then that is enough. Their attitude is
</p>
<p>that if the users cannot make the system work, it is due to the users&rsquo; lack of
</p>
<p>knowledge or ability, rather than being due to some fault of the developers. The
</p>
<p>fundamental problem with this view is that if the delivered system does not fit with
</p>
<p>the way that users normally carry out their work, there is a risk that it may not be
</p>
<p>accepted (e.g., see Berg 1997). The acid test of acceptability often comes when the
</p>
<p>users have to try to use the new system in their normal working environment.
</p>
<p>The purpose of user testing is not to understand users but to evaluate how
</p>
<p>particular users can carry out particular tasks (using your system) in a particular
</p>
<p>context. There are still some designers who mistakenly believe that they know
</p>
<p>exactly how users carry out their work. In practice, however, when you observe
</p>
<p>users you see that they are often very creative, and use systems in ways that were
</p>
<p>never conceived of by their designers. The use of spreadsheets to format text or to
</p>
<p>make art, the use of thumbs to press cell phone buttons, and the use of social media
</p>
<p>broadcast tools like Twitter to organize political activities are just a few examples
</p>
<p>of creative use that were never imagined by their designers.
</p>
<p>354 13 Methodology III: Empirical Evaluation</p>
<p/>
</div>
<div class="page"><p/>
<p>We know a lot about users, and their capabilities and limitations. We have
</p>
<p>covered much of this in the first part of this book and considered the implications
</p>
<p>for system design. Given what we know about the human visual system (Chap. 4),
</p>
<p>we can deduce that a 3-point font is likely to be too small to read. User testing is
</p>
<p>not necessary here; the decision can be derived from first principles. User testing
</p>
<p>may still be essential, however, for other system related questions&mdash;for example,
</p>
<p>to provide evidence that the right design choices and assumptions have been made
</p>
<p>when theories and assumptions make different suggestions, and that the system
</p>
<p>will work in its intended context.
</p>
<p>Comprehensive user testing can be expensive and time consuming, but that
</p>
<p>does not mean that user testing should be ignored. As noted above, there are
</p>
<p>several discount or lightweight methods that can be used (Monk 1998; Nielsen
</p>
<p>1993) to identify potential problems more cheaply, and at an earlier stage of
</p>
<p>development.
</p>
<p>13.1.2 When Do We Carry Out User Testing?
</p>
<p>Everybody makes mistakes&mdash;in the most general sense of the term&mdash;from time to
</p>
<p>time. This includes developers who may base their design decisions on insufficient
</p>
<p>or incorrect information at any stage of the development process&mdash;for example
</p>
<p>during analysis, design, and/or implementation. The consequences of these mis-
</p>
<p>takes may not always be immediately apparent, but may surface much later.
</p>
<p>Carrying out evaluations helps to identify potential problems so that they can be
</p>
<p>appropriately rectified before the system gets delivered.
</p>
<p>The ultimate goal of user testing is to make sure that the users can get the
</p>
<p>delivered system to do what they want it to do. In addition to helping to show that
</p>
<p>a system meets its requirements and is acceptable to the users, testing can also help
</p>
<p>to identify flaws in the development process. User testing is therefore often an
</p>
<p>effective way of providing designers with timely feedback at a relatively early
</p>
<p>stage during ongoing iterative development. Evaluating cheap, simple prototypes
</p>
<p>early in the development cycle can help to avoid potentially costly mistakes at a
</p>
<p>later stage in the lifecycle.
</p>
<p>It is worth noting one of the practicalities of design that has implications for
</p>
<p>evaluation. It may not always be possible for designers to consult users during all
</p>
<p>stages of development. Instead, they work with a customer representative to come
</p>
<p>up with a system that will be acceptable to the users. Sometimes, however, the
</p>
<p>customer representative is not one of the target users, so they may not fully
</p>
<p>understand the subtleties of how the users really carry out their work using the
</p>
<p>system. It is therefore better to try to make sure that you can involve real users
</p>
<p>during evaluation.
</p>
<p>Many developers still neither really understand what their users do, nor why
</p>
<p>they do what they do. Design and development are often carried out in isolation
</p>
<p>from the end users&mdash;agile methods can help address this limitation&mdash;with the
</p>
<p>13.1 Introduction 355</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4">http://dx.doi.org/10.1007/978-1-4471-5134-0_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4">http://dx.doi.org/10.1007/978-1-4471-5134-0_4</a></div>
</div>
<div class="page"><p/>
<p>result that the delivered system is not acceptable, because it does not fit in with the
</p>
<p>way that the users work. User testing during the early stages of development can
</p>
<p>highlight potential problems: making developers watch users wrestle with their
</p>
<p>product in an effort to make it do what they want is often a real eye-opener.
</p>
<p>At least some part of systems development is based on the use of guidelines and
</p>
<p>principles. There are many guidelines and principles available, and they are mostly
</p>
<p>generic, which can make selecting the relevant ones for a specific project a major
</p>
<p>task. If you do use guidelines and principles, user testing can help to highlight the
</p>
<p>more subtle aspects of the system&rsquo;s context that need to be taken into account
</p>
<p>during development, thereby providing evidence to support your particular choice.
</p>
<p>13.2 Planning Your Evaluation Study
</p>
<p>Collecting data is not difficult. Collecting the right data&mdash;data that is pertinent to
</p>
<p>the questions that are being posed&mdash;is not so straightforward. Collecting the
</p>
<p>appropriate data to answer strategically relevant questions requires careful plan-
</p>
<p>ning. Here we identify some of the main issues that can help to improve the
</p>
<p>chances of your evaluation study being a success. Many of the issues that we
</p>
<p>highlight are central to good experimental design.
</p>
<p>13.2.1 What Type of Data: Qualitative or Quantitative?
</p>
<p>One of the first things you will need to consider is the type of data that you will
</p>
<p>collect. The general rule of thumb is that you should think about collecting data to
</p>
<p>help you understand the thing (system, product, application, and so on) before you
</p>
<p>collect data to more precisely measure it. Typically the first type of data to collect
</p>
<p>is qualitative data, in other words, statements or general behavior, rather than
</p>
<p>precise numbers. Quantitative measures (e.g., times, number of clicks) can be used
</p>
<p>to verify assumptions with some degree of confidence over the intended population
</p>
<p>of users.
</p>
<p>13.2.2 Selecting a Hypothesis
</p>
<p>Creating hypotheses for your evaluation study helps to frame the study but also to
</p>
<p>keep it focused and grounded. A hypothesis is a proposition of what you believe to
</p>
<p>be the case (e.g., that a change you have made will cause a change in user behavior
</p>
<p>in some way) and will check with data. The null hypothesis (H0) normally states
</p>
<p>that there is no difference between the things you are testing, e.g., there is no
</p>
<p>difference between the usability of application A and of application B. The
</p>
<p>356 13 Methodology III: Empirical Evaluation</p>
<p/>
</div>
<div class="page"><p/>
<p>alternative hypothesis (H1) and the null hypothesis are mutually exclusive, so in
</p>
<p>our case it would be that there is a difference between the usability of application
</p>
<p>A and of application B. The multi-dimensional nature of usability means that
</p>
<p>experiments are often set up with several pairs of hypotheses, one for each
</p>
<p>dimension of usability. Some user studies might have multiple hypotheses to be
</p>
<p>tested.
</p>
<p>13.2.3 Identifying the Dependent and Independent Variables
</p>
<p>An independent variable is a factor that is independent of user behavior, and which
</p>
<p>can be varied by the person carrying out the evaluation (or the experiment, more
</p>
<p>generally). The dependent variable is the thing that depends on the user&rsquo;s behavior,
</p>
<p>or on the changes in the independent variable(s). Within user centered design, the
</p>
<p>sorts of things that would often be considered as independent variables include the
</p>
<p>type of input device (e.g., touch screen or keyboard), or different web page
</p>
<p>designs. The dependent variables are often more limited, however, to those things
</p>
<p>that are generally taken to measure the usability of a system (e.g., efficiency,
</p>
<p>effectiveness, satisfaction, ease of learning, and workload).
</p>
<p>13.2.4 What Type of Evaluation: Formative or Summative?
</p>
<p>There are two basic types of user-based evaluation: formative and summative.
</p>
<p>Each of these has a different purpose, and takes place at a different stage of
</p>
<p>development, as described below. They each help to remove different types of
</p>
<p>uncertainty, and to reduce the risk that the system will not be usable, or will be
</p>
<p>unacceptable to the end users.
</p>
<p>Formative evaluation can take place at any point during development. It is used
</p>
<p>to help designers refine and form their designs. The focus of formative evaluation
</p>
<p>is to identify problems and potential solutions. In this type of evaluation the
</p>
<p>desired result is an indication of any problems that there may be in using the
</p>
<p>system, possibly with some indication of their frequency of occurrence. The
</p>
<p>designers can then use these frequencies to help rate the severity of the problems
</p>
<p>so a decision can be made about which problems should be fixed first.
</p>
<p>Summative evaluation is concerned with assessing the success of the finished
</p>
<p>system or product, summarizing its overall impact and effectiveness. It is often
</p>
<p>used to test for any fixes that may be needed before the system is released, and to
</p>
<p>assess future releases. The end result may be some sort of usability score, and
</p>
<p>individual organizations may have their own particular threshold values for
</p>
<p>acceptability. One useful metric is to require that novice users of a new system are
</p>
<p>able to demonstrate performance levels that are some predetermined percentage of
</p>
<p>expert levels on the same system. The performance levels are measured using a set
</p>
<p>13.2 Planning Your Evaluation Study 357</p>
<p/>
</div>
<div class="page"><p/>
<p>of predefined benchmark tasks. Defining a set of appropriate summative measures
</p>
<p>remains a difficult problem to solve, however, because systems, unlike many
</p>
<p>manufactured goods, cannot be assessed against tight specifications and tolerances.
</p>
<p>13.2.5 Validity, Reliability, and Sensitivity
</p>
<p>When it comes to designing an evaluation study, you want to make sure that you
</p>
<p>are evaluating the right thing, that you can measure the effects that you are looking
</p>
<p>for, and that the results can be generalized to other situations. To achieve these
</p>
<p>goals, you will need to think about the issues of validity, reliability, and sensitivity.
</p>
<p>This is true irrespective of whether you are collecting qualitative or quantitative
</p>
<p>data.
</p>
<p>13.2.5.1 Validity
</p>
<p>Validity refers to whether the measure that you are using is really measuring what
</p>
<p>it is supposed to be measuring. Reliability, on the other hand, refers to the con-
</p>
<p>sistency of a measure across different conditions. Note that it is possible to use a
</p>
<p>measure that has validity, but is not reliable, and vice versa. You should be aiming
</p>
<p>for high degrees of validity and reliability.
</p>
<p>In addition to validity and reliability, you will also need to consider the sen-
</p>
<p>sitivity of the measure that you are using: does it react sufficiently well to changes
</p>
<p>to the independent variable. Validity, reliability, and sensitivity will all differ,
</p>
<p>depending on the context in which you are doing the evaluation.
</p>
<p>There are several types of validity that you will need to think about. Here they
</p>
<p>are classified into two basic types:
</p>
<p>&bull; Instrument validity which relates to the instruments or measures that you will
</p>
<p>use in your evaluation. There are three subtypes: construct validity, content
</p>
<p>validity, and face validity.
</p>
<p>&bull; Experimental validity which relates the generalizability of the results. There are
</p>
<p>three subtypes: internal validity, external validity, and ecological validity.
</p>
<p>We discuss each of these in more detail below as well as explaining the trade-
</p>
<p>offs that you may need to make when deciding on which type of experimental
</p>
<p>validity is important to your evaluation study.
</p>
<p>Construct validity refers to the extent that your instrument or measure really
</p>
<p>does measure what you think it does. Probably the simplest example is to think
</p>
<p>about an IQ test as a whole, and how much it actually measures intelligence.
</p>
<p>Supporting evidence usually comes from both theory and testing, and can include
</p>
<p>statistical analysis of how responses and test items are related. If you think about
</p>
<p>usability, and how you measure that, things start to get a bit trickier because there
</p>
<p>are several different dimensions to the concept of usability. In other words, you
</p>
<p>358 13 Methodology III: Empirical Evaluation</p>
<p/>
</div>
<div class="page"><p/>
<p>cannot directly assess the usability of an artifact using a single measure. In this
</p>
<p>case you first have to operationalize the concept of usability, and then measure the
</p>
<p>different dimensions separately to assess efficiency, effectiveness, satisfaction, and
</p>
<p>so on. So although you are not measuring usability directly, by measuring the
</p>
<p>separate dimensions you are improving your construct validity. At this stage you
</p>
<p>will also need to think about the content validity.
</p>
<p>Content validity refers to whether the content of a measure or instrument
</p>
<p>corresponds to the content of the construct that the test was designed to cover.
</p>
<p>Again, if we think about an IQ test, its content validity is determined by whether
</p>
<p>the items in the test cover all the different areas of intelligence that are discussed in
</p>
<p>the literature. For a usability survey, you would systematically examine the items
</p>
<p>in the survey to make sure that you had covered all of the relevant aspects of
</p>
<p>usability for the artifact that you are evaluating. So you might have items about the
</p>
<p>display layouts, the content, and so on. Often the way that content validity is
</p>
<p>evaluated is by having domain experts compare the test items against the speci-
</p>
<p>fication for the thing that is being tested.
</p>
<p>Face validity (also called surface validity) refers to whether a test appears to
</p>
<p>measure a certain criterion. It is closely related to content validity. The main
</p>
<p>difference is that you assess content validity by using a systematic review, whereas
</p>
<p>you assess face validity by having people make judgments about the test simply
</p>
<p>based on the surface appearance of the test. You could assess face validity, for
</p>
<p>example, by asking somebody (it does not have to be an expert) what they think
</p>
<p>the test is measuring. Sometimes you may get more honest answers if you have
</p>
<p>lower face validity, because the people doing the test are focused more on the task
</p>
<p>than what they think is being tested. It is also worth noting that you should not rely
</p>
<p>on face validity alone, because even so-called experts can get it wrong (consider,
</p>
<p>for example, the way they used to test whether someone was a witch or not in the
</p>
<p>Middle Ages).
</p>
<p>Note that a test may have poor face validity but good construct validity. A game
</p>
<p>in which you shoot a gun at letters might not appear to measure spelling ability, for
</p>
<p>example, unless the letters pop up in a pattern that is based on correct spelling.
</p>
<p>Similarly, a tank simulation game might have poor surface validity for a naval
</p>
<p>task. However, both of these situations might have good construct validity in that
</p>
<p>the mental representations or the perceptual goals and cues are accurately repre-
</p>
<p>sented (Smallman and St. John 2005). So you may have to consider how to trade
</p>
<p>off face validity against construct validity (and content validity) when designing
</p>
<p>your evaluation study.
</p>
<p>Internal validity refers to how well conclusions can be drawn about cause-effect
</p>
<p>(causal) relationships based on the study design, including the measures used, and
</p>
<p>the situation in which the study was carried out. Internal validity is generally
</p>
<p>highest for tightly controlled studies which investigate the effect of an independent
</p>
<p>variable on a dependent variable, often run in a laboratory setting. To get good
</p>
<p>internal validity you need to make sure you control for other effects that could
</p>
<p>have an impact on the results you obtain. These include:
</p>
<p>13.2 Planning Your Evaluation Study 359</p>
<p/>
</div>
<div class="page"><p/>
<p>&bull; Maturation of the participants: if their condition changes over the duration of the
</p>
<p>study, e.g., they become more tired.
</p>
<p>&bull; The types of participants: it is often impossible to use randomly selected par-
</p>
<p>ticipants, so you need to make sure that you do not end up with unbalanced
</p>
<p>groups of participants (e.g., all males, or all people aged over 50 in one of the
</p>
<p>groups).
</p>
<p>&bull; Testing effects: if you give participants in the study the same test at two different
</p>
<p>times, they may find it easier the second time because they already know the
</p>
<p>questions.
</p>
<p>These potential confounding effects are well known. In many cases there are
</p>
<p>well documented solutions too which can be found in books on experimental
</p>
<p>psychology methods such as those by Calfe (1985), Ray (2008), and Campbell and
</p>
<p>Stanley (1963).
</p>
<p>External validity relates to how far the results of the study can be generalized to
</p>
<p>other populations (such as different user groups), other places, and other times.
</p>
<p>One of the main factors that needs to be considered is the choice of participants
</p>
<p>used in the study. If all your participants are university students, for example, how
</p>
<p>can you be sure that the findings will apply to people who are aged over 60? To get
</p>
<p>good external validity you need to be aware of other effects that could have an
</p>
<p>impact on the results that you obtain, and provide some way of alleviating them.
</p>
<p>These effects include:
</p>
<p>&bull; Awareness of anticipated results: if participants can guess what they think the
</p>
<p>outcome of the study should be, they may adapt their behavior to what they
</p>
<p>think you expect them to do.
</p>
<p>&bull; The Hawthorne effect: people&rsquo;s performance can change simply as a function of
</p>
<p>being watched or recorded.
</p>
<p>&bull; Order effects: if you test people on artifact A first and then artifact B, there may
</p>
<p>be some carryover effect which means that their results with artifact B are better
</p>
<p>than they would otherwise have been.
</p>
<p>&bull; Treatment interaction effects: it may be the case that the participants in your
</p>
<p>study are motivated differently, and the way they are allocated to groups for
</p>
<p>testing means that you have one group that is more highly motivated than the
</p>
<p>other, which hence performs at a higher level.
</p>
<p>Again, these potential confounding effects and solutions to the problems caused
</p>
<p>by them can be found in the literature mentioned above.
</p>
<p>One way to increase external validity is to make sure that you use a wide range
</p>
<p>of users, stimuli, and contexts. The downside is that this will increase costs (time
</p>
<p>and money) and make it more difficult to detect real differences. Care is also
</p>
<p>needed to make sure that you do not reduce reliability (which is discussed below).
</p>
<p>Ecological validity refers to the extent to which your results can be applied to
</p>
<p>real world settings. You should be able to see that it is closely related to external
</p>
<p>validity. For an evaluation study to have high ecological validity, the methods,
</p>
<p>materials, and setting of the study must approximate the real-life situation that is
</p>
<p>360 13 Methodology III: Empirical Evaluation</p>
<p/>
</div>
<div class="page"><p/>
<p>being investigated. If you wanted to conduct an evaluation of the usability of an
</p>
<p>application that is used in an office environment, for example, you would need to
</p>
<p>make sure that your setting resembled that of a normal office, where telephone
</p>
<p>calls and conversations (work and non-work related) are both constant sources of
</p>
<p>interruptions to task performance. The downside of having high ecological validity
</p>
<p>is that you cannot control all the possible independent variables that may affect the
</p>
<p>thing you are trying to measure.
</p>
<p>At first glance there appears to be a conflict between internal and external (and
</p>
<p>ecological) validity. The main reason for carrying out evaluations in a laboratory
</p>
<p>setting is so that you can control for all interfering variables. Although this will
</p>
<p>increase your internal validity you lose external and ecological validity because
</p>
<p>you are using an artificial context for collecting data, and your results may not
</p>
<p>generalize to the real world&mdash;you may lose external and/or ecological validity. If
</p>
<p>you are carrying out an evaluation in a real world setting, however&mdash;using
</p>
<p>observation, for example&mdash;you will have high external (and ecological) validity
</p>
<p>but your internal validity will be reduced. Whether this is a problem or not depends
</p>
<p>on your research strategy. If you are following an inductive research strategy, then
</p>
<p>it is a problem because you will be concerned with the generalization of results; if
</p>
<p>you are following a deductive strategy, to test a theory, for example, then it is not a
</p>
<p>problem, because you are only concerned with threats to internal validity.
</p>
<p>13.2.5.2 Reliability
</p>
<p>Reliability refers to the ability of a measure to produce consistent results when the
</p>
<p>same things are measured under different conditions. Usually this is used in the
</p>
<p>context of test&ndash;retest reliability. In other words, if you conducted the same test again
</p>
<p>under the same conditions, but on a different day or with a similar set of participants,
</p>
<p>for example, you should get the same results if the measure is reliable. Reliability is
</p>
<p>also used in the context of assessing coding schemes, particularly when you need to
</p>
<p>encode the responses that you collect from users. If a coding scheme is reliable, then
</p>
<p>when you give the scheme and the data to another person, they should code the same
</p>
<p>data items in the same way. The level of agreement between the people who do the
</p>
<p>coding is what is called the inter-rater reliability, and you can measure this sta-
</p>
<p>tistically (Cohen&rsquo;s Kappa test is often used to calculate the results).
</p>
<p>13.2.5.3 Sensitivity
</p>
<p>Even if the selected measure is both valid and reliable, it may not be sensitive
</p>
<p>enough to produce discernible effects that can easily be measured. The chosen
</p>
<p>measure may not change very much when you change the independent variables,
</p>
<p>for example. In this case it may be necessary to use a large number of participants.
</p>
<p>To achieve results that are statistically significant, however, you will still need to
</p>
<p>make sure that the measure has high reliability; otherwise your results will still be
</p>
<p>open to question.
</p>
<p>13.2 Planning Your Evaluation Study 361</p>
<p/>
</div>
<div class="page"><p/>
<p>13.3 Evaluation Methods
</p>
<p>Evaluation methods are generally divided into four categories: usability testing,
</p>
<p>field studies, expert (heuristic) evaluation, and A/B testing. One of the funda-
</p>
<p>mental notions behind expert evaluation is that a small number of experts can be
</p>
<p>used to quickly identify a large number of the problems with the system. You
</p>
<p>should think carefully before using these methods because they are not ideally
</p>
<p>suited to all types of system. Each of the evaluation methods has its own strengths
</p>
<p>and weaknesses, and they are often used in combination with each other.
</p>
<p>13.3.1 Usability Testing
</p>
<p>The term usability testing is usually restricted to describing the evaluation of the
</p>
<p>usability of a system under controlled (laboratory) conditions. Quite often usability
</p>
<p>testing is carried out in dedicated laboratories that have been specially designed for
</p>
<p>the purpose. Fluent Studios, for example, is a usability laboratory based in central
</p>
<p>London. It consists of two purpose-built usability rooms, equipped with high
</p>
<p>definition audio-visual technology. These rooms are shown in Fig. 13.1.
</p>
<p>Different organizations will set up their usability testing facility in different
</p>
<p>ways. Generally, one room is set up for testing whilst the other is configured as an
</p>
<p>observation room, which allows the developers, testers, and other interested
</p>
<p>stakeholders to see what the users are doing without disturbing them through their
</p>
<p>presence in the same room. The rooms are physically separated rather than being
</p>
<p>connected by a one-way mirror. Any action that takes place in the testing room is
</p>
<p>projected into the observation room. There are several advantages to using pro-
</p>
<p>jection rather than a one-way mirror:
</p>
<p>Fig. 13.1 A user working with a system being tested (left) and the observation room where
designers and analysts can watch the study going on (right). (Copyright ï¿½ Fluent Interaction Ltd,
www.fluent-interaction.co.uk, reproduced with permission)
</p>
<p>362 13 Methodology III: Empirical Evaluation</p>
<p/>
<div class="annotation"><a href="http://www.fluent-interaction.co.uk">http://www.fluent-interaction.co.uk</a></div>
</div>
<div class="page"><p/>
<p>&bull; Observers feel less intrusive
</p>
<p>&bull; Observers can talk in the observation room
</p>
<p>&bull; Observers can move around, allowing brainstorming activities
</p>
<p>&bull; Participants are less aware of being watched (because there is no large mirror in
</p>
<p>the room, and sound contamination is reduced)
</p>
<p>&bull; A visual area larger than the participant&rsquo;s screen can be used to observe what
</p>
<p>they are doing
</p>
<p>&bull; There is greater flexibility in the way the observation room can be configured
</p>
<p>&bull; Costs are reduced
</p>
<p>&bull; It is easier to use
</p>
<p>&bull; The volume of what the participant is saying can be controlled within the
</p>
<p>observation room.
</p>
<p>Fluent Studios&rsquo; laboratory is used to conduct usability tests in a creative
</p>
<p>environment. Whilst one-to-one testing is carried out with users in the testing
</p>
<p>room, it is regarded as very important to get the observers involved as well. So,
</p>
<p>often when a new design or prototype is being tested, the tests will be designed to
</p>
<p>try and identify usability issues early on in the testing, so that they can be resolved
</p>
<p>at the earliest opportunity.
</p>
<p>Usually the first step in testing is to develop a set of task scenarios that capture
</p>
<p>the critical characteristics of the tasks that are likely to be carried out using the
</p>
<p>system (Carroll 2000). These scenarios are usually descriptions of real-world tasks
</p>
<p>that users can be expected to understand, but the scenario does not describe how the
</p>
<p>task is done using this system. They are typically expressed as problems that the
</p>
<p>user would normally be expected to solve using the system as part of their work.
</p>
<p>For example, consider the following scenario:
</p>
<p>You are a system administrator for a software system that schedules and allocates
resources ranging from company pool cars to meeting rooms. Unfortunately one of the
meeting rooms has unexpectedly been designated to be refurbished, which will take
2 months beginning in July. Your task is to notify those people who have booked the room
for July and August and to provide alternative resources.
</p>
<p>You should be able to see that this scenario contains a goal, information about
</p>
<p>that goal, and information about the context in which the task takes place. It does
</p>
<p>not, however, contain instructions about how to use the system to achieve the
</p>
<p>desired goal.
</p>
<p>The focus of the scenarios determines the shape of the evaluation: everyday
</p>
<p>usage scenarios, for example, will capture information about everyday usage of the
</p>
<p>system. Similarly, for critical systems (safety critical, mission critical, business
</p>
<p>critical, and so on) the scenarios would be designed to focus on critical (but
</p>
<p>unusual) incidents. Ideally a more comprehensive evaluation could be carried out
</p>
<p>using both types of scenarios.
</p>
<p>An illustration of the benefits of usability testing occurred when new designs for
</p>
<p>a national educational site were being tested in Fluent Studios. Some usability
</p>
<p>problems were quickly observed with the method of global navigation: the first
</p>
<p>four users who were tested all struggled to find the site&rsquo;s home page. Between
</p>
<p>13.3 Evaluation Methods 363</p>
<p/>
</div>
<div class="page"><p/>
<p>testing sessions a new page header was developed, and tests with the next four
</p>
<p>participants demonstrated that the introduction of the new design had resolved the
</p>
<p>problem. This rapid development methodology is used to test designs in an agile
</p>
<p>way, which makes the most effective use of the testing time allocated to a project.
</p>
<p>13.3.2 Field Studies and Field Experiments
</p>
<p>Field studies, as the name implies, are evaluations that are carried out in the field,
</p>
<p>that is, in real world settings. Field studies are often carried out to discover more
</p>
<p>about the context of use of a technology that is to be designed or is being designed.
</p>
<p>Studying activities in the &lsquo;&lsquo;real&rsquo;&rsquo; world can be challenging. If you just think about
</p>
<p>the things that happen every day in an office environment you should start to get
</p>
<p>the picture. In an office, users may be carrying out some task using the computer.
</p>
<p>They can break off from their work at any point, though, such as when they are
</p>
<p>interrupted by the telephone ringing, if a colleague stops by to discuss something
</p>
<p>(work or otherwise), or if their boss calls them into a meeting. So carrying out the
</p>
<p>task is not simply a matter of planning what to do, then just getting on and doing it
</p>
<p>step by step in sequence, from start to finish: people will often have to juggle
</p>
<p>several, possibly unrelated, and often unscheduled, activities at once. The big
</p>
<p>advantage of field studies is that they show you how people really work. One
</p>
<p>obvious design implication of the fractured nature of work is that you should make
</p>
<p>it relatively easy for people to pick up where they left off after an interruption. The
</p>
<p>main disadvantage of field studies is that it is often very difficult to exercise
</p>
<p>experimental control over what happens, so it is harder to focus on the relation-
</p>
<p>ships between some of the task variables, and to have results that are both general
</p>
<p>and applicable to other settings or times.
</p>
<p>Field experiments are trials of technologies in real world settings. This is often
</p>
<p>when a fully functional prototype can be deployed into a real world setting and, as
</p>
<p>designers and developers, we want to see how users will interact with the tech-
</p>
<p>nology. Such field experiments tend to be for non-safety&ndash;critical systems, such as
</p>
<p>recreational and social Internet sites. Often there is some latitude for changing the
</p>
<p>technology, but most of the functionality is set. In this instance, the evaluation will
</p>
<p>likely involve many different methods: collecting usage data, conducting obser-
</p>
<p>vations of the technology in use, interviewing and surveying users, small con-
</p>
<p>trolled experiments, and so on (for an example of a technology that was fielded and
</p>
<p>evaluated see Churchill et al. 2003).
</p>
<p>13.3.3 (Expert) Heuristic Evaluation
</p>
<p>Heuristic evaluation (Nielsen and Molich 1990) is a relatively informal way of
</p>
<p>analyzing the usability of an interface design. A small select number of people&mdash;
</p>
<p>ideally interface design experts, and preferably domain experts too&mdash;are asked to
</p>
<p>364 13 Methodology III: Empirical Evaluation</p>
<p/>
</div>
<div class="page"><p/>
<p>make judgments, based on a set of guidelines or principles together with their own
</p>
<p>knowledge, about a particular design. The individual results are then aggregated
</p>
<p>together. In this way it is possible to overcome the inherent inaccuracy of indi-
</p>
<p>vidual evaluations.
</p>
<p>In the ideal world all of the evaluators would use the same (standard) set of
</p>
<p>criteria for judging what is good or bad. In reality, most people tend to rely on
</p>
<p>intuition and common sense, partly because most usability guidelines tend to be
</p>
<p>excessively large, often having many tens or even hundreds of rules (e.g., Brown
</p>
<p>1988; Mosier and Smith 1986). Molich and Nielsen (1990), however, suggested
</p>
<p>that a relatively simple set of guidelines can be used as the basis for evaluation.
</p>
<p>Initially they used nine guidelines, but over the years, these have been refined and
</p>
<p>the number increased to ten, as shown in Table 13.1.
</p>
<p>Each expert works their way through the user interface design individually
</p>
<p>noting compliance with the heuristics. Note that the user interface may just be a
</p>
<p>paper-based prototype, because the experts are not being asked to carry out tasks
</p>
<p>using the system. Problems that are detected can either be written down or
</p>
<p>recorded verbally (e.g., by taking verbal protocols). The individual results are then
</p>
<p>aggregated to highlight the detected problems.
</p>
<p>Typically, only three to five experts are required to carry out a heuristic eval-
</p>
<p>uation and generate useful results. Many people have taken this to be a hard and
</p>
<p>fast rule for all types of evaluation, however, which can be a serious mistake. The
</p>
<p>requisite number, to a large extent, depends on the diversity of the eventual user
</p>
<p>population. So, for example, if you were designing an on-line population census,
</p>
<p>then it would not make sense to just use three to five users, since such a small
</p>
<p>sample is very unlikely to be truly representative of the diversity inherent in a
</p>
<p>nation&rsquo;s general population.
</p>
<p>Table 13.1 Heuristic basis for user interface evaluation (adapted from http://www.nngroup.com/
articles/ten-usability-heuristics)
</p>
<p>1. The current system status should always be readily visible to the user
</p>
<p>2. There should be a match between the system and the user&rsquo;s world: the system should speak
the user&rsquo;s language
</p>
<p>3. The user should have the control and freedom to undo and redo functions that they
mistakenly perform
</p>
<p>4. The interface should exhibit consistency and standards so that the same terms always mean
the same thing
</p>
<p>5. Errors should be prevented where possible
</p>
<p>6. Use recognition rather than recall in order to minimize the mental workload of the users
</p>
<p>7. The system should have flexibility and efficiency of use across a range of users, e.g., through
keyboard short-cuts for advanced users
</p>
<p>8. The system should be esthetic and follow a minimalist design, i.e., do not clutter up the
interface with irrelevant information
</p>
<p>9. Users should be helped to manage errors: not all errors can be prevented so make it easier for
the users to recognize, diagnose, and recover
</p>
<p>10. Help and documentation should be readily available and structured for ease of use
</p>
<p>13.3 Evaluation Methods 365</p>
<p/>
<div class="annotation"><a href="http://www.nngroup.com/articles/ten-usability-heuristics">http://www.nngroup.com/articles/ten-usability-heuristics</a></div>
<div class="annotation"><a href="http://www.nngroup.com/articles/ten-usability-heuristics">http://www.nngroup.com/articles/ten-usability-heuristics</a></div>
</div>
<div class="page"><p/>
<p>It should be noted that many of the problems that are identified by heuristic
</p>
<p>evaluation may not affect the usability of the system. In addition, the results are
</p>
<p>often only presented in negative terms, focusing on what is bad about the design,
</p>
<p>instead of also highlighting the things that are good.
</p>
<p>13.3.4 Co-operative Evaluation
</p>
<p>Co-operative evaluation is another type of expert evaluation method. It was
</p>
<p>developed at the University of York (UK), and is related to Scandinavian design
</p>
<p>practices (Monk et al. 1993; M&uuml;ller et al. 1997). As the name suggests, the
</p>
<p>evaluation is carried out co-operatively, with the user effectively becoming part of
</p>
<p>the evaluation team. The method is based on the notion that any user difficulties
</p>
<p>can be highlighted by two simple tactics:
</p>
<p>1. Identifying the use of inefficient strategies by the user (e.g., copy-paste-delete,
</p>
<p>rather than cut and paste).
</p>
<p>2. Identifying occasions when the user talks about the interface, rather than their
</p>
<p>tasks. These are called breakdowns, based on the notion that good tools should
</p>
<p>be transparent, so the user should be talking about the task rather than the
</p>
<p>technology.
</p>
<p>The user is asked to talk aloud as they carry out a series of tasks, and can be
</p>
<p>prompted with questions. It is a formative evaluation technique, in that it is used to
</p>
<p>gather information about the design as it is being formed. The method can
</p>
<p>therefore be used with a working prototype or with the real system.
</p>
<p>13.3.5 A/B Testing
</p>
<p>A recent trend is to do live testing of multiple interfaces. This is called A/B testing
</p>
<p>or bucket testing. In this approach a web service exposes different users to different
</p>
<p>interfaces and/or interactions. This can be seen at Google, for example, who was
</p>
<p>one of the first Internet sites to use this method extensively to guide their interface
</p>
<p>and interaction design decisions. In bucket tests, interfaces can vary in subtle
</p>
<p>ways, such as color changes, or may differ substantially, including manipulations
</p>
<p>of key functionality. User actions such as clicks (measured as CTR or click
</p>
<p>through rates) are studied to see the impact on user behavior, if any, of the
</p>
<p>changes.
</p>
<p>There are many advantages to these kinds of studies&mdash;not least that a test can be
</p>
<p>run at scale and while maintaining ongoing business, and that feedback is fast. Of
</p>
<p>course, this approach requires building the test interfaces, and having the platform
</p>
<p>on which to partition users into conditions and deliver the experiences.
</p>
<p>366 13 Methodology III: Empirical Evaluation</p>
<p/>
</div>
<div class="page"><p/>
<p>13.4 What to Evaluate?
</p>
<p>In general, the sooner evaluation is done during development, the sooner you will
</p>
<p>get feedback, and the more likely it is that the delivered product will be both
</p>
<p>usable and acceptable to users. There is a trade-off here between the need for
</p>
<p>evaluation and how closely related the current version is to the final version. If an
</p>
<p>iterative development life cycle approach is used, this means that evaluation
</p>
<p>should be carried out as part of each iteration. Obviously, the earlier in develop-
</p>
<p>ment that evaluation takes place, the less developed the system that is being
</p>
<p>evaluated will be. The way that evaluation is often carried out during development
</p>
<p>is using some sort of prototype, until eventually the full system can be evaluated.
</p>
<p>The prototype usually starts out as something with low fidelity (possibly just one
</p>
<p>or more sketches), and increases in fidelity as the project progresses.
</p>
<p>13.4.1 Pencil and Paper Prototypes
</p>
<p>At the earliest stages of development, pencil and paper mockups of the interface
</p>
<p>can be shown to the users, who are then asked how they would carry out particular
</p>
<p>tasks. This technique, which is often described as storyboarding should ideally be
</p>
<p>carried out with real users, although other designers, and even hostile users, could
</p>
<p>be employed.
</p>
<p>Using pencil and paper sketches is cheap, and can be used very early in design.
</p>
<p>At this stage, ideas are usually still being explored, so the evaluations are usually
</p>
<p>formative. The data collected are normally qualitative rather than quantitative,
</p>
<p>with the results being used to inform the design of the artifact.
</p>
<p>13.4.2 Computer-Based Prototypes
</p>
<p>The next level of sophistication involves building a computer-based prototype.
</p>
<p>There are now several tools around that can be used for prototyping at several
</p>
<p>levels, from pencil and paper style sketches to interactive working prototypes.
</p>
<p>At the earliest stages of computer-based prototyping you can employWizard of Oz
</p>
<p>techniques, where the user will interact with a prototype (computer-based) interface.
</p>
<p>The full functionality of the rest of the system is usually not available at this point, so
</p>
<p>a human acts behind the scenes to process user input and actions and provide the
</p>
<p>required responses (like the Wizard of Oz did in the film!). This technique has been
</p>
<p>used very effectively for evaluating the potential of speech-based systems.
</p>
<p>The level of sophistication of the prototype should naturally increase as
</p>
<p>development progresses, and the prototype becomes closer to the finished product.
</p>
<p>How it develops will depend mostly on which basic method of prototyping you
</p>
<p>use: evolutionary or revolutionary. In evolutionary prototyping, the original
</p>
<p>13.4 What to Evaluate? 367</p>
<p/>
</div>
<div class="page"><p/>
<p>prototype is refined after each iteration of the development cycle: the prototype
</p>
<p>evolves towards the deliverable version. This is the sort of approach that is used in
</p>
<p>developing web sites, where they use wireframes to lay out the basic initial design,
</p>
<p>which then gets filled in and refined as the design evolves. In revolutionary pro-
</p>
<p>totyping, the current prototype is thrown away at the end of each iteration of the
</p>
<p>development cycle, and a new prototype is developed.
</p>
<p>In addition to helping identify design issues, prototypes can also be used to help
</p>
<p>users to articulate requirements. People often find it much easier to talk about
</p>
<p>something concrete, referring to the prototype, than to talk about something
</p>
<p>abstract, where they have to imagine what the application or product should do.
</p>
<p>Prototypes vary in cost, depending upon the sophistication of the prototype and
</p>
<p>the length of the evaluation period (laboratory-based user testing vs field studies).
</p>
<p>They do tend to give good results and are suitable for many stages of the design
</p>
<p>process, for both formative and summative evaluations.
</p>
<p>13.4.3 The Final System
</p>
<p>Evaluations of the final system will often be performed in house first, possibly
</p>
<p>using laboratory-based testing. If there is latitude for some redesign, systems may
</p>
<p>be deployed and field experiments conducted, but this only tends to be the case for
</p>
<p>systems that are not safety&ndash;critical, as noted above. For enterprise, and safety- and
</p>
<p>security-critical systems, it is more usually the case that the system is evaluated in
</p>
<p>full before it gets delivered to the customer. The final system will usually be
</p>
<p>subjected to a formal acceptance test, normally on the customer&rsquo;s premises, where
</p>
<p>the customer will sign to say that the system has successfully passed the agreed
</p>
<p>tests. You should note that web sites are very rarely tested at the customer&rsquo;s site
</p>
<p>(largely because they will normally be used from elsewhere).
</p>
<p>Once a system is delivered and has been accepted by the customer, it is unlikely
</p>
<p>that any further formal evaluation will take place. The picture is slightly different
</p>
<p>for web sites, however, where the delivered system will normally reside in a
</p>
<p>dynamic environment, so the iterative development may continue, albeit with
</p>
<p>iterations that have a longer duration. In both cases, data on patterns of usage may
</p>
<p>be collected, along with information about problems logged with customer sup-
</p>
<p>port, as noted above, and this can be used to inform future development projects
</p>
<p>and refinements to existing systems and products.
</p>
<p>13.5 Measuring Usability
</p>
<p>There are several dimensions to usability, so there are several measures, both
</p>
<p>qualitative and quantitative, that can be used to indicate how usable a particular
</p>
<p>artifact is. Most people will be familiar with task time as the de facto standard for
</p>
<p>368 13 Methodology III: Empirical Evaluation</p>
<p/>
</div>
<div class="page"><p/>
<p>measuring efficiency and productivity, and hence giving an indication of usability.
</p>
<p>There are several others too, though, and they are usually concerned with either
</p>
<p>performance (quantitative measures) or process (qualitative measures). There is
</p>
<p>also the concept of user experience, related to how much satisfaction the user
</p>
<p>obtains from the system. Here we briefly describe the measures that you are most
</p>
<p>likely to encounter. Often you will use several complementary methods to mea-
</p>
<p>sure usability, such as a combination of task performance times, and a usability
</p>
<p>survey.
</p>
<p>13.5.1 Task Time
</p>
<p>Task performance time is widely used as a measure of efficiency within the fields
</p>
<p>of HCI and human factors and ergonomics. The task is usually one of three: a
</p>
<p>small cognitively manageable task, often referred to as a unit task (Card et al.
</p>
<p>1983); a standard, predefined benchmark task (that you use to assess efficiency for
</p>
<p>similar artifacts); or a task scenario (as described above).
</p>
<p>It is easy to determine task time using a stop watch, for example, or using time
</p>
<p>stamps if you are recording task performance. Time is a measure that is widely
</p>
<p>understood, and is easy to analyze statistically. Time is generally used as a
</p>
<p>measure in summative evaluations of the final system. Where the performance
</p>
<p>time is relatively insensitive, however, it can be costly to carry out evaluations,
</p>
<p>because you will have to run the test many times to be able to draw solid statistical
</p>
<p>conclusions from the results.
</p>
<p>Remember that usability is not only concerned with how easy something is to
</p>
<p>use, but also how easy it is to learn to use. Task times can also be used to
</p>
<p>determine how long it takes to learn to use a system. Normally some threshold
</p>
<p>level of performance is defined in advance, and the length of time it takes
</p>
<p>to reach that threshold is measured. Alternatively, the length of time it takes
</p>
<p>to recover from observable errors can be measured: you would expect to see
</p>
<p>this time reduce as people learn how to do the task and how to manage the
</p>
<p>errors.
</p>
<p>One of the main problems of using time measures is that they are not easily
</p>
<p>compared unless all the contextual elements (tasks, level of expertise, lighting
</p>
<p>conditions, and so on) are kept constant. The corollary of this is that if you want to
</p>
<p>compare times when you cannot fully control the contextual effects, you have to
</p>
<p>convert the data into a more stable metric, i.e., one that is not so easily affected by
</p>
<p>changes in these elements. One way of doing this, which was proposed byWhiteside
</p>
<p>et al. (1985), is to calculate a score in the range 1&ndash;100 as shown in Eq. (13.1):
</p>
<p>Score &frac14; 1=T&eth; &THORN; ï¿½ P ï¿½ C &eth;13:1&THORN;
</p>
<p>where T = time, C = constant based on fastest expert time, and P = percentage
</p>
<p>of task completed.
</p>
<p>13.5 Measuring Usability 369</p>
<p/>
</div>
<div class="page"><p/>
<p>13.5.2 Errors
</p>
<p>Errors can bemeasured quantitatively (by simply counting them) or qualitatively (by
</p>
<p>noting the different types of error). Whilst time is best suited to summative evalu-
</p>
<p>ations, error measures can be used in both summative and formative evaluations.
</p>
<p>As we have already seen in Chap. 10, however, errors are not easy to define,
</p>
<p>and they can be hard to count too. This is particularly true when observing expert
</p>
<p>behavior. One of the key aspects of expert performance is that they often detect
</p>
<p>and recover their own errors before the effects of the error become apparent to
</p>
<p>outside observers. So if you watch an expert perform a task, you may not even
</p>
<p>realize that they have made an error.
</p>
<p>We can distinguishmany types of errors&mdash;slips, mistakes, violations, mode errors
</p>
<p>(e.g., problemswith grayed outmenu items), discrimination errors (e.g., selecting the
</p>
<p>wrong menu item because of ambiguous labels), and so on. The types of errors will
</p>
<p>vary depending on which taxonomy of errors you use (see Chap. 10 for examples).
</p>
<p>13.5.3 Verbal Protocols
</p>
<p>Verbal protocols can be a useful way of understanding the issues that confront
</p>
<p>users as they try to tackle particular problems using some artifact. Some care is
</p>
<p>needed when reading about verbal protocols, because many people use the terms
</p>
<p>talk aloud and think aloud interchangeably. Strictly speaking you usually want
</p>
<p>people to produce talk aloud reports, reflecting the things that are in their short
</p>
<p>term memory as they do the task; if they generate think aloud reports, this suggests
</p>
<p>that they are processing things more deeply and (possibly) rationalizing their
</p>
<p>decisions and actions before they verbalize them.
</p>
<p>The two main types of verbal protocols are concurrent, which are taken whilst
</p>
<p>the person performs the task, and retrospective, where the person describes what
</p>
<p>they did after completing the task. In concurrent verbal protocols, the user is asked
</p>
<p>to talk about information as it comes to mind, to &lsquo;&lsquo;say out loud everything that you
</p>
<p>say to yourself&rsquo;&rsquo; (Ericsson and Simon 1980, 1993). The user should not be
</p>
<p>reflecting upon their own behavior and providing explanations of causality. While
</p>
<p>this kind of reflective behavior (referred to as introspection) may provide some
</p>
<p>useful insights, these insights are not considered valid data because they are easily
</p>
<p>influenced by other aspects, such as expected task performance, social pressure,
</p>
<p>and the user&rsquo;s (often incorrect) theories of how their own mind works. Talking
</p>
<p>aloud about content is generally regarded as being more objective than thinking
</p>
<p>aloud, which usually involves introspecting about the process.
</p>
<p>Providing concurrent protocols can be hard for users, but they are more reliable
</p>
<p>than other types of verbal protocol. When you take concurrent verbal protocols,
</p>
<p>you should ask the user to practice providing a concurrent verbal protocol whilst
</p>
<p>carrying out a simple task, such as an arithmetic addition or counting the windows
</p>
<p>in their childhood home (Ericsson and Simon 1993, appendix).
</p>
<p>370 13 Methodology III: Empirical Evaluation</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10">http://dx.doi.org/10.1007/978-1-4471-5134-0_10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10">http://dx.doi.org/10.1007/978-1-4471-5134-0_10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10">http://dx.doi.org/10.1007/978-1-4471-5134-0_10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10">http://dx.doi.org/10.1007/978-1-4471-5134-0_10</a></div>
</div>
<div class="page"><p/>
<p>You may find it easier to collect concurrent protocols by having two users work
</p>
<p>together on a task. The natural dialogue that takes place (assuming that dialogue
</p>
<p>occurs or is required for the task) will encapsulate the information they are using to
</p>
<p>do the task. Another possible variation is to use expert commentary. Here one
</p>
<p>expert describes what the user is doing as they perform the task.
</p>
<p>Retrospective protocols can also be used, and these are taken after the task has
</p>
<p>been performed. They tend to be more useful when people can watch a video or
</p>
<p>pictorial record&mdash;we discuss visual protocols in the next section&mdash;of their per-
</p>
<p>formance to help them remember what they did. This helps them to recognize their
</p>
<p>actions, rather than just having to recall them from memory. Although subjects
</p>
<p>may find it easier to provide retrospective verbal protocols, they can lead people to
</p>
<p>provide post hoc rationalizations of actions that they now perceive to be incorrect
</p>
<p>or that they performed instinctively.
</p>
<p>Another way that you can interrogate what users are doing is by using pop-up
</p>
<p>menus (Feurzeig and Ritter 1988). This idea has not been fully tested, however,
</p>
<p>and does not have the same level of theoretical support as concurrent verbal
</p>
<p>protocols. The obvious criticism is that the pop-up menu interrupts the task, and
</p>
<p>may break the user&rsquo;s flow of activity because it draws their attention away from
</p>
<p>the task. A similar but more intrusive approach is to freeze the task and ask users
</p>
<p>about what they are doing at that particular point in time. This latter technique has
</p>
<p>been used in measuring situation awareness (Endsley 1995).
</p>
<p>13.5.4 Video Protocols
</p>
<p>Video protocols (also called visual protocols) involve making a video recording of
</p>
<p>users as they carry out some prescribed task. The recording is often made using
</p>
<p>multiple cameras positioned to capture different aspects of performance, such as
</p>
<p>what is currently shown on the screen, the position of the user&rsquo;s hands, and a more
</p>
<p>general view that shows both the user and the system together. Sometimes the
</p>
<p>recordings are made directly from the monitor. Although video protocols provide
</p>
<p>very rich data, the fact that they are being video recorded does make some users
</p>
<p>feel under pressure, and can lead to unnatural behavior.
</p>
<p>The main problem with video protocols is that analyzing them can be very hard
</p>
<p>and is very time-consuming. Typically, analysis can take anywhere between 10
</p>
<p>and 100 times as long as the duration of the recording.
</p>
<p>As noted above, video protocols can be shown to users to help in the collection
</p>
<p>of retrospective verbal protocols. This technique is sometimes called auto-con-
</p>
<p>frontation, because the users are shown the video recording and asked to explain
</p>
<p>their behavior.
</p>
<p>Video protocols can be shown to developers to let them see the sorts of
</p>
<p>problems that real users encounter with their system. It is arguably better, though,
</p>
<p>to let the developers watch users try to use their product in a usability laboratory in
</p>
<p>real time. Both of these methods are generally much more effective than simply
</p>
<p>13.5 Measuring Usability 371</p>
<p/>
</div>
<div class="page"><p/>
<p>providing the developers with a written report of qualitative and quantitative
</p>
<p>performance data. They can also be used when the developers are remote from the
</p>
<p>site where the evaluation is taking place, as long as suitable network connections
</p>
<p>are available to transmit the recordings.
</p>
<p>13.5.5 Eye Movement Tracking
</p>
<p>In the last 10 years an increasing number of people have begun to collect data on
</p>
<p>eye movements to analyze how people use web pages (e.g., Nielsen and Pernice
</p>
<p>2010; and see Navalpakkam and Churchill in press, for a more general review of
</p>
<p>eye-tracking). The current eye-tracking equipment is much easier to use, much
</p>
<p>cheaper, and much less invasive than earlier generations of eye-trackers which
</p>
<p>required you to have your head clamped in place, and required frequent re-cali-
</p>
<p>bration. They also generated large amounts of data that required significant effort
</p>
<p>to analyze and interpret, whereas there are now several good software packages
</p>
<p>available that will help you make sense of the data. You should recall that we
</p>
<p>discussed eye-tracking in Chap. 4.
</p>
<p>Eye movement data is particularly useful as a way of generating heat maps
</p>
<p>which show the hot spots on a web page. These are the parts of a web page that
</p>
<p>users spend most of their time looking at, either by gazing at it for a long period of
</p>
<p>time, or visiting it for several shorter periods of time. In general, users have
</p>
<p>predetermined expectations about where they expect certain items such as menus,
</p>
<p>navigation bars, back/next buttons, and so on to appear on a web page. This leads
</p>
<p>them to automatically look for those items in the expected places first. If they are
</p>
<p>not where they are expected to be, you start to see scan patterns in the eye
</p>
<p>movements as the eyes jump around trying to find the required element.
</p>
<p>There are some drawbacks to using eye movement data, which mean that you
</p>
<p>often need to complement it by using an additional method. The two main
</p>
<p>drawbacks are that the data do not tell you why users fixated on a particular point
</p>
<p>on the page and that the data do not tell you what items on the page the participant
</p>
<p>missed or did not notice.
</p>
<p>13.5.6 Questionnaires and Surveys
</p>
<p>If you want to discover opinions about something, often the best way is to ask
</p>
<p>people. Subjective measures are frequently used to assess attitudes towards a new
</p>
<p>piece of technology&mdash;feelings of control, frustration, etc. Sometimes just asking
</p>
<p>people for their opinions is the only way of gathering this data. Note, however, that
</p>
<p>sometimes surveys can measure opinions but not actions; early work has shown that
</p>
<p>what people do and what they say they will do can vary up to 100% (LaPiere 1934).
</p>
<p>Surveys are more valid when the attitudes are more stable, relevant, and salient to
</p>
<p>372 13 Methodology III: Empirical Evaluation</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4">http://dx.doi.org/10.1007/978-1-4471-5134-0_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4">http://dx.doi.org/10.1007/978-1-4471-5134-0_4</a></div>
</div>
<div class="page"><p/>
<p>the behavior, and there are less situational pressures on the behavior (Hock 2002,
</p>
<p>pp 281&ndash;288). Questionnaires and surveys allow you to gather large amounts of data
</p>
<p>in a relatively short period of time, as long as you distribute them appropriately.
</p>
<p>Designing questionnaires and surveys is an art in itself, as great care needs to be
</p>
<p>exercised to make sure that any potential biases are avoided. It is also important to
</p>
<p>make sure that the questionnaires are well structured and tested, as this helps to
</p>
<p>ensure the validity of the resulting data. For this reason, it is almost invariably a
</p>
<p>good idea to carry out a pilot study on a small sample of users, and then refine the
</p>
<p>questionnaires appropriately. Having a pilot study is also very useful for deter-
</p>
<p>mining how long it will take to complete the survey. As a rule of thumb, most
</p>
<p>people are relatively happy with filling in surveys that take 10&ndash;15 min to com-
</p>
<p>plete, without any reward.
</p>
<p>The questions need to be carefully designed, because you will not have a chance
</p>
<p>to explain them to respondents. So they need to be clear, unambiguous, and easy to
</p>
<p>understand. It is also important that you do not ask leading questions that reflect
</p>
<p>any biases that you may have. You also need to think about the answers that you
</p>
<p>require. In some cases it may be a simple &lsquo;&lsquo;Yes/No/Don&rsquo;t Know,&rsquo;&rsquo; or it may be
</p>
<p>&lsquo;&lsquo;select one (or more) options&rsquo;&rsquo; from a possible list. In other cases (and quite often
</p>
<p>in usability surveys) you will be trying to gauge people&rsquo;s opinions about some-
</p>
<p>thing, in which case you are more likely to use rating scales, such as a five-point
</p>
<p>Likert scale, where you will ask respondents how much they agree with a particular
</p>
<p>statement, such as &lsquo;&lsquo;I found it easy to locate the home page button.&rsquo;&rsquo; In this case the
</p>
<p>response scale would normally be from Strongly Disagree to Strongly Agree.
</p>
<p>Distribution of questionnaires and surveys requires careful thought. Usability
</p>
<p>surveys are frequently handed out on paper to participants as part of a usability
</p>
<p>study (often at the end). There are some standard usability rating scales that you
</p>
<p>could use or adapt for your own purposes, such as the System Usability Scale
</p>
<p>(SUS, Brooke 1996). More generally, however, you may want to use electronic
</p>
<p>surveys, in which case you need to think about how you will attract people from
</p>
<p>your target audience to complete the survey.
</p>
<p>Note that if you intend to use follow-up surveys at the end of a test, you need to
</p>
<p>be aware of what is called the media equation (Reeves and Nass 1996). This refers
</p>
<p>to the fact that if you give people the survey on the same machine as the one on
</p>
<p>which you give them the test, they rate things more highly than if they complete
</p>
<p>the survey on a different machine! They treat the machine they used as an agent
</p>
<p>that needs to be treated socially.
</p>
<p>13.5.7 Interviews and Focus Groups
</p>
<p>Interviews can take three different forms: structured, unstructured, and semi-
</p>
<p>structured. Whichever type you decide to use, it is often a good idea to record
</p>
<p>them, with the written consent of the interviewees. It is also a good idea to make
</p>
<p>some written notes. These will help add extra context to help interpret the content
</p>
<p>13.5 Measuring Usability 373</p>
<p/>
</div>
<div class="page"><p/>
<p>that has been recorded, and will also act as a back-up in case recording fails for
</p>
<p>some reason.
</p>
<p>Structured interviews are based around a fixed set of questions that the inter-
</p>
<p>viewees must answer. These questions are often closed, i.e., the user is expected to
</p>
<p>answer the question and no more. Typically these questions have &lsquo;&lsquo;Yes/No&rsquo;&rsquo; type
</p>
<p>answers.
</p>
<p>Unstructured interviews are generally more informal, and are a bit more like a
</p>
<p>chat with the users. So you may start off with a small number of issues (perhaps as
</p>
<p>few as one or two) that you want to discuss with the users, and then the direction
</p>
<p>you take for the rest of the interview is determined by what they say.
</p>
<p>Semi-structured interviews fall somewhere between structured and unstructured
</p>
<p>interviews. Usually you will have a short standard list of questions, which may be
</p>
<p>open, and then you direct the interview based on what the users say in response to
</p>
<p>the questions you ask. Unstructured and semi-structured interviews tend to be
</p>
<p>slightly harder to carry out because they will often require the interviewer to think
</p>
<p>on their feet during the interview. Their big advantage, however, is that they can
</p>
<p>uncover issues that may not previously have been thought of.
</p>
<p>Whilst interviews tend to be carried out on a one-to-one basis, it can be useful
</p>
<p>to have group discussions, which are often carried out as focus groups. Usually a
</p>
<p>focus group is carried out with a small group of up to about ten users or stake-
</p>
<p>holders. The basic aim is to get the focus group members to express their opinions
</p>
<p>in a relatively friendly environment. To conduct a focus group successfully you
</p>
<p>need to have a list of issues or questions for discussion, and to have an experienced
</p>
<p>facilitator who can make sure that everybody gets a chance to air their opinions.
</p>
<p>The sessions can produce lots of useful data, so it is often best to record them as
</p>
<p>well as making notes (it may help to have separate people taking notes and
</p>
<p>facilitating the discussions).
</p>
<p>13.5.8 Workload Measures
</p>
<p>Workload measures attempt to describe how much mental effort the user expends
</p>
<p>in performing a particular task. They are generally used more often to evaluate
</p>
<p>critical systems rather than web sites per se. The measures are hard to devise, but
</p>
<p>can be useful in many contexts. The most common approach is to periodically ask
</p>
<p>users to state (or rate) what they think their current workload is, although this can
</p>
<p>be quite disruptive of performance and hence affect their perceived workload.
</p>
<p>The NASA-TLX (Task Load indeX) workload measurement instrument (Hart
</p>
<p>and Staveland 1988) is probably the most commonly used method. NASA-TLX
</p>
<p>can be administered on paper or on-line. The NASA TLX is a multi-dimensional
</p>
<p>rating procedure that provides an overall workload score based on a weighted
</p>
<p>average of ratings on six workload dimensions: mental demands, physical
</p>
<p>demands, temporal demands, own performance, effort, and frustration (NASA,
</p>
<p>1987).
</p>
<p>374 13 Methodology III: Empirical Evaluation</p>
<p/>
</div>
<div class="page"><p/>
<p>During the standard NASA-TLX procedure users carry out pairwise compari-
</p>
<p>sons of the six dimensions. In each of the 15 (5 ? 4 ? 3 ? 2 ? 1) comparisons,
</p>
<p>users select the dimension that contributed more to workload. Each dimension
</p>
<p>receives one point for each comparison where it was greater. The relative weight
</p>
<p>for each dimension is then given by the sum of those points, divided by 15 to
</p>
<p>normalize it.
</p>
<p>Probably the most accurate approach for measuring workload is to use a sec-
</p>
<p>ondary task that the user must perform as and when they can (e.g., responding to
</p>
<p>visual or auditory signals). For example, at random intervals the user has to push
</p>
<p>an &lsquo;A&rsquo; when the number that pops up on the screen is odd and a &lsquo;B&rsquo; when the
</p>
<p>number is even. The time and correctness of the response is a measure of how hard
</p>
<p>the user is working.
</p>
<p>We sometimes find that while two systems give comparable performance
</p>
<p>results on the primary task, performance on the secondary task may be very
</p>
<p>different., This suggests that one interface is more demanding than the other, i.e.,
</p>
<p>where performance on the secondary task is worse, this indicates that the user is
</p>
<p>expending more mental effort on the primary task.
</p>
<p>13.5.9 Patterns of Usage
</p>
<p>Rather than looking at performance on unit or benchmark tasks in a laboratory
</p>
<p>setting, you can place prototype versions of your system in real work settings and
</p>
<p>observe actual patterns of use, either directly or through videotape. Often you will
</p>
<p>find that certain features, including those that have been requested by users, are
</p>
<p>very rarely used, e.g., style sheets in Word.
</p>
<p>You could also consider instrumenting the user interface or using a general
</p>
<p>keystroke logger (e.g., Kukreja et al. 2006) to collect (timed) logs of the key-
</p>
<p>strokes, and other interactions that the user performs. This data gets logged in what
</p>
<p>are sometimes called dribble files. These files can quickly become excessively
</p>
<p>large, however, and thus be hard to analyze. They can be used as a way to identify
</p>
<p>errors, error recovery, and patterns of use. Note that if you will be collecting data
</p>
<p>in this way, you will need ethical approval, which we talk about below.
</p>
<p>If you are evaluating a system that has been released into the marketplace, you
</p>
<p>can also get some information on patterns of usage by looking at the logs of calls
</p>
<p>to customer/technical support services. Note that this data only measures problems
</p>
<p>that have been reported, rather than all of the problems. Users are often very
</p>
<p>flexible and adaptable and will develop ways of making the system do what they
</p>
<p>want it to do, such as workarounds, rather than spend extra time and effort on the
</p>
<p>end of a phone line trying to contact technical support to report the problem.
</p>
<p>Customer support activity data can be both politically and commercially sen-
</p>
<p>sitive&mdash;it may allow competitors to see where the problems are with a particular
</p>
<p>product. Such data can be very valuable, however, because it does give a good
</p>
<p>indication of where the real problems may lie.
</p>
<p>13.5 Measuring Usability 375</p>
<p/>
</div>
<div class="page"><p/>
<p>13.5.10 User Experience
</p>
<p>Finally, there is the concept of user experience (Tullis and Albert 2008). In
</p>
<p>addition to these mostly quantitative measures, there is the qualitative experience
</p>
<p>of using the system that is being tested. This is an important concept, and is related
</p>
<p>to several concepts that can sometimes be hard to define, and even harder to
</p>
<p>measure. Many organizations now rate a high level of user experience (explained
</p>
<p>in Chap. 2) as being a major determinant in the success of a system or product.
</p>
<p>One of the factors that will influence user experience is task importance. If
</p>
<p>the task is important to the user and the system gets the task done, then, it will
</p>
<p>be a successful system. Early systems, e.g., TVs, phones, portable phones, PDAs,
</p>
<p>Blackberries, were all hard to use and the times taken to use them were rela-
</p>
<p>tively high compared to today&rsquo;s standards. However, they were successful
</p>
<p>because they provided a better experience or supported a task that was not
</p>
<p>supported before. Over time and extended use, other measures and aspects
</p>
<p>became important.
</p>
<p>13.6 The Ethics of Evaluation
</p>
<p>Studies that involve users interacting with technological products now routinely
</p>
<p>need to be vetted to ensure that participants are treated appropriately. This means
</p>
<p>that ethical clearance (or approval) is required from the appropriate authoritative
</p>
<p>body. In most countries this will normally be done by an ethics committee, whilst
</p>
<p>in the US it will be carried out by an institutional review board (IRB). They will
</p>
<p>review the study to determine that the relevant guidelines are being followed. The
</p>
<p>main things they check are whether vulnerable people will be involved, whether
</p>
<p>participants are aware of what they are committing to in the study, and that any
</p>
<p>collected data is stored appropriately. Usually the latter involves anonymizing data
</p>
<p>so that they cannot be linked to the participant. These requirements vary based on
</p>
<p>funding, use, publication, and teaching, so take advice if you have not done this
</p>
<p>before.
</p>
<p>As a matter of routine you should produce information sheets for participants,
</p>
<p>describing the study and explaining that they can withdraw from the study at any
</p>
<p>point. You should also take informed written consent, having them sign a consent
</p>
<p>form that says that they have read and understood the information sheet, that they
</p>
<p>are willing to take part, and that they understand that they can withdraw at any
</p>
<p>point. You should also think about how you will debrief at the end of a testing
</p>
<p>session: you could either give them a debrief sheet, explaining the purpose of the
</p>
<p>study in more detail, or simply verbally debrief them. You may also want to ask
</p>
<p>them not to discuss the study with others, because it could influence their behavior
</p>
<p>if they were subsequently in the study. Further details on this process are available
</p>
<p>(Ritter et al. 2013; Ritter et al. 2009).
</p>
<p>376 13 Methodology III: Empirical Evaluation</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2">http://dx.doi.org/10.1007/978-1-4471-5134-0_2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2">http://dx.doi.org/10.1007/978-1-4471-5134-0_2</a></div>
</div>
<div class="page"><p/>
<p>13.7 Summary
</p>
<p>There is a lot more to evaluation than many people imagine. Carrying out an
</p>
<p>evaluation requires careful thought and planning before you begin testing. In this
</p>
<p>chapter we have highlighted the sorts of issues you need to think about during
</p>
<p>planning. Most development is carried out using an iterative cycle in which a
</p>
<p>formative evaluation is carried out during each cycle. The information that comes
</p>
<p>out of the evaluation can then be used to inform development during the next cycle
</p>
<p>of development. It is therefore important that you clearly understand what sort of
</p>
<p>data you should collect, and why. You also need to think about whom you will
</p>
<p>collect the data from, and the environment in which you will collect them.
</p>
<p>Once you have the basic plan, you can start to think in more detail about how
</p>
<p>you will collect the data (and how you will analyze them, although we have not
</p>
<p>covered that issue here). There are many methods that you could use, and your
</p>
<p>final choice may be determined by factors such as how much time is available,
</p>
<p>what resources are available, and how many (potential) users are accessible to take
</p>
<p>part in the tests. We have briefly discussed several evaluation methods that are
</p>
<p>available, and touched)on the importance of making sure that you are aware of the
</p>
<p>need to treat the participants in your evaluation in a way that is ethical.
</p>
<p>Evaluation is important because it produces feedback on development as it is
</p>
<p>progressing. If you can get real users to take part in your evaluations, their
</p>
<p>feedback will help make sure that the system is more likely to be usable and
</p>
<p>acceptable when it is delivered. In other words, it will reduce the risks that the final
</p>
<p>system will be a failure when it is delivered.
</p>
<p>13.8 Other Resources
</p>
<p>There is a web site devoted to the subject of evaluating adaptive systems: EASy-
</p>
<p>Hub (which stands for Evaluation of Adaptive Systems Hub) is available at http://
</p>
<p>www.easy-hub.org.
</p>
<p>If you are designing a usability laboratory, Jacob Nielsen edited a special issue
</p>
<p>of the BIT journal about how to create and use usability laboratories. Although it is
</p>
<p>now somewhat dated, it still contains several useful nuggets of information:
</p>
<p>Nielsen, J. (Ed.). (1994). Special issue: Usability Laboratories. Behaviour &amp; Information
Technology 13(1&ndash;2).
</p>
<p>If you are not experienced working with studies with human participants, useful
</p>
<p>guides include:
</p>
<p>Ritter, F. E., Kim, J. W., Morgan, J. H., &amp; Carlson, R. A. (2013). Running behavioral
studies with human participants: A practical guide. Thousand Oaks, CA: Sage.
</p>
<p>Shadbolt, N. R., &amp; Burton, A. M. (1995). Knowledge elicitation: A systematic approach.
</p>
<p>13.7 Summary 377</p>
<p/>
<div class="annotation"><a href="http://www.easy-hub.org">http://www.easy-hub.org</a></div>
<div class="annotation"><a href="http://www.easy-hub.org">http://www.easy-hub.org</a></div>
</div>
<div class="page"><p/>
<p>In J. R. Wilson &amp; E. N. Corlett (Eds.), Evaluation of human work: A practical ergonomics
methodology (pp. 406&ndash;440). London: Taylor and Francis.
</p>
<p>Stanton, N.A. &amp; Young, M. (1999). A guide to methodology in ergonomics: Designing for
human use. London, UK: Taylor &amp; Francis.
</p>
<p>One of the best introductions to user focused evaluations is by Elizabeth
</p>
<p>Goodman, Mike Kuniavsky, and Andrea Moed (also recommended in Chap. 2).
</p>
<p>They cover basic techniques and methods that will help you design better inter-
</p>
<p>actions. They also offer case studies and examples that you can compare to your
</p>
<p>own design situations:
</p>
<p>Goodman, E., Kuniavsky, M., &amp; Moed, A. (2012). Observing the user experience: A
practitioner&rsquo;s guide to user research. San Francisco, CA: Morgan Kaufman
</p>
<p>Another highly recommended text is Kim Goodwin&rsquo;s Designing for the Digital
</p>
<p>Age, published in 2011:
</p>
<p>Goodwin, Kim. (2011) Designing for the digital age: How to create human-centered
products and services. Wiley.
</p>
<p>Finally, it is worth reading Gilbert Cockton&rsquo;s &lsquo;&lsquo;Usability Evaluation&rsquo;&rsquo; published
</p>
<p>online by the Interaction Design Foundation.
</p>
<p>http://interaction-design.org/encyclopedia/usability_evaluation.html
</p>
<p>13.9 Exercises
</p>
<p>13.1 Design a usability test for comparing two makes of mobile device (such as a
</p>
<p>smartphone), using at least two of the ways of measuring usability described
</p>
<p>above. You should include details of how many participants you would use,
</p>
<p>and an explanation of why you chose your selected ways of measuring
</p>
<p>usability.
</p>
<p>13.2 Design a study to evaluate the usability of an advanced photocopier/printer,
</p>
<p>using at least two of the ways of measuring usability that were described
</p>
<p>above. You should include details of how many participants you would use,
</p>
<p>and an explanation of why you chose your selected ways of measuring
</p>
<p>usability.
</p>
<p>13.3 Design a usability test for evaluating the web site of an on-line retailer,
</p>
<p>using at least two of the ways of measuring usability that were described
</p>
<p>above. You should include details of how many participants you would use,
</p>
<p>and an explanation of why you chose your selected ways of measuring
</p>
<p>usability.
</p>
<p>13.4 Summarize the evaluations in Exercises 13.1&ndash;13.3, comparing and con-
</p>
<p>trasting how the devices being evaluated influence the number of participants
</p>
<p>and the choice of evaluation methods.
</p>
<p>378 13 Methodology III: Empirical Evaluation</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2">http://dx.doi.org/10.1007/978-1-4471-5134-0_2</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_2">http://dx.doi.org/10.1007/978-1-4471-5134-0_2</a></div>
<div class="annotation"><a href="http://interaction-design.org/encyclopedia/usability_evaluation.html">http://interaction-design.org/encyclopedia/usability_evaluation.html</a></div>
</div>
<div class="page"><p/>
<p>References
</p>
<p>Berg, M. (1997). Rationalizing medical work: Decision support techniques and medical
practices. Cambridge, MA: MIT Press.
</p>
<p>Brooke, J. (1996). SUS: A &lsquo;quick and dirty&rsquo; usability scale. In P. W. Jordan, B. Thomas,
B. A. Weerdmeester, &amp; I. L. McClelland (Eds.), Usability evaluation in industry (pp.
189&ndash;194). London: Taylor &amp; Francis.
</p>
<p>Brown, C. M. L. (1988). Human-computer interface design guidelines. Norwood, NJ: Ablex.
Calfee, R. C. (1985). Experimental methods in psychology. New York, NY: Holt, Rinehart and
</p>
<p>Winston.
Campbell, D. T., &amp; Stanley, J. C. (1963). Experimental and quasi-experimental designs for
</p>
<p>research. Boston, MA: Houghton Mifflin.
Card, S. K., Moran, T., &amp; Newell, A. (1983). The psychology of human-computer interaction.
</p>
<p>Hillsdale, NJ: Erlbaum.
Carroll, J. M. (2000). Making use: Scenario-based design of human-computer interactions.
</p>
<p>Cambridge, MA: MIT Press.
Carroll, J. M., &amp; Rosson, M. B. (1992). Getting around the task-artifact cycle: How to make
</p>
<p>claims and design by scenario. ACM Transactions on Information Systems, 10, 181&ndash;212.
Churchill, E. F., Nelson, L., Denoue, L., Murphy, P., &amp; Helfman, J. I. (2003). The Plasma poster
</p>
<p>network: Social hypermedia on public display. In K. O&rsquo;Hara, M. Perry, E. Churchill, &amp;
D. Russell (Eds.), Social and interactional aspects of shared display technologies. London:
Kluwer Academic Publishers.
</p>
<p>Endsley, M. R. (1995). Toward a theory of situation awareness in dynamic systems. Human
Factors, 37(1), 32&ndash;64.
</p>
<p>Ericsson, K. A., &amp; Simon, H. A. (1980). Protocol analysis: Verbal reports as data. Psychological
Review, 87, 215&ndash;251.
</p>
<p>Ericsson, K. A., &amp; Simon, H. A. (1993). Protocol analysis: Verbal reports as data (2nd ed.).
Cambridge, MA: MIT Press.
</p>
<p>Feurzeig, W., &amp; Ritter, F. (1988). Understanding reflective problem solving. In J. Psotka,
L. D. Massey, &amp; S. A. Mutter (Eds.), Intelligent tutoring systems: Lessons learned. Hillsdale,
NJ: Erlbaum.
</p>
<p>Goodman, E., Kuniavsky, M., &amp; Moed, A. (2012). Observing the user experience: A
practitioner&rsquo;s guide to user research (2nd ed.). Waltham, MA: Morgan Kaufmann.
</p>
<p>Hart, S. G., &amp; Staveland, L. E. (1988). Development of the NASA-TLX (Task Load Index):
Results of empirical and theoretical research. In P. A. Hancock &amp; N. Meshkati (Eds.), Human
mental workload (pp. 139&ndash;185). Amsterdam: North Holland.
</p>
<p>Hock, R. R. (2002). Forty studies that changed psychology. Upper Saddle River, NJ: Prentice
Hall.
</p>
<p>Howell, D. C. (2010). Statistical methods for psychology (7th ed.). Belmont, CA: Wadsworth.
Kukreja, U., Stevenson, W. E., &amp; Ritter, F. E. (2006). RUI&mdash;recording user input from interfaces
</p>
<p>under Windows and Mac OS X. Behavior Research Methods, 38(4), 656&ndash;659.
LaPiere, R. T. (1934). Attitude versus action. Social Forces, 13, 230&ndash;237.
Lazar, J., Feng, J. H., &amp; Hochheiser, H. (2010). Research methods in human-computer
</p>
<p>interaction. New York, NY: Wiley.
Miles, M. B., Huberman, A. M., &amp; Salda&ntilde;a, J. (2013). Qualitative data analysis: A methods
</p>
<p>sourcebook. Thousand Oaks, CA: Sage.
</p>
<p>Molich, R., &amp; Nielsen, J. (1990). Improving a human-computer dialogue. Communications of the
</p>
<p>ACM, 33(3), 338&ndash;348.
</p>
<p>Monk, A., Wright, P., Haber, J., &amp; Davenport, L. (1993). Apendix 1&mdash;cooperative evaluation: A
</p>
<p>run-time guide. In Improving your human-computer interface: A practical technique. New
</p>
<p>York: Prentice-Hall.
</p>
<p>References 379</p>
<p/>
</div>
<div class="page"><p/>
<p>Monk, A. F. (1998). Lightweight techniques to encourage innovative user interface design. In
L. Wood (Ed.), User interface design: Bridging the gap between user requirements and
design (pp. 109&ndash;129). Boca Raton, FL: CRC Press.
</p>
<p>Mosier, J. N., &amp; Smith, S. L. (1986). Application of guidelines for designing user interface
software. Behaviour and Information Technology, 5, 39&ndash;46.
</p>
<p>M&uuml;ller, M. J., Haslwanter, J. H., &amp; Dayton, T. (1997). Participatory practices in the software
lifecycle. In M. G. Helander, T. K. Landauer, &amp; P. V. Prabhu (Eds.), Handbook of human-
computer interaction (2nd ed., pp. 255&ndash;297). Amsterdam, NL: Elsevier.
</p>
<p>NASA. (1987). NASA Task Load Index (TLX) V 1.0. Users Manual. Retrieved 10 March 2014,
from http://humansystems.arc.nasa.gov/groups/TLX/downloads/TLX_comp_manual.pdf.
</p>
<p>Navalpakkam, V., &amp; Churchill, E. F. (in press). Eyetracking: A brief introduction. In J. S. Olson
&amp; W. Kellogg (Eds.), Ways of knowing, HCI methods. Heidelberg, Germany: Springer.
</p>
<p>Nielsen, J. (1993). Usability engineering. Chestnut Hill, MA: AP Professional Press.
Nielsen, J., &amp; Molich, R. (1990). Heuristic evaluation of user interfaces. In Proceedings of CHI
</p>
<p>90 (pp. 249&ndash;256). New York: ACM.
Nielsen, J., &amp; Pernice, K. (2010). Eyetracking web usability. Berkeley, CA: New Riders.
Ray, W. J. (2008). Methods toward a science of behavior and experience (9th ed.). Belmont, CA:
</p>
<p>Wadsworth Publishing.
Reeves, B., &amp; Nass, C. (1996). The media equation: How people treat computers, television, and
</p>
<p>new media like real people and places. New York: NY Cambridge University Press.
Ritter, F. E., Kim, J. W., &amp; Morgan, J. H. (2009). Running behavioral experiments with human
</p>
<p>participants: A practical guide (Tech. Report No. 2009-1). Applied Cognitive Science Lab:
The Pennsylvania State University, College of Information Sciences and Technology.
</p>
<p>Ritter, F. E., Kim, J. W., Morgan, J. H., &amp; Carlson, R. A. (2013). Running behavioral studies with
human participants: A practical guide. Thousand Oaks, CA: Sage.
</p>
<p>Smallman, H. S., &amp; St. John, M. (2005). Na&iuml;ve realism: Misplaced faith in the utility of realistic
displays. Ergonomics in Design, 13(Summer), 6&ndash;13.
</p>
<p>Todd, Z. (Ed.). (2004). Mixing methods in psychology: The integration of qualitative and
quantitative methods in theory and practice. Abingdon, UK: Psychology Press.
</p>
<p>Tullis, T., &amp; Albert, B. (2008). Measuring the user experience. Burlington, MA: Morgan
Kaufmann.
</p>
<p>Whiteside, J., Jones, S., Levy, P. S., &amp; Wixon, D. (1985). User performance with command,
menu, and iconic interfaces. In Proceedings of CHI&rsquo;85 Human Factors in Computing Systems
(185&ndash;191). New York: ACM.
</p>
<p>Woods, D. D., &amp; Dekker, S. W. A. (2000). Anticipating the effects of technological change: A
new era of dynamics for human factors. Theoretical Issues in Ergonomic Science, 1(3),
272&ndash;282.
</p>
<p>380 13 Methodology III: Empirical Evaluation</p>
<p/>
<div class="annotation"><a href="http://humansystems.arc.nasa.gov/groups/TLX/downloads/TLX_comp_manual.pdf">http://humansystems.arc.nasa.gov/groups/TLX/downloads/TLX_comp_manual.pdf</a></div>
</div>
<div class="page"><p/>
<p>Part IV
</p>
<p>Summary</p>
<p/>
</div>
<div class="page"><p/>
<p>Chapter 14
</p>
<p>Summary: Putting It All Together
</p>
<p>Abstract This chapter recaps some of the many things that you have learned about
</p>
<p>users in terms of their anthropometric, behavioral, cognitive, and social aspects.
</p>
<p>You have been provided with a lot of information, so we describe a number of
</p>
<p>different possible ways you can organize it. One way to organize and apply the
</p>
<p>information is with user models. These models span the range from implicit
</p>
<p>descriptive models, such as guidelines, through to explicit information processing
</p>
<p>models, which can be executed to produce behavior and predict performance.
</p>
<p>Another way is to organize the information based on how to use it. So we finish by
</p>
<p>looking at one system development process model&mdash;the Risk-Driven Incremental
</p>
<p>Commitment Model&mdash;as an example of how you can integrate knowledge about
</p>
<p>users into the system development life cycle. Failure to consider the users and their
</p>
<p>tasks during development leads to increased system development risk.
</p>
<p>14.1 Introduction
</p>
<p>Human centered-design is about putting humans at the center of system design. If
</p>
<p>we want to design systems that are both useful and usable, we need to understand
</p>
<p>humans&mdash;users, in particular&mdash;and this is not a trivial undertaking. If we do not
</p>
<p>take appropriate account of the users there is an increased risk that the project will
</p>
<p>be a failure: the users could refuse to accept the system if it does not fit into and
</p>
<p>support the way they work, or the users may end up wrestling with the system
</p>
<p>trying to make it behave as they expect it to, possibly with fatal consequences
</p>
<p>(e.g., Baxter et al. 2007), or it could just not be fully adopted by users.
</p>
<p>Developing systems is an inherently interdisciplinary practice. The knowledge
</p>
<p>that we have presented here should make software and system engineers at least
</p>
<p>aware of the sorts of issues that human factors engineers routinely discuss. In this
</p>
<p>book we have tried to highlight the capabilities and limitations of humans but,
</p>
<p>really, we have just scratched the surface. We are not expecting software engineers
</p>
<p>to become human factors experts as a result of reading this book. We hope,
</p>
<p>F. E. Ritter et al., Foundations for Designing User-Centered Systems,
DOI: 10.1007/978-1-4471-5134-0_14, ï¿½ Springer-Verlag London 2014
</p>
<p>383</p>
<p/>
</div>
<div class="page"><p/>
<p>however, that it will enable them to communicate with human factors engineers,
</p>
<p>and develop a shared understanding of the issues as they affect system develop-
</p>
<p>ment and use.
</p>
<p>We conclude our discussions with a brief summary of what we have presented
</p>
<p>in this book. You will want to organize it yourself in some meaningful way to be
</p>
<p>able to make effective use of all the information about users that we have pre-
</p>
<p>sented. How you decide to organize it will partly depend on how you intend to use
</p>
<p>it. You might find the metaphors in Chap. 12, those of the Gulfs and Cognitive
</p>
<p>Dimensions, to be useful. There are also methods and techniques that can help you.
</p>
<p>A few of these have been implemented as computer programs that are fairly easy
</p>
<p>to use, and encapsulate summaries of user behavior that can be applied in a range
</p>
<p>of ways. These models are just one way of applying what we know about humans
</p>
<p>to system design; they can also be used to help teach designers and developers
</p>
<p>about users as a sharable representation.
</p>
<p>We finish by describing howyou can take forwardwhat you have learned here and
</p>
<p>incorporate it into system development. We would contend that you should always
</p>
<p>apply this knowledge, because a lack of knowledge about users nearly always con-
</p>
<p>stitutes a risk to system development. We illustrate this argument using an extended
</p>
<p>version of the Risk-Driven Incremental Commitment Model (Pew andMavor2007).
</p>
<p>14.2 Organizing What We Have Learnt About Users
</p>
<p>If your aim is to build systems that are both useful and usable then the best way
</p>
<p>forward in many cases is to focus on particular people doing particular tasks in
</p>
<p>particular contexts. The knowledge that we have provided you will help. Whether
</p>
<p>a system can be described as usable or not depends on factors such as the shape
</p>
<p>and size of the users (anthropometric factors), external body functioning and
</p>
<p>simple sensory-motor concerns and motivation (behavioral factors), internal
</p>
<p>mental functioning (cognitive factors), and external mental functioning (social and
</p>
<p>organizational factors). It therefore makes sense to consider organizing your
</p>
<p>knowledge about these different factors in terms of the types of user characteristics
</p>
<p>that we introduced early in the book: Anthropometric; Behavioral; Cognitive; and
</p>
<p>Social&mdash;the ABCS. You should be aware that there are other factors too, which we
</p>
<p>have not addressed in this summary such as legal liability, and physiological
</p>
<p>factors which will often also be important.
</p>
<p>14.2.1 Anthropometrics
</p>
<p>Users vary. One obvious way they can vary is in physical size, as Chap. 3 noted.
</p>
<p>Different people of the same age and gender may have different heights and
</p>
<p>different weights, for example. Users also change over time as they develop and
</p>
<p>384 14 Summary: Putting It All Together</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12">http://dx.doi.org/10.1007/978-1-4471-5134-0_12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_12">http://dx.doi.org/10.1007/978-1-4471-5134-0_12</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3">http://dx.doi.org/10.1007/978-1-4471-5134-0_3</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_3">http://dx.doi.org/10.1007/978-1-4471-5134-0_3</a></div>
</div>
<div class="page"><p/>
<p>age. The physical attributes of the user will affect how they use a particular
</p>
<p>artifact, so you need to consider aspects such as whether they can reach the
</p>
<p>controls, whether they can operate the levers, whether they can push buttons, and
</p>
<p>so on.
</p>
<p>The way that people use artifacts can also affect the well-being of the user.
</p>
<p>Upper limb disorders, for example, can arise from having to carry out the same
</p>
<p>task repeatedly over extended periods of time, and from the user failing to adopt
</p>
<p>the correct posture.
</p>
<p>Anthropometrics is an important consideration in interfaces where touch) plays
</p>
<p>a central role. Probably the most obvious and widespread examples are smart-
</p>
<p>phones and tablet computers. In addition, it is important when thinking about
</p>
<p>keyboards: conventional keyboards are still widely used with most personal
</p>
<p>computers, and many people use their thumbs to type on the keypads of some cell
</p>
<p>phones, for example.
</p>
<p>14.2.2 Behavior
</p>
<p>The user&rsquo;s behavioral characteristics are mostly related to perception, and the most
</p>
<p>important of these are vision and audition, as noted in Chap. 4. Users will also
</p>
<p>differ in terms of their perceptual capabilities. As people get older, for example,
</p>
<p>their vision and hearing often diminish and there are people who have permanently
</p>
<p>impaired vision or hearing.
</p>
<p>When you are designing systems it is therefore important to realize that all users
</p>
<p>will not always behave in exactly the same way. Their performance will vary
</p>
<p>across a range of behavior which is approximately normally distributed, as shown
</p>
<p>on the left in Fig. 14.1. In those situations where the distribution cannot be two
</p>
<p>tailed, such as where reaction times (which cannot be negative!) are being mea-
</p>
<p>sured, performance more closely approximates a gamma distribution, as shown on
</p>
<p>the right in Fig. 14.1.
</p>
<p>Understanding the way that people perceive things is important, because this
</p>
<p>understanding can be used to create artifacts that more closely match the way that
</p>
<p>users behave. Knowing about red&ndash;green color deficiency, for example, is impor-
</p>
<p>tant because it will influence the way that colored items are used in an interface. At
</p>
<p>a higher level, knowing the Gestalt laws that describe the way people perceive
</p>
<p>groups of objects (Chap. 4) can be used to help you work out the layout of objects
</p>
<p>in an interface.
</p>
<p>When it comes to designing audio outputs, knowing the way that hearing works
</p>
<p>can help you determine what sort of sounds to use for alarms, for example. We
</p>
<p>also know that people are poor at localizing sound, but it is easier to localize high
</p>
<p>pitch sounds than low pitch ones, and that speech conveys more information than
</p>
<p>sounds.
</p>
<p>All users, from novices to experts, make errors and in some cases make the
</p>
<p>same errors as noted in Chap. 10. One of the main differences between novices and
</p>
<p>14.2 Organizing What We Have Learnt About Users 385</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4">http://dx.doi.org/10.1007/978-1-4471-5134-0_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4">http://dx.doi.org/10.1007/978-1-4471-5134-0_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4">http://dx.doi.org/10.1007/978-1-4471-5134-0_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_4">http://dx.doi.org/10.1007/978-1-4471-5134-0_4</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10">http://dx.doi.org/10.1007/978-1-4471-5134-0_10</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_10">http://dx.doi.org/10.1007/978-1-4471-5134-0_10</a></div>
</div>
<div class="page"><p/>
<p>experts is that expert users can often (but not always) detect and correct errors
</p>
<p>before any adverse consequences arise. When you design systems, you need to
</p>
<p>remember that all users will make errors. Some of these errors will be preventable,
</p>
<p>but others may not. You will therefore need to decide which errors you will
</p>
<p>prevent (using risk assessment, for example). For the other errors, you will need to
</p>
<p>include support to help the user spot errors and, in particular, to support the ability
</p>
<p>to correct errors, ideally before any adverse consequences arise.
</p>
<p>Where the users have physical limitations, however, or there are contextual
</p>
<p>limitations (low lightinglevels, for example), these limitations will constrain what
</p>
<p>the users can and cannot do.
</p>
<p>14.2.3 Cognition
</p>
<p>Users&rsquo; cognition is limited, at both the tactical level (e.g., limited working
</p>
<p>memoryand some difficulties in storing and retrieving items from memory) and at
</p>
<p>the strategic level (e.g., how to decide which are the important and long term
</p>
<p>issues), as noted in Chaps. 5&ndash;7. In some cases, the effects of these limitations can
</p>
<p>be ameliorated through learning, or through social processes, particularly where
</p>
<p>skills are pooled to perform particular tasks.
</p>
<p>Attracting, managing, and maintaining the user&rsquo;s attention are all important.
</p>
<p>Users have limited attentional resources. This means that in busy contexts, where
</p>
<p>lots of things are happening or several tasks have to be performed simultaneously,
</p>
<p>they are unlikely to be able to attend to all of them. In other words, they will find it
</p>
<p>difficult to consciously control how they perform all the tasks. With practice, users
</p>
<p>can learn to perform some tasks with little or no conscious control (i.e., with little
</p>
<p>Time to Push a Button
</p>
<p>D
is
</p>
<p>tr
ib
</p>
<p>u
ti
o
</p>
<p>n
 o
</p>
<p>f 
R
</p>
<p>e
a
</p>
<p>c
ti
o
</p>
<p>n
 T
</p>
<p>im
e
</p>
<p>s
 
</p>
<p>D
is
</p>
<p>tr
ib
</p>
<p>u
ti
o
</p>
<p>n
 o
</p>
<p>f 
P
</p>
<p>ro
b
</p>
<p>le
m
</p>
<p>s
 A
</p>
<p>tt
e
</p>
<p>m
p
</p>
<p>te
d
 
</p>
<p>Number of Problems Attempted
</p>
<p>Fig. 14.1 A normal curve (left) [Strictly speaking, number of problems cannot go below 0 either,
but for most practical examples, this distribution will be well represented by a normal curve when
0 is more than three standard deviations from the mean (the peak).] and a gamma curve (right)
showing typical distributions for tasks attempted and response times for a task. These curves
illustrate that users will have a distribution of behavior, and not always perform a task or have
knowledge in a single way
</p>
<p>386 14 Summary: Putting It All Together</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5">http://dx.doi.org/10.1007/978-1-4471-5134-0_5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_5">http://dx.doi.org/10.1007/978-1-4471-5134-0_5</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7">http://dx.doi.org/10.1007/978-1-4471-5134-0_7</a></div>
</div>
<div class="page"><p/>
<p>or no attention). The classic example that is usually quoted is that of riding a bike:
</p>
<p>when you first start out, you try to think of lots of things at once&mdash;keeping your
</p>
<p>balance, remembering to pedal, keeping the handlebars straight, being aware of the
</p>
<p>traffic around you, and so on&mdash;but as you learn how to do the task, you will focus
</p>
<p>more on just keeping the bike going in a straight line, and maintaining awareness
</p>
<p>of the traffic around you. We know that people learn in various ways, so you
</p>
<p>should design your system in such a way that it facilitates learning.
</p>
<p>It is important to know your users, and to understand the language that they use.
</p>
<p>By doing so, you will be able to develop systems that they can more readily
</p>
<p>understand and use. The interaction between the user and their computer-based
</p>
<p>system can be considered as a form of conversation, which means that it can be
</p>
<p>optimized using Grice&rsquo;s maxims (Chap. 7). It is particularly important to know
</p>
<p>something about how people read and the ways that they seek out information
</p>
<p>(mostly through searching), because these are two of the most common user
</p>
<p>activities. You should design systems that present information in ways that the
</p>
<p>users can easily read, understand, and find. This means that you need to think
</p>
<p>about presentation (font choices, for example) as well as content issues.
</p>
<p>Users have mental models of how things work, and the way they interact with
</p>
<p>an artifact is usually based on the (most) relevant mental model. These models
</p>
<p>develop over time as the user&rsquo;s knowledge and experience of using the artifact
</p>
<p>increases. As a system designer you should try to help the user to develop the right
</p>
<p>model of how your system operates. The mental model will help the users decide
</p>
<p>which action to take next. When they cannot see which action to perform, they will
</p>
<p>normally engage in problem solving behavior, which may involve reasoning from
</p>
<p>first principles, using trial and error, for example. On the basis of their problem
</p>
<p>solving, users will then make decisions. Decision making is usually sub-optimal
</p>
<p>because people do not take into account all of the relevant information that is
</p>
<p>available to them, and because their decision making processes are often biased in
</p>
<p>known ways. As a designer you can try to help users by making relevant infor-
</p>
<p>mation salient and by counteracting the known biases where possible.
</p>
<p>The use of mental models also applies to users themselves. Across the range of
</p>
<p>behavior types, there are very few aspects of their behavior that users know about
</p>
<p>intrinsically. They can see their size, and this they know something about. Yet
</p>
<p>when it comes to choosing a chair, they have to sit in it to know if it fits. Many
</p>
<p>users do not sit in the best posture, and so we might note that many users do not
</p>
<p>know all that they could about themselves anthropometrically.
</p>
<p>Many users do not know about their fovea, and most other aspects of perception
</p>
<p>are not available to consciousness&mdash;it is impenetrable. The results of vision are
</p>
<p>available when objects are attended to, but the parts that are not attended to are
</p>
<p>ignored or filled in. For example, most users will not know much about the blind
</p>
<p>spot on their retina, let alone see it. Most of perception is impenetrable. So, what
</p>
<p>they know about perception is mostly folk psychology.
</p>
<p>Users (and untrained designers) think they know how they think. This is often
</p>
<p>misguided. While they are thinking about how they think, they are busy thinking.
</p>
<p>Imagine creating a computer that stored every action it took&mdash;but how can it do
</p>
<p>14.2 Organizing What We Have Learnt About Users 387</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7">http://dx.doi.org/10.1007/978-1-4471-5134-0_7</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_7">http://dx.doi.org/10.1007/978-1-4471-5134-0_7</a></div>
</div>
<div class="page"><p/>
<p>this? It would have to record actions while it was doing them. Users are basically
</p>
<p>like this as well. It is very hard to remember what you are doing when you are busy
</p>
<p>doing it. Ericsson and Simon (1993) laid out a fairly good theory of when users can
</p>
<p>talk aloud about what they are doing. It is even more difficult to talk about what
</p>
<p>you have done and be completely accurate. That said, sometimes the only data we
</p>
<p>can afford to gather is how users think they think, and sometimes users will choose
</p>
<p>systems based on such judgments, so we will often have to work with these
</p>
<p>judgements. You might wish to be more skeptical in the future about users&rsquo; (and
</p>
<p>untrained designers&rsquo;) reports about how they do a task or whether they learn or not.
</p>
<p>14.2.4 Social
</p>
<p>Most tasks are carried out by teams of people interacting with one another.
</p>
<p>Sometimes they will be working directly with co-located people, but in other cases
</p>
<p>they may be working distally as a team. Individual users have limitations on how
</p>
<p>well they work together in teams: some people are natural leaders, whilst some are
</p>
<p>natural followers.
</p>
<p>Chapters 8 and 9 note social factors that influence users, including distributed
</p>
<p>responsibility, and social influence on teams. For example, users (and system
</p>
<p>developers) will often misjudge social relationships. They will often send out one
</p>
<p>blanket email to ten people asking for one of them to volunteer, rather than
</p>
<p>sending out ten individual emails. The sorts of variations in performance that you
</p>
<p>see across users can sometimes be attributed to the context they are working in, as
</p>
<p>well as their own capabilities and limitations. If you put the same user in the same
</p>
<p>task and physical situation but vary the environmental conditions by increasing the
</p>
<p>temperature, or reducing the lightinglevels, for example, this may affect their
</p>
<p>performance.
</p>
<p>14.2.5 The Role of Tasks and Environments
</p>
<p>Knowing users&rsquo; tasks will help design systems to perform these tasks in numerous
</p>
<p>ways as presented in Chap. 11. There are a wide range of uses and applications,
</p>
<p>and of ways to represent users&rsquo; tasks and activities. Good designers can choose
</p>
<p>appropriately based on what is needed for a given design project.
</p>
<p>Users&rsquo; tasks are not always directly understandable by designers using their
</p>
<p>own intuitions, but there are ways to find what tasks users do and what tasks they
</p>
<p>want to do. However, there will still be surprises because it is difficult to know
</p>
<p>everything, particularly for new tasks and unexpected uses.
</p>
<p>It is also important to understand the environment in which users perform their
</p>
<p>tasks. Usability studies help to provide a way to understand the tasks, the users, the
</p>
<p>environments, and how they interact.
</p>
<p>388 14 Summary: Putting It All Together</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8">http://dx.doi.org/10.1007/978-1-4471-5134-0_8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_8">http://dx.doi.org/10.1007/978-1-4471-5134-0_8</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_9">http://dx.doi.org/10.1007/978-1-4471-5134-0_9</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11">http://dx.doi.org/10.1007/978-1-4471-5134-0_11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11">http://dx.doi.org/10.1007/978-1-4471-5134-0_11</a></div>
</div>
<div class="page"><p/>
<p>14.2.6 Summary
</p>
<p>Users can be viewed as having some aspects that are more uniform and some that
</p>
<p>are more unique. There are some communalities across levels that we can point
</p>
<p>out:
</p>
<p>1. The ABCS note some of these aspects where users have shared communalities
</p>
<p>in how they think, interact with the world, and interact with each other; in some
</p>
<p>ways users are alike. So, when designing systems, you should not despair that
</p>
<p>all users are different.
</p>
<p>2. There are also differences between users. There are simple differences in simple
</p>
<p>capabilities, such as different input and output speeds and capabilities. In more
</p>
<p>complex capabilities, like how to do a task and mental models of systems, users
</p>
<p>can vary widely based on previous experience and practice. In cases of goals
</p>
<p>and cultural beliefs they can vary the most. So, when designing, you need to
</p>
<p>keep in mind that, for some aspects of design, users can differ.
</p>
<p>3. Users have limited capabilities. Across the chapters, limitations on how fast
</p>
<p>users can move, how fast and how they can think, and their abilities to produce
</p>
<p>perfect, error-free performance were noted. Most importantly, user limitations
</p>
<p>can be avoided by better design that does not make incorrect assumptions about
</p>
<p>users. Many of the bad web site design contests and bad and dangerous
</p>
<p>interface galleries are filled with designs that assumed something incorrect
</p>
<p>about the users&rsquo; abilities or interests. So, when designing, you need to design
</p>
<p>for what people can do.
</p>
<p>4. Users do not always know themselves. You can ask them, but they will
</p>
<p>sometimes not provide very accurate descriptions. Designers are also a type of
</p>
<p>user, and they suffer the same limitations about knowing users and themselves.
</p>
<p>So, when designing, do ask them but also think more broadly about users and
</p>
<p>their context. In addition, try to study the user as a domain. Have a theory of
</p>
<p>how they perform tasks, test this theory with data, and expand the theory as you
</p>
<p>learn and read more.
</p>
<p>5. Systems can be helped in a variety of ways because of users. Users can learn,
</p>
<p>can then find new strategies, and can help each other. So, when you design,
</p>
<p>keep these less obvious changes in mind.
</p>
<p>14.3 Models of Users
</p>
<p>For the purpose of engineering design, it would be useful to model the human part
</p>
<p>of the overall system in a more formalized way, in the same way that engineering
</p>
<p>design specifications can be used to present a relatively clear and precise model for
</p>
<p>implementation. The model of the user would serve as a shared representation that
</p>
<p>could be used to support system design. From the human factors engineer&rsquo;s point
</p>
<p>14.2 Organizing What We Have Learnt About Users 389</p>
<p/>
</div>
<div class="page"><p/>
<p>of view, a user model captures the capabilities and limitations on user perfor-
</p>
<p>mance; from the software engineer&rsquo;s point of view, it would be used to illustrate
</p>
<p>how the system could perform when operated by real users.
</p>
<p>Models of users therefore serve as a summary repository of our knowledge of
</p>
<p>users. It is important that this knowledge be captured in one place because it can
</p>
<p>lead to emergent behaviors where there are interactions between the different
</p>
<p>characteristics of users. The behavior of the models should be constrained in the
</p>
<p>same sorts of ways that human behavior is constrained (memory limitations, and
</p>
<p>so on).
</p>
<p>We have seen throughout this book that humans are less predictable, consistent,
</p>
<p>and deterministic than computers. Defining a general, formal model of the human
</p>
<p>(as part of the broader socio-technical system) is not currently possible. Instead, a
</p>
<p>number of fragmentary and incomplete models of human information processing
</p>
<p>behavior have been proposed by cognitive psychologists and reinforced by
</p>
<p>empirical exploration. These models can be used to make predictions but do not
</p>
<p>provide details about how the system should be designed. Although the models are
</p>
<p>good at generating first-order effects, at lower levels of analysis their limitations
</p>
<p>and inconsistencies become apparent. The models are therefore useful at pre-
</p>
<p>dicting gross behavior, such as error-free, expert behavior on unit tasks.
</p>
<p>The most accurate, detailed models have generally been developed for those
</p>
<p>aspects of human performance that are easiest to test. Thus, models of the char-
</p>
<p>acteristics of the senses are well established (particularly vision and hearing),
</p>
<p>whereas there are very few models of some of the more intricate aspects of
</p>
<p>cognition that can only be indirectly observed and are less well understood.
</p>
<p>14.3.1 Unified Theories of Cognition
</p>
<p>There have been several attempts to integrate all that we know about human
</p>
<p>behavior into a single, unified theory of cognition (Newell 1990). The latest
</p>
<p>attempts have been realized as cognitive architectures, although they might be
</p>
<p>more properly described as human performance architectures because they deal
</p>
<p>with more than just the cognitive aspects of human performance. These cognitive
</p>
<p>architectures typically take the form of a computer programming language with
</p>
<p>special capabilities and limitations representing a (small) subset of the known
</p>
<p>capabilities and limitations of humans. Progress has been relatively slow, but the
</p>
<p>cognitive architecture developers are working towards providing a single coherent
</p>
<p>theory that ultimately accounts for&mdash;and predicts&mdash;human performance on all
</p>
<p>tasks.
</p>
<p>A unified theory of cognition effectively forms a single repository of useful
</p>
<p>user-related information. This can be used in three main ways:
</p>
<p>1. To help you remember theories and facts about users. You can use the schematic
</p>
<p>of the Model Human Processor (MHP, described below), ACT-R (also described
</p>
<p>390 14 Summary: Putting It All Together</p>
<p/>
</div>
<div class="page"><p/>
<p>below), or Soar (Laird 2012), for example, to work your way through their
</p>
<p>hypothesized modules to understand how behavior will be generated. At this
</p>
<p>level of abstraction, there is a fair amount of agreement between the theories in
</p>
<p>that they all include modules for input, memory, cognition, and output.
</p>
<p>2. To summarize user behavior. In time, architectures may be used more often
</p>
<p>during design as a way to conveniently capture theories of user behavior, and as
</p>
<p>a teaching aid to help designers understand users (Pew and Mavor 2007).
</p>
<p>3. To apply what we know about users. In some cases, the models only offer fairly
</p>
<p>crude approximations of users, but they have been useful for populating computer
</p>
<p>games and military simulations. In other cases, they are being used to test inter-
</p>
<p>faces and make predictions for designs (for a review, see any of these reports:
</p>
<p>Booher and Minninger 2003; Pew and Mavor 1998, 2007; Ritter et al. 2003).
</p>
<p>14.3.2 Types of User Models
</p>
<p>There are now more than 100 cognitive (and user) architectures if you include
</p>
<p>variants and different versions (Morrison 2003; Pew and Mavor1998; Ritter et al.
</p>
<p>2003). They can be categorized into four types:
</p>
<p>1. Implicit descriptive models. When you look at a car, for example, you can
</p>
<p>imagine some of the assumptions the designers have made about the driver.
</p>
<p>These assumptions are captured in an implicit model of the driver in which
</p>
<p>vision takes place in the top part of the body, and another part of the body
</p>
<p>operates the controls on the floor.
</p>
<p>2. Explicit declarative models. These models describe the components or a
</p>
<p>structure in a system, but neither describe the mechanisms nor perform the task.
</p>
<p>3. Explicit process models. The mechanisms and the way they operate are
</p>
<p>described, but the models, while perhaps supported by software, do not process
</p>
<p>information.
</p>
<p>4. Explicit information processing models. These models include a full informa-
</p>
<p>tion processing architecture that produces behavior, and can predict perfor-
</p>
<p>mance times and the information processing steps that will be performed and
</p>
<p>their results.
</p>
<p>14.3.2.1 Implicit Descriptive Models
</p>
<p>Implicit user models appear in many systems, and some people would claim that
</p>
<p>all systems include a model of the user. For example, chairs assume a height of the
</p>
<p>user, and many file systems assume users can read and write English. Taken
</p>
<p>together, the set of assumptions used by the designer to create an artifact is an
</p>
<p>implicit model of the user, but it may be a particularly impoverished, incomplete,
</p>
<p>or incorrect model. There are certainly several tools and approaches that include
</p>
<p>14.3 Models of Users 391</p>
<p/>
</div>
<div class="page"><p/>
<p>models of users where the model is clear enough to talk about, but is not explicitly
</p>
<p>represented and may not be visible (or even known) to most people. Guidelines
</p>
<p>and web accessibility tools, for example, show that models can be useful even
</p>
<p>when they are not explicit, examinable, or even very modifiable.
</p>
<p>Guidelines attempt to describe how to build a system to support users. The
</p>
<p>guidelines reflect an implicit model of the user (which may be more explicitly
</p>
<p>specified by the guideline developers). Guidelines that give advice about visual
</p>
<p>layout, for example, may assume that the users have normal (20/20) vision which,
</p>
<p>clearly, all users do not.
</p>
<p>It would be difficult for designers to use these models and to manually apply
</p>
<p>tests against the guidelines. Where the guidelines have been encapsulated in
</p>
<p>software tools they are relatively easy to apply. Some of these tools only indicate
</p>
<p>compliance (or otherwise) with the guidelines, however, and do not explain why
</p>
<p>particular features are undesirable.
</p>
<p>Where guidelines are implemented in software, for example, to test the
</p>
<p>accessibility of a web site, an implicit user model is employed to evaluate the
</p>
<p>interface against those guidelines. Tools like Bobby and Truwex (search online or
</p>
<p>see the book&rsquo;s web site), for example, assess the accessibility of web sites against
</p>
<p>the Web Content Accessibility Guidelines (WCAG, www.w3.org/WAI/intro/
</p>
<p>wcag.php). For a more extensive discussion of automated tools for evaluating
</p>
<p>interfaces see Ivory and Hearst&rsquo;s (2001) review that divides the tools into various
</p>
<p>categories and assesses their potential impact.
</p>
<p>14.3.2.2 Explicit Descriptive Models
</p>
<p>Explicit descriptive models describe the process and mechanisms that make up
</p>
<p>user behavior. These models include task analysis. Examples include models built
</p>
<p>with the KLM and with GOMS (Chap. 11) because they simply describe the
</p>
<p>behavior (a trace of the behavior) without describing in detail the inner workings
</p>
<p>of how the behavior is implemented in cognitive and other mechanisms.
</p>
<p>These models can be very useful in system development. Examples of tools to
</p>
<p>help create such models include Interacting Cognitive Subsystems (ICS, Barnard
</p>
<p>1987) and the Improved Performance Research Integration Tool (IMPRINT,
</p>
<p>Booher and Minninger 2003). IMPRINT has probably had the largest impact. It
</p>
<p>describes the tasks that users have to perform and how long each task should take.
</p>
<p>The resulting model is then used to predict how performance is degraded by
</p>
<p>fatigue and how many users are required to perform the set of tasks.
</p>
<p>There are also tools that try to replicate the time course of the interaction,
</p>
<p>sometimes interacting with a simulation of the external world. The GOMS Lan-
</p>
<p>guage Evaluation and Analysis tool (GLEAN), for example, encapsulates the
</p>
<p>GOMS task analysis methodology (Kieras 1999; Kieras et al. 1995) in a way that
</p>
<p>makes it easier to use and apply GOMS models. This approach really sits halfway
</p>
<p>between descriptive models and process models that perform the task by pro-
</p>
<p>cessing information.
</p>
<p>392 14 Summary: Putting It All Together</p>
<p/>
<div class="annotation"><a href="http://www.w3.org/WAI/intro/wcag.php">http://www.w3.org/WAI/intro/wcag.php</a></div>
<div class="annotation"><a href="http://www.w3.org/WAI/intro/wcag.php">http://www.w3.org/WAI/intro/wcag.php</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11">http://dx.doi.org/10.1007/978-1-4471-5134-0_11</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11">http://dx.doi.org/10.1007/978-1-4471-5134-0_11</a></div>
</div>
<div class="page"><p/>
<p>14.3.2.3 Explicit Process Models: Model Human Processor
</p>
<p>Card et al. (1980, 1983) believed applying information processing psychology
</p>
<p>should be based on task analysis, calculation, and approximation. Their Model
</p>
<p>Human Processor (MHP) offers an early, simple, integrated description of psy-
</p>
<p>chological knowledge about error-free human performance relevant to HCI and
</p>
<p>system design. It was one of the first attempts to get away from the proliferation
</p>
<p>of descriptions developed to account for different psychological observations, and
</p>
<p>to provide a unified description of users. It started to create a quantitative
</p>
<p>methodology including average times. The MHP was an oversimplification, but it
</p>
<p>did provide a kind of prototype model that could be used as the basis for
</p>
<p>discussions.
</p>
<p>The MHP was made up of a set of memories and processors, together with a
</p>
<p>set of principles, including the &lsquo;&lsquo;principles of operation,&rsquo;&rsquo; which describe how the
</p>
<p>components functioned together. There were three interacting subsystems: the
</p>
<p>perceptual system, the motor system, and the cognitive system, each of which
</p>
<p>had their own memories and processors. These are shown schematically
</p>
<p>in Fig. 14.2. A detailed description of how the MHP would perform a task
</p>
<p>is achieved using either a KLM analysis or a GOMS analysis, described in
</p>
<p>Chap. 11. Examples of MHP analyses are shown in Table 14.1, and two more are
</p>
<p>on the book&rsquo;s web site.
</p>
<p>Long term memory essentially does not decay (d = ?) and has infinite
</p>
<p>capacity (l = ?). Working memory has a visual store and an auditory store.
</p>
<p>Memories in both stores decay, but at different rates, and the sizes are different.
</p>
<p>Working memory outside the stores has a capacity limitation. The perceptual
</p>
<p>processor consists of sensors and associated buffer memories, the most important
</p>
<p>being a Visual Image Store, and an Auditory Image Store to hold the output of
</p>
<p>the sensory system while it is being symbolically coded. The cognitive pro-
</p>
<p>cessor receives symbolically coded information from the sensory image store
</p>
<p>into its working memory, and uses information previously stored in long-term
</p>
<p>memory to decide how to respond. The motor processor carries out the selected
</p>
<p>response.
</p>
<p>Time predictions are generated by analyzing a task into the constituent oper-
</p>
<p>ations that are executed by the subsystems. Then average times are associated with
</p>
<p>these operations based on the selected band of performance: Fastman, Slowman,
</p>
<p>and Middleman, which allows predictions to be made along the central and
</p>
<p>extreme points of the behavioral continuum of fast to slow users.
</p>
<p>The MHP assumes highly idealized behavior (e.g., a single strategy to solve a
</p>
<p>task), and has trouble representing errors. The latter is important. Errors in text
</p>
<p>editing, for example, have been shown to account for 35% of expert performance
</p>
<p>time and 80% of the variability in that time (Landauer 1987, p. 151). Although the
</p>
<p>representations of the perceptual, cognitive, and motor subsystems were weak, the
</p>
<p>MHP did demonstrate the feasibility of the general idea and inspired later work on
</p>
<p>information processing cognitive architectures realized as computer programs,
</p>
<p>such as Soar (Newell 1990) and ACT-R (Anderson 2007).
</p>
<p>14.3 Models of Users 393</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_11">http://dx.doi.org/10.1007/978-1-4471-5134-0_11</a></div>
</div>
<div class="page"><p/>
<p>14.3.2.4 Explicit Information Processing Models: ACT-R
</p>
<p>There is now a range of cognitive architectures that take as input a descriptive task
</p>
<p>analysis that looks a lot like a computer program, and then simulate the cognitive
</p>
<p>aspects of task performance, often with limitations simulated from vision and
</p>
<p>motor performance. One of the most widely used architectures is ACT-R; others
</p>
<p>include EPIC (Kieras et al. 1997) and Soar (Laird 2012; Ritter 2003; Ritter and
</p>
<p>Bibby 2008).
</p>
<p>Fig. 14.2 A diagram of the model human processor (adapted from Card et al. 1983). d indicates a
half-life decay rate; l is a capacity; j is the modality of the storage; s is the time to do something
</p>
<p>394 14 Summary: Putting It All Together</p>
<p/>
</div>
<div class="page"><p/>
<p>ACT-R has been continually evolved and updated&mdash;the latest version is
</p>
<p>available at act.psy.cmu.edu. The structure of the latest version of ACT-R (see
</p>
<p>Fig. 14.3) is somewhat similar to that of the MHP. The figure shows the modules
</p>
<p>and mechanisms of cognition. It also attempts to show a mapping between the
</p>
<p>mechanisms and the areas of the brain responsible for creating the behavior. This
</p>
<p>correspondence is not perfect yet (Anderson 2007), but as technology advances
</p>
<p>(brain scanning in particular) and becomes more sophisticated, it is becoming
</p>
<p>more and more feasible to do this mapping.
</p>
<p>ACT-R has been fairly extensively tested against psychology data to validate its
</p>
<p>predictions. Like all information processing models, it has mostly been used in
</p>
<p>thought experiments and as a research tool. ACT-R in particular, though, has been
</p>
<p>used to create a large number of user models for several different domains
</p>
<p>including driving (Salvucci 2006), human-robot interaction (Ritter et al. 2006,
</p>
<p>2007), aviation (Byrne and Kirlik 2005; Gluck et al. 2007), air traffic control and
</p>
<p>dual tasking (Schoelles and Gray 2001), and menu use (Byrne 2001). These
</p>
<p>models are harder to create than GOMS or KLM models, but they make more
</p>
<p>detailed predictions, including what information is required to perform the task,
</p>
<p>and the results of the information processing. If an addition is performed by users,
</p>
<p>for example, ACT-R can be used to predict their answers and the distribution of
</p>
<p>errors in their answers (Lebiere and Anderson 1998).
</p>
<p>Table 14.1 Example MHP analysis
</p>
<p>MHP: example 1: motor skills, typing behavior
</p>
<p>A manufacturer is considering whether to use an alphabetic keyboard on his handheld point of
sale (PoS) system. Among several factors influencing his decision is the question of whether
experienced users will find the keyboard slower for touch typing than the standard Sholes
(QWERTY) keyboard arrangement. What is the relative typing speed for expert users on the
two keyboards?
</p>
<p>Typing rate = 152/ks (72 words/min)
</p>
<p>Typing rate (alphabetic) = 164 ms/key (66.5 words/min)
</p>
<p>MHP: example 2: cognitive, working memory
</p>
<p>A programmer is told verbally the one-syllable file names of a dozen files to load into his
programming system. Assuming all the names are arbitrary, in which order should the
programmer write down the names so that he remembers the greatest number of them (has to
ask for the fewest number to be repeated)?
</p>
<p>The fact that there are 12 arbitrary file names means the programmer has to remember 12 chunks
(assuming one chunk/name), which is larger than the storage capacity of working memory,
so some of the file names will be forgotten. The act of trying to recall the file names will
add new items to working memory, interfering with the previous names. The items likely
to be in working memory but not yet in long-term memory are those from the end of the
list. If the task is to recall the names from the end of the list first, he can snatch some of
these from working memory before they are displaced. The probability of recalling the
first names will not be affected because if they are available, they are in long-term
memory. Thus the programmer should recall the last names first and then the others
but will forget some
</p>
<p>14.3 Models of Users 395</p>
<p/>
</div>
<div class="page"><p/>
<p>14.3.3 Summary
</p>
<p>What is the purpose of user models? One use is that they can provide a way to
</p>
<p>create a shared representation of the user between interface designers, system
</p>
<p>designers, and others working on system development (Pew and Mavor 2007).
</p>
<p>They can also be used as summaries of knowledge (Newell 1990), and are thus
</p>
<p>useful to people learning about users. These models are also useful in video games
</p>
<p>and other simulations where the more advanced types can serve as surrogate users,
</p>
<p>opponents, and teammates (Pew and Mavor 1998; Ritter et al. 2003).
</p>
<p>User models provide frameworks, ways of seeing designs and targeting
</p>
<p>potential problems, and integrating psychological principles because the user&rsquo;s
</p>
<p>knowledge and capabilities are represented explicitly.
</p>
<p>Which type of user model you choose depends on what part of the design you
</p>
<p>are working on and what you want from the model. For example, task analysis as a
</p>
<p>simple version of a user model is very lightweight and very useful, particularly for
</p>
<p>simple web site design. A more complex and formal model is useful as the
</p>
<p>complexity and impact of the system increase. For testing large numbers of
</p>
<p>interfaces (e.g., a web site), or for testing a site often or repeatedly, an automatic
</p>
<p>tool is useful. For high impact interfaces (e.g., aviation, automotive interfaces due
</p>
<p>to the large number of users, or space station interfaces), more complete and
</p>
<p>complex models are useful because they are more accurate, but currently come at a
</p>
<p>very high price.
</p>
<p>The choice of which model to use can be based on what you want to learn about
</p>
<p>how users interact with your system. This can be seen as a way to reduce system
</p>
<p>development risks, and your choice of model can be based on the questions of
</p>
<p>Intentional System
(not modeled)
</p>
<p>Declarative Memory
(Temporal/Hippocampus)
</p>
<p>Retrieval (VLPFC)Goal (DLPFC)
</p>
<p>Visual (Parietal) Manual (Motor)
</p>
<p>Matching (Striatum)
</p>
<p>Selection (Pallidum)
</p>
<p>Execution (Thalmus)
</p>
<p>Environment
</p>
<p>Visual System
(loosely modeled)
</p>
<p>Effector System for 
</p>
<p>Hands (loosely modeled)
</p>
<p>M
o
</p>
<p>d
u
</p>
<p>le
s
</p>
<p>B
u
</p>
<p>ff
e
</p>
<p>rs
</p>
<p>P
ro
</p>
<p>d
u
</p>
<p>c
ti
</p>
<p>o
n
</p>
<p>s
 
</p>
<p>(B
a
</p>
<p>s
a
</p>
<p>l 
G
</p>
<p>a
n
</p>
<p>g
li
</p>
<p>a
)
</p>
<p>Fig. 14.3 The schematic
block diagram of ACT-R 6.
Taken from Anderson (2007)
and used with permission
</p>
<p>396 14 Summary: Putting It All Together</p>
<p/>
</div>
<div class="page"><p/>
<p>what risks do you want to reduce, will the system be fast enough to use? Fast
</p>
<p>enough to learn? Will the error rate be too high? Using risk reduction in system
</p>
<p>design is taken up in the next section.
</p>
<p>14.4 Risk-Driven Incremental Commitment Model
</p>
<p>14.4.1 Introduction
</p>
<p>There is now widespread acceptance of the fact that most systems development
</p>
<p>follows an iterative cycle, often represented by the spiral model (Boehm and
</p>
<p>Hansen 2001). It is only relatively recently, however, that human factors issues
</p>
<p>have been explicitly incorporated into the latest version of the spiral model
</p>
<p>(Boehm and Lane 2006) by the (US) Committee on Human-System Design
</p>
<p>Support for Changing Technology (Pew and Mavor2007). The revised model&mdash;the
</p>
<p>Risk Driven Incremental Commitment Model (RD-ICM)&mdash;encourages incremen-
</p>
<p>tal development of systems in an ongoing spiral process comprising requirements
</p>
<p>specification, technical exploration, and stakeholder commitment. The process is
</p>
<p>shown in Fig. 14.4, where movement around the spiral represents time and
</p>
<p>commitment and work on the project.
</p>
<p>The spiral is also sometimes shown linearly, as in Fig. 14.4, for discussion
</p>
<p>purposes. At each stage, the system development is assessed for risks to the
</p>
<p>system&rsquo;s success. The process is then targeted at reducing these risks. Where the
</p>
<p>risks are technical (e.g., Can we build it? Can we build it for that price?), technical
</p>
<p>work is performed to reduce the risk through increased understanding of the
</p>
<p>technical issues and how to deal with them. Other risks can arise from historical
</p>
<p>events, which are harder to reduce; and from financial matters, which can often be
</p>
<p>reduced by setting up contracts at a known price.
</p>
<p>The RD-ICM has several key features:
</p>
<p>1. Systems should be developed through a process that considers and satisfices the
</p>
<p>needs of stakeholders (it finds a reasonable solution that keeps in mind the costs
</p>
<p>of finding a (better) solution). This step is addressed by the Exploration and
</p>
<p>Valuation stages shown in Fig. 14.4.
</p>
<p>2. Development is incremental and performed iteratively. These related aspects
</p>
<p>are shown in Fig. 14.4 by the multiple loops representing the increasing amount
</p>
<p>of resources committed to design and implementation, and in Fig. 14.5 by the
</p>
<p>five stages (Exploration, Valuation, Architecting, Development, and Opera-
</p>
<p>tion). These stages are incremental because movement from one stage to the
</p>
<p>next depends upon a successful review to go to the next stage.
</p>
<p>3. Development occurs concurrently, that is, multiple steps may be performed
</p>
<p>simultaneously&mdash;some people thus refer to this model as an Incremental
</p>
<p>Concurrent Commitment model. One part of the system may be implemented
</p>
<p>while another part is being tested. This is not immediately clear from Figs. 14.4
</p>
<p>14.3 Models of Users 397</p>
<p/>
</div>
<div class="page"><p/>
<p>or 14.5, but can be seen more clearly in Fig. 14.6. This figure shows how the
</p>
<p>amount of effort put into a given activity varies through the life of a system for
</p>
<p>a hypothetical example system. Some peaks occur on some activities when their
</p>
<p>phase is active (e.g., development), and some activities peak near the reviews
</p>
<p>(i.e., the Evaluation, Valuation, Architecting, Construction, and Operations
</p>
<p>Commitment Reviews). The level of activity will also vary within a phase, as
</p>
<p>iterations are done within that phase.
</p>
<p>4. The process explicitly takes account of risks during system development and
</p>
<p>deployment. The level of risk is assessed at reviews between stages (shown
</p>
<p>holistically in Fig. 14.4 and explicitly in Fig. 14.5). Risk is used to manage the
</p>
<p>project&mdash;the level of effort and level of detail of work are driven by the level of
</p>
<p>risk (Boehm 2008 provides some nice additional information and examples).
</p>
<p>Where there is no risk to system development, there is no need for any effort to
</p>
<p>reduce risk. For example, if the system being developed is similar to an existing
</p>
<p>product, there may be no reason to explore further how to support users or how
</p>
<p>to manufacture that system.
</p>
<p>1
</p>
<p>2
</p>
<p>3
</p>
<p>4
</p>
<p>5
</p>
<p>6
</p>
<p>STAKEHOLDER
COMMITMENT
REVIEW POINTS:
</p>
<p>Opportunities to
proceed, skip
phases, backtrack,
or terminate
</p>
<p>Exploration Commitment Review
</p>
<p>Valuation Commitment Review
</p>
<p>Architecture Commitment Review
</p>
<p>Development Commitment Review
</p>
<p>Operations1 and Development2
Commitment Review
</p>
<p>Operations2 and Development3
Commitment Review
</p>
<p>Cumulative Level of Understanding, Cost, Time, Product, and
Process Detail (Risk-Driven)
</p>
<p>Concurrent
Engineering of
Products and
Processes
</p>
<p>2345
</p>
<p>ARCHITECTINGARCHITECTING
</p>
<p>VALUATION
</p>
<p>DEVELOPMENT
</p>
<p>1
</p>
<p>OPERATION2
</p>
<p>16
</p>
<p>OPERATION
</p>
<p>ARCHITECTING
</p>
<p>EXPLORATION
</p>
<p>Fig. 14.4 The RD-ICM model as a spiral. Reprinted from Pew and Mavor (2007) with
permission from the National Academy of Sciences, courtesy of the National Academies Press
</p>
<p>398 14 Summary: Putting It All Together</p>
<p/>
</div>
<div class="page"><p/>
<p>Pew and Mavor (2007, pp. 91&ndash;133) provide three examples of using the Risk-
</p>
<p>Driven Spiral Model method to develop specific systems. These examples are
</p>
<p>taken from different domains and are different sizes. Their Chap. 5 (http://www.
</p>
<p>nap.edu/openbook.php?record_id=11893&amp;amp;page=91) covers the development
</p>
<p>of an unmanned aerial system (i.e., an unmanned aerial vehicle, a UAV) for the
</p>
<p>military, a port security screening system for homeland security, and an intrave-
</p>
<p>nous infusion pump for use in hospitals. Each example covers different aspects of
</p>
<p>the process, so together they provide fairly broad coverage of the approach.
</p>
<p>The model is relatively complex, so we advocate that another way to under-
</p>
<p>stand it is through the viewpoint of concurrent activities. The standard way of
</p>
<p>presenting the model is as a spiral (as shown in Fig. 14.4), although the spiral can
</p>
<p>be unwound and the task activity levels can be represented in a linear fashion
</p>
<p>(Fig. 14.5), which makes it easier to recognize the concurrent phases of devel-
</p>
<p>opment, as well as concurrent activities that are out of phase and aspects like
</p>
<p>stakeholder commitment review points where the risks are assessed.
</p>
<p>.AelpmaxE
</p>
<p> Simple Enterprise 
</p>
<p>)PRE(gninnalPecruoseR
</p>
<p> based application
</p>
<p>Activities
</p>
<p>General/
</p>
<p>DoD Milestones
</p>
<p>Example B. 
</p>
<p> Complex, but feasible
</p>
<p> product development
</p>
<p>Example C. 
</p>
<p> Stakeholders agree that 
</p>
<p> more convergence of
</p>
<p> objectives is necessary
</p>
<p>Example D. 
</p>
<p> A superior product
</p>
<p> enters the market
</p>
<p>Too high, 
</p>
<p>unaddressable
</p>
<p>High, but
</p>
<p>addressable
</p>
<p>Acceptable
</p>
<p>Negligible
Risk? Risk? Risk? Risk? Risk?
</p>
<p>Negligible
</p>
<p>Acceptable Acceptable Acceptable ...
</p>
<p>AcceptableAcceptable
</p>
<p>Risk? Risk? Risk? Risk? Risk?
</p>
<p>Acceptable Acceptable Acceptable ...
</p>
<p>AcceptableAcceptable
</p>
<p>Risk? Risk? Risk? Risk? Risk?
</p>
<p>Acceptable Acceptable Acceptable ...
</p>
<p>AcceptableAcceptable
</p>
<p>Risk? Risk? Risk? Risk? Risk?
</p>
<p>Too high, 
</p>
<p>unaddressable
</p>
<p>High, but
</p>
<p>addressable
</p>
<p>Discontinue 
</p>
<p>ICM
</p>
<p>Life-cycle Phases
</p>
<p>E
xp
</p>
<p>lo
ra
</p>
<p>tio
n
</p>
<p>V
al
ua
</p>
<p>tio
n
</p>
<p>A
rc
</p>
<p>hi
te
</p>
<p>ct
in
g
</p>
<p>D
ev
</p>
<p>el
op
</p>
<p>m
en
</p>
<p>t 1
</p>
<p>Ar
ch
</p>
<p>ite
ct
in
g 2
</p>
<p>O
pe
</p>
<p>ra
tio
</p>
<p>n 1
</p>
<p>   
 D
</p>
<p>ev
el
op
</p>
<p>m
en
</p>
<p>t 2
</p>
<p>Ar
ch
</p>
<p>ite
ct
in
g 3
</p>
<p>...
</p>
<p>Ex
pl
or
</p>
<p>at
io
n
</p>
<p>C
om
</p>
<p>m
itm
</p>
<p>en
t
</p>
<p>R
ev
</p>
<p>ie
w Va
</p>
<p>lu
at
</p>
<p>io
n
</p>
<p>C
om
</p>
<p>m
itm
</p>
<p>en
t
</p>
<p>R
ev
</p>
<p>ie
w Ar
</p>
<p>ch
ite
</p>
<p>ct
ur
</p>
<p>e
</p>
<p>C
om
</p>
<p>m
itm
</p>
<p>en
t
</p>
<p>R
ev
</p>
<p>ie
w D
</p>
<p>ev
el
op
</p>
<p>m
en
</p>
<p>t
</p>
<p>C
om
</p>
<p>m
itm
</p>
<p>en
t
</p>
<p>R
ev
</p>
<p>ie
w O
</p>
<p>pe
ra
</p>
<p>tio
ns
</p>
<p>C
om
</p>
<p>m
itm
</p>
<p>en
t
</p>
<p>R
ev
</p>
<p>ie
w O
</p>
<p>pe
ra
</p>
<p>tio
ns
</p>
<p>C
om
</p>
<p>m
itm
</p>
<p>en
t
</p>
<p>R
ev
</p>
<p>ie
w
</p>
<p>ECR VCR/CD ACR/A DCR/B
OCR
</p>
<p>1 
/C
</p>
<p>1
</p>
<p>DCR
2 
</p>
<p>/B
2
</p>
<p>OCR
2 
</p>
<p>/C
2
</p>
<p>DCR
3 
</p>
<p>/B
3
</p>
<p>Fig. 14.5 The RD-ICM laid out linearly. This figure also shows the role of risk in system
development, showing how different risk patterns yield different processes. Reprinted from Pew
and Mavor (2007) with permission from the National Academy of Sciences, courtesy of the
National Academies Press
</p>
<p>14.4 Risk-Driven Incremental Commitment Model 399</p>
<p/>
<div class="annotation"><a href="http://www.nap.edu/openbook.php?record_id=11893&amp;page=91">http://www.nap.edu/openbook.php?record_id=11893&amp;page=91</a></div>
<div class="annotation"><a href="http://www.nap.edu/openbook.php?record_id=11893&amp;page=91">http://www.nap.edu/openbook.php?record_id=11893&amp;page=91</a></div>
</div>
<div class="page"><p/>
<p>14.4.2 Insight 1: The RD-ICM Provides a Way to Organize
</p>
<p>User-Related Knowledge and Ways of Knowing
</p>
<p>Experiences teaching and applying the RD-ICM to system design have led to a few
</p>
<p>insights and extensions. These are related to learning: learning through using this
</p>
<p>approach how to organize methods to reduce risks, learning by system
</p>
<p>ACTIVITIES
</p>
<p>Initial Elab
#1
</p>
<p>Elab
#2
</p>
<p>Const
#1
</p>
<p>Const
#2
</p>
<p>Tran
#1
</p>
<p>Tran
#2
</p>
<p>Inception Elaboration Construction Transition
</p>
<p>Business Modeling
</p>
<p>System Scoping/
</p>
<p>Requirements
</p>
<p>Understanding Needs/ 
</p>
<p>Stakeholder Requirements
</p>
<p>Envisioning
</p>
<p>Evaluation
</p>
<p>c. Hardware
</p>
<p>b. Human     
</p>
<p>Architecting and 
</p>
<p>Designing    a. System
</p>
<p>d. Software
</p>
<p>Maintenance
</p>
<p>Operations
</p>
<p>Development
</p>
<p>Iterations within Phases
</p>
<p>A
c
</p>
<p>ti
v
</p>
<p>it
y
</p>
<p> L
e
v
e
</p>
<p>ls
</p>
<p>E
C
R
</p>
<p>V
C
R
</p>
<p>A
C
R
</p>
<p>C
C
R
</p>
<p>O
C
R
</p>
<p>Planning
</p>
<p>Fig. 14.6 The role of concurrency in system development, showing how different tasks may be
performed concurrently and how activity levels rise and fall over the course of a project. It is
similar to Fig. 2.3 in Pew and Mavor (2007) and incorporates ideas from Boehm&rsquo;s other work
(e.g., Boehm 2008)
</p>
<p>400 14 Summary: Putting It All Together</p>
<p/>
</div>
<div class="page"><p/>
<p>development managers that there are sometimes risks related to humans using their
</p>
<p>systems, learning that designers are stakeholders too, and learning by designers as
</p>
<p>lessons from one design are applied to later designs.
</p>
<p>Pew and Mavor (2007) report that the RD-ICM approach provides a useful way
</p>
<p>to organize usability methods. We have found that this approach also provides a
</p>
<p>useful framework for teaching this material. The three main areas that involve HIS
</p>
<p>activities are identified as:
</p>
<p>1. Defining the opportunities and context of system use.
</p>
<p>2. Defining system requirements and design.
</p>
<p>3. Evaluation of the system.
</p>
<p>There are several methods that can be used to reduce risk in these three areas.
</p>
<p>All of the HCI methodologies (not just the examples presented in the Pew and
</p>
<p>Mavor book) can be organized with respect to how much they can contribute to
</p>
<p>each stage of system development.
</p>
<p>The RD-ICM has been very useful in discussing the relative merits of meth-
</p>
<p>odologies, and when to use each of the methodologies or techniques. Figure 14.7
</p>
<p>highlights several examples of methods that are applicable across several stages of
</p>
<p>system development, as shown by the horizontal lines under each of the method
</p>
<p>names. The figure could be further extended by weighting the lines to emphasize
</p>
<p>where individual methods are more appropriate to a particular stage of develop-
</p>
<p>ment. If all the methods were included, the figure would also show that methods
</p>
<p>(and thus practitioners) could be grouped by usefulness at particular stages of
</p>
<p>development: some methods are best suited to the early valuation stage, for
</p>
<p>example, and some to evaluation.
</p>
<p>14.4.3 Insight 2: RD-ICM is Descriptive as Well
</p>
<p>as Prescriptive
</p>
<p>The RD-ICM formalizes to some extent what many people accept as perceived
</p>
<p>wisdom, i.e., that many system developers already recognize that several devel-
</p>
<p>opment processes are risk driven (or at least risk aware), incremental, and con-
</p>
<p>current. Indeed, we believe that most system development processes are risk
</p>
<p>driven, and that systems developers are aware of the risks and adjust their
</p>
<p>development processes to reduce or mitigate the effects of the identified risks. We
</p>
<p>also believe that some parts of system development are often carried out in par-
</p>
<p>allel. Furthermore, we believe that there is buy-in from at least some of the system
</p>
<p>stakeholders in nearly all projects. The RD-ICM is therefore not merely a nor-
</p>
<p>mative model, prescribing what system developers should do, but instead captures
</p>
<p>and describes the practice of systems development. If the RD-ICM was described
</p>
<p>to systems developers, we believe many of them would claim that they already
</p>
<p>follow a similar process.
</p>
<p>14.4 Risk-Driven Incremental Commitment Model 401</p>
<p/>
</div>
<div class="page"><p/>
<p>There are two major areas of risk, however, that system developers and man-
</p>
<p>agers seem to be less aware of:
</p>
<p>&bull; The risks that arise from not giving appropriate consideration to all of the
</p>
<p>system stakeholders
</p>
<p>&bull; The risks that arise from not considering humans as part of the system.
</p>
<p>Developers and managers are probably not effectively addressing these risks
</p>
<p>because they believe the risks have low probability or only lead to very minor
</p>
<p>consequences, perhaps because they lack formal training in these areas.1 We
</p>
<p>believe that the developers and managers more fundamentally do not recognize the
</p>
<p>potential threat to the system&rsquo;s success from these two major areas of risk. Thus,
</p>
<p>we can either educate the managers, or provide other ways to highlight risks
</p>
<p>outside their expertise. It may be useful to bring in outside experts to evaluate the
</p>
<p>risks. The corollary of this is that it is probably worthwhile to include outside
</p>
<p>experts in the evaluation of all risks. They are likely to have greater awareness of a
</p>
<p>wider range of risks across a wider range of contexts, and to be more objective
</p>
<p>with respect to the project, so they will help to make the evaluation more
</p>
<p>comprehensive.
</p>
<p>Irrespective of whether you are following some version of the Spiral Model
</p>
<p>(such as the ICM or RD-ICM) or any other life cycle model (waterfall, V-model,
</p>
<p>and so on), it is important that all stakeholders are considered. It is also important
</p>
<p>Fig. 14.7 Figure 7.1 from Pew and Mavor (2007) revised to show the approximate range of use
of several methodologies across the development process. Reprinted with permission from the
National Academy of Sciences, courtesy of the National Academies Press
</p>
<p>1 Engineers will see engineering risks, accountants accounting risks, and human factors
engineers HF risks.
</p>
<p>402 14 Summary: Putting It All Together</p>
<p/>
</div>
<div class="page"><p/>
<p>that they are considered from the start of the project. In other words, before we get
</p>
<p>to thinking about design issues.
</p>
<p>There are several illustrations of why it is important to include consideration of
</p>
<p>users at the earliest stages of system development. Figures 1.1 through 1.4 in
</p>
<p>Chap. 1, for example, all showed that there are fundamental aspects of human
</p>
<p>behavior that designers are often unaware of. Some would argue that the conse-
</p>
<p>quences of these failures are irritating rather than severe, but the range and impact
</p>
<p>of the risks are exemplified in summary reviews such as those by Booher and
</p>
<p>Minninger (2003) and Casey (1998, 2006), in the regularly updated Risks Digest,2
</p>
<p>and in publicly reported incidents like that involving the USS Vincennes, where a
</p>
<p>civilian airliner was shot down by a US Navy ship because the airliner was thought
</p>
<p>to be a fighter plane. The examples in all of these reviews help to raise the
</p>
<p>visibility of the risks that need to be considered during development.
</p>
<p>This approach is therefore not just prescriptive but also descriptive. Failures
</p>
<p>arise from not knowing risks. To fix this, we need to educate designers about
</p>
<p>human-centered risks and how to avoid them. This book can be seen as a direct
</p>
<p>step to address this problem.
</p>
<p>14.4.4 Extension 1: Designers are Stakeholders Too
</p>
<p>One of the insights that arose from teaching the RD-ICM is that a description of
</p>
<p>the development process reinforces the fact that designers are stakeholders too (see
</p>
<p>Steele et al. 2011 for one example). The success of designers is at least partially
</p>
<p>linked to the success of the project, and their needs and capabilities will influence
</p>
<p>the development process.
</p>
<p>Designers are therefore stakeholders too, and, just like users, they have capa-
</p>
<p>bilities and limitations that can affect the outcome of a project. They have creative
</p>
<p>skills and experience of how to turn requirements into deliverable systems. More
</p>
<p>fundamentally, they will also have experience of the feasibility of whether a
</p>
<p>particular set of requirements can reasonably be turned into a deliverable system.
</p>
<p>In one sense, designers are users too, because they often rely on automated tools to
</p>
<p>help them to carry out and manage system development. If they are not supported
</p>
<p>or lack resources, including time, they will produce problems like that shown in
</p>
<p>Fig. 14.8.
</p>
<p>If designers are stakeholders then there needs to be time allocated to soliciting
</p>
<p>their input, and to making sure that they are equipped with the appropriate skills
</p>
<p>and tools to do the design. This may mean that they need to be educated about the
</p>
<p>capabilities and limitations of users, for example, and to be provided with tools
</p>
<p>that can allow them to create design representations that they can share with other
</p>
<p>stakeholders as well as the users.
</p>
<p>2 http://catless.ncl.ac.uk/Risks
</p>
<p>14.4 Risk-Driven Incremental Commitment Model 403</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1">http://dx.doi.org/10.1007/978-1-4471-5134-0_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1">http://dx.doi.org/10.1007/978-1-4471-5134-0_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1">http://dx.doi.org/10.1007/978-1-4471-5134-0_1</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_1">http://dx.doi.org/10.1007/978-1-4471-5134-0_1</a></div>
<div class="annotation"><a href="http://catless.ncl.ac.uk/Risks">http://catless.ncl.ac.uk/Risks</a></div>
</div>
<div class="page"><p/>
<p>When designers (and implementers) push back against the discussion and
</p>
<p>management of risks related to human&ndash;system integration, this may be because
</p>
<p>they do not fully appreciate the risks in this area. Explicitly including designers as
</p>
<p>stakeholders should focus on helping them become more cognizant of the issues
</p>
<p>and context involved that is outside their training. Giving them this broader
</p>
<p>context should ultimately lead to better integration and greater risk reduction,
</p>
<p>including the reduction of system implementation related risks.
</p>
<p>14.4.5 Extension 2: Learning Within and Between Projects
</p>
<p>Given the multidisciplinary nature of system development, and the importance of
</p>
<p>involving all the stakeholders, it is obvious that communication is important. The
</p>
<p>various disciplines that need to talk to each other during system development all
</p>
<p>have their own history and culture, which includes their own terminology. One of
</p>
<p>the easiest ways of facilitating communication is through the use of representations
</p>
<p>that help to make ideas and concepts more tangible. Pew and Mavor (2007)
</p>
<p>explicitly recognized this in their call for research on shared representation and
</p>
<p>integration across the design process. In some ways this can be regarded as an
</p>
<p>extension to the idea of software design patterns which provide generic templates
</p>
<p>or descriptions of solutions to problems that can be applied in different situations
</p>
<p>(e.g., Gemma et al. 1995).
</p>
<p>One of the major results from using simulation in CAD/CAM is that the lessons
</p>
<p>learned about one design can be applied to subsequent designs as well as to the
</p>
<p>current design. For example, in printed circuit boards, traces (printed wire paths)
</p>
<p>can be positioned too closely together. Tools like Spice (Thorpe 1992) help to
</p>
<p>highlight effects such as cross talk between the traces and short circuits that can be
</p>
<p>caused by the manufacturing process. After these design lessons are learned on the
</p>
<p>first design, they can be used to steer subsequent designs away from the problem
</p>
<p>rather than forcing the designer to start from scratch each time, modifying their
</p>
<p>Fig. 14.8 The question was,
&lsquo;&lsquo;How did Robinson Crusoe
meet Friday?&rsquo;&rsquo; The
duplication of the answer into
the extra information field
suggests that the interface did
not support a system
designer, and that the results
were not tested
</p>
<p>404 14 Summary: Putting It All Together</p>
<p/>
</div>
<div class="page"><p/>
<p>designs based on a new analysis of the problems. Similar effects of transfer will
</p>
<p>happen after computing Fitts&rsquo; Law a few times or comparing mouse movement
</p>
<p>times to keystroke times.
</p>
<p>To facilitate learning, shared representations need to be made available within
</p>
<p>projects, across the system development team and across the different stages of the
</p>
<p>design process for a single project. We extend this, though, to re-using repre-
</p>
<p>sentations across multiple projects. This may mean that the shareable represen-
</p>
<p>tations have to be able to reflect different levels of abstraction (based on their
</p>
<p>dependency on their context of use) so that they can be learned from and re-used.
</p>
<p>The corollary of this is that those people developing the shared representations are
</p>
<p>likely to need to document the shared representations with information about
</p>
<p>context.
</p>
<p>In addition to sharing representations within projects, it may be possible to re-
</p>
<p>use these representations across projects. This would increase the value of these
</p>
<p>representations, and achieve the re-use that is called for by Pew and Mavor (2007).
</p>
<p>This would also broaden the audience for the shared representations to include
</p>
<p>managers and developers on future projects who may be able to learn about
</p>
<p>potential risks and which stakeholders to consult.
</p>
<p>14.4.6 Summary
</p>
<p>The RD-ICM model is just one way of creating systems that are useful and safe. It
</p>
<p>involves identifying the stakeholders&mdash;including the designers&mdash;and coming up
</p>
<p>with a system through satisficing their different requirements, finding the best
</p>
<p>solution matching their constraints, including the cost to find better solutions as a
</p>
<p>constraint. If stakeholders&rsquo; needs are not adequately supported, they may not
</p>
<p>participate in the system development process fully, and may either obstruct the
</p>
<p>process or even refuse to accept the final system. An advantageous side effect of
</p>
<p>using the RD-ICM is that it can provide new ways of summarizing HCI methods
</p>
<p>and, more broadly, Human-System Integration (HSI) as an integral part of design
</p>
<p>and development.
</p>
<p>In the vast majority of systems, a failure to consider the users as stakeholders,
</p>
<p>and a lack of understanding of the abilities, capabilities, and limitations of users
</p>
<p>will constitute a risk to system development and use. The main exceptions are
</p>
<p>where the system being developed is not novel, so the risks in these areas are likely
</p>
<p>to have been considered and dealt with on other projects. Where there are risks,
</p>
<p>however, work has to be done to manage them appropriately, given the available
</p>
<p>resources, and to balance all of the identified risks (user related risks will need to
</p>
<p>be balanced against technical risks, for example).
</p>
<p>Managers and developers are usually familiar with the technical risks associ-
</p>
<p>ated with software and hardware. To make them more aware of user-related risks,
</p>
<p>they are likely to require some level of education and training about the capa-
</p>
<p>bilities and limitations of users. This education and training should take them to a
</p>
<p>14.4 Risk-Driven Incremental Commitment Model 405</p>
<p/>
</div>
<div class="page"><p/>
<p>level where they feel comfortable discussing these sorts of issues with people from
</p>
<p>the other disciplines involved in systems development.
</p>
<p>Shared representations are an important part of the development process, but
</p>
<p>they can be expensive to produce. It is therefore important to find ways to make
</p>
<p>them more valuable through reuse, for example. One way of doing this is by
</p>
<p>applying lessons from one design to subsequent designs on related projects.
</p>
<p>On the surface, the RD-ICM may appear to encapsulate a relatively complex
</p>
<p>theory of how systems should be created. It attempts to capture best practice and
</p>
<p>what many developers already do, highlighting that development is not a simple,
</p>
<p>linear, one-size-fits-all process. There are enough facets to the RD-ICM that it
</p>
<p>appears to have the same sort of level of complexity as a programming language or
</p>
<p>even a cognitive architecture. Although learningto use the RD-ICM approach takes
</p>
<p>time and effort, the fact that it takes explicit account of human factors currently
</p>
<p>makes it possibly the best model to use for development.
</p>
<p>14.5 Building on the Foundations
</p>
<p>At this point you should know much more about users than you did when you
</p>
<p>started reading this book. We hope that we have convinced you of the importance
</p>
<p>of understanding users and that, as a result, you are now more sensitive to the ways
</p>
<p>that users think and behave.
</p>
<p>There is a lot to learn, and while we have presented you with a lot of infor-
</p>
<p>mation, we continue to learn more about users as new technologies emerge and
</p>
<p>give rise to new ways of working. Even with the new technologies and new ways
</p>
<p>of working, it is important to think of them in terms of particular users doing
</p>
<p>particular tasks in a particular context. The information we have presented in this
</p>
<p>book should allow you to start to do that in a principled way, enabling you to
</p>
<p>design usable systems and to justify why you have designed them in a particular
</p>
<p>way. The Implications for system design sections should help here. Note, however,
</p>
<p>that in this book we have only really scratched the surface of what there is to learn
</p>
<p>about people, tasks, and contexts. If you want to find out more about any of the
</p>
<p>topics we mention, the lists of Other resources should provide a good starting
</p>
<p>point. Cynics might say that &lsquo;&lsquo;Keep in mind that a year in the lab can save you an
</p>
<p>hour&rsquo;s reading. That is, spending a little time looking at previous work can save a
</p>
<p>lot of time needlessly duplicating known results.
</p>
<p>One implicit lesson that we hope you have learned is that developing systems
</p>
<p>draws on multiple disciplines. We are not expecting software designers to become
</p>
<p>fully fledged psychologists, but we hope that our book sensitizes software
</p>
<p>designers to the psychological issues (about users) that need to be considered. We
</p>
<p>also hope that it provides a foundation for useful dialog across disciplines during
</p>
<p>system design.
</p>
<p>You should also have tools for finding out information when the information is
</p>
<p>not yet published. The short exercises at the end of most chapters on gathering data
</p>
<p>406 14 Summary: Putting It All Together</p>
<p/>
</div>
<div class="page"><p/>
<p>and Chap. 13 on usability studies should provide you with a way to find out more
</p>
<p>about particular users, particular tasks, or particular aspects of a task. There are
</p>
<p>important topics not included here because of space, such as emotions, and these
</p>
<p>you are now well equipped to learn on your own, or through further formal study
</p>
<p>As you start to use and apply your knowledge of users to systems development,
</p>
<p>you are likely to find that it leads you to raise several questions. When you address
</p>
<p>these questions to human factors engineers, you will often find that their answer is
</p>
<p>&lsquo;&lsquo;It depends.&rsquo;&rsquo; If this book has achieved nothing else, it should at least have helped
</p>
<p>you to appreciate why &lsquo;&lsquo;it depends&rsquo;&rsquo;: system performance is all about particular
</p>
<p>people doing particular tasks in particular contexts, and those people are all dif-
</p>
<p>ferent individuals, they have different skills and abilities, and they may work in
</p>
<p>different physical, social, and organizational contexts.
</p>
<p>The importance of appropriately integrating what we know about users into
</p>
<p>system design is becoming increasingly widespread. The revised version of Boehm
</p>
<p>and Hansen&rsquo;s (2001) incremental commitment model of system development, for
</p>
<p>example, includes explicit consideration of users (Pew and Mavor2007). The new
</p>
<p>model provides a principled way for deciding when you need to know more about
</p>
<p>your users. It explicitly acknowledges that not knowing enough about your users is
</p>
<p>a risk to the successful completion of a system development project. If this lack of
</p>
<p>knowledge about your users (their tasks and the context in which they work) poses
</p>
<p>a significant risk, then you need to invest more time and effort in addressing those
</p>
<p>issues until the risk is reduced to an acceptable level.
</p>
<p>We have now shown you what sort of things you will need to know about your
</p>
<p>users, and how to go about finding out that information. In doing so, we have
</p>
<p>provided you with the foundations for designing user-centered systems.
</p>
<p>14.6 Other Resources
</p>
<p>Pew (2007) has written a history of models in this area. In it he provides a
</p>
<p>summary as well as a description of the relationships between the various families
</p>
<p>of models.
</p>
<p>Salvucci has some nice models of how people drive (Salvucci2006), and some
</p>
<p>tools for predicting how secondary tasks will impair driving (Salvucci et al. 2005).
</p>
<p>Byrne and Kirlik (2005) have provided similar lessons in aviation.
</p>
<p>We have previously laid out a vision of future work that is needed to help
</p>
<p>designers create models routinely (Ritter et al. 2003). It is available online and
</p>
<p>notes about 20 projects that remain to be done with computational models of users.
</p>
<p>Pew and Mavor&rsquo;s (2007) book is available on line, and you can purchase it or
</p>
<p>register and download it. Their book provides useful pointers to a range of
</p>
<p>methodologies for reducing the risks to system success that are caused by not
</p>
<p>understanding users or their tasks. It could be and has been used to teach a separate
</p>
<p>class on HCI methodologies. There was also a special issue of the Journal of
</p>
<p>Cognitive Engineeringand Decision Making related to the topic published in 2008.
</p>
<p>14.5 Building on the Foundations 407</p>
<p/>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13">http://dx.doi.org/10.1007/978-1-4471-5134-0_13</a></div>
<div class="annotation"><a href="http://dx.doi.org/10.1007/978-1-4471-5134-0_13">http://dx.doi.org/10.1007/978-1-4471-5134-0_13</a></div>
</div>
<div class="page"><p/>
<p>A short, easy to read technical report is available online that lays out a tax-
</p>
<p>onomy of system development risks and a method to perform a risk analysis:
</p>
<p>Carr, M., Konda, S., Monarch, I., Ulrich, C., &amp; Walker, C. (1993). Taxonomy-Based Risk
Identification (Tech. Report No. CMU/SEI-93-TR-6, ADA266992). Pittsburgh, PA:
Software Engineering Institute, Carnegie-Mellon University.
</p>
<p>14.7 Exercises
</p>
<p>14.1 Consider a smartphone, either a specific one or a composite one, or a simple
</p>
<p>cell phone. Note all the limitations that will preclude users from performing
</p>
<p>well with it. Organize these by the ABCS framework.
</p>
<p>14.2 Choose an existing interface. Note the tasks that users will want to use it for.
</p>
<p>Note the types of users and their characteristics. Run two small studies
</p>
<p>examining how well your theory of use fits the data. These studies could be
</p>
<p>to find out what tasks users really do, how well they do it (time and errors,
</p>
<p>and strategies), or characteristics of the users.
</p>
<p>14.3 Choose an interface or system to create, such as a new application for a
</p>
<p>smartphone, such as a game, or book reader. Note what risks there are in
</p>
<p>developing such a system, with particular attention paid to the technical risks
</p>
<p>and those related to the user. Prioritize them. If you had 100 h, how would
</p>
<p>you allocate that time to reduce these risks?
</p>
<p>14.4 Go back and read the Appendix on the Kegworth air accident again. Read the
</p>
<p>supplementary material referenced (e.g., the AAIB report) or other reports
</p>
<p>you can find. Identify four more factors (events, processes, or mistakes) that
</p>
<p>can be considered as causes of the accident. Describe how these things could
</p>
<p>have been avoided or ameliorated. Address the question of whether it was
</p>
<p>&lsquo;pilot error&rsquo; that caused that plane to crash.
</p>
<p>References
</p>
<p>Anderson, J. R. (2007). How can the human mind exist in the physical universe? New York, NY:
Oxford University Press.
</p>
<p>Barnard P. J. (1987). Cognitive resources and the learning of human-computer dialogues. In
J. M. Carroll (Ed.), Interfacing thought: Cognitive aspects of human&ndash;computer interaction
(pp. 112&ndash;158). Cambridge, MA: MIT Press.
</p>
<p>Baxter, G., Besnard, D., &amp; Riley, D. (2007). Cognitive mismatches in the cockpit: Will they ever
be a thing of the past? Applied Ergonomics, 38, 417&ndash;423.
</p>
<p>Boehm, B. (2008). Making a difference in the software century. IEEE Computer,41(3), 32&ndash;38.
Boehm, B., &amp; Hansen, W. (2001). The spiral model as a tool for evolutionary acquisition.
</p>
<p>Crosstalk: The Journal of Defense Software Engineering, 14(5), 4&ndash;11.
Boehm, B., &amp; Lane, J. (2006). 21st century processes for acquiring 21st century systems of
</p>
<p>systems. Crosstalk, 19(5), 4&ndash;9.
</p>
<p>408 14 Summary: Putting It All Together</p>
<p/>
</div>
<div class="page"><p/>
<p>Booher, H. R., &amp; Minninger, J. (2003). Human systems integration in Army systems acquisition.
In H. R. Booher (Ed.), Handbook of human systems integration (pp. 663&ndash;698). Hoboken, NJ:
John Wiley.
</p>
<p>Byrne, M. D. (2001). ACT-R/PM and menu selection: Applying a cognitive architecture to HCI.
International Journal of Human&ndash;Computer Studies, 55(1), 41&ndash;84.
</p>
<p>Byrne, M. D., &amp; Kirlik, A. (2005). Using computational cognitive modeling to diagnose possible
sources of aviation error. International Journal of Aviation Psychology, 15(2), 135&ndash;155.
</p>
<p>Card, S. K., Moran, T. P., &amp; Newell, A. (1980). The keystroke-level model for user performance
time with interactive systems. Communications of the ACM, 23(7), 396&ndash;410.
</p>
<p>Card, S. K., Moran, T., &amp; Newell, A. (1983). The psychology of human&ndash;computer interaction.
Hillsdale, NJ: Erlbaum.
</p>
<p>Casey, S. M. (1998). Set phasers on stun: And other true tales of design, technology, and human
error. Santa Barbara, CA: Aegean.
</p>
<p>Casey, S. M. (2006). The atomic chef: And other true tales of design, technology, and human
error. Santa Barbara, CA: Aegean.
</p>
<p>Ericsson, K. A., &amp; Simon, H. A. (1993). Protocol analysis: Verbal reports as data (2nd ed.).
Cambridge, MA: MIT Press.
</p>
<p>Gemma, E., Helm, R., Johnson, R., &amp; Vlissides, J. (1995). Design patterns: Elements of reusable
object-oriented software. Boston, MA: Addison-Wesley.
</p>
<p>Gluck, K. A., Ball, J. T., &amp; Krusmark, M. A. (2007). Cognitive control in a computational model
of the predator pilot. In W. D. Gray (Ed.), Integrated models of cognitive systems (pp. 13&ndash;28).
New York: Oxford University Press.
</p>
<p>Ivory, M. Y., &amp; Hearst, M. A. (2001). The state of the art in automating usability evaluation of
user interfaces. ACM Computing Surveys, 33(4), 470&ndash;516.
</p>
<p>Kieras, D. E. (1999). A guide to GOMS model usability evaluation using GOMSL and GLEAN3.
AI Lab, University of Michigan. Retrieved 10 March 2014 from http://web.eecs.umich.edu/
*kieras/docs/GOMS
</p>
<p>Kieras, D. E., Wood, S. D., Abotel, K., &amp; Hornof, A. (1995). GLEAN: A computer-based tool for
rapid GOMS model usability evaluation of user interface designs. In Proceedings of the ACM
Symposium on User Interface Software and Technology (UIST&rsquo;95) (pp. 91&ndash;100). New York,
NY: ACM.
</p>
<p>Kieras, D. E., Wood, S. D., &amp; Meyer, D. E. (1997). Predictive engineering models based on the
EPIC architecture for a multimodal high-performance human-computer interaction task.
Transactions on Computer&ndash;Human Interaction, 4(3), 230&ndash;275.
</p>
<p>Laird, J. E. (2012). The soar cognitive architecture. Cambridge, MA: MIT Press.
Landauer, T. K. (1987). Relations between cognitive psychology and computer systems design.
</p>
<p>In J. Preece &amp; L. Keller (Eds.), Human&ndash;computer interaction (pp. 141&ndash;159). Englewood
Cliffs, NJ: Prentice-Hall.
</p>
<p>Lebiere, C., &amp; Anderson, J. R. (1998). Cognitive arithmetic. In J. R. Anderson &amp; C. Lebi&egrave;re
(Eds.), The atomic components of thought (pp. 297&ndash;342). Mahwah, NJ: Erlbaum.
</p>
<p>Morrison, J. E. (2003). A review of computer-based human behavior representations and their
relation to military simulations (IDA Paper P-3845). Alexandria, VA: Institute for Defense
Analyses.
</p>
<p>Newell, A. (1990). Unified theories of cognition. Cambridge, MA: Harvard University Press.
Pew, R. W. (2007). Some history of human performance modeling. In W. Gray (Ed.), Integrated
</p>
<p>models of cognitive systems (pp. 29&ndash;44). New York, NY: Oxford University Press.
Pew, R. W., &amp; Mavor, A. S. (Eds.). (1998). Modeling human and organizational behavior:
</p>
<p>Application to military simulations. Washington, DC: National Academies Press. Retrieved
from 10 March 2014 http://books.nap.edu/catalog/6173.html
</p>
<p>Pew, R. W., &amp; Mavor, A. S. (Eds.). (2007). Human-system integration in the system development
process: A new look. Washington, DC: National Academies Press. Retrieved March, 2014
from http://books.nap.edu/catalog.php?record_id=11893
</p>
<p>Ritter, F. E. (2003). Soar. In L. Nadel (Ed.), Encyclopedia of cognitive science (Vol. 4,
pp. 60&ndash;65). London: Nature Publishing Group.
</p>
<p>References 409</p>
<p/>
<div class="annotation"><a href="http://web.eecs.umich.edu/~kieras/docs/GOMS">http://web.eecs.umich.edu/~kieras/docs/GOMS</a></div>
<div class="annotation"><a href="http://web.eecs.umich.edu/~kieras/docs/GOMS">http://web.eecs.umich.edu/~kieras/docs/GOMS</a></div>
<div class="annotation"><a href="http://books.nap.edu/catalog/6173.html">http://books.nap.edu/catalog/6173.html</a></div>
<div class="annotation"><a href="http://books.nap.edu/catalog.php?record_id=11893">http://books.nap.edu/catalog.php?record_id=11893</a></div>
</div>
<div class="page"><p/>
<p>Ritter, F. E., &amp; Bibby, P. A. (2008). Modeling how, when, and what learning happens in a
diagrammatic reasoning task. Cognitive Science, 32, 862&ndash;892.
</p>
<p>Ritter, F. E., Shadbolt, N. R., Elliman, D., Young, R. M., Gobet, F., &amp; Baxter, G. D. (2003).
Techniques for modeling human performance in synthetic environments: A supplementary
</p>
<p>review. Wright-Patterson Air Force Base, OH: Human Systems Information Analysis Center
(HSIAC).
</p>
<p>Ritter, F. E., Van Rooy, D., St. Amant, R., &amp; Simpson, K. (2006). Providing user models direct
access to interfaces: An exploratory study of a simple interface with implications for HRI and
HCI. IEEE Transactions on System, Man, and Cybernetics, Part A: Systems and Humans,
36(3), 592&ndash;601.
</p>
<p>Ritter, F. E., Kukreja, U., &amp; St. Amant, R. (2007). Including a model of visual processing with a
cognitive architecture to model a simple teleoperation task. Journal of Cognitive Engineering
and Decision Making, 1(2), 121&ndash;147.
</p>
<p>Salvucci, D. D. (2006). Modeling driver behavior in a cognitive architecture. Human Factors,48,
362&ndash;380.
</p>
<p>Salvucci, D. D., Zuber, M., Beregovaia, E., &amp; Markley, D. (2005). Distract-R: Rapid prototyping
and evaluation of in-vehicle interfaces. In Human Factors in Computing Systems: CHI 2005
Conference Proceedings (pp. 581&ndash;589). New York, NY: ACM Press.
</p>
<p>Schoelles, M. J., &amp; Gray, W. D. (2001). Argus: A suite of tools for research in complex cognition.
Behavior Research Methods, Instruments, &amp; Computers, 33(2), 130&ndash;140.
</p>
<p>Steele, M., Dow, L., &amp; Baxter, G. (2011). Promoting public awareness of the links between
lifestyle and cancer: A controlled study of the usability of health information leaflets.
International Journal of Medical Informatics, 80, e214&ndash;e229.
</p>
<p>Thorpe, T. W. (1992). Computerized circuit analysis with SPICE: A complete guide to SPICE,
with applications. New York, NY: Wiley.
</p>
<p>410 14 Summary: Putting It All Together</p>
<p/>
</div>
<div class="page"><p/>
<p>Appendix
</p>
<p>The Kegworth Air Accident (1989)
</p>
<p>Introduction
</p>
<p>The Kegworth air accident is used to illustrate several points in this book. We
</p>
<p>chose this particular accident because it is well known and has been widely
</p>
<p>analyzed over the years (e.g., see Besnard et al. 2004). The full accident report is
</p>
<p>very comprehensive, and covers all aspects of the accident as well as the human
</p>
<p>factors issues. It is available from the web site of the UK&rsquo;s Air Accidents
</p>
<p>Investigation Branch (AAIB).1 The AAIB are responsible for investigating
</p>
<p>accidents that occur within UK air space.
</p>
<p>Description of the Accident
</p>
<p>On 8 January 1989 a British Midland Airways (BMA) Boeing 737-400 plane
</p>
<p>crashed into the embankment of the UK&rsquo;s M1 motorway close to the village of
</p>
<p>Kegworth in the East Midlands, during a flight from London Heathrow to Belfast.
</p>
<p>Of the 126 people on board, 47 lost their lives.
</p>
<p>Both members of the flight crew were highly experienced. The Captain had
</p>
<p>logged over 13,000 flying hours, whilst the First Officer had logged over 3,200.
</p>
<p>Both pilots were rated for the B737-200, -300, and -400 series aircraft. They had a
</p>
<p>combined experience of 76 flight hours in the Boeing 737-400 series aircraft.
</p>
<p>Furthermore, they had not been trained on the new plane&rsquo;s controls, but had only
</p>
<p>received a 1-day audio&ndash;visual conversion course on the B737-400, which has a
</p>
<p>glass cockpit, i.e., the information is presented on digital displays rather than the
</p>
<p>vast array of analogue instruments and electro-mechanical displays that appeared
</p>
<p>in the cockpit of its predecessor, the B737-300. In addition, the B737-400 series
</p>
<p>was fitted with a newer variant of an engine which could generate slightly more
</p>
<p>thrust. The engine had been certified by the appropriate authorities after
</p>
<p>undergoing testing.
</p>
<p>During the flight, a fan blade broke off in the #1 engine. This resulted in an
</p>
<p>increase in vibration above what is considered normal, and which was strong
</p>
<p>1 http://www.aaib.gov.uk/sites/aaib/publications/formal_reports/4_1990_g_obme.cfm
</p>
<p>F. E. Ritter et al., Foundations for Designing User-Centered Systems,
DOI: 10.1007/978-1-4471-5134-0, ï¿½ Springer-Verlag London 2014
</p>
<p>411</p>
<p/>
<div class="annotation"><a href="http://www.aaib.gov.uk/sites/aaib/publications/formal_reports/4_1990_g_obme.cfm">http://www.aaib.gov.uk/sites/aaib/publications/formal_reports/4_1990_g_obme.cfm</a></div>
</div>
<div class="page"><p/>
<p>enough to be felt by the crew. This happened shortly after 20:05 h. At the same
</p>
<p>time as the increase in vibration was felt, smoke and fumes were drawn into the
</p>
<p>aircraft through the air conditioning system. In their analysis of the problem, the
</p>
<p>flight crew mistakenly identified the right hand (#2) engine as being at fault and
</p>
<p>therefore reduced its power accordingly.
</p>
<p>An analysis of the data from the cockpit voice recorder (CVR) showed that
</p>
<p>there had been a slight hesitancy in determining which of the engines was at fault.
</p>
<p>When the Captain (the senior officer on the flight deck) asked the First Officer
</p>
<p>which engine was faulty, he replied &lsquo;It&rsquo;s the le&hellip; it&rsquo;s the right one.&rsquo; As a
</p>
<p>consequence, the power to the right hand (#2) engine was throttled back and the
</p>
<p>engine was eventually shut down.
</p>
<p>The actions taken on the right hand engine coincided (as it later turned out) with
</p>
<p>a reduction in vibration, and the smoke and fumes emerging from the left (faulty)
</p>
<p>engine also stopped. The flight crew therefore decided, erroneously (again, as it
</p>
<p>later turned out), that the correct engine had been shut down. They decided to put
</p>
<p>in motion the plan to make an emergency landing at East Midlands Airport, which
</p>
<p>involved talking to Air Traffic Control (ATC) to make sure they could get the
</p>
<p>appropriate clearances to land. Although the left engine continued to show a higher
</p>
<p>than normal level of vibration for several minutes, the crew did not notice this at
</p>
<p>the time.
</p>
<p>When the crew began their descent towards the airport they reduced the power
</p>
<p>to the left engine. This led to a further reduction in the vibration in that engine to
</p>
<p>the point where it was not much higher than what would normally be expected.
</p>
<p>About 10 min later the crew decided to increase the power to the left engine once
</p>
<p>more, in order to maintain the aircraft&rsquo;s altitude in the final stages of descent. The
</p>
<p>vibration levels increased once more to very high levels, power was lost in engine
</p>
<p>#1, and a fire warning sounded. At this point the crew tried to restart the #2 engine
</p>
<p>but did not manage to achieve this before the aircraft crashed into the ground 0.5
</p>
<p>nautical miles short of the runway shortly after 20:12 h.
</p>
<p>An Analysis of Possible Contributory Factors
</p>
<p>It is often very difficult to single out the exact causes of an accident after the fact.
</p>
<p>Where lives and machinery are lost, the best attempts involve a reconstruction of
</p>
<p>events based on the available evidence. In the case of aircraft accidents, this
</p>
<p>includes the information captured by the Flight Data Recorder, and the CVR.
</p>
<p>These are what you often hear referred to as &lsquo;&lsquo;the Black Box&rsquo;&rsquo; although they are
</p>
<p>usually a highly visible shade of orange!
</p>
<p>In the Kegworth accident, the crash was ultimately attributed to the way that the
</p>
<p>flight crew managed a mechanical incident in the left (#1) engine. The events
</p>
<p>unfolded very quickly: from the vibration being detected to the crash took less than
</p>
<p>7 min 30 s. As is often the case, there were several contributory events that
</p>
<p>happened which contributed to the accident. These occurred at different levels
</p>
<p>412 Appendix: The Kegworth Air Accident (1989)</p>
<p/>
</div>
<div class="page"><p/>
<p>within the system. We pick out examples of several types of these below. Rather
</p>
<p>than providing an exhaustive analysis (which you can find by reading the accident
</p>
<p>report in full, and consulting the many papers that have been published about the
</p>
<p>accident), our intention is to illustrate the points of particular interest. We start at a
</p>
<p>level that is some distance away from the point at which people are interacting
</p>
<p>with technology, as a way of highlighting the importance of understanding the
</p>
<p>wider context in which people make decisions and take actions. When you have
</p>
<p>finished reading the book, you should be able to come back to the accident
</p>
<p>description above and identify further examples (this is Exercise 14.4).
</p>
<p>Regulatory Level Issues
</p>
<p>The B737-400 was fitted with a new type of engine. As with all aircraft engines, it
</p>
<p>had to undergo extensive testing before it could be certified for operational use.
</p>
<p>The engine in this case was a variant of an existing engine (which is common
</p>
<p>practice in the aero-engine industry), and it was thoroughly tested on the ground
</p>
<p>before being certified by the FAA (and ratified by the CAA). The engine was not,
</p>
<p>however, tested either in an altitude test cell (which simulates the conditions of
</p>
<p>flying at high altitudes) or in flight. If it had been so tested, this may have
</p>
<p>highlighted the fact that there was a flaw in the design which led to a turbine blade
</p>
<p>failure under certain patterns of vibration. This scenario illustrates how decisions
</p>
<p>that are made at remote distance from the user interface in a system can have an
</p>
<p>impact on the way that the users behave. If the engine had still been certified, and
</p>
<p>both the airline and the flight crew had known that this was a potential (even if
</p>
<p>very rare) problem, they could have included a checklist to deal with it in the
</p>
<p>Quick Reference Handbook (QRH) that is used by all pilots to deal with known
</p>
<p>situations, such as smoke in the cockpit.
</p>
<p>Organizational Level Issues
</p>
<p>The B737-400 was what is known as a glass cockpit aircraft, in which the
</p>
<p>information is presented on digital displays rather than the vast array of analogue
</p>
<p>instruments and electro-mechanical displays that appeared in the cockpit of its
</p>
<p>predecessor, the B737-300. The airline (BMA) did not have a glass cockpit flight
</p>
<p>training simulator for the B737-400, so pilots could only gain experience in using
</p>
<p>the new glass cockpit when they were actually flying it (i.e., on the job). The only
</p>
<p>training the pilots were given about the B737-400 was a 1-day audio&ndash;visual
</p>
<p>conversion course.
</p>
<p>ATC offered the pilots two places to land. On company instructions, they chose to
</p>
<p>land at East Midlands airport, which was on their flight path, and the closest airport.
</p>
<p>This reduced the amount of time that they had available to reflect fully on the
</p>
<p>decisions and actions taken so far to deal with the engine problems. While the pilots
</p>
<p>Appendix: The Kegworth Air Accident (1989) 413</p>
<p/>
</div>
<div class="page"><p/>
<p>were trying to get ready for descent and landing, they were also in receipt of regular
</p>
<p>communications from ATC, had to talk to the operating company (BMA), keep the
</p>
<p>passengers informed of the situation, and complete the appropriate checklist in
</p>
<p>preparation for landing with one engine. The problem was made worse by the fact
</p>
<p>that the First Officer struggled to reprogram the Flight Management System (FMS)
</p>
<p>successfully with the details needed for landing at East Midlands airport. The way
</p>
<p>they had to use the FMSwas unusual and rarely practiced. This is another area where
</p>
<p>the lack of appropriate recurrent training contributed to the accident.
</p>
<p>Flight Crew Level Issues
</p>
<p>During the flight the pilots announced to the crew and passengers that there had
</p>
<p>been some trouble with the right engine but it had now been shut down. While
</p>
<p>some passengers could see the evidence of an engine fire, they did not inform the
</p>
<p>pilots that they had shut down the wrong engine. This appears to be an example of
</p>
<p>the problem of social distance, where the passengers perceive the pilots as being
</p>
<p>highly trained professionals, so they must know what they are doing, which means
</p>
<p>that the passengers do not feel in a position to correct them. The smell of smoke
</p>
<p>had dissipated by the time the announcement was made, too, which may also have
</p>
<p>had an influence on the passengers&rsquo; thinking.
</p>
<p>Three members of the cabin crew also reported having seen evidence of the fire
</p>
<p>in the #1 engine but they did not report this to the pilots. This seems to have been a
</p>
<p>failure in what is called Crew Resource Management, a procedure designed to
</p>
<p>ensure that all the members of a flight crew (pilots and cabin crew) communicate
</p>
<p>with one another and work together as a team. So the cabin crew should not have
</p>
<p>felt that there was a large social distance between them and the pilots, and should
</p>
<p>have not felt intimidated about telling the pilots about what they had seen even
</p>
<p>though it appeared to contradict what the pilots had said. This could have been
</p>
<p>attributed to a lack of CRM training.
</p>
<p>Cockpit Level Issues
</p>
<p>The first indication that there was a problem with the engines came when the flight
</p>
<p>crew felt excessive vibrations in the aircraft and detected smoke in the cockpit.
</p>
<p>When both pilots were interviewed after the accident, neither could recall having
</p>
<p>seen any indication of the abnormally high vibration levels on the Engine
</p>
<p>Instrument System (EIS). The Captain noted that he rarely scanned the vibration
</p>
<p>gauges because he had found them to be unreliable in other aircraft in the past.
</p>
<p>Experts, like pilots, have a highly developed mental model of the world in which
</p>
<p>they normally operate, and this helps them to perform the tasks they are supposed
</p>
<p>to. In pilots, this mental model will help guide where they need to look to find
</p>
<p>appropriate information about the current state of the aircraft. In this case, the
</p>
<p>414 Appendix: The Kegworth Air Accident (1989)</p>
<p/>
</div>
<div class="page"><p/>
<p>Captain appears to have eliminated the vibration gauges from his mental model,
</p>
<p>because he has found that they do not provide any useful information (because
</p>
<p>they are unreliable). If the captain had looked closely at the EIS, he may have
</p>
<p>observed information about the engines that would have changed how the flight
</p>
<p>crew dealt with the engine problems.
</p>
<p>Technology Issues
</p>
<p>The EIS which was fitted to the B737-400 used digital rather than analogue displays.
</p>
<p>A subsequent survey showed that nearly two-thirds of BMA pilots believed that the
</p>
<p>new EIS was not effective in drawing their attention to rapid changes in the engine
</p>
<p>parameters, and nearly three-quarters preferred the old EIS. Thus, the system
</p>
<p>designers of the EIS and the training could be deemed to have contributed to the
</p>
<p>accident. It appears that the pilots of BMA (at least) were not involved in carrying
</p>
<p>out any evaluation of the new EIS before they had to use it in flight.
</p>
<p>External Issues
</p>
<p>When the aircraft was in sight of the airport, the #1 engine finally failed completely.
</p>
<p>There was not enough time to restart the #2 engine, and the aircraft ended up landing
</p>
<p>on the M1 (one of the UK&rsquo;s main motorways). This road had had noise abatement
</p>
<p>embankments (small hills) put up to shelter the surrounding land from motorway
</p>
<p>noise. This caused the plane to bounce, and probably compounded the crash.
</p>
<p>Summary
</p>
<p>The formal accident investigation attributed the cause of the accident to pilot error.
</p>
<p>As you look through the description of what happened, and the list of contributory
</p>
<p>events, you should start to appreciate that maybe it was a series of mistakes, errors,
</p>
<p>and bad luck from a wide range of people who were part of the broad system.
</p>
<p>During a normal flight there are several things happening at the same time at
</p>
<p>different levels within the air transport system, and the flight crew has to deal with
</p>
<p>many of them. In the vast majority of cases, all the tasks are performed
</p>
<p>successfully, and the flight arrives safely at its destination and in a timely manner.
</p>
<p>It is often only when things go wrong, however, that you really begin to understand
</p>
<p>just how complicated getting a plane full of passengers from its original airport to
</p>
<p>its destination can be.
</p>
<p>Reference
</p>
<p>Besnard, D., Greathead, D., &amp; Baxter, G. (2004). When mental models go wrong.
</p>
<p>Co-occurrences in dynamic, critical systems. International Journal of Human-
</p>
<p>Computer Studies,60(60), 117&ndash;128.
</p>
<p>Appendix: The Kegworth Air Accident (1989) 415</p>
<p/>
</div>
<div class="page"><p/>
<p>Glossary
</p>
<p>ABCS Anthropometric, Behavior, Cognition, and Social factors: the high-level
</p>
<p>constructs which are useful for organizing the knowledge about people that is
</p>
<p>relevant to system design.
</p>
<p>ACT-R A cognitive architecture used to model human cognition.
</p>
<p>Aesthetics Relates to the characteristics of an object or system that make it
</p>
<p>pleasurable to use. Sometimes called Esthetics.
</p>
<p>Affordance The intrinsic property of an object that suggests actions that can be
</p>
<p>performed with it, e.g., a handle affords grasping and pulling.
</p>
<p>Anthropometrics The study of the shape of the body and how it influences what
</p>
<p>is designed. It takes into consideration the physical characteristics of intended
</p>
<p>users such their size and their muscular strength.
</p>
<p>Attention A term that refers to the selective nature of perception which functions
</p>
<p>in such a way that at any given time a person focuses on some feature(s) of the
</p>
<p>environment to the exclusion of others.
</p>
<p>Attribution theory Describes the tendency of people to attribute their own
</p>
<p>actions to external situational causes, whereas external observers attribute the
</p>
<p>same actions to causes that are internal to the person carrying out the actions.
</p>
<p>Availability bias Arises because users tend to recall those items that are easier to
</p>
<p>recall even when they may not be most representative of a particular situation.
</p>
<p>Blunt end The part of the system that is furthest away from where the user
</p>
<p>interacts with the technology. Normally refers to the level at which regulations
</p>
<p>and laws are applied. Often used in contrast to the sharp end.
</p>
<p>Closed loop behavior A pattern of behavior in which users take some actions,
</p>
<p>and look for feedback on those actions before deciding how to proceed. Also
</p>
<p>referred to as feedback control.
</p>
<p>Cognitive architecture A framework that supports the modeling of human
</p>
<p>information processing under different conditions. Cognitive architectures
</p>
<p>include mechanisms designed to help model human cognition.
</p>
<p>F. E. Ritter et al., Foundations for Designing User-Centered Systems,
DOI: 10.1007/978-1-4471-5134-0, ï¿½ Springer-Verlag London 2014
</p>
<p>417</p>
<p/>
</div>
<div class="page"><p/>
<p>Cognitive dimensions (of notation) A common ontology used to name specific
</p>
<p>aspects of design as well as the associated design trade-offs.
</p>
<p>Cognitive dissonance Cognitive dissonance occurs when a person holds two or
</p>
<p>more beliefs that are in conflict at one time, as in when people do not get what
</p>
<p>they want.
</p>
<p>Cognitive modeling Using computer programs to simulate human behavior,
</p>
<p>usually within the framework of a cognitive architecture.
</p>
<p>Cognitive task analysis (CTA) An extension of traditional task analysis tech-
</p>
<p>niques to facilitate the collection of information about the mental processes that
</p>
<p>underpin observable task performance. Usually comprises several methods.
</p>
<p>Computer supported co-operative work (CSCW) The study of how people
</p>
<p>work together using technology.
</p>
<p>Cones A type of light receptor cell located on the retina. Cones are sensitive to
</p>
<p>color. See also Rods.
</p>
<p>Confirmation bias Arises because users tend to look for information that con-
</p>
<p>firms their understanding of a particular situation, and hence have difficulty
</p>
<p>seeing things that conflict with their understanding of the world.
</p>
<p>Content strategy Content strategy relates to the planning for the creation, pub-
</p>
<p>lication, and governance of content that are both useful and usable. It covers
</p>
<p>which content to publish as well as why. Mostly used when referring to the web,
</p>
<p>but applies to all media, platforms, and devices.
</p>
<p>Co-operative principle Basically refers to trying to say the right thing at the right
</p>
<p>time&mdash;the co-operative principle can also be seen as a description of the way
</p>
<p>that people normally conduct conversations. See also Grice&rsquo;s maxims.
</p>
<p>CREAM (Cognitive reliability and error analysis method) Method for itera-
</p>
<p>tively modeling and analyzing erroneous performance in a prospective or ret-
</p>
<p>rospective manner. The CREAM assumes that the context is a major influence
</p>
<p>on human performance. See also THEA.
</p>
<p>Decibel A logarithmic measure of sound pressure: a tenfold increase in sound
</p>
<p>pressure (e.g., 10&ndash;20 dB) sounds twice as loud.
</p>
<p>Declarative memory A hypothesized store which holds facts or statement about
</p>
<p>the world, e.g., the earth is flat.
</p>
<p>Designers People who design systems or technology.
</p>
<p>Diffusion of social responsibility When a group of people are held jointly
</p>
<p>responsible for dealing with a particular situation, the responsibility diffuses
</p>
<p>across people: several people may decide not to do anything in the belief that
</p>
<p>someone else in the group will.
</p>
<p>418 Glossary</p>
<p/>
</div>
<div class="page"><p/>
<p>Distributed learning Learning that occurs when practice is distributed over time
</p>
<p>in such a way that there are gaps between practice sessions.
</p>
<p>Efficiency A system property that can be measured through its use of resources
</p>
<p>such as processor time, memory, network access, system facilities, disk space,
</p>
<p>and so on.
</p>
<p>Einstellung Einstellung is related to Functional Fixedness but refers to the situ-
</p>
<p>ation where a person gets fixated on a strategy to solve a problem.
</p>
<p>Ergonomics The field that is concerned with providing a good fit between people
</p>
<p>and their work or leisure environments. Often used interchangeably with human
</p>
<p>factors.
</p>
<p>Error The part of the system state that may lead to a subsequent failure.
</p>
<p>Esthetics Relates to the characteristics of an object or system that make it plea-
</p>
<p>surable to use.
</p>
<p>Event tree An inductive method for analyzing errors using a graphical binary tree
</p>
<p>representation.
</p>
<p>Explicit memory A hypothesized store of items that can be explicitly reported.
</p>
<p>Most declarative information can be explicitly reported. Often used in contrast
</p>
<p>to Implicit memory.
</p>
<p>Extrinsic motivation Motivation that arises from factors outside the individual,
</p>
<p>such as being paid to do something.
</p>
<p>Eye-tracking A method for recording where the user&rsquo;s eyes are looking using a
</p>
<p>dedicated device (an eye-tracker).
</p>
<p>Failure Something that occurs when the service that is delivered by a system or
</p>
<p>component is judged to have deviated from its specification.
</p>
<p>Fault The adjudged cause of an error within a system.
</p>
<p>Fault tree A deductive method for analyzing the causal factors that contribute to
</p>
<p>an error or accident, using a graphical tree representation.
</p>
<p>Feeling of knowing Refers to the feelings an individual has about their knowl-
</p>
<p>edge on a particular topic, and particularly whether or not that knowledge exists
</p>
<p>within memory. It normally relates to making judgments either prior to
</p>
<p>recalling the target item, or after failing to recall it. The focus is on whether an
</p>
<p>individual feels that they know the answer, rather than what the answer actually
</p>
<p>is. Often used in the context of metacognition.
</p>
<p>Field experiments Field experiments are trials of technologies in real world
</p>
<p>settings.
</p>
<p>Field studies Evaluations that are carried out in the field, that is, in real world
</p>
<p>settings.
</p>
<p>Glossary 419</p>
<p/>
</div>
<div class="page"><p/>
<p>Figure and ground Figure is the term used to refer to the objects being focused
</p>
<p>on; ground is the rest of the perceptual field.
</p>
<p>Fitts&rsquo; law A method used to predict the time it takes to move a pointer to a target.
</p>
<p>Flesch reading ease score A calculated value that reflects the readability of a
</p>
<p>selected piece of text.
</p>
<p>Forcing function A mechanism for physically constraining actions to prevent the
</p>
<p>user from proceeding to the next step in task performance. To start most cars,
</p>
<p>for example, you are forced to put the key into the ignition.
</p>
<p>Formative evaluation A type of evaluation that is used to help designers refine
</p>
<p>and form their designs. The focus of formative evaluation is to identify prob-
</p>
<p>lems and potential solutions.
</p>
<p>Fovea A small area of the retina (covering about 2ï¿½ of visual arc). This is the area
</p>
<p>of clearest vision.
</p>
<p>Framing effects Refers to the fact that the way that potential outcomes of a
</p>
<p>particular situation are presented (framed) has a powerful influence on how
</p>
<p>users choose between alternatives.
</p>
<p>Functional fixedness Functional fixedness occurs when a person becomes fixated
</p>
<p>on a particular use of an object.
</p>
<p>Functionality What the system does. Usually specified by the functional
</p>
<p>requirements.
</p>
<p>Fundamental attribution error The belief that our own behavior can be
</p>
<p>attributed to extrinsic factors in the environment, and that the behavior of others
</p>
<p>is attributable to their intrinsic properties (e.g., they are a bad person).
</p>
<p>Fundamental attribution error of design The belief, held by designers, that
</p>
<p>users act and behave in the same way as designers when using technology.
</p>
<p>Generic error modeling system (GEMS) An approach to modeling errors based
</p>
<p>on interpretation, planning, memory, and acting.
</p>
<p>Gestalt principles of visual grouping Can be used to explain how groups of
</p>
<p>objects are interpreted. The principles were developed as a rebellion against the
</p>
<p>simplistic notion that perception could be structurally analyzed into its com-
</p>
<p>ponent parts, and that complex ideas were the result of associating together
</p>
<p>simpler ones.
</p>
<p>GOMS (Goals, operators, methods, and selection rules) A method of task
</p>
<p>analysis that can be used to describe the details of error-free, expert task per-
</p>
<p>formance using Goals, Operators (actions), Methods (procedures), and Selec-
</p>
<p>tion rules (to choose between methods).
</p>
<p>420 Glossary</p>
<p/>
</div>
<div class="page"><p/>
<p>Grice&rsquo;s maxims The four basic maxims underlying the co-operative principle.
</p>
<p>These maxims make strong suggestions about how people should communicate
</p>
<p>with other people. When these suggestions are followed, communication is
</p>
<p>more successful and more satisfying.
</p>
<p>GUI (Graphical user interface) A user interface that is made up of graphical
</p>
<p>objects, such as icons.
</p>
<p>Gulf of evaluation The gap between the concepts used in the physical system and
</p>
<p>the user&rsquo;s psychological representation of those concepts.
</p>
<p>Gulf of execution The gap between the user&rsquo;s (psychological) goals and inten-
</p>
<p>tions and the physical actions they need to take to achieve those goals.
</p>
<p>Habituation Becoming so used to a stimulus that it becomes unnoticeable. (This
</p>
<p>is very similar to desensitization.)
</p>
<p>Haptic devices Devices which utilize touch and tactile feedback. Most haptic
</p>
<p>devices only support interaction using the hands or fingers, even though users
</p>
<p>could use any part of their body. There is a growing number of devices that
</p>
<p>support input using the feet.
</p>
<p>Hard mental operations One of the cognitive dimensions. It relates to the fact
</p>
<p>that users find some kinds of operations harder to perform than others, so they
</p>
<p>prefer easier mental operations.
</p>
<p>HCI (Human&ndash;computer interaction) The study of how people interact with
</p>
<p>technology. The abbreviation is also sometimes used to refer to Human&ndash;
</p>
<p>Computer Interface.
</p>
<p>Heuristic evaluation A relatively informal way of analyzing the usability of an
</p>
<p>interface design in which a small select number of people are asked to judge the
</p>
<p>design based on a set of guidelines or principles together with their own
</p>
<p>knowledge.
</p>
<p>Hicks law An equation that is used to describe the time to make a decision based
</p>
<p>on the number of available choices. Also called the Hick&ndash;Hyman Law.
</p>
<p>Hidden dependencies One of the cognitive dimensions. They show how visible
</p>
<p>the relationships between design components are, describing the number and
</p>
<p>direction of those relationships.
</p>
<p>Hierarchical task analysis (HTA) A method for analyzing in detail how tasks
</p>
<p>are performed by decomposing goals into subgoals. It is often described in
</p>
<p>terms of decomposing tasks into sub-tasks.
</p>
<p>Human factors The field that is concerned with providing a good fit between
</p>
<p>people and their work or leisure environments. Often used interchangeably with
</p>
<p>Ergonomics.
</p>
<p>Glossary 421</p>
<p/>
</div>
<div class="page"><p/>
<p>Human-centered design (HCD) An expansion of the User-Centered Design
</p>
<p>approach which extends the focus from the user&rsquo;s interaction with the system to
</p>
<p>considering how human capabilities and characteristics are affected by the
</p>
<p>system beyond direct interaction with the interface or system itself.
</p>
<p>Iconic memory A store where perceptual images are held for a short period of
</p>
<p>time. Visual iconic memory, for example, holds only a few items and these
</p>
<p>decay fairly quickly.
</p>
<p>Ill-structured problem Some problems are more difficult than others because
</p>
<p>they are ill-structured, that is, they are not clearly defined in terms of states,
</p>
<p>goals, and actions that are available. Also called ill-defined or messy problems.
</p>
<p>Implicit memory A hypothesized store of items that cannot be explicitly repor-
</p>
<p>ted. Most procedural information cannot be explicitly reported. Often used in
</p>
<p>contrast to Explicit memory.
</p>
<p>Information Information can be thought of as organized data.
</p>
<p>Information architecture A term used to describe how on-line information is
</p>
<p>structured to support usability by both its creators and its users.
</p>
<p>Information scent Information scent is what leads a user to spend more time
</p>
<p>exploring a web page (or menu item) to find what they are looking for because
</p>
<p>the content effectively smells like the thing they are looking for. The idea is to
</p>
<p>make sure that objects and links appear to smell like the content they contain
</p>
<p>and do not smell like content that they do not contain.
</p>
<p>Insight problems A class of problems where novel behavior or understanding is
</p>
<p>required to solve them. Sometimes called &lsquo;&lsquo;Aha&rsquo;&rsquo; problems.
</p>
<p>Interaction design (IxD) An approach to designing interactive products and
</p>
<p>systems to support the way that people interact and communicate.
</p>
<p>Intrinsic motivation The motivation to do something that arises directly from a
</p>
<p>person&rsquo;s inherent needs and desires.
</p>
<p>Introspection The examination of your own mental experiences. It can be a
</p>
<p>source of insight but has been proven to be unreliable in general.
</p>
<p>Just noticeable difference (JND) The smallest change in a perceptual stimulus
</p>
<p>that is noticeable by a user.
</p>
<p>Keystroke level model (KLM) A simplified version of GOMS. It provides a
</p>
<p>quick and approximate way to calculate how long users will take to perform a
</p>
<p>cognitively manageable (unit) task.
</p>
<p>Kinesthesis Kinesthesis (or the kinesthetic sense) generates an awareness of static
</p>
<p>and dynamic body posture based on information coming from the muscles,
</p>
<p>joints, and skin, along with a copy of the signal sent to the motor system.
</p>
<p>422 Glossary</p>
<p/>
</div>
<div class="page"><p/>
<p>KSA (knowledge, skills, and attitudes) Individual (or team) competencies that
</p>
<p>influence behavior.
</p>
<p>Learnability How easy it is to learn to use the system.
</p>
<p>Learning curve A graphical representation of performance that is assumed to
</p>
<p>reflect the learning that has occurred through practice. The shape of the curve
</p>
<p>reflects how response time changes with practice on a task. The curve is often
</p>
<p>described by a power law function and sometimes as an exponential function.
</p>
<p>Loftus effect Refers to the fact that when people are presented with misleading
</p>
<p>information between the encoding of another piece of information and its later
</p>
<p>recall, the recall of the original information is altered by misleading informa-
</p>
<p>tion. Often referred to as the (Loftus) misinformation effect.
</p>
<p>Long term memory An unlimited capacity store for items that have been pro-
</p>
<p>cessed or interpreted and permanently encoded.
</p>
<p>Maintainability How easy a system is to maintain and upgrade over its lifetime.
</p>
<p>Massed learning Learning that occurs when the practice is relatively or com-
</p>
<p>pletely located within a single time period.
</p>
<p>Mental model A user&rsquo;s mental model is a representation of some part of the
</p>
<p>world that can include the structures of the world (the ontology of the relevant
</p>
<p>objects), how they interact, and how the user can interact with them.
</p>
<p>Metacognition Literally cognition about cognition. It includes knowledge about
</p>
<p>when and how to use specific strategies for problem solving and learning. See
</p>
<p>also Feeling of knowing.
</p>
<p>Millisecond (ms) Abbreviated ms, this is one thousandth of a second.
</p>
<p>Mistake A failure in planning. Refers to an action that was performed correctly
</p>
<p>but in the wrong circumstances.
</p>
<p>Mnemonic Mnemonics are techniques that help to increase the amount or quality
</p>
<p>of information that can be stored, or the speed at which can it be retrieved.
</p>
<p>Model human processor (MHP) One of the first simple integrated descriptions
</p>
<p>of psychological knowledge relating to error-free human performance in HCI.
</p>
<p>Need for cognition Refers to the fact that some users like to think, and seek out
</p>
<p>opportunities to think, problem solve, and learn.
</p>
<p>Normative behavior A term used to describe what people should do, rather than
</p>
<p>what they really do.
</p>
<p>Open loop behavior A pattern of behavior in which users anticipate what will
</p>
<p>happen next in a particular situation, and take actions on that basis. There is
</p>
<p>little or no need to monitor the results of the actions. Also described as feed-
</p>
<p>forward control.
</p>
<p>Glossary 423</p>
<p/>
</div>
<div class="page"><p/>
<p>Operators Generally used to refer to users who work in industrial settings such as
</p>
<p>nuclear power stations and chemical plants.
</p>
<p>Parafovea The area of the retina that immediately surrounds the fovea. It pro-
</p>
<p>vides a lower level of visual acuity than the fovea.
</p>
<p>Periphery The area of the retina beyond the parafovea. Visual acuity is at its
</p>
<p>lowest in the periphery and vision is only in black and white.
</p>
<p>Pop-out (effect) Refers to the effect that some stimuli appear to &lsquo;pop out&rsquo; of a
</p>
<p>visual field based on color, size, shape, or other unique and easy to distinguish
</p>
<p>features.
</p>
<p>Post-completion errors Errors that arise when the main goal for a task has been
</p>
<p>accomplished, but the goals of the subtasks have not.
</p>
<p>Power law of learning A mathematical description of how learning takes place
</p>
<p>over time. Usually represented by an equation of the form RT = aP-b ? c,
</p>
<p>where RT is the response time for a particular trial, P, and a, b, and c are all
</p>
<p>constants.
</p>
<p>PQ4R A method of studying designed to help readers retain more from what they
</p>
<p>read. It stands for Preview, Question, Read, Reflect, Recite, Review.
</p>
<p>Premature commitment One of the cognitive dimensions. It relates to the situ-
</p>
<p>ation where design decisions have to be made before all of the required
</p>
<p>information is available.
</p>
<p>Primacy effect Refers to the fact that the items presented at the start of a list of
</p>
<p>items to be learned are subsequently better recalled than items in the middle of
</p>
<p>the list in a free (unprimed) recall situation.
</p>
<p>Priming Used with respect to learning to refer to the presentation of a particular
</p>
<p>experience which makes the responder more sensitive or responsive to a wide
</p>
<p>range of stimuli.Used with respect to memory to refer to the triggering of the
</p>
<p>recall of related items, e.g., &lsquo;&lsquo;yellow&rsquo;&rsquo; would prime the recall of &lsquo;&lsquo;banana,&rsquo;&rsquo;
</p>
<p>&lsquo;&lsquo;custard,&rsquo;&rsquo; and other items that are yellow in color.
</p>
<p>Problem solving Problem solving essentially involves working out how to get
</p>
<p>from the current state of affairs to the goal that you are trying to achieve by
</p>
<p>taking appropriate actions. More formally, this can be described as applying
</p>
<p>operators to states to reach a goal.
</p>
<p>Procedural memory A hypothesized store which holds procedures that encap-
</p>
<p>sulate how to do a particular task, such as how to move a knight in chess.
</p>
<p>Programmable user models (PUMs) A psychologically constrained architecture
</p>
<p>which an interface designer programs to simulate a user performing a range of
</p>
<p>tasks with a proposed interface.
</p>
<p>424 Glossary</p>
<p/>
</div>
<div class="page"><p/>
<p>Recency effect Refers to the fact that the items presented at the end of a list of
</p>
<p>items to be learned are subsequently better recalled than items in the middle of
</p>
<p>the list in a free (unprimed) recall situation.
</p>
<p>Recognition-primed decision making (RPDM) An approach to decision making
</p>
<p>which suggests that experts do not do problem solving, but that they recognize
</p>
<p>the particular situation (through perception) which directly leads them to make
</p>
<p>decisions about the correct actions to take.
</p>
<p>Reliability When referring to evaluation, reliability describes the ability of a
</p>
<p>particular measure to produce consistent results when the same things are
</p>
<p>measured under different conditions. Often used in the context of test&ndash;retest
</p>
<p>reliability.When referring to systems, it refers to a dynamic property of the
</p>
<p>eventual system which relates to the ability of the system to function under
</p>
<p>stated conditions for a specified period of time.
</p>
<p>Repetitive strain injury (RSI) A condition arising from upper limb disorders.
</p>
<p>Retrieval biases Describes the inherent biases within people that affect what they
</p>
<p>recall from memory. They include primary effects, recency effects, and the von
</p>
<p>Restorff effect.
</p>
<p>Rich pictures A component part of Soft Systems Methodology. Used to represent
</p>
<p>graphically the work context based on the roles, responsibilities, and concerns
</p>
<p>of the system stakeholders.
</p>
<p>Risk-driven incremental commitment model A revised version of the spiral
</p>
<p>model which encourages incremental development of systems in an ongoing
</p>
<p>spiral process comprising requirements specification, technical exploration, and
</p>
<p>stakeholder commitment. At each stage the system development is assessed for
</p>
<p>risks to the success of the overall system.
</p>
<p>Rods A type of light receptor cell located on the retina. Rods are very sensitive to
</p>
<p>motion. See also Cones.
</p>
<p>Role-expressiveness One of the cognitive dimensions. It describes the extent to
</p>
<p>which a system reveals the goals of the system designer to the user.
</p>
<p>Satisficing A method that finds a reasonable solution taking into consideration the
</p>
<p>costs of finding a (better, more optimal) solution.
</p>
<p>Search engine optimization The process of increasing the visibility of a web
</p>
<p>page or web site in a search engine&rsquo;s organic (unpaid) search results.
</p>
<p>Sensitivity A term used to describe how much a particular measure will change as
</p>
<p>other factors change.
</p>
<p>Serial position curve A graphical representation of how the position of an item in
</p>
<p>a list affects its recall from memory. Often used to help show primacy and
</p>
<p>recency effects.
</p>
<p>Glossary 425</p>
<p/>
</div>
<div class="page"><p/>
<p>Sharp end The part of the system where the user interacts with the technology.
</p>
<p>Sometimes used in contrast to the blunt end.
</p>
<p>Short term memory (STM) A relatively limited capacity store for items that
</p>
<p>have received a limited amount of processing or interpretation. STM is
</p>
<p>somewhat analogous to the registers in a computer.
</p>
<p>Signal detection theory (SDT) A mathematical theory of the detection of
</p>
<p>physical signals based on the assumption that sensitivity to a signal depends on
</p>
<p>its intensity, the amount of noise, the user&rsquo;s motivation, and the criterion set for
</p>
<p>registering responses to the signal. Sometimes referred to as the Theory of
</p>
<p>Signal Detection (TSD).
</p>
<p>Slip A failure in the execution of an action. Refers to performing the wrong action
</p>
<p>in the right circumstances.
</p>
<p>Social capital A concept that highlights the value of social relations and the role
</p>
<p>of cooperation and confidence in establishing trusts and norms to get collective
</p>
<p>results.
</p>
<p>Socio-technical systems Systems that involve a complex interaction between
</p>
<p>humans, machines, and the environmental aspects of the work system. (Now-
</p>
<p>adays this description applies to most enterprise systems.)
</p>
<p>Soft systems methodology Essentially an analytical approach, mostly focusing
</p>
<p>on organizational aspects of the system. It does not purport to support systems
</p>
<p>design.
</p>
<p>Spiral model A model of the system development lifecycle, which uses an iter-
</p>
<p>ative development process.
</p>
<p>S&ndash;R (Stimulus&ndash;response) compatibility Refers to the fact the response should be
</p>
<p>compatible with the stimulus that causes it. This is typically exploited in the
</p>
<p>way that physical aspects of an interface (e.g., buttons) and displays (e.g.,
</p>
<p>GUIs) are mapped onto the world that they are representing. It also explains
</p>
<p>why the call buttons for elevators are situated with the &lsquo;&lsquo;up&rsquo;&rsquo; button above the
</p>
<p>&lsquo;&lsquo;down&rsquo;&rsquo; one.
</p>
<p>Stimulus&ndash;response mapping The mapping between the stimulus that the users
</p>
<p>see to the responses that they produce. Mappings that are simple and similar to
</p>
<p>previous mappings lead to faster, less error-prone interactions.
</p>
<p>Subitizing The ability to determine directly the number of objects the user is
</p>
<p>looking at without counting them. This only works for small numbers of
</p>
<p>objects.
</p>
<p>Summative evaluation A type of evaluation used to assess the success of the
</p>
<p>finished system or product, summarizing its overall impact and effectiveness.
</p>
<p>426 Glossary</p>
<p/>
</div>
<div class="page"><p/>
<p>Task-action mapping Describes the relationship between the domain of the task
</p>
<p>and the domain of actions. Ideally there should be a simple and direct mapping
</p>
<p>between the two.
</p>
<p>THEA (Technique for human error assessment) Method for analyzing erro-
</p>
<p>neous performance using an iterative process. Like the CREAM it assumes that
</p>
<p>the context is a major influence on performance.
</p>
<p>THERP (Technique for human error rate prediction) An approach to mod-
</p>
<p>eling errors in human performance. The probability of errors occurring is
</p>
<p>conditioned by performance shaping factors as a way of taking into account the
</p>
<p>context in which the error happens.
</p>
<p>Threshold The smallest energy level in a stimulus that can be detected by a user.
</p>
<p>Tower of Hanoi A task used to study problem solving. It has three pegs or posts,
</p>
<p>and disks, typically three to eight, but in theory there could be any number of
</p>
<p>disks.
</p>
<p>Transfer (of learning) Where learning on one task has an effect (either positive
</p>
<p>or negative) on a task that is performed later.
</p>
<p>Upper limb disorders (ULD) Aches, pains, tension, and disorders that involve
</p>
<p>any part of the arm from fingers to shoulder or neck. They include problems
</p>
<p>with the soft tissues, muscles, tendons, and ligaments, as well as with the
</p>
<p>circulatory and nerve supply to the limbs. Often caused or exacerbated by work
</p>
<p>and, particularly, repetitive work. They lead to conditions such as repetitive
</p>
<p>strain injuries.
</p>
<p>Usability A multi-faceted concept used to represent how easy a system is to use,
</p>
<p>how easy it is to learn to use, how safe it is, how effective (and efficient) it is,
</p>
<p>and how satisfying it is to use.
</p>
<p>Usability testing A term usually restricted to describe the evaluation of the
</p>
<p>usability of a system under controlled (laboratory) conditions.
</p>
<p>User experience (UX) The user&rsquo;s perceptions and responses that result from the
</p>
<p>use or anticipated use of a product, system or service. Some people regard UX
</p>
<p>as representing a broader view than usability.
</p>
<p>User-centered design (UCD) An approach that focuses on the user&rsquo;s needs,
</p>
<p>carrying out an activity/task analysis as well as general requirements analysis,
</p>
<p>performing early testing and evaluation and designing iteratively.
</p>
<p>Users Generally refers to people who use artifacts (systems, devices, and so on).
</p>
<p>There are several types of user, including operators, pilots, and drivers.
</p>
<p>Validity A term used to refer to whether the particular measure that you are using
</p>
<p>is really measuring what it is supposed to be measuring. There are several types
</p>
<p>of validity.
</p>
<p>Glossary 427</p>
<p/>
</div>
<div class="page"><p/>
<p>Viscosity One of the cognitive dimensions. It reflects how hard it is to change
</p>
<p>something within a system.
</p>
<p>von Restorff effect Refers to the fact that a single item that is made distinctive in
</p>
<p>a list of otherwise similar items will be easier to learn and subsequently recall.
</p>
<p>WIMP (windows, icons, menus, and pointer) A shorthand description for a type
</p>
<p>of graphical user interface, using the elements that appear in that interface.
</p>
<p>Sometimes used interchangeably with GUI, but, strictly speaking, not all GUIs
</p>
<p>are WIMPs.
</p>
<p>Working memory A hypothesized temporary store (an audio or semantic
</p>
<p>scratchpad) with associated mechanisms for rehearsing, refreshing, and using
</p>
<p>the stored information. It also includes a mechanism of central or executive
</p>
<p>attention that regulates the contents of that store based on performing a task.
</p>
<p>428 Glossary</p>
<p/>
</div>
<div class="page"><p/>
<p>Index
</p>
<p>Symbols
</p>
<p>b Beta, threshold, from signal detection theory,
84, 85
</p>
<p>H theta, k lambda, 84
</p>
<p>A
</p>
<p>Abbreviations, 126
ABCS, v, xxv, xxvi, 3, 16, 23, 24, 277, 281,
</p>
<p>386&ndash;391, 410
Accessibility, 394
Accident, 9, 13, 21, 46, 176, 281&ndash;283, 286,
</p>
<p>287, 413&ndash;417
Accountability, 240, 303
Acoustical loop, 127
Activity theory, 45, 326
ACT-R, 23, 24, 43, 126, 134, 140, 392,
</p>
<p>395&ndash;397
Acuity, 86, 87, 92
Adaptability, 46, 238, 290
Aesthetic, 419. See also Esthetics
Affordances, 19, 58, 59, 237, 347
Aids to memory, 131, 336, 370, 371, 392, 393,
</p>
<p>395, 397
Aircraft, 9, 10, 13, 14, 18, 21, 22, 28, 49, 84,
</p>
<p>111, 145, 153, 154, 160, 169, 176,
226, 283, 286&ndash;288, 301, 345, 405,
413&ndash;417
</p>
<p>Airport
Dulles, 173
London, 173
Philadelphia, 169, 170
</p>
<p>Air traffic controller(s) and control (ATC), 13,
22, 226, 283, 287
</p>
<p>Alarm, 44, 83&ndash;85, 112, 116, 319, 387
Alerts, 111, 112
Allocation of function, 39, 311
Americans with Disabilities Act, 15
Anthropometrics, 16, 18, 28, 50, 59, 76, 77,
</p>
<p>343, 351, 386, 387, 389
</p>
<p>implications for system design, 17, 57, 82,
85, 91, 98, 111, 115, 136, 144, 155,
173
</p>
<p>Apple design guidelines, 46
Arms, 18, 60, 67, 92
Arthritis, 58, 287
Assessment, 35, 47, 118, 217, 319, 388
Assessment of Repetitive Tasks
</p>
<p>(ART) tool, 60
Association for Computing Machinery
</p>
<p>(ACM), 45
Astronauts, 74, 267
Attention, 8, 9, 20, 22, 60, 85, 91, 113, 118,
</p>
<p>123, 124, 137&ndash;141, 144, 146, 275,
276, 286, 287, 301, 318, 341, 343,
371, 388, 410
</p>
<p>divided, 141
implications for system design, 85, 144
Wickens theory of attentional resources, 139
</p>
<p>Attributions and attributional style, 230, 231
Attribution theory, 10, 38, 228, 230&ndash;232, 246
Audio, 362, 387
Audio&ndash;visual, 9, 362, 411, 413
Audition/auditory, 74, 75, 82, 106, 109, 119,
</p>
<p>158
Auditory system, 82, 106
Authority figures, 236, 244, 246
Automatic usability inspection, 11
Automation, 21, 301
Automation deficit, 143, 144
Automobiles, see Car interfaces, driving
Availability bias, 189
Avatar, 255
Awareness, 38, 62, 95, 238, 286, 360, 389
</p>
<p>B
</p>
<p>Backtracking, 177
Behavioral approach, 204, 211, 214, 218, 246,
</p>
<p>343, 408
</p>
<p>F. E. Ritter et al., Foundations for Designing User-Centered Systems,
DOI: 10.1007/978-1-4471-5134-0, ï¿½ Springer-Verlag London 2014
</p>
<p>429</p>
<p/>
</div>
<div class="page"><p/>
<p>implications for system design, 85
Better products, 11
Biases, 84, 85, 124, 134, 151, 158, 166, 177,
</p>
<p>188, 189, 193, 197, 198, 290, 291,
373, 389
</p>
<p>Biases in reasoning, 193, 195
Blind, 8, 75, 90, 111
Blind spot, 389
Blunt end, 288, 302
Bobby (web site testing tool), 394
Breakout boxes, 181, 193&ndash;196
Brightness, 91, 93, 95, 102
Button, 5, 18, 20, 59, 65, 68, 70, 72, 75, 148,
</p>
<p>151, 157, 171, 183&ndash;188, 201, 323,
339, 344, 354
</p>
<p>C
</p>
<p>Calibrated, 171, 195, 198, 372
Camera, eye like, 86, 88, 101, 117, 371
Capabilities, 4, 13, 20, 33, 39, 46, 50, 57, 58,
</p>
<p>76, 119, 171, 184, 196, 231, 385,
387, 390&ndash;392, 405, 407
</p>
<p>Car interfaces, 19, 289
Categories, 50, 64, 69, 119, 124, 129, 185,
</p>
<p>286, 292, 294, 362, 393
Caterham Formula 1 team, 58
Cause&ndash;effect, 359
CD writer, 170
Cell phone, 3, 8, 11, 138, 173, 303, 314, 354,
</p>
<p>387
Channels, 74, 82, 272
Checklists, 9, 8, 22, 175
CHI conference, 27
Choice shift in decision making, 226
Circuit schematic, 167
Citeseer, 11
Classical ergonomics/interface ergonomics, 37
Classification, 28, 84, 150, 167, 292, 294, 328
Clearview Hwy font, 206
Closed loop behavior, 142, 153
CMN-GOMS, see KLM GOMS
Cockpits, 9, 58, 226, 287, 345
Cockpit resource management, 226, 287,
</p>
<p>415&ndash;417
Cocktail-party effect, 139
Cognitive, 16, 20, 21, 23, 24, 28, 39, 40, 42,
</p>
<p>83, 100, 105, 125, 138, 145, 149,
159, 181, 213, 231, 242, 281, 288,
294, 311, 317, 320, 324, 325, 328,
329, 336, 343, 349, 350, 386, 388,
393, 395, 397
</p>
<p>approach, 350
architecture, 23, 24, 42, 149, 193, 392,
</p>
<p>395, 408
</p>
<p>dimensions, 51, 335&ndash;343
hard mental operations, 337, 341, 342
hidden dependencies, 336, 337
premature commitment, 337, 340
role-expressiveness, 337, 339
turning cognitive dimensions into a
</p>
<p>methodology, 342
viscosity, 337, 338
what is omitted, 343
</p>
<p>Cognitive dissonance, 231
Cognitive ergonomics/ systems engineering,
</p>
<p>39, 145
Cognitive modeling, 42, 52, 159, 326
Cognitive reliability and error analysis method
</p>
<p>(CREAM), 294, 295, 297&ndash;300, 302
Cognitive systems engineering (CSE), 39, 40,
</p>
<p>410
Cognitive task analysis (CTA), 317&ndash;319,
</p>
<p>329
components, 317
example application, 318
</p>
<p>Cognitive walkthroughs, 318
Coins, 7, 8, 101
Collision, 284
Color
</p>
<p>blindness, 95
perception of, 95, 100
systems, 95, 96
vision, 94, 95
</p>
<p>Command-line, 33
Commands, 7, 124, 131&ndash;132, 142, 151, 155,
</p>
<p>157, 242, 277, 320, 321, 328, 344
Common ground, 201, 243, 256
Communicate, 9, 21, 22, 25, 26, 70, 72, 74,
</p>
<p>201, 202, 204, 212, 218, 219, 226,
234, 237, 245, 246, 248, 253, 256,
262, 268, 270, 271, 287, 299, 318,
386, 406
</p>
<p>Communities, 43, 226, 240, 259, 268, 296
Communities of practice, 268
Competent/competencies, 153, 195, 234, 319,
</p>
<p>329
Complexity, 198, 347, 398, 408
Comprehend, 133, 136, 205, 208, 209, 217,
</p>
<p>218
Computational model, 192, 204, 272&ndash;273, 276
Computational models of social behavior, 272,
</p>
<p>276
Computer-based prototypes, 367
Computer&ndash;Human Interaction, 45
Computer&ndash;Human Interaction Special Interest
</p>
<p>Group of the Association for Com-
puting Machinery (ACM-SIGCHI),
27
</p>
<p>Computer-mediated communication, 34, 219
</p>
<p>430 Index</p>
<p/>
</div>
<div class="page"><p/>
<p>Computer-supported co-operative work
(CSCW), 41, 219, 276, 248
</p>
<p>Concurrency in system development, 402
Concurrent, 140, 370, 371, 401, 403
Cones [eye], 89, 91, 95, 207, 211, 217, 372
Confidence judgments, 171. See also Feeling
</p>
<p>of knowing
Confirmation bias, 189, 193
Confuse, 8, 20, 45, 48, 73, 111, 134, 173, 283,
</p>
<p>301, 340
Conscious, 4, 139, 146, 348
Consciousness, 8, 152, 389
Considerations when choosing a TA method,
</p>
<p>326
Consistency, 47, 135, 320, 329, 337, 339, 340,
</p>
<p>348, 358, 365
Construct validity, 358, 359
Content
</p>
<p>strategy, 315, 316
validity, 359
</p>
<p>Context, 15, 25, 34, 40, 44, 45, 63, 85, 105,
115, 119, 127, 134, 136, 169, 193,
198, 211, 212, 218, 220, 225, 226,
235, 236, 244, 247, 264, 266, 267,
270, 281, 282, 286, 287, 291, 293,
299, 300, 309, 318, 319, 326, 327,
336, 349, 356, 360, 361, 363, 369,
374, 386, 388, 403, 404, 407&ndash;409
</p>
<p>Contextual design, 266
Contrast, 92&ndash;94, 102, 207, 209
Controls, 5, 18, 37, 75, 187, 288, 322, 344,
</p>
<p>347, 348, 387
Conversations, 108, 109, 139, 201, 203, 254,
</p>
<p>256, 326, 361, 389
Co-operative
</p>
<p>evaluation, 335, 366
principle, 203, 204
</p>
<p>Co-pilot, 286, 287. See also Pilot
Correct rejections, 84, 120
Cost savings, 110
CPM-GOMS, 320, 322
Creating content, 216
CRM, see Cockpit resource management
Crosstalk journal, 406
CTA, see Cognitive task analysis
Cultural effects, 265, 275
Culture, 17, 22, 34, 45, 187, 218, 227, 235,
</p>
<p>240, 247, 253, 264, 265, 267, 275,
303, 391, 406
</p>
<p>D
</p>
<p>d&rsquo; (dprime), 84
Danger, 13, 85, 118, 285, 302, 313, 339, 348,
</p>
<p>391
</p>
<p>da Vinci surgical system, 63
DBLP, 11
Decibels (dB), 108
Decision making, 9, 37, 122, 42, 133, 165,
</p>
<p>176, 184, 188, 190&ndash;193, 197, 198,
206, 216, 225&ndash;228, 228, 233, 234,
245, 247, 274, 317, 389, 410
</p>
<p>attributions and attributional style, 230,
231
</p>
<p>implications for system design, 192
known influences on, 176, 188
majority and minority effects, 233
often not rational, 184
social effects on, 228
social responsibility effects, 228
</p>
<p>Decision-support, 192, 318
Declarative memory/knowledge, 23, 128, 129,
</p>
<p>140, 146, 151, 156, 267, 320, 328,
393
</p>
<p>Delivering content, 215, 218
Dependability, 282, 318
Depth cues, 101, 102, 105
Descriptive behavior, 196
Descriptive social models, 267
Design, 4, 6, 7, 9, 10, 12, 15, 16, 18, 24&ndash;28,
</p>
<p>33&ndash;35, 37, 38, 42, 44, 45, 47, 49,
57, 76, 124, 132, 136, 142, 144,
149, 155, 160, 167, 169, 171, 173,
179, 181, 183, 185, 187, 188, 192,
196, 197, 201, 204, 206, 211, 218,
231, 258, 261, 273, 287, 300, 313,
326, 335, 342, 344, 346, 349, 355,
359, 365, 368, 389, 391, 395, 406
</p>
<p>Design of content, 215&ndash;218
content strategy, 215
creating content, 216
delivering content, 218
information architecture, 216
structuring content, 217
</p>
<p>Design patterns, 406
Designer, 3&ndash;5, 8, 10, 11, 22, 24, 33, 34, 37, 42,
</p>
<p>46, 47, 49, 57, 58, 65, 67, 74, 81,
93, 105, 112, 134, 166, 182, 192,
196, 309
</p>
<p>Designers are stakeholders too, 405
Development, 4, 22, 33, 37, 39, 44, 46, 49, 60,
</p>
<p>169, 188, 216, 238, 240, 244, 269,
301, 309, 317, 329, 348, 353&ndash;357,
364, 367, 377, 386, 390, 398&ndash;400,
402, 403, 405&ndash;407, 409
</p>
<p>Devices, 10, 13, 19, 20, 28, 36, 59, 62, 63, 65,
66, 70, 75
</p>
<p>cell phone, 314, 330
X-ray machine, 13
other, 72
</p>
<p>Index 431</p>
<p/>
</div>
<div class="page"><p/>
<p>Diabetes, 74, 75
Diagnose, 13, 143, 166, 227, 365
Dialogues, 132, 142, 202, 371
Differences, individual, 34, 40, 127, 181
Diffusion of social responsibility, 228, 230,
</p>
<p>246
Digital Equipment Corporation (DEC), 41
Disabilities, 17, 63
Disasters, 22, 28, 247, 284, 345, 346
Discriminate, 8, 86, 94, 95, 97, 111, 142, 370
Discriminating sounds, 111
Distinctive, 112, 125, 313, 319
Distinguish, 12, 62, 63, 150, 282, 310, 320,
</p>
<p>370
Distracted, 22, 98, 145, 286, 287
Distributed learning/practice, 133, 152
Diversity, 26, 236, 238, 239, 366
Divided attention, 141
Driving, 70, 128, 139, 141, 146, 185, 310, 409
Dulles airport, 173
Dunbar number, 261, 262
</p>
<p>E
</p>
<p>Ear, 106&ndash;108, 110, 117
E-commerce, 213
Eclipse, 68, 77
Ecological validity, 290&ndash;292, 358, 360, 361
Effectiveness, 48, 357, 359
Effective technical and human implementation
</p>
<p>of computer-based systems (ETH-
ICS), 41
</p>
<p>Efficiency, 47&ndash;49, 225, 313, 365, 369
of a system, 48, 357
</p>
<p>Efficient, 3, 10, 48&ndash;50, 52, 150, 178, 219
Effort, 4, 15, 20, 143, 145&ndash;147, 175&ndash;176, 189,
</p>
<p>192, 218, 238, 326, 338, 344, 356,
372, 374&ndash;376, 400, 409
</p>
<p>Einstellung effects, 177
Ejector seats, 18
Elbows, 10, 36, 142
Elderly, 8, 58, 59
Email, 10, 36, 142, 180, 188, 189, 218, 229,
</p>
<p>232, 242, 246, 257, 261, 262, 276
why it has gone awry, 232
</p>
<p>Emergencies, 228, 413&ndash;417
Emergent, 269, 301, 392
Emotions/feelings, 44, 373
Empirical, 313, 261, 392
</p>
<p>evaluation, 353
Encoding effects, memory, 128, 134
Engineering, 225, 353, 385
Enjoyable, 3, 50
Entertainment, 181, 226
EPIC cognitive architecture, 396
</p>
<p>Episodic memory, 140
Ergonomics, 17, 34, 35, 38, 46, 96, 284, 314,
</p>
<p>319
Errors, 204, 208, 281&ndash;285, 288, 290, 292&ndash;297,
</p>
<p>299, 320, 322, 324, 325, 341, 343,
347, 365, 369, 370, 375, 387, 388,
391, 392, 395, 397, 410
</p>
<p>analyzing, 296, 300
archive data, 291
ergonomics, 38
event trees, 296
fault trees, 296
field-based observation, 290
implications for design, 142, 300
introduction to, 3, 281
keystroke rate, 324
laboratory-based experiments, 289
latent, 282
omisions, 292
post-completion, 180, 181
reduction, 287
selecting the most appropriate data col-
</p>
<p>lection method, 289&ndash;291
studying, 12, 288&ndash;292
taxonomies, 292
typing, 13, 64, 158, 160, 303, 395, 397
usability measure, 320, 370
what is, 282
</p>
<p>Esthetics, 26&ndash;28, 45, 46, 75, 365, 205, 207,
212, 419
</p>
<p>Ethics, effective technical and human imple-
mentation of computer-based sys-
tems, 41
</p>
<p>Ethics of evaluation, 376
Ethnography, 41, 267
Evaluate, 12, 21, 25, 34, 43&ndash;45, 50, 51, 196,
</p>
<p>242, 262, 263, 270, 284, 292, 329,
337, 344&ndash;346, 348, 350, 354, 356,
358, 361, 362, 365&ndash;367, 369, 374,
376, 404
</p>
<p>Evaluation methods
co-operative evaluation, 335, 366
heuristic (expert) evaluation, 365, 366
usability testing field studies and field
</p>
<p>experiments, 362, 364
Evaluation study, 356, 358, 360
Event tree, 296
E-voting system, 65
Exchange costs and benefits, 256
Experiments, 4, 5, 46, 101, 114, 119, 155, 158,
</p>
<p>184, 228, 233, 242, 261, 289, 357,
364, 397
</p>
<p>Expert, 12, 15, 20, 34, 37, 39, 45, 48, 64, 97,
131, 132, 145, 147, 154, 175, 211,
217, 246, 284, 290, 293, 301, 319,
</p>
<p>432 Index</p>
<p/>
</div>
<div class="page"><p/>
<p>324, 329, 359, 362, 365, 366, 371,
387
</p>
<p>Expert (heuristic) evaluation, 362, 365, 366
Explicit memory, 129, 130
Exploration, 7, 25, 62, 66, 72, 76, 89, 135, 156,
</p>
<p>198, 214, 234, 272, 336, 340, 392,
399, 400
</p>
<p>External validity, 358, 360
Extrinsic motivation, 114, 115, 120, 243, 245,
</p>
<p>246, 274
Eyes, 74, 86&ndash;93, 95, 97, 100, 101, 105, 117,
</p>
<p>118, 207, 211, 217, 356, 372
smooth pursuit movements, 101, 226
</p>
<p>Eye movements, 372
Eye-strain, 60
Eye-tests, 86
Eye-tracker, 88, 89, 372
Eyewitness, see Loftus effect
</p>
<p>F
</p>
<p>Face validity, 289, 359
Factors affecting team performance, 234
</p>
<p>authority figures, 235
implications for design, 243
mutual support and mutual surveillance,
</p>
<p>235, 240
social distance, 235, 240
spatial distance, 235, 240
task attractiveness, 235
team competencies, 153
team processes and tasks, 269
team size, 236, 236
team structure and composition, 235, 237
</p>
<p>Failure, 7&ndash;9, 14, 21, 26, 49, 124, 128, 131,
191, 231, 247, 260, 282, 284, 286,
293, 385, 407
</p>
<p>False alarms, 84&ndash;86, 120
Fatigue, 38, 208, 288
Fault&ndash;error&ndash;failure model, 282
Faults, 175, 225, 282, 296, 354
Fault trees, 296, 303
Feedback, 13, 21, 26, 46, 48, 57, 63, 65, 66,
</p>
<p>70, 72&ndash;75, 88, 141, 144, 343, 346,
348, 355, 377
</p>
<p>Feedforward, 141
Feeling of knowing (FoK), 124, 171
Field-based observation, 290
Field experiments, 364, 368
Field of view, 93, 94, 101
Field studies, 362, 364
Figure and ground, 93, 103
Filter, 90, 110, 276
Final system, what to evaluate, 367
</p>
<p>Fingers, 64, 65, 110, 60, 63, 67, 69, 70, 131
Fingertips, 74
Fire, 9, 155, 192, 296
Fire-fighting, 192
Fitting the man to the job and the job to the
</p>
<p>man (FMJ/FJM), 36
Fitts&rsquo; law, 324, 325, 407
Fitts list, 19, 311
Fixated, 177, 179, 372
Fixation (eye), 211
Flesch&ndash;Kincaid reading index, 217
Flexibility, 47, 48, 363, 365
Flicker, 92, 96, 100
Flight, 9, 36, 38, 144, 176, 226, 227, 283, 286,
</p>
<p>413&ndash;417
Focus, 25, 33, 34, 43, 44, 48, 91, 101, 166,
</p>
<p>184, 202, 214, 225, 227, 270, 289,
299, 336, 340, 343, 366
</p>
<p>Fonts, 20, 27, 148, 206, 207, 210, 218, 221,
335, 389
</p>
<p>Foolishness, 195
Forcing function, 19, 20
Forgetting, 57, 128, 143, 208, 301, 338
Formative evaluation, 357, 370, 377
Formula 1, 58
Fourier transform, 106, 108
Fovea, 87, 88, 95, 389
Framing effects (in decision making), 190
Frequency, 11, 106&ndash;108, 110, 111, 331, 141,
</p>
<p>205, 247, 290, 296, 357
Frustration, 155, 373, 375
Functional fixedness, 177, 178
Functionality, 4, 14, 15, 20, 26, 27, 47, 49, 62,
</p>
<p>74, 165, 168, 177, 208, 364, 366,
367
</p>
<p>Function allocation, 301
Fundamental attribution error, 10, 24, 231
</p>
<p>of design, 10, 231
</p>
<p>G
</p>
<p>Games, 22, 60, 74, 101, 116, 120, 141, 142,
151, 177, 180, 242, 249, 256&ndash;258,
313, 344, 359, 398, 410
</p>
<p>Gaze, 66, 105, 118
Generalities of human behavior, 386&ndash;391
Generic Error Modeling System
</p>
<p>(GEMS), 293, 294
Geographic, 112, 240
Geometric, 112, 146, 193
Gestalt principles of visual grouping, 103&ndash;105,
</p>
<p>138, 387
Glare, 19, 82
Glasses, 87
</p>
<p>Index 433</p>
<p/>
</div>
<div class="page"><p/>
<p>Gloves, force feedback, 70
Goal, 12, 23, 46, 147, 155, 156, 174, 175, 177,
</p>
<p>180&ndash;182, 197, 226, 231, 236, 242,
244, 246, 256, 258, 269, 274, 299,
310, 314, 319, 320, 326, 336, 339,
340, 344&ndash;346, 358, 363
</p>
<p>Goal-driven, 238
Goal-oriented, 326
Goggles, 58, 90
Golden rule, v
GOMS (goals, operators, methods and selec-
</p>
<p>tion rules), 12, 43, 318, 319, 322,
328, 335, 394, 395
</p>
<p>components, 320
example application, 320
</p>
<p>GOMSL, 320
GPS, 65, 320, 326
Graphic design to help reading and scanning,
</p>
<p>27, 205
Graphical user interfaces (GUIs),
</p>
<p>33, 34, 339
Graphics, 27, 45, 104, 176, 218, 338
Grice&rsquo;s maxims of conversation, 203&ndash;205,
</p>
<p>219, 221, 339, 389
Ground and figure, see Figure and ground
Groups, 45, 119, 126, 131, 181, 214, 221, 225,
</p>
<p>226, 228, 229, 233, 236, 238&ndash;240,
242, 247, 253, 260, 262, 264, 268,
272, 275, 360, 374, 387
</p>
<p>Groupthink, 233
GUI, see Graphical user interface
Guidelines, 8, 37, 45, 46, 241, 321, 347, 356,
</p>
<p>365, 376, 394
Gulf of evaluation, 11, 345&ndash;351
Gulf of execution, 11, 172, 345&ndash;351
Gulfs in practice, 345
Gulfs of evaluation and execution
</p>
<p>implications for design, 346&ndash;349
in practice, 345
limitations of, 349
</p>
<p>H
</p>
<p>Habituate, 62, 83, 85
Haptic, 57, 63, 70, 72, 75, 101
</p>
<p>devices, 72
interfaces, advantages and disadvantages
</p>
<p>of, 72
Hard mental operations (cognitive
</p>
<p>dimensions), 336, 337, 341&ndash;343,
351
</p>
<p>Harmonics, 108
Hawthorne effect, 360, 390
Hazards, 35, 287, 338
</p>
<p>Human&ndash;computer interaction (HCI), 14, 27,
45, 52, 70, 89, 230, 327, 354, 369,
403, 407, 410
</p>
<p>HCI bibliography project, hcibib.org, 27
Head-mounted, 88, 117
Health and safety executive (UK), 60, 61
Hearing, 23, 46, 62, 64, 81, 82, 86, 106, 108,
</p>
<p>112, 117, 127, 139, 141, 227, 301,
387
</p>
<p>Heuristic evaluation, 365, 366
Heuristics, 350, 365
Hick&ndash;Hyman Law/Hicks law, 68, 182
Hidden dependencies (cognitive dimensions),
</p>
<p>335&ndash;337, 342
Hierarchical task analysis (HTA), 299,
</p>
<p>314&ndash;317, 329
components, 314
example application, 315
</p>
<p>Higher level visual perception, 100
implications for system design, 105
</p>
<p>Hindsight, 283, 295, 302
Hits, 27, 83, 85, 292
Hospitals, 227, 270, 318, 410
How to encourage cooperation, 258
Hue, 94
Human-centered, 43, 50, 378, 405
Human-centered design (HCD), 43
Human-centered systems design
</p>
<p>(HCSD), 33
Human&ndash;computer interface(s)
</p>
<p>(HCI), 4, 14, 27, 33, 45, 52, 89, 184,
225, 230, 327, 369, 395, 410
</p>
<p>Human error rate prediction, 38, 292
Human error, see Error
Human factors, 17, 26, 27, 34, 35, 39, 45, 52,
</p>
<p>76, 192, 276, 284, 314, 341, 369,
385, 408, 409
</p>
<p>Human&ndash;Human communication, 34, 201
Human information behavior, 213
Human&ndash;information seeking behavior, 213
</p>
<p>implications for system design, 214
Human&ndash;information systems, 23
Human&ndash;machine systems, 40
Human&ndash;robot interation, 397
Human&ndash;system integration, 407
</p>
<p>I
</p>
<p>Iconic memory, 125
Icons, 33, 59, 72, 93, 120, 142, 188, 203,
</p>
<p>205, 218
Identifying the dependent and independent
</p>
<p>variables, 357
Ill-structured problems, 181, 182
</p>
<p>434 Index</p>
<p/>
</div>
<div class="page"><p/>
<p>Illuminate, 72, 88, 91, 92, 210
Images, 86, 91, 96, 101, 105, 125, 274, 340,
</p>
<p>395
Immersion, 70, 74
Immersive reality, 71
Impaired, 11, 75, 82, 111, 136, 387
Implications for system design, 82, 92, 142,
</p>
<p>183, 192, 204, 211, 214, 218, 273,
300, 387
</p>
<p>social and organizational aspects, 82, 92
Implicit memory, 129, 130
IMPRINT, 394
Incidents, 319, 364, 409
Incompetence, 193, 194, 196
Incubation in problem solving, 143
Index of difficulty, 67
Indicator, 47, 85
Individual differences, 34, 40, 127, 181
Informatics, 41
Information
</p>
<p>architecture, 215, 216, 220
processing model of attention, 140
scent, 214, 219
seeking behavior, 201, 212&ndash;215
</p>
<p>Information, 212
Infrared, 90
Input glove, 16
Insight problems, 179, 180
Instruction, 133, 135, 156, 204, 319, 324, 328,
</p>
<p>347, 363
implications for, 133, 135, 136
</p>
<p>Instructional, 156, 177
Instrument validity, 358
Intelligence, 13, 24, 43, 134, 171, 358
Interaction design (I9D), 33, 366, 378
Interface
</p>
<p>design, 12, 13, 26, 28, 45, 97, 119, 131,
155, 160, 171, 173, 204, 214, 220,
311, 313, 329, 343, 365
</p>
<p>ergonomics, 37
Interference in memory, 124
Internal validity, 358, 359, 361
International Standards Organization (ISO),
</p>
<p>44, 48, 76, 98
Inter-rater reliability, 361
Interruptions, 21, 22, 137, 142, 143, 144, 286,
</p>
<p>325, 361, 364
Interviews, 310, 318, 326
Interviews and focus groups, 190, 242, 270,
</p>
<p>374
Intrinsic motivation, 325, 343, 345
</p>
<p>implications for system design, 115, 116
Introspection, 4, 151, 370
Intuitions, 365, 390
</p>
<p>iPod, 72, 109, 189, 343
Ironies of automation, 301
</p>
<p>J
</p>
<p>Joysticks, 317, 322
Judgments, see Decision making
Just noticeable differences (JNDs), 82, 83, 85
</p>
<p>K
</p>
<p>Kegworth air disaster, 9&ndash;10, 22, 281, 345, 346,
413&ndash;417
</p>
<p>Key bindings, 151, 152, 155
Keyboards/keypads, 60, 63, 64, 69, 74, 77,
</p>
<p>151, 324, 365, 387, 397
Key, see Keystroke
Keystoke logger, 303, 375
Keystroke level model (KLM), 43, 320, 322
</p>
<p>description of components, 324
example application, 325
</p>
<p>Keystrokes, 64, 130, 132, 149, 155, 157, 322,
324
</p>
<p>Keystroke shortcuts, 132, 325
Kinesthetic information, 62, 63
Kiosks, 65, 172, 210
Kitchen, 52
Klaxons, 112
Knees, 18
Kneecaps, 18
Knobs, 6, 18, 19, 37, 182, 322
Knowledge
</p>
<p>declarative, 128, 146, 328
procedural, 140, 328
skills and attitudes (KSA), 234, 265
</p>
<p>Knowledge-based, 153, 156, 234, 293, 326
Knowledge-level, 153
</p>
<p>L
</p>
<p>Laboratory-based experiments, 289, 368
Language, 17, 33, 40, 42, 127, 129, 155, 181,
</p>
<p>197, 201&ndash;204, 219, 326, 335&ndash;338,
341, 389, 392, 394, 408
</p>
<p>implications for system design, 33, 127,
156, 204
</p>
<p>Lapses, 286, 293
Laptops, 18, 57, 208
Latent errors, 282
Leadership, 195, 238, 242, 245, 260, 390
Learnability, 47, 48, 320
Learner, 48, 131, 133, 145, 217, 242
Learning, 202, 217, 220, 246, 258, 264, 273,
</p>
<p>274, 283, 284, 290, 309, 311, 326,
</p>
<p>Index 435</p>
<p/>
</div>
<div class="page"><p/>
<p>326, 338&ndash;340, 351, 369, 388, 389,
391, 398, 402, 403, 407, 408
</p>
<p>implications for interface design, 155&ndash;158
implications for system design, 204, 214,
</p>
<p>244, 402, 408, 409
improvements from, 147&ndash;150
process of, 145&ndash;147
Rasmussen&rsquo;s theory of knowledge, 284,
</p>
<p>293, 348
stages of, 399
transfer of, 407
types of, 130, 150, 151, 157
</p>
<p>Learning and skilled behavior, 144&ndash;157
Learning curve, 148&ndash;152, 205
Learning within and between projects, 406,
</p>
<p>407
Legal, 303, 386
Legibility, 206, 219
Levers, 317, 387
Lights, 327, 369, 388, 390
Light waves, 206, 208, 290
Likeability, 48
Likelihood, 240, 245, 247, 296
Limb, 387
Line between success and failure, 284, 286
Linguistics, 202, 256
Listening, 202, 287
Lists, 322, 408
Load bearing, 62
Localizing sound, 387
Loftus effect, 135&ndash;136
London airport, 173
London ambulance dispatching system, 22
Long-term memory (LTM), 158, 321, 395, 397
Loudness, 370
Low-level visual perception, 92, 100, 103
</p>
<p>implications for system design, 98&ndash;100
Luminance, 208
</p>
<p>M
</p>
<p>MABA&ndash;MABA, 301
Maintenance, 201, 219, 238, 262, 367, 388,
</p>
<p>389
Majority and minority effects, 233
Man&ndash;computer, 354
Man&ndash;machine, 40
Massed learning, massed practice, 11, 13, 152
Mastery, 245, 246, 274
Means (average), 357
Means-ends analysis (MEA), 176
Meaning-making, 202, 203, 283
Measurement of light, 92
Measuring usability, 359, 369, 379
</p>
<p>errors, 370
eye movement tracking, 372
interviews and focus groups, 374
patterns of usage, 375
questionnaires and surveys, 373
task time, 369
user experience, 376
verbal protocols, 370
video protocols, 371
workload measures, 374, 375
</p>
<p>Medicine, 214, 272, 287
Memorability, 64, 125
Memorable, 126
Memories, 8, 20, 124, 127&ndash;129, 133, 134, 136,
</p>
<p>140, 141, 145, 151, 156, 190, 217,
388, 395
</p>
<p>Memorize, 7, 28, 124, 167
Memory
</p>
<p>aids, 135, 395
biases, 133
declarative, 129
encoding effects, 134
episodic, 124, 140
iconic, 124
implications for system design, 156
interference in, 134
priming, 135
procedural, 129, 151
prospective, 131
recognition, 132, 151
representation, 136
retention, 331
retrieval, 124, 125, 128, 134, 135, 160,
</p>
<p>189, 193
retrospective, 131
short term, 20, 124&ndash;128
types of, 124
</p>
<p>Mental model, 21, 165, 166, 169&ndash;171, 173,
176, 183, 188, 192, 196, 197, 217,
256, 287, 301, 345, 349, 348, 489
</p>
<p>Mental models, of users, 348, 389
Mental representation, 166
</p>
<p>implications for design, 173
simple representations, 167
</p>
<p>Menu bar, 67, 68, 160
Menus, 7, 8, 28, 33, 68, 77, 159, 172, 182, 185
Metacognition, 194, 196
Metaphor, 138, 177, 187
Method of loci, 131
Micro-saccades, 88
Misinterpretation, 135, 217, 289
Mismatch, 71, 171, 187
Misses, 84, 85
Mistake, 12, 13, 28, 143, 153, 155, 194
</p>
<p>436 Index</p>
<p/>
</div>
<div class="page"><p/>
<p>Misunderstanding, 22
Mnemonics, 19, 131, 132, 136
Mobile phone, 18, 69, 72, 75
Modalities, 67, 74, 76, 144, 158
Mode, 12, 37, 75
Model human processor (MHP), 43, 392,
</p>
<p>395&ndash;397
Modeling, 23, 42, 43, 52, 159
Models, 9, 12, 14, 21, 23, 24, 38, 42, 43, 49,
</p>
<p>51, 64, 68, 131, 140, 165, 166,
168&ndash;171, 173, 176, 178, 192, 196,
272, 376
</p>
<p>of social processes, 266&ndash;269
of users, 23, 391&ndash;399
</p>
<p>Monitoring, 39, 138, 141, 142
Monochromats, 95
Monochrome, 95
Motivation, 4, 5, 17, 21
Motor, 16, 23, 62, 74, 75, 138, 141
Mouse, 59, 66&ndash;68, 72, 75, 77
Mouth, 63
Movement perception, 87, 101
Movements, 16, 52, 57, 66&ndash;71, 146, 174, 295,
</p>
<p>372
MS word, 28
Multimodal, 133
Multi-tasking, 12, 158
Multi-touch, 63
Muscle, 16, 17
Music, 72, 108, 189
Mutual support and mutual surveillance, 235,
</p>
<p>240
Mythical man-month, 235, 238
Myths, 159, 187
</p>
<p>N
</p>
<p>NASA&rsquo;s Aviation Safety Reporting System
(ASRS), 286
</p>
<p>NASA-TLX (task load index), 375
Nash equilibrium point, 257
Naturalistic, 192
Navigation, 65, 364, 372
Near misses, 22
Need for cognition, 180, 181, 295
Negotiation toolset, vi
Neonatal, 270, 271, 318
Nepal, 125, 128, 132, 135
Networks, 48, 132, 173, 213, 235, 253, 260,
</p>
<p>261, 262, 264, 343
leadership in, 260
</p>
<p>Networks lead to better work, 262
NGOMSL, 320
Norm, 236, 241, 327
</p>
<p>Normal curve, 388
Norman&rsquo;s seven stages of action, 343&ndash;345
Normative behavior/norms, 265, 310
Novice, 21, 28, 48, 64, 147, 156, 157, 173,
</p>
<p>175, 177, 188, 191, 217, 326, 328,
329, 357, 387
</p>
<p>NYNEX, 11&ndash;12
</p>
<p>O
</p>
<p>Observer, 184, 188, 228, 231, 291, 303, 363,
370
</p>
<p>Old, 12, 70, 75, 176, 180, 187, 261, 287, 338,
340. See also Elderly
</p>
<p>Omissions
error of, 64, 295
</p>
<p>Open loop behavior/control, 141, 142
Operate, 9, 12, 63, 64, 62, 75, 131, 152, 153,
</p>
<p>166, 176, 227, 244, 247, 302, 345,
389, 393
</p>
<p>Operators, 11, 12, 37, 43, 143, 153, 174, 176,
177, 181&ndash;183, 187, 227, 238, 286,
288, 290, 291, 301, 313, 320, 321,
324, 329, 346
</p>
<p>Optical, 86, 87, 91, 105
Optimization, 18, 34, 37, 48, 184, 204, 206,
</p>
<p>219, 238, 262, 274
Organization, 22, 26, 34, 36, 40, 41, 43, 44, 60,
</p>
<p>76, 211, 216, 225, 227, 235&ndash;240,
243, 249, 259, 253, 265, 274&ndash;276,
302, 311, 357, 362, 376, 386, 409
</p>
<p>Organizational and cultural levels, 264
Organizational effects, 265
Organizing what we have learnt about users,
</p>
<p>386
Overview of vision, 86
</p>
<p>P
</p>
<p>Paper-based reading, vs. screen-based reading,
208
</p>
<p>Parafovea, 87, 90
Parallax, 19, 101
Participants, 230, 242, 258, 259, 319, 360, 361,
</p>
<p>373, 376, 377, 379
Participation in an activity, 240
Participation outside work settings, 116, 253
</p>
<p>implications for system design, 136
Passwords, 129, 136, 145, 160
Patterns of usage, 368, 375, 376
Payoffs, 235, 242, 254, 256, 257,
</p>
<p>259, 274
Peer-to-peer, 241
Pencil and paper prototypes, 367
</p>
<p>Index 437</p>
<p/>
</div>
<div class="page"><p/>
<p>Penny, knowledge in the head vs. in the world,
7, 8, 28, 347
</p>
<p>Perceive-decide-act cycle, 345
Perception, 44, 95, 124, 236, 284
Perceptual-motor, 124, 213, 320, 324
Performance assurance, 311
Performance shaping factors (PSFs), 293
Periphery [eye], 50, 90, 91, 95, 101, 181
Philadelphia airport, 169, 170
Phones, 8, 14, 65, 70, 74, 77, 112, 159, 173,
</p>
<p>182, 198, 219, 221, 242, 246, 253,
303, 320, 376, 387
</p>
<p>Photoreceptor, 90
Physical, 17, 18, 20, 36, 52, 58, 63, 110, 120,
</p>
<p>149, 171, 235, 267, 270, 286, 319,
322, 327, 343&ndash;345, 375, 386, 409
</p>
<p>Physical aspects of interaction, 59
Physical keyboard, 63
Physiology, 33, 81, 103, 113, 211, 281, 287,
</p>
<p>294, 386
Physiology of vision, 86
</p>
<p>implications for system design, 91
Pilots, 9, 13, 21, 22, 74, 153, 176, 226, 266,
</p>
<p>283, 286, 287, 313, 346, 373, 410
Planning, 138, 146, 153, 195, 246, 284,
</p>
<p>293&ndash;295, 299, 315, 339, 377
Planning your evaluation study, 356&ndash;362
Platinum rule, v
Play, 18, 22, 60, 74, 84, 108, 113, 141, 142,
</p>
<p>151, 174, 191&ndash;192, 249, 257&ndash;259,
326, 327
</p>
<p>Pleasurable, 26, 27
Pluralistic ignorance, 228, 230, 248
Pointing devices, 66
Policy, 26, 29, 198, 266, 273
Pop-out effects, 92, 97&ndash;100, 116
Post-completion error, 180, 181
Postures, 60, 76, 17, 59, 60, 63, 387, 389
Power law of learning, 148, 149
Poynter Institute, 119
PQ4R, 133
Practice, see Learning
Practitioners, 15, 34, 45, 154, 403
Predictability, 8, 26, 38, 40, 67, 142, 143, 149,
</p>
<p>155, 156, 188, 211, 241, 285, 288,
290, 313, 320, 385, 392, 394, 397
</p>
<p>Prediction, 5, 38, 269, 272, 292, 313, 314, 324,
392, 395, 397
</p>
<p>Preferences, 44, 96, 112, 338
Premature babies, see Neonatal
Premature commitment (cognitive
</p>
<p>dimensions), 341
Prescriptions/prescriptive, 37, 46, 214, 265,
</p>
<p>310, 405
Primacy and recency, 189
</p>
<p>Primacy effect, 125&ndash;127, 134
Priming, of memory, 134
Principles, 37, 41, 46, 103, 105, 145, 204, 348,
</p>
<p>355, 356, 365, 389, 395, 398
Prisoner&rsquo;s dilemma (PD), 256&ndash;260
</p>
<p>how to do well, 258
suggestions for how to promote coopera-
</p>
<p>tion, 258
Problem solving, 40, 42, 145, 146, 152, 165,
</p>
<p>166, 174&ndash;177, 180, 181, 183, 184,
192, 196&ndash;198, 202, 213, 239, 265,
293, 344, 345, 389
</p>
<p>examples of, 175
implications for system design, 192
known influences on, 176
the importance of, 175
</p>
<p>Procedural memory, 129
Procedures, 9, 19, 38, 41, 129, 151, 176, 265,
</p>
<p>375
Process of learning, 145
Programmable User Models (PUMs), 43
Programmer, 48, 143, 340, 343, 397
Programming, 33, 48, 51, 129, 143, 160, 336,
</p>
<p>338, 341, 392, 408
Project lifecycle, 355, 404
Propositional representation, 167
Proprioception, 42
Prospective memory, 131, 158
Prototype, 4, 45, 101, 363, 364, 366&ndash;368,
</p>
<p>395
Proximal, 81, 115
Psycholinguistics, 89
Psychological science in the public interest,
</p>
<p>198
Psychology, 4, 10, 26, 34&ndash;36, 40, 76, 82, 103,
</p>
<p>115, 117, 119, 145, 151, 158, 159,
166, 184, 192, 197, 202, 226, 228,
237, 349, 360, 389, 395, 397
</p>
<p>Psychology/design of everyday things, 27, 350
Psychometric, 15
Psycho-physiology, 103, 281
Psychotherapy, 281
8 puzzle, 130, 157
</p>
<p>Q
</p>
<p>Questionnaires and surveys, 373
</p>
<p>R
</p>
<p>Radiation, see X-ray
Rarefaction, 106, 108
Rasmussen&rsquo;s theory of knowledge, 284, 293,
</p>
<p>348
Ratings, 373, 375
</p>
<p>438 Index</p>
<p/>
</div>
<div class="page"><p/>
<p>Rationality, 184, 192, 193, 291
RD-ICM, risk-driven incremental commitment
</p>
<p>(concurrent) model, 399&ndash;408
Reaction time, 64, 67, 387
Readability measures, 207, 217
Reading, 4, 20, 25, 60, 70, 72, 88, 97, 100,
</p>
<p>125, 155, 158, 160, 197, 201, 204,
206&ndash;209, 216&ndash;218, 220, 221, 266,
302, 330, 389, 393, 410
</p>
<p>factors affecting, 205
implications for system design, 136
paper-based reading, vs. screen-based
</p>
<p>reading, 208
scanning, 27
</p>
<p>Reading from the screen, 208, 219
Reading index, 217
Reasoning, 8, 23, 42, 134, 145&ndash;147, 389
Recall, 7&ndash;9, 112, 128, 132, 135, 136, 157, 160
Recallable, 136
Recency effect, 126
Recency of memory, 134
Receptor, 62, 86, 87, 89, 91
Recognition memory, 132
Recognition-primed decision making
</p>
<p>(RPDM), 191, 192
Red&ndash;green color differences, 91, 95
Redundancy, 47, 100, 336, 344
Regression to the mean, 189
Regulatory, 21, 247, 274, 288, 415
Rehearse, 135
Reliability, 4, 14, 47, 49, 50, 108, 186, 284,
</p>
<p>290, 294, 358, 361, 371
of user testing, 355
</p>
<p>Remember/remembering, 8, 20, 50, 111, 125,
128, 135, 158, 159, 189, 192, 208,
226, 274, 276, 310, 353, 369, 371,
388, 389, 392
</p>
<p>Reminders, 70, 136, 350
Repetition of stimuli, 132
Repetitive strain injury (RSI), 60
Representation in memory, 151
Requirements, 43, 44, 50, 115, 289, 313, 343,
</p>
<p>354, 368, 399, 405, 407
Respiratory distress syndrome (RDS), 318
Retention, memory, 331
Retina, 87&ndash;89, 95, 101, 104
Retrieval biases, 134
Retrieval from memory, 125, 132, 134, 189,
</p>
<p>193
Retrospective memory, 297, 370, 371
Rich pictures, 267, 270&ndash;272, 318, 319
Risk-aversive, 193
Risk-driven incremental commitment (con-
</p>
<p>current) model, 341, 385, 399
</p>
<p>descriptive as well as prescriptive, 404
designers are stakeholders too, 405
learning within and between projects, 406
provides a way to organize user related
</p>
<p>knowledge and ways of knowing,
403
</p>
<p>Risks, 14&ndash;16, 60, 66, 190, 234, 245, 266, 342,
385, 399, 400, 403, 409
</p>
<p>Risk-taking, 234
Road, 70, 206, 228, 310
Robot-assisted surgery, see da Vinci
Rods [eye], 83, 89, 91, 95
Role-expressiveness (cognitive dimensions),
</p>
<p>337, 339, 340
Role of tasks and environments, 390
Rubin vase, 94
Rule-based behavior/rule-level, 153
Rules, 14, 27, 115, 145, 147, 149, 153, 158,
</p>
<p>166, 193, 226, 259, 283, 321, 322,
341, 365
</p>
<p>S
</p>
<p>Saccades, 87
Safer systems, 10, 13
Safety, 13, 15, 22, 35, 38, 49, 60, 64, 100, 115,
</p>
<p>287, 296, 303, 310, 314, 339
Safety-critical systems, 21, 364
Salience, 83, 86, 95
Sample size effects, 189
Samsung TicToc mp3 player, 72
Satisfaction, 116, 148, 357, 359, 369
Satisficing, 407
Scanning, 118, 202, 206, 209, 211, 212, 218,
</p>
<p>219
Scanning displays and menus, 209
Scenario-based, 299, 363, 364, 415
Scenarios, 9, 296, 299, 363, 369
Screen layouts, 81
Screens, 65, 72, 85, 98, 100, 104, 105, 206,
</p>
<p>208, 210, 218&ndash;220, 317, 363, 371,
375
</p>
<p>Screenshot, 187, 212
Scrolling, 59, 65, 72, 150, 185, 321
Searching, 11, 19, 27, 40, 84, 97, 120, 147,
</p>
<p>150, 151, 172, 173, 184, 192, 202,
205, 206, 212&ndash;215, 231, 273, 276,
321, 327, 389
</p>
<p>Search engine optimization (SEO), 215
Seats, 88
Second Life, 258, 277
Seeing, 83, 84, 88, 95, 103, 105, 138, 146, 289
Seeking, 104, 131, 190, 201, 212, 213, 219,
</p>
<p>220, 231, 389
</p>
<p>Index 439</p>
<p/>
</div>
<div class="page"><p/>
<p>Selecting a hypothesis, 356
Selecting the most appropriate data collection
</p>
<p>method for error study, 289, 291
Self-determination theory (SDT), 113
Semantics, 127, 140, 188, 202, 203, 208
Semi-structured interviews, 270, 318, 374
Sensation, 74, 81, 89, 94, 107
Senses, 19, 23, 25, 48, 49, 57, 60, 62, 63, 74,
</p>
<p>81&ndash;83, 88, 90, 106, 114, 117, 176,
195, 202, 208, 239&ndash;241, 284, 303,
311, 355, 365, 366, 372, 386, 405
</p>
<p>Sensitivity, 74, 83, 84, 88, 90, 91, 94, 108,
117, 358, 361
</p>
<p>of user testing, 361
Sensors, 34, 395
Sensory threshold, 83
Sensory-motor, 386
Serial position curve, 126
Serifs, 210
Shapes, 103, 104, 205
Shared representations, 407, 408
Sharp end, 288, 302
Shortcuts, keystroke, 132
Short-term memory (STM), 125
Sight, see Vision
Signal, 62, 74, 84, 85, 375
Signal detection theory (SDT), 82&ndash;85, 120,
</p>
<p>185
Simple decisions, see Hicks law and speed-
</p>
<p>accuracy trade-offs
Simulating humans, x, 23
Simulation, 42, 267, 272, 273, 290, 359, 393,
</p>
<p>394, 398, 406
Simulator, 9, 290&ndash;292, 303
Situation awareness (SA), vii, 138, 202, 238,
</p>
<p>302, 371
Skill-based/skilled, 12, 15, 141, 146, 153,
</p>
<p>293, 348
Skilled behavior in complex environments,
</p>
<p>153
Slack, 284, 293
Slip, 284, 293, 370
Slips of actions, 19, 141, 142
Small world phenomena, 260
Smartphones, 77, 242, 249
Smell, 81, 82, 88, 134, 214, 219
Smooth pursuit eye movements, 101
Soar, 43, 129, 159, 232, 393, 395, 397
Soccer, 249
Social and organizational aspects, implica-
</p>
<p>tions for system design, 204
Social capital, 260
Social distance, 236, 239, 240, 246, 274
Social effects on decision making, xv, 228
Social issues, 9
</p>
<p>Social networks lead to better work, 262
Social responsibility effects, vi, 228
Social theories and models, 253
</p>
<p>cultural effects, 275
exchange costs and benefits, 256
good personal social networks lead to
</p>
<p>better work, 262
implications for system design, 273
informal, pairwise analyses, 254
networks, 260
organizational and cultural levels, 264
organizational effects, 265
</p>
<p>Sociology, 273, 276
Socio-technical system design (STSD) meth-
</p>
<p>ods, 41, 226, 273, 301
Socio-technical systems, 329
Soft systems methodology (SSM), 267, 269,
</p>
<p>270
Sound, 19, 34, 46, 82, 83, 85, 106, 108,
</p>
<p>110&ndash;112, 117, 134, 203, 363, 387
localizing, 110, 387
measuring, 108, 109, 239
theoretical description of, 106
implications for system design, 111, 204
</p>
<p>Sounds discriminating, 111
Spam, 232, 275, 277
Spatial distance, 236, 241
Spatial perception, 101
Special interest group (SIG) on computer&ndash;
</p>
<p>human interaction (SIGCHI), 45
Specification, 282, 320, 322, 358, 359, 391
Spectrum, 90&ndash;92
Speech, 72, 157, 247, 368, 387
Speed-accuracy trade-offs, 185
Spelling mistakes, 97
Spiral model, see RD-ICM
S&ndash;R (Stimulus&ndash;response) compatibility, see
</p>
<p>Stimulus-response compatibility
Stages of learning, 146, 149
Stakeholders, vi, 269&ndash;271, 362, 399&ndash;407, 427
Standard, 37, 46, 50, 62, 76, 96, 106, 108, 269,
</p>
<p>347, 365, 376
Stereoscopic vision, 102
Stimuli, 5, 63, 81&ndash;83, 85, 97, 101, 108, 119,
</p>
<p>132, 171, 186, 360
Stimulus&ndash;response compatibility, 5, 171&ndash;173,
</p>
<p>186, 187
for decisions, 186
for mental models, 171
</p>
<p>Stimulus&ndash;response mapping, 427
Storage, 42, 123, 131, 270, 293, 338, 397
Store, 19, 38, 124, 125, 127, 129&ndash;131, 321,
</p>
<p>323, 395
Stories, vii, 155, 228
Storyboarding, 4, 367
</p>
<p>440 Index</p>
<p/>
</div>
<div class="page"><p/>
<p>Stove-top mappings, 6
Strategy, 8, 21, 147, 149, 150, 171, 178, 192,
</p>
<p>215, 216, 258, 259, 361, 395
Stress/stressors, 46, 241, 293
Structured, 131, 182, 201, 211, 215&ndash;217, 219,
</p>
<p>244, 299, 374
Structure of the eye, 86, 211
Structuring content, 217
Styles, 19, 20, 51, 64, 146, 159, 187
Subgoals, 313&ndash;316, 321, 323, 325, 422
Subitizing, 102
Sub-tasks, 149, 315, 422
Summaries of users, 23, 385
Summative evaluation, 357, 368, 369, 427
Supervisory control, 39
Supporting participation outside work
</p>
<p>settings, 375
Surface fidelity, 290, 367
Surgery, 70, 74, 75
Surprises, 165, 197
Surveillance, 240, 241
Survey, 9, 62, 150, 160
Switches and lights, 5
Symbol, 20, 42, 202, 242
Syntax, 39, 139
System fidelity, 4
Systems ergonomics, 39
System usability scale (SUS), 373
</p>
<p>T
</p>
<p>Tactics, 158, 213, 366
Tactile, 57, 63, 72, 74
Talking, 127, 138, 256, 286, 366, 371, 414
Task-action mapping, 187
Task analysis (TA), 12, 248, 309, 311,
</p>
<p>313&ndash;314
considerations when choosing a method,
</p>
<p>326
uses of task analysis, 12, 311&ndash;314
where to apply, 310
</p>
<p>Task and interface design, 26, 311, 313
Task attractiveness, 236
Task-centered user interface design, 26, 119,
</p>
<p>329
Task time, 156, 326, 330, 369
Taste, 82, 189
Taxonomies, 142, 292&ndash;293, 303
Team-building, 327
Team competencies, 236
Team processes and tasks, 236
Teams, 12, 49, 113, 225&ndash;227, 234
Team size, 236
Team structure and composition, 236
</p>
<p>Teamwork, 234&ndash;235, 239, 248, 253, 258
Technique for human error assessment
</p>
<p>(THEA), 299, 428
Technique for human error rate prediction
</p>
<p>(THERP), 38
Ted Williams, 18
Telephone, 11, 70, 111, 264, 313, 323, 361,
</p>
<p>364
Telepresence, 74
Tests, 136, 151
Text-based virtual environments, 253
Text-editing, 321, 325
Texture, 72, 94, 102
Theremin, 202, 203
Three letter acronyms, TLAs, 126
Three Mile Island accident, 282, 284
Threshold, 357, 369
</p>
<p>sensory, 83
Thumbs, 77, 98, 111
Time-and-motion, 325
Time-constrained, 286
Time-sensitive, 313
Tolerances, 17, 88, 358
Tones, 106&ndash;108, 110, 111
Touch-based, 65, 72
Touch screen, 65
Touch, see Haptic
Touch-typing, 397
Tower of Hanoi, 174
Tracker ball, 75
Trade-offs, 64, 77, 132, 143, 155, 157, 186,
</p>
<p>205, 212, 257, 327, 329, 330, 335,
339, 341, 343, 347, 350, 351, 367
</p>
<p>Training, 5, 9, 19, 35&ndash;36, 39, 117, 120, 155,
286&ndash;287, 293, 295, 301, 314, 319,
347, 404, 407
</p>
<p>Transfer, of knowledge, 48, 155
Troubleshooting, 147, 166, 169
Trust, 136, 147, 213, 244
Type of data: qualitative or quantitative, 195,
</p>
<p>354, 356
Type of evaluation: formative or summative,
</p>
<p>357
Types of memory, 123, 124, 129, 150
Types of user models, 393
Typing, 13, 64, 141, 303, 324, 367&ndash;368, 397
Typing errors, 303
Typist model, 64
</p>
<p>U
</p>
<p>Ultraviolet, 90
Unified theories of cognition, 42, 159
University department web sites, 52, 160, 312
</p>
<p>Index 441</p>
<p/>
</div>
<div class="page"><p/>
<p>Unsafe, 266, 283
Unusable, 266, 353
Upper limb disorders (ULD), 18, 35, 60, 61,
</p>
<p>387
Usability, 11, 14, 18, 26, 43&ndash;44, 47&ndash;48, 57, 76,
</p>
<p>136, 160, 172&ndash;173, 211, 216, 320,
336, 343, 357&ndash;358, 362&ndash;366, 369,
372&ndash;373, 378, 390, 403, 409
</p>
<p>usability, testing, 362
User experience (UX), 33, 44, 216, 218, 369,
</p>
<p>376
User manuals, 60, 314
User testing, 335, 353&ndash;355, 368
</p>
<p>identifying the dependent and independent
variables, 357
</p>
<p>planning your evaluation study, 356
selecting a hypothesis, 356
type of evaluation: formative or summa-
</p>
<p>tive, 357
when to carry out, 355
why needed, 354
</p>
<p>User-based evaluation, 357
User-centered design (UCD), 33&ndash;35, 39, 43,
</p>
<p>50&ndash;51
Users, 1&ndash;412
Users&rsquo; bodies, see Anthropometrics
Users, how they read, 216
User, senses of the user, 81&ndash;121
User&rsquo;s mental models, 165, 168, 196
Users, why don&rsquo;t users do what they should,
</p>
<p>194
Uses of task analysis, 12, 311&ndash;314
</p>
<p>allocation of function, 311
performance assurance, 311
task and interface design, 313
</p>
<p>V
</p>
<p>Validation, 353
Validity, 289, 291, 353, 358
</p>
<p>construct, 358
content, 359
ecological, 360
external, 360
face, 359
instrument, 358
internal, 359
of user testing, 358&ndash;361
</p>
<p>Verbal protocol, 365, 370, 372
Verification and validation, 353
Video games, 70. See also Games
Video protocol, 70, 185, 371
Vigilance, 84, 85
Violations, 265, 283, 370
</p>
<p>Virtual reality systems 3.3.5, 63, 70
Viscosity (cognitive dimensions), 337&ndash;338,
</p>
<p>341
Visibility, 337, 346&ndash;347, 405
Vision, 23, 34, 62, 75, 211, 286, 338, 355, 371,
</p>
<p>375, 387, 392&ndash;393, 395
implications for system design, 91
</p>
<p>Vocabulary tutor, 340, 343
Voice, 106, 111, 112, 144, 173, 414
Voice output(s), 144
Von Restorff effect, 125, 132, 134
</p>
<p>W
</p>
<p>Warnings, 288
Wason reasoning task, 194
Waterfall model, 404
Waveform/waves, 86, 90, 106&ndash;108, 110, 112
Wave-length, 90, 91, 94, 95, 110
Ways email has gone awry, 232
Webbly, 11
Web content usability guidelines, 394
Websites, 37, 38, 78, 277, 312, 329
What is omitted by the cognitive dimensions,
</p>
<p>343
What to evaluate, 367
When not to study the user, see Risk driven
</p>
<p>spiral model
Why don&rsquo;t users do what they should, 194
Wickens theory of attentional resources, 139
WIMP interfaces (windows, interfaces, menus,
</p>
<p>pointer), 33
Windows in childhood home, 371
Windows (OS), 68, 371
Windows in childhood home, 371
Win&ndash;win requirements negotiation tools, vi
Wizard of Oz (WoO) technique, 367
Workarounds, 47, 50, 376
Workers, 38, 263, 329
Working memory, 127, 151, 388, 395
Workload, 301
Workload measures, 374
Workspaces, 37, 330
Workstation, 12, 60
Writing, the importance of, 125, 211
</p>
<p>X
</p>
<p>X-ray machine, 13
</p>
<p>Y
</p>
<p>Yellow&ndash;blue color, 95
Yellow&ndash;green light, 95
</p>
<p>442 Index</p>
<p/>
</div>
<ul>	<li>Foreword</li>
	<li>Preface</li>
	<li>Acknowledgments</li>
	<li>Contents</li>
	<li>Overview of Book</li>
	<li>Endorsements</li>
	<li>Part IIntroduction: Aims, Motivations, and Introduction to Human-Centered Design</li>
	<li>1 Introducing User-Centered Systems Design</li>
<ul>	<li>Abstract</li>
	<li>1.1&hellip;Introduction</li>
	<li>1.2&hellip;Starting to Understand Users</li>
<ul>	<li>1.2.1 Designing Mappings Between Buttons and Lights</li>
	<li>1.2.2 Designing Stove-Top Mappings</li>
	<li>1.2.3 Designing Coins</li>
	<li>1.2.4 What Happens If You do not Take Proper Account of Users, Tasks, and Context?</li>
</ul>
	<li>1.3&hellip;The Benefits and Costs of Understanding Users</li>
<ul>	<li>1.3.1 Benefit 1: More Usable Products</li>
	<li>1.3.2 Benefit 2: Financial Savings</li>
	<li>1.3.3 Benefit 3: Safer Systems</li>
	<li>1.3.4 Cost 1: Understanding the Users Does Not Guarantee Success</li>
	<li>1.3.5 Cost 2: Knowing When to Stop Analyzing the Users can be Difficult</li>
</ul>
	<li>1.4&hellip;Summarizing Design Relevant User Characteristics: The ABCS Framework</li>
<ul>	<li>1.4.1 Anthropometrics Approach</li>
	<li>1.4.2 Behavioral Aspects</li>
	<li>1.4.3 Cognition</li>
	<li>1.4.4 Social Factors</li>
</ul>
	<li>1.5&hellip;Simulating User Characteristics: Cognitive Architectures</li>
	<li>1.6&hellip;Summary</li>
<ul>	<li>1.6.1 Structure of the Rest of the Book</li>
	<li>1.6.2 Future Work</li>
</ul>
	<li>1.7&hellip;Other Resources</li>
	<li>1.8&hellip;Exercises</li>
	<li>References</li>
</ul>
	<li>2 User-Centered Systems Design: A Brief History</li>
<ul>	<li>Abstract</li>
	<li>2.1&hellip;Introduction</li>
	<li>2.2&hellip;Influential and Related Research Fields</li>
<ul>	<li>2.2.1 Ergonomics and Human Factors</li>
<ul>	<li>2.2.1.1 Classical Ergonomics</li>
	<li>2.2.1.2 Error Ergonomics</li>
	<li>2.2.1.3 Systems Ergonomics</li>
	<li>2.2.1.4 Cognitive Ergonomics/Cognitive Systems Engineering</li>
</ul>
	<li>2.2.2 Socio-Technical Systems Design</li>
	<li>2.2.3 Cognitive Modeling and Programmable User Models</li>
	<li>2.2.4 User-Centered and Human-Centered Design</li>
	<li>2.2.5 User Experience</li>
	<li>2.2.6 Human--Computer Interaction</li>
</ul>
	<li>2.3&hellip;Standards, Principles, and Guidelines</li>
	<li>2.4&hellip;Summary</li>
	<li>2.5&hellip;Other Resources</li>
	<li>2.6&hellip;Exercises</li>
	<li>References</li>
</ul>
	<li>Part IIDesign Relevant User Characteristics: The ABCS</li>
	<li>3 Anthropometrics: Important Aspects of Users&rsquo; Bodies</li>
<ul>	<li>Abstract</li>
	<li>3.1&hellip;Introduction</li>
	<li>3.2&hellip;Physical Aspects of Interaction</li>
<ul>	<li>3.2.1 Posture</li>
	<li>3.2.2 Load Bearing</li>
</ul>
	<li>3.3&hellip;Interacting with Haptic Devices</li>
<ul>	<li>3.3.1 Physical Keyboards</li>
	<li>3.3.2 Touch Screens</li>
	<li>3.3.3 Pointing Devices</li>
	<li>3.3.4 Mobile Phones</li>
	<li>3.3.5 Video Games and Virtual Reality Systems</li>
	<li>3.3.6 Other Devices</li>
	<li>3.3.7 Advantages and Disadvantages of Haptic Interfaces</li>
</ul>
	<li>3.4&hellip;Implications for System Design</li>
	<li>3.5&hellip;Summary</li>
	<li>3.6&hellip;Other Resources</li>
	<li>3.7&hellip;Exercises</li>
	<li>References</li>
</ul>
	<li>4 Behavior: Basic Psychology of the User</li>
<ul>	<li>Abstract</li>
	<li>4.1&hellip;Introduction</li>
	<li>4.2&hellip;Behavioral Psychology Terminology</li>
<ul>	<li>4.2.1 Thresholds and Just Noticeable Differences (JNDs)</li>
	<li>4.2.2 Habituation</li>
	<li>4.2.3 Signal Detection Theory (SDT)</li>
	<li>4.2.4 Implications for System Design</li>
</ul>
	<li>4.3&hellip;The Physiology of Vision</li>
<ul>	<li>4.3.1 Overview of Vision</li>
	<li>4.3.2 The Basic Structure of the Eye</li>
	<li>4.3.3 Using Eye-Tracking to Measure Eye Movements</li>
	<li>4.3.4 Rods and Cones</li>
	<li>4.3.5 Implications for System Design</li>
</ul>
	<li>4.4&hellip;Low Level Visual Perception</li>
<ul>	<li>4.4.1 Vision and the Measurement of Light</li>
	<li>4.4.2 Color Vision</li>
	<li>4.4.3 Color Blindness</li>
	<li>4.4.4 Color Systems</li>
	<li>4.4.5 Flicker</li>
	<li>4.4.6 Pop-Out Effects</li>
	<li>4.4.7 Implications for System Design</li>
</ul>
	<li>4.5&hellip;Higher Level Visual Perception</li>
<ul>	<li>4.5.1 Movement and Spatial Perception</li>
	<li>4.5.2 Depth Cues</li>
	<li>4.5.3 Subitizing</li>
	<li>4.5.4 Gestalt Principles of Grouping</li>
	<li>4.5.5 Other Theories of High Level Visual Perception</li>
	<li>4.5.6 Implications for System Design</li>
</ul>
	<li>4.6&hellip;The Auditory System</li>
<ul>	<li>4.6.1 Theoretical Description of Sound</li>
	<li>4.6.2 Measuring Sound</li>
	<li>4.6.3 Localizing Sound</li>
	<li>4.6.4 Discriminating Sounds</li>
	<li>4.6.5 Implications for System Design</li>
</ul>
	<li>4.7&hellip;Motivation</li>
<ul>	<li>4.7.1 Introduction</li>
	<li>4.7.2 Maslow&rsquo;s Hierarchical Theory</li>
	<li>4.7.3 Extrinsic and Intrinsic Motivation</li>
	<li>4.7.4 Implications for System Design</li>
</ul>
	<li>4.8&hellip;Summary</li>
	<li>4.9&hellip;Other Resources</li>
	<li>4.10&hellip;Exercises</li>
	<li>References</li>
</ul>
	<li>5 Cognition: Memory, Attention, and Learning</li>
<ul>	<li>Abstract</li>
	<li>5.1&hellip;Introduction</li>
	<li>5.2&hellip;Memory</li>
<ul>	<li>5.2.1 Types of Memory</li>
<ul>	<li>5.2.1.1 Iconic Memory</li>
	<li>5.2.1.2 Short-Term Memory</li>
	<li>5.2.1.3 Working Memory</li>
	<li>5.2.1.4 Long-Term Memory</li>
	<li>5.2.1.5 Declarative Versus Procedural Memory</li>
	<li>5.2.1.6 Implicit Versus Explicit Memory</li>
	<li>5.2.1.7 Prospective Memory </li>
</ul>
	<li>5.2.2 Mnemonics and Aids to Memory</li>
	<li>5.2.3 PQ4R: A Way to Improve Reading Comprehension</li>
	<li>5.2.4 Memory Biases</li>
<ul>	<li>5.2.4.1 Interference</li>
	<li>5.2.4.2 Retrieval Biases</li>
	<li>5.2.4.3 Encoding Effects</li>
	<li>5.2.4.4 Priming</li>
	<li>5.2.4.5 The Loftus Effect</li>
</ul>
	<li>5.2.5 Implications for System Design</li>
</ul>
	<li>5.3&hellip; Attention</li>
<ul>	<li>5.3.1 Wickens&rsquo; Theory of Attentional Resources</li>
	<li>5.3.2 An Information Processing Model of Attention</li>
	<li>5.3.3 Divided Attention </li>
	<li>5.3.4 Slips of Action</li>
	<li>5.3.5 Interruptions</li>
	<li>5.3.6 Automation Deficit: Keeping the Human in the Loop</li>
	<li>5.3.7 Implications for System Design</li>
</ul>
	<li>5.4&hellip;Learning and Skilled Behavior</li>
<ul>	<li>5.4.1 The Process of Learning</li>
	<li>5.4.2 Improvements from Learning</li>
	<li>5.4.3 Types of Learning</li>
	<li>5.4.4 Skilled Behavior, Users in Complex Environments</li>
	<li>5.4.5 Expertise</li>
	<li>5.4.6 Transfer</li>
	<li>5.4.7 Implications for System Design</li>
</ul>
	<li>5.5&hellip;Summary</li>
	<li>5.6&hellip;Other Resources</li>
	<li>5.7&hellip;Exercises</li>
	<li>References</li>
</ul>
	<li>6 Cognition: Mental Representations, Problem Solving, and Decision Making</li>
<ul>	<li>Abstract</li>
	<li>6.1&hellip;Introduction</li>
	<li>6.2&hellip;Mental Representations</li>
<ul>	<li>6.2.1 Simple Representations</li>
	<li>6.2.2 User&rsquo;s Mental Models</li>
	<li>6.2.3 Feeling of Knowing and Confidence Judgments</li>
	<li>6.2.4 Stimulus--Response Compatibility for Mental Models</li>
	<li>6.2.5 Implications for System Design </li>
</ul>
	<li>6.3&hellip;Problem Solving</li>
<ul>	<li>6.3.1 The Importance of Problem Solving</li>
	<li>6.3.2 Examples of Problem Solving</li>
	<li>6.3.3 Known Influences on Problem Solving</li>
<ul>	<li>6.3.3.1 Based on Mental Models</li>
	<li>6.3.3.2 Avoids Apparent Backtracking</li>
	<li>6.3.3.3 Functional Fixedness, Einstellung, and Insight Problems</li>
	<li>6.3.3.4 Post-completion Errors</li>
	<li>6.3.3.5 Breakout Box: Need for Cognition</li>
</ul>
	<li>6.3.4 Ill-Structured Problems</li>
	<li>6.3.5 Summary of Problem Solving with Implications for System Design</li>
</ul>
	<li>6.4&hellip;Decision Making</li>
<ul>	<li>6.4.1 Decision Making is Often Not Rational</li>
	<li>6.4.2 Simple Decisions: Hicks Law and Speed--Accuracy Trade-Offs</li>
	<li>6.4.3 Stimulus--Response Compatibility for Decisions</li>
	<li>6.4.4 Known Influences on Decision Making</li>
<ul>	<li>6.4.4.1 Based on Mental Models</li>
	<li>6.4.4.2 Confirmation Bias</li>
	<li>6.4.4.3 Regression to the Mean/Sample Sizes</li>
	<li>6.4.4.4 Availability Bias (Representativeness)</li>
	<li>6.4.4.5 Framing Effects</li>
	<li>6.4.4.6 Learning and Feedback</li>
</ul>
	<li>6.4.5 Larger Scale Decision Making Process: Expertise and RPDM</li>
	<li>6.4.6 Summary of Decision Making with Implications for System Design</li>
<ul>	<li>6.4.6.1 Breakout Box: Biases in Reasoning</li>
	<li>6.4.6.2 Breakout Box: Why Don&rsquo;t Users Do What They Should?</li>
</ul>
</ul>
	<li>6.5&hellip;Summary</li>
	<li>6.6&hellip;Other Resources</li>
	<li>6.7&hellip;Exercises</li>
	<li>References</li>
</ul>
	<li>7 Cognition: Human--Computer Communication</li>
<ul>	<li>Abstract</li>
	<li>7.1&hellip;Introduction</li>
	<li>7.2&hellip;Language</li>
<ul>	<li>7.2.1 Symbols, Syntax, and Semantics</li>
	<li>7.2.2 Grice&rsquo;s Maxims of Conversation</li>
	<li>7.2.3 Implications for System Design</li>
</ul>
	<li>7.3&hellip;How Users Read</li>
<ul>	<li>7.3.1 The Effects of Fonts</li>
	<li>7.3.2 Graphic Design to Help Reading and Scanning</li>
	<li>7.3.3 Paper-Based Versus Screen-Based Reading</li>
	<li>7.3.4 Scanning Displays and Menus</li>
	<li>7.3.5 Implications for System Design</li>
</ul>
	<li>7.4&hellip;Information Seeking Behavior</li>
<ul>	<li>7.4.1 Information</li>
	<li>7.4.2 Human Information Behavior</li>
	<li>7.4.3 Human Information Seeking Behavior</li>
	<li>7.4.4 Information Scent</li>
	<li>7.4.5 Implications for System Design</li>
</ul>
	<li>7.5&hellip;Designing Content</li>
<ul>	<li>7.5.1 Content Strategy</li>
	<li>7.5.2 Information Architecture</li>
	<li>7.5.3 Creating Content</li>
	<li>7.5.4 Structuring Content</li>
	<li>7.5.5 Delivering Content</li>
</ul>
	<li>7.6&hellip;Implications for System Design</li>
	<li>7.7&hellip;Summary</li>
	<li>7.8&hellip;Other Resources</li>
	<li>7.9&hellip;Exercises</li>
	<li>References</li>
</ul>
	<li>8 Social: Social Cognition and Teamwork</li>
<ul>	<li>Abstract</li>
	<li>8.1&hellip;Introduction</li>
	<li>8.2&hellip;Social Effects on Decision Making</li>
<ul>	<li>8.2.1 Introduction</li>
	<li>8.2.2 Social Responsibility Effects</li>
	<li>8.2.3 Attributions and Attributional Style</li>
<ul>	<li>8.2.3.1 Breakout Box: Ways Email Has Gone Awry</li>
</ul>
	<li>8.2.4 Majority and Minority Effects</li>
	<li>8.2.5 Summary</li>
</ul>
	<li>8.3&hellip;Factors Affecting Team Performance</li>
<ul>	<li>8.3.1 Introduction</li>
	<li>8.3.2 Team Size</li>
	<li>8.3.3 Team Competencies</li>
	<li>8.3.4 Team Structure and Composition</li>
	<li>8.3.5 Social Distance</li>
	<li>8.3.6 Spatial Distance</li>
	<li>8.3.7 Mutual Support and Mutual Surveillance</li>
	<li>8.3.8 Authority Figures</li>
	<li>8.3.9 Task Attractiveness</li>
	<li>8.3.10 Team Processes and Tasks</li>
	<li>8.3.11 Implications for System Design</li>
	<li>8.3.12 Summary</li>
</ul>
	<li>8.4&hellip;Factors Affecting Performance in Community Settings</li>
	<li>8.5&hellip;Implications for System Design</li>
	<li>8.6&hellip;Summary</li>
	<li>8.7&hellip;Other Resources</li>
	<li>8.8&hellip;Exercises</li>
	<li>References</li>
</ul>
	<li>9 Social: Theories and Models</li>
<ul>	<li>Abstract</li>
	<li>9.1&hellip;Introduction</li>
	<li>9.2&hellip;Analyzing How People Work Together</li>
<ul>	<li>9.2.1 Introduction</li>
	<li>9.2.2 Informal, Pairwise Analyses</li>
	<li>9.2.3 Exchange Costs and Benefits</li>
	<li>9.2.4 Networks</li>
	<li>9.2.5 Good Personal Social Networks Lead to Better Work</li>
	<li>9.2.6 Summary</li>
</ul>
	<li>9.3&hellip;Higher Social Levels: Organizational and Cultural </li>
<ul>	<li>9.3.1 Organizational Effects</li>
	<li>9.3.2 Cultural Effects</li>
	<li>9.3.3 Summary</li>
</ul>
	<li>9.4&hellip;Models of Social Processes</li>
<ul>	<li>9.4.1 Introduction</li>
	<li>9.4.2 Descriptive Social Models</li>
<ul>	<li>9.4.2.1 Ethnographic Descriptions of Social Processes</li>
	<li>9.4.2.2 Communities of Practice</li>
	<li>9.4.2.3 Static Models of Social Processes</li>
	<li>9.4.2.4 Dynamic Models of Social Processes</li>
</ul>
	<li>9.4.3 Soft Systems Methodology</li>
	<li>9.4.4 Rich Pictures</li>
	<li>9.4.5 Computational Models of Social Behavior</li>
<ul>	<li>9.4.5.1 Analytic Models</li>
	<li>9.4.5.2 Process Models</li>
</ul>
	<li>9.4.6 Summary</li>
</ul>
	<li>9.5&hellip;General Implications for System Design</li>
	<li>9.6&hellip;Summary</li>
	<li>9.7&hellip;Other Resources</li>
	<li>9.8&hellip;Exercises</li>
	<li>References</li>
</ul>
	<li>10 Errors: An Inherent Part of Human-System Performance</li>
<ul>	<li>Abstract</li>
	<li>10.1&hellip;Introduction to Errors</li>
<ul>	<li>10.1.1 What is Error?</li>
	<li>10.1.2 The Fine Line Between Success and Failure</li>
	<li>10.1.3 The Accident was Caused by Human Error, Right?</li>
</ul>
	<li>10.2&hellip;Studying Error</li>
<ul>	<li>10.2.1 Laboratory-Based Experiments</li>
	<li>10.2.2 Field-Based Observation</li>
	<li>10.2.3 Archive Data</li>
	<li>10.2.4 Selecting the Most Appropriate Data Collection Method</li>
</ul>
	<li>10.3&hellip;Error Taxonomies </li>
<ul>	<li>10.3.1 The Technique for Human Error Rate Prediction </li>
	<li>10.3.2 Generic Error Modeling System </li>
	<li>10.3.3 The Cognitive Reliability and Error Analysis Method </li>
</ul>
	<li>10.4&hellip;Analyzing Errors</li>
<ul>	<li>10.4.1 Event Trees</li>
	<li>10.4.2 Fault Trees</li>
	<li>10.4.3 CREAM</li>
	<li>10.4.4 THEA</li>
</ul>
	<li>10.5&hellip;Implications for System Design</li>
	<li>10.6&hellip;Summary</li>
	<li>10.7&hellip;Other Resources</li>
	<li>10.8&hellip;Exercises</li>
	<li>References</li>
</ul>
	<li>Part IIIMethods</li>
	<li>11 Methodology I: Task Analysis</li>
<ul>	<li>Abstract</li>
	<li>11.1&hellip;Introduction</li>
	<li>11.2&hellip;The Uses of Task Analysis</li>
<ul>	<li>11.2.1 Allocation of Function</li>
	<li>11.2.2 Performance Assurance</li>
	<li>11.2.3 Task and Interface Design</li>
</ul>
	<li>11.3&hellip;Hierarchical Task Analysis</li>
<ul>	<li>11.3.1 HTA Components</li>
	<li>11.3.2 Example Application of HTA</li>
	<li>11.3.3 Summary</li>
</ul>
	<li>11.4&hellip;Cognitive Task Analysis</li>
<ul>	<li>11.4.1 CTA Components</li>
	<li>11.4.2 Example Application of CTA</li>
	<li>11.4.3 Summary</li>
</ul>
	<li>11.5&hellip;GOMS</li>
<ul>	<li>11.5.1 GOMS Components</li>
	<li>11.5.2 Example Application of GOMS</li>
	<li>11.5.3 Summary</li>
</ul>
	<li>11.6&hellip;The Keystroke Level Model</li>
<ul>	<li>11.6.1 Description of KLM Components</li>
	<li>11.6.2 Example Application of the KLM </li>
	<li>11.6.3 Summary</li>
</ul>
	<li>11.7&hellip;Considerations When Choosing a TA Method</li>
	<li>11.8&hellip;Summary</li>
	<li>11.9&hellip;Other Resources</li>
	<li>11.10&hellip;Exercises</li>
	<li>References</li>
</ul>
	<li>12 Methodology II: Cognitive Dimensions and the Gulfs</li>
<ul>	<li>Abstract</li>
	<li>12.1&hellip;Introduction</li>
	<li>12.2&hellip;The Cognitive Dimensions</li>
<ul>	<li>12.2.1 Hidden Dependencies</li>
	<li>12.2.2 Viscosity</li>
	<li>12.2.3 Role-Expressiveness</li>
	<li>12.2.4 Premature Commitment</li>
	<li>12.2.5 Hard Mental Operations</li>
</ul>
	<li>12.3&hellip;Turning Cognitive Dimensions into a Methodology</li>
	<li>12.4&hellip;What is Omitted by the Cognitive Dimensions?</li>
	<li>12.5&hellip;Norman&rsquo;s Seven Stages of Action</li>
<ul>	<li>12.5.1 The Gulfs of Evaluation and Execution</li>
	<li>12.5.2 The Gulfs in Practice</li>
</ul>
	<li>12.6&hellip;Implications of the Gulfs for Design</li>
	<li>12.7&hellip;Limitations of the Gulfs</li>
	<li>12.8&hellip;Summary</li>
	<li>12.9&hellip;Other Resources</li>
	<li>12.10&hellip;Exercises</li>
	<li>References</li>
</ul>
	<li>13 Methodology III: Empirical Evaluation</li>
<ul>	<li>Abstract</li>
	<li>13.1&hellip;Introduction</li>
<ul>	<li>13.1.1 Why Do We Need User Testing?</li>
	<li>13.1.2 When Do We Carry Out User Testing?</li>
</ul>
	<li>13.2&hellip;Planning Your Evaluation Study</li>
<ul>	<li>13.2.1 What Type of Data: Qualitative or Quantitative?</li>
	<li>13.2.2 Selecting a Hypothesis</li>
	<li>13.2.3 Identifying the Dependent and Independent Variables</li>
	<li>13.2.4 What Type of Evaluation: Formative or Summative?</li>
	<li>13.2.5 Validity, Reliability, and Sensitivity</li>
<ul>	<li>13.2.5.1 Validity</li>
	<li>13.2.5.2 Reliability</li>
	<li>13.2.5.3 Sensitivity</li>
</ul>
</ul>
	<li>13.3&hellip;Evaluation Methods</li>
<ul>	<li>13.3.1 Usability Testing</li>
	<li>13.3.2 Field Studies and Field Experiments</li>
	<li>13.3.3 (Expert) Heuristic Evaluation</li>
	<li>13.3.4 Co-operative Evaluation</li>
	<li>13.3.5 A/B Testing</li>
</ul>
	<li>13.4&hellip;What to Evaluate?</li>
<ul>	<li>13.4.1 Pencil and Paper Prototypes</li>
	<li>13.4.2 Computer-Based Prototypes</li>
	<li>13.4.3 The Final System</li>
</ul>
	<li>13.5&hellip;Measuring Usability</li>
<ul>	<li>13.5.1 Task Time </li>
	<li>13.5.2 Errors </li>
	<li>13.5.3 Verbal Protocols</li>
	<li>13.5.4 Video Protocols</li>
	<li>13.5.5 Eye Movement Tracking</li>
	<li>13.5.6 Questionnaires and Surveys </li>
	<li>13.5.7 Interviews and Focus Groups</li>
	<li>13.5.8 Workload Measures</li>
	<li>13.5.9 Patterns of Usage </li>
	<li>13.5.10 User Experience</li>
</ul>
	<li>13.6&hellip;The Ethics of Evaluation</li>
	<li>13.7&hellip;Summary</li>
	<li>13.8&hellip;Other Resources</li>
	<li>13.9&hellip;Exercises</li>
	<li>References</li>
</ul>
	<li>Part IVSummary</li>
	<li>14 Summary: Putting It All Together</li>
<ul>	<li>Abstract</li>
	<li>14.1&hellip;Introduction</li>
	<li>14.2&hellip;Organizing What We Have Learnt About Users</li>
<ul>	<li>14.2.1 Anthropometrics</li>
	<li>14.2.2 Behavior</li>
	<li>14.2.3 Cognition</li>
	<li>14.2.4 Social</li>
	<li>14.2.5 The Role of Tasks and Environments</li>
	<li>14.2.6 Summary</li>
</ul>
	<li>14.3&hellip;Models of Users</li>
<ul>	<li>14.3.1 Unified Theories of Cognition</li>
	<li>14.3.2 Types of User Models</li>
<ul>	<li>14.3.2.1 Implicit Descriptive Models</li>
	<li>14.3.2.2 Explicit Descriptive Models</li>
	<li>14.3.2.3 Explicit Process Models: Model Human Processor</li>
	<li>14.3.2.4 Explicit Information Processing Models: ACT-R</li>
</ul>
	<li>14.3.3 Summary</li>
</ul>
	<li>14.4&hellip;Risk-Driven Incremental Commitment Model</li>
<ul>	<li>14.4.1 Introduction</li>
	<li>14.4.2 Insight 1: The RD-ICM Provides a Way to Organize User-Related Knowledge and Ways of Knowing</li>
	<li>14.4.3 Insight 2: RD-ICM is Descriptive as Well as Prescriptive</li>
	<li>14.4.4 Extension 1: Designers are Stakeholders Too</li>
	<li>14.4.5 Extension 2: Learning Within and Between Projects</li>
	<li>14.4.6 Summary</li>
</ul>
	<li>14.5&hellip;Building on the Foundations</li>
	<li>14.6&hellip;Other Resources</li>
	<li>14.7&hellip;Exercises</li>
	<li>References</li>
</ul>
	<li>AppendixThe Kegworth Air Accident (1989)</li>
	<li>Glossary</li>
	<li>Index</li>
</ul>
</body></html>