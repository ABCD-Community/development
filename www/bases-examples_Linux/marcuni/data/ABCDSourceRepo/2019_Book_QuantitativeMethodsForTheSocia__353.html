<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Untitled</title>
</head>
<body><div class="page"><p/>
<p>Daniel&nbsp;Stockemer
</p>
<p>Quantitative 
Methods for the 
Social Sciences
A Practical Introduction with Examples 
in SPSS and Stata</p>
<p/>
</div>
<div class="page"><p/>
<p>Quantitative Methods for the Social Sciences</p>
<p/>
</div>
<div class="page"><p/>
<p>Daniel Stockemer
</p>
<p>Quantitative Methods
for the Social Sciences
</p>
<p>A Practical Introduction with Examples
in SPSS and Stata</p>
<p/>
</div>
<div class="page"><p/>
<p>Daniel Stockemer
University of Ottawa
School of Political Studies
Ottawa, Ontario, Canada
</p>
<p>ISBN 978-3-319-99117-7 ISBN 978-3-319-99118-4 (eBook)
https://doi.org/10.1007/978-3-319-99118-4
</p>
<p>Library of Congress Control Number: 2018957702
</p>
<p># Springer International Publishing AG 2019
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the
material is concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation,
broadcasting, reproduction on microfilms or in any other physical way, and transmission or information
storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology
now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a specific statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this
book are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or
the editors give a warranty, express or implied, with respect to the material contained herein or for any
errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional
claims in published maps and institutional affiliations.
</p>
<p>This Springer imprint is published by the registered company Springer Nature Switzerland AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland</p>
<p/>
<div class="annotation"><a href="https://doi.org/10.1007/978-3-319-99118-4">https://doi.org/10.1007/978-3-319-99118-4</a></div>
</div>
<div class="page"><p/>
<p>Contents
</p>
<p>1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
</p>
<p>2 The Nuts and Bolts of Empirical Social Science . . . . . . . . . . . . . . . . 5
</p>
<p>2.1 What Is Empirical Research in the Social Sciences? . . . . . . . . . 5
</p>
<p>2.2 Qualitative and Quantitative Research . . . . . . . . . . . . . . . . . . . 8
</p>
<p>2.3 Theories, Concepts, Variables, and Hypothesis . . . . . . . . . . . . . 10
</p>
<p>2.3.1 Theories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
</p>
<p>2.3.2 Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
</p>
<p>2.3.3 Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
</p>
<p>2.3.4 Hypotheses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
</p>
<p>2.4 The Quantitative Research Process . . . . . . . . . . . . . . . . . . . . . . 18
</p>
<p>References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
</p>
<p>3 A Short Introduction to Survey Research . . . . . . . . . . . . . . . . . . . . 23
</p>
<p>3.1 What Is Survey Research? . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
</p>
<p>3.2 A Short History of Survey Research . . . . . . . . . . . . . . . . . . . . . 24
</p>
<p>3.3 The Importance of Survey Research in the Social Sciences
</p>
<p>and Beyond . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
</p>
<p>3.4 Overview of Some of the Most Widely Used Surveys
</p>
<p>in the Social Sciences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
</p>
<p>3.4.1 The Comparative Study of Electoral Systems (CSES) . . . 28
</p>
<p>3.4.2 The World Values Survey (WVS) . . . . . . . . . . . . . . . . 29
</p>
<p>3.4.3 The European Social Survey (ESS) . . . . . . . . . . . . . . . 30
</p>
<p>3.5 Different Types of Surveys . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
</p>
<p>3.5.1 Cross-sectional Survey . . . . . . . . . . . . . . . . . . . . . . . . 31
</p>
<p>3.5.2 Longitudinal Survey . . . . . . . . . . . . . . . . . . . . . . . . . . 32
</p>
<p>References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
</p>
<p>4 Constructing a Survey . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
</p>
<p>4.1 Question Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
</p>
<p>4.2 Ordering of Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
</p>
<p>4.3 Number of Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
</p>
<p>4.4 Getting the Questions Right . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
</p>
<p>4.4.1 Vague Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
</p>
<p>4.4.2 Biased or Value-Laden Questions . . . . . . . . . . . . . . . . 39
</p>
<p>v</p>
<p/>
</div>
<div class="page"><p/>
<p>4.4.3 Threatening Questions . . . . . . . . . . . . . . . . . . . . . . . . 39
</p>
<p>4.4.4 Complex Questions . . . . . . . . . . . . . . . . . . . . . . . . . . 40
</p>
<p>4.4.5 Negative Questions . . . . . . . . . . . . . . . . . . . . . . . . . . 40
</p>
<p>4.4.6 Pointless Questions . . . . . . . . . . . . . . . . . . . . . . . . . . 40
</p>
<p>4.5 Social Desirability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
</p>
<p>4.6 Open-Ended and Closed-Ended Questions . . . . . . . . . . . . . . . . 42
</p>
<p>4.7 Types of Closed-Ended Survey Questions . . . . . . . . . . . . . . . . . 44
</p>
<p>4.7.1 Scales . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
</p>
<p>4.7.2 Dichotomous Survey Questions . . . . . . . . . . . . . . . . . . 47
</p>
<p>4.7.3 Multiple-Choice Questions . . . . . . . . . . . . . . . . . . . . . 47
</p>
<p>4.7.4 Numerical Continuous Questions . . . . . . . . . . . . . . . . . 48
</p>
<p>4.7.5 Categorical Survey Questions . . . . . . . . . . . . . . . . . . . 48
</p>
<p>4.7.6 Rank-Order Questions . . . . . . . . . . . . . . . . . . . . . . . . 49
</p>
<p>4.7.7 Matrix Table Questions . . . . . . . . . . . . . . . . . . . . . . . 49
</p>
<p>4.8 Different Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
</p>
<p>4.9 Coding of Different Variables in a Dataset . . . . . . . . . . . . . . . . 51
</p>
<p>4.9.1 Coding of Nominal Variables . . . . . . . . . . . . . . . . . . . 51
</p>
<p>4.10 Drafting a Questionnaire: General Information . . . . . . . . . . . . . 52
</p>
<p>4.10.1 Drafting a Questionnaire: A Step-by-Step Approach . . . 53
</p>
<p>4.11 Background Information About the Questionnaire . . . . . . . . . . . 54
</p>
<p>References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
</p>
<p>5 Conducting a Survey . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57
</p>
<p>5.1 Population and Sample . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57
</p>
<p>5.2 Representative, Random, and Biased Samples . . . . . . . . . . . . . . 58
</p>
<p>5.3 Sampling Error . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
</p>
<p>5.4 Non-random Sampling Techniques . . . . . . . . . . . . . . . . . . . . . . 62
</p>
<p>5.5 Different Types of Surveys . . . . . . . . . . . . . . . . . . . . . . . . . . . 64
</p>
<p>5.6 Which Type of Survey Should Researchers Use? . . . . . . . . . . . 67
</p>
<p>5.7 Pre-tests . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
</p>
<p>5.7.1 What Is a Pre-test? . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
</p>
<p>5.7.2 How to Conduct a Pre-test? . . . . . . . . . . . . . . . . . . . . . 69
</p>
<p>References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69
</p>
<p>6 Univariate Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
</p>
<p>6.1 SPSS and Stata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
</p>
<p>6.2 Putting Data into an SPSS Spreadsheet . . . . . . . . . . . . . . . . . . . 73
</p>
<p>6.3 Putting Data into a Stata Spreadsheet . . . . . . . . . . . . . . . . . . . . 75
</p>
<p>6.4 Frequency Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76
</p>
<p>6.4.1 Constructing a Frequency Table in SPSS . . . . . . . . . . . 77
</p>
<p>6.4.2 Constructing a Frequency Table in Stata . . . . . . . . . . . 78
</p>
<p>6.5 The Measures of Central Tendency: Mean, Median, Mode,
</p>
<p>and Range . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79
</p>
<p>6.6 Displaying Data Graphically: Pie Charts, Boxplots, and
</p>
<p>Histograms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80
</p>
<p>vi Contents</p>
<p/>
</div>
<div class="page"><p/>
<p>6.6.1 Pie Charts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80
</p>
<p>6.6.2 Doing a Pie Chart in SPSS . . . . . . . . . . . . . . . . . . . . . 82
</p>
<p>6.6.3 Doing a Pie Chart in Stata . . . . . . . . . . . . . . . . . . . . . . 83
</p>
<p>6.7 Boxplots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
</p>
<p>6.7.1 Doing a Boxplot in SPSS . . . . . . . . . . . . . . . . . . . . . . 86
</p>
<p>6.7.2 Doing a Boxplot in Stata . . . . . . . . . . . . . . . . . . . . . . . 86
</p>
<p>6.8 Histograms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
</p>
<p>6.8.1 Doing a Histogram in SPSS . . . . . . . . . . . . . . . . . . . . 88
</p>
<p>6.8.2 Doing a Histogram in Stata . . . . . . . . . . . . . . . . . . . . . 90
</p>
<p>6.9 Deviation, Variance, Standard Deviation, Standard Error,
</p>
<p>Sampling Error, and Confidence Interval . . . . . . . . . . . . . . . . . 91
</p>
<p>6.9.1 Calculating the Confidence Interval in SPSS . . . . . . . . 95
</p>
<p>6.9.2 Calculating the Confidence Interval in Stata . . . . . . . . . 96
</p>
<p>Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98
</p>
<p>7 Bivariate Statistics with Categorical Variables . . . . . . . . . . . . . . . . 101
</p>
<p>7.1 Independent Sample t-Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101
</p>
<p>7.1.1 Doing an Independent Samples t-Test in SPSS . . . . . . . 104
</p>
<p>7.1.2 Interpreting an Independent Samples t-Test
</p>
<p>SPSS Output . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106
</p>
<p>7.1.3 Reading an SPSS Independent Samples t-Test Output
</p>
<p>Column by Column . . . . . . . . . . . . . . . . . . . . . . . . . . 107
</p>
<p>7.1.4 Doing an Independent Samples t-Test in Stata . . . . . . . 108
</p>
<p>7.1.5 Interpreting an Independent Samples t-Test Stata
</p>
<p>Output . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
</p>
<p>7.1.6 Reporting the Results of an Independent
</p>
<p>Samples t-Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
</p>
<p>7.2 F-Test or One-Way ANOVA . . . . . . . . . . . . . . . . . . . . . . . . . . 111
</p>
<p>7.2.1 Doing an f-Test in SPSS . . . . . . . . . . . . . . . . . . . . . . . 113
</p>
<p>7.2.2 Interpreting an SPSS ANOVA Output . . . . . . . . . . . . . 115
</p>
<p>7.2.3 Doing a Post hoc or Multiple Comparison Test
</p>
<p>in SPSS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
</p>
<p>7.2.4 Doing an f-Test in Stata . . . . . . . . . . . . . . . . . . . . . . . 119
</p>
<p>7.2.5 Interpreting an f-Test in Stata . . . . . . . . . . . . . . . . . . . 120
</p>
<p>7.2.6 Doing a Post hoc or Multiple Comparison Test
</p>
<p>with Unequal Variance in Stata . . . . . . . . . . . . . . . . . . 121
</p>
<p>7.2.7 Reporting the Results of an f-Test . . . . . . . . . . . . . . . . 124
</p>
<p>7.3 Cross-tabulation Table and Chi-Square Test . . . . . . . . . . . . . . . 125
</p>
<p>7.3.1 Cross-tabulation Table . . . . . . . . . . . . . . . . . . . . . . . . 125
</p>
<p>7.3.2 Chi-Square Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
</p>
<p>7.3.3 Doing a Chi-Square Test in SPSS . . . . . . . . . . . . . . . . 127
</p>
<p>7.3.4 Interpreting an SPSS Chi-Square Test . . . . . . . . . . . . . 128
</p>
<p>7.3.5 Doing a Chi-Square Test in Stata . . . . . . . . . . . . . . . . . 130
</p>
<p>7.3.6 Reporting a Chi-Square Test Result . . . . . . . . . . . . . . . 131
</p>
<p>Reference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
</p>
<p>Contents vii</p>
<p/>
</div>
<div class="page"><p/>
<p>8 Bivariate Relationships Featuring Two Continuous Variables . . . . . 133
</p>
<p>8.1 What Is a Bivariate Relationship Between Two Continuous
</p>
<p>Variables? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
</p>
<p>8.1.1 Positive and Negative Relationships . . . . . . . . . . . . . . 133
</p>
<p>8.2 Scatterplots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134
</p>
<p>8.2.1 Positive Relationships Displayed in a Scatterplot . . . . . 134
</p>
<p>8.2.2 Negative Relationships Displayed in a Scatterplot . . . . . 134
</p>
<p>8.2.3 No Relationship Displayed in a Scatterplot . . . . . . . . . . 135
</p>
<p>8.3 Drawing the Line in a Scatterplot . . . . . . . . . . . . . . . . . . . . . . . 136
</p>
<p>8.4 Doing Scatterplots in SPSS . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
</p>
<p>8.5 Doing Scatterplots in Stata . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
</p>
<p>8.6 Correlation Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142
</p>
<p>8.6.1 Doing a Correlation Analysis in SPSS . . . . . . . . . . . . . 144
</p>
<p>8.6.2 Interpreting an SPSS Correlation Output . . . . . . . . . . . 145
</p>
<p>8.6.3 Doing a Correlation Analysis in Stata . . . . . . . . . . . . . 147
</p>
<p>8.7 Bivariate Regression Analysis . . . . . . . . . . . . . . . . . . . . . . . . . 148
</p>
<p>8.7.1 Gauging the Steepness of a Regression Line . . . . . . . . 148
</p>
<p>8.7.2 Gauging the Error Term . . . . . . . . . . . . . . . . . . . . . . . 150
</p>
<p>8.8 Doing a Bivariate Regression Analysis in SPSS . . . . . . . . . . . . 152
</p>
<p>8.9 Interpreting an SPSS (Bivariate) Regression Output . . . . . . . . . . 153
</p>
<p>8.9.1 The Model Summary Table . . . . . . . . . . . . . . . . . . . . . 153
</p>
<p>8.9.2 The Regression ANOVA Table . . . . . . . . . . . . . . . . . . 154
</p>
<p>8.9.3 The Regression Coefficient Table . . . . . . . . . . . . . . . . 155
</p>
<p>8.10 Doing a (Bivariate) Regression Analysis in Stata . . . . . . . . . . . . 156
</p>
<p>8.10.1 Interpreting a Stata (Bivariate) Regression Output . . . . 157
</p>
<p>8.10.2 Reporting and Interpreting the Results of a Bivariate
</p>
<p>Regression Model . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
</p>
<p>Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161
</p>
<p>9 Multivariate Regression Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . 163
</p>
<p>9.1 The Logic Behind Multivariate Regression Analysis . . . . . . . . . 163
</p>
<p>9.2 The Functional Forms of Independent Variables to Include
</p>
<p>in a Multivariate Regression Model . . . . . . . . . . . . . . . . . . . . . 165
</p>
<p>9.3 Interpretation Help for a Multivariate Regression Model . . . . . . 166
</p>
<p>9.4 Doing a Multiple Regression Model in SPSS . . . . . . . . . . . . . . 166
</p>
<p>9.5 Interpreting a Multiple Regression Model in SPSS . . . . . . . . . . 166
</p>
<p>9.6 Doing a Multiple Regression Model in Stata . . . . . . . . . . . . . . . 168
</p>
<p>9.7 Interpreting a Multiple Regression Model in Stata . . . . . . . . . . . 168
</p>
<p>9.8 Reporting the Results of a Multiple Regression Analysis . . . . . . 170
</p>
<p>9.9 Finding the Best Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170
</p>
<p>9.10 Assumptions of the Classical Linear Regression Model or
</p>
<p>Ordinary Least Square Regression Model (OLS) . . . . . . . . . . . . 171
</p>
<p>Reference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174
</p>
<p>viii Contents</p>
<p/>
</div>
<div class="page"><p/>
<p>Appendix 1: The Data of the Sample Questionnaire . . . . . . . . . . . . . . . . 175
</p>
<p>Appendix 2: Possible Group Assignments That Go with This Course . . . 177
</p>
<p>Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179
</p>
<p>Contents ix</p>
<p/>
</div>
<div class="page"><p/>
<p>Introduction 1
</p>
<p>Under what conditions do countries go to war? What is the influence of the
</p>
<p>2008&ndash;2009 economic crisis on the vote share of radical right-wing parties in Western
</p>
<p>Europe? What type of people are the most likely to protest and partake in
</p>
<p>demonstrations? How has the urban squatters&rsquo; movement developed in
</p>
<p>South Africa after apartheid? There is hardly any field in the social sciences that
</p>
<p>asks as many research questions as political science. Questions scholars are interested
</p>
<p>in can be specific and reduced to one event (e.g., the development of the urban
</p>
<p>squatter&rsquo;s movement in South Africa post-apartheid) or general and systemic such as
</p>
<p>the occurrence of war and peace. Whether general or specific, what all empirical
</p>
<p>research questions have in common is the necessity to use adequate research methods
</p>
<p>to answer them. For example, to effectively evaluate the influence of the economic
</p>
<p>downturn in 2008&ndash;2009 on the radical right-wing success in the elections preceding
</p>
<p>the crisis, we need data on the radical right-wing vote before and after the crisis, a
</p>
<p>clearly defined operationalization of the crisis and data on confounding factors such
</p>
<p>as immigration, crime, and corruption. Through appropriate modeling techniques
</p>
<p>(i.e., multiple regression analysis on macro-level data), we can then assess the
</p>
<p>absolute and relative influence of the economic crisis on the radical right-wing vote
</p>
<p>share.
</p>
<p>Research methods are the &ldquo;bread and butter&rdquo; of empirical political science. They
</p>
<p>are the tools that allow researchers to conduct research and detect empirical
</p>
<p>regularities, causal chains, and explanations of political and social phenomena. To
</p>
<p>use a practical analogy, a political scientist needs to have a toolkit of research
</p>
<p>methods at his or her disposal to build good empirical research in the same way as
</p>
<p>a mason must have certain tools to build a house. It is indispensable for a mason to
</p>
<p>not only have some rather simple tools (e.g., a hammer) but also some more
</p>
<p>sophisticated tools such as a mixer or crane. The same applies for a political scientist.
</p>
<p>Ideally, he or she should have some easy tools (such as descriptive statistics or means
</p>
<p>testing) at his or her disposal but also some more complex tools such as pooled time
</p>
<p>series analysis or maximum likelihood estimation. Having these tools allows
</p>
<p># Springer International Publishing AG 2019
</p>
<p>D. Stockemer, Quantitative Methods for the Social Sciences,
</p>
<p>https://doi.org/10.1007/978-3-319-99118-4_1
</p>
<p>1</p>
<p/>
<div class="annotation"><a href="http://crossmark.crossref.org/dialog/?doi=10.1007/978-3-319-99118-4_1&amp;domain=pdf">http://crossmark.crossref.org/dialog/?doi=10.1007/978-3-319-99118-4_1&amp;domain=pdf</a></div>
</div>
<div class="page"><p/>
<p>political scientists to both conduct their own research and judge and evaluate other
</p>
<p>peoples&rsquo;work. This book will provide a first simple toolkit in the area of quantitative
</p>
<p>methods, survey research, and statistics.
</p>
<p>There is one caveat in methods training: research methods can hardly be learnt by
</p>
<p>just reading articles and books. Rather, they need to be learnt in an applied fashion.
</p>
<p>Similar to the mixture of theoretical and practical training a mason acquires during
</p>
<p>her apprenticeship, political science students should be introduced to methods&rsquo;
</p>
<p>training in a practical manner. In particular, this applies to quantitative methods
</p>
<p>and survey research. Aware that methods learning can only be fruitful if students
</p>
<p>learn to apply their theoretical skills in real-world scenarios, I have constructed this
</p>
<p>book on survey research and quantitative methods in a very practical fashion.
</p>
<p>Through my own experience as a professor of introductory courses into quantita-
</p>
<p>tive method, I have learnt over and over again that students only enjoy these classes
</p>
<p>if they see the applicability of the techniques they learn. This book follows the
</p>
<p>structure as laid down in Fig. 1.1; it is structured so that students learn various
</p>
<p>statistical techniques while using their own data. It does not require students to have
</p>
<p>taken prior methods classes. To lay some theoretical groundwork, the first chapter
</p>
<p>starts with an introduction into the nuts and bolts of empirical social sciences (see
</p>
<p>Chap. 2). The book then shortly introduces students to the nuts and bolts of survey
</p>
<p>research (see Chap. 3). The following chapter then very briefly teaches students how
</p>
<p>they can construct and administer their own survey. At the end of Chap. 4, students
</p>
<p>also learn how to construct their own questionnaire. The fifth chapter, entitled
</p>
<p>&ldquo;Conducting a Survey,&rdquo; instructs students on how to conduct a survey in the field.
</p>
<p>During this chapter, groups of students test their survey in an empirical setting by
</p>
<p>soliciting answers from peers. Chapters 6 to 9 are then dedicated to analyzing the
</p>
<p>survey. In more detail, students learn how to input their responses into either an
</p>
<p>SPSS or STATA dataset in the first part of Chap. 6. The second part covers
</p>
<p>univariate statistics and graphical representations of the data. In Chap. 7, I introduce
</p>
<p>different forms of means testing, and Chap. 8 is then dedicated to bivariate correla-
</p>
<p>tion and regression analysis. Finally, Chap. 9 covers multivariate regression
</p>
<p>analysis).
</p>
<p>The book can be used as a self-teaching device. In this case, students should redo
</p>
<p>the exercises with the data provided. In a second step, they should conduct all the
</p>
<p>tests with other data they have at their disposal. The book is also the perfect
</p>
<p>accompanying textbook for an introductory class to survey research and statistics.
</p>
<p>In the latter case, there is a built-in semester-long group exercise, which enhances the
</p>
<p>learning process. In the semester-long group work that follows the sequence of the
</p>
<p>book, students are asked to conceive, conduct, and analyze survey. The survey that is
</p>
<p>analyzed throughout is a colloquial survey that measures the amount of money
</p>
<p>students spend partying. Actually, the survey is an original survey including the
</p>
<p>original data, which one of my student groups collected during their semester-long
</p>
<p>project. Using this &ldquo;colloquial&rdquo; survey, the students in this study group had lots of
</p>
<p>fun collecting and analyzing their data, showing that learning statistics can (and
</p>
<p>should) be fun. I hope that the readers and users of this book experience the same joy
</p>
<p>in their first encounter with quantitative methods.
</p>
<p>2 1 Introduction</p>
<p/>
</div>
<div class="page"><p/>
<p>Step 1
</p>
<p>Step 2
</p>
<p>Step 3: 
</p>
<p>Step 4:
</p>
<p>Step 5:
</p>
<p>Step 6:
</p>
<p>Determine the purpose and the 
</p>
<p>design of the study. 
</p>
<p>De�ine/select the questions
</p>
<p>Decide upon the population and 
</p>
<p>sample
</p>
<p>Pre-test the questionnaire
</p>
<p>Conduct the survey
</p>
<p>Analyze the data
</p>
<p>Report the results
</p>
<p>Constructing a 
</p>
<p>Survey
</p>
<p>Conducting a Survey
</p>
<p>Analyzing a Survey
</p>
<p>Fig. 1.1 Different steps in survey research
</p>
<p>1 Introduction 3</p>
<p/>
</div>
<div class="page"><p/>
<p>The Nuts and Bolts of Empirical Social
Science 2
</p>
<p>Abstract
</p>
<p>This chapter covers the nuts and bolts of empirical political science. It gives an
</p>
<p>introduction into empirical research in the social sciences and statistics; explains
</p>
<p>the notion of concepts, theories, and hypotheses; as well as introduces students to
</p>
<p>the different steps in the quantitative research process.
</p>
<p>2.1 What Is Empirical Research in the Social Sciences?
</p>
<p>Regardless of the social science sub-discipline, empirical research in the social
</p>
<p>sciences tries to decipher how the world works around us. Be it development studies,
</p>
<p>economics, sociology, political science, or geography, just to name a few disciplines,
</p>
<p>researchers try to explain how some part of how the world is structured. For
</p>
<p>example, political scientists try to answer why some people vote, while others
</p>
<p>abstain from casting a ballot. Scholars in developmental studies might look at the
</p>
<p>influence of foreign aid on economic growth in the receiving country. Researchers in
</p>
<p>the field of education studies might examine how the size of a school class impacts
</p>
<p>the learning outcomes of high school students, and economists might be interested in
</p>
<p>the effect of raising the minimum wage on job growth. Regardless of the discipline
</p>
<p>they are in, social science researchers try to explain the behavior of individuals such
</p>
<p>as voters, protesters, and students; the behavior of groups such as political parties,
</p>
<p>companies, or social movement organizations; or the behavior of macro-level units
</p>
<p>such as countries.
</p>
<p>While the tools taught in this book are applicable to all social science disciplines,
</p>
<p>I mainly cover examples from empirical political science, because this is the
</p>
<p>discipline in which I teach and research. In all social sciences and in political science,
</p>
<p>more generally, knowledge acquisition can be both normative and empirical. Nor-
</p>
<p>mative political science asks the question of how the world ought to be. For example,
</p>
<p>normative democratic theorists quibble with the question of what a democracy ought
</p>
<p># Springer International Publishing AG 2019
</p>
<p>D. Stockemer, Quantitative Methods for the Social Sciences,
</p>
<p>https://doi.org/10.1007/978-3-319-99118-4_2
</p>
<p>5</p>
<p/>
<div class="annotation"><a href="http://crossmark.crossref.org/dialog/?doi=10.1007/978-3-319-99118-4_2&amp;domain=pdf">http://crossmark.crossref.org/dialog/?doi=10.1007/978-3-319-99118-4_2&amp;domain=pdf</a></div>
</div>
<div class="page"><p/>
<p>to be. Is it an entity that allows free, fair, and regular elections, which, in the
</p>
<p>democracy literature, is referred to as the &ldquo;minimum definition of democracy&rdquo;
</p>
<p>(Bogaards 2007)? Or must a country, in addition to having a fair electoral process,
</p>
<p>grant a variety of political rights (e.g., freedom of religion, freedom of assembly),
</p>
<p>social rights (e.g., the right to health care and housing), and economic rights (e.g., the
</p>
<p>right to education or housing) to be &ldquo;truly&rdquo; democratic? This more encompassing
</p>
<p>definition is currently referred to in the literature as the &ldquo;maximum definition of
</p>
<p>democracy&rdquo; (Beetham 1999). While normative and empirically oriented research
</p>
<p>have fundamentally different goals, they are nevertheless complementary. To high-
</p>
<p>light, an empirical democracy researcher must have a benchmark when she defines
</p>
<p>and codes a country as a democracy or nondemocracy. This benchmark can only be
</p>
<p>established through normative means. Normative political science must establish the
</p>
<p>&ldquo;gold standard&rdquo; against which empirically oriented political scientists can empiri-
</p>
<p>cally test whether a country is a democracy or not.
</p>
<p>As such, empirical political science is less interested in what a democracy should
</p>
<p>be, but rather how a democracy behaves in the real world. For instance, an empirical
</p>
<p>researcher could ask the following questions: Do democracies have more women&rsquo;s
</p>
<p>representation in parliament than nondemocracies? Do democracies have less mili-
</p>
<p>tary spending than autocracies or hybrid regimes? Is the history curriculum in high
</p>
<p>schools different in democracies than in other regimes? Does a democracy spend
</p>
<p>more on social services than an autocracy? Answering these questions requires
</p>
<p>observation and empirical data. Whether it is collected at the individual level through
</p>
<p>interviews or surveys, at the meso-level through, for example, membership data of
</p>
<p>parties or social movements, or at the macro level through government/international
</p>
<p>agencies or statistical offices, the collected data should be of high quality. Ideally, the
</p>
<p>measurement and data collection process of any study should be clearly laid down by
</p>
<p>the researcher, so that others can replicate the same study. After all, it is our goal to
</p>
<p>gain intersubjective knowledge. Intersubjective means that if two individuals would
</p>
<p>engage in the same data collection process and would conduct the same empirical
</p>
<p>study, their results would be analogous. To be as intersubjective or &ldquo;facts based&rdquo; as
</p>
<p>possible, empirical political science should abide by the following criteria:
</p>
<p>Falsifiability The falsifiability paradigm implies that statements or hypotheses can
</p>
<p>be proven or refuted. For example, the statement that democracies do not go to war
</p>
<p>with each other can be tested empirically. After defining what war and democracy is,
</p>
<p>we can get data that fits our definition for a country&rsquo;s regime type from a trusted
</p>
<p>source like the Polity IV data verse and data for conflict/war from another high-
</p>
<p>quality source such as the UCDP/PRIO Armed Conflict dataset. In second stop, we
</p>
<p>6 2 The Nuts and Bolts of Empirical Social Science</p>
<p/>
</div>
<div class="page"><p/>
<p>can then use statistics to test whether the statement that democracies refrain from
</p>
<p>engaging in warfare with each other is true or not.1,2
</p>
<p>Transmissibility The process through which the transmissibility of research
</p>
<p>findings is achieved is called replication. Replication refers to the process by
</p>
<p>which prior findings can be retested. Retesting can involve either the same data or
</p>
<p>new data from the same empirical referents. For instance, the &ldquo;law-like&rdquo; statement
</p>
<p>that democracies do not go to war with each other could be retested every 5 years
</p>
<p>with the most recent data from Polity IV and theUCDP/PRIO Armed Conflict dataset
</p>
<p>covering these 5 years to see if it still holds. Replication involves high scientific
</p>
<p>standards; it is only possible to replicate a study if the data collection, the data
</p>
<p>source, and the analytical tools are clearly explained and laid down in any piece of
</p>
<p>research. The replicator should then also use these same data and methods for her
</p>
<p>replication study.
</p>
<p>Cumulative Nature of Knowledge Empirical scientific knowledge is cumulative.
</p>
<p>This entails that substantive findings and research methods are based upon prior
</p>
<p>knowledge. In short, researchers do not start from scratch or intuition when engaging
</p>
<p>in a research project. Rather, they try to confirm, amend, broaden, or build upon prior
</p>
<p>research and knowledge. For example, the statement that democracies avoid war
</p>
<p>with each other had been confirmed and reconfirmed many times in the 1980s,
</p>
<p>1990s, and 2000s (see Russett 1994; De Mesquita et al. 1999). After confirming that
</p>
<p>the Democratic Peace Theory in its initial form is solid, researchers tried to broaden
</p>
<p>the democratic peace paradigm and examined, for example, if countries that share
</p>
<p>the same economic system (e.g., neoliberalism) also do not go to war with each
</p>
<p>other. Yet, for the latter relationship, tests and retests have shown that the empirical
</p>
<p>linkage for the economic system&rsquo;s peace is less strong than the democratic peace
</p>
<p>statement (Chandler 2010). The same applies to another possible expansion, which
</p>
<p>looks at if democracies, in general, are less likely to go to war than nondemocracies.
</p>
<p>Here again the empirical evidence is negative or inconclusive at best (Daase 2006;
</p>
<p>Mansfield and Snyder 2007).
</p>
<p>Generalizability In empirical social science, we are interested in general rather
</p>
<p>than specific explanations; we are interested in boundaries or limitations of empirical
</p>
<p>statements. Does an empirical statement only apply to a single case (e.g., does it only
</p>
<p>explain why the United States and Canada have never gone to war), or can it be
</p>
<p>generalized to explain many cases (e.g., does it explain why all pairs of democracies
</p>
<p>don&rsquo;t go to war?) In other words, if it can be generalized, does the democratic peace
</p>
<p>1The Polity IV database adheres to rather minimal definition of democracy. In essence, the database
</p>
<p>gauges the fairness and competitiveness of the elections and the electoral process on a scale from
</p>
<p>�10 to +10. �10 describes the &ldquo;worst&rdquo; autocracy, while 10 describes a country that fully respects
</p>
<p>free, fair, and competitive elections (Marshall et al. 2011).
2The UCDP/PRIO Armed Conflict Dataset defines minor wars by a death toll between 25 and 1000
</p>
<p>people and major wars by a death toll of 1000 people and above (see Gleditsch 2002).
</p>
<p>2.1 What Is Empirical Research in the Social Sciences? 7</p>
<p/>
</div>
<div class="page"><p/>
<p>paradigm apply to all democracies, or only to neoliberal democracies, and does it
</p>
<p>apply across all (normative) definitions of democracies, as well as all time periods?).
</p>
<p>Stated differently, we are interested in the number of cases in which the statement is
</p>
<p>applicable. Of course, the broader the applicability of an explanation, the more
</p>
<p>weight it carries. In political science the Democratic Peace Theory is among the
</p>
<p>theories with the broadest applicability. While there are some questionable cases of
</p>
<p>conflict between states such as the conflict between Turkey and Greece over Cyprus
</p>
<p>in 1974, there has, so far, been no case that clearly disproves the Democratic Peace
</p>
<p>Theory. In fact, the Democratic Peace Theory is one of the few law-like rules in
</p>
<p>political science.
</p>
<p>2.2 Qualitative and Quantitative Research
</p>
<p>In the social sciences, we distinguish two large strands of research: quantitative and
</p>
<p>qualitative research. The major difference between these two research traditions is
</p>
<p>the number of observations. Research that involves few observations (e.g., one, two,
</p>
<p>or three individuals or countries) is generally referred to as qualitative. Such research
</p>
<p>requires an in-depth examination of the cases at hand. In contrast, work that includes
</p>
<p>hundreds, thousands, or even hundred thousand observations is generally called
</p>
<p>quantitative research. Quantitative research works with statistics or numbers that
</p>
<p>allow researchers to quantify the world. In the twenty-first century, statistics are
</p>
<p>nearly everywhere. In our daily lives, we encounter statistics in approval ratings of
</p>
<p>TV shows, the measurement of consumer preferences, weather forecasts, and betting
</p>
<p>odds, just to name a few examples. In social and political science research, statistics
</p>
<p>are the bread and butter of much scientific inquiry; statistics help us make sense of
</p>
<p>the world around us. For instance, in the political realm, we might gauge turnout
</p>
<p>rates as a measurement of the percentage of citizens that turned out during an
</p>
<p>election. In economics, some of the most important indicators about the state of
</p>
<p>the economy are monthly growth rates and consumer price indexes. In the field of
</p>
<p>education, the average grade of a student from a specific school gives an indication
</p>
<p>of the school&rsquo;s quality.
</p>
<p>By using statistics, quantitative methods not only allow us to numerically
</p>
<p>describe phenomena, they also help us determine relationships between two or
</p>
<p>more variables. Examples of these relationships are multifold. For example, in the
</p>
<p>field of political science, statistics and quantitative methods have allowed us to
</p>
<p>detect that citizens who have a higher socioeconomic status (SES) are more likely
</p>
<p>to vote than individuals with a lower socioeconomic status (Milligan et al. 2004). In
</p>
<p>the field of economics, researchers have established with the help of quantitative
</p>
<p>analysis that low levels of corruption foster economic growth (Mo 2001). And in
</p>
<p>education research, there is near consensus in the quantitative research tradition that
</p>
<p>students from racially segregated areas and poor inner-city schools, on average,
</p>
<p>perform less strongly in college entry exams than students from rich, white
</p>
<p>neighborhoods (Rumberger and Palardy 2005).
</p>
<p>8 2 The Nuts and Bolts of Empirical Social Science</p>
<p/>
</div>
<div class="page"><p/>
<p>Quantitative research is the primary tool to establish empirical relationships.
</p>
<p>However, it is less well-suited to explain the constituents or causal mechanism
</p>
<p>behind a statistical relationship. To highlight, quantitative research can illustrate
</p>
<p>that individuals with low education levels and below average income are less likely
</p>
<p>to vote compared to highly educated and rich citizens. Yet, it is less suitable to
</p>
<p>explain the reasons for their abstentions. Do they not feel represented? Are they fed
</p>
<p>up with how the system works? Do they not have the information and knowledge
</p>
<p>necessary to vote? Similarly, quantitative research robustly tells us that students in
</p>
<p>racially segregated areas tend to perform less strongly than students in predomi-
</p>
<p>nantly white and wealthy neighborhoods. However, it does not tell us how the
</p>
<p>disadvantaged students feel about these inequalities and what they think can be
</p>
<p>done to reverse them. Are they enraged or fed up with the political regime and the
</p>
<p>politicians that represent it? Questions like these are better answered by qualitative
</p>
<p>research. The qualitative researcher wants to interpret the observational data (i.e., the
</p>
<p>fact that low SES individual has a higher likelihood to vote) and wants to grasp the
</p>
<p>opinions and attitudes of study subjects (i.e., how minority students feel in dis-
</p>
<p>advantaged areas, how they think the system perpetuates these inequalities, and
</p>
<p>under what circumstances they are ready to protest). To gather this in-depth infor-
</p>
<p>mation, the qualitative researcher uses different techniques than the quantitative
</p>
<p>researchers. She needs research tools to tap into the opinions, perceptions, and
</p>
<p>feelings of study subjects. Tools appropriate for these inquiries are ethnographic
</p>
<p>methods including qualitative interviewing, participant observations, and the study
</p>
<p>of focus groups. These tools help us understand how individuals live, act, think, and
</p>
<p>feel in their natural setting and give meaning to quantitative findings.
</p>
<p>In addition to allowing us to decipher meaning behind quantitative relationships,
</p>
<p>qualitative research techniques are an important tool in theory building. In fact, many
</p>
<p>research findings originate in qualitative research and are tested in a later stage in a
</p>
<p>quantitative large-N study. To take a classic in social sciences, Theda Skocpol offers
</p>
<p>in her seminal work States and Social Revolutions: A comparative Analysis of Social
</p>
<p>Revolutions in Russia, France and China (1979), an explanation for the occurrence
</p>
<p>of three important revolutions in the modern world, the French Revolution in 1789,
</p>
<p>the Chinese Revolution in 1911, and the Russian Revolution in 1917. Through
</p>
<p>historical analysis, Skocpol identifies three conditions for a revolution to happen:
</p>
<p>(1) a profound state crisis, (2) the emergence of a dominant class outside of the ruling
</p>
<p>elites, and (3) a state of severe economic and/or security crisis. Skocpol&rsquo;s book is an
</p>
<p>important exercise in theory building. She identifies three causal conditions,
</p>
<p>conditions that are quantifiable and that can be tested for other or all revolutions.
</p>
<p>By testing whether a profound state crisis, the emergence of a dominant class outside
</p>
<p>of the ruling elites, or a state of crisis explains other or all revolutions, quantitative
</p>
<p>researchers can establish the boundary conditions of Skocpol&rsquo;s theory.
</p>
<p>It is also important to note that not all research is quantifiable. Some phenomena
</p>
<p>such as individual identities or ideologies are difficult to reduce to numbers: What
</p>
<p>are ethnic identities, religious identities, or regional identities? Often these critical
</p>
<p>concepts are not only difficult to identify but frequently also difficult to grasp
</p>
<p>empirically. For example, to understand what the regional francophone identity of
</p>
<p>2.2 Qualitative and Quantitative Research 9</p>
<p/>
</div>
<div class="page"><p/>
<p>Quebecers is, we need to know the historical, social, and political context of the
</p>
<p>province and the fact that the province is surrounded by English speakers. To get a
</p>
<p>complete grasp of this regional identity, we, ideally, also have to retrace the recent
</p>
<p>development that more and more English is spoken in the major cities of Qu&eacute;bec
</p>
<p>such as Montr&eacute;al, particularly in the business world. These complexities are hard to
</p>
<p>reduce to numbers and need to be studied in-depth. For other events, there are just
</p>
<p>not enough observations to quantify them. For example, the Cold War is a unique
</p>
<p>event, an event that organized and shaped the world for 45 years in the twentieth
</p>
<p>century. Nearly, by definition this even is important and needs to be studied in-depth.
</p>
<p>Other events, like World War I and World War II, are for sure a subset of wars.
</p>
<p>However, these two wars have been so important for world history that, nearly by
</p>
<p>definition, they require in-depth study, as well. Both wars have shaped who we as
</p>
<p>individuals are (regardless where we live), what we think, how we act, and what we
</p>
<p>do. Hence, any bits of additional knowledge we acquire from these events not only
</p>
<p>help us understand the past but also help us move forward in the future.
</p>
<p>Quantitative and qualitative methods are complimentary; students of the social
</p>
<p>sciences should master both techniques. However, it is hardly possible to do a
</p>
<p>thorough introduction into both. This book is about survey research, quantitative
</p>
<p>research tools, and statistics. It will teach you how to draft, conduct, and analyze a
</p>
<p>survey. However, before delving into the nuts and bolts of data analysis, we need to
</p>
<p>know what theories, hypotheses, concepts, and variables are. The next section will
</p>
<p>give you a short overview of these building blocks in social research.
</p>
<p>2.3 Theories, Concepts, Variables, and Hypothesis
</p>
<p>2.3.1 Theories
</p>
<p>We have already learnt that social science research is cumulative. We build current
</p>
<p>knowledge on prior knowledge. Normally, we summarize our prior knowledge in
</p>
<p>theories, which are parsimonious or simplified explanations of how the world works.
</p>
<p>As such, a theory summarizes established knowledge in a specific field of study.
</p>
<p>Because the world around us is dynamic, a theory in the social sciences is never a
</p>
<p>deterministic statement. Rather it is open to revisions and amendments.3 Theories
</p>
<p>can cover the micro-, meso-, and macro-levels. Below are three powerful social
</p>
<p>sciences theories.
</p>
<p>Example of a Microlevel Theory: Relative Deprivation
</p>
<p>Relative deprivation is a powerful individual-level theory to explain and predict
</p>
<p>citizens&rsquo; participation in social movement activities. Relative deprivation starts with
</p>
<p>the premise that individuals do not protest, when they are happy with their lives.
</p>
<p>3The idea behind parsimony is that scientists should rely on as few explanatory factors as possible
</p>
<p>while retaining a theory&rsquo;s generalizability.
</p>
<p>10 2 The Nuts and Bolts of Empirical Social Science</p>
<p/>
</div>
<div class="page"><p/>
<p>Rather grievance theorists (e.g., Gurr 1970; Runciman 1966) see a discrepancy
</p>
<p>between value expectation and value capabilities as the root cause for protest
</p>
<p>activity. For example, according to Gurr (1970), individuals normally have no
</p>
<p>incentive to protest and voice their dissatisfaction if they are content with their
</p>
<p>daily lives. However, a deteriorating economic, social, or political situation can
</p>
<p>trigger frustrations, whether or real or perceived; the higher these frustrations are, the
</p>
<p>higher the likelihood that somebody will protest.
</p>
<p>Example of a Meso-level Theory: The Iron Law of Oligarchy
</p>
<p>The iron law of oligarchy is a political meso-level theory developed by German
</p>
<p>sociologist Robert Michels. His main argument is that over time all social groups,
</p>
<p>including trade unions and political parties, will develop hierarchical power
</p>
<p>structures or oligarchic tendencies. Stated differently, in any organization a &ldquo;leader-
</p>
<p>ship class&rdquo; consisting of paid administrators, spokespersons, societal elites, and
</p>
<p>organizers will prevail and centralize its power. And with power comes the possi-
</p>
<p>bility to control the laws and procedures of the organization and the information it
</p>
<p>communicates as well as the possibility to reward faithful members; all these
</p>
<p>tendencies are accelerated by apathetic masses, which will allow elites to hierarchize
</p>
<p>an organization faster (see Michels 1915).
</p>
<p>Example of a Macro-level Theory: The Democratic Peace Theory
</p>
<p>As discussed earlier in this chapter, a famous example of a macro-level theory is the
</p>
<p>so-called Democratic Peace Theory, which dates back to Kant&rsquo;s treatise on Perpetual
</p>
<p>Peace (1795). The theory states that democracies will not go to war with each other.
</p>
<p>It explicitly tackles the behavior of some type of state (i.e., democracies) and has
</p>
<p>only applicability at the macro-level.
</p>
<p>Theory development is an iterative process. Because the world around us is
</p>
<p>dynamic (what is true today might no longer be true tomorrow), a theory must be
</p>
<p>perpetually tested and retested against reality. The more it is confirmed across time
</p>
<p>and space, the more it is robust. Theory building is a reiterative and lengthy process.
</p>
<p>Sometimes it takes years, if not decades to build and construct a theory. A famous
</p>
<p>example of how a theory can develop and refine is the simple rational choice theory
</p>
<p>of voting. In his 1957 famous book, An Economic Theory of Democracy, Anthony
</p>
<p>Downs tries to explain why some people vote, whereas others abstain from casting
</p>
<p>their ballots. Using a simple rational choice explanation, he concludes that voting is a
</p>
<p>&ldquo;rational act&rdquo; if the benefits of voting surpass the costs. To operationalize his theory,
</p>
<p>he defines the benefits of voting by the probability that an individual vote counts.
</p>
<p>The costs include the physical costs of actually leaving one&rsquo;s house and casting a
</p>
<p>ballot, as well as the ideational costs of gathering the necessary information to cast
</p>
<p>an educated ballot. While Downs finds his theory logical, he intuitively finds that
</p>
<p>there is something wrong with it. That is, the theory would predict that in the overall
</p>
<p>majority of cases, citizens should not vote, because in almost every case, the
</p>
<p>probability that an individual&rsquo;s vote will count is close to 0. Hence, the costs of
</p>
<p>voting surpass the benefits of voting for nearly every individual. However, Downs
</p>
<p>2.3 Theories, Concepts, Variables, and Hypothesis 11</p>
<p/>
</div>
<div class="page"><p/>
<p>finds that in the majority people still vote, but does not have an immediate answer for
</p>
<p>this paradox of voting.
</p>
<p>More than 10 years later, in a reformulation of Downs&rsquo; theory, Riker and
</p>
<p>Ordeshook (1968) resolve Downs&rsquo; paradox by adding an important component to
</p>
<p>Downs&rsquo; model: the intangible benefits. According to the authors, the benefits of
</p>
<p>voting are not reduced to pure materialistic evaluations (i.e., the chance that a
</p>
<p>person&rsquo;s vote counts) but also to some nonmaterialistic benefits such as citizens&rsquo;
</p>
<p>willingness to support democracy or the democratic system. Adding this additional
</p>
<p>component makes Down&rsquo;s theory more realistic and in tune with reality. On the
</p>
<p>negative side, adding nonmaterial benefits makes Down&rsquo;s theory less parsimonious.
</p>
<p>However, all researchers would probably agree that this sacrifice of parsimony is
</p>
<p>more than compensated for by the higher empirical applicability of the theory.
</p>
<p>Therefore, in this case the more complex theory is preferential to the more parsi-
</p>
<p>monious theory. More generally, a theory should be as simple or parsimonious as
</p>
<p>possible and as complex as necessary.
</p>
<p>2.3.2 Concepts
</p>
<p>Theories are abstractions of objects, objects&rsquo; properties, or behavioral phenomena.
</p>
<p>Any theory normally consists of at least two concepts, which define a theory&rsquo;s
</p>
<p>content and attributes. For example, the Democratic Peace Theory consists of the
</p>
<p>two concepts: democracy and war. Some concepts are concise (e.g., wealth, edu-
</p>
<p>cation, women&rsquo;s representation) and easier to measure, whereas other concepts are
</p>
<p>abstract (democracy, equal opportunity, human rights, social mobility, political
</p>
<p>culture) and more difficult to gauge. Whether abstract or precise, concepts provide
</p>
<p>a common language for political science. For sure, researchers might disagree about
</p>
<p>the precise (normative) definition of a concept. Nevertheless, they agree about its
</p>
<p>meaning. For example, if we talk about democracy, there is common understanding
</p>
<p>that we talk about a specific regime type that allows free and fair elections and some
</p>
<p>other freedoms. Nevertheless, there might be disagreement about the precise defi-
</p>
<p>nition of the concept in question; in this case disagreement about democracy might
</p>
<p>revolve the following questions: do we only look at elections, do we include political
</p>
<p>rights, social rights, economic rights, or all of the above? To avoid any confusion,
</p>
<p>researchers must be precise when defining the meaning of a concept. In particular,
</p>
<p>this applies for contested concepts such as democracy. As already mentioned, for
</p>
<p>some scholars, the existence of parties, free and fair elections, and a reasonable
</p>
<p>participation by the population might be enough to classify a country as a demo-
</p>
<p>cracy. For others, a country must have legally enforced guarantees for freedoms of
</p>
<p>speech, press, and religion and must guarantee social and economic rights. It can be
</p>
<p>either a normative or a practical question or both whether one or the other classifi-
</p>
<p>cation is more appropriate. It might also be a question of the specific research topic or
</p>
<p>research question, whether one or the other definition is more appropriate. Yet,
</p>
<p>whatever definition she chooses, a researcher must clearly identify and justify the
</p>
<p>12 2 The Nuts and Bolts of Empirical Social Science</p>
<p/>
</div>
<div class="page"><p/>
<p>choice of her definition, so that the reader of a published work can judge the
</p>
<p>appropriateness of the chosen definition.
</p>
<p>It is also worth noting that the meaning of concepts can also change over time. Take
</p>
<p>again the example of democracy. Democracy 2000 years ago had a different meaning
</p>
<p>than democracy today. In the Greek city-states (e.g., Athens), democracy was a system
</p>
<p>of direct decision-making, in which all men above a certain income threshold convened
</p>
<p>on a regular basis to decide upon important matters such as international treaties, peace
</p>
<p>and war, as well as taxation. Women, servants, slaves, and poor citizens were not
</p>
<p>allowed to participate in these direct assemblies. Today, more than 2000 years after the
</p>
<p>Greek city-states, we commonly refer to democracy as a representative form of
</p>
<p>government, in which we elect members to parliament. In the elected assembly, these
</p>
<p>elected politicians should then represent the citizens that mandated them to govern.
</p>
<p>Despite the contention of how many political, civic, and social rights are necessary to
</p>
<p>consider a country a democracy, there is nevertheless agreement among academics and
</p>
<p>practitioners today that the Greek definition of democracy is outdated. In the twenty-
</p>
<p>first century, no serious academic would disagree that suffrage must be universal, each
</p>
<p>vote must count equally, and elections must be free and fair and must occur on a regular
</p>
<p>basis such as in a 4- or 5-year interval.
</p>
<p>2.3.3 Variables
</p>
<p>A variable refers to properties or attributes of a concept that can be measured in some
</p>
<p>way or another: in short, a variable is a measurable version of a concept. The process
</p>
<p>to transform a concept into a variable is called operationalization. To take an
</p>
<p>example, age is a variable, but the answer to the question how old you are is a
</p>
<p>variable. Some concepts in political or social science are rather easy to measure. For
</p>
<p>instance, on the individual level, somebody&rsquo;s education level can be measured by the
</p>
<p>overall years of schooling somebody has achieved or by the highest degree some-
</p>
<p>body has obtained. On the macro-level, women&rsquo;s representation in parliament can be
</p>
<p>easily measured by the percentage of seats in the elected assembly which are
</p>
<p>occupied by women. Other concepts, such as someone&rsquo;s political ideology on the
</p>
<p>individual level or democracy on the macro-level, are more difficult to measure. For
</p>
<p>example, operationalizations of political ideology range from the party one identifies
</p>
<p>with, to answers to survey questions about moral issues such as abortion or same-sex
</p>
<p>marriage, and to questions about whether somebody prefers more welfare state
</p>
<p>spending and higher taxes or less welfare state spending and lower taxes. For
</p>
<p>democracy, as already discussed, there is not only discussion of the precise definition
</p>
<p>of democracy but also on how to measure different regime types. For example, there
</p>
<p>is disagreement in the academic literature if we should adopt a dichotomous defi-
</p>
<p>nition that distinguishes a democracy from a nondemocracy (Przeworski et al. 1996),
</p>
<p>a distinction in democracy, hybrid regime, or autocracy (Bollen 1990), or if we
</p>
<p>should use a graded measure, that is, democracy is not a question of kind, but of
</p>
<p>degree, and the gradation should capture sometimes partial processes of democratic
</p>
<p>institutions in many countries (Elkins 2000).
</p>
<p>2.3 Theories, Concepts, Variables, and Hypothesis 13</p>
<p/>
</div>
<div class="page"><p/>
<p>When measuring a concept, it is important that a concept has high content
</p>
<p>validity; there should be a high degree of convergence between the measure and
</p>
<p>the concept it is thought to represent. In other words, a high content validity is
</p>
<p>achieved if a measure represents all facets of a given concept. To highlight how this
</p>
<p>convergence can be achieved, I use one famous definition of democracy, Dahl&rsquo;s
</p>
<p>polyarchy. Polyarchy, according to Dahl, is a form of representative democracy
</p>
<p>characterized by a particular set of political institutions. These include elected
</p>
<p>officials, free and fair elections, inclusive suffrage, the right to run for office,
</p>
<p>freedom of expression, alternative information, and associational autonomy (see
</p>
<p>Dahl 1973). To achieve high content validity, any measurement of polyarchy must
</p>
<p>include the seven dimensions of democracy; that is, any of these seven dimensions
</p>
<p>must be explicitly measured. Sometimes a conceptual definition predisposes
</p>
<p>researchers to use one operationalization of a concept over another one. In Dahl&rsquo;s
</p>
<p>classification, the respect of the seven features is a minimum standard for demo-
</p>
<p>cracy; that is why his concept of polyarchy is best operationalized dichotomously.
</p>
<p>That is, a country is a polyarchy if it respects all of the seven features and is not if it
</p>
<p>doesn&rsquo;t (i.e., it is enough to not qualify as a democracy if one of the features is not
</p>
<p>respected). Table 2.1 graphically displays this logic. Only country 1 respects all
</p>
<p>features of a polyarchy and can be classified as such. Countries 2 and 3 violate some
</p>
<p>or all of these minimum conditions of polyarchy and hence must be coded as
</p>
<p>nondemocracies.
</p>
<p>Achieving high content validity is not always easy. Some concepts are difficult to
</p>
<p>measure. Take the concept of political corruption. Political corruption, or the private
</p>
<p>(mis)use of public funds for illegitimate private gains, happens behind closed doors
</p>
<p>without the supervision of the public. Nearly by definition this entails that nearly all
</p>
<p>proxy variables to measure corruption are imperfect. There are at least three ways to
</p>
<p>measure corruption:
</p>
<p>1. Large international efforts compiled by international organizations such as the
</p>
<p>World Bank or Transparency International try to track corruption in the public
</p>
<p>sector around the globe. For example, the Corruption Perceptions Index (CPI)
</p>
<p>Table 2.1 Measuring Dahl&rsquo;s polyarchy
</p>
<p>Components of democracy
</p>
<p>Country
</p>
<p>1
</p>
<p>Country
</p>
<p>2
</p>
<p>Country
</p>
<p>3
</p>
<p>Elected officials have control over government decisions x &ndash; x
</p>
<p>Free, fair, and frequent elections x &ndash; x
</p>
<p>Universal suffrage x &ndash; x
</p>
<p>Right to run for office for all citizens x &ndash; x
</p>
<p>Freedom of expression x &ndash; &ndash;
</p>
<p>Alternative sources of information x &ndash; &ndash;
</p>
<p>Right to form and join autonomous political
</p>
<p>organizations
</p>
<p>x &ndash; x
</p>
<p>Polyarchy Yes No No
</p>
<p>14 2 The Nuts and Bolts of Empirical Social Science</p>
<p/>
</div>
<div class="page"><p/>
<p>focuses on corruption in the public sector. It uses expert surveys with country
</p>
<p>experts inside and outside the country under scrutiny on, among others, bribery of
</p>
<p>public officials, kickbacks in public procurement, embezzlement of public funds,
</p>
<p>and the strength and effectiveness of public sector anti-corruption efforts. It then
</p>
<p>creates a combined measure from these surveys.
</p>
<p>2. National agencies in several (Western) countries track data on the number of
</p>
<p>federal, state, and local government officials prosecuted and convicted for cor-
</p>
<p>ruption crimes.
</p>
<p>3. International public opinion surveys (e.g., the World Value Survey) ask citizens
</p>
<p>about their own experience with corruption (e.g., if they have paid or received a
</p>
<p>bribe to or for any public service within the past 12 months).
</p>
<p>Any of these three measurements is potentially problematic. First, perception
</p>
<p>indexes based on interviews/surveys with country experts can be deceiving, as there
</p>
<p>is no hard evidence to back up claims of high or low corruption, even if these
</p>
<p>assessments come from so-called experts. However, the hard evidence can be
</p>
<p>deceiving as well. Are many corruption charges and indictments a sign of high or
</p>
<p>low corruption? They might be a sign of high corruption, as it shows corruption is
</p>
<p>widespread; a certain percentage of the officials in the public sector engage in the
</p>
<p>exchange of public goods for private promotion. Yet, many cases treated in court
</p>
<p>might also be a sign of low corruption. It might show that the system works, as it
</p>
<p>cracks down on corrupted officials. For the third measure, citizens&rsquo; personal experi-
</p>
<p>ence with corruption is suboptimal, as well. Given that corruption is a shameful act,
</p>
<p>survey participants might not admit that they have participated in fraudulent
</p>
<p>activities. They might also fear repercussions by the public if they admit being
</p>
<p>part of a corrupt network. Finally, it might not be rational to admit corruption,
</p>
<p>particularly if you are one of the beneficiaries of it.
</p>
<p>In particular, for difficult to measure concepts such as corruption, it might be
</p>
<p>advisable to cross-validate any imperfect proxy with another measure. In other
</p>
<p>words, different measures must resemble each other if they tap into the same
</p>
<p>concept. If this is the case, we speak of high construct validity, and it is possibly
</p>
<p>safe to use one proxy or even better create a conjoint index of the proxy variables in
</p>
<p>question. If this is not the case, then there is a problem with one or several
</p>
<p>measurements, something the researcher should assess in detail. One way to measure
</p>
<p>whether two measurements of the same variable are strongly related to each other is
</p>
<p>through correlation analysis (see Chap. 8).
</p>
<p>Sometimes it is not only difficult to achieve high operational validity of difficult
</p>
<p>concepts such as corruption but sometimes also for seemingly simple concepts such
</p>
<p>as voting or casting a ballot for a radical right-wing party. In answering a survey,
</p>
<p>individuals might pretend they have voted or cast a ballot for a mainstream party to
</p>
<p>pretend that they abide by the societal norms. Yet it is very difficult to detect the
</p>
<p>type of individuals, who either deliberately or undeliberately answer a survey
</p>
<p>question incorrectly (for a broader discussion of biases in survey research, see
</p>
<p>Sect. 5.2).
</p>
<p>2.3 Theories, Concepts, Variables, and Hypothesis 15</p>
<p/>
</div>
<div class="page"><p/>
<p>2.3.3.1 Types of Variables
In empirical research we distinguish two main types of variables: dependent variable
</p>
<p>and independent variable.
</p>
<p>Dependent Variable The dependent variable is the variable the researcher is trying
</p>
<p>to explain. It is the primary variable of interest and depends on other variables
</p>
<p>(so-called independent variables). In quantitative studies, the dependent variable has
</p>
<p>the notation y.
</p>
<p>Independent Variable Independent variables are hypothesized to explain variation
</p>
<p>in the dependent variable. Because they are thought to explain variation or changes
</p>
<p>in the dependent variable, independent variables are sometimes also called expla-
</p>
<p>natory variables (as they should explain the dependent variable). In quantitative
</p>
<p>studies, the independent variable has the notation x.
</p>
<p>I use another famous theory, modernization theory, to explain the difference
</p>
<p>between independent and dependent variable. In essence, modernization theory
</p>
<p>states that countries with a higher degree of development are more likely to be
</p>
<p>democratic (Lipset 1959). In this example, the dependent variable is regime type
</p>
<p>(however measured). The independent variable is a country&rsquo;s level of development,
</p>
<p>which could, for instance, be measured by a country&rsquo;s GDP per capita.
</p>
<p>In the academic literature, independent variables that are not the focus of the
</p>
<p>study, but which might also have an influence on the dependent variable, are
</p>
<p>sometimes referred to as control variables. To take an example from the turnout
</p>
<p>literature, a researcher might be interested in the relationship between electoral
</p>
<p>competitiveness and voter turnout. Electoral competitiveness is the independent
</p>
<p>variable, and turnout is the dependent variable. However, turnout rates in countries
</p>
<p>or electoral districts are not only dependent on the competiveness of the election
</p>
<p>(which is often operationalized by the difference in votes between the winner and the
</p>
<p>runner-up) but also by a host of other factors including compulsory voting, the
</p>
<p>electoral system type, corruption, or income inequalities, to name a few factors.
</p>
<p>These other independent variables must also be accounted for and included in the
</p>
<p>study. In fact, researchers can only test the &ldquo;real impact&rdquo; of competitiveness on
</p>
<p>turnout, if they also take these other factors into consideration.
</p>
<p>2.3.4 Hypotheses
</p>
<p>A hypothesis is a tentative, provisional, or unconfirmed statement derived from
</p>
<p>theory that can (in principle) be either verified or falsified. It explicitly states the
</p>
<p>expected relationship between an independent and dependent variable. Hypotheses
</p>
<p>must be empirically testable statements that can cover any level of analysis. In fact, a
</p>
<p>good hypothesis should specify the types or level of political actor to which the
</p>
<p>hypothesis will test (see also Table 2.2).
</p>
<p>16 2 The Nuts and Bolts of Empirical Social Science</p>
<p/>
</div>
<div class="page"><p/>
<p>Macro-level An example of a macro-level hypothesis derived from modernization
</p>
<p>theory would be: The more highly developed a country, the more likely it is a
</p>
<p>democracy.
</p>
<p>Meso-level An example of a meso-level hypothesis derived from the iron law of
</p>
<p>oligarchy would be: The longer a political or social organization is in existence, the
</p>
<p>more hierarchical are its power structures.
</p>
<p>Microlevel An example of a microlevel hypothesis derived from the resource theory
</p>
<p>of voting would be: The higher somebody&rsquo;s level of education, the more likely they
</p>
<p>are to vote.
</p>
<p>Scientific hypotheses are always stated in the following form:
</p>
<p>The more [independent variable], the more [dependent variable] or the more
</p>
<p>[independent variable], the less [dependent variable].
</p>
<p>When researchers formulate hypotheses, they make three explicit statements:
</p>
<p>1. X and Y covary. This implies that there is variation in the independent and
</p>
<p>dependent variable and that at least some of the variation in the dependent
</p>
<p>variable is explained by variation in the independent variable.
</p>
<p>2. Change in X precedes change in Y. By definition a change in independent variable
</p>
<p>can only trigger a change in the dependent variable if this change happens before
</p>
<p>the change in the dependent variable.
</p>
<p>3. The effect of the independent variable on the dependent variable is not coinci-
</p>
<p>dental or spurious (which means explained by other factors) but direct.
</p>
<p>To provide an example, the resource theory of voting states that individuals with
</p>
<p>higher socioeconomic status (SES) are more likely to vote. From this theory, I can
</p>
<p>derive the microlevel hypothesis that the more educated a citizen is, the higher the
</p>
<p>chance that she will cast a ballot. To be able to test this hypothesis, I operationalize
</p>
<p>SES by a person&rsquo;s years of full-time schooling and voting by a survey question
</p>
<p>asking whether somebody voted or not in the last national election. By formulating
</p>
<p>this hypothesis, I make the implicit assumption that there is variation in the overall
</p>
<p>years of schooling and variation in voting. I also explicitly state that the causal
</p>
<p>Table 2.2 Examples of good and bad hypotheses
</p>
<p>Wrong Right
</p>
<p>Democracy is the best form of
</p>
<p>government
</p>
<p>The more democratic a country is, the better its
</p>
<p>government performance will be
</p>
<p>The cause of civil war is economic
</p>
<p>upheaval
</p>
<p>The more there is economic upheaval, the more likely a
</p>
<p>country will experience civil war
</p>
<p>Raising the US minimum wage
</p>
<p>will affect job growth
</p>
<p>Raising the minimum wage will create more jobs (positive
</p>
<p>relationship)
</p>
<p>Raising the minimum wage will cut jobs (negative
</p>
<p>relationship)
</p>
<p>2.3 Theories, Concepts, Variables, and Hypothesis 17</p>
<p/>
</div>
<div class="page"><p/>
<p>explanatory chain goes from education to voting (i.e., that education precedes
</p>
<p>voting). Finally, I expect that changes in somebody&rsquo;s education trigger changes in
</p>
<p>somebody&rsquo;s likelihood to vote (i.e., I expect the relationship to not be spurious).
</p>
<p>While for the resource hypothesis, there is probably consensus that the causal chain
</p>
<p>goes from more education to a higher likelihood to vote, and not the other way
</p>
<p>around, the same does not apply to all empirical relationships. Rather, in political
</p>
<p>science we do not always have a one-directional relationship. For example, regard-
</p>
<p>ing the modernization hypothesis, there is some debate in the scholarly community
</p>
<p>surrounding whether it is development that triggers the installation of democracy or
</p>
<p>if it is democracy that triggers robust economic development more than any other
</p>
<p>regime type. There are statistical methods to treat cases of reversed causation such as
</p>
<p>structural equation modelling. Because of the advanced nature of these techniques, I
</p>
<p>will not cover these techniques in this book. Nevertheless, what is important to take
</p>
<p>away from this discussion is that students of political science and the social sciences,
</p>
<p>more generally, must think carefully about the direction of cause and effect before
</p>
<p>they formulate a hypothesis.
</p>
<p>It is also important that students know the difference between an alternative
</p>
<p>hypothesis and a null hypothesis. The alternative hypothesis, sometimes also called
</p>
<p>research hypothesis, is the hypothesis you are going to test. The null hypothesis is
</p>
<p>the rival hypothesis&mdash;it assumes that there is no association between the independent
</p>
<p>and dependent variables. To give an example derived from the iron law of oligarchy,
</p>
<p>a researcher wanting to test this theory could postulate the hypothesis that &ldquo;the
</p>
<p>longer a political organization is in existence, the more hierarchical it will get.&rdquo; In
</p>
<p>social science jargon, this hypothesis is called the alternative hypothesis. The
</p>
<p>corresponding null-hypothesis would be that length of existence of a political
</p>
<p>organization and its hierarchical structure are unrelated.
</p>
<p>2.4 The Quantitative Research Process
</p>
<p>The quantitative research process is deductive (see Fig. 2.1). It is theory driven; it
</p>
<p>starts and ends with theory. Before the start of any research project, students of
</p>
<p>political science must know the relevant literatures. They must know the dominant
</p>
<p>theories and explanations of the phenomenon they want to study and identify
</p>
<p>controversies and holes or gaps in knowledge. The existing theory will then guide
</p>
<p>them to formulate some hypotheses that will ideally try to resolve some of the
</p>
<p>controversies or fill one or several gaps in knowledge. Quantitative research might
</p>
<p>also test existing theories with new quantitative data, establish the boundaries or
</p>
<p>limitations of a theory, or establish the conditions under which a theory applies.
</p>
<p>Whatever its purpose, good research starts with a theoretically derived research
</p>
<p>question and hypothesis. Ideally, the research question should address a politically
</p>
<p>relevant and important topic and make a potential theoretical contribution to the
</p>
<p>literature (it should potentially add to, alter, change, or refute the existing theory).
</p>
<p>The hypothesis should clearly identify the independent and dependent variable. It
</p>
<p>should be a plausible statement of how the researcher thinks that the independent
</p>
<p>18 2 The Nuts and Bolts of Empirical Social Science</p>
<p/>
</div>
<div class="page"><p/>
<p>variable behaves toward the dependent variable. In addition, the researcher must also
</p>
<p>identify potential control variables. In the next step, the researcher has to think about
</p>
<p>how to measure independent, dependent, and control variables. When
</p>
<p>operationalizing her variables, she must ensure that there is high content validity
</p>
<p>between the numerical representation and the conceptional definition of any given
</p>
<p>concept. After having decided how to measure the variables, the researcher has to
</p>
<p>think about sampling. In other words, which empirical referents will she use to test
</p>
<p>her hypothesis? Measurement and sampling are often done concurrently, because the
</p>
<p>empirical referents, which the researchers study, might predispose her to use one
</p>
<p>operationalization of an indicator over another. Sometimes, also practical consider-
</p>
<p>ations such as the existence of empirical data determine the measurement of
</p>
<p>variables and the number and type of observations studied. Once the researcher
</p>
<p>has her data, she can then conduct the appropriate statistical tests to evaluate research
</p>
<p>question and hypothesis. The results of her study will then ideally have an influence
</p>
<p>on theory.
</p>
<p>Let us explain Fig. 2.1 with a concrete example. We assume that a researcher is
</p>
<p>interested in individuals&rsquo; participation in demonstrations. Reading the literature, she
</p>
<p>finds two dominant theories. On the one hand, the resource theory of political action
</p>
<p>states that the more resources individuals have in the form of civic skills, network
</p>
<p>connections, time, and money, the more likely they are to engage in collective
</p>
<p>political activities including partaking in demonstrations. On the other hand, the
</p>
<p>relative deprivation approach states that individuals must be frustrated with their
</p>
<p>economic, social, and political situation. The more they see a gap between value
</p>
<p>expectations and value capabilities, the more likely they are going to protest. Implicit
</p>
<p>Theory
</p>
<p>Hypotheses
Statistical Analysis
</p>
<p>SamplingOperationalization
</p>
<p>Measurement
</p>
<p>Adapted from
</p>
<p>Walsh and
</p>
<p>Ollenburger 2001
</p>
<p>Fig. 2.1 Display of the quantitative research process
</p>
<p>2.4 The Quantitative Research Process 19</p>
<p/>
</div>
<div class="page"><p/>
<p>in the second argument is that individuals in the bottom echelon of society such as
</p>
<p>the unemployed, those who struggle economically, or those who are deprived of
</p>
<p>equal chances in society such as minorities are more likely to demonstrate. Having
</p>
<p>identified this controversy, the researcher asks himself which, if either, of the two
</p>
<p>competing theories is more correct. Because the researcher does not know, a priori,
</p>
<p>which of the two theories is more likely to apply, she formulates two competing
</p>
<p>hypotheses:
</p>
<p>Hypothesis 1: The higher somebody&rsquo;s SES, the higher somebody&rsquo;s likelihood to
</p>
<p>partake in a demonstration.
</p>
<p>Hypothesis 2: The higher somebody&rsquo;s dissatisfaction with her daily life, the higher
</p>
<p>the likelihood that this person will demonstrate.
</p>
<p>Having formulated her hypotheses, the researcher has to identify other potentially
</p>
<p>relevant variables that could explain one&rsquo;s decision to partake in a demonstration.
</p>
<p>From the academic literature on protest, she identifies gender, age, political sociali-
</p>
<p>zation, and place of residency as other potentially relevant variables which she also
</p>
<p>has to include/control for in her study. Once the hypotheses are formulated and
</p>
<p>control variables identified, the researcher then has to determine the measurement of
</p>
<p>the main variables of interest and for the control variables before finding an
</p>
<p>appropriate study sample. To measure the first independent variable, a person&rsquo;s
</p>
<p>SES, the researcher decides to employ two very well-known proxy variables,
</p>
<p>education and income. For the second, independent variable, she thinks that the
</p>
<p>survey question &ldquo;how satisfied are you with your daily life&rdquo; captures individuals&rsquo;
</p>
<p>levels of frustrations pretty well. The dependent variable, partaking in a demon-
</p>
<p>stration, could be measured by a survey question asking whether somebody has
</p>
<p>demonstrated within the past year. Because the researcher finds that the European
</p>
<p>Social Survey (ESS) asks all these questions using a representative sample of
</p>
<p>individuals in about 20 European countries, she uses this sample as the study object
</p>
<p>or data source. She then engages in appropriate statistical techniques to gauge the
</p>
<p>influence of her two main variables of interest on the dependent variable. As a
</p>
<p>preliminary test, she must also test her assumption that people with poor SES are
</p>
<p>more likely to be frustrated and dissatisfied with their lives. Let us assume she finds
</p>
<p>through appropriate statistical analysis that it is in fact less educated and lower-
</p>
<p>income individuals who are more likely to be dissatisfied and who demonstrate
</p>
<p>more. Finding this, the researcher would resolve some of the controversy around the
</p>
<p>two contradictory hypotheses for partaking in demonstrations, at least when it comes
</p>
<p>to the European countries under consideration.
</p>
<p>References
</p>
<p>Beetham, D. (1999). Democracy and human rights. Cambridge: Polity.
</p>
<p>Bogaards, M. (2007). Measuring democracy through election outcomes: A critique with African
</p>
<p>data. Comparative Political Studies, 40(10), 1211&ndash;1237.
</p>
<p>20 2 The Nuts and Bolts of Empirical Social Science</p>
<p/>
</div>
<div class="page"><p/>
<p>Bollen, K. A. (1990). Political democracy: Conceptual and measurement traps. Studies in Compar-
</p>
<p>ative International Development (SCID), 25(1), 7&ndash;24.
</p>
<p>Chandler, D. (2010). The uncritical critique of &lsquo;liberal peace&rsquo;. Review of International Studies,
</p>
<p>36(1), 137&ndash;155.
</p>
<p>Daase, C. (2006). Democratic peace&mdash;Democratic war: Three reasons why democracies are
</p>
<p>war-prone. In Democratic wars (pp. 74&ndash;89). London: Palgrave Macmillan.
</p>
<p>Dahl, R. A. (1973). Polyarchy: Participation and opposition. Yale: Yale University Press.
</p>
<p>De Mesquita, B. B., Morrow, J. D., Siverson, R. M., &amp; Smith, A. (1999). An institutional
</p>
<p>explanation of the democratic peace. American Political Science Review, 93(4), 791&ndash;807.
</p>
<p>Downs, A. (1957). An economic theory of political action in a democracy. Journal of Political
</p>
<p>Economy, 65(2), 135&ndash;150.
</p>
<p>Elkins, Z. (2000). Gradations of democracy? Empirical tests of alternative conceptualizations.
</p>
<p>American Journal of Political Science, 44(2), 293&ndash;300.
</p>
<p>Gleditsch, N. E. (2002). Armed conflict 1946&ndash;2001: A new dataset. Journal of Peace Research,
</p>
<p>39(5), 615&ndash;637.
</p>
<p>Gurr, T. R. (1970). Why men rebel. Princeton: Princeton University Press.
</p>
<p>Kant, I. (1795) [2011]. Zum ewigen Frieden. (3rd ed.). Berlin: Akademie Verlag.
</p>
<p>Lipset, S. L. (1959). Some social requisites of democracy: Economic development and political
</p>
<p>legitimacy. American Political Science Review, 53(1), 69&ndash;105.
</p>
<p>Mansfield, E. D., &amp; Snyder, J. (2007). Electing to fight: Why emerging democracies go to war.
</p>
<p>Boston: MIT Press.
</p>
<p>Marshall, M. G., Jaggers, K., &amp; Gurr, T. R. (2011). Polity IV project: Dataset users&rsquo; manual.
</p>
<p>Arlington: Polity IV Project.
</p>
<p>Michels, R. (1915). Political parties: A sociological study of the oligarchical tendencies of
</p>
<p>modern democracy. New York: The Free Press.
</p>
<p>Milligan, K., Moretti, E., &amp; Oreopoulos, P. (2004). Does education improve citizenship? Evidence
</p>
<p>from the United States and the United Kingdom. Journal of Public Economics, 88(9),
</p>
<p>1667&ndash;1695.
</p>
<p>Mo, P. H. (2001). Corruption and economic growth. Journal of Comparative Economics, 29(1),
</p>
<p>66&ndash;79.
</p>
<p>Przeworski, A., Alvarez, M., Cheibub, J. A., &amp; Linongi, F. (1996). What makes democracies
</p>
<p>endure? Journal of Democracy, 7(1), 39&ndash;55.
</p>
<p>Riker, W. H., &amp; Ordeshook, P. C. (1968). A theory of the calculus of voting. American Political
</p>
<p>Science Review, 62(1), 25&ndash;42.
</p>
<p>Rumberger, R. W., &amp; Palardy, G. J. (2005). Does segregation still matter? The impact of student
</p>
<p>composition on academic achievement in high school. Teachers College Record, 107(9), 1999.
</p>
<p>Runciman, W. G. (1966). Relative deprivation and social injustice. A study of attitudes to social
</p>
<p>inequality in twentieth century England. London: Routledge and Keagan Paul.
</p>
<p>Russett, B. (1994). Grasping the democratic peace: Principles for a post-cold war world.
</p>
<p>Princeton: Princeton University Press.
</p>
<p>Skocpol, T. (1979). States and social revolutions: A comparative analysis of France, Russia and
</p>
<p>China. Cambridge: Cambridge University Press.
</p>
<p>Walsh, A., &amp; Ollenburger, J. C. (2001). Essential statistics for the social and behavioral sciences: A
</p>
<p>conceptual approach. Prentice Hall: Pearson Education.
</p>
<p>Further Reading
</p>
<p>Research Design
</p>
<p>Creswell, J. W., &amp; Creswell, J. D. (2017). Research design: Qualitative, quantitative, and mixed
</p>
<p>methods approaches. Thousand Oaks, CA: Sage. Nice introduction into the two main research
</p>
<p>References 21</p>
<p/>
</div>
<div class="page"><p/>
<p>traditions qualitative and quantitative research. The book also covers mixed methods&rsquo;
</p>
<p>approaches (approaches that combine qualitative and quantitative methods).
</p>
<p>McNabb, D. E. (2015). Research methods for political science: Quantitative and qualitative
</p>
<p>methods. London: Routledge (Chap. 7). Nice introduction into the nuts and bolts of quantitative
</p>
<p>methods. Introduces basic concepts such as reliability and validity, as well as discusses different
</p>
<p>types of statistics (i.e. inferential statistics).
</p>
<p>Shively, W. P. (2016). The craft of political research. New York: Routledge. Precise and holistic
</p>
<p>introduction into the quantitative research process.
</p>
<p>Theories and Hypotheses
</p>
<p>Brians, C. L., Willnat, L., Manheim, J., &amp; Rich, R. (2016). Empirical political analysis. London:
</p>
<p>Routledge (Chaps. 2, 4, 5). Comprehensive introduction into theories, hypothesis testing and
</p>
<p>operationalization of variables.
</p>
<p>Qualitative Research
</p>
<p>Elster, J. (1989). Nuts and bolts for the social sciences. Cambridge: Cambridge University Press. A
</p>
<p>nice introduction into causal explanations and causal mechanisms. The book explains what
</p>
<p>causal mechanisms are and what research steps the researcher can conduct to detect them.
</p>
<p>Gerring, J. (2004). What is a case study and what is it good for?. American political science review,
</p>
<p>98(2), 341&ndash;354. A nice introduction on what a case study is, what is good for in
</p>
<p>political science, and what different types of case studies exist.
</p>
<p>Lijphart, A. (1971). Comparative politics and the comparative method. American Political Science
</p>
<p>Review, 65(3), 682&ndash;693. Seminal work on the comparative case study. Explains what a compar-
</p>
<p>ative case study is, how it relates to the field of comparative politics, and how to conduct a
</p>
<p>comparative case study.
</p>
<p>22 2 The Nuts and Bolts of Empirical Social Science</p>
<p/>
</div>
<div class="page"><p/>
<p>A Short Introduction to Survey Research 3
</p>
<p>Abstract
</p>
<p>This chapter offers a brief introduction into survey research. In the first part of the
</p>
<p>chapter, students learn about the importance of survey research in the social and
</p>
<p>behavioral sciences, substantive research areas where survey research is fre-
</p>
<p>quently used, and important cross-national survey such as the World Values
</p>
<p>Survey and the European Social Survey. In the second, I introduce different
</p>
<p>types of surveys.
</p>
<p>3.1 What Is Survey Research?
</p>
<p>Survey research has become a major, if not the main, technique to gather information
</p>
<p>about individuals of all sorts. To name a few examples:
</p>
<p>&bull; Costumer surveys ask individuals about their purchasing habits or their satisfac-
</p>
<p>tion with a product or service. Such surveys can gain and reveal consumer habits
</p>
<p>and inform marketing strategies by companies.
</p>
<p>&bull; Attitudinal surveys poll participants on social, economic, or cultural attitudes.
</p>
<p>These surveys are important for researchers and policy makers as they allow us to
</p>
<p>detect cultural values, political attitudes, and social preferences.
</p>
<p>&bull; Election surveys ask citizens about their voting habits. As such they can, for
</p>
<p>example, influence campaign strategies by parties.
</p>
<p>Regardless of its type, survey research involves the systematic collection of
</p>
<p>information from individuals using standardized procedures. When conducting
</p>
<p>survey research, the researcher normally uses a (random or representative) sample
</p>
<p>from the population she wants to study and asks the survey subjects one or several
</p>
<p>questions about attitudes, perceptions, or behaviors. In the ideal case, she wants to
</p>
<p>produce a set of data on a given phenomenon that captures the studied concept, as
</p>
<p># Springer International Publishing AG 2019
</p>
<p>D. Stockemer, Quantitative Methods for the Social Sciences,
</p>
<p>https://doi.org/10.1007/978-3-319-99118-4_3
</p>
<p>23</p>
<p/>
<div class="annotation"><a href="http://crossmark.crossref.org/dialog/?doi=10.1007/978-3-319-99118-4_3&amp;domain=pdf">http://crossmark.crossref.org/dialog/?doi=10.1007/978-3-319-99118-4_3&amp;domain=pdf</a></div>
</div>
<div class="page"><p/>
<p>well as relevant independent variables. She also wants to have a sample that
</p>
<p>describes the population she wants to study fairly well (Fowler 2009: 1). To provide
</p>
<p>a concrete example, if a researcher wants to gather information on the popularity of
</p>
<p>the German chancellor, she has to collect a sufficiently large sample that is represen-
</p>
<p>tative of the German population (see Chap. 4 for a discussion of representativeness).
</p>
<p>She might ask individuals to rate the popularity of the German chancellor on a 0&ndash;100
</p>
<p>scale. She might also ask respondents about their gender, age, income, education,
</p>
<p>and place of residency to determine what types of individuals like the head of the
</p>
<p>German government more and what groups like her less. If these data are collected
</p>
<p>on a regular basis, it also allows researchers to gain relevant information about trends
</p>
<p>in societies. For example, so-called trend studies allow researchers to track the
</p>
<p>popularity of the chancellor over time and possibly to associate increases and
</p>
<p>decreases in her popularity with political events such as the German reunification
</p>
<p>in 1990 or the refugee crisis in Germany in 2015.
</p>
<p>3.2 A Short History of Survey Research
</p>
<p>The origins of survey research go back thousands of years. These origins are linked
</p>
<p>to the understanding that every society with some sort of bureaucracy, in order to
</p>
<p>function properly, needs some information about its citizens. For example, in order
</p>
<p>to set taxation levels and plan infrastructure, bureaucracies need to know basic
</p>
<p>information about their citizens such as how many citizens live in a geographical
</p>
<p>unit, how much money they earn, and how many acres of land they own. Hints on
</p>
<p>first data collection efforts date back to the great civilizations of antiquity, such as
</p>
<p>China, Egypt, Persia, Greece, or the Roman Empire. A famous example of early data
</p>
<p>collection is the census mentioned in the bible during the time of Jesus&rsquo; birth:
</p>
<p>In those days a decree went out from Emperor Augustus that all the world should be
</p>
<p>registered. This was the first registration and was taken while Quirinius was governor of
</p>
<p>Syria. All went to their own towns to be registered. Joseph also went from the town of
</p>
<p>Nazareth in Galilee to Judea, to the city of David called Bethlehem, because he was
</p>
<p>descended from the house and family of David. He went to be registered with Mary, to
</p>
<p>whom he was engaged and who was expecting a child. (Luke 2:1&ndash;5)
</p>
<p>While it is historically unclear whether the census by Emperor Augustus was
</p>
<p>actually held at the time of Jesus&rsquo; birth, the citation from the bible nevertheless
</p>
<p>shows that as early as in the ancient times, governments tried to retrieve information
</p>
<p>about their citizens. To do so, families had to register in the birth place of the head of
</p>
<p>the family and answer some questions which already resembled our census questions
</p>
<p>today.
</p>
<p>In the middle ages, data collection efforts and surveys became more sophisti-
</p>
<p>cated. England took a leading role in this process. The first Norman king, William
</p>
<p>the Conqueror, was a leading figure in this quest. After his conquest of England in
</p>
<p>1066, he strived to gather knowledge on the property conditions, as well as the
</p>
<p>yearly income of the barons and cities in the seized territories. For example, he
</p>
<p>24 3 A Short Introduction to Survey Research</p>
<p/>
</div>
<div class="page"><p/>
<p>wanted to know how many acres of land the barons owned so that he could
</p>
<p>determine appropriate taxes. In the following centuries, the governing processes
</p>
<p>became increasingly centralized. To run their country efficiently and to defend the
</p>
<p>country against external threats, the absolutist English rulers depended on extensive
</p>
<p>data on labor, military capabilities, and trade (Hooper 2006). While some of these
</p>
<p>data were &ldquo;hard data&rdquo; collected directly from official books (e.g., the manpower of
</p>
<p>the army), other data, for example, on military capabilities, trade returns, or the
</p>
<p>development of the population, were, at least in part, retrieved through survey
</p>
<p>questions or interviews. Regardless of its nature, the importance of data collection
</p>
<p>rose, in particularly, in the economic and military realms. London was the first city,
</p>
<p>where statistics were systematically applied to some collected data. In the seven-
</p>
<p>teenth century, economists including John Graunt, William Petty, and Edmund
</p>
<p>Halley tried to estimate population developments on the basis of necrologies and
</p>
<p>birth records. These studies are considered to be the precursors of modern quanti-
</p>
<p>tative analysis with the focus on causal explanations (Petty and Graunt 1899).
</p>
<p>Two additional societal developments rendered the necessity for good data the
</p>
<p>more urgent. First, the adaption of a data-based capitalist economic system in the
</p>
<p>eighteenth and nineteenth century accelerated data collection efforts in England and
</p>
<p>later elsewhere in Europe. The rationalization of administrative planning processes
</p>
<p>in many European countries further increased the need to gain valid data, not only
</p>
<p>about the citizens but also about the administrative processes. Again, some of these
</p>
<p>data could only be collected by asking others. The next boost then occurred in the
</p>
<p>early nineteenth century. The Industrial Revolution combined with urbanization had
</p>
<p>created high levels of poverty for many residents in large British cities such as
</p>
<p>Manchester or Birmingham. To get some &ldquo;valid picture&rdquo; of the diffusion of poverty,
</p>
<p>journalists collected data by participating in poor people&rsquo;s lives, asking them
</p>
<p>questions about their living standard and publishing their experiences. This devel-
</p>
<p>opment resulted in the establishment of &ldquo;statistical societies&rdquo; in most large English
</p>
<p>cities (Wilcox 1934). Although the government shut down most of these statistical
</p>
<p>societies, it was pressed to extend its own data gathering by introducing routine data
</p>
<p>collections on births, deaths, and crime. Another element of these developments was
</p>
<p>the implementation of enquete commissions whose work looked at these abominable
</p>
<p>living conditions in some major English cities and whose conclusions were partly
</p>
<p>based on quantitative data gathered by asking people questions about their lives.
</p>
<p>Similar developments happened elsewhere, as well. A prominent example is the
</p>
<p>empirical research of medical doctors in Germany in the nineteenth century, who
</p>
<p>primarily examined the living and working conditions of laborers and the health-care
</p>
<p>system (Schnell et al. 2011: 13&ndash;20).
</p>
<p>Despite these efforts, it was not until the early twentieth century until political
</p>
<p>opinion polling in the way we conduct it today was born. Opinion polling in its
</p>
<p>contemporary form has its roots in the United States of America (USA). It started in
</p>
<p>the early twentieth century, when journalists attempted to forecast the outcomes of
</p>
<p>presidential elections. Initially, the journalists just took the assessment of some
</p>
<p>citizens before newspapers came up with more systematic approaches to predict
</p>
<p>the election results. The Literary Digest was the first newspaper to distribute a large
</p>
<p>3.2 A Short History of Survey Research 25</p>
<p/>
</div>
<div class="page"><p/>
<p>number of postal surveys among voters in 1916 (Converse 2011). The poll also
</p>
<p>correctly predicted the winner of the 1916 Presidential Elections, Woodrow Wilson.
</p>
<p>This survey was the first mass survey in the United States and the first systematic
</p>
<p>opinion poll in the country&rsquo;s history (Burnham et al. 2008: 99 f.). At about the same
</p>
<p>time, the British philanthropists Charles Booth and Seebohm Rowntree chose
</p>
<p>interview approaches to explain the causes of poverty. What distinguishes their
</p>
<p>works from former studies is the close link between social research and political
</p>
<p>application. To a get valid picture of poverty in the English city of York, Rowntree
</p>
<p>attempted to interview all working-class people living in York. Of course, this was a
</p>
<p>long and tiring procedure that took several years. The Rowntree example rendered it
</p>
<p>very clear to researchers, journalists, and data collection organizations that collecting
</p>
<p>data on the population researchers want to study is very cumbersome and difficult to
</p>
<p>do. Consequently, this method of data collection has become very exceptional
</p>
<p>(Burnham et al. 2008: 100 f.; Schnell et al. 2011: 21&ndash;23). Due to the immense
</p>
<p>costs associated with complete enumerations, only governments have the means to
</p>
<p>carry them out today (e.g., through the census). Researchers must rely mainly on
</p>
<p>samples, which they use to draw inferences on population statistics. Building on the
</p>
<p>work of The Literary Digest, in the USA and various efforts on the continent, the
</p>
<p>twentieth century has seen a refinement of survey and sampling techniques and their
</p>
<p>broad application to many different scenarios, be they economic, social, or political.
</p>
<p>Today surveys are ubiquitous. There is probably not one adult individual in the
</p>
<p>Western world who has not been asked at least once in her lifetime to participate in a
</p>
<p>survey.
</p>
<p>3.3 The Importance of Survey Research in the Social Sciences
and Beyond
</p>
<p>Survey research is one of the pillars in social science research in the twenty-first
</p>
<p>century. Surveys are used to measure almost everything from voting behavior to
</p>
<p>public opinion and to sexual preferences (De Leeuw et al. 2008: 1). They are of
</p>
<p>interest to a wide range of constituents including citizens, parties, civil society
</p>
<p>organizations, and governments. Individuals might be interested in situating their
</p>
<p>beliefs and behavior in relation to those of their peers and societies. Parties might
</p>
<p>want to know which party is ahead in the public preference at any given point in time
</p>
<p>and what the policy preferences of citizens are. Civil society organizations might use
</p>
<p>surveys to give credence to their lobbying points. Governments at various levels
</p>
<p>(i.e., the federal, regional, or local) may use surveys to find out how the public judges
</p>
<p>their performance or how popular specific policy proposals are among the general
</p>
<p>public. In short, surveys are ubiquitous in social and political life (for a good
</p>
<p>description of the importance of survey research, see Archer and Berdahl 2011).
</p>
<p>Opinion polls help us to situate ourselves with regard to others in different social
</p>
<p>settings. On the one hand, survey research allows us to compare our social norms
</p>
<p>and ideals in Germany, Western Europe, or the Americas to those in Japan, China, or
</p>
<p>Southeast Asia. For example, analyzing data from a general cross-national social
</p>
<p>26 3 A Short Introduction to Survey Research</p>
<p/>
</div>
<div class="page"><p/>
<p>survey provides us with an opportunity to compare attitudes and social behaviors
</p>
<p>across countries; for instance, we can compare whether we eat more fast food, watch
</p>
<p>more television, have more pets, or believe more in extensive social welfare than
</p>
<p>citizens in Australia or Asia. Yet, not only does survey research allow us to detect
</p>
<p>between country variation in opinions, beliefs, and behaviors but also within a
</p>
<p>country, if the sample is large enough. In Germany, for example, large-scale surveys
</p>
<p>can detect if individuals in the East have stronger anti-immigrant attitudes than
</p>
<p>individuals in the West. In the United States, opinion polls can identify whether
</p>
<p>the approval rating of President Trump is higher in Texas than in Connecticut.
</p>
<p>Finally, opinion polls can serve to detect differences in opinion between different
</p>
<p>cohorts of the population. For example, we can compare how much trust young
</p>
<p>people (i.e., individuals in the age cohort 18&ndash;25) have into the military compared to
</p>
<p>senior citizens (i.e., individuals aged 60 and older) both for one country and for
</p>
<p>several countries.
</p>
<p>Survey research has also shaped the social- and political sciences. To illustrate, I
</p>
<p>will just introduce two classic works in political science, whose findings and
</p>
<p>conclusions are primarily based on survey research. First, one of the most outstand-
</p>
<p>ing political treatises based on survey research is The Civic Culture by Gabriel
</p>
<p>Almond and Sidney Verba (1963). In their study, the authors use surveys on political
</p>
<p>orientations about the political systems (e.g., opinions, attitudes, and values) to
</p>
<p>detect that cultural norms must be congruent with the political system to ensure
</p>
<p>the stability of the system in question. Another classic using survey research is
</p>
<p>Robert Putnam&rsquo;s Bowling Alone; The collapse and revival of American community
</p>
<p>(2001). Mainly through survey research, Putnam finds that social engagement had
</p>
<p>weakened in the United States during the late twentieth century. He links the drop in
</p>
<p>all types of social and political activities to a decrease in membership in all kinds of
</p>
<p>organizations (e.g., social, political, or community organizations), declining contract
</p>
<p>among individuals (e.g., among neighbors, friends, and family), less volunteering,
</p>
<p>and less religious involvement. It should also be noted that survey research is not
</p>
<p>only a stand-alone tool to answer many relevant research questions, it can also be
</p>
<p>combined with other types of research such as qualitative case studies or the analysis
</p>
<p>of hard macro-level data. In a prime example of mixed methods, Wood (2003),
</p>
<p>aiming to understand the peasant&rsquo;s rationales in El Salvador to join revolutionary
</p>
<p>movements in the country&rsquo;s civil war, uses first ethnographic interviews of some
</p>
<p>peasants in a specific region to tap into these motivations. In a later stage, she
</p>
<p>employs large national household surveys to confirm the conclusions derived from
</p>
<p>the interviews.
</p>
<p>3.4 Overview of Some of the Most Widely Used Surveys
in the Social Sciences
</p>
<p>Governments, governmental and non-governmental organizations, and social
</p>
<p>research centers spend millions of dollars per year to conduct cross-national surveys.
</p>
<p>These surveys (e.g., the World Values Survey or the European Social Survey) use
</p>
<p>3.4 Overview of Some of the Most Widely Used Surveys in the Social Sciences 27</p>
<p/>
</div>
<div class="page"><p/>
<p>representative or random samples of individuals in many countries to detect trends in
</p>
<p>individuals&rsquo; social and political opinions, as well as their social and political
</p>
<p>behavior. We can distinguish different types of surveys. First, behavioral surveys
</p>
<p>measure individuals&rsquo; political-related, health-related, or job-related behavior. Prob-
</p>
<p>ably most prominent in the field of political science, election surveys gauge
</p>
<p>individuals&rsquo; conventional and unconventional political activities in a regional,
</p>
<p>national, or international context (e.g., whether somebody participates in elections,
</p>
<p>engages in protest activity, or contacts a political official). Other behavioral surveys
</p>
<p>might capture health risk behaviors, employee habits, or drug use, just to name few.
</p>
<p>Second, opinion surveys try to capture opinions and beliefs in a society; these
</p>
<p>questionnaires aim at gauging individual opinions on a variety of topics ranging
</p>
<p>from consumer behavior to public preferences, to political ideologies, and to pre-
</p>
<p>ferred free time activities and preferred vacation spots.
</p>
<p>Below, I present three of the most widely used surveys in political science and
</p>
<p>possibly the social sciences more generally: the Comparative Study of Electoral
</p>
<p>Systems (CSES), the World Values Survey (WVS), and the European Social
</p>
<p>Survey (ESS). Hundreds, if not thousands, of articles have emanated from these
</p>
<p>surveys. In these large-scale research projects, the researcher&rsquo;s duties include the
</p>
<p>composition of the questionnaire and the selection and training of the interviewers.
</p>
<p>The latter functions as the link between researcher and respondent. They run the
</p>
<p>interviews and should record the responses precisely and thoroughly (Loosveldt
</p>
<p>2008: 201).
</p>
<p>3.4.1 The Comparative Study of Electoral Systems (CSES)
</p>
<p>The Comparative Study of Electoral Systems (CSES) is a collaborative program of
</p>
<p>cross-national research among election studies conducted in over 50 states. The
</p>
<p>CSES is composed of three tightly linked parts: first, a common module of public
</p>
<p>opinion survey questions is included in each participant country&rsquo;s post-election
</p>
<p>study. These &ldquo;microlevel&rdquo; data include vote choice, candidate and party evaluations,
</p>
<p>current and retrospective economic evaluations, evaluations of the electoral system
</p>
<p>itself, and standardized sociodemographic measures. Second, district-level data are
</p>
<p>reported for each respondent, including electoral returns, turnout, and the number of
</p>
<p>candidates. Finally, system- or &ldquo;macro-level&rdquo; data report aggregate electoral returns,
</p>
<p>electoral rules and formulas, and regime characteristics. This design allows
</p>
<p>researchers to conduct cross-level and cross-national analyses, addressing the effects
</p>
<p>of electoral institutions on citizens&rsquo; attitudes and behavior, the presence and nature
</p>
<p>of social and political cleavages, and the evaluation of democratic institutions across
</p>
<p>different political regimes.
</p>
<p>The CSES is unique among comparative post-electoral studies because of the
</p>
<p>extent of cross-national collaboration at all stages of the project: the research agenda,
</p>
<p>the survey instrument, and the study design are developed by the CSES Planning
</p>
<p>Committee, whose members include leading scholars of electoral politics from
</p>
<p>around the world. This design is then implemented in each country by that country&rsquo;s
</p>
<p>28 3 A Short Introduction to Survey Research</p>
<p/>
</div>
<div class="page"><p/>
<p>foremost social scientists, as part of their national post-election studies. Frequently,
</p>
<p>the developers of the survey decide upon a theme for any election cycle. For
</p>
<p>example, the initial round of collaboration focused on three general themes: the
</p>
<p>impact of electoral institutions on citizens&rsquo; political cognition and behavior (parlia-
</p>
<p>mentary versus presidential systems of government, the electoral rules that govern
</p>
<p>the casting and counting of ballots and political parties), the nature of political and
</p>
<p>social cleavages and alignments, and the evaluation of democratic institutions and
</p>
<p>processes. The key theoretical question to be addressed by the second module is the
</p>
<p>contrast between the view that elections are a mechanism to hold government
</p>
<p>accountable and the view that they are a means to ensure that citizens&rsquo; views and
</p>
<p>interests are properly represented in the democratic process. It is the module&rsquo;s aim to
</p>
<p>explore how far this contrast and its embodiment in institutional structures influences
</p>
<p>vote choice and satisfaction with democracy.
</p>
<p>The CSES can be accessed at http://www.isr.umich.edu/cps/project_cses.html.
</p>
<p>3.4.2 The World Values Survey (WVS)
</p>
<p>The World Values Survey is a global research project that explores peoples&rsquo; values
</p>
<p>and beliefs, how they change over time, and what social and political impact they
</p>
<p>have. It emerged in 1981 and was mainly coined by the scientists Ronald Inglehart,
</p>
<p>Jan Kerkhofs, and Ruud de Moor. The survey&rsquo;s focus was initially on European
</p>
<p>countries, although since the late 1990s, however, non-European countries have
</p>
<p>received more attention. Today, more than 80 independent countries representing
</p>
<p>85% of the world&rsquo;s population are included in the survey (Hurtienne and Kaufmann
</p>
<p>2015: 9 f.). The survey is carried out by a worldwide network of social scientists
</p>
<p>who, since 1981, have conducted representative national surveys in multiple waves
</p>
<p>in over 80 countries. The WVS measures, monitors, and analyzes a host of issues
</p>
<p>including support for democracy; tolerance of foreigners and ethnic minorities;
</p>
<p>support for gender equality; the role of religion and changing levels of religiosity;
</p>
<p>the impact of globalization; attitudes toward the environment, work, family, politics,
</p>
<p>national identity, culture, diversity, and insecurity; and subjective well-being on the
</p>
<p>basis of face-to-face interviews. The questionnaires are distributed among
</p>
<p>1100&ndash;3500 interviewees per country. The findings are valuable for policy makers
</p>
<p>seeking to build civil society and democratic institutions in developing countries.
</p>
<p>The work is also frequently used by governments around the world, scholars,
</p>
<p>students, journalists, and international organizations and institutions such as the
</p>
<p>World Bank and the United Nations (UNDP and UN-Habitat). Thanks to the
</p>
<p>increasing number of participating countries and the growing time period that the
</p>
<p>WVS covers, the WVS satisfies (some of) the demand for cross-sectional attitudinal
</p>
<p>data. The application of WVS data in hundreds of publications and in more than
</p>
<p>20 languages stresses the crucial role that the WVS plays in scientific research today
</p>
<p>(Hurtienne and Kaufmann 2015: 9 f.).
</p>
<p>The World Values Survey can be accessed at http://www.worldvaluessurvey.org/.
</p>
<p>3.4 Overview of Some of the Most Widely Used Surveys in the Social Sciences 29</p>
<p/>
<div class="annotation"><a href="http://www.isr.umich.edu/cps/project_cses.html">http://www.isr.umich.edu/cps/project_cses.html</a></div>
<div class="annotation"><a href="http://www.worldvaluessurvey.org/">http://www.worldvaluessurvey.org/</a></div>
</div>
<div class="page"><p/>
<p>3.4.3 The European Social Survey (ESS)
</p>
<p>The European Social Survey (ESS) is an academically driven cross-national survey
</p>
<p>that has been conducted every 2 years across Europe since 2001. It is directed by
</p>
<p>Rory Fitzgerald (City University London). The survey measures the attitudes,
</p>
<p>beliefs, and behavioral patterns of diverse populations in more than 30 European
</p>
<p>nations. As the largest data collection effort in and on Europe, the ESS has five aims:
</p>
<p>1. To chart stability and change in social structure, conditions, and attitudes in
</p>
<p>Europe and to interpret how Europe&rsquo;s social, political, and moral fabric is
</p>
<p>changing.
</p>
<p>2. To achieve and spread higher standards of rigor in cross-national research in the
</p>
<p>social sciences, including, for example, questionnaire design and pre-testing,
</p>
<p>sampling, data collection, reduction of bias, and the reliability of questions.
</p>
<p>3. To introduce soundly based indicators of national progress, based on citizens&rsquo;
</p>
<p>perceptions and judgements of key aspects of their societies.
</p>
<p>4. To undertake and facilitate the training of European social researchers in com-
</p>
<p>parative quantitative measurement and analysis.
</p>
<p>5. To improve the visibility and outreach of data on social change among academics,
</p>
<p>policy makers, and the wider public.
</p>
<p>The findings of the ESS are based on face-to-face interviews, and the question-
</p>
<p>naire is comprised of three sections, a core module, two rotating modules, and a
</p>
<p>supplementary questionnaire. The core module comprises questions on the media
</p>
<p>and social trust, politics, the subjective well-being of individuals, gender and
</p>
<p>household dynamics, sociodemographics, and social values. As such, the core
</p>
<p>module should capture topics that are of enduring interest for researchers as well
</p>
<p>as provide the most comprehensive set of socio-structural variables in a cross-
</p>
<p>national survey worldwide. The two rotating modules capture &ldquo;hot&rdquo; social science
</p>
<p>topics; for example, rotating modules in 2002 and 2014 focused on immigration,
</p>
<p>while the 2016 wave captures European citizens&rsquo; attitudes about welfare and
</p>
<p>opinions toward climate change. The purpose of the supplementary questionnaire
</p>
<p>at the end of the survey is to elaborate in more detail on human values and to test the
</p>
<p>reliability and validity of the items in the principal questionnaire on the basis of some
</p>
<p>advanced statistical techniques (ESS 2017).
</p>
<p>The European Social Survey can be accessed at http://www.
</p>
<p>europeansocialsurvey.org/.
</p>
<p>3.5 Different Types of Surveys
</p>
<p>For political science students, it is important to realize that one survey design does
</p>
<p>not necessarily resemble another survey design. Rather, in survey research, we
</p>
<p>generally distinguish between two types of surveys: cross-sectional surveys and
</p>
<p>longitudinal surveys (see Frees 2004: 2).
</p>
<p>30 3 A Short Introduction to Survey Research</p>
<p/>
<div class="annotation"><a href="http://www.europeansocialsurvey.org/">http://www.europeansocialsurvey.org/</a></div>
<div class="annotation"><a href="http://www.europeansocialsurvey.org/">http://www.europeansocialsurvey.org/</a></div>
</div>
<div class="page"><p/>
<p>3.5.1 Cross-sectional Survey
</p>
<p>A cross-sectional survey is a survey that is used to gather information about
</p>
<p>individuals at a single point in time. The survey is conducted once and not repeated.
</p>
<p>An example of a cross-sectional survey would be a poll that asks respondents in the
</p>
<p>United States how much they donated toward the reconstruction efforts after Hurri-
</p>
<p>cane Katrina hit the Southern States of the United States. Surveys, such as the one
</p>
<p>capturing donation patterns in the aftermath of Hurricane Katrina, are particularly
</p>
<p>interesting to seize attitudes and behaviors related to one event that probably will not
</p>
<p>repeat itself. Yet, cross-sectional surveys are not only used to capture one-time
</p>
<p>events. To the contrary, they are quite frequently used by researchers to tap into
</p>
<p>all types of research questions. Because, it is logistically complicated, time-
</p>
<p>consuming, and costly to conduct the same study at regular intervals with or without
</p>
<p>the same individuals, cross-sectional studies are frequently the fall-back option for
</p>
<p>many researchers. In many instances, the use of cross-sectional surveys can be
</p>
<p>justified from a theoretical perspective; frequently, a cross-sectional study still
</p>
<p>allows researchers to draw inferences about relationships between independent and
</p>
<p>dependent variables (Behnke et al. 2006: 70 f.).
</p>
<p>However, it is worth noting that the use of these types of surveys to detect
</p>
<p>empirical relationships can be tricky. Most importantly, because we only have data
</p>
<p>at one point for both independent and dependent variables, cross-sectional surveys
</p>
<p>cannot establish causality (i.e., they cannot establish that a change in the independent
</p>
<p>variable precedes a change in the dependent variable) (De Vaus 2001: 51). There-
</p>
<p>fore, it is important that findings/conclusions derived from cross-sectional studies are
</p>
<p>supported by theory, logic, and/or intuition (Frees 2004: 286). In other words, a
</p>
<p>researcher should only use cross-sectional data to test theories, if the temporal chain
</p>
<p>between independent and dependent variable is rather clear a priori.
</p>
<p>If we have clear theoretical assumptions about a relationship, a cross-sectional
</p>
<p>survey can provide a good tool to test hypotheses. For example, a cross-sectional
</p>
<p>survey could be appropriate to test the linkage between formal education and casting a
</p>
<p>ballot at elections, as there is a strong theoretical argument in favor of the proposition
</p>
<p>that higher formal education will increase somebody&rsquo;s propensity to vote. According
</p>
<p>to the resource model of voting (see Brady et al. 1995), higher educated individuals
</p>
<p>have the material and nonmaterial resources necessary to understand complex politi-
</p>
<p>cal scenarios, as well as the network connections, all of which should render some-
</p>
<p>body more likely to vote. Vice versa, uneducated individuals lack these resources and
</p>
<p>are frequently politically disenfranchised. Practically, it is also impossible that the
</p>
<p>sheer act of voting changes somebody&rsquo;s formal education. Hence, if we analyze a
</p>
<p>cross-sectional survey on voting and find that more educated individuals are more
</p>
<p>likely to vote, we can assume that this association reflects an empirical reality. To take
</p>
<p>another example, if we want to study the influence of age on protesting, data from a
</p>
<p>cross-sectional survey could be completely appropriate, as well, to study this rela-
</p>
<p>tionship, as the causal change clearly goes from age to protesting and not the other
</p>
<p>way round. By definition, the fact that I protest does not make me younger or older,
</p>
<p>at least when we look at somebody&rsquo;s biological age.
</p>
<p>3.5 Different Types of Surveys 31</p>
<p/>
</div>
<div class="page"><p/>
<p>Nevertheless, empirical relationships are not always that clear-cut. Rather con-
</p>
<p>trary, sometimes it is tricky to derive causal explanations from cross-sectional
</p>
<p>studies. To highlight this dilemma, let us take an example from American Politics
</p>
<p>and look at the relationship between watching Fox News and voting for Donald
</p>
<p>Trump. For one, it makes theoretical sense that watching Fox News in the United
</p>
<p>States increases somebody&rsquo;s likelihood to vote for Donald Trump in the Presidential
</p>
<p>Election, because this TV chain supports this populist leader. Yet, the causal or
</p>
<p>correlational chain could also go the other way round. In other words, it might also
</p>
<p>be that somebody, who decided to vote for Trump, is actively looking for a news
</p>
<p>outlet that follows her convictions. As a result, she might watch Fox News after
</p>
<p>voting for Trump.
</p>
<p>A slightly different example highlights even clearer that the correlational or
</p>
<p>causal direction between independent and dependent variable is not always clear.
</p>
<p>For example take the following example; it is theoretically unclear if the consump-
</p>
<p>tion of Fox News renders somebody more conservative or if more conservative
</p>
<p>individuals have a higher likelihood to watch Fox News. Rather than one variable
</p>
<p>influencing the other, both factors might mutually reinforce each other. Therefore,
</p>
<p>even if a researcher finds support for the hypothesis that watching Fox News makes
</p>
<p>people more conservative, we cannot be sure of the direction of this association
</p>
<p>because a cross-sectional survey would ask individuals the same question at the
</p>
<p>same time.1 Consequently, we cannot detect what comes first: watching Fox News or
</p>
<p>being conservative. Hence, cross-sectional surveys cannot resolve the aforemen-
</p>
<p>tioned temporal aspect. Rather than a cross-sectional survey, a longitudinal survey
</p>
<p>would be necessary to determine the causal chain between being conservative and
</p>
<p>watching Fox News. Such a survey, in particular, if it is conducted over many years
</p>
<p>and if it solicits the same individuals in regular intervals, could tell researchers if
</p>
<p>respondents first become conservative and then watch Fox News or if the relation-
</p>
<p>ship is the other way round.
</p>
<p>3.5.2 Longitudinal Survey
</p>
<p>In contrast to cross-sectional studies, which are conducted once, longitudinal
</p>
<p>surveys repeat the same survey questions several times. This allows the researchers
</p>
<p>to analyze changing attitudes or behaviors that occur within the population over
</p>
<p>time. There are three types of longitudinal surveys: trend studies, cohort studies, and
</p>
<p>panel studies.
</p>
<p>3.5.2.1 Trend Surveys
A trend study, which is frequently also labeled a repeated cross-sectional survey, is a
</p>
<p>repeated survey that is normally not composed of the same individuals in the
</p>
<p>different waves. Most of the main international surveys including the European
</p>
<p>1In the literature, such reversed causation is often referred to as an endogeneity problem.
</p>
<p>32 3 A Short Introduction to Survey Research</p>
<p/>
</div>
<div class="page"><p/>
<p>Social Survey or the World Values Survey are trend studies. The surveys of the
</p>
<p>different waves are fully or partly comprised of the same questions. As such they
</p>
<p>allow researchers to detect broad changes in opinions and behaviors over time.
</p>
<p>Nevertheless, and because the collected data covers different individuals in each
</p>
<p>wave of the study, the collected data merely allows for conclusions on the aggregate
</p>
<p>level such as the regional or the national level (Schumann 2012: 113). To highlight,
</p>
<p>most of the major surveys ask the question: How satisfied are you with how
</p>
<p>democracy works in your country? Frequently, the answer choices range from 0 or
</p>
<p>not satisfied at all to 10 or very satisfied. Since, citizens answer these questions every
</p>
<p>2 years, researchers can track satisfaction rates with democracy over a longer period
</p>
<p>such as 10 years. Comparing the answers for several waves, a researcher can also
</p>
<p>establish if the same or different independent variables (e.g., unemployment or
</p>
<p>economic insecurity, gender, age, or income) trigger higher rates of dissatisfaction
</p>
<p>with democracy. However, what such a question/study cannot do is to track down
</p>
<p>what altered an individual&rsquo;s assessment of the state of democracy in her country.
</p>
<p>Rather, it only allows researchers to draw conclusions on the macro- or aggregate
</p>
<p>level.
</p>
<p>3.5.2.2 Cohort Surveys
While trend studies normally focus on the whole population, cohort studies merely
</p>
<p>focus on a segment of the population. One common feature of a cohort study is that a
</p>
<p>central event or feature occurred approximately at the same time to all members of
</p>
<p>the group. Most common are birth cohorts. In that case, birth is the special event that
</p>
<p>took place in the same year or in the same years for all members of the cohort (e.g.,
</p>
<p>all Americans who were born in or after 1960). Analogous to trend studies, cohort
</p>
<p>studies use the same questions in several waves. In each wave, a sample is drawn
</p>
<p>from the cohort. This implies that the population remains the same over time,
</p>
<p>whereas the individuals in the sample change. A typical example of cohort studies
</p>
<p>is the &ldquo;British National Child Study&rdquo; (NCDS). In the course of this study, 11,400
</p>
<p>British citizens born between March 3 and 9, 1958, were examined with respect to
</p>
<p>their health, education, income, and attitudes in eight waves in a time span of
</p>
<p>50 years (Schnell et al. 2011: 237 f.).
</p>
<p>3.5.2.3 Panel Surveys
Panel studies normally ask the same questions to the same people in subsequent
</p>
<p>waves. These types of surveys are the most costly and most difficult to implement,
</p>
<p>but they are the best suited to detect causal relationships or changes in individual
</p>
<p>behavior. For example, a researcher could ask questions on the consumption of Fox
</p>
<p>News and being conservative to the same individual over the period of several years.
</p>
<p>This could help her detect the temporal chain in the relationship between a certain
</p>
<p>type of news consumption and political ideologies. Panel studies frequently have the
</p>
<p>problem of high attrition or mortality rates. In other words, people drop out during
</p>
<p>waves for multiple reasons, for example, they could move, become sick, or simply
</p>
<p>refuse further participation. Hence, it is likely that a sample that was representative
</p>
<p>from the outset becomes less and less representative for subsequent waves of the
</p>
<p>3.5 Different Types of Surveys 33</p>
<p/>
</div>
<div class="page"><p/>
<p>panel. To highlight, imagine that a researcher is conducting a panel on citizens&rsquo;
</p>
<p>preference on which electoral system should be used in a country, and they ask this
</p>
<p>question every 2 years to the same individuals. Individuals who are interested in
</p>
<p>electoral politics, and/or have a strong opinion in favor of one or the other type of
</p>
<p>electoral system, might have a higher likelihood to stay in the sample than citizens
</p>
<p>who do not care. In contrast, those who are less interested will no longer participate
</p>
<p>in future waves. Others, like old-age citizens, might die or move into an old people&rsquo;s
</p>
<p>home. A third group such as diplomats and consultants is more likely to move than
</p>
<p>manual workers. It is possible to continue the list. Therefore, there is the danger that
</p>
<p>many panels become less representative of the population for any of the waves
</p>
<p>covered. Nevertheless, in particular, if some representativeness remains in
</p>
<p>subsequent waves or if the representativeness is not an issue for the research
</p>
<p>question, panel studies can be a powerful tool to detect causal relationships. An
</p>
<p>early example of an influential panel study is Butler and Stokes&rsquo; Political Change in
</p>
<p>Britain: Forces Shaping Electoral Choice. Focusing on political class as the key
</p>
<p>independent variable for the vote choice for a party, the authors conducted three
</p>
<p>waves of panels with the same randomly selected electors in the summer 1963, after
</p>
<p>the general elections 1964 and after the general elections 1966 to determine habitual
</p>
<p>voting and vote switching. Among others, they find that voting patterns in favor of
</p>
<p>the three main parties (i.e., the Liberal Party, Labour Party, and the Conservative
</p>
<p>Party) are more complex to be fully captured by class.
</p>
<p>References
</p>
<p>Almond, G., &amp; Verba, S. (1963) [1989]. The civic culture: Political attitudes and democracy in
</p>
<p>five nations. Newbury Park, CA: Sage.
</p>
<p>Archer, K., &amp; Berdahl, L. (2011). Explorations: Conducting empirical research in canadian poli-
</p>
<p>tical science. Toronto: Oxford University Press.
</p>
<p>Behnke, J., Baur, N., &amp; Behnke, N. (2006). Empirische Methoden der Politikwissenschaft.
</p>
<p>Paderborn: Sch&ouml;ningh.
</p>
<p>Brady, H. E., Verba, S., &amp; Schlozman, K. L. (1995). Beyond SES: A resource model of
</p>
<p>political participation. American Political Science Review, 89(2), 271&ndash;294.
</p>
<p>Burnham, P., Lutz, G. L., Grant, W., &amp; Layton-Henry, Z. (2008). Research methods in politics
</p>
<p>(2nd ed.). Basingstoke, Hampshire: Palgrave Macmillan.
</p>
<p>Converse, J. M. (2011). Survey research in the United States: Roots and emergence 1890&ndash;1960.
</p>
<p>Picataway: Transaction.
</p>
<p>De Leeuw, E. D., Hox, J. J., &amp; Dillman, D. A. (2008). The cornerstones of survey research. In
</p>
<p>E. D. De Leeuw, J. J. Hox, &amp; D. A. Dillman (Eds.), International handbook of survey method-
</p>
<p>ology. New York: Lawrence Erlbaum Associates.
</p>
<p>De Vaus, D. (2001). Research design in social research. London: Sage.
</p>
<p>ESS (European Social Survey). (2017). Source questionnaire. Retrieved August 7, 2017, from
</p>
<p>http://www.europeansocialsurvey.org/methodology/ess_methodology/source_questionnaire/
</p>
<p>Fowler, F. J. (2009). Survey research methods (4th ed.). Thousand Oaks, CA: Sage.
</p>
<p>Frees, E. W. (2004). Longitudinal and panel data: Analysis and applications in the social sciences.
</p>
<p>Cambridge: Cambridge University Press.
</p>
<p>Hooper, K. (2006). Using William the conqueror&rsquo;s accounting record to assess manorial efficiency:
</p>
<p>A critical appraisal. Accounting History, 11(1), 63&ndash;72.
</p>
<p>34 3 A Short Introduction to Survey Research</p>
<p/>
<div class="annotation"><a href="http://www.europeansocialsurvey.org/methodology/ess_methodology/source_questionnaire/">http://www.europeansocialsurvey.org/methodology/ess_methodology/source_questionnaire/</a></div>
</div>
<div class="page"><p/>
<p>Hurtienne, T., &amp; Kaufmann, G. (2015).Methodological biases: Inglehart&rsquo;s world value survey and
</p>
<p>Q methodology. Berlin: Folhas do NAEA.
</p>
<p>Loosveldt, G. (2008). Face-to-face interviews. In E. D. De Leeuw, J. J. Hox, &amp; D. A. Dillman
</p>
<p>(Eds.), International handbook of survey methodology. New York: Lawrence Erlbaum
</p>
<p>Associates.
</p>
<p>Petty, W., &amp; Graunt, J. (1899). The economic writings of Sir William Petty (Vol. 1). London:
</p>
<p>University Press.
</p>
<p>Putnam, R. D. (2001). Bowling alone: The collapse and revival of American community. New York:
</p>
<p>Simon and Schuster.
</p>
<p>Schnell, R., Hill, P. B., &amp; Esser, E. (2011). Methoden der empirischen Sozialforschung (9th ed.).
</p>
<p>M&uuml;nchen: Oldenbourg.
</p>
<p>Schumann, S. (2012). Repr&auml;sentative Umfrage: Praxisorientierte Einf&uuml;hrung in empirische Meth-
</p>
<p>oden und statistische Analyseverfahren (6th ed.). M&uuml;nchen: Oldenbourg.
</p>
<p>Willcox, W. F. (1934). Note on the chronology of statistical societies. Journal of the
</p>
<p>American Statistical Association, 29(188), 418&ndash;420.
</p>
<p>Wood, E. J. (2003). Insurgent collective action and civil war in El Salvador. Cambridge:
</p>
<p>Cambridge University Press.
</p>
<p>Further Reading
</p>
<p>Why Do We Need Survey Research?
</p>
<p>Converse, J. M. (2017). Survey research in the United States: Roots and emergence 1890&ndash;1960.
</p>
<p>New York: Routledge. This book has more of an historical ankle. It tackles the history of survey
</p>
<p>research in the United States.
</p>
<p>Davidov, E., Schmidt, P., &amp; Schwartz, S. H. (2008). Bringing values back in: The adequacy of the
</p>
<p>European Social Survey to measure values in 20 countries. Public Opinion Quarterly, 72(3),
</p>
<p>420&ndash;445. This rather short article highlights the importance of conducting a large pan-European
</p>
<p>survey to measure European&rsquo;s social and political beliefs.
</p>
<p>Schmitt, H., Hobolt, S. B., Popa, S. A., &amp; Teperoglou, E. (2015). European parliament election
</p>
<p>study 2014, voter study. GESIS Data Archive, Cologne. ZA5160 Data file Version, 2(0). The
</p>
<p>European Voter Study is another important election study that researchers and students can
</p>
<p>access freely. It provides a comprehensive battery of variables about voting, political
</p>
<p>preferences, vote choice, demographics, and political and social opinions of the electorate.
</p>
<p>Applied Survey Research
</p>
<p>Almond, G. A., &amp; Verba, S. (1963). The civic culture: Political attitudes and democracy in five
</p>
<p>nations. Princeton: Princeton University Press. Almond&rsquo;s and Verba&rsquo;s masterpiece is a seminal
</p>
<p>work in survey research measuring citizens&rsquo; political and civic attitudes in key Western
</p>
<p>democracies. The book is also one of the first books that systematically uses survey research
</p>
<p>to measure political traits.
</p>
<p>Inglehart, R., &amp; Welzel, C. (2005). Modernization, cultural change, and democracy: The human
</p>
<p>development sequence. Cambridge: Cambridge University Press. This is an influential book,
</p>
<p>which uses data from the World Values Survey to explain modernization as a process that
</p>
<p>changes individual&rsquo;s values away from traditional and patriarchal values and toward post-
</p>
<p>materialist values including environmental protection, minority rights, and gender equality.
</p>
<p>References 35</p>
<p/>
</div>
<div class="page"><p/>
<p>Constructing a Survey 4
</p>
<p>Abstract
</p>
<p>This chapter instructs students on how to conduct a survey. Topics covered
</p>
<p>include question design, question wording, the use of open- and closed-ended
</p>
<p>questions, measurement, pre-testing, and refining a survey. As part of this
</p>
<p>chapter, students construct their own survey.
</p>
<p>4.1 Question Design
</p>
<p>In principle, in a survey a researcher can ask questions about what people think, what
</p>
<p>they do, what attributes they have, and how much knowledge they have about an
</p>
<p>issue.
</p>
<p>Questions about opinions, attitudes, beliefs, and values&mdash;capture what people think
</p>
<p>about an issue, a person or an event
</p>
<p>These questions frequently give respondents some choices in their answers
</p>
<p>Example: Do you agree with the following statement? The European Union should
</p>
<p>create a crisis fund in order to be able to rapidly bail out member countries, when
</p>
<p>they are in financial difficulties. (Possible answer choices: Agree, partly agree,
</p>
<p>partly disagree, and do not agree)
</p>
<p>Questions about individual behavior&mdash;capture what people do
</p>
<p>Example: Did you vote in the last election? (Possible answer choices, yes or no)
</p>
<p>Questions about attributes&mdash;what are peoples&rsquo; characteristics
</p>
<p>Example: age, gender, etc.
</p>
<p>Example: What is your gender? (Possible answers, male, female, no answer)
</p>
<p>Questions about knowledge&mdash;how much people know about political, social, or
</p>
<p>cultural issues
</p>
<p>Example: In your opinion, how much of its annual GDP per capita does Germany
</p>
<p>attribute toward development aid?
</p>
<p># Springer International Publishing AG 2019
</p>
<p>D. Stockemer, Quantitative Methods for the Social Sciences,
</p>
<p>https://doi.org/10.1007/978-3-319-99118-4_4
</p>
<p>37</p>
<p/>
<div class="annotation"><a href="http://crossmark.crossref.org/dialog/?doi=10.1007/978-3-319-99118-4_4&amp;domain=pdf">http://crossmark.crossref.org/dialog/?doi=10.1007/978-3-319-99118-4_4&amp;domain=pdf</a></div>
</div>
<div class="page"><p/>
<p>4.2 Ordering of Questions
</p>
<p>There are some general guidelines for constructing surveys that make it easy for
</p>
<p>participants to respond.
</p>
<p>1. The ordering of questions should be logical to the respondents and flow smoothly
</p>
<p>from one question to the next. As a general rule, questions should go from general
</p>
<p>to specific, impersonal to personal, and easy to difficult.
</p>
<p>2. Questions related to the same issue should be grouped together. For example, if a
</p>
<p>survey captures different forms of political participation, questions capturing
</p>
<p>voting, partaking in demonstrations, boycotting, and signing petitions should be
</p>
<p>grouped together. Ideally, the questions could also go from conventional political
</p>
<p>participation to unconventional political participation. The same applies to other
</p>
<p>sorts of common issues such as opinions about related subjects (e.g., satisfaction
</p>
<p>with the government&rsquo;s economic, social, and foreign policy, respectively). Con-
</p>
<p>sequently, it makes sense to divide the questionnaire in different sections, each of
</p>
<p>which should begin with a short introductory sentence. However, while it makes
</p>
<p>sense to cluster questions by theme, there should not be too many similar
</p>
<p>questions, with similar measurements either. In particular, the so-called consis-
</p>
<p>tency bias might come into play, if there are too many similar questions. Cogni-
</p>
<p>tively, some respondents wish to appear consistent in the way they answer the
</p>
<p>questions, in particular if these questions look alike. To mitigate the consistency
</p>
<p>bias effects, it is useful to switch up the questions and do not have a row of 20 or
</p>
<p>30 questions that are openly interrelated and use the same scale (Weisberg et al.
</p>
<p>1996: 89 f.).
</p>
<p>4.3 Number of Questions
</p>
<p>Researchers always have to draw a fine line between the exhaustiveness and the
</p>
<p>parsimony of the questionnaire. They want to ask as many questions as are necessary
</p>
<p>to capture the dependent and all necessary independent variables in the research
</p>
<p>project. Yet, they do not want to ask too many questions either, because the more
</p>
<p>questions that are included in an interview or a survey, the less likely people are to
</p>
<p>finish a face-to-face or phone interview or to return a completed paper or online
</p>
<p>questionnaire. There are no strict provisions for the length of a survey, though. The
</p>
<p>general rule that guides the construction of a research could also guide the construc-
</p>
<p>tion of a questionnaire; a questionnaire should include as many questions as neces-
</p>
<p>sary and as few questions as possible.
</p>
<p>4.4 Getting the Questions Right
</p>
<p>When writing surveys, researchers normally follow some simple rules. The question
</p>
<p>wording needs to be clear, simple, and precise. In other words, questions need to be
</p>
<p>written so that respondents understand their meaning right away. In contrast, poorly
</p>
<p>38 4 Constructing a Survey</p>
<p/>
</div>
<div class="page"><p/>
<p>written questions lead to ambiguity and misunderstandings and can lead to untrust-
</p>
<p>worthy answers. In particular, vague questions, biased/value-laden questions, threat-
</p>
<p>ening questions, complex questions, negative questions, and pointless questions
</p>
<p>should be avoided.
</p>
<p>4.4.1 Vague Questions
</p>
<p>Vague questions are questions that do not clearly communicate to the respondent
</p>
<p>what the question is actually all about. For example, a question like &ldquo;Taken alto-
</p>
<p>gether, how happy are you with Chancellor Merkel?&rdquo; is unclear. It is imprecise
</p>
<p>because the respondent does not know what substantive area the questions is based
</p>
<p>on. Does the pollster want to know whether the respondent is &ldquo;happy&rdquo; with her
</p>
<p>rhetorical style, her appearance, her leadership style or her government&rsquo;s record, or
</p>
<p>all of the above? Also the word happy should be avoided because it is at least
</p>
<p>somewhat value laden. Hence, the researcher should refine her research question by
</p>
<p>specifying a policy area and a measurement scale and by using more neutral- and less
</p>
<p>colloquial language. Hence a better question would be: Overall, how would you rate
</p>
<p>the performance of Chancellor Merkel in the domain of refugee policy during the
</p>
<p>refugee crisis in 2015 on a 0&ndash;100 scale?
</p>
<p>4.4.2 Biased or Value-Laden Questions
</p>
<p>Biased or value-laden questions are questions that predispose individuals to answer a
</p>
<p>question in a certain way. These questions are not formulated in a neutral way.
</p>
<p>Rather, they use strong normative words. Consider, for example, the question: On a
</p>
<p>scale from 0 to 100, how evil do you think the German Christian Democratic Union
</p>
<p>(CDU) is? This question is clearly inappropriate for a survey as it bears judgement
</p>
<p>on the question subject. Therefore a better formulation of the same question would
</p>
<p>be: On scale from 1 to 100 how would you rate the performance of the Christian
</p>
<p>Democratic Union in the past year? Ideally, the pollster could also add a policy area
</p>
<p>to this question.
</p>
<p>4.4.3 Threatening Questions
</p>
<p>Threating questions might render respondents to surveys uneasy and/or make it hard
</p>
<p>for the respondent to answer to her best capacities. For instance, the question: &ldquo;Do
</p>
<p>you have enough knowledge about German politics to recall the political program of
</p>
<p>the four parties the Christian Democrats, the Social Democrats, the Green Party, and
</p>
<p>the Party of Democratic Socialism?&rdquo;might create several forms of uneasiness on the
</p>
<p>beholder. The person surveyed might question their capability to answer the ques-
</p>
<p>tion, they might assume that the pollster is judging them, and they might not know
</p>
<p>how to answer the question, because it is completely unclear what enough
</p>
<p>4.4 Getting the Questions Right 39</p>
<p/>
</div>
<div class="page"><p/>
<p>knowledge means. Also, it might be better to reduce the question to one party,
</p>
<p>because citizens might know a lot about one party program and relatively few things
</p>
<p>about another program. A better question would be: On a scale from 0 to 100, how
</p>
<p>familiar are you with the political programs of the Social Democratic Party for the
</p>
<p>General Election 2017. (0 means I am not familiar at all and 100 means I am an
</p>
<p>expert.)
</p>
<p>4.4.4 Complex Questions
</p>
<p>Researchers should avoid complex questions that ask the polled about various issues
</p>
<p>at once. For example, a question like this: &ldquo;On a scale from 1 to 10, please rate, for
</p>
<p>each of the 12 categories listed below, your level of knowledge, confidence, and
</p>
<p>experience&rdquo; should be avoided, as it confuses respondents and makes it impossible
</p>
<p>for the respondent to answer precisely. Rather than clustering many items at once,
</p>
<p>the researcher should ask one question per topic.
</p>
<p>4.4.5 Negative Questions
</p>
<p>The usage of negative questions might induce bias or normative connotation into a
</p>
<p>question. A question such as &ldquo;On a scale from 0 to 100 how unfit do you think
</p>
<p>American President Donald Trump is for the Presidency of the United States?&rdquo; is
</p>
<p>more value laden than the same question expressed in positive terms: &ldquo;On a scale
</p>
<p>from 0 to 100 how fit do you think American President Donald Trump is for
</p>
<p>Presidency of the United States?&rdquo; Using the negative form might also confuse
</p>
<p>people. Therefore, it is a rule in survey research to avoid the usage of negative
</p>
<p>wording. This includes the use of words such as &ldquo;not,&rdquo; &ldquo;rarely,&rdquo; &ldquo;never,&rdquo; or words
</p>
<p>with negative prefixes &ldquo;in-,&rdquo; &ldquo;im-,&rdquo; &ldquo;un-.&rdquo; Therefore, researchers should always ask
</p>
<p>their questions in a positive fashion.
</p>
<p>4.4.6 Pointless Questions
</p>
<p>A pointless question is a question that does not allow the researcher or pollster to
</p>
<p>gain any relevant information. For example, the form I-94 from the US Citizenship
</p>
<p>and Immigration Services that every foreigner, who enters the United States has to
</p>
<p>fill out does not make any sense. The form asks any foreigner entering the United
</p>
<p>States: Have you ever been or are you now involved in espionage or sabotage or in
</p>
<p>terrorist activities or genocide, or between 1933 and 1945 were you involved, in any
</p>
<p>way, in persecutions associated with Nazi Germany or its allies? Respondents can
</p>
<p>circle either yes or no. This question is futile in two ways. First, people involved in
</p>
<p>any of these illegal activities have no incentive to admit to it; admitting to it would
</p>
<p>automatically mean that their entry into the United States would be denied. Second,
</p>
<p>and possibly even more importantly, there remain very few individuals alive who, in
</p>
<p>40 4 Constructing a Survey</p>
<p/>
</div>
<div class="page"><p/>
<p>theory, could have been involved in illegal activities during the Nazi era. And
</p>
<p>furthermore, virtually all of those very few individuals who are still alive are
</p>
<p>probably too old now to travel to the United States.
</p>
<p>4.5 Social Desirability
</p>
<p>The &ldquo;social desirability paradigm&rdquo; refers to a phenomenon that we frequently
</p>
<p>encounter in social science research: survey respondents are inclined to give socially
</p>
<p>desirable responses, or responses that make them look good against the background
</p>
<p>of social norms or common values. The social desirability bias is most prevalent in
</p>
<p>the field of sensitive self-evaluation questions. Respondents can be inclined to avoid
</p>
<p>disapproval, embarrassment, or legal consequences and therefore opt for an incorrect
</p>
<p>answer in a survey. For example, respondents know that voting in elections is a
</p>
<p>socially desirable act. Hence, they might be tempted to affirm that they have voted in
</p>
<p>the last presidential or parliamentary election even if they did not. Vice versa, the
</p>
<p>consumption of hard drugs such as cocaine or ecstasy is a socially undesirable act
</p>
<p>that is also punishable by law. Consequently, even if the survey is anonymously
</p>
<p>conducted, a respondent might not admit to consuming hard drugs, even if she does
</p>
<p>so regularly.
</p>
<p>The social desirability construct jeopardizes the validity of a survey as socially
</p>
<p>undesired responses are underestimated. In a simple survey, it is very difficult for a
</p>
<p>researcher to detect how much the social desirability bias impacts the given
</p>
<p>responses. One implicit way of detection would be to check if a respondent answers
</p>
<p>a number of similar questions in a socially desirable manner. For example, if a
</p>
<p>researcher asks if respondents have ever speeded, smoked cigarettes, smoked mari-
</p>
<p>juana, cheated with the taxes, or lied to a police officer, and gets negative answers for
</p>
<p>all five items, there is a possibility that the respondent chose social desirability over
</p>
<p>honesty. Yet, the researcher a priori cannot detect, whether this cheating with the
</p>
<p>answers happened and for what questions. The only thing she can do is to treat the
</p>
<p>answers of this particular questionnaire with care, when analyzing the questionnaire.
</p>
<p>Another, albeit also imperfect, way to detect socially desirable rather than correct
</p>
<p>answers is by follow-up questions. For example, a researcher could first ask the
</p>
<p>question. Did you vote in the last parliamentary election? A follow-up question
</p>
<p>could then ask the respondent for which party she voted for? This follow-up question
</p>
<p>could include the do not know category. It is likely that respondents remember for
</p>
<p>which party they voted, in particularly, if the survey is conducted relatively shortly
</p>
<p>after the election. This implies that somebody, who indicated that she voted, but does
</p>
<p>not recall her party choice, might be a candidate for a socially desirable rather than an
</p>
<p>honest answer for the voting question (see Steenkamp et al. 2010: 200&ndash;202;
</p>
<p>Hoffmann 2014: 7 f.; Van de Vijver and He 2014: 7 for an extensive discussion of
</p>
<p>the social desirability paradigm).
</p>
<p>Not only can social desirability be inherent in attitudinal and behavioral
</p>
<p>questions, it can also come from outside influences such as from the pollster itself.
</p>
<p>A famous example of the effect of socially desirable responding was the 1989
</p>
<p>4.5 Social Desirability 41</p>
<p/>
</div>
<div class="page"><p/>
<p>Virginia gubernatorial race between the African-American Douglas Wilder and the
</p>
<p>Caucasian Marshall Coleman. Wilder, who had been ahead in the polls by a
</p>
<p>comfortable buffer of 4&ndash;11%, ended up winning the election merely by the tiny
</p>
<p>margin of 0.6%. The common explanation for that mismatch between the projected
</p>
<p>vote margin in polls and the real vote margin was that a number of White
</p>
<p>respondents interviewed by African-Americans declared their alleged preference
</p>
<p>for Wilder in order to appear tolerant in the eyes of the African-American inter-
</p>
<p>viewer (Krosnick 1999: 44 f.).
</p>
<p>4.6 Open-Ended and Closed-Ended Questions
</p>
<p>In survey research we normally distinguish between two broad types of questions:
</p>
<p>open-ended and closed-ended questions. Questionnaires can be open ended and
</p>
<p>closed ended or can include a mixture of open- and closed-ended questions. The
</p>
<p>main difference between these types of questions is that open-ended questions allow
</p>
<p>respondents to come up with their own answers in their own words, while closed-
</p>
<p>ended questions require them to select an answer from a set of predetermined choices
</p>
<p>(see Table 4.1 for a juxtaposition between open- and closed-ended questions). An
</p>
<p>example of an open-ended question would be: &ldquo;Why did you join the German
</p>
<p>Christian Democratic Party?&rdquo; To answer such a question, the person surveyed
</p>
<p>must describe, in her own words, what factors enticed her to become a member of
</p>
<p>that specific party and what her thought process was before joining. In contrast, an
</p>
<p>example of a closed-ended question would be: &ldquo;Did you partake in a demonstration
</p>
<p>in the past 12 months?&rdquo; This question gives respondents two choices&mdash;they can
</p>
<p>either choose the affirmative answer or the negative answer. Of course, not all open-
</p>
<p>ended questions are qualitative in nature. For example, the question, &ldquo;how much
</p>
<p>money did you donate to the Christian Democratic Party&rsquo;s election campaign in
</p>
<p>2012&rdquo; requires a precise number. In fact, all closed- and open-ended questions, either
</p>
<p>require numerical answers or answers that can relatively easily be converted into a
</p>
<p>number in order for them to be utilized in quantitative research (see Table 4.1).
</p>
<p>In fact, the usage of non-numerical open-ended questions and closed-ended
</p>
<p>questions frequently follows different logics. Open-ended questions are frequently
</p>
<p>Table 4.1 Open-ended versus closed-ended questions
</p>
<p>Open-ended questions Closed-ended questions
</p>
<p>No predetermined responses given Designed to obtain predetermined responses
</p>
<p>Respondent is able to answer in his or her
</p>
<p>own words
</p>
<p>Possible answers: yes/no; true/false, scales,
</p>
<p>values
</p>
<p>Useful in exploratory research and to
</p>
<p>generate hypotheses
</p>
<p>Useful in hypotheses testing
</p>
<p>Require skills on the part of the researcher in
</p>
<p>asking the right questions
</p>
<p>Easy to count, analyze, and interpret
</p>
<p>Answers can lack uniformity and be difficult
</p>
<p>to analyze
</p>
<p>There is the risk that the given question might not
</p>
<p>include all possible answers
</p>
<p>42 4 Constructing a Survey</p>
<p/>
</div>
<div class="page"><p/>
<p>used in more in-depth questionnaires and interviews aiming to generate high-quality
</p>
<p>data that can help researchers generate hypotheses and/or explain causal
</p>
<p>mechanisms. Since it can sometimes be tricky to coherently summarize qualitative
</p>
<p>interview data, qualitative researchers must frequently utilize sophisticated data
</p>
<p>analytical techniques including refined coding schemes and thought-through docu-
</p>
<p>ment analytical techniques (Seidman 2013; Yin 2015). However, since this is a book
</p>
<p>about quantitative methods and survey research, I do not discuss qualitative
</p>
<p>interviewing and coding in detail here. Rather, I focus on quantitative research.
</p>
<p>Yet, working with a set of categories is not without caveats either; it can lead to
</p>
<p>biased answers and restrict the respondent in his or her answering possibilities. As a
</p>
<p>rule, the amount of response choices should not be too restricted to give respondents
</p>
<p>choices. At the same time, however, the amount of options should not exceed the
</p>
<p>cognitive capacities of the average respondent either. With regard to a phone or face-
</p>
<p>to-face interview, there is some consensus that not more than seven response
</p>
<p>categories should be offered (Schumann 2012: 74).
</p>
<p>The choice of the appropriate number of response choices can be a tricky process.
</p>
<p>As a general rule, it makes sense to be consistent with respect to the selection of
</p>
<p>response scales for similar questions to prevent confusing the respondent (Weisberg
</p>
<p>et al. 1996: 98). For example, if a researcher asks in a survey of citizens&rsquo; satisfaction
</p>
<p>with the country&rsquo;s economy, the country&rsquo;s government, and the country&rsquo;s police
</p>
<p>forces, it makes sense to use the same scale for all three questions. However, there
</p>
<p>are many options I can use. Consider the following question: How satisfied are you
</p>
<p>with the economic situation in your country? A researcher could use a scale from 0 to
</p>
<p>10 or a scale from 0 to 100, both of which would allow respondents to situate
</p>
<p>themselves. A researcher could also use a graded measure with or without a neutral
</p>
<p>category and/or a do not know option (for a list of options see Table 4.2). To a certain
</p>
<p>degree, the chosen operationalization depends on the purpose of the study and the
</p>
<p>research question but to a certain degree is also a question of taste.
</p>
<p>Table 4.2 Response choices for the question how satisfied are you with the economic situation in
</p>
<p>your country?
</p>
<p>Operationalization 1 Scale from 0 to 100 (zero meaning not satisfied at all, 100 meaning very
</p>
<p>satisfied)
</p>
<p>Operationalization 2 Scale from 0 to 10 (zero meaning not satisfied at all, 10 meaning very
</p>
<p>satisfied)
</p>
<p>Operationalization 3 5 value scale including the categories very satisfied, satisfied, neutral, not
</p>
<p>satisfied, not satisfied at all
</p>
<p>Operationalization 4 4 value scale including the categories very satisfied, satisfied, not satisfied,
</p>
<p>not satisfied at all
</p>
<p>Operationalization 5 6 value scale including the categories very satisfied, satisfied, neutral, not
</p>
<p>satisfied, not satisfied at all, and do not know
</p>
<p>Operationalization 6 5 value scale including the categories very satisfied, satisfied, not satisfied,
</p>
<p>not satisfied at all, I do not know
</p>
<p>4.6 Open-Ended and Closed-Ended Questions 43</p>
<p/>
</div>
<div class="page"><p/>
<p>4.7 Types of Closed-Ended Survey Questions
</p>
<p>Researchers can choose from a variety of questions including scales, dichotomous
</p>
<p>questions, and multiple-choice questions. In this section, this book presents the most
</p>
<p>important types of questions:
</p>
<p>4.7.1 Scales
</p>
<p>Scales are ubiquitous in social sciences questionnaires. Nearly all opinion-based
</p>
<p>questions use some sort of scale. An example would be: &ldquo;Rate your satisfaction with
</p>
<p>your country&rsquo;s police forces from 0 (not satisfied at all) to 10 (very satisfied).&rdquo;Many
</p>
<p>questions tapping into personal attributes use scales, as well [e.g., &ldquo;how would you
</p>
<p>rate your personal health?&rdquo; (0, poor; 1, rather poor; 2, average; 3, rather good; 4, very
</p>
<p>good)]. Finally, some behavioral questions use scales, as well. For example, you
</p>
<p>might find the question: &ldquo;How often do you generally watch the news on TV?&rdquo;
</p>
<p>Response options could be not at all (coded 0), rather infrequently (coded 1),
</p>
<p>sometimes (coded 2), rather frequently (coded 3), and very frequently (coded 4).
</p>
<p>The most prominent scales are Likert and Guttman scales.
</p>
<p>Likert Scale A Likert Scale is the most frequently used ordinal variable in
</p>
<p>questionnaires (maybe the most frequently used type of questions overall) (Kumar
</p>
<p>1999: 129). Likert Scales use fixed choice response formats and are designed to
</p>
<p>measure attitudes or opinions (Bowling 1997; Burns and Grove 1997). Such a scale
</p>
<p>assumes that the strength/intensity of the experience is linear, i.e., on a continuum
</p>
<p>from strongly agree to strongly disagree, and makes the assumption that attitudes can
</p>
<p>be measured. Respondents may be offered a choice of five to seven or even nine
</p>
<p>pre-coded responses with the neutral point being neither agree nor disagree (Kumar
</p>
<p>1999: 132).
</p>
<p>Example 1: Going to War in Iraq Was a Mistake of the Bush Administration
</p>
<p>The respondent has five choices: strongly agree, somewhat agree, neither agree nor
</p>
<p>disagree, somewhat disagree, and strongly disagree.
</p>
<p>Example 2: How Often Do You Discuss Politics with Your Peers?
</p>
<p>The respondent has five choices: very frequently, frequently, occasionally, rarely,
</p>
<p>and never.
</p>
<p>In the academic literature, there is a rather intense debate about the usage of the
</p>
<p>neutral category and the do not know option. This applies to Likert Scales and other
</p>
<p>survey questions as well. Including a neutral category makes it easier for some
</p>
<p>people to choose/respond. It might be a safe option, in particular for individuals, who
</p>
<p>prefer not taking a choice. However, excluding the neutral option forces individuals
</p>
<p>to take a position, even if they are torn, or really stand in the middle for the precise
</p>
<p>question at hand (Sapsford 2006; Neuman and Robson 2014). A similar logic applies
</p>
<p>44 4 Constructing a Survey</p>
<p/>
</div>
<div class="page"><p/>
<p>to the do not know option (see Mondak and Davis 2001; Sturgis et al. 2008). The
</p>
<p>disadvantage of this option is that many respondents go with &ldquo;no opinion&rdquo; just
</p>
<p>because it is more comfortable. In most cases, respondents choose this option due to
</p>
<p>conflicting views and not due to a lack of knowledge. So, in a sense, they usually do
</p>
<p>have an opinion and lean at least slightly to one side or another. That is why the
</p>
<p>inclusion of a &ldquo;no opinion&rdquo; option can reduce the number of respondents who give
</p>
<p>answers to more complex subjects. On the other hand, if this option is omitted,
</p>
<p>respondents can feel pressed to pick a side although they really are indifferent, for
</p>
<p>example, because they know very little about the matter. Pushing respondents to give
</p>
<p>arbitrary answers can therefore affect the validity and reliability of a survey.
</p>
<p>For example, somebody might not be interested in economics and besides getting
</p>
<p>her monthly paycheck has no idea how the economy functions in her country. Such a
</p>
<p>person can only take a random guess for this question, if the &ldquo;do not know&rdquo; option is
</p>
<p>not included in the questionnaire. For sure, she could leave out the question, but this
</p>
<p>might feel challenging. Hence, the respondent might feel compelled to give an
</p>
<p>answer even if it is just a random guess.
</p>
<p>While there is no panacea for avoiding these problems, the researcher must be
</p>
<p>aware of the difficulty of finding the right number and type of response categories
</p>
<p>and might think through these categories carefully. A possible way of dealing with
</p>
<p>this challenge is to generally offer &ldquo;no opinion&rdquo; options, but to omit them for items
</p>
<p>on well-known issues or questions where individuals should have an opinion. For
</p>
<p>example, if you ask respondents about their self-reported health, there is no reason to
</p>
<p>assume that respondents do not know how they feel. In contrast, if you ask them
</p>
<p>knowledge questions (e.g., &ldquo;who is the president of the European Commission?&rdquo;),
</p>
<p>the do not know option is a viable choice, as it is highly possible that politically
</p>
<p>uninterested citizens do not know who the president of the European Commission
</p>
<p>is. Alternatively, the researcher can decide to omit the &ldquo;no opinion&rdquo; option and test
</p>
<p>the strength of an attitude through follow-up questions. This way, it might become
</p>
<p>evident whether the given response represents a real choice rather than a guess
</p>
<p>(Krosnick 1999: 43 f.; Weisberg et al. 1996: 89 f.). For example, a pollster could first
</p>
<p>ask an individual about her political knowledge using the categories low, rather low,
</p>
<p>middle, rather high, and very high. In a second step, she could ask &ldquo;hard&rdquo; questions
</p>
<p>about the function of the political system or the positioning of political parties. These
</p>
<p>&ldquo;hard&rdquo; questions could verify whether the respondent judges her political knowledge
</p>
<p>level accurately.
</p>
<p>The Semantic Differential Scale The use of the semantic differential scale allows
</p>
<p>for more options than the use of a Likert Scale, which is restricted to four or five
</p>
<p>categories. Rather than having each category labeled, the semantic scale uses two
</p>
<p>bipolar adjectives at each end of the question. Semantic differential scales normally
</p>
<p>range from 7 to 10 response choices (see Tables 4.3 and 4.4).
</p>
<p>Large Rating Scales These are scales that have a larger range than 0&ndash;10. Such
</p>
<p>scales can often have a range from 0 to 100. Within this range the respondent is free
</p>
<p>4.7 Types of Closed-Ended Survey Questions 45</p>
<p/>
</div>
<div class="page"><p/>
<p>to choose the number that most accurately reflects her opinion. For example,
</p>
<p>researchers could ask respondents how satisfied they are with the state of the
</p>
<p>economy in their country, on a scale from 0, not satisfied at all, to 100 very satisfied.
</p>
<p>Guttman Scale The Guttman scale represents another rather simple way of mea-
</p>
<p>suring ordinal variables. This scale is based on a set of items with which the
</p>
<p>respondents can agree or disagree. All items refer to the exact same variable.
</p>
<p>However, they vary in their level of &ldquo;intensity&rdquo; which means that even people
</p>
<p>with low agreement might still agree with the first items (questions with a low
</p>
<p>degree of intensity usually come first) while it takes high stakes for respondents to
</p>
<p>agree with the last ones. The respondent&rsquo;s score is the total number of items she
</p>
<p>agrees with&mdash;a high score implies a high degree of agreement with the initial
</p>
<p>questions. Since, all items of one variable are commonly listed in increasing order
</p>
<p>according to their intensity, this operationalization is based on the assumption that if
</p>
<p>a respondent agrees with any one of the asked items, she should have agreed with all
</p>
<p>previous items too. The following example clarifies the idea of &ldquo;intensity&rdquo; in
</p>
<p>response patterns.
</p>
<p>Example: Do You Agree or Disagree that Abortions Should Be Permitted?
</p>
<p>1. When the life of the woman is in danger.
</p>
<p>2. In the case of incest or rape.
</p>
<p>3. When the fetus appears to be unhealthy.
</p>
<p>4. When the father does not want to have a baby.
</p>
<p>5. When the woman cannot afford to have a baby.
</p>
<p>6. Whenever the woman wants.
</p>
<p>Due to the Guttman scale&rsquo;s basic assumption, a respondent with a score of
</p>
<p>4 agrees with the first four items and disagrees with the last two items. The largest
</p>
<p>challenge when using a Guttman scale is to find a suitable set of items that (perfectly)
</p>
<p>match the required response patterns. In other words, there must be graduation
</p>
<p>between each response category and consensus that agreement to the fourth item is
</p>
<p>more difficult and restricted than agreement to the third item.
</p>
<p>Table 4.3 Example of a semantic differential scale with seven response choices
</p>
<p>How satisfied are you with the services received?
</p>
<p>1 7
</p>
<p>Not at all satisfied Very satisfied
</p>
<p>Table 4.4 Example of a semantic differential scale with ten response choices
</p>
<p>Do you think immigrants make your country a better or a worse place to live in?
</p>
<p>1 10
</p>
<p>Better place Worse place
</p>
<p>46 4 Constructing a Survey</p>
<p/>
</div>
<div class="page"><p/>
<p>4.7.2 Dichotomous Survey Questions
</p>
<p>The dichotomous survey question normally leaves respondents with two answering
</p>
<p>choices. These two choices can include personal characteristics such as male and
</p>
<p>female, or they can include questions about personal attributes such as whether
</p>
<p>somebody is married or not.
</p>
<p>Example: Did You Participate in a Lawful Demonstration in the Past
</p>
<p>12 Months? (Yes/No)
</p>
<p>Please note that some questions that were asked dichotomously for decades have
</p>
<p>recently been asked in a more trichotomous fashion. The prime example is gender.
</p>
<p>For decades, survey respondents had two options to designate their gender man or
</p>
<p>woman, not considering that some individuals might not identify with either of the
</p>
<p>dichotomous choices. Thus the politically correct way now is to include a third
</p>
<p>option such as neither nor.
</p>
<p>4.7.3 Multiple-Choice Questions
</p>
<p>Multiple-choice questions are another form of a frequently used question type. They
</p>
<p>are easy to use, respond to, and analyze. The different categories the respondents can
</p>
<p>choose from must be mutually exclusive. Multiple-choice questions can be both
</p>
<p>single answer (i.e., the respondent can only pick one option) and multiple answer
</p>
<p>(i.e., the respondent can pick several answers) (see Tables 4.5 and 4.6).
</p>
<p>One of the weaknesses of some type of multiple-choice questions is that the
</p>
<p>choice of responses is rather limited and sometimes not final. For example, in
</p>
<p>Table 4.5 Example of single-answer multiple-choice question
</p>
<p>Who is your favorite politician among the four politicians listed below?
</p>
<p>A Donald Trump
</p>
<p>B Emmanuel Macron
</p>
<p>C Angela Merkel
</p>
<p>D Theresa May
</p>
<p>Table 4.6 Example of a multiple-answer multiple-choice question
</p>
<p>Which medium do you use to get your political information from? (click all that apply)
</p>
<p>A Television news broadcasts
</p>
<p>B Radio
</p>
<p>C Internet
</p>
<p>D Newspaper
</p>
<p>E Discussion with friends
</p>
<p>F Other (please specify)
</p>
<p>G I do not inform myself politically
</p>
<p>4.7 Types of Closed-Ended Survey Questions 47</p>
<p/>
</div>
<div class="page"><p/>
<p>Table 4.6, somebody could receive her political information from weekly
</p>
<p>magazines, talk shows, or political parties. In the current example, we have not
</p>
<p>included these options for parsimony reasons. Yet, the option E (other) allows
</p>
<p>respondents to add other items, thus allowing for greater inclusivity. (But please
</p>
<p>note that if the respondents list too many options under the category &ldquo;other,&rdquo; the
</p>
<p>analysis of the survey becomes more complicated).
</p>
<p>4.7.4 Numerical Continuous Questions
</p>
<p>Numerical continuous questions ask respondents a question that in principle allows
</p>
<p>the respondent to choose from an infinite number of response choices. Examples
</p>
<p>would be questions that ask: what is your age? What is your net income?
</p>
<p>4.7.5 Categorical Survey Questions
</p>
<p>Frequently, researchers split continuous numerical questions into categories. These
</p>
<p>categories frequently correspond to established categories in the literature. For
</p>
<p>example, instead of asking what your age is, you could provide age brackets
</p>
<p>distinguishing young individuals (i.e., 18 and younger), rather young individuals
</p>
<p>(19&ndash;34), middle-aged individuals (35&ndash;50), rather old individuals (51&ndash;64), and old
</p>
<p>individuals (65 and higher) (see Table 4.7). The same might apply to income. For
</p>
<p>example, we could have income brackets for every $20,000 (see Table 4.8).
</p>
<p>Using brackets or categories might be particularly helpful for features, where
</p>
<p>respondents do not want to reveal the exact number. For example, some respondents
</p>
<p>might not want to reveal their exact age. The same might apply to income. If they are
</p>
<p>Table 4.7 Example of a
</p>
<p>categorical survey question
</p>
<p>with five choices
</p>
<p>Which category best describes your age?
</p>
<p>Younger than 18
</p>
<p>19&ndash;34
</p>
<p>35&ndash;50
</p>
<p>51&ndash;64
</p>
<p>65 and higher
</p>
<p>Table 4.8 Example of a
</p>
<p>categorical survey question
</p>
<p>with six choices
</p>
<p>In which bracket does your net income fall?
</p>
<p>Lower than $20,000
</p>
<p>$20,000&ndash;$39,999
</p>
<p>$40,000&ndash;$59,999
</p>
<p>$60,000&ndash;$79,999
</p>
<p>$80,000&ndash;$99,999
</p>
<p>Over 100,000
</p>
<p>48 4 Constructing a Survey</p>
<p/>
</div>
<div class="page"><p/>
<p>offered rather broad age or income brackets, they might be more willing to provide
</p>
<p>an answer than be probed for their exact age or income.
</p>
<p>4.7.6 Rank-Order Questions
</p>
<p>Sometimes researchers might be interested in rankings. Rank-order questions allow
</p>
<p>respondents to rank persons, brands, or products based on certain attributes such as
</p>
<p>the popularity of politicians or the vote choice for parties. In rank-order questions,
</p>
<p>the respondent must consecutively rank the choices from most favorite to least
</p>
<p>favorite (see Table 4.9).
</p>
<p>4.7.7 Matrix Table Questions
</p>
<p>Matrix-level questions are questions in tabular format. They consist of multiple
</p>
<p>questions with the same response choices. The questions are normally connected
</p>
<p>to each other, and the response choices frequently follow a scale such as a Likert
</p>
<p>scale (see Table 4.10).
</p>
<p>Table 4.9 Example of a rank order question
</p>
<p>Consecutively rank the following five parties from most popular (coded 1) to least popular
</p>
<p>(coded 5)
</p>
<p>Christian Democratic Party
</p>
<p>Social Democratic Party
</p>
<p>Free Democratic Party
</p>
<p>Green Party
</p>
<p>Left Party
</p>
<p>Alternative for Germany
</p>
<p>Table 4.10 Example of a matrix table question
</p>
<p>How would you rate the following attributes of President Trump?
</p>
<p>Well below
</p>
<p>average
</p>
<p>Below
</p>
<p>average Average
</p>
<p>Above
</p>
<p>Average
</p>
<p>Well above
</p>
<p>average
</p>
<p>Honesty
</p>
<p>Competence
</p>
<p>Trustworthiness
</p>
<p>Charisma
</p>
<p>4.7 Types of Closed-Ended Survey Questions 49</p>
<p/>
</div>
<div class="page"><p/>
<p>4.8 Different Variables
</p>
<p>Regardless of the type of survey questions, there are four different ways to
</p>
<p>operationalize survey questions. The four types of variables are string variables,
</p>
<p>continuous variables (interval variables), ordinal variables, and nominal variables.
</p>
<p>A string variable is a variable that normally occupies the first column in a
</p>
<p>dataset. It is a non-numerical variable, which serves as the identifier. Examples are
</p>
<p>individuals in a study or countries. This variable is normally not part of any analysis.
</p>
<p>A continuous variable can have, in theory, an infinite number of observations
</p>
<p>(e.g., age, income). Such a question normally follows from a continuous numerical
</p>
<p>question. To highlight, personal income levels can in theory have any value between
</p>
<p>0 and infinity.
</p>
<p>An interval variable is a specific type of variable; it is a continuous variable with
</p>
<p>equal gaps between values. For example, counting the income in steps of thousand
</p>
<p>would be an interval variable: 1000, 2000, 3000, 4000, . . .
</p>
<p>A nominal variable is categorized. There is no specific order or value to the
</p>
<p>categorization (e.g., the order is arbitrary). Because there is no hierarchy in the
</p>
<p>organization of the data, this type of variable is the most difficult to present in
</p>
<p>datasets (see discussion under Sect. 4.9.1).
</p>
<p>An example of a two-categorical nominal variable would be gender (i.e., men and
</p>
<p>women). Such a variable is also called dichotomous or dummy variable.
</p>
<p>An example of a categorical variable with more than two categories would be
</p>
<p>religious affiliation (e.g., Protestant, Catholic, Buddhist, Muslim, etc.)
</p>
<p>An ordinal variable consists of data that are categorized, and there is a clear
</p>
<p>order to the categories. Normally all scales are transformed into ordinal variables.
</p>
<p>For example, educational experience is a typical variable to be grouped as an
</p>
<p>ordinal variable. For example, a coding in the following categories could make
</p>
<p>sense: no elementary school, elementary school graduate, high school graduate,
</p>
<p>college graduate, Master&rsquo;s degree, and Ph.D.
</p>
<p>An ordinal variable can also be a variable that categorizes a variable into set
</p>
<p>intervals. Such an interval question could be: How much time does it take you to get
</p>
<p>to work in the morning? Please tick the applicable category (see Table 4.11).
</p>
<p>What is important for such an ordinal coding of a continuous variable is that the
</p>
<p>intervals are comparable and that there is some type of linear progression.
</p>
<p>The most frequent types of ordinal variables are scales. Representative of such
</p>
<p>scales would be the answer to the question: Please indicate how satisfied you are
</p>
<p>with Chancellor Merkel&rsquo;s foreign policy on a scale from 1 to 5 (see Table 4.12).
</p>
<p>Table 4.11 Ordinal coding of the variable time it takes somebody to go to work
</p>
<p>Less than 10 min 10-30 min 30-60 min More than 60 min
</p>
<p>50 4 Constructing a Survey</p>
<p/>
</div>
<div class="page"><p/>
<p>4.9 Coding of Different Variables in a Dataset
</p>
<p>Except for string variables, question responses need to be transformed into numbers
</p>
<p>to be useful for data analytical purposes. Table 4.13 highlights some rules how this is
</p>
<p>normally done:
</p>
<p>1. In the first column in Table 4.13, we have a string variable. This first variable
</p>
<p>identifies the participants of the study. In a real scientific study, the researcher
</p>
<p>would render the names anonymous and write: student 1, student 2, . . .
</p>
<p>2. The second column is dichotomous variable (i.e., a variable with two possible
</p>
<p>response choices). Whenever researchers have a dichotomous variable, they
</p>
<p>create two categories labeling the first category 0 and the second category
</p>
<p>1. (For any statistical analysis, it does not matter which one of the two categories
</p>
<p>you code 0 and 1, but, of course, you need to remember your coding to interpret
</p>
<p>the data correctly later.)
</p>
<p>3. Columns three and four are continuous variables representing the self-reported
</p>
<p>income and self-reported age the respondent has given in the questionnaire.
</p>
<p>4. The fourth column captures a three-item ordinal variable asking individuals about
</p>
<p>their satisfaction with their job. The choices respondents have are low satisfaction
</p>
<p>(coded 0), medium satisfaction (coded 1), and high satisfaction (coded 2).
</p>
<p>Normally, ordinal variables are consecutively labeled from 0 or 1 for the lowest
</p>
<p>category to how ever many categories there are. To code ordinal variables, it is
</p>
<p>important that categories are mutually exclusive (i.e., one value cannot be in two
</p>
<p>categories). It is also important that progression between the various categories is
</p>
<p>linear.
</p>
<p>4.9.1 Coding of Nominal Variables
</p>
<p>For some analysis such as regression analysis (see Chaps. 8 and 9), non-dichotomous
</p>
<p>categorical variables (e.g., different religious affiliations) cannot be expressed in any
</p>
<p>ordered form, because there is no natural progression in their values. For all statistical
</p>
<p>tests that assume progression between the categories, this causes a problem. To
</p>
<p>circumvent this problem for these tests, we use dummy variables to express such a
</p>
<p>variable. The rule for the creation of dummy variables is that I create one dummy
</p>
<p>variable less than I have categories. For example, if I have four categories, I create
</p>
<p>Table 4.12 Ordinal coding of the scaled variable satisfaction with Chancellor Merkel
</p>
<p>1 not satisfied at all 2 3 4 5 very satisfied
</p>
<p>4.9 Coding of Different Variables in a Dataset 51</p>
<p/>
</div>
<div class="page"><p/>
<p>three dummy variables, with the first category serving what is called the reference
</p>
<p>category. In the example in Table 4.14, the Muslim religion is the reference category
</p>
<p>against which we compare the other religions. (Since this procedure is rather com-
</p>
<p>plex, we will discuss the creation of dummy variables in Chap. 5 again.)
</p>
<p>4.10 Drafting a Questionnaire: General Information
</p>
<p>In real research, the selection of an overarching question guiding the research
</p>
<p>process and the development of a questionnaire is theory driven. In other words,
</p>
<p>social science theory should inform researchers&rsquo; choices of survey questions, and a
</p>
<p>good survey should respond to a precise theoretically driven research question (Mark
</p>
<p>1996: 15f). Yet, for the exercise in this book, where you are supposed to create your
</p>
<p>own questionnaire, you are not supposed to be an expert in a particular field. Rather,
</p>
<p>you can use your general interest, knowledge, and intuition to draft a questionnaire.
</p>
<p>Please also keep in mind that you can use your personal experience to come up with
</p>
<p>the topic and overarching research question of your sample survey. To highlight, if a
</p>
<p>researcher has been affected by poverty in his childhood, he might intuitively have
</p>
<p>an idea about the consequences of child poverty. In her case, it is also likely that she
</p>
<p>has read about this phenomenon and liked a hypothesis of one of the authors she has
</p>
<p>read (e.g., that people who suffered from poverty in their childhood are less likely to
</p>
<p>go to college). Once you have identified a topic and determined the goals and
</p>
<p>objectives of your study, think about the questions you might want to include in
</p>
<p>your survey. Locating previously conducted surveys on similar topics might be an
</p>
<p>additional step enabling you to discover examples of different research designs about
</p>
<p>the same topic.
</p>
<p>When you select the subject of your study, it is important to take the subject&rsquo;s
</p>
<p>practicability into account, as well. For one, a study on the political participation of
</p>
<p>university students can be relatively easily carried through by a university professor
</p>
<p>or a student. On the other hand, studies on human behavior in war situations for
</p>
<p>instance are very difficult to be carried out (Schnell et al. 2011: 3 f.). Also keep in
</p>
<p>mind that before thinking about the survey questions, you must have identified
</p>
<p>Table 4.14 Representing
a nominal variable in a
</p>
<p>dataset
</p>
<p>Dummy 1 Dummy 2 Dummy 3
</p>
<p>Muslim 0 0 0
</p>
<p>Christian 1 0 0
</p>
<p>Buddhist 0 1 0
</p>
<p>Hindu 0 0 1
</p>
<p>Table 4.13 Representing
</p>
<p>string, dichotomous,
</p>
<p>continuous, and ordinal
</p>
<p>variables in a dataset
</p>
<p>Student Gender Income Age Job satisfaction
</p>
<p>John 1 12,954 43 2
</p>
<p>Mary 0 33,456 67 1
</p>
<p>James 1 98,534 54 0
</p>
<p>52 4 Constructing a Survey</p>
<p/>
</div>
<div class="page"><p/>
<p>dependent, independent, and control variables. You must have a concrete idea how
</p>
<p>these variables can be measured in your survey. For example, if a researcher wants to
</p>
<p>explain variation in a student&rsquo;s grades, a student&rsquo;s cumulative grade average is the
</p>
<p>dependent variable. Possible independent or explanatory variables are the numbers
</p>
<p>of hours a student studies per week, the level of her class attendance gauged in
</p>
<p>percent of all classes, her interest in her field of study gauged from 0 not interested at
</p>
<p>all to 10 very interested, and her general life satisfaction again measured on a 0&ndash;10
</p>
<p>scale. In addition, she might add questions about the gender, place of residency (city,
</p>
<p>suburban area, or countryside), and the year of study (i.e., freshman, sophomore,
</p>
<p>junior, and senior or first, second, third, and fourth year).
</p>
<p>4.10.1 Drafting a Questionnaire: A Step-by-Step Approach
</p>
<p>1. Think of an interesting social science topic of your choice (be creative), some-
</p>
<p>thing that is simple enough to ask fellow students or your peers.
</p>
<p>2. Specify the dependent variable as a continuous variable.1
</p>
<p>3. Think of six to eight independent (explanatory) variables which might affect the
</p>
<p>dependent variable. You should include three types of independent variables:
</p>
<p>continuous, ordinal, and nominal/dichotomous variables. Do not ask questions
</p>
<p>that are too sensitive, and do not include open-ended questions.
</p>
<p>4. On the question sheet, clearly label your dependent variable and your indepen-
</p>
<p>dent variables.
</p>
<p>5. On a separate sheet, add a short explanation where you justify your study topic.
</p>
<p>Also add several sentences per independent variable where you formulate a
</p>
<p>hypothesis and very quickly justify your hypothesis. In justifying your hypothe-
</p>
<p>sis, you do not need to consult the academic literature. Rather you can use your
</p>
<p>intuition and knowledge of the work you have already read.
</p>
<p>6. If you encounter problems specifying and explaining a hypothesis, the survey
</p>
<p>question you have chosen might be suboptimal, and you may want to choose
</p>
<p>another research question.
</p>
<p>7. Add a very short introduction to your survey, where you introduce your topic.
</p>
<p>The example below can serve as a basis when you construct your survey.
</p>
<p>1For data analytical reasons, it is important to specify your dependent variable as a continuous
</p>
<p>variable, as the statistical techniques, you will learn later frequently require that the dependent
</p>
<p>variable is continuous.
</p>
<p>4.10 Drafting a Questionnaire: General Information 53</p>
<p/>
</div>
<div class="page"><p/>
<p>Sample Questionnaire
</p>
<p>Dear participants
</p>
<p>This survey is about the money college students spend partying and
</p>
<p>possible factors that might influence students&rsquo; partying expenses. Please
</p>
<p>answer the following questions which will be exclusively used for data
</p>
<p>analytical purposes in my political science research methods class. If you are
</p>
<p>not sure about an answer, just give an estimate. All answers will be treated
</p>
<p>confidentially. I thank you for contributing to our study.
</p>
<p>Dependent variable:
</p>
<p>&bull; How much money do you spend partying per week?
</p>
<p>Independent variables:
</p>
<p>&bull; What is your gender?
</p>
<p>Male Female (circle one)
</p>
<p>&bull; What is your year of study?
</p>
<p>1 2 3 4 5 6 or higher (circle one)
</p>
<p>&bull; On average, how many hours do you spend studying per week?
</p>
<p>&bull; On average, how many days do you go partying per week?
</p>
<p>1 2 3 4 5 or more (circle one)
</p>
<p>&bull; On a scale from 0 to 100, determine how much fun you can have without
</p>
<p>alcohol (0 meaning you can have a lot of fun, 100 you cannot have fun at
</p>
<p>all).
</p>
<p>&bull; On a scale from 0 to 100, determine the quality of the officially sanctioned
</p>
<p>free-time activities at your institution (0 meaning they are horrible,
</p>
<p>100 meaning they are very good).
</p>
<p>&bull; What percent of your tuition do you pay yourself?
</p>
<p>4.11 Background Information About the Questionnaire
</p>
<p>Study Purpose This research analyzes university students&rsquo; spending patterns,
</p>
<p>when they go out to party. This information might be important for university
</p>
<p>administrations, businesses, and parents. It might also serve as an indication of
</p>
<p>how serious they take their studies. Finally, it gives us some measurement on how
</p>
<p>much money students have at their disposal and how they spend it (or at least part of
</p>
<p>it).
</p>
<p>Hypotheses:
</p>
<p>H(1): Guys spend more money than girls.
</p>
<p>54 4 Constructing a Survey</p>
<p/>
</div>
<div class="page"><p/>
<p>It is highly possible that guys like the bar scene more than girls do. For one,
</p>
<p>they go there to watch sports events such as soccer games. Additionally, they like
</p>
<p>to hang out there with friends while having some pints.
</p>
<p>H(2): The more advanced students are in their university career, the less money and
</p>
<p>time they spend going out.
</p>
<p>More advanced classes are supposedly getting more difficult than first or
</p>
<p>second year classes. This would imply that students must spend more time
</p>
<p>studying and would therefore have less time to go out. This, in turn, would entail
</p>
<p>that they are unlikely to spend money for partying purposes.
</p>
<p>H(3): The more time students spend studying, the less money they spend going out.
</p>
<p>The rationale for this hypothesis is that students that study long hours just do
</p>
<p>not have the time to go out a lot and hence are unlikely to spend a lot of money.
</p>
<p>H(4): The more students think they need alcohol to have fun, the more they will
</p>
<p>spend going out.
</p>
<p>Alcohol is expensive, and the more students drink while going out, the more
</p>
<p>money they will spend at bars and nightclubs.
</p>
<p>H(5): The more students think that their university offers them good free time
</p>
<p>activities, the less money they will spend while going out.
</p>
<p>If students spend a lot of their free time participating in university sponsored
</p>
<p>sports or social clubs, they will not have the time to go to bars or nightclubs
</p>
<p>frequently. As a result, they will not spend significant amounts of money while
</p>
<p>going out.
</p>
<p>H(6): People that pay their tuition in full or partly will not spend as much money at
</p>
<p>bars than people that have their tuition paid.
</p>
<p>The rationale for this hypothesis is straightforward: students that must pay a
</p>
<p>significant amount of their tuition do not have a lot of money left to spend at bars
</p>
<p>and nightclubs.
</p>
<p>References
</p>
<p>Bowling, A. (1997). Research methods in health. Buckingham: Open University Press.
</p>
<p>Burns, N., &amp; Grove, S. K. (1997). The practice of nursing research conduct, critique, &amp; utilization.
</p>
<p>Philadelphia: W.B. Saunders.
</p>
<p>Hoffmann, A. (2014). Indirekte Befragungstechniken zur Kontrolle sozialer Erw&uuml;nschtheit in
</p>
<p>Umfragen. Doctoral Thesis, D&uuml;sseldorf.
</p>
<p>Krosnick, J. A. (1999). Maximizing questionnaire quality. In J. P. Robinson, P. R. Shaver, &amp; L. S.
</p>
<p>Wrightsman (Eds.),Measures of political attitudes: Volume 2 in measures of social psychologi-
</p>
<p>cal attitudes series. San Diego: Academic Press.
</p>
<p>Kumar, R. (1999). Research methodology: A step-by-step guide for beginners. In E. D. De Leeuw,
</p>
<p>J. J. Hox, &amp; D. A. Dillman (Eds.), International handbook of survey methodology. New York:
</p>
<p>Lawrence Erlbaum Associates.
</p>
<p>Mark, R. (1996). Research made simple: A handbook for social workers. Thousand Oaks, CA:
</p>
<p>Sage.
</p>
<p>Mondak, J., &amp; Davis, B. C. (2001). Asked and answered: Knowledge levels when we will not take
</p>
<p>&ldquo;don&rsquo;t know&rdquo; for an answer. Political Behaviour, 23(3), 199&ndash;224.
</p>
<p>Neuman, W. L., &amp; Robson, K. (2014). Basics of social research. Toronto: Pearson Canada.
</p>
<p>References 55</p>
<p/>
</div>
<div class="page"><p/>
<p>Sapsford, R. (2006). Survey research. Thousand Oaks, CA: Sage.
</p>
<p>Schnell, R., Hill, P. B., &amp; Esser, E. (2011). Methoden der empirischen Sozialforschung (9th ed.).
</p>
<p>M&uuml;nchen: Oldenbourg.
</p>
<p>Schumann, S. (2012). Repr&auml;sentative Umfrage: Praxisorientierte Einf&uuml;hrung in empirische
</p>
<p>Methoden und statistische Analyseverfahren (6th ed.). M&uuml;nchen: Oldenbourg.
</p>
<p>Seidman, I. (2013). Interviewing as qualitative research: A guide for researchers in education and
</p>
<p>the social sciences. New York: Teachers College Press.
</p>
<p>Steenkamp, J.-B., De Jong, M. G., &amp; Baumgartner, H. (2010). Socially desirable response
</p>
<p>tendencies in survey research. Journal of Marketing Research, 47(2), 199&ndash;214.
</p>
<p>Sturgis, P., Allum, N., &amp; Smith, P. (2008). An experiment on the measurement of political
</p>
<p>knowledge in surveys. Public Opinion Quarterly, 72(1), 90&ndash;102.
</p>
<p>Van de Vijver, F. J. R., &amp; He, J. (2014). Report on social desirability, midpoint and extreme
</p>
<p>responding in TALIS 2013. OECD Education Working Papers, No. 107. Paris: OECD.
</p>
<p>Weisberg, H. F., Krosnick, J. A., &amp; Bowen, B. D. (1996). An introduction to survey research,
</p>
<p>polling, and data analysis (3rd ed.). Thousand Oaks, CA: Sage.
</p>
<p>Yin, R. K. (2015). Qualitative research from start to finish. New York: Guilford.
</p>
<p>Further Reading
</p>
<p>Nuts and Bolts of Survey Research
</p>
<p>Nardi, P. M. (2018). Doing survey research: A guide to quantitative methods. London: Routledge
</p>
<p>(Chap. 1; Chap. 4). Chapter 1 of this book provides a nice introduction why we do survey
</p>
<p>research, why it is important, and what important insights it can bring to the social sciences.
</p>
<p>Chapter 4 gives a nice introduction into questionnaire developments and the different steps that
</p>
<p>go into the construction of a survey.
</p>
<p>Constructing a Survey
</p>
<p>Krosnick, J. A. (2018). Questionnaire design. In The Palgrave handbook of survey research
</p>
<p>(pp. 439&ndash;455). Basingstoke: Palgrave Macmillan. Short and comprehensive summary of the
</p>
<p>dominant literature into questionnaire design. Good as a first read of the topic.
</p>
<p>Saris, W. E., &amp; Gallhofer, I. N. (2014). Design, evaluation, and analysis of questionnaires for survey
</p>
<p>research. San Francisco: Wiley. A very comprehensive guide into the design of surveys. Among
</p>
<p>others, the book thoroughly discusses how concepts become questions, how we can come up
</p>
<p>with response categories for the questions we use, and how to structure questions.
</p>
<p>Applied Texts: Question Wording
</p>
<p>Lundmark, S., Gilljam, M., &amp; Dahlberg, S. (2015). Measuring generalized trust: An examination of
</p>
<p>question wording and the number of scale points. Public Opinion Quarterly, 80(1), 26&ndash;43. The
</p>
<p>authors show that the question wording of the general questions about trust in other individuals
</p>
<p>(i.e. generally speaking, would you say that most people can be trusted?) matters in getting
</p>
<p>accurate responses.
</p>
<p>56 4 Constructing a Survey</p>
<p/>
</div>
<div class="page"><p/>
<p>Conducting a Survey 5
</p>
<p>Abstract
</p>
<p>When the questionnaire is in its final form, the researcher needs to determine what
</p>
<p>the sample and what the population of her study is. This chapter first explains
</p>
<p>both terms and further distinguishes between random, representative, and biased
</p>
<p>samples. Second, it discusses several sampling techniques such as quota sampling
</p>
<p>and snowball sampling. Third, it introduces different types of surveys (e.g., face-
</p>
<p>to-face surveys, telephone surveys, and mail-in or Internet surveys) the author of
</p>
<p>a survey can use to distribute it. As a practical component, students test their
</p>
<p>surveys in an empirical setting by soliciting answers from peers. While this
</p>
<p>procedure does not allow students to get representative or random samples, it
</p>
<p>nevertheless offers students the possibility to collect their own data, which they
</p>
<p>can analyze later. At the end of the unit, students are taught how to input their
</p>
<p>responses into an SPSS or Stata dataset.
</p>
<p>5.1 Population and Sample
</p>
<p>When the questionnaire is in its final form, the researcher needs to determine what
</p>
<p>the population of her study is and what type of sample she will take (see Fig. 5.1).
</p>
<p>The population is the entire group of subjects the researcher wants information
</p>
<p>on. Normally the researcher or polling firm is not able to interview all units of the
</p>
<p>population because of the sheer size. To highlight, the United States has over
</p>
<p>300 million inhabitants, Germany over 80 million, and France over 65 million. It
</p>
<p>is logistically and financially impossible to interview the whole population. There-
</p>
<p>fore, the pollster needs to select a sample of the population instead. To do so, she
</p>
<p>first needs to define a sampling frame. A sampling frame consists of all units from
</p>
<p>which the sample will be drawn. Ideally, the sample frame should be identical to the
</p>
<p>population or at least closely resemble it. In reality, population and sampling frame
</p>
<p>frequently differ (Weisberg et al. 1996: 39). For example, let us consider that the
</p>
<p># Springer International Publishing AG 2019
</p>
<p>D. Stockemer, Quantitative Methods for the Social Sciences,
</p>
<p>https://doi.org/10.1007/978-3-319-99118-4_5
</p>
<p>57</p>
<p/>
<div class="annotation"><a href="http://crossmark.crossref.org/dialog/?doi=10.1007/978-3-319-99118-4_5&amp;domain=pdf">http://crossmark.crossref.org/dialog/?doi=10.1007/978-3-319-99118-4_5&amp;domain=pdf</a></div>
</div>
<div class="page"><p/>
<p>population are all inhabitants of Berlin. A reasonable sampling frame would include
</p>
<p>all households in the German capital, from which a random sample could be taken.
</p>
<p>Using this sample frame, a researcher could then send a questionnaire or survey to
</p>
<p>these randomly chosen households. However, this sampling frame does not include
</p>
<p>homeless people; because they do not have a fixed address, they cannot receive the
</p>
<p>questionnaires. Consequently, this sample drawn from the population will be slightly
</p>
<p>biased, as it will not include the thousands of people, who live on the streets in
</p>
<p>Berlin.
</p>
<p>A sample is a subset of the population the researcher actually examines to gather
</p>
<p>her data. The collected data on the sample aims at gaining information on the entire
</p>
<p>population (Bickman and Rog 1998: 102). For example, if the German government
</p>
<p>wants to know whether individuals favor the introduction of a highway usage fee in
</p>
<p>Germany, it could ask 1000 people whether or not they agree with this proposal. For
</p>
<p>this survey, the population is the 82 million habitants of Germany, and the sample is
</p>
<p>the 1000 people, which the government asks. To make valid inference from a sample
</p>
<p>for a whole population, the sample should be either representative or random.
</p>
<p>5.2 Representative, Random, and Biased Samples
</p>
<p>Representative Sample A representative sample is a sample in which the people in
</p>
<p>the sample have the same characteristics as the people in the population. For
</p>
<p>example, if a researcher knows that in the population she wishes to study 55% of
</p>
<p>people are men, 18% are African&ndash;Americans, 7% are homeless, and 23% earn more
</p>
<p>than 100,000 Euros, she should try to match these characteristics in the sample in
</p>
<p>order to represent the population.
</p>
<p>Random Sample In many social settings, it is basically impossible for researchers
</p>
<p>to match the population characteristics in the sample. Rather than trying any
</p>
<p>matching technique, researchers can take a random sample. Randomization helps
</p>
<p>to offset the confounding effects of known and unknown factors by randomly
</p>
<p>choosing cases. For example, the lottery is a random draw of 6 numbers between
</p>
<p>________________
</p>
<p>________________
</p>
<p>Population
</p>
<p>Sample
</p>
<p>Fig. 5.1 Graphical display of
</p>
<p>a population and a sample
</p>
<p>58 5 Conducting a Survey</p>
<p/>
</div>
<div class="page"><p/>
<p>1 and 49. Similarly large-scale international surveys (e.g., the European Social
</p>
<p>Survey) use randomization techniques to select participants (Nachmias and
</p>
<p>Nachmias 2008). Ideally, such randomization techniques give every individual in
</p>
<p>the population the same chance to be selected in the sample.
</p>
<p>Biased Sample A biased sample is a sample that is neither representative nor
</p>
<p>random. Rather than being a snapshot of the population, a biased sample is a sample,
</p>
<p>whose answers do not reflect the answers we would get had we the possibility to poll
</p>
<p>the whole population.
</p>
<p>There are different forms of biases survey responses can suffer from:
</p>
<p>Selection Bias We have selection bias if the sample is not representative of the
</p>
<p>population it should represent. In other words, a sample is biased if some type of
</p>
<p>individuals such as middle-class men are overrepresented and other types such as
</p>
<p>unemployed women are underrepresented. The more this is the case, the more biased
</p>
<p>the sample becomes, and the potentially more biased the responses will be. Much of
</p>
<p>the early opinion polls that were conducted in the early twentieth century were
</p>
<p>biased. For example, the aforementioned Literary Digest poll, which was sent to
</p>
<p>around ten million people prior to the Presidential Elections 1916 to 1936, was a poll
</p>
<p>that suffered from serious selection bias. Despite the fact that it correctly predicted
</p>
<p>the presidential winners of 1916 to 1932 (but it failed to predict the 1936 winner), it
</p>
<p>did not represent the American voting population accurately. To mail out its
</p>
<p>questionnaire, The Literary Digest used three sources, its own readership, registered
</p>
<p>automobile users, and registered telephone users. Yet, the readers of The Literary
</p>
<p>Digest were middle- or upper-class individuals and so were automobile and tele-
</p>
<p>phone owners. For sure, in the 1910s, 1920s, and 1930s, the use of these sources was
</p>
<p>probably a convenient way to reach millions of Americans. Nevertheless, the
</p>
<p>sampling frame failed to reach poor working-class Americans, as well as the
</p>
<p>unemployed. In particular, during the Great Depression in 1936, rather few
</p>
<p>Americans could afford the luxuries of reading a literary magazine or owning a
</p>
<p>car or a telephone. Hence, the unrepresentativeness of The Literary Digest&rsquo;s sample
</p>
<p>was probably aggravated in 1936. To a large degree, this can explain why The
</p>
<p>Literary Digest survey predicted Alfred Landon to win the presidential election in
</p>
<p>1936, whereas in reality Franklin D. Roosevelt won in a landslide amassing 61% of
</p>
<p>the popular vote. In fact, for The Literary Digest poll, the bias was aggravated by
</p>
<p>non-response bias (Squire 1988).
</p>
<p>Non-response Bias Non-response bias occurs, if certain individuals in your sample
</p>
<p>have a higher likelihood to respond than others and if the responses of those who do
</p>
<p>not respond would differ considerably from the responses of those who respond. The
</p>
<p>source of this type of bias is self-selection bias. For most surveys (except for the
</p>
<p>census in some countries), respondents normally have their entirely free will to
</p>
<p>decide whether or not to participate in the survey. Naturally, some people are more
</p>
<p>likely to participate than others are. Most frequently, this self-selection bias stems for
</p>
<p>5.2 Representative, Random, and Biased Samples 59</p>
<p/>
</div>
<div class="page"><p/>
<p>the topic of the survey. To highlight, individuals who are politically interested and
</p>
<p>knowledgeable might be more prone to answer a survey on conventional and
</p>
<p>unconventional political participation than individuals who could not care less
</p>
<p>about politics. Yet, non-response bias could also stem from other sources. For
</p>
<p>example, it could stem from the time that somebody has at her disposal. In addition,
</p>
<p>persons with a busy professional and private life might simply forget to either fill out
</p>
<p>or return a survey. In contrast, individuals with more free time might be less likely to
</p>
<p>forget to fill out the survey; they might also be more thorough in filling it out.
</p>
<p>Finally, somebody&rsquo;s likelihood to fill out a survey might also be linked to technology
</p>
<p>(especially for online surveys). For example, not everybody has a smartphone or
</p>
<p>permanent access to the internet, some people differ in their email security settings,
</p>
<p>and some people might just not regularly check their emails. This implies that a
</p>
<p>survey reaches some people of the initial sample, but probably not all of them
</p>
<p>(especially if it is a survey that was sent out by email).
</p>
<p>Response Bias Response bias happens when respondents answer a question mis-
</p>
<p>leadingly or untruthfully. The most common form of response bias is the so-called
</p>
<p>social desirability bias; respondents might try to answer the questions less according
</p>
<p>to their own convictions but more in an attempt to adhere to social norms (see also
</p>
<p>Sect. 4.5). For example, social or behavioral surveys (such as the European Social
</p>
<p>Survey or National Election Studies) frequently suffer from response bias for the
</p>
<p>simple question whether individuals voted or not. Voting is an act that is socially
</p>
<p>desirable; a good citizen is expected to vote in an election. When asked the simple
</p>
<p>question whether or not they voted in the past national, regional, or any other
</p>
<p>election, citizens know this social convention. Some nonvoters might feel uneasy
</p>
<p>to admit they did not vote and indicate in the survey that they cast their ballot, even if
</p>
<p>they did not do so. In fact, over-reporting in election surveys is about 10&ndash;15
</p>
<p>percentage points in Western democracies (see Zeglovits and Kritzinger 2014). In
</p>
<p>contrast to the persistent over-reporting of electoral participation, the vote share for
</p>
<p>radical right-wing parties is frequently under-reported in surveys. Parties like the
</p>
<p>Front National in France or the Austrian Freedom Party attract voters and followers
</p>
<p>with their populist, anti-immigration, and anti-elite platforms (Mudde and
</p>
<p>Kaltwasser 2012). Voting for such a party might involve some negative stigmatiza-
</p>
<p>tion as these parties are shunned by the mainstream political elites, intellectuals, and
</p>
<p>the media. For these reasons, citizens might feel uneasy divulging their vote decision
</p>
<p>in a survey. In fact, the real percentage of citizens voting for a radical right-wing
</p>
<p>party is sometimes twice as high as the self-reported vote choice in election surveys
</p>
<p>(see: Stockemer 2012).
</p>
<p>Response bias also frequently occurs for personality traits and for the description
</p>
<p>of certain behaviors. For example, when asked, few people are willing to admit that
</p>
<p>they are lazy or that they chew their fingernails. The same applies to risky and illegal
</p>
<p>behaviors. Few individuals will openly admit to engage in drug consumption or will
</p>
<p>indicate in a survey that they have committed a crime.
</p>
<p>60 5 Conducting a Survey</p>
<p/>
</div>
<div class="page"><p/>
<p>Biased samples are ubiquitous in the survey research landscape. Nearly any freely
</p>
<p>accessible survey you find in a magazine or on the Internet has a biased sample. Such
</p>
<p>a sample is biased because not all the people from the population see the sample, and
</p>
<p>of those who see it, not everybody will have the same likelihood to respond. In many
</p>
<p>freely accessible surveys, there is frequently also the likelihood to respond several
</p>
<p>times. A blatant example of a biased sample would be the National Gun Owner&rsquo;s
</p>
<p>Action Survey 2018 conducted by the influential US gun lobbyist, the National Rifle
</p>
<p>Association (NRA). The survey consists of ten value-laden questions about gun
</p>
<p>rights. For example, in the survey, respondents are asked: should Congress and the
</p>
<p>states eliminate so-called gun free zones that leave innocent citizens defenseless
</p>
<p>against terrorists and violent criminals? The anti-gun media claims that most gun
</p>
<p>owners support mandatory, national gun registration? Do you agree that law-abiding
</p>
<p>citizens should be forced to submit to mandatory gun registration or else forfeit their
</p>
<p>guns and their freedom? In addition to these value-laden questions, the sample is
</p>
<p>mainly restricted to NRA members, gun owners who cherish the second amendment
</p>
<p>of the American Constitution. Consequently, they will show high opposition toward
</p>
<p>gun control. Yet, their opinion will certainly not be representative of the American
</p>
<p>population.
</p>
<p>Yet, surveys are not only (ab)used by think tanks and non-governmental
</p>
<p>organizations to push their demands; in recent times, political parties and candidates
</p>
<p>also use (online) surveys for political expediency or as a political stunt. For example,
</p>
<p>after taking office in January 2017, President Trump&rsquo;s campaign sent out an online
</p>
<p>survey to his supporters entitled &ldquo;Mainstream Media Accountability Survey.&rdquo; In the
</p>
<p>introduction the survey directly addressed the American people&mdash;&ldquo;you are our last
</p>
<p>line of defense against the media&rsquo;s hit jobs. You are our greatest asset in helping our
</p>
<p>movement deliver the truth to the American people.&rdquo; The questionnaire then asked
</p>
<p>questions like: &ldquo;has the mainstream media reported unfairly on our movement?&rdquo; &ldquo;Do
</p>
<p>you believe that the mainstream media does not do their due diligence of fact-
</p>
<p>checking before publishing stories on the Trump administration?&rdquo; or &ldquo;Do you
</p>
<p>believe that political correctness has created biased news coverage on both illegal
</p>
<p>immigration and radical Islamic terrorism?&rdquo; From a survey perspective, Trump&rsquo;s
</p>
<p>survey is the anti-example of doing survey research. The survey pretends to address
</p>
<p>the American people, whereas in fact it is only sent to Trump&rsquo;s core supporters. It
</p>
<p>further uses biased and value-laden questions. The results of such a biased survey is
</p>
<p>a political stunt that the Trump campaign still uses for political purposes. In fact,
</p>
<p>with the proliferation of online surveys, with the continued discussion about fake
</p>
<p>news, and with the ease with which a survey can be created and distributed, there is
</p>
<p>the latent danger that organizations try to send out surveys less to get a &ldquo;valid&rdquo;
</p>
<p>opinion from a population or clearly defined subgroup of that population, but rather
</p>
<p>as a stunt to further their cause.
</p>
<p>5.2 Representative, Random, and Biased Samples 61</p>
<p/>
</div>
<div class="page"><p/>
<p>5.3 Sampling Error
</p>
<p>For sure, the examples described under biased surveys have high sampling errors,
</p>
<p>but even with the most sophisticated randomization techniques, we can never have a
</p>
<p>100% accurate representation of a population from a sample. Rather, there is always
</p>
<p>some statistical imprecision in the data. Having a completely random sample would
</p>
<p>imply that all individuals who are randomly chosen to participate in the survey
</p>
<p>actually do participate, something that will never happen. The sampling error depicts
</p>
<p>the degree to which the results derived from a sample differs from the results derived
</p>
<p>from a population. For a random sample, there is a formula of how to calculate the
</p>
<p>sampling error (see Sect. 6.6). Basically, the sampling error depends on the number
</p>
<p>of observations (i.e., the more observations I have in the sample, the more precision
</p>
<p>there is in the data) and the variability of the data (i.e., how much peoples&rsquo; opinions
</p>
<p>differ). For example, if I ask Germans to rate chancellor Merkel&rsquo;s popularity from
</p>
<p>0 to 100, I will have a higher sampling error if I ask only 100 instead of 1000
</p>
<p>individuals.1 Similarly, I will have a higher sampling error, if individuals&rsquo; opinions
</p>
<p>differ widely rather than being clustered around a specific value. To highlight, if
</p>
<p>Merkel&rsquo;s popularity values differ considerably&mdash;that is, some individuals rate her at
</p>
<p>0, others at 100&mdash;there is more sampling error than when nearly everybody rates her
</p>
<p>around 50, because there is just more variation in the data.
</p>
<p>5.4 Non-random Sampling Techniques
</p>
<p>Large-scale national surveys, measuring the popularity of politicians, citizens&rsquo;
</p>
<p>support for a law, or citizens&rsquo; voting intentions, generally use random sampling
</p>
<p>techniques. Yet, not all research questions require a random sampling. Sometimes
</p>
<p>random sampling might not be possible or too expensive. The most common
</p>
<p>non-probabilistic sampling techniques are convenience sampling, purposive sam-
</p>
<p>pling, volunteer sampling, and snowball sampling,
</p>
<p>Convenience Sampling Convenience sampling is a type of non-probabilistic sam-
</p>
<p>pling technique where people are selected because they are readily available. The
</p>
<p>primary selection criterion relates to the ease of obtaining a sample. One of the most
</p>
<p>common examples of convenience sampling is using student volunteers as subjects
</p>
<p>for research (Battaglia 2008). In fact, college students are probably the most fre-
</p>
<p>quently used group in psychological research. For instance, many researchers (e.g.,
</p>
<p>Praino et al. 2013) examining the influence of physical attractiveness on the electoral
</p>
<p>success of candidates for political office use college students from their local college
</p>
<p>or university to rank the physical attractiveness of the their study subjects (i.e.,
</p>
<p>1Increasing the number of participants in the sample increases the precision of the data up to a
</p>
<p>certain number such as 1000 or 2000 participants. Beyond that number, the gains in increasing
</p>
<p>precision are limited.
</p>
<p>62 5 Conducting a Survey</p>
<p/>
</div>
<div class="page"><p/>
<p>political candidates running for office). These students are readily available and
</p>
<p>cheap to recruit.
</p>
<p>Purposive Sampling In purposive sampling subjects are selected because of some
</p>
<p>characteristics, which the researcher predetermines before the study. Purposive
</p>
<p>sampling can be very useful in situations where the researcher needs information
</p>
<p>for a specific target group (e.g., blond women aged 30&ndash;40). She can purposefully
</p>
<p>restrict her sample to the required social group. A common form of purposive
</p>
<p>sampling is expert sampling. An expert sample is a sample of experts with known
</p>
<p>and demonstrable expertise in a given area of interest. For example, a researcher uses
</p>
<p>an expert sampling technique, if she sends out a survey to corruption specialists to
</p>
<p>ask them about their opinions about the level of corruption in a country (Patton
</p>
<p>1990). In fact, most major international corruption indicators such as Transparency
</p>
<p>International, the World Bank anti-corruption indicator, or the electoral corruption
</p>
<p>indicators collected by the Electoral Integrity Project are all constructed from expert
</p>
<p>surveys.
</p>
<p>Volunteer Sampling Volunteer sampling is a sampling technique frequently used
</p>
<p>in psychology or marketing research. In this type of sampling, volunteers are
</p>
<p>actively searched for or invited to participate. Most of the internet surveys that
</p>
<p>flood the web also use volunteer sampling. Participants in volunteer samples often
</p>
<p>have an interest in the topic, or they participate in the survey because they are
</p>
<p>attracted by the money or the nonfinancial compensation they receive for their
</p>
<p>participation (Black 1999). Sometimes pollsters also offer a high monetary prize
</p>
<p>for one or several lucky participants to increase participation. In our daily lives,
</p>
<p>volunteer surveys are ubiquitous, ranging from airline passenger feedback surveys to
</p>
<p>surveys about costumer habits and to personal hygiene questionnaires.
</p>
<p>Snowball Sampling Snowball sampling is typically employed with populations,
</p>
<p>which are difficult to access. The snowball sampling technique is relatively straight-
</p>
<p>forward. In the first step, the researcher has to identify one or several individuals of
</p>
<p>the group she wants to study. She then asks the first respondents if they know others
</p>
<p>of the same group. By continuing this process, the researcher slowly expands her
</p>
<p>sample of respondents (Spreen 1992). For example, if a researcher wants to survey
</p>
<p>homeless people in the district of Kreuzberg in Berlin, she is quite unlikely to find a
</p>
<p>list with all the people who live in the street. However, if the researcher identifies
</p>
<p>several homeless people, they are likely to know other individuals that live in the
</p>
<p>streets, who again might know others.
</p>
<p>Quota Sampling As implied in the word, quota sampling is a technique (which is
</p>
<p>frequently employed in online surveys), where sampling is done according to certain
</p>
<p>preestablished criteria. For example, many polls have an implicit quota. For exam-
</p>
<p>ple, customer satisfaction polls, membership polls, and readership polls all have an
</p>
<p>implicit quota. They are restricted to those that have purchased a product or service
</p>
<p>for customer satisfaction surveys, the members of an organization or party for
</p>
<p>5.4 Non-random Sampling Techniques 63</p>
<p/>
</div>
<div class="page"><p/>
<p>membership surveys, and the readers of a journal, magazine, or online site for
</p>
<p>readership polls. Yet, quota sampling can also be deliberately used to increase the
</p>
<p>representativeness of the sample. For example, let us assume that a researcher wants
</p>
<p>to know how Americans think about same-sex marriage. Let us further assume that
</p>
<p>the researcher sets the sample size at 1000 people. Using an online questionnaire, she
</p>
<p>cannot get a random or fully representative sample, because still not everybody has
</p>
<p>continuous access to the Internet. Yet, what she can do is to make her sample
</p>
<p>representative of some characteristics such as gender and region. By setting up
</p>
<p>quotas, she can do this relatively easily. For example, as regions, she could identify
</p>
<p>the East, the Midwest, the West, and the South of the United States. For gender, she
</p>
<p>could split the sample so that she has 50% men and women. This gives her a quota of
</p>
<p>125 men and 125 women for each region. Once, she reaches this quota, she closes
</p>
<p>the survey for this particular cohort (for the technical details on how this works, see
</p>
<p>also Fluid Survey University 2017). Using such a technique allows researchers to
</p>
<p>build samples that more or less reflect the population at least when it comes to certain
</p>
<p>characteristics. While it is cheaper than random sampling, quota sampling with the
</p>
<p>help of a survey company can still prove rather expensive. For example, using an
</p>
<p>online quota sampling for a short questionnaire on Germans&rsquo; knowledge and
</p>
<p>assessment of the fall of the Berlin Wall in 1989, which I conducted in 2014, I
</p>
<p>paid $8 per stratified survey. The stratification criteria I used were first gender
</p>
<p>balance and second the requirement that half the participants must reside in the
</p>
<p>East of Germany and the other half in the West.
</p>
<p>5.5 Different Types of Surveys
</p>
<p>Questions about sampling and the means through which a survey is distributed often
</p>
<p>go hand in hand. Several sampling techniques lend themselves particularly well to
</p>
<p>one or another distribution medium. In survey research, we distinguish four different
</p>
<p>ways to conduct a survey: face-to-face surveys, telephone surveys, mail-in surveys,
</p>
<p>and online surveys.
</p>
<p>Face-to-Face Surveys Historically the most commonly employed survey method
</p>
<p>is the face-to-face survey. In essence, in a face-to-face interview or survey, the
</p>
<p>interviewer travels to the respondent&rsquo;s location, or the two meet somewhere else.
</p>
<p>The key feature is the personal interaction between the interviewer who asks
</p>
<p>questions from a questionnaire and the respondent who answers the interviewer&rsquo;s
</p>
<p>questions. The direct personal contact is the key difference from a telephone
</p>
<p>interview, and it comes with both opportunities and risks. One of the greatest
</p>
<p>advantages is that the interviewer can also examine the interviewee&rsquo;s nonverbal
</p>
<p>behavior and draw some conclusions from this. She can also immediately respond
</p>
<p>when problems arise during the task performance; for example, if the respondent
</p>
<p>does not understand the content of a question, the interviewer can explain the
</p>
<p>question in more detail.
</p>
<p>64 5 Conducting a Survey</p>
<p/>
</div>
<div class="page"><p/>
<p>Therefore, this type of survey is especially suitable when it comes to long surveys
</p>
<p>on more complex topics, topics where the interviewer must sit down with the
</p>
<p>respondent to explain certain items. Nevertheless, this type of survey also has its
</p>
<p>drawbacks: a great risk with this type of survey stems from the impact of the
</p>
<p>interviewer&rsquo;s physical presence on the respondents&rsquo; answers. For example, slight
</p>
<p>differences about the interviewers&rsquo; ways of presenting an item can influence the
</p>
<p>responses. In addition, there is the problem of social desirability bias. In particular, in
</p>
<p>the presence of an interviewer, respondents could feel more pressured to meet social
</p>
<p>norms than when answering questions. For example, in the presence of a pollster,
</p>
<p>individuals might be less likely to admit that they have voted for a radical right-wing
</p>
<p>party or that they support the death penalty. In a more anonymous survey, such as an
</p>
<p>online survey, the respondents might be more willing to admit socially frowned-
</p>
<p>upon behaviors or opinions. Face-to-face surveys are still employed for large-scale
</p>
<p>national surveys such as the census in some countries. Some sampling techniques,
</p>
<p>such as snowball sampling, also work best with face-to-face surveys.
</p>
<p>Telephone Survey In many regards, the telephone interview resembles the face-to-
</p>
<p>face interview. Rather than personal, the interaction between interviewer and inter-
</p>
<p>viewee is via the phone. Trained interviewers can ask the same questions to different
</p>
<p>respondents in a uniform manner thus fostering precision and accuracy in soliciting
</p>
<p>responses. The main difference between a telephone interview and a personal
</p>
<p>interview is logistics. Because the interviewer does not have to travel to the
</p>
<p>interviewee&rsquo;s residence or meet her in a public location, a larger benefit from this
</p>
<p>technique is cost. Large-scale telephone surveys significantly simplify the supervi-
</p>
<p>sion of the interviewers as most or all of them conduct the interviews from the same
</p>
<p>site. More so than face-to-face surveys, telephone surveys can also take advantage of
</p>
<p>recent technological advancements. For example, so-called computer-assisted tele-
</p>
<p>phone surveys (CATS) allow the interviewer to record the data directly into a
</p>
<p>computer. This has several advantages: (1) there is no need for any time-consuming
</p>
<p>transfer process from a transcription medium to a computer (which is a potential
</p>
<p>source of errors too). (2) The computer can check immediately whether given
</p>
<p>responses are invalid and change or skip questions depending on former answers.
</p>
<p>In particular, survey firms use telephone interviews extensively, thus benefiting from
</p>
<p>the accuracy and time efficiency of modern telephone surveys coupled with modern
</p>
<p>computer technology (Weisberg et al. 1996: 112&ndash;113; Carr and Worth 2001).
</p>
<p>Mail-in Survey Mail-in surveys are surveys that are sent to peoples&rsquo; mailboxes.
</p>
<p>The key difference between these self-administered questionnaires and the afore-
</p>
<p>mentioned methods is the complete absence of an interviewer. The respondent must
</p>
<p>cope with the questionnaire herself; she only sees the questions and does not hear
</p>
<p>them; assistance cannot be provided, and there is nobody who can clarify unclear
</p>
<p>questions or words. For this reason, researchers or survey firms must devote great
</p>
<p>care when conceiving a mail-in survey. In particular, question wording, the sequence
</p>
<p>of questions, and the layout of the questionnaire must be easy to understand for
</p>
<p>respondents (De Leeuw et al. 2008: 239&ndash;241). Furthermore, reluctant &ldquo;respondents&rdquo;
</p>
<p>5.5 Different Types of Surveys 65</p>
<p/>
</div>
<div class="page"><p/>
<p>cannot be persuaded by an interviewer to participate in the survey, which results in
</p>
<p>relatively low response rates. Yet, individuals can take the surveys at their leisure
</p>
<p>and can think about an answer as much time as they like.
</p>
<p>A potential problem of mail-in surveys is the low response rate. Sometimes, only
</p>
<p>5, 10, or 20% of the sample sends the questionnaire back, a feature which could
</p>
<p>render the results biased. To tackle the issue of low response rates, the researcher
</p>
<p>should consider little incentives for participation (e.g., the chance to win a prize or
</p>
<p>some compensation for participation), and she should send follow-up mailings to
</p>
<p>increase the participants&rsquo; willingness to participate. The upside of the absence of an
</p>
<p>interviewer is that the researcher does not need to worry about interviewer effects
</p>
<p>biasing the results. Another advantage of mail-in surveys is the possibility to target
</p>
<p>participants. Provided that the researcher has demographic information about each
</p>
<p>household in the population or sample she wants to study, mail-in surveys allow
</p>
<p>researchers to target the type of individuals she is most interested in. For example, if
</p>
<p>a researcher wants to study the effect of disability on political participation, she
</p>
<p>could target only those individuals, who fall under the desired category, people with
</p>
<p>disabilities, provided she has the addresses of those individuals.
</p>
<p>Online Survey Online surveys are essentially a special form of mail in surveys.
</p>
<p>Instead of sending a questionnaire by mail, researchers send online surveys by email or
</p>
<p>use a website such as SurveyMonkey to host their questionnaire. Online surveys have
</p>
<p>become more and more prominent over the past 20 years in research. The main
</p>
<p>advantage is costs. Thanks to survey sites such as SurveyMonkey or Fluid Survey,
</p>
<p>everybody can create a survey with little cost. This also implies that the use of online
</p>
<p>surveys is not restricted to research. To name a few, fashion or sports magazines,
</p>
<p>political parties, daily newspapers, as well as radio and television broadcasting stations
</p>
<p>all use online surveys. Most of the time, these surveys are open to the interested reader,
</p>
<p>and there are no restrictions for participation. Consequently, the answers to such
</p>
<p>surveys frequently do not cater to the principles of representativeness. Rather, these
</p>
<p>surveys are based on a quota or convenience sample. Sometimes this poses little
</p>
<p>problems, as many online surveys target a specific population. For example, it
</p>
<p>frequently happens to researchers who publish in a scientific journal with publishing
</p>
<p>houses such as Springer or Tyler and Francis that they receive a questionnaire asking
</p>
<p>them to rate their level of satisfaction with the publishing experience with the specific
</p>
<p>publishing house. Despite the fact that the responses to these questionnaires are almost
</p>
<p>certainly unrepresentative of the whole population of scientists, the feedback they
</p>
<p>receive might give these publishing houses an idea which authors&rsquo; services work and
</p>
<p>which do not work and what they can improve to make the publishing experience
</p>
<p>more rewarding for authors. Yet, online surveys can also be more problematic. They
</p>
<p>become particularly problematic if an online sample is drawn from a biased sample to
</p>
<p>draw inferences beyond the target group (see Sect. 5.2).
</p>
<p>66 5 Conducting a Survey</p>
<p/>
</div>
<div class="page"><p/>
<p>5.6 Which Type of Survey Should Researchers Use?
</p>
<p>While none of the aforementioned survey types is a priori superior to the others, the
</p>
<p>type of survey researchers should use depends on several considerations. First, and
</p>
<p>most importantly, it depends on the purpose of the research and the researcher&rsquo;s
</p>
<p>priorities. For instance, many surveys, including surveys about voting intentions or
</p>
<p>the popularity of politicians, nearly by definition require some national random
</p>
<p>telephone and face-to-face survey or online samples. Second, surveys of a small
</p>
<p>subset of the population, who are difficult to reach by phone or mail, such as the
</p>
<p>homeless, similarly require face-to-face interactions. For such a survey, the sample
</p>
<p>will most likely be a nonrandom snowball or convenience sample. Third, for other
</p>
<p>surveys more relevant for marketing firms and companies, an online convenience
</p>
<p>sample might suffice to draw some &ldquo;valid&rdquo; inferences about customer satisfaction
</p>
<p>with a service or a product.
</p>
<p>There are some more general guidelines. For one, online surveys can reach a large
</p>
<p>number of individuals at basically no cost, in particular if there are no quotas
</p>
<p>involved and if the polling firm has the relevant email addresses or access to a
</p>
<p>hosting website. One the other hand, face-to-face and telephone interviews can target
</p>
<p>the respondents more thoroughly. If the response rate is a particularly important
</p>
<p>consideration, then personal face-to-face surveys or telephone surveys might also be
</p>
<p>a good choice. The drawback to these types of surveys is the cost; these personal
</p>
<p>surveys are the most expensive type of survey (with telephone surveys having
</p>
<p>somewhat lower costs than face-to-face surveys). For research questions where the
</p>
<p>representativeness or randomness of the sample is less of an issue, or for surveys that
</p>
<p>target a specific constituency, mail-in or online surveys could be a rather cost-
</p>
<p>effective means. In particular, the latter are more and more frequently used, because
</p>
<p>through quota sampling techniques, these surveys can also generate rather represen-
</p>
<p>tative samples, at least according to some characteristics. However, as the example
</p>
<p>of the Trump survey illustrates, online surveys can also be used for political
</p>
<p>expediency. That is why the reader, before believing any of these survey results,
</p>
<p>in particular, in a nonscientific context, should inform herself about the sampling
</p>
<p>techniques, and she should look at question wording and the layout of the survey.
</p>
<p>5.7 Pre-tests
</p>
<p>5.7.1 What Is a Pre-test?
</p>
<p>Questionnaire design is complex; hardly any expert can design a perfect question-
</p>
<p>naire by just sitting at her desk (Campanelli 2008: 176). Therefore, before beginning
</p>
<p>the real polling, a researcher should test her questions in an authentic setting to see if
</p>
<p>the survey as a whole and individual questions make sense and are easily understood
</p>
<p>by the respondents. To do so, she could conduct the survey with a small subset of the
</p>
<p>original sample or population aiming to minimize problems before the actual data
</p>
<p>5.7 Pre-tests 67</p>
<p/>
</div>
<div class="page"><p/>
<p>collection begins (Krosnick and Presser 2010: 266 f.; Krosnick 1999: 50 f.) Such
</p>
<p>preliminary research or pre-tests make particular sense in five cases.
</p>
<p>First, for some questions researchers need to decide upon several possible
</p>
<p>measurements. For example, for questions using a Likert scale, a pre-test could
</p>
<p>show if most individuals choose the middle category or the do not know option. If
</p>
<p>this is the case, researchers might want to consider eliminating these options. In
</p>
<p>addition, for a question about somebody&rsquo;s income, a pre-test could indicate whether
</p>
<p>respondents are more comfortable answering a question with set income brackets or
</p>
<p>if they are willing to reveal their real income.
</p>
<p>Second, questions need to be culturally and situationally appropriate, easy to
</p>
<p>understand, and they must carry the inherent concept&rsquo;s meaning. To highlight, if a
</p>
<p>researcher conducts a survey with members of a populist radical right-wing party,
</p>
<p>these members might feel alienated or insulted if she uses the word radical right or
</p>
<p>populist right. Rather, they define themselves as an alternative that incorporates
</p>
<p>common sense. Normally, a researcher engaging in this type of research should
</p>
<p>already know this, but in case she does not, a pre-test can alert her to such
</p>
<p>specificities allowing her to use situationally appropriate wording.
</p>
<p>Third, a pre-test can help a researcher discover if responses to a specific item vary
</p>
<p>or not. In case there is no variance in the responses to a specific question at all, or
</p>
<p>very little variance, the researcher could think about omitting the issue to assure that
</p>
<p>the final questionnaire is solely comprised of discriminative items (items with
</p>
<p>variance) (Kumar 1999: 132). For example, if a researcher asks the question whether
</p>
<p>the United States should leave NATO and everybody responds with no, the
</p>
<p>researcher might consider dropping this question, as there is no variation in answers.
</p>
<p>Fourth, a pre-test is particularly helpful if the survey contains open-ended
</p>
<p>questions and if a coding scheme for these open-ended questions is developed
</p>
<p>alongside the survey. Regardless of the level of sophistication of the survey, there
</p>
<p>is always the possibility that unexpected and therefore unclassifiable responses that
</p>
<p>will be encountered during the survey arise. Conducting a pre-test can reduce
</p>
<p>this risk.
</p>
<p>Fifth, and more practically, a pre-test is especially recommendable if a group of
</p>
<p>interviewers (with little experience) run the interviews. In this case, the pre-test can
</p>
<p>be part of the interviewers&rsquo; training. After the pre-test, the interviewers not only
</p>
<p>share their experiences and discuss which questions were too vague or ambiguous
</p>
<p>but also share their experience asking the questions (Behnke et al. 2006: 258 f.).
</p>
<p>After the pre-test, several questions might be changed depending on the
</p>
<p>respondents&rsquo; reactions (e.g., low response rates) to the initial questionnaire. If
</p>
<p>significant changes are made in the aftermath of the pre-test, the revised questions
</p>
<p>should also be retested. This subsequent pre-test allows the researcher to check if the
</p>
<p>new questions, or the new question wordings, are clearer or if the changes have
</p>
<p>caused new problems (for more information on pre-testing, see Guyette 1983,
</p>
<p>pp. 54&ndash;55).
</p>
<p>68 5 Conducting a Survey</p>
<p/>
</div>
<div class="page"><p/>
<p>5.7.2 How to Conduct a Pre-test?
</p>
<p>The creation of a questionnaire/survey is a reiterative process. In a first step, the
</p>
<p>researcher should check the questions several times to see if there are any uncertain or
</p>
<p>vague questions, if the question flow is good, and if the layout is clear and appealing.
</p>
<p>To this end, it also makes sense for the researcher to read the questions aloud so that
</p>
<p>she can reveal differences between written and spoken language. In a next step, she
</p>
<p>might run the survey with a friend or colleague. This preliminary testing might
</p>
<p>already allow the researcher to identify (some) ambiguous or sensitive questions or
</p>
<p>other problematic aspects in the questionnaire. Then, after this preliminary check, the
</p>
<p>researcher should conduct a trial or pre-test to verify if the topic of the questionnaire
</p>
<p>and every single question are well understood by the survey respondents. To conduct
</p>
<p>such a pre-test, researchers normally choose a handful of individuals who are similar
</p>
<p>to those that will actually take the survey. When conducting her trial, the researcher
</p>
<p>must also decide whether the interviewer (if he does not run the pre-test himself)
</p>
<p>informs the respondent about the purpose of the survey beforehand. An informed
</p>
<p>respondent could be more aware of the interviewing process and any kinds of issues
</p>
<p>that arise during the pre-test. However, the flipside is that the respondent may take the
</p>
<p>survey less seriously. The so-called respondent debriefing session offers a middle
</p>
<p>way addressing the described obstacles. In a first step, the pre-test is conducted
</p>
<p>without informing the respondent beforehand. Then, shortly after the end of the
</p>
<p>pre-test, the interviewer asks the respondent about obstacles and challenges the
</p>
<p>respondent encountered in the course of the pre-test (Campanelli 2008: 180).
</p>
<p>References
</p>
<p>Battaglia, M. (2008). Convenience sampling. In P. J. Lavrakas (Ed.), Encyclopedia of survey
</p>
<p>research methods. Thousand Oaks, CA: Sage.
</p>
<p>Behnke, J., Baur, N., &amp; Behnke, N. (2006). Empirische Methoden der Politikwissenschaft.
</p>
<p>Paderborn: Sch&ouml;ningh.
</p>
<p>Bickman, L., &amp; Rog, D. J. (1998). Handbook of applied social research methods. Thousand Oaks,
</p>
<p>CA: Sage.
</p>
<p>Black, T. R. (1999). Doing quantitative research in the social sciences: An integrated approach to
</p>
<p>research design, measurement, and statistics. Thousand Oaks, CA: Sage.
</p>
<p>Campanelli, P. (2008). Testing survey questions. In E. D. De Leeuw, J. J. Hox, &amp; D. A. Dillman
</p>
<p>(Eds.), International handbook of survey methodology. New York: Lawrence Erlbaum
</p>
<p>Associates.
</p>
<p>Carr, E. C., &amp;Worth, A. (2001). The use of the telephone interview for research. NT research, 6(1),
</p>
<p>511&ndash;524.
</p>
<p>De Leeuw, E. D., Hox, J. J., &amp; Dillman, D. A. (2008). Mixed-mode surveys: When and why. In
</p>
<p>International handbook of survey methodology (pp. 299&ndash;316). New York: Routledge.
</p>
<p>Fluid Surveys University. (2017). Quota sampling effectively &ndash; How to get a representative sample
</p>
<p>for your online surveys. Retrieved December 1, 2017, from http://fluidsurveys.com/university/
</p>
<p>using-quotas-effectively-get-representative-sample-online-surveys/
</p>
<p>Guyette, S. (1983). Community based research: A handbook for native Americans. Los Angeles:
</p>
<p>American Indian Studies Center.
</p>
<p>References 69</p>
<p/>
<div class="annotation"><a href="http://fluidsurveys.com/university/using-quotas-effectively-get-representative-sample-online-surveys/">http://fluidsurveys.com/university/using-quotas-effectively-get-representative-sample-online-surveys/</a></div>
<div class="annotation"><a href="http://fluidsurveys.com/university/using-quotas-effectively-get-representative-sample-online-surveys/">http://fluidsurveys.com/university/using-quotas-effectively-get-representative-sample-online-surveys/</a></div>
</div>
<div class="page"><p/>
<p>Krosnick, J. A. (1999). Maximizing questionnaire quality. In J. P. Robinson, P. R. Shaver, &amp; L. S.
</p>
<p>Wrightsman (Eds.),Measures of political attitudes: Volume 2 in measures of social psychologi-
</p>
<p>cal attitudes series. San Diego: Academic Press.
</p>
<p>Krosnick, J. A., &amp; Presser, S. (2010). Question and questionnaire design. In P. V. Marsden &amp; J. D.
</p>
<p>Wright (Eds.), Handbook of survey research. Bingley: Emerald.
</p>
<p>Kumar, R. (1999). Research methodology: A step-by-step guide for beginners. In E. D. De Leeuw,
</p>
<p>J. J. Hox, &amp; D. A. Dillman (Eds.), International handbook of survey methodology. New York:
</p>
<p>Lawrence Erlbaum Associates.
</p>
<p>Mudde, C., &amp; Kaltwasser, C. R. (Eds.). (2012). Populism in Europe and the Americas: Threat or
</p>
<p>corrective for democracy. Cambridge: Cambridge University Press.
</p>
<p>Nachmias, C. F., &amp; Nachmias, D. (2008). Research methods in the social sciences (7th ed.).
</p>
<p>New York: Worth.
</p>
<p>Patton, M. Q. (1990). Qualitative evaluation and research methods (2nd ed.). Newbury Park, CA:
</p>
<p>Sage.
</p>
<p>Praino, R., Stockemer, D., &amp; Moscardelli, V. G. (2013). The lingering effect of scandals in
</p>
<p>congressional elections: Incumbents, challengers, and voters. Social Science Quarterly, 94(4),
</p>
<p>1045&ndash;1061.
</p>
<p>Spreen, M. (1992). Rare populations, hidden populations and link-tracing designs: What and why?
</p>
<p>Bulletin Methodologie Sociologique, 36(1), 34&ndash;58.
</p>
<p>Squire, P. (1988). Why the 1936 literary digest poll failed. Public Opinion Quarterly, 52(1),
</p>
<p>125&ndash;133.
</p>
<p>Stockemer, D. (2012). The Swiss radical right: Who are the (new) voters of Swiss Peoples&rsquo; Party?
</p>
<p>Representation, 48(2), 197&ndash;208.
</p>
<p>Weisberg, H. F., Krosnick, J. A., &amp; Bowen, B. D. (1996). An introduction to survey research,
</p>
<p>polling, and data analysis (3rd ed.). Thousand Oaks, CA: Sage.
</p>
<p>Zeglovits, E., &amp; Kritzinger, S. (2014). New attempts to reduce overreporting of voter turnout and
</p>
<p>their effects. International Journal of Public Opinion Research, 26(2), 224&ndash;234.
</p>
<p>Further Reading
</p>
<p>Constructing and Conducting a Survey
</p>
<p>Kelley, K., Clark, B., Brown, V., &amp; Sitzia, J. (2003). Good practice in the conduct and reporting of
</p>
<p>survey research. International Journal for Quality in Health Care, 15(3), 261&ndash;266. The short
</p>
<p>article provides a hands-on step-by-step approach into data collection, data analysis, and
</p>
<p>reporting. For each step of the survey process, it identifies best practices and pitfalls to be
</p>
<p>avoided so that the survey becomes valid and credible.
</p>
<p>Krosnick, J. A., Presser, S., Fealing, K. H., Ruggles, S., &amp; Vannette, D. L. (2015). The future of
</p>
<p>survey research: Challenges and opportunities. The National Science Foundation Advisory
</p>
<p>Committee for the social, behavioral and economic sciences subcommittee on advancing sbe
</p>
<p>survey research. Available online at: http://www.nsf.gov/sbe/AC_Materials/The_Future_of_
</p>
<p>Survey_Research.pdf. Comprehensive reports on the best practices, challenges, innovations,
</p>
<p>and new data-collection strategies in survey research.
</p>
<p>Rea, L. M., &amp; Parker, R. A. (2014). Designing and conducting survey research: A comprehensive
</p>
<p>guide. San Francisco: Wiley. A very comprehensive book into survey research consisting of
</p>
<p>three parts: (1) developing and administering a questionnaire, (2) ensuring scientific accuracy,
</p>
<p>and (3) presenting and analyzing survey results.
</p>
<p>70 5 Conducting a Survey</p>
<p/>
<div class="annotation"><a href="http://www.nsf.gov/sbe/AC_Materials/The_Future_of_Survey_Research.pdf">http://www.nsf.gov/sbe/AC_Materials/The_Future_of_Survey_Research.pdf</a></div>
<div class="annotation"><a href="http://www.nsf.gov/sbe/AC_Materials/The_Future_of_Survey_Research.pdf">http://www.nsf.gov/sbe/AC_Materials/The_Future_of_Survey_Research.pdf</a></div>
</div>
<div class="page"><p/>
<p>Internet Survey
</p>
<p>Alessi, E. J., &amp; Martin, J. I. (2010). Conducting an internet-based survey: Benefits, pitfalls, and
</p>
<p>lessons learned. Social Work Research, 34(2), 122&ndash;128. This text provides a very hands-on
</p>
<p>introduction into the conduct of an Internet survey with a special focus on recruitment strategies
</p>
<p>and response rate.
</p>
<p>De Bruijne, M., &amp; Wijnant, A. (2014). Improving response rates and questionnaire design for
</p>
<p>mobile web surveys. Public Opinion Quarterly, 78(4), 951&ndash;962. This research note provides
</p>
<p>some practical lessons how the response rate and data quality can be improved for Internet
</p>
<p>surveys especially constructed for smartphones.
</p>
<p>References 71</p>
<p/>
</div>
<div class="page"><p/>
<p>Univariate Statistics 6
</p>
<p>Abstract
</p>
<p>This first practical chapter is split into two parts. In the first part, I succinctly
</p>
<p>present the two statistical software packages, SPSS and Stata, which are probably
</p>
<p>the most used statistical programs in the social sciences. I also explain how to
</p>
<p>input data into SPSS and Stata datasets. Second, I cover the two univariate
</p>
<p>statistical categories, frequency tables and descriptive statistics, as well as some
</p>
<p>graphical representations of a variable (i.e., boxplot, pie chart, and histogram).
</p>
<p>For each test, the mathematical foundations as well as the practical implementa-
</p>
<p>tion in SPSS and Stata will be introduced based on the sample survey presented at
</p>
<p>the end of Chap. 4.
</p>
<p>6.1 SPSS and Stata
</p>
<p>SPSS and Stata are probably the most frequently used software packages in introductory
</p>
<p>statistics&rsquo; classes. Both programs are complete, integrated statistics packages that allow
</p>
<p>for data analysis, data management, and graphics. They are available in most university
</p>
<p>libraries and are rather simple to navigate. For each test or graphic, the book will
</p>
<p>illustrate the logic behind the test, its mathematical foundations, as well as illustrate
</p>
<p>how to conduct the respective analysis in both SPSS and Stata. Depending on which
</p>
<p>software package you use, you only need to read either the SPSS or the Stata example.
</p>
<p>6.2 Putting Data into an SPSS Spreadsheet
</p>
<p>To create a data file in SPSS, open SPSS then click on new dataset. This opens up a
</p>
<p>spreadsheet similar to an Excel document. There are two parts to any SPSS dataset,
</p>
<p>one part labeled Variable View and one part labeled Data View. Data View is used to
</p>
<p>enter data. Variable View is used to set up the data&mdash;names, variable labels, value
</p>
<p># Springer International Publishing AG 2019
</p>
<p>D. Stockemer, Quantitative Methods for the Social Sciences,
</p>
<p>https://doi.org/10.1007/978-3-319-99118-4_6
</p>
<p>73</p>
<p/>
<div class="annotation"><a href="http://crossmark.crossref.org/dialog/?doi=10.1007/978-3-319-99118-4_6&amp;domain=pdf">http://crossmark.crossref.org/dialog/?doi=10.1007/978-3-319-99118-4_6&amp;domain=pdf</a></div>
</div>
<div class="page"><p/>
<p>labels, etc. To change from Data View to Variable View, click on the icons in the
</p>
<p>lower left corner of the dataset.
</p>
<p>The first step of creating a dataset consists normally of labeling the data. We
</p>
<p>generally do this labeling in the Variable View. In the Variable View, each row
</p>
<p>represents one variable. Each column represents a case such as a person or a country
</p>
<p>(see Fig. 6.1). The first variable we normally enter into a dataset is a string variable,
</p>
<p>an identifier of the cases for which we have collected data for. To enter your survey
</p>
<p>data, go to the Variable View and write in &ldquo;respondent&rdquo; in the first row of the first
</p>
<p>column labeled Name. If you enter your own data, label these data appropriately.
</p>
<p>Because this first variable is normally a string variable (i.e., a non-numeric variable),
</p>
<p>choose the option String in the second column. The other variables are normally
</p>
<p>numeric variables&mdash;the actual data. Include their variable names in the subsequent
</p>
<p>rows, and make sure that these variables are labeled as Numeric (i.e., check the
</p>
<p>second column). When you label the data, make sure that you do not leave any space
</p>
<p>between letters, as SPSS will not allow you to leave any space.
</p>
<p>The copied graph above shows the Variable View of the data from our sample
</p>
<p>questionnaire from Sect. 4.11. The first variable, labeled student, is the identifier
</p>
<p>variable. The second variable is the dependent variable measuring the amount of
</p>
<p>money students spend per week while going out. The remaining variables are the
</p>
<p>independent variables.
</p>
<p>Figure 6.2 shows the Data View of our sample questionnaire data. The variable in
</p>
<p>the first column is the identifier. The second column is the dependent variable, the
</p>
<p>Fig. 6.1 Display of the sample data in Variable View
</p>
<p>Fig. 6.2 Display of the sample data in Data View
</p>
<p>74 6 Univariate Statistics</p>
<p/>
</div>
<div class="page"><p/>
<p>amount of money students spend going out. Variables 3&ndash;8 are the independent
</p>
<p>variables.
</p>
<p>6.3 Putting Data into a Stata Spreadsheet
</p>
<p>To create a data file, you have to click on the icon displaying a spreadsheet and a
</p>
<p>pencil or type &ldquo;edit&rdquo; into the command line. This opens up a spreadsheet similar
</p>
<p>to an Excel document. You can then input the data by hand into this data editor. To
</p>
<p>do so, you have to first label the data. The first variable we normally enter into a
</p>
<p>dataset is a string variable, an identifier of the cases for which we have collected data.
</p>
<p>In our case, this is a string variable, which we label student. Add the name of the
</p>
<p>other variables in the subsequent fields of the first row. When you label the data,
</p>
<p>make sure that you do not leave any space between letters, as Stata does not allow
</p>
<p>you to leave any space. After labeling the variables, you can then input the data.
</p>
<p>Alternatively, you can enter the data in an Excel spreadsheet and copy it to Stata.
</p>
<p>When you paste the data into the Stata data editor, Stata asks you whether you want
</p>
<p>to treat the first row as variable names or data. You click variable names; otherwise,
</p>
<p>the data will not be labeled.
</p>
<p>In Stata we have two different screens, the main screen we use to do our data
</p>
<p>analysis (see Fig. 6.3) and the data editor or the screen in which we can see the data
</p>
<p>(see Fig. 6.4). On the main screen, there is some information about Stata and an
</p>
<p>indication of the dataset you use. On the right side of the screen (i.e., the right upper
</p>
<p>corner), there is a listing of all the variables. On the bottom of the screen is the
</p>
<p>command editor, which you will use to do your analyses.
</p>
<p>Figure 6.4 shows the data editor featuring our sample questionnaire data. The
</p>
<p>variable in the first column is the identifier. The second column is the dependent
</p>
<p>Fig. 6.3 The main Stata screen
</p>
<p>6.3 Putting Data into a Stata Spreadsheet 75</p>
<p/>
</div>
<div class="page"><p/>
<p>variable, the amount of time students spend per week when partying. Variables 3&ndash;8
</p>
<p>are the independent variables.
</p>
<p>(Please note that when you create your Stata file, some of the original variable
</p>
<p>names might be too long, and Stata might not accept them. If this is the case, you
</p>
<p>have to shorten the original name.)
</p>
<p>6.4 Frequency Tables
</p>
<p>A frequency table is a rather simple univariate statistic that is particularly useful for
</p>
<p>categorical variables such as ordinal variables that do not have too many categories.
</p>
<p>For each category or value, such a table indicates the number of times or percentage
</p>
<p>of times each value occurs. A frequency table normally has four columns. The first
</p>
<p>column lists the available categories. The second column displays the raw frequency
</p>
<p>or the number of times a single value occurs. The third column shows the percentage
</p>
<p>of observations that fall into each category&mdash;the basic formula to calculate this
</p>
<p>percentage is the number of observations in the category divided by the total number
</p>
<p>of observations. The final column, labeled cumulative percentage, displays the
</p>
<p>percentage of individuals up to a certain category or point.
</p>
<p>Table 6.1 displays a frequency table, of the variable times partying. The first
</p>
<p>column displays the available options (i.e., the six categories ranging from zero to
</p>
<p>five times and more). The second column shows the raw frequencies (i.e., how many
</p>
<p>individuals normally party, zero times, once, twice, three times, four times or five
</p>
<p>times, and more per week). The third column displays the raw frequency in
</p>
<p>percentages. The final column displays the cumulative percentage. For example,
</p>
<p>Table 6.1 highlights that 60% of the polled, on average, party two times or fewer per
</p>
<p>week.
</p>
<p>Fig. 6.4 Display of the sample data in the Stata data editor
</p>
<p>76 6 Univariate Statistics</p>
<p/>
</div>
<div class="page"><p/>
<p>6.4.1 Constructing a Frequency Table in SPSS
</p>
<p>Step 1: Go to Analyze&mdash;Descriptive Statistics&mdash;Frequencies (see Fig. 6.5).
</p>
<p>Step 2: Highlight the variable&mdash;times_partying&mdash;and then click on the arrow. The
</p>
<p>variable appears in the right rectangle. Then click okay (see Fig. 6.6).
</p>
<p>The SPSS output has five columns (see Table 6.2). Columns one, two, three, and five
</p>
<p>mimic Table 4.6. The first variable is the identifier and displays the existing
</p>
<p>Fig. 6.5 Doing a frequency table in SPSS (first step)
</p>
<p>Table 6.1 Frequency table of the variable times partying
</p>
<p>On average, how many times per week do
</p>
<p>you party Frequency Percentage
</p>
<p>Cumulative
</p>
<p>percentage
</p>
<p>Zero times 3 7.5 7.5
</p>
<p>Once 8 20 27.5
</p>
<p>Twice 13 32.5 60
</p>
<p>Three times 10 25 85
</p>
<p>Four times 5 12.5 97.5
</p>
<p>Five or more times 1 2.5 100
</p>
<p>Total 40 100
</p>
<p>Fig. 6.6 Doing a frequency table in SPSS (second step)
</p>
<p>6.4 Frequency Tables 77</p>
<p/>
</div>
<div class="page"><p/>
<p>categories. Columns two, three, and five display the raw frequency, the
</p>
<p>corresponding percentage for each category, and the cumulative percentage, respec-
</p>
<p>tively. The fourth column, labeled valid percent, displays the percentage of each cell
</p>
<p>by taking into consideration missing values. Missing values are answers to questions
</p>
<p>left blank by the respondent (i.e., a respondent did not answer the question). In our
</p>
<p>example, all survey respondents answered the question on how many times they
</p>
<p>normally go party. Therefore, there are no missing values, and the values in column
</p>
<p>four match the values in column three.
</p>
<p>6.4.2 Constructing a Frequency Table in Stata
</p>
<p>Step 1: Write in the Stata Command field &ldquo;tab Times_Partying,&rdquo; and press enter.
</p>
<p>(Alternatively, you can also write tab and then click on the variable
</p>
<p>Times_Partying in the upper right corner of the display.) (See Fig. 6.7.)
</p>
<p>The Stata output in Table 6.3 has four columns: (1) variable name (this lists all the
</p>
<p>possible categories), (2) raw frequency (lists the occurrence of each category),
</p>
<p>(3) Percent per category (lists the percentage of values that fall into any category),
</p>
<p>and (4) cumulative percentage (the cumulative percentage of values that fall into the
</p>
<p>listed category or a lower category).
</p>
<p>Fig. 6.7 Doing a frequency
</p>
<p>table in Stata
</p>
<p>Table 6.2 SPSS Frequency table output
</p>
<p>Times_Partying
</p>
<p>Frequency Percent Valid percent Cumulative percent
</p>
<p>Valid 0.00 3 7.5 7.5 7.5
</p>
<p>1.00 8 20.0 20.0 27.5
</p>
<p>2.00 13 32.5 32.5 60.0
</p>
<p>3.00 10 25.0 25.0 85.0
</p>
<p>4.00 5 12.5 12.5 97.5
</p>
<p>5.00 1 2.5 2.5 100.0
</p>
<p>Total 40 100.0 100.0
</p>
<p>78 6 Univariate Statistics</p>
<p/>
</div>
<div class="page"><p/>
<p>6.5 The Measures of Central Tendency: Mean, Median, Mode,
and Range
</p>
<p>This part shortly introduces the most widely used measures of central tendency or
</p>
<p>univariate statistics: mean, median, mode, and range.
</p>
<p>Mean
</p>
<p>The mean is the value we commonly call the average. To calculate the mean, sum up
</p>
<p>all observations, and then divide this sum by the number of subjects or observations.
</p>
<p>In statistical language the mean is denoted by �x an observation is denoted x, and
</p>
<p>the sample is denoted by n.
</p>
<p>The mean in mathematical language:
</p>
<p>�x &frac14; x1 &thorn; x2 &thorn; x3 &thorn; . . .&thorn; xn
n
</p>
<p>&frac14;
</p>
<p>P
</p>
<p>n
</p>
<p>i&frac14;1
xi
</p>
<p>n
</p>
<p>The mean can be strongly influenced by outliers (i.e., observations that fall far
</p>
<p>from the rest of the data). To highlight, we take a subsample from our sample dataset.
</p>
<p>For example, the last five values of the variable money spent partying are 60, 60,
</p>
<p>90, 70, and 200.
</p>
<p>If we calculate the mean, we will get (60 + 60 + 90 + 70 + 200)/5 &frac14; 96
We can clearly see that the mean is strongly influenced by the outlier 200. While
</p>
<p>the first 4 students in our subsample spend between 60 and 90 $/week partying, the
</p>
<p>last student spends 200 dollars, which is much different from the other values.
</p>
<p>Without the outlier 200, the mean would be only 70.
</p>
<p>Table 6.3 Stata frequency table output
</p>
<p>6.5 The Measures of Central Tendency: Mean, Median, Mode, and Range 79</p>
<p/>
</div>
<div class="page"><p/>
<p>Median
</p>
<p>The median, or &ldquo;midpoint,&rdquo; is the middle number of a distribution. It is less sensitive
</p>
<p>to outliers and therefore a more &ldquo;resistant&rdquo; measure of central tendency than the
</p>
<p>mean. To calculate the median by hand, just line all values up in order and find the
</p>
<p>middle one (or average of the two middles when n, the number of observations, is
</p>
<p>even.).
</p>
<p>In our example, we would line up the values: 60, 60, 70, 90, and 200, and the
</p>
<p>median would be 70.
</p>
<p>If we were to calculate the median without the outlier 200, we would again line up
</p>
<p>the values: 60, 60, 70, and 90. We would then calculate the mean between the two
</p>
<p>middle values 60 and 70, which is 65.
</p>
<p>Mode
</p>
<p>The mode is the value that occurs most often in the sample. In cases where there are
</p>
<p>several values that occur most often, the mode can consist of these several values.
</p>
<p>Taking our five values again (i.e., 60, 60, 70, 90, 200), the value that appears most
</p>
<p>often is 60, which is the mode of this subsample.
</p>
<p>Range
</p>
<p>The range is a measure that provides us with some indication how widely spread our
</p>
<p>data are. It is calculated by subtracting the highest from the lowest value. In the five-
</p>
<p>value subsample used above, the range would be 140 (i.e., 200 � 60).
</p>
<p>6.6 Displaying Data Graphically: Pie Charts, Boxplots,
and Histograms
</p>
<p>6.6.1 Pie Charts
</p>
<p>A pie chart, sometimes also called circle chart, is one way to display a frequency
</p>
<p>table graphically. The graphic consists of a circle that is divided into slices. Each
</p>
<p>slice represents one of the variable&rsquo;s categories. The size of each slice is proportional
</p>
<p>to the frequency of the value. Pie charts can be strong graphical representation of
</p>
<p>categorical data with few categories. However, the more categories we include into a
</p>
<p>pie chart the harder it is to succinctly compare categories. It is also rather difficult to
</p>
<p>compare data across different pie charts. Figure 6.8 displays the pie chart of the
</p>
<p>variable Times_Partying. We can see that the interpretation is already difficult, as it
</p>
<p>is already hard to guess from the graph the frequency of each slice. If we take another
</p>
<p>variable with more categories such as our dependent variable money spent partying
</p>
<p>(see Fig. 6.9), we see that the categories are basically indistinguishable from each
</p>
<p>other. Hence, a pie chart is not a good option to display this variable.
</p>
<p>80 6 Univariate Statistics</p>
<p/>
</div>
<div class="page"><p/>
<p>0 1
</p>
<p>2 3
</p>
<p>4 5
</p>
<p>Fig. 6.8 Pie chart of the variable times partying
</p>
<p>30 35
</p>
<p>40 50
</p>
<p>60 70
</p>
<p>75 80
</p>
<p>90 100
</p>
<p>110 120
</p>
<p>130
</p>
<p>Fig. 6.9 Pie chart of the variable money spent partying
</p>
<p>6.6 Displaying Data Graphically: Pie Charts, Boxplots, and Histograms 81</p>
<p/>
</div>
<div class="page"><p/>
<p>6.6.2 Doing a Pie Chart in SPSS
</p>
<p>Step 1: Go to Graphs&mdash;Legacy Dialogue &ndash; Pie (see Fig. 6.10).
</p>
<p>Step 2: Click Summaries of groups of cases (see Fig. 6.11).
</p>
<p>Step 3: Highlight the variable&mdash;Times_Partying&mdash;and click on the arrow next to
</p>
<p>Define Slices to include the variable in the field. Then click okay (see Fig. 6.12).
</p>
<p>Fig. 6.10 Doing a pie chart in SPSS (first step)
</p>
<p>Fig. 6.11 Doing a pie chart in SPSS (second step)
</p>
<p>82 6 Univariate Statistics</p>
<p/>
</div>
<div class="page"><p/>
<p>The SPSS output in Fig. 6.13 displays the pie chart; in the right-hand upper corner, it
</p>
<p>denotes the variable name and the existing categories including the corresponding
</p>
<p>colors in the chart.
</p>
<p>6.6.3 Doing a Pie Chart in Stata
</p>
<p>Step 1: Write in the Stata Command field: graph pie, over(Times_Partying) (see
</p>
<p>Fig. 6.14).
</p>
<p>Figures 6.8 and 6.9 display the pie chart Stata output of the two variables times
</p>
<p>partying and money spent partying.
</p>
<p>Fig. 6.12 Doing a pie chart in SPSS (third step)
</p>
<p>6.6 Displaying Data Graphically: Pie Charts, Boxplots, and Histograms 83</p>
<p/>
</div>
<div class="page"><p/>
<p>6.7 Boxplots
</p>
<p>A boxplot is a very convenient way of displaying variables. This type of graph
</p>
<p>allows us to display three measures of central tendency in one graph. The median or
</p>
<p>the midpoint of each dataset is indicated by the black centerline. The blue/gray
</p>
<p>shaded box, which is also known as the interquartile range (IQR) includes the
</p>
<p>mid-50% of the data. The two outer lines denote the range of the data. If values
</p>
<p>extend up to 1.5 times the interquartile range from the upper or lower boundary of
</p>
<p>the mid-50%, they are plotted individually as asterisks. These individually plotted
</p>
<p>values are the outliers.
</p>
<p>Figure 6.15 displays the boxplot of the variable average study time. From the
</p>
<p>graph, we see that the median study time of those students, who participated in the
</p>
<p>survey, is approximately 10 h. We also learn that the mid-50% of the data generally
</p>
<p>study between 7 and 11 h/week. The range of the data is 14. (The maximum value
</p>
<p>denoted by the upper line is 15; the minimum value denoted by the lower line is 1).
</p>
<p>Figure 6.16 displays the boxplot of the variable&mdash;money spent partying (per
</p>
<p>week). We see that the median amount of money students spend partying is
</p>
<p>Fig. 6.14 Doing a pie chart in Stata
</p>
<p>Fig. 6.13 SPSS pie chart output of the variable times partying
</p>
<p>84 6 Univariate Statistics</p>
<p/>
</div>
<div class="page"><p/>
<p>0
5
0
</p>
<p>1
0
</p>
<p>0
1
5
</p>
<p>0
2
0
</p>
<p>0
</p>
<p>M
o
n
</p>
<p>e
y
_
</p>
<p>S
p
e
</p>
<p>n
t_
</p>
<p>P
a
</p>
<p>rt
y
in
</p>
<p>g
</p>
<p>Fig. 6.16 Stata boxplot of the variable money spent partying (per week)
</p>
<p>0
5
</p>
<p>1
0
</p>
<p>1
5
</p>
<p>S
tu
</p>
<p>d
y
_
</p>
<p>T
im
</p>
<p>e
</p>
<p>Fig. 6.15 Stata boxplot of the variable study time (per week)
</p>
<p>6.7 Boxplots 85</p>
<p/>
</div>
<div class="page"><p/>
<p>approximately 75 $/week. The mid-50% of students spend between 60 and 90 dollars
</p>
<p>approximately. At the extremes, students spend 120 dollars at the upper end for
</p>
<p>partying and 30 dollars at the lower end. The boxplot also indicates that there is one
</p>
<p>outlying student in the data. By spending 200 dollars, she does not fit the pattern of
</p>
<p>other students.
</p>
<p>6.7.1 Doing a Boxplot in SPSS
</p>
<p>Step 1: Go to Graphs&mdash;Chart Builder; a dialogue box will open; if this is the case,
</p>
<p>press okay. You will be directed to the Chart Builder, which you see below (see
</p>
<p>Fig. 6.17).
</p>
<p>Step 2: Go to the item&mdash;Choose from&mdash;click on Boxplot. Then in the rectangle to the
</p>
<p>right, three different types of boxplots will appear. Drag the first boxplot image to
</p>
<p>the open field above. After that, click on your variable of interest&mdash;in our case,
</p>
<p>study time&mdash;and drag it to the y-axis. Finally, click okay (see Figs. 6.18 and 6.19).
</p>
<p>Figure 6.19 displays the boxplot of the variable study time. The median is at 10 h/
</p>
<p>week. The range is 14 h (i.e., the minimum in the sample is 1 h, the maximum is
</p>
<p>15 h), and the interquartile range or the mid-50% of the data goes from 7 to 11.
</p>
<p>6.7.2 Doing a Boxplot in Stata
</p>
<p>Step 1: Write in the Stata Command field: graph box Study_Time (see Fig. 6.20).
</p>
<p>Figures 6.15 and 6.16 display two Stata boxplot outputs featuring the variables study
</p>
<p>time per week and money spent partying per week.
</p>
<p>Fig. 6.17 Doing a boxplot in SPSS (first step)
</p>
<p>86 6 Univariate Statistics</p>
<p/>
</div>
<div class="page"><p/>
<p>6.8 Histograms
</p>
<p>Histograms are one of the most widely used graphs in statistics to graphically display
</p>
<p>continuous variables. These graphs display the frequency distribution of a given
</p>
<p>variable. Histograms are very important for statistics in that they tell us if the data is
</p>
<p>normally distributed. In statistical inference&mdash;which means using a sample to gener-
</p>
<p>alize about a population&mdash;normally distributed data is a prerequisite for many
</p>
<p>statistical tests (see below), which we use to generalize from a sample toward a
</p>
<p>population.
</p>
<p>Figure 6.21 shows two normal distributions (i.e., the blue line and the red line). In
</p>
<p>their ideal shape, these distributions have the following features: (1) the mode, mean,
</p>
<p>Fig. 6.18 Doing a boxplot in SPSS (second step)
</p>
<p>6.8 Histograms 87</p>
<p/>
</div>
<div class="page"><p/>
<p>and median are the same value in the center of the distribution. (2) The distribution is
</p>
<p>symmetrical, that is, it has the same shape on each side of the distribution.
</p>
<p>6.8.1 Doing a Histogram in SPSS
</p>
<p>Step 1: Go to Graphs&mdash;Chart Builder&mdash;a dialogue box opens; when this is the case,
</p>
<p>press okay. You will be directed to the Chart Builder (this is the same procedure
</p>
<p>as constructing a boxplot).
</p>
<p>Step 2: Go to the item &ldquo;Choose from,&rdquo; and click on Histogram. Then, in the rectangle
</p>
<p>to the right, four different types of histograms will appear. Drag the first type of
</p>
<p>16
</p>
<p>14
</p>
<p>12
</p>
<p>10
</p>
<p>8
</p>
<p>6
</p>
<p>4
</p>
<p>S
tu
d
y
_
T
im
e
</p>
<p>Fig. 6.19 SPSS boxplot of
</p>
<p>the variable study time (per
</p>
<p>week)
</p>
<p>Fig. 6.20 Doing a boxplot in
</p>
<p>Stata
</p>
<p>Data
</p>
<p>The Normal (Bell) Curve
</p>
<p>F
re
</p>
<p>q
u
</p>
<p>e
n
</p>
<p>c
y
</p>
<p>Fig. 6.21 Shape of a normal
</p>
<p>distribution
</p>
<p>88 6 Univariate Statistics</p>
<p/>
</div>
<div class="page"><p/>
<p>histogram that appears to the open field above. After that, click on your variable
</p>
<p>of interest&mdash;in our case times spent partying&mdash;and drag it to the x-axis. Finally,
</p>
<p>click okay (see Table 7.3 and Fig. 6.22).
</p>
<p>The histogram in Fig. 6.23 displays the distribution of the variable money spent
</p>
<p>partying. We see that the mode is approximately 80 $/month. Pertaining to the
</p>
<p>normality assumption, we see that the data is very roughly normally distributed.
</p>
<p>There are fewer observations on the extremes and more observations in the center.
</p>
<p>However, to be perfectly normally distributed, the bar at 100 should be higher; there
</p>
<p>should also not be any outlier at 200. However, for analytical purposes, we would
</p>
<p>Fig. 6.22 Doing a histogram in SPSS
</p>
<p>6.8 Histograms 89</p>
<p/>
</div>
<div class="page"><p/>
<p>say that this graph is close enough to a normal distribution to make &ldquo;correct&rdquo;
</p>
<p>inferences from samples to populations.
</p>
<p>6.8.2 Doing a Histogram in Stata
</p>
<p>Step 1: Write in the Stata Command field: hist Money_Spent_Partying (see
</p>
<p>Fig. 6.24).
</p>
<p>The Stata output of the variable money spent partying (see Fig. 6.25) uses somewhat
</p>
<p>larger bars than the SPSS output and is therefore a little less &ldquo;precise&rdquo; than the SPSS
</p>
<p>output.
</p>
<p>Mean = 76.50
Std. Dev. = 30.15345
N = 40
</p>
<p>20.0
</p>
<p>15.0
</p>
<p>10.0
</p>
<p>5.0
</p>
<p>0.0
</p>
<p>Money_Spent_Partying
</p>
<p>F
re
q
u
e
n
c
y
</p>
<p>.00 50.00 100.00 150.00 200.00 250.00
</p>
<p>Fig. 6.23 SPSS Histogram of the variable money spent partying per week
</p>
<p>Fig. 6.24 Doing a histogram in Stata
</p>
<p>90 6 Univariate Statistics</p>
<p/>
</div>
<div class="page"><p/>
<p>6.9 Deviation, Variance, Standard Deviation, Standard Error,
Sampling Error, and Confidence Interval
</p>
<p>On the following pages, I will illustrate how you can calculate the sampling error and
</p>
<p>the confidence interval, two univariate statistics that are of high value for survey
</p>
<p>research. In order to calculate the sampling error and confidence interval, we have to
</p>
<p>follow several intermediate steps. We have to calculate the deviation, sample
</p>
<p>variance, standard deviation, and standard error.
</p>
<p>Deviation
</p>
<p>Every sample has a sample mean, and for each observation there is a deviation from
</p>
<p>that mean. The deviation is positive when the observation falls above the mean and
</p>
<p>negative when the observation falls below the mean. The magnitude of the value
</p>
<p>reports how different (in the relevant numerical scale) an observation is from the
</p>
<p>mean.
</p>
<p>Formula deviation: Difference between the observation and the mean, Yi &ndash; Ŷ
</p>
<p>Example: Assume we have the following three numbers: 1, 2, and 6
</p>
<p>For these numbers the deviations are:
</p>
<p>1 &ndash; 3 &frac14; &ndash;2
2 &ndash; 3 &frac14; &ndash;1
6 &ndash; 3 &frac14; 3
(By definition, the sum of these deviations is 0)
</p>
<p>0
.0
</p>
<p>0
5
</p>
<p>.0
1
</p>
<p>.0
1
5
</p>
<p>.0
2
</p>
<p>D
e
</p>
<p>n
s
it
y
</p>
<p>0 50 100 150 200
</p>
<p>Money_Spent_Partying
</p>
<p>Fig. 6.25 Stata Histogram of the variable money spent partying (per week)
</p>
<p>6.9 Deviation, Variance, Standard Deviation, Standard Error, Sampling Error. . . 91</p>
<p/>
</div>
<div class="page"><p/>
<p>Sample Variance
</p>
<p>The variance is the approximate average of the squared deviations. In other words,
</p>
<p>the variance measures the approximate average of the squared distance between
</p>
<p>observations and the mean. For this measure, we use squares because the deviations
</p>
<p>can be negative, and squaring gets rid of the negative sign.
</p>
<p>Formula Sample Variance
</p>
<p>S2 &frac14;
P
</p>
<p>xi � x&eth; &THORN;2
n� 1
</p>
<p>Standard Deviation
</p>
<p>The standard deviation is a measure of volatility that measures the amount of
</p>
<p>variability or volatility around the mean. The standard deviation is large if there is
</p>
<p>high volatility in the data and low if the data is closely clustered around the mean. In
</p>
<p>other words, the smaller the standard deviation, the less &ldquo;error&rdquo; we have in our data
</p>
<p>and the more secure we can be in knowing that our sample mean closely matches our
</p>
<p>population mean.
</p>
<p>Formula Standard Deviation
</p>
<p>S &frac14;
</p>
<p>ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
</p>
<p>P
</p>
<p>N
</p>
<p>i&frac14;1
</p>
<p>�
</p>
<p>xi � �x
�2
</p>
<p>N � 1
</p>
<p>v
</p>
<p>u
</p>
<p>u
</p>
<p>u
</p>
<p>t
</p>
<p>The standard deviation is also important for standardizing variables. If the data
</p>
<p>are normally distributed (i.e., they follow a bell-shaped curve), the data have the
</p>
<p>following properties. Sixty-eight percent of the cases fall within one standard
</p>
<p>deviation, 95% of the cases fall between two standard deviations, and 99.7% cases
</p>
<p>fall between three standard deviations (see Figs. 6.26).
</p>
<p>Fig. 6.26 Standard deviation
</p>
<p>in a normal distribution
</p>
<p>92 6 Univariate Statistics</p>
<p/>
</div>
<div class="page"><p/>
<p>Standard Error
</p>
<p>The standard error allows researchers to measure how close the mean of the sample
</p>
<p>is to the population mean.
</p>
<p>Formula of the Standard Error
</p>
<p>The standard error is important, because it allows researchers to calculate the
</p>
<p>confidence interval. The confidence interval, in turn, allows researchers to make
</p>
<p>inferences from the sample mean toward the population mean. It allows researchers
</p>
<p>to calculate the population mean based on the sample mean. In other words, it gives
</p>
<p>us a range in which the real mean falls.
</p>
<p>(In reality, this method only works if we have a random sample and a normally
</p>
<p>distributed variable.)
</p>
<p>Formula of the Confidence Interval
</p>
<p>The confidence interval applied:
</p>
<p>6.9 Deviation, Variance, Standard Deviation, Standard Error, Sampling Error. . . 93</p>
<p/>
</div>
<div class="page"><p/>
<p>Surveys generally use the confidence interval to depict the accuracy of their
</p>
<p>predictions.
</p>
<p>For example, a 2006 opinion poll of 1000 randomly selected Americans aged
</p>
<p>18&ndash;24 conducted by the Roper Public Affairs Division and National Geographic
</p>
<p>finds that:
</p>
<p>&bull; Sixty-three percent of young adults ages 18&ndash;24 cannot find Iraq on a map of the
</p>
<p>Middle East.
</p>
<p>&bull; Eighty-eight percent of young adults ages 18&ndash;24 cannot find Afghanistan on a
</p>
<p>map of Asia.
</p>
<p>At the end of the survey, we find the stipulation that the results of this survey are
</p>
<p>accurate at the 95% confidence level �3% points (margin of error �3%).
This means that we are 95% confident that the true population statistic, i.e., the
</p>
<p>true percentage of American youths who cannot find Iraq on a map is somewhere in
</p>
<p>between 60 and 66. In other words, the &ldquo;real&rdquo; mean in the population is anywhere
</p>
<p>between �3% points from the mean. This error range is normally called the margin
of error or the sampling error. In the Iraqi example, we say we have a sampling
</p>
<p>error of �3% points (mean �3% points) (see Fig. 6.27).
</p>
<p>Calculating the Confidence Interval (by Hand)
</p>
<p>To give you an idea on how to construct the confidence interval by hand using the
</p>
<p>ten first values of the variable study time per week of our sample dataset (see
</p>
<p>Appendix 1).
</p>
<p>Step 1: Calculating the mean
</p>
<p>7&thorn; 8&thorn; 12&thorn; 3&thorn; 11&thorn; 14&thorn; 11&thorn; 10&thorn; 9&thorn; 8&eth; &THORN;=10 &frac14; 9:3
</p>
<p>Fig. 6.27 Graphical
</p>
<p>depiction of the confidence
</p>
<p>interval
</p>
<p>94 6 Univariate Statistics</p>
<p/>
</div>
<div class="page"><p/>
<p>Step 2: Calculating the variance
</p>
<p>7� 9:3&eth; &THORN;2 &thorn; 8� 9:3&eth; &THORN;2 &thorn; 12� 9:3&eth; &THORN;2 &thorn; 3� 9:3&eth; &THORN;2 &thorn; 11� 9:3&eth; &THORN;2 &thorn; 14� 9:3&eth; &THORN;2
</p>
<p>&thorn; 11� 9:3&eth; &THORN;2 &thorn; 10� 9:3&eth; &THORN;2 &thorn; 9� 9:3&eth; &THORN;2 &thorn; 8� 9:3&eth; &THORN;=9
&frac14; 9:34
</p>
<p>Step 3: Calculating the standard deviation
</p>
<p>ffiffiffiffiffiffiffiffiffi
</p>
<p>9:34
p
</p>
<p>&frac14; 3:06
</p>
<p>Step 4: Calculating the standard error
</p>
<p>9:34
ffiffiffiffiffi
</p>
<p>10
p
</p>
<p>� �
</p>
<p>&frac14; 2:95
</p>
<p>Step 5: Calculating the confidence interval
</p>
<p>9:3� 1:96� 9:34ffiffiffiffiffi
10
</p>
<p>p
� �
</p>
<p>&frac14; 15:09; 3:51
</p>
<p>Assuming that this sample is random and normally distributed, we would find that
</p>
<p>the real average study time of students lies between 3.5 and 15.1 h. This confidence
</p>
<p>interval is large because we have few observations and relatively widespread data.
</p>
<p>6.9.1 Calculating the Confidence Interval in SPSS
</p>
<p>With the help of SPSS, we can calculate the standard deviation and the standard
</p>
<p>error. We cannot directly calculate the confidence interval but instead use the SPSS
</p>
<p>Descriptive Statistics to calculate it by hand (i.e., we have to do the last step by
</p>
<p>hand).
</p>
<p>Step 1: Go to Analyze&mdash;Descriptive Statistics&mdash;Descriptives (see Fig. 6.28).
</p>
<p>Step 2: Once the following window appears, drag the variable study time to the right.
</p>
<p>Then, click on options. The menu, which you will see to the right, will open. On
</p>
<p>this menu, you can choose what statistics SPSS will display. Add the option
</p>
<p>6.9 Deviation, Variance, Standard Deviation, Standard Error, Sampling Error. . . 95</p>
<p/>
</div>
<div class="page"><p/>
<p>S.E. mean. (The options for Mean, Std. Deviation, Minimum, and Maximum are
</p>
<p>checked automatically). Click continue and okay (see Fig. 6.29).
</p>
<p>You will receive the following SPSS output (see Table 6.4) (please note that this
</p>
<p>output is based on data for the variable study time from the whole dataset and not
</p>
<p>only the first ten observations). The output displays the number of observations (N ),
</p>
<p>the minimum and maximum value, and the mean, accompanied by its standard error
</p>
<p>and the standard deviation. If we want to calculate the confidence interval, we have
</p>
<p>to do it by hand by using the formula introduced above.
</p>
<p>The confidence interval for the variable study time is:
</p>
<p>Calculating the upper limit: 9.38 + 1.96 � 0.489
Calculating the lower limit: 9.38 &ndash; 1.96 � 0.489
</p>
<p>Assuming that the questionnaire data (see appendix) was drawn from a random
</p>
<p>sample of students that is normally distributed, we could conclude with 95%
</p>
<p>certainty that the real mean in students&rsquo; study time would lie between 8.42 and
</p>
<p>10.34 h (see Table 6.4).
</p>
<p>6.9.2 Calculating the Confidence Interval in Stata
</p>
<p>Step 1: Write in the Stata Command field: tabstat Study_Time, stats(mean sd semean
</p>
<p>min max n) (see Fig. 6.30).
</p>
<p>(mean &frac14; mean; sd &frac14; standard deviation; semean &frac14; standard error of the mean;
min&frac14;minimum; max&frac14;maximum; max&frac14;maximum; n&frac14; number of observations)
</p>
<p>Fig. 6.28 Calculating the confidence interval in SPSS (first step)
</p>
<p>96 6 Univariate Statistics</p>
<p/>
</div>
<div class="page"><p/>
<p>The stat output provides five statistics: (1) the number of observation the
</p>
<p>calculations are based on, (2) the sample mean, (3) the standard deviation, (4) the
</p>
<p>minimum sample value, and (5) the maximum sample value. The confidence interval
</p>
<p>is not explicitly listed. If we want to calculate it, we can do so by hand (see also
</p>
<p>Table 6.5):
</p>
<p>Fig. 6.29 Calculating the confidence interval in SPSS (second step)
</p>
<p>6.9 Deviation, Variance, Standard Deviation, Standard Error, Sampling Error. . . 97</p>
<p/>
</div>
<div class="page"><p/>
<p>Calculating the upper limit: 9.38 + 1.96 � 0.489
Calculating the lower limit: 9.38 &ndash; 1.96 � 0.489
</p>
<p>Assuming that the questionnaire data (see appendix) would be drawn from a random
</p>
<p>sample of students that is normally distributed, we could conclude with 95%
</p>
<p>certainty that the real mean in students&rsquo; study time would lie between 8.42 and
</p>
<p>10.34 h.
</p>
<p>Further Reading
</p>
<p>SPSS Introductory Books
</p>
<p>Cronk, B. C. (2017). How to use SPSS&reg;: A step-by-step guide to analysis and interpretation.
</p>
<p>London: Routledge. Hands-on introduction into the statistical package SPSS designed for
</p>
<p>beginners. Shows users how to enter data and conduct some rather simple statistical tests.
</p>
<p>Green, S. B., &amp; Salkind, N. J. (2016). Using SPSS for Windows and Macintosh, Books a la Carte.
</p>
<p>Upper Saddle River: Pearson. An introduction into SPSS specifically designed for students of
</p>
<p>the social and political sciences. Guides users through basic SPSS techniques and statistics.
</p>
<p>Table 6.4 Descriptive statistics of the variable study time (SPSS output)
</p>
<p>Descriptive statistics
</p>
<p>N Minimum Maximum Mean
</p>
<p>Std.
</p>
<p>deviation
</p>
<p>Statistic Statistic Statistic Statistic
</p>
<p>Std.
</p>
<p>error Statistic
</p>
<p>Study_Time 40 3 15 9.38 0.489 3.094
</p>
<p>Valid
</p>
<p>N (listwise)
</p>
<p>40
</p>
<p>Fig. 6.30 Calculating the confidence interval in Stata
</p>
<p>Table 6.5 Descriptive statistics of the variable study time (Stata output)
</p>
<p>98 6 Univariate Statistics</p>
<p/>
</div>
<div class="page"><p/>
<p>Stata Introductory Books
</p>
<p>Mehmetoglu, M., &amp; Jakobsen, T. G. (2016). Applied statistics using Stata: A guide for the social
</p>
<p>sciences. London: Sage. A good applied textbook into regression analysis with plenty of applied
</p>
<p>examples in Stata.
</p>
<p>Pollock III, P. H. (2014). A Stata&reg; companion to political analysis. Thousand Oaks: CQ Press.
</p>
<p>Provides a step-by-step introduction into Stata. It includes plenty of supplementary material
</p>
<p>such as a sample dataset, more than 50 exercises and customized screenshots.
</p>
<p>Univariate and Descriptive Statistics
</p>
<p>Park, H. M. (2008). Univariate analysis and normality test using SAS, Stata, and SPSS. Technical
</p>
<p>working paper. The University Information Technology Services (UITS) Center for Statistical
</p>
<p>and Mathematical Computing, Indiana University. https://scholarworks.iu.edu/dspace/handle/
</p>
<p>2022/19742. A concise introduction into descriptive statistics and graphical representations of
</p>
<p>data including a discussion of their underlying statistical assumptions.
</p>
<p>Further Reading 99</p>
<p/>
<div class="annotation"><a href="https://scholarworks.iu.edu/dspace/handle/2022/19742">https://scholarworks.iu.edu/dspace/handle/2022/19742</a></div>
<div class="annotation"><a href="https://scholarworks.iu.edu/dspace/handle/2022/19742">https://scholarworks.iu.edu/dspace/handle/2022/19742</a></div>
</div>
<div class="page"><p/>
<p>Bivariate Statistics with Categorical
Variables 7
</p>
<p>Abstract
</p>
<p>In this part, we will discuss three types of bivariate statistics: first, an independent
</p>
<p>samples t-test measures if two groups of a continuous variable are different from
</p>
<p>one another; second, an f-test or ANOVA measures if several groups of one
</p>
<p>continuous variable are different from one another; third, a chi-square test gauges
</p>
<p>whether there are differences in a frequency table (i.e., two-by-two table or two-
</p>
<p>by-three table). Wherever possible we use money spent partying per week as the
</p>
<p>dependent variable. For the independent variables, we employ an appropriate
</p>
<p>explanatory variable from our sample survey.
</p>
<p>7.1 Independent Sample t-Test
</p>
<p>An independent samples t-test assesses whether the means of two groups are
</p>
<p>statistically different from each other. To properly conduct such a t-test, the follow-
</p>
<p>ing conditions should be met:
</p>
<p>(1) The dependent variable should be continuous.
</p>
<p>(2) The independent variable should consist of mutually exclusive groups (i.e., be
</p>
<p>categorical).
</p>
<p>(3) All observations should be independent, which means that there should not be
</p>
<p>any linkage between observations (i.e., there should be no direct influence from
</p>
<p>one value within one group over other values in this same group).
</p>
<p>(4) There should not be many significant outliers (this applies the more the smaller
</p>
<p>the sample is).
</p>
<p>(5) The dependent variable should be more or less normally distributed.
</p>
<p>(6) The variances between groups should be similar.
</p>
<p># Springer International Publishing AG 2019
</p>
<p>D. Stockemer, Quantitative Methods for the Social Sciences,
</p>
<p>https://doi.org/10.1007/978-3-319-99118-4_7
</p>
<p>101</p>
<p/>
<div class="annotation"><a href="http://crossmark.crossref.org/dialog/?doi=10.1007/978-3-319-99118-4_7&amp;domain=pdf">http://crossmark.crossref.org/dialog/?doi=10.1007/978-3-319-99118-4_7&amp;domain=pdf</a></div>
</div>
<div class="page"><p/>
<p>For example, for our data we might be interested whether guys spend more
</p>
<p>money than girls while partying, and therefore our dependent variable would be
</p>
<p>money spent partying (per week) and our independent variable gender. We have
</p>
<p>relative independence of observations as we cannot assume that the money one
</p>
<p>individual in the sample spends partying directly hinges upon the money another
</p>
<p>individual in the sample spends partying. From Figs. 6.23 and 6.25, we also know
</p>
<p>that the variable money spent partying per week is approximately normally
</p>
<p>distributed. As a preliminary test, we must check if the variance between the two
</p>
<p>distributions is equal, but a SPSS or Stata test can later help us detect that.
</p>
<p>Having verified that our data fit the conditions for a t-test, we can now get into the
</p>
<p>mechanics of conducting such a test. Intuitively, we could first compare the means
</p>
<p>for the two groups. In other words, we should look at how far the two means are apart
</p>
<p>from each other. Second, we ought to look at the variability of the data. Pertaining to
</p>
<p>the variability, we can follow a simple rule; the less there is variability, the less there
</p>
<p>is overlap in the data, and the more the two groups are distinct. Therefore, to
</p>
<p>determine whether there is a difference between two groups, two conditions must
</p>
<p>be met: (1) the two group means must differ quite considerably, and (2) the spread of
</p>
<p>the two distributions must be relatively low. More precisely, we have to judge the
</p>
<p>difference between the two means relative to the spread or variability of their scores
</p>
<p>(see Fig. 7.1). The t-test does just this.
</p>
<p>Figure 7.2 graphically illustrates that it is not enough that two group means are
</p>
<p>different from one another. Rather, it is also important how close the values of the
</p>
<p>two groups cluster around a mean. In the last of the three graphs, we can see that the
</p>
<p>two groups are distinct (i.e., there is basically no data overlap between the two
</p>
<p>groups). In the middle graph, we can be rather sure that these two groups are similar
</p>
<p>(i.e., more than 80% of the data points are indistinguishable; they could belong to
</p>
<p>either of the two groups). Looking at the first graph, we see that most of the
</p>
<p>observations clearly belong to one of the two groups but that there is also some
</p>
<p>overlap. In this case, we would not be sure that the two groups are different.
</p>
<p>control
</p>
<p>group
</p>
<p>mean
</p>
<p>treatment
</p>
<p>group
</p>
<p>mean
</p>
<p>Fig. 7.1 The logic of a t-test
</p>
<p>102 7 Bivariate Statistics with Categorical Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>Statistical Analysis of the t-Test
</p>
<p>The difference between the means is the signal, and the bottom part of the formula is
</p>
<p>the noise, or a measure of variability; the smaller there are differences in the signal
</p>
<p>and the larger the variability, the harder it is to see the group differences. The logic of
</p>
<p>a t-test can be summarized as follows (see Fig. 7.3):
</p>
<p>The top part of the formula is easy to compute&mdash;just find the difference between
</p>
<p>the means. The bottom is a bit more complex; it is called the standard error of the
</p>
<p>difference. To compute it, we have to take the variance for each group and divide it
</p>
<p>by the number of people in that group. We add these two values and then take their
</p>
<p>square root. The specific formula is as follows:
</p>
<p>SE
�
</p>
<p>�XT � �XC
�
</p>
<p>&frac14;
</p>
<p>ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
</p>
<p>VarT
</p>
<p>nT
&thorn;
VarC
</p>
<p>nC
</p>
<p>r
</p>
<p>The final formula for the t-test is the following:
</p>
<p>signal difference between group means
</p>
<p>variability of groupsnoise
</p>
<p>t-value
</p>
<p>=
</p>
<p>=
</p>
<p>=
</p>
<p>XT
</p>
<p>SE(XT -  XC)
</p>
<p>XC-
_ _
</p>
<p>_ _
</p>
<p>Fig. 7.3 Formula/logic of a t-
</p>
<p>test
</p>
<p>medium
</p>
<p>variability
</p>
<p>high
</p>
<p>variability
</p>
<p>low
</p>
<p>variability
</p>
<p>Fig. 7.2 The question of
</p>
<p>variability in a t-test
</p>
<p>7.1 Independent Sample t-Test 103</p>
<p/>
</div>
<div class="page"><p/>
<p>t &frac14;
�XT � �XC
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
</p>
<p>VarT
nT
</p>
<p>&thorn; VarC
nC
</p>
<p>q
</p>
<p>The t-value will be positive if the first mean is larger than the second one and
</p>
<p>negative if it is smaller. However, for our analysis this does not matter. What matters
</p>
<p>more is the size of the t-value. Intuitively, we can say that the larger the t-value the
</p>
<p>higher the chance that two groups are statistically different. A high T-value is
</p>
<p>triggered by a considerable difference between the two group means and low
</p>
<p>variability of the data around the two group means. To statistically determine
</p>
<p>whether the t-value is large enough to conclude that the two groups are statistically
</p>
<p>different, we need to use a test of significance. A test of significance sets the amount
</p>
<p>of error, called the alpha level, which we allow our statistical calculation to have. In
</p>
<p>most social research, the &ldquo;rule of thumb&rdquo; is to set the alpha level at 0.05. This means
</p>
<p>that we allow 5% error. In other words, we want to be 95% certain that a given
</p>
<p>relationship exists. This implies that, if we were to take 100 samples from the same
</p>
<p>population, we could get a significant T-value in 95 out of 100 cases.
</p>
<p>As you can see from the formula, doing a t-test by hand can be rather complex.
</p>
<p>Therefore, we have SPSS or Stata to do the work for us.
</p>
<p>7.1.1 Doing an Independent Samples t-Test in SPSS
</p>
<p>Step 1: Pre-test&mdash;Create a histogram to detect whether the dependent variable&mdash;
</p>
<p>money spent partying&mdash;is normally distributed (see Sect. 6.8). Despite the outlier
</p>
<p>(200 $/month), the data is approximately normally distributed, and we can
</p>
<p>proceed with the independent samples t-test (see Fig. 7.4).
</p>
<p>Step 2: Go to Analyze&mdash;Compare Means&mdash;Independent Samples T-Test (see
</p>
<p>Fig. 7.5).
</p>
<p>Step 2: Put your continuous variable as test variable and your dichotomous variable
</p>
<p>as grouping variable. In the example that follows, we use our dependent vari-
</p>
<p>able&mdash;money spent partying from our sample dataset&mdash;as the test variable. As the
</p>
<p>grouping variable, we use the only dichotomous variable in our dataset&mdash;gender.
</p>
<p>After dragging over gender to the grouping field, click on Define Groups and
</p>
<p>label the grouping variable 1 and 0. Click okay (see Fig. 7.6).
</p>
<p>Step 3: Verifying the equal variance assumption&mdash;before we conduct and interpret
</p>
<p>the t-test, we have to verify whether the assumption of equal variance is met.
</p>
<p>Columns 1 and 2 in Table 7.1 display the Levene test for equal variances, which
</p>
<p>measures whether the variances or spread of the data is similar between the two
</p>
<p>groups (in our case between guys and girls). If the f-value is not significant (i.e.,
</p>
<p>the significance level in the second column is larger than 0.05), we do not violate
</p>
<p>the assumption of equal variances. In this case, it does not matter whether we
</p>
<p>interpret the upper or the lower row of the output table. However, in our case the
</p>
<p>significance value in the second column is below 0.05 ( p &frac14; 0.018). This implies
that the assumption of equal variances is violated. Yet, this is not dramatic for
</p>
<p>104 7 Bivariate Statistics with Categorical Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>interpreting the output, as SPSS offers us an adapted t-test, which relaxes the
</p>
<p>assumption of equal variances. This implies that, in order to interpret the t-test, we
</p>
<p>have to use the second row (i.e., the row labeled equal variances not assumed). In
</p>
<p>our case, it is the outlier that skews the variance, in particular in the girls&rsquo; group.
</p>
<p>Fig. 7.5 Independent samples t-test in SPSS (second step)
</p>
<p>Mean = 76.50
Std. Dev. = 30.153
</p>
<p>N = 40
</p>
<p>20
</p>
<p>15
</p>
<p>10
</p>
<p>5
</p>
<p>0
</p>
<p>Money_Spent_Partying
</p>
<p>F
re
</p>
<p>q
u
</p>
<p>e
n
</p>
<p>c
y
</p>
<p>.00 50.00 100.00 150.00 200.00 250.00
</p>
<p>Fig. 7.4 Histogram of the variable money spent partying
</p>
<p>7.1 Independent Sample t-Test 105</p>
<p/>
</div>
<div class="page"><p/>
<p>7.1.2 Interpreting an Independent Samples t-Test SPSS Output
</p>
<p>Having tested the data for normality and equal variances, we can now interpret the t-
</p>
<p>test. The t-test output provided by SPSS has two components (see Table 7.1): one
</p>
<p>summary table and one independent samples t-test table. The summary table gives us
</p>
<p>Table 7.1 SPSS output of an independent samples t-test
</p>
<p>The significance level determines the alpha 
</p>
<p>level. In our case, the alpha level is superior 
</p>
<p>to 0.05. Hence, we would conclude that the 
</p>
<p>two groups are not different enough to 
</p>
<p>conclude with 95% certainty that there is a 
</p>
<p>difference
</p>
<p>Fig. 7.6 Independent samples t-test in SPSS (third step)
</p>
<p>106 7 Bivariate Statistics with Categorical Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>the mean amount of money that girls and guys spent partying. We find that girls
</p>
<p>(who were coded 1) spend slightly more money when they go out and party
</p>
<p>compared to guys (which we coded 0). Yet, the difference is rather moderate. On
</p>
<p>average, girls merely spend 6 dollars more per week than guys. If we further look at
</p>
<p>the standard deviation, we see that it is rather large, especially for group 1 featuring
</p>
<p>girls. Yet, this large standard deviation is expected and at least partially triggered by
</p>
<p>the outlier. Based on these observations, we can take the educated guess that there is,
</p>
<p>in fact, no significant difference between the two groups. In order to confirm or
</p>
<p>disprove this conjecture, we have to look at the second output in Table 7.1, in
</p>
<p>particular the fifth column of the second table (which is the most important field to
</p>
<p>interpret a t-test). It displays the significance or alpha level of the independent
</p>
<p>samples t-test. Assuming that we take the 0.05 benchmark, we cannot reject the
</p>
<p>null hypothesis with 95% certainty. Hence, we can conclude that there is no statisti-
</p>
<p>cally significant difference between the two groups.
</p>
<p>7.1.3 Reading an SPSS Independent Samples t-Test Output Column
by Column
</p>
<p>Column 3 displays the actual t-value. (Large t-values normally trigger a difference
</p>
<p>in the two groups, whereas small t-values indicate that the two groups are
</p>
<p>similar.)
</p>
<p>Column 4 displays what is called degrees of freedom (df) in statistical language. The
</p>
<p>degrees of freedom are important for the determination of the significance level in
</p>
<p>the statistical calculation. For interpretation purposes, they are less important. In
</p>
<p>short, the df are the number of observations that are free to vary. In our case, we
</p>
<p>have a sample of 40 and we have 2 groups, girls and guys. In order to conduct a t-
</p>
<p>test, we must have at least one girl and one guy in our sample, these two
</p>
<p>parameters are fixed. The remaining 38 people can then be either guys or girls.
</p>
<p>This means that we have 2 fixed parameters and 38 free-flying parameters or df.
</p>
<p>Column 5 displays the significance or alpha level. The significance or alpha level is
</p>
<p>the most important sample statistic in our interpretation of the t-test; it gives us a
</p>
<p>level certainty about our relationship. We normally use the 95% certainty level in
</p>
<p>our interpretation of statistics. Hence, we allow 5% error (i.e., a significance level
</p>
<p>of 0.05). In our example, the significance level is 0.103, which is higher than 0.05.
</p>
<p>Therefore, we cannot reject the null hypothesis and hence cannot be sure that girls
</p>
<p>spend more than guys.
</p>
<p>Column 6 displays the difference in means between the two groups (i.e., in our
</p>
<p>example this is the difference in the average amount spent partying between girls
</p>
<p>and guys, which is 5.86). The difference in means is also the numerator of the t-
</p>
<p>test formula.
</p>
<p>Column 7 displays the denominator of the t-test, which is the standard error of the
</p>
<p>difference of the two groups. If we divide the value in column 6 by the value in
</p>
<p>column 7, we get the t-statistic (i.e., 5.86/9.27 &frac14; 0.632).
</p>
<p>7.1 Independent Sample t-Test 107</p>
<p/>
</div>
<div class="page"><p/>
<p>Column 8 This final split column gives the confidence interval of the difference
</p>
<p>between the two groups. Assuming that this sample was randomly taken, we
</p>
<p>could be confident that the real difference between girls and guys lies between
</p>
<p>&ndash;0.321 and 3.554. Again, these two values confirm that we cannot reject the null
</p>
<p>hypothesis, because the value 0 is part of the confidence interval.
</p>
<p>7.1.4 Doing an Independent Samples t-Test in Stata
</p>
<p>Step 1: Pre-test&mdash;Histogram to detect whether the dependent variable&mdash;money spent
</p>
<p>partying per week&mdash;is normally distributed. Despite the outlier (200 $/month),
</p>
<p>the data is approximately normally distributed, and we can proceed with the
</p>
<p>independent samples t-test (Fig. 7.7).
</p>
<p>Step 2: Pre-test&mdash;Checking for equal variances&mdash;write into the Stata Command
</p>
<p>field: robvar Money_Spent_Partying, by(Gender) (see Fig. 7.8)&mdash;this command
</p>
<p>will conduct a Levene test of equal variances; if this test turns out to be signifi-
</p>
<p>cant, then the null hypothesis of equal variances must be rejected (to interpret the
</p>
<p>0
.0
</p>
<p>0
5
</p>
<p>.0
1
</p>
<p>.0
1
5
</p>
<p>.0
2
</p>
<p>D
e
</p>
<p>n
s
it
y
</p>
<p>0 50 100 150 200
</p>
<p>Money_Spent_Partying
</p>
<p>Fig. 7.7 Stata histogram of the variable money spent partying
</p>
<p>Fig. 7.8 Levene test of equal variances
</p>
<p>108 7 Bivariate Statistics with Categorical Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>Levene test, use the test labeled WO). This is the case in our example (see
</p>
<p>Table 7.2). The significance level (PR &gt; F &frac14; 0.018) is below the bar of 0.05.
Step 3: Doing a t-test in in Stata&mdash;type into the Stata Command field: &ldquo;ttest
</p>
<p>Money_Spent_Partying, by(Gender) unequal&rdquo; (see Fig. 7.9). (Note: if the Levene
</p>
<p>test for equal variances does not come out significant, you do not need to add
</p>
<p>equal at the end of the command.)
</p>
<p>7.1.5 Interpreting an Independent Samples t-Test Stata Output
</p>
<p>Having tested the data for normality and equal variances, we can now interpret the t-
</p>
<p>test. The t-test output provided by Stata has six columns (see Table 7.3):
</p>
<p>Column 1 labels the two groups (in our case group 0 &frac14; guys and group 1 &frac14; girls).
Column 2 gives the number of observations. In our case, we have 19 guys and
</p>
<p>21 girls.
</p>
<p>Column 3 displays the mean spending value for the two groups. We find that girls
</p>
<p>spend slightly more money when they go out and party compared to guys. Yet,
</p>
<p>the difference is rather moderate. On average, girls merely spend roughly 6 dollars
</p>
<p>more per week than guys.
</p>
<p>Columns 4 and 5 show the standard error and standard deviation, respectively. If we
</p>
<p>look at both measures, we see that they are rather large, especially for group
</p>
<p>1 featuring girls. Yet, this large standard deviation is expected and at least
</p>
<p>Table 7.2 Stata Levene test of equal variances
</p>
<p>Fig. 7.9 Doing a t-test in Stata
</p>
<p>7.1 Independent Sample t-Test 109</p>
<p/>
</div>
<div class="page"><p/>
<p>partially triggered by the outlier. (Based on these two observations&mdash;the two
</p>
<p>means are relatively close each other and the standard deviation/standard errors
</p>
<p>are comparatively large&mdash;we can take the educated guess that there is no signifi-
</p>
<p>cant difference in the spending patterns of guys and girls when they party.)
</p>
<p>Column 6 presents the 95% confidence interval. It highlights that if these data were
</p>
<p>randomly drawn from a sample of college students, the real mean would fall
</p>
<p>between 65.88 dollars per week and 80.96 dollars per week for guys (allowing a
</p>
<p>certainty level of 95%). For girls, the corresponding confidence interval would be
</p>
<p>between 61.45 dollars per week and 97.12 dollars per week. Because there is
</p>
<p>some large overlap between the two confidence intervals, we can already con-
</p>
<p>clude that the two groups are not statistically different from zero.
</p>
<p>In order to statistically determine via the appropriate test statistic whether the two
</p>
<p>groups are different, we have to look at the significance level associated with the t-
</p>
<p>Table 7.3 Stata independent samples t-test output
</p>
<p>The signi�icance level determines 
</p>
<p>the alpha level. In our case, the 
</p>
<p>alpha level is superior to .05. 
</p>
<p>Hence, we would conclude that the 
</p>
<p>two groups are not different 
</p>
<p>enough to conclude with 95 
</p>
<p>percent certainty that there is a 
</p>
<p>difference
</p>
<p>110 7 Bivariate Statistics with Categorical Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>test (see arrow below). The significance level is 0.53, which is above the 0.05
</p>
<p>benchmark. Consequently, we cannot reject the null hypothesis with 95% certainty
</p>
<p>and can conclude that that there is no statistically significant difference between the
</p>
<p>two groups.
</p>
<p>7.1.6 Reporting the Results of an Independent Samples t-Test
</p>
<p>In Sect. 4.12 we hypothesized that guys like the bar scene more than girls do and are
</p>
<p>therefore going to spend more money when they go out and party. The independent
</p>
<p>samples t-test disconfirms this hypothesis. On average, it is actually girls who spend
</p>
<p>slightly more than guys do. However, the difference in average spending (73 dollars
</p>
<p>for guys and 79 dollars for girls) is not statistically different from zero ( p &frac14; 0.53).
Hence, we cannot reject the null hypothesis and can conclude that the spending
</p>
<p>pattern for partying is similar for the two genders.
</p>
<p>7.2 F-Test or One-Way ANOVA
</p>
<p>T-tests work great with dummy variables, but sometimes we have categorical
</p>
<p>variables with more than two categories. In cases where we have a continuous
</p>
<p>variable paired with an ordinal or nominal variable with more than two categories,
</p>
<p>we use what is called an f-test or one-way ANOVA. The logic behind an f-test is
</p>
<p>similar to the logic for a t-test. To highlight, if we compare the two graphs in
</p>
<p>Fig. 7.10, we would probably conclude that the three groups in the second graph
</p>
<p>are different, while the three groups in the first graph are rather similar (i.e., in the
</p>
<p>first graph, there is a lot of overlap, whereas in the second graph, there is no overlap,
</p>
<p>which entails that each value can only be attributed to one distribution).
</p>
<p>Fig. 7.10 What makes
</p>
<p>groups different?
</p>
<p>7.2 F-Test or One-Way ANOVA 111</p>
<p/>
</div>
<div class="page"><p/>
<p>While the logic of an f-test reflects the logic of a t-test, the calculation of several
</p>
<p>group means and several measures of variability around the group means becomes
</p>
<p>more complex in an f-test. To reduce this complexity, an ANOVA test uses a simple
</p>
<p>method to determine whether there is a difference between several groups. It splits
</p>
<p>the total variance into two groups: between variance and within variance. The
</p>
<p>between variance measures the variation between groups, whereas the within vari-
</p>
<p>ance measures the variation within groups. Whenever the between variation is
</p>
<p>considerably larger than the within variation, we can say that there are differences
</p>
<p>within groups. The following example highlights this logic (see Table 7.4).
</p>
<p>Let us assume that Table 7.4 depicts two hypothetical samples, which measure
</p>
<p>the approval ratings of Chancellor Merkel based on social class. In the survey, an
</p>
<p>approval score of 0 means that respondents are not at all satisfied with her perfor-
</p>
<p>mance as chancellor. In contrast, 100 signifies that individuals are very satisfied with
</p>
<p>her performance as chancellor. The first sample consists of young people (i.e.,
</p>
<p>18&ndash;25) and the second sample of old people (65 and older). Both samples are split
</p>
<p>into three categories&mdash;high, medium, and low. High stands for higher or upper
</p>
<p>classes, med stands for medium or middle classes, and low stands for the lower or
</p>
<p>working classes. We can see that the mean satisfaction ratings for Chancellor Merkel
</p>
<p>per social strata do not differ between the two samples; that is, the higher classes, on
</p>
<p>average, rate her at 52, the middle classes at 42, and the lower classes at 32.
</p>
<p>However, what differs tremendously between the two samples is the variability of
</p>
<p>the data. In the first sample, the values are very closely clustered around the mean
</p>
<p>throughout each of the three categories. We can see that there is much more
</p>
<p>variability between groups than between observations within one group. Hence,
</p>
<p>we would conclude that the groups are different. In contrast, in sample 2, there is
</p>
<p>large within-group variation. That is, the values within each group differ much more
</p>
<p>than the corresponding values between groups. Therefore, we would predict for
</p>
<p>sample 2 that the three groups are probably not that different, despite the fact that
</p>
<p>their means are different. Following this logic, the formula for an ANOVA analysis
</p>
<p>or f-test is between-group variance/within-group variance. Since it is too difficult
</p>
<p>to calculate the between- and within-group variance by hand, we let statistical
</p>
<p>computer programs do it for us.
</p>
<p>Table 7.4 Within and between variation (as in other occassions, make sure to put
</p>
<p>the table heading and then the table)
</p>
<p>112 7 Bivariate Statistics with Categorical Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>A standard f-test or ANOVA analysis illustrates if there are differences between
</p>
<p>groups or group means, but it does not show which specific group means are
</p>
<p>different from one another. Yet, in most cases researchers want to know not only
</p>
<p>that there are some differences but also between which groups the differences lie.
</p>
<p>So-called multiple comparison tests&mdash;basically t-tests between the different
</p>
<p>groups&mdash;compare all means against one another and help us detect where the
</p>
<p>differences lie.
</p>
<p>7.2.1 Doing an f-Test in SPSS
</p>
<p>For our f-test we use the variable money spent partying per week as the dependent
</p>
<p>variable and the categorical variable times partying per week as the factor or
</p>
<p>grouping variable. Given that we only have 40 observations and given that there
</p>
<p>should be at least several observations per category to yield valid test results, we will
</p>
<p>reduce the six categories to three. In more detail, we cluster together no partying and
</p>
<p>partying once, partying twice and three times, and partying four times and five times
</p>
<p>and more together. We can create this new variable by hand, or we can also have
</p>
<p>SPSS do it for us. We will label this variable times partying 1.
</p>
<p>Step 1: Creating the variable times partying 1&mdash;go to Transform&mdash;Recode into
</p>
<p>Different Variable (see Fig. 7.11).
</p>
<p>Step 2: Drag the variable Times_Partying into the middle field&mdash;name the Output
</p>
<p>Variable Times_Partying_1&mdash;click on Change&mdash;click on Old and New Values
</p>
<p>(see Fig. 7.12).
</p>
<p>Step 3: Include in the Range field the value range that will be clustered together&mdash;
</p>
<p>add the new value in the field labeled New Value&mdash;click Add&mdash;do this for the all
</p>
<p>three ranges&mdash;once your dialog field looks like the dialog field below click
</p>
<p>Continue. You will be redirected to the initial screen; click okay and then the
</p>
<p>new variable will be added to the SPSS dataset (see Fig. 7.13).
</p>
<p>Fig. 7.11 Recoding the variable times partying 1 (first step)
</p>
<p>7.2 F-Test or One-Way ANOVA 113</p>
<p/>
</div>
<div class="page"><p/>
<p>Step 4: For doing the actual f-test&mdash;go to Analyze&mdash;Compare Means&mdash;One-Way
</p>
<p>ANOVA (see Fig. 7.14).
</p>
<p>Step 5: Put your continuous variable (money spent partying) as Dependent Variable
</p>
<p>and your ordinal variable (times spent partying 1) as Factor. Click okay (see
</p>
<p>Fig. 7.15).
</p>
<p>Fig. 7.13 Recoding the variable Times Partying 1 (third step)
</p>
<p>Fig. 7.12 Recoding the variable Times Partying 1 (second step)
</p>
<p>114 7 Bivariate Statistics with Categorical Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>7.2.2 Interpreting an SPSS ANOVA Output
</p>
<p>The SPSS ANOVA output contains five columns (see Table 7.5). Similar to a t-test,
</p>
<p>the most important column is the significance level (i.e., Sig). It tells us whether there
</p>
<p>is a difference between at least two out of the however many groups we have. In our
</p>
<p>example, the significance level is 0.000, which means that we can tell with nearly
</p>
<p>100% certainty that at least two groups differ in the money they spent partying per
</p>
<p>week. Yet, the SPSS ANOVA output does not tell us which groups are different; the
</p>
<p>only thing it tells us is that at least two groups are different from one another.
</p>
<p>In more detail, the different columns are interpreted as follows:
</p>
<p>Column 1 displays the sum of squares or the squared deviations for the different
</p>
<p>variance components (i.e., between-group variance, within-group variance, and
</p>
<p>total variance).
</p>
<p>Fig. 7.15 Doing an f-test in SPSS (second step)
</p>
<p>Fig. 7.14 Doing an f-test in SPSS (first step)
</p>
<p>7.2 F-Test or One-Way ANOVA 115</p>
<p/>
</div>
<div class="page"><p/>
<p>Column 2 displays the degrees of freedom, which allows us to calculate the within
</p>
<p>and between variance. The formula for these degrees of freedom is number of
</p>
<p>groups (k) &ndash; 1 for the between-group estimator and the number of observations
</p>
<p>(N ) &ndash; k for within group.
</p>
<p>Column 3 shows the between and within variance or sum of squares. According to
</p>
<p>the f-test formula, we need to divide the between variance by the within variance
</p>
<p>(F &frac14; 6242.50/620.95 &frac14; 10.053).
Column 4 displays the f-value. The larger the f-value, the more likely it is that at
</p>
<p>least two groups are statistically different from one another.
</p>
<p>Column 5 gives us an alpha level or level of certainty indicating a probability level
</p>
<p>that there is a difference between at least two groups. In our case, the significance
</p>
<p>level is 0.000 indicating that we can be nearly be 100% certain that at least two
</p>
<p>groups differ in, how much money the spent partying per week.
</p>
<p>7.2.3 Doing a Post hoc or Multiple Comparison Test in SPSS
</p>
<p>The violation of the equal variance assumption (i.e., the distributions around the
</p>
<p>group means are different for the various groups in the sample) is rather unproblem-
</p>
<p>atic for interpreting a one-way ANOVA analysis (Park 2009). Yet, having an equal
</p>
<p>or unequal variability around the group means is important when doing multiple
</p>
<p>pairwise comparison tests between means. This assumption needs to be tested before
</p>
<p>we can do the test:
</p>
<p>Step 1: Testing the equal variance assumption&mdash;go to the One-Way ANOVA Screen
</p>
<p>(see step 5 in Sect. 7.2.1)&mdash;click on Options&mdash;a new screen with options opens&mdash;
</p>
<p>click on Homogeneity of Variance Test (see Fig. 7.16).
</p>
<p>Step 2: Press Continue&mdash;you will be redirected to the previous screen&mdash;press Okay
</p>
<p>(see Fig. 7.17).
</p>
<p>The equality of means test provides a significant result (Sig&frac14; 0.024) indicating
that the variation around the three group means in our sample is not equal. We
</p>
<p>have to take this inequality of variance in the three distributions into consideration
</p>
<p>when conducting the multiple comparison test (see Table 7.6).
</p>
<p>Table 7.5 SPSS ANOVA output
</p>
<p>116 7 Bivariate Statistics with Categorical Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>Step 3: Conducting the multiple comparison test&mdash;go to the One-Way ANOVA
</p>
<p>Command window (see Step 2)&mdash;click on the button Post Hoc and choose any of
</p>
<p>the four options under the label Equal Variances Not Assumed. Please note if
</p>
<p>your equality of variances test did not yield a statistically significant result (i.e. the
</p>
<p>sig value is not smaller than 0.05) you should choose any of the options under the
</p>
<p>label Equal Variances Assumed) (see Fig. 7.18).
</p>
<p>Fig. 7.17 Doing a post hoc multiple comparison test in SPSS (second step)
</p>
<p>Fig. 7.16 Doing a post hoc multiple comparison test in SPSS (first step)
</p>
<p>7.2 F-Test or One-Way ANOVA 117</p>
<p/>
</div>
<div class="page"><p/>
<p>The post hoc multiple comparison test (see Table 7.7) allows us to decipher which
</p>
<p>groups are actually statistically different from one another. From the SPSS output,
</p>
<p>we see that individuals who either do not go out not at all or go out once per week
</p>
<p>(group 0) spend less than individuals who go out four times or more (group 2). The
</p>
<p>average mean difference is 43 dollars per week, this difference is statistically
</p>
<p>different from zero ( p &frac14; 0.032). We also see from the SPSS output that individuals
who go out and party two or three times (group 1) spend significantly less than
</p>
<p>individuals who party four or more times (group 2). In absolute terms, they are
</p>
<p>predicted to spend 39.5 dollars less per week. This difference is statistically different
</p>
<p>from zero ( p &frac14; 0.041). In contrast, there is no statistical difference in the spending
</p>
<p>Table 7.6 Robust test of equality of means
</p>
<p>Fig. 7.18 Doing a post hoc multiple comparison test in SPSS (third step)
</p>
<p>118 7 Bivariate Statistics with Categorical Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>patterns between groups 0 and 1. In absolute terms, there is a mere 3.5 dollars
</p>
<p>difference between the two groups. This difference is not statistically different from
</p>
<p>zero ( p &frac14; 0.955).
</p>
<p>7.2.4 Doing an f-Test in Stata
</p>
<p>For our f-test we use money spent partying per week as the dependent variable, and
</p>
<p>as the independent variable, we use the categorical variable times partying per week.
</p>
<p>Given that we only have 40 observations and given that there should be at least
</p>
<p>several observations per category to yield valid test results, we reduce the six
</p>
<p>categories to three. In more detail, we cluster together no partying and partying
</p>
<p>once, partying twice and three times, and partying four times and five times or more.
</p>
<p>We can create this new variable by hand, or we can also have Stata do it for us. We
</p>
<p>will label this variable times partying 1.
</p>
<p>Preliminary Procedure: Creating the variable times partying 1
</p>
<p>Write in the Stata Command editor:
</p>
<p>(1) generate Times_Partying_1 &frac14; 0
(this creates the variable and assigns the value of 0 to all observations) (see
</p>
<p>Fig. 7.19)
</p>
<p>(2) replace Times_Partying_1 &frac14; 1 if(Times_Partying � 2) and Times_Partying � 3
(this assigns the value of 1 to all individuals in groups 2 and 3 for the variable
</p>
<p>times partying) (see Fig. 7.20).
</p>
<p>(3) replace Times_Partying_1 &frac14; 2 if(Times_Partying � 4) (see Fig. 7.21)
(this assigns the value of 2 to all individuals in groups 4 and 5).
</p>
<p>Table 7.7 SPSS output of a post hoc multiple comparison test
</p>
<p>7.2 F-Test or One-Way ANOVA 119</p>
<p/>
</div>
<div class="page"><p/>
<p>Main analysis: conducting the ANOVA
</p>
<p>Write in the Stata Command editor: oneway Money_Spent_Partying
</p>
<p>Times_Partying_1, tabulate (see Fig. 7.22).
</p>
<p>7.2.5 Interpreting an f-Test in Stata
</p>
<p>In the first part of the table, Stata provides summary statistics of the three group
</p>
<p>means (Table 7.8). The output reports that individuals who go out partying once a
</p>
<p>week or less spend on average 64 dollars per week. Those who party two to three
</p>
<p>times per week merely spend 3.5 dollars more than the first group. In contrast,
</p>
<p>individuals in the third group of students, who party four or more times, spend
</p>
<p>approximately 107 dollars per week partying. We also see that the standard
</p>
<p>deviations are quite large, especially for the third group&mdash;students that party four
</p>
<p>or more times per week. These descriptive statistics also give us a hint that there is
</p>
<p>probably a statistically significant difference between the third group and the two
</p>
<p>other groups. The f-test (Prob &gt; F &frac14; 0.0003) further reveals that there are in fact
differences between groups. However, the f-test does not allow us to detect where the
</p>
<p>differences lie. In order to gauge this, we have to conduct a multiple comparison test.
</p>
<p>However, before doing so we have to gauge whether the variances of the three
</p>
<p>Fig. 7.19 Generating the variable Times_Partying 1 (first step)
</p>
<p>Fig. 7.20 Generating the variable Times_Partying 1 (second step)
</p>
<p>Fig. 7.21 Generating the variable Times_Partying 1 (third step)
</p>
<p>Fig. 7.22 Doing an ANOVA analysis in Stata
</p>
<p>120 7 Bivariate Statistics with Categorical Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>groups are equal or if they are dissimilar. The Bartlett&rsquo;s test for equal variance, which
</p>
<p>is listed below the ANOVA output, gives us this information. If the test statistic
</p>
<p>provides a statistically significant value, then we have to reject the null hypothesis of
</p>
<p>equal variances and accept the alternative hypothesis that the variances between
</p>
<p>groups are unequal. In our case, the Bartlett&rsquo;s test displays a statistically significant
</p>
<p>value (prob &gt; chi2 &frac14; 0.001). Hence, we have to proceed with a post-stratification
test with unequal variance.
</p>
<p>7.2.6 Doing a Post hoc or Multiple Comparison Test with Unequal
Variance in Stata
</p>
<p>Since the Bartlett&rsquo;s test indicates some violation of the equal variance assumption
</p>
<p>(i.e., the distributions around the group means are different for the various groups in
</p>
<p>the sample), we have to conduct a multiple comparison test in which the unequal
</p>
<p>variance assumption is relaxed. A Stata module to compute pairwise multiple
</p>
<p>comparisons with unequal variances exists, but is not included by default and must
</p>
<p>be downloaded. To do the test we have follow a multistep procedure:
</p>
<p>Step 1: Write in the Command field: search pwmc (see Fig. 7.23).
</p>
<p>This brings us to a Stata page with several links&mdash;click on the first link and click on
</p>
<p>&ldquo;(Click here to install)&rdquo; to download the program (Once, downloaded, the
</p>
<p>program is installed and does not need to be downloaded again) (see Fig. 7.24).
</p>
<p>Step 2: Write into the Command field: pwmc Money_Spent_Partying, over
</p>
<p>(Times_Partying_1) (Fig. 7.25).
</p>
<p>Table 7.8 Stata ANOVA output this table is misplaced here put below the text in 7.2.5
</p>
<p>7.2 F-Test or One-Way ANOVA 121</p>
<p/>
</div>
<div class="page"><p/>
<p>Stata actually provides test results of three different multiple comparison tests, all
</p>
<p>using some slightly different algebra (see Table 7.9). Regardless of the test, what we
</p>
<p>can see is that, substantively, the results of the three tests do not differ. These tests
</p>
<p>are also slightly more difficult to interpret because they do not display any signifi-
</p>
<p>cance level. Rather, we have to interpret the confidence interval to determine
</p>
<p>whether two means are statistically different from zero. We find that there is no
</p>
<p>statistically significant difference between groups 0 and 1. For example, if we look at
</p>
<p>the first of the three tests, we find that the confidence interval includes positive and
</p>
<p>negative values; it ranges from &ndash;16.90 to 23.90. Hence, we cannot accept the
</p>
<p>alternative hypothesis that groups 0 and 1 are different from one another. In contrast,
</p>
<p>we can conclude that groups 0 and 2, as well as 1 and 2, are statistically different
</p>
<p>from one another, respectively, because both confidence intervals include only
</p>
<p>positive values (i.e., the confidence interval for the difference between groups
</p>
<p>0 and 2 ranges from 2.38 to 83.62 and the confidence interval for the difference
</p>
<p>between groups 1 and 2 ranges from 2.54 to 76.46).
</p>
<p>Please also note that in case the Bartlett&rsquo;s test of equal variance (see Table 6.3)
</p>
<p>does not display any significance, a multiple comparison test assuming equal
</p>
<p>variance can be used. Stata has many options; the most prominent ones are probably
</p>
<p>the algorithms by Scheffe and Sidak. For presentation purposes, let us assume that
</p>
<p>the Bartlett test was not significant in Table 6.3.
</p>
<p>In such a case, we would type into the Stata Command field:
</p>
<p>Fig. 7.23 Downloading a post hoc or multiple comparison test with unequal variance
</p>
<p>Fig. 7.24 Download page for the post hoc multiple comparison test
</p>
<p>Fig. 7.25 Doing a post hoc or multiple comparison test with unequal variance in Stata
</p>
<p>122 7 Bivariate Statistics with Categorical Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>oneway Money_Spent_Partying Times_Partying_1, sidak (see Fig. 7.26).
</p>
<p>To determine whether there is a significant difference between groups, we would
</p>
<p>interpret the two-by-two table (see the second part of Table 7.10). The table
</p>
<p>highlights that the mean difference between group 0 and group 1 is 3.5 dollars, a
</p>
<p>value that is not statistically different from 0 (Sig&frac14; 0.978). In contrast the difference
in spending between group 0 and group 2, which is 43 dollars, is statistically
</p>
<p>significant (sig &frac14; 0.001). The same applies to the difference in spending (39.5
dollars) between groups 1 and 2 (sig &frac14; 0.001).
</p>
<p>Fig. 7.26 Multiple comparison test according to Sidak
</p>
<p>Table 7.9 Stata output of post hoc multiple comparison test
</p>
<p>7.2 F-Test or One-Way ANOVA 123</p>
<p/>
</div>
<div class="page"><p/>
<p>7.2.7 Reporting the Results of an f-Test
</p>
<p>In Sect. 4.12, we hypothesized that individuals who party more frequently will spend
</p>
<p>more money for their weekly partying habits than individuals that party less fre-
</p>
<p>quently. Creating three groups of party goers&mdash;(1) students, who party once or less,
</p>
<p>on average, (2) students who party between two and three times, and (3) students
</p>
<p>who party more than four times&mdash;we find some support for our hypothesis; that is, a
</p>
<p>general f-test confirms (Sig&frac14; 0.0003) that there are differences between groups. Yet,
the f-test cannot tell us between which groups the differences lie. In order to find this
</p>
<p>out, we must compute a post hoc multiple comparison test. We do so assuming
</p>
<p>unequal variances between the three distributions, because a Bartlett&rsquo;s test of equal
</p>
<p>variance (sig &frac14; 0.001) reveals that the null hypothesis (get rid of the plural, I cannot
delete the word hypotheses) hypotheses of equal variances must be rejected. Our
</p>
<p>results indicate that the mean spending average statistically significantly differs
</p>
<p>between groups 0 and 2 [i.e., the average difference in party spending is 43 dollars
</p>
<p>(sig &frac14; 0.032)]. The same applies to the difference between groups 1 and 2 [i.e., the
average difference in party spending is 39.5 dollars (Sig&frac14; 0.041)]. In contrast, there
is no difference in spending between those who party once or less and those who
</p>
<p>party two or three times (sig 0.955).
</p>
<p>Table 7.10 Multiple comparison test with equal variance in Stata
</p>
<p>124 7 Bivariate Statistics with Categorical Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>7.3 Cross-tabulation Table and Chi-Square Test
</p>
<p>7.3.1 Cross-tabulation Table
</p>
<p>So far, we have discussed bivariate tests that work with a categorical variable as the
</p>
<p>independent variable and a continuous variable as the dependent variable (i.e., an
</p>
<p>independent samples t-test if the independent variable is binary and the dependent
</p>
<p>variable continuous and an ANOVA or f-test if the independent variable has more
</p>
<p>than two categories). What happens if both the independent and dependent variables
</p>
<p>are binary? In this case, we can present the data in a crosstab.
</p>
<p>Table 7.11 provides an example of a two-by-two table. The table presents the
</p>
<p>results of a lab experiment with mice. A researcher has 105 mice with a severe
</p>
<p>illness; she treats 50 mice with a new drug and does not treat 55 mice at all. She
</p>
<p>wants to know whether this new drug can cure animals. To do so she creates four
</p>
<p>categories: (1) treated and dead, (2) treated and alive, (3) not treated and dead, and
</p>
<p>(4) not treated and alive.
</p>
<p>Based on this two-by-two table, we can ask the question: How many of the dead
</p>
<p>are either treated or not treated? To answer this question, we have to use the column
</p>
<p>as unit of analysis and calculate the percentage of dead, which are treated and the
</p>
<p>percentage of dead, which are not treated. To do so, we have to convert the column
</p>
<p>raw numbers into percentages. To calculate these percentages for the first field, we
</p>
<p>take the number in the field&mdash;treated/dead&mdash;and divide it by the column total
</p>
<p>(36/66 &frac14; 55.55%). We do analogously for the other fields (see Table 7.12).
Interpreting Table 6.7, we can find, for example, that roughly 56% of the dead
</p>
<p>mice have been treated, but only 35.9% of those alive have undergone treatment.
</p>
<p>Instead of asking the question how many of the dead mice have been treated, we
</p>
<p>might change the question and ask how many of the dead have been treated or alive?
</p>
<p>To get at this information, we first calculate the percentage of dead mice with
</p>
<p>treatment and of alive mice with treatment. We do analogously for the dead that
</p>
<p>are not treated and the alive that are not treated. Doing so, we find that of all treated,
</p>
<p>72% are dead and only 28% are alive. In contrast, the not treated mice have a higher
</p>
<p>chance of survival. Only 55.55% have died and 44.45% have survived (see
</p>
<p>Table 7.13).
</p>
<p>Table 7.11 Two-by-two table measuring the relationship between drug treatment and the survival
of animals
</p>
<p>Dead Alive
</p>
<p>Treated 36 14
</p>
<p>Not treated 30 25
</p>
<p>Total 66 39
</p>
<p>7.3 Cross-tabulation Table and Chi-Square Test 125</p>
<p/>
</div>
<div class="page"><p/>
<p>7.3.2 Chi-Square Test
</p>
<p>Having interpreted the crosstabs a researcher might ask whether there is a relation-
</p>
<p>ship between drug treatment and the survival of mice. To answer this research
</p>
<p>question, she might postulate the following hypothesis:
</p>
<p>H0: The survival of the animals is independent of drug treatment.
</p>
<p>Ha: The survival of the animals is higher with drug treatment.
</p>
<p>In order to determine if there is a relationship between drug treatment and the
</p>
<p>survival of mice, we use what is called a chi-square test. To apply this test, we
</p>
<p>compare the actual value in each field with a random distribution of values between
</p>
<p>the four fields. In other words, we compare the real value in each field with an
</p>
<p>expected value, calculated so that the chance that a mouse falls in each of the four
</p>
<p>fields is the same.
</p>
<p>To calculate this expected value, we use the following formula:
</p>
<p>RowTotal� ColumnTotal
</p>
<p>Table Total
</p>
<p>Table 7.14 displays the observed and the expected values for the four possible
</p>
<p>categories: (1) treated and dead, (2) treated and alive, (3) not-treated and dead, and
</p>
<p>Table 7.14 Calculating
</p>
<p>the expected values
Dead Alive Total
</p>
<p>Treated 36 (31.4) 14 (18.6) 50
</p>
<p>Not treated 30 (34.6) 25 (20.4) 55
</p>
<p>Total 66 39 105
</p>
<p>Table 7.12 Two-by-two
</p>
<p>table focusing on the
</p>
<p>interpretation of the
</p>
<p>columns
</p>
<p>Dead Alive
</p>
<p>Treated 36 14
</p>
<p>Percent 55.55 35.90
</p>
<p>Not treated 30 25
</p>
<p>Percent 44.45 64.10
</p>
<p>Total 66 39
</p>
<p>Percent 100 100
</p>
<p>Table 7.13 Two-by-two
table focusing on the
</p>
<p>interpretation of the rows
</p>
<p>Dead Alive Total
</p>
<p>Treated 36 14 50
</p>
<p>Percent 72.00 28.00 100
</p>
<p>Not treated 30 25 55
</p>
<p>Total 55.55 44.45 100
</p>
<p>126 7 Bivariate Statistics with Categorical Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>(4) not-treated and alive. The logic behind a chi-square test is that the larger the gap
</p>
<p>between one or several observed and expected values, the higher the chance that
</p>
<p>there actually is a pattern or relationship in the data (i.e., that treatment has an
</p>
<p>influence on survival).
</p>
<p>The formula for a chi-square test is:
</p>
<p>X2 &frac14;
Observed� Expected&eth; &THORN;2
</p>
<p>Expected
</p>
<p>In more detail the four steps to calculate a chi-square value are the following:
</p>
<p>(1) For each observed value in the table, subtract the corresponding expected value
</p>
<p>(O&ndash;E).
</p>
<p>(2) Square the difference (O&ndash;E)2.
</p>
<p>(3) Divide the squares obtained for each cell in the table by the expected number for
</p>
<p>that cell
</p>
<p>(O&ndash;E)2/E.
</p>
<p>(4) Sum all the values for (O&ndash;E)2/E. This is the chi-square statistic.
</p>
<p>Our treated animal example gives us a chi-square value of 3.418. This value is not
</p>
<p>high enough to reject the null hypothesis of a no effect between treatment and
</p>
<p>survival. Please note that in earlier times, researchers compared their chi-square
</p>
<p>test value with a critical value, a value that marked the 5% alpha level (i.e., a 95%
</p>
<p>degree of certainty). If their test value fell below this critical value, then the
</p>
<p>researcher could conclude that there is no difference between the groups, and if it
</p>
<p>was above, then the researcher could conclude that there is a pattern in the data. In
</p>
<p>modern times, statistical outputs display the significance level associated with a
</p>
<p>chi-square value right away, thus allowing the researcher to determine right away if
</p>
<p>there is a relationship between the two categorical variables.
</p>
<p>A chi-square test works with the following limitations:
</p>
<p>&ndash; No expected cell count can be less than 5.
</p>
<p>&ndash; Larger samples are more likely to trigger statistically significant results.
</p>
<p>&ndash; The test only identifies that a difference exists, not necessarily where it exists.
</p>
<p>(If we want to decipher where the differences are, we have look at the data and
</p>
<p>detect in what cells are the largest differences between observed and expected
</p>
<p>values. These differences are the drivers of a high chi-square value.)
</p>
<p>7.3.3 Doing a Chi-Square Test in SPSS
</p>
<p>The dependent variable of our study, which we used for the previous tests (i.e., t-test
</p>
<p>and f-test)&mdash;money spent partying&mdash;is continuous, and we cannot use it for our chi-
</p>
<p>square test. We have to use two categorical variables and make sure that there are
</p>
<p>7.3 Cross-tabulation Table and Chi-Square Test 127</p>
<p/>
</div>
<div class="page"><p/>
<p>least five observations in each cell. The two categorical variables we choose are
</p>
<p>gender and times partying per week. Since, we have only 40 observations, we further
</p>
<p>contract the variable times partying and create 2 categories: (1) partying a lot (three
</p>
<p>times or more a week) and partying moderately (less than 3 times a week). We name
</p>
<p>this new variable times partying 2. To create this new variable, see Sect. 7.1.2.
</p>
<p>Step 1: Go to Analyze&mdash;Descriptive Statistics&mdash;Crosstabs (see Fig. 7.27).
</p>
<p>Step 2: Put Gender in the Row(s) field and Times Partying 2 in the Columns field.
</p>
<p>Click on statistics (see Fig. 7.28).
</p>
<p>Step 3: In the Crosstabs: Statistics field, check the box Chi-square&mdash;click continue&mdash;
</p>
<p>you will be redirected to the previous box&mdash;click okay (see Fig. 7.29).
</p>
<p>7.3.4 Interpreting an SPSS Chi-Square Test
</p>
<p>An SPSS chi-square test output consists of two parts: a cross-tabulation table and the
</p>
<p>actual chi-square test (see Table 7.15). The crosstab indicates that the sample
</p>
<p>consists of 21 guys and 19 girls. Within the 2 genders, partying habits are quite
</p>
<p>equally distributed; 9 guys party 2 times or less per week, and 12 guys party 3 times
</p>
<p>or more. For girls, the numbers are rather similar&mdash;ten girls party twice or less per
</p>
<p>week, on average, and nine girls three times or more. We already see from the
</p>
<p>chi-square table that there is hardly any difference between guys and girls. The
</p>
<p>Pearson chi-square test (i.e., first row of the chi-square test table) confirms this
</p>
<p>observation. The chi-square value is 0.382 and the corresponding significance level
</p>
<p>is 0.536, which is far above the benchmark of 0.05. Based on these test-statistics, we
</p>
<p>cannot reject the null hypothesis; this implies that we can conclude that the partying
</p>
<p>habits of guys and girls (in terms of the times per week both genders party) do not
</p>
<p>differ.
</p>
<p>Fig. 7.27 Doing crosstabs in SPSS (first step)
</p>
<p>128 7 Bivariate Statistics with Categorical Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>Fig. 7.28 Doing crosstabs in SPSS (second step)
</p>
<p>Fig. 7.29 Doing crosstabs in SPSS (third step)
</p>
<p>7.3 Cross-tabulation Table and Chi-Square Test 129</p>
<p/>
</div>
<div class="page"><p/>
<p>7.3.5 Doing a Chi-Square Test in Stata
</p>
<p>To do a chi-square test, we cannot use the dependent variable of our study&mdash;money
</p>
<p>spent partying&mdash;because it is continuous. For a chi-square test to function, we have
</p>
<p>to use two categorical variables and make sure that there are at least five observations
</p>
<p>in each cell. The two categorical variables we choose are gender and times partying
</p>
<p>per week. Since we have only 40 observations, we further collapse the variable times
</p>
<p>partying and create 2 categories: (1) partying a lot (3 times or more a week) and
</p>
<p>(2) partying moderately (less than 3 times a week). We name this new variable times
</p>
<p>partying 2. To create this new variable, see Sect. 8.1.3.
</p>
<p>Step 1: Write into the Stata Command field: tab Gender Times_Partying_2 (see
</p>
<p>Fig. 7.30)
</p>
<p>(the order in which we write our two categorical variables does not matter).
</p>
<p>Fig. 7.30 Doing a chi-square
</p>
<p>test in Stata
</p>
<p>Table 7.15 SPSS chi-square test output
</p>
<p>130 7 Bivariate Statistics with Categorical Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>The Stata test output in Table 7.16 consists of a cross-tabulation table and the
</p>
<p>actual chi-square test below. The crosstab indicates that the sample consists of
</p>
<p>21 guys and 19 girls. Within the 2 genders, partying habits are quite equally
</p>
<p>distributed; 9 guys party 2 times or less per week, and 12 guys party 3 times or
</p>
<p>more. For girls, the numbers are rather similar: ten girls party twice or less per week,
</p>
<p>on average, and nine girls three times or more. We already see from the chi-square
</p>
<p>table that there is hardly any difference between guys and girls. The Pearson
</p>
<p>chi-square test result below the cross-table confirms this observation. The
</p>
<p>chi-square value is 0.382, and the corresponding significance level is 0.536, which
</p>
<p>is far above the benchmark of 0.05. Based on these test statistics, we can conclude
</p>
<p>that the partying habits of guys and girls (in terms of the times per week both genders
</p>
<p>party) do not differ.
</p>
<p>7.3.6 Reporting a Chi-Square Test Result
</p>
<p>Using a chi-square test, we have tried to detect if there is a relationship between
</p>
<p>gender and the times per week students party. We find that in absolute terms roughly
</p>
<p>about half the girls and guys, respectively, either party two times or less or three
</p>
<p>times or more. The chi-square test confirms that there is no statistically significant
</p>
<p>difference in the number of times either of two genders goes out to party (i.e., the
</p>
<p>chi-square value is 0.38 and the corresponding significance level is 0.534).
</p>
<p>Reference
</p>
<p>Park, H. (2009). Comparing group means: T-tests and one-way ANOVA using Stata, SAS, R, and
</p>
<p>SPSS. Working paper, The University Information Technology Services (UITS), Center for
</p>
<p>Statistical and Mathematical Computing, Indiana University.
</p>
<p>Table 7.16 Stata chi-square output
</p>
<p>Reference 131</p>
<p/>
</div>
<div class="page"><p/>
<p>Further Reading
</p>
<p>Statistics Textbooks
</p>
<p>Basically every introductory to statistics book covers bivariate statistics between categorical and
</p>
<p>continuous variables. The books I list here are just a short selection of possible textbooks. I have
</p>
<p>chosen these books because they are accessible and approachable and they do not use math
</p>
<p>excessively.
</p>
<p>Brians, C. L. (2016). Empirical political analysis: Pearson new international edition coursesmart
</p>
<p>etextbook. London: Routledge (chapter 11). Provides a concise introduction into different types
</p>
<p>of means testing.
</p>
<p>Macfie, B. P., &amp; Nufrio, P. M. (2017). Applied statistics for public policy. New York: Routledge.
</p>
<p>This practical text provides students with the statistical tools needed to analyze data. It also
</p>
<p>shows through several examples how statistics can be used as a tool in making informed,
</p>
<p>intelligent policy decisions (part 2).
</p>
<p>Walsh, A., &amp; Ollenburger, J. C. (2001). Essential statistics for the social and behavioral sciences: A
</p>
<p>conceptual approach. Upper Saddle River: Prentice Hall (chapters 7&ndash;11). These chapters
</p>
<p>explain in rather simple forms the logic behind different types of statistical tests between
</p>
<p>categorical variables and provide real life examples.
</p>
<p>Presenting Results in Publications
</p>
<p>Morgan, S., Reichert, T., &amp; Harrison, T. R. (2016). From numbers to words: Reporting statistical
</p>
<p>results for the social sciences. London: Routledge. This book complements introductory to
</p>
<p>statistics books. It shows scholars how they can present their test results in either visual or text
</p>
<p>form in an article or scholarly book
</p>
<p>132 7 Bivariate Statistics with Categorical Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>Bivariate Relationships Featuring Two
Continuous Variables 8
</p>
<p>Abstract
</p>
<p>In this chapter, we discuss bivariate relationships between two continuous
</p>
<p>variables. In research, these are the relationships that occur the most often. We
</p>
<p>can express bivariate relationships between continuous variables in three ways:
</p>
<p>(1) through a graphical representation in the form of a scatterplot, (2) through a
</p>
<p>correlation analysis, and (3) through a bivariate regression analysis. We describe
</p>
<p>and explain each method and show how to implement it in SPSS and Stata.
</p>
<p>8.1 What Is a Bivariate Relationship Between Two Continuous
Variables?
</p>
<p>A bivariate relationship involving two continuous variables can be displayed
</p>
<p>graphically and through a correlation or regression analysis. Such a relationship
</p>
<p>can exist if there is a general tendency for these two variables to be related, even if it
</p>
<p>is not a completely determined rule. In statistical terms, we say that these two
</p>
<p>variables &ldquo;vary together&rdquo;; this means that values of the variable x (the independent
</p>
<p>variable) tend to occur more often with some values of the variable y (the dependent
</p>
<p>variable) than with other values of the variable y.
</p>
<p>8.1.1 Positive and Negative Relationships
</p>
<p>When we describe relationships between variables, we normally distinguish between
</p>
<p>positive and negative relationships.
</p>
<p>Positive relationship High, or above average, values of x tend to occur with high, or
</p>
<p>above average, values of y. Also, low values of x tend to occur with low values of y.
</p>
<p># Springer International Publishing AG 2019
</p>
<p>D. Stockemer, Quantitative Methods for the Social Sciences,
</p>
<p>https://doi.org/10.1007/978-3-319-99118-4_8
</p>
<p>133</p>
<p/>
<div class="annotation"><a href="http://crossmark.crossref.org/dialog/?doi=10.1007/978-3-319-99118-4_8&amp;domain=pdf">http://crossmark.crossref.org/dialog/?doi=10.1007/978-3-319-99118-4_8&amp;domain=pdf</a></div>
</div>
<div class="page"><p/>
<p>Examples:
</p>
<p>&bull; Income and education
</p>
<p>&bull; National wealth and degree of democracy
</p>
<p>&bull; Height and weight
</p>
<p>Negative relationship High, or above average, values of x tend to occur with low, or
</p>
<p>below average, values of y. Also, low values of x tend to occur with high values of y.
</p>
<p>Examples:
</p>
<p>&bull; State social spending and income inequality
</p>
<p>&bull; Exposure to Fox News and support for Democrats
</p>
<p>&bull; Smoking and life expectancy
</p>
<p>8.2 Scatterplots
</p>
<p>A scatterplot graphically describes a quantitative relationship between two continu-
</p>
<p>ous variables: Each dot (point) is one individual observation&rsquo;s value on x and y. The
</p>
<p>values of the independent variable (X) appear in sequence on the horizontal or x-axis.
</p>
<p>The values of the dependent variable (Y ) appear on the vertical or y-axis. For a
</p>
<p>positive association, the points tend to move diagonally from lower left to upper
</p>
<p>right. For a negative association, the points tend to move from upper left to lower
</p>
<p>right. For NO association, points are scattered with no discernable diagonal line.
</p>
<p>8.2.1 Positive Relationships Displayed in a Scatterplot
</p>
<p>Figure 8.1 displays a positive association, or a positive relationship, between
</p>
<p>countries&rsquo; per capita GDP and the amount of energy they consume. We see that
</p>
<p>even if the data do not exactly follow a line, there is nevertheless a tendency that
</p>
<p>countries with higher GDP per capita values are associated with more energy usage.
</p>
<p>In other words, higher values of the x-axis (the independent variable) correspond to
</p>
<p>higher values on the y-axis (the dependent variable).
</p>
<p>8.2.2 Negative Relationships Displayed in a Scatterplot
</p>
<p>Figure 8.2 displays a negative relationship between per capita GDP, and the share
</p>
<p>agriculture makes up of a country&rsquo;s GDP; that is, our results indicate that the richer a
</p>
<p>country becomes, the more agriculture loses its importance for the economy. In
</p>
<p>statistical terms, we find that low values of the x-axis correspond to high values on
</p>
<p>the y-axis and high values on the x-axis correspond to low values on the y-axis.
</p>
<p>134 8 Bivariate Relationships Featuring Two Continuous Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>8.2.3 No Relationship Displayed in a Scatterplot
</p>
<p>Figure 8.3 displays an instance in which the independent and dependent variable are
</p>
<p>unrelated to one another. In more detail, the graph highlights that the affluence of a
</p>
<p>country is unrelated to its size. In other words, there is no discernable direction to the
</p>
<p>points in the scatterplot.
</p>
<p>Fig. 8.2 Bivariate relationship between national wealth and agriculture
</p>
<p>Fig. 8.1 Bivariate relationship between the GDP per capita and energy spending
</p>
<p>8.2 Scatterplots 135</p>
<p/>
</div>
<div class="page"><p/>
<p>8.3 Drawing the Line in a Scatterplot
</p>
<p>The line we draw in a scatterplot is called the ordinary least square line (OLS line). In
</p>
<p>theory, we can draw a multitude of lines, but in practice we want to find the best
</p>
<p>fitting line to the data. The best fitting line is the line where the summed up distance
</p>
<p>of the points from below the line is equal to the summed up distance of the points
</p>
<p>from above the line. Figure 8.4 clearly shows a line that does not fit the data properly.
</p>
<p>The distance of all the points toward the line is much larger for the points below the
</p>
<p>line in comparison to the points above the line. In contrast, the distance of the points
</p>
<p>toward the line is the same for the points above the line as for the points below the
</p>
<p>line in Fig. 8.4. In contrast, the line in Fig. 8.5 is the best fitting line (i.e. the sum of
</p>
<p>the distance of all the points from the line is zero).
</p>
<p>8.4 Doing Scatterplots in SPSS
</p>
<p>For our scatterplot, we will use money spent partying as the dependent variable. For
</p>
<p>the independent variable, we will use quality of extra-curricular activities,
</p>
<p>hypothesizing that students who enjoy the university-sponsored activities will
</p>
<p>spend less money partying. Rather than going out and party, they will be in sports
</p>
<p>and social or political university clubs and partake in their activities. A scatterplot
</p>
<p>can help us confirm or disconfirm this hypothesis.
</p>
<p>Step 1: Go to Graphs&mdash;Legacy Dialogs&mdash;Scatter/Dot (see Fig. 8.6).
</p>
<p>Fig. 8.3 Relationship between a country&rsquo;s GDP per capita and its size
</p>
<p>136 8 Bivariate Relationships Featuring Two Continuous Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>Step 2: Then you see the box below&mdash;click on Simple Scatter and Define (see
</p>
<p>Fig. 8.7).
</p>
<p>Step 3: Put the dependent variable (i.e., money spent partying) on the y-axis and the
</p>
<p>independent variable (quality of extra-curricular activities) on the x-axis. Click
</p>
<p>okay (see Fig. 8.8).
</p>
<p>Step 4: After the completion of the steps explained in step 3, the scatterplot will
</p>
<p>show up. However, it would be nice to add a line, which can give us a more robust
</p>
<p>estimate of the relationship between the two variables. In order to include the line,
</p>
<p>double-click on the scatterplot in the output window. The chart builder below will
</p>
<p>appear. Then, just click on the line icon on the second row (the middle icon), and
</p>
<p>the scatterplot with the line will appear (see Fig. 8.9).
</p>
<p>Fig. 8.5 An example of the best fitted line
</p>
<p>Fig. 8.4 An example of a line that fits the data poorly
</p>
<p>8.4 Doing Scatterplots in SPSS 137</p>
<p/>
</div>
<div class="page"><p/>
<p>As expected, Fig. 8.9 displays a negative relationship between the quality of extra-
</p>
<p>curricular activities and the money students spent partying. The graph displays that
</p>
<p>students who think that the extra-curricular activities offered by the university are
</p>
<p>poor do in fact spend more money per week partying. In contrast, students who like
</p>
<p>the sports and social and political clubs at their university are less likely to spend a
</p>
<p>lot of money partying. Because we can see that the line is relatively steep, we can
</p>
<p>already detect that the relationship is relatively strong; a bivariate regression analysis
</p>
<p>(see below) will give us some information about the strength of this relationship.
</p>
<p>Fig. 8.7 Doing a scatterplot in SPSS (second step)
</p>
<p>Fig. 8.6 Doing a scatterplot in SPSS (first step)
</p>
<p>138 8 Bivariate Relationships Featuring Two Continuous Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>8.5 Doing Scatterplots in Stata
</p>
<p>For our scatterplot, we will use money spent partying as the dependent variable.
</p>
<p>For the independent variable, we will use quality of extra-curricular activities,
</p>
<p>hypothesizing that students who enjoy the university-sponsored free time activities
</p>
<p>will spend less money partying. Rather than going out and party, they will be
</p>
<p>involved in sports or social and political university clubs and partake in their
</p>
<p>activities. A scatterplot can help us confirm or disconfirm this hypothesis.
</p>
<p>Fig. 8.8 Doing a scatterplot in SPSS (third step)
</p>
<p>8.5 Doing Scatterplots in Stata 139</p>
<p/>
</div>
<div class="page"><p/>
<p>Step 1: Type in the command editor:
</p>
<p>graph twoway (scatter Money_Spent_Partying Quality_Extra_Curricular_Activ)
</p>
<p>(lfit Money_Spent_Partying Quality_Extra_Curricular_Activ)1 (see Fig. 8.10).
</p>
<p>Figure 8.11 displays a negative slope, that is, the graph displays that students
</p>
<p>who think that the extra-curricular activities offered by the university are poor do
</p>
<p>in fact spend more money partying. In contrast, students who like the sports,
</p>
<p>social, and political clubs at their university are less likely to spend a lot of money
</p>
<p>partying. Because we can see that the line is relatively steep, we can already
</p>
<p>detect that the relationship is relatively strong; a bivariate regression analysis (see
</p>
<p>below) will give us some information about the strength of this relationship.
</p>
<p>y=1.15E2-0.84*x
</p>
<p>R
2 
Linear = 0.361
</p>
<p>200.00
</p>
<p>150.00
</p>
<p>100.00
</p>
<p>50.00
</p>
<p>.00
</p>
<p>Quality_Extra_Curricular_Activities
</p>
<p>M
o
</p>
<p>n
e
y
_
S
</p>
<p>p
e
n
</p>
<p>t_
P
</p>
<p>a
rt
</p>
<p>y
in
</p>
<p>g
</p>
<p>.00 20.00 40.00 60.00 80.00 100.00
</p>
<p>Fig. 8.9 SPSS scatterplot between the quality of extra-curricular activities and money spent
partying per week
</p>
<p>Fig. 8.10 Doing a scatterplot in Stata
</p>
<p>1In the dataset, you might want to write Atktiv because writing out activities makes the word too
</p>
<p>long to fit into the data field in Stata.
</p>
<p>140 8 Bivariate Relationships Featuring Two Continuous Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>Step 2: Stata allows us to include the confidence interval around the fitted line:
</p>
<p>graph twoway (scatter Money_Spent_Partying Quality_Extra_Curricular_Activ)
</p>
<p>(lfitci Money_Spent_Partying Quality_Extra_Curricular_Activ) (see Fig. 8.12).
</p>
<p>Assuming that our sample was randomly picked from a population of univer-
</p>
<p>sity students, the confidence interval in Fig. 8.13 depicts the range around the
</p>
<p>fitted line in which the real relationship falls. In other words, the population line
</p>
<p>displaying the relationship between the independent and dependent variable
</p>
<p>should be anywhere in the gray shaded area.
</p>
<p>0
5
0
</p>
<p>1
0
</p>
<p>0
1
5
</p>
<p>0
2
0
</p>
<p>0
</p>
<p>0 20 40 60 80 100
</p>
<p>Quality_Extra_Curricular_Activities
</p>
<p>Money_Spent_Partying Fitted values
</p>
<p>Fig. 8.11 Stata scatterplot between the quality of extra-curricular activities and the money spent
</p>
<p>partying
</p>
<p>Fig. 8.12 Doing a scatterplot with confidence interval in Stata
</p>
<p>8.5 Doing Scatterplots in Stata 141</p>
<p/>
</div>
<div class="page"><p/>
<p>8.6 Correlation Analysis
</p>
<p>A correlation analysis is closely linked to the analysis of scatterplots. In order to do a
</p>
<p>correlation analysis, the relationship between independent and dependent variable
</p>
<p>must be linear. In other words, we must be able to use a line to express the
</p>
<p>relationship between the independent variable x and the dependent variable y. To
</p>
<p>interpret a scatterplot, two things are important: (1) the direction of the line (i.e., a
</p>
<p>relationship can only exist if the fitted line is either positive or negative) and (2) the
</p>
<p>closeness of the points toward the line (i.e., the closer the points are clustered around
</p>
<p>the line, the stronger the correlation is). In fact, in a correlation analysis, it is solely
</p>
<p>the second point, the closeness of the points to the line that helps us determine the
</p>
<p>strength of the relationship. To highlight, if we move from graph 1 to graph 4 in
</p>
<p>Fig. 8.14, we can see that the points get closer to the line for each of the fourth
</p>
<p>graphs. Hence, the correlation between the two variables becomes stronger.
</p>
<p>In statistical terms, the correlation coefficient, also called Pearson correlation
</p>
<p>coefficient, is denoted by r. It expresses both the strength and direction of a
</p>
<p>relationship between two variables in a single number. If the dots line up to exactly
</p>
<p>one line, we have a perfect correlation or a correlation coefficient of 1. In contrast,
</p>
<p>the more all over the place the dots are, the more the correlation coefficient
</p>
<p>approaches 0 (see Fig. 8.3). In terms of direction, a correlation coefficient with a
</p>
<p>positive sign depicts a positive correlation, whereas a correlation coefficient with a
</p>
<p>negative sign depicts a negative correlation.
</p>
<p>0
5
0
</p>
<p>1
0
</p>
<p>0
1
5
</p>
<p>0
2
0
</p>
<p>0
</p>
<p>0 20 40 60 80 100
</p>
<p>Quality_Extra_Curricular_Activities
</p>
<p>Money_Spent_Partying 95% CI
</p>
<p>Fitted values
</p>
<p>Fig. 8.13 Stata scatterplot between the quality of extra-curricular activities and the money spent
</p>
<p>partying with the confidence interval
</p>
<p>142 8 Bivariate Relationships Featuring Two Continuous Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>Formula for r:
</p>
<p>r &frac14;
1
</p>
<p>n� 1
</p>
<p>X
</p>
<p>n
</p>
<p>i&frac14;1
</p>
<p>xi � �x
</p>
<p>Sx
</p>
<p>� �
</p>
<p>yi � �y
</p>
<p>Sy
</p>
<p>� �
</p>
<p>Properties of r:
</p>
<p>&ndash; &ndash;1 &lt; r &lt; 1.
</p>
<p>&ndash; r &gt; 0 means a positive relationship&mdash;the stronger the relationship, the closer r is
</p>
<p>to 1.
</p>
<p>&ndash; r &lt; 0 means a negative relationship&mdash;the stronger the relationship, the closer r is
</p>
<p>to &ndash;1.
</p>
<p>&ndash; r &frac14; 0 means no relationship.
</p>
<p>Benchmarks for establishing the level of correlation:
</p>
<p>(&ndash;) 0.3 &lt; r &lt; (&ndash;) 0.45 &frac14; weak correlation
</p>
<p>(&ndash;) 0.45 &lt; r &lt; (&ndash;) 0.6 &frac14; medium strong correlation
</p>
<p>r &lt; (&ndash;) 0.6 &frac14; strong correlation
</p>
<p>R, like the mean and the standard deviation, is sensitive to outliers. For example,
</p>
<p>Fig. 8.15 displays nearly identical scatterplots, with the sole difference being that we
</p>
<p>add an outlier to graph 2. Adding this outlier decreases the correlation coefficient by
</p>
<p>0.2 points. Given that the line is drawn so that the sum of the points below the line
</p>
<p>and the sum of the points above the line equal 0, an outlier pushes the line in one
</p>
<p>direction (in our case downward), thus increasing the distance of each point toward
</p>
<p>the line, which, in turn, decreases the strength of the correlation.
</p>
<p>Fig. 8.14 Assessing the strength of relationships in correlation analysis
</p>
<p>8.6 Correlation Analysis 143</p>
<p/>
</div>
<div class="page"><p/>
<p>There are two important caveats with correlation analysis. First, since a correla-
</p>
<p>tion analysis defines strength at how close the points in a scatterplot are toward a
</p>
<p>line, it does not provide us with any indication of the strength in impact, in the
</p>
<p>substantial sense, of a relationship of an independent on a dependent variable.
</p>
<p>Second, a correlation analysis depicts only whether two variables are related and
</p>
<p>how closely they follow a positive or a negative direction. It does not give us any
</p>
<p>indication which variable is the cause and which is the effect.
</p>
<p>8.6.1 Doing a Correlation Analysis in SPSS
</p>
<p>Step 1: Go to Analyze&mdash;Correlate&mdash;Bivariate (see Fig. 8.16).
</p>
<p>Fig. 8.15 R with and without an outlier
</p>
<p>Fig. 8.16 Doing a correlation in SPSS (first step)
</p>
<p>144 8 Bivariate Relationships Featuring Two Continuous Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>Step 2: Choose the continuous variables you want to correlate and click okay (see
</p>
<p>Fig. 8.17).
</p>
<p>It is important to note the correlation analysis only functions with continuous
</p>
<p>variables. We have five continuous variables in our data and will include them all
</p>
<p>in the correlation matrix. These five variables are (1) money spent partying, (2) qual-
</p>
<p>ity of extra-curricular activities, (3) the amount of tuition students pay themselves,
</p>
<p>(4) whether or not students can have fun without alcohol when they go out, and
</p>
<p>(5) their study time per week.
</p>
<p>8.6.2 Interpreting an SPSS Correlation Output
</p>
<p>The correlation output in Table 8.1 displays the bivariate correlations between the
</p>
<p>five continuous variables in our dataset. To determine whether two variables are
</p>
<p>correlated, we first look at the significance or alpha level for each correlation. If we
</p>
<p>find that sig &gt;0.05, we can conclude that the two variables are not correlated. In this
</p>
<p>case, we do not interpret the correlation coefficient, which should be small anyways.
</p>
<p>If we find a significant p-value (sig, �0.05), we can go on and interpret the strength
</p>
<p>of the correlation using the benchmarks provided in Sect. 8.6. To highlight, let us
</p>
<p>Fig. 8.17 Doing a correlation in SPSS (second step)
</p>
<p>8.6 Correlation Analysis 145</p>
<p/>
</div>
<div class="page"><p/>
<p>look at the correlation between the amount of tuition students pay and the amount of
</p>
<p>time students generally dedicate to their studies per week; we find that there is no
</p>
<p>correlation between these two variables. The significance or alpha level (denoted p in
</p>
<p>statistical language) is 0.228, which is much higher than the benchmark of 0.05.
</p>
<p>Hence, we would conclude from there that there is no relationship between these two
</p>
<p>variables. In other words, we would stop our interpretation here, and we would not
</p>
<p>interpret the correlation coefficient, because it is not statistically significant. In
</p>
<p>contrast, if we look at the relationship between the variable money spent partying
</p>
<p>and the variable quality of extra-curricular activities, we find that the significance
</p>
<p>level is 0.000. This means that we can be nearly 100% sure that there is a correlation
</p>
<p>between the two variables. Having established that a correlation exists, we can now
</p>
<p>look at the sign and the magnitude of the coefficient. We find that the sign is
</p>
<p>negative, indicating that the more money students spend while going out, the less
</p>
<p>they participate in extra-curricular activities in their university. Knowing that there is
</p>
<p>a negative correlation, we can now interpret the magnitude of the correlation
</p>
<p>coefficient, which is &ndash;0.600, indicating that we have medium strong to strong
</p>
<p>negative correlation. In addition to the correlation between the quality of extra-
</p>
<p>curricular activities and money spent partying, there is one more statistically signifi-
</p>
<p>cant and substantively strong correlation, namely, between students&rsquo; study time per
</p>
<p>week and whether or not they can have fun partying without alcohol. This correlation
</p>
<p>is significant at the 0.000 level and substantively strong (i.e., r &frac14; &ndash;0.777). The
</p>
<p>negative sign further highlights that it is negative indicating that high values for one
</p>
<p>variable trigger low values for the other variables. In this case, this implies that
</p>
<p>students that study a lot also think that they can have a lot of fun without alcohol
</p>
<p>when they party.
</p>
<p>Table 8.1 SPSS correlation output
</p>
<p>146 8 Bivariate Relationships Featuring Two Continuous Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>8.6.3 Doing a Correlation Analysis in Stata
</p>
<p>It is important to note that correlation analyses only function with continuous
</p>
<p>variables. We have five continuous variables in our data and include them in the
</p>
<p>Stata correlation matrix: (1) money spent partying, (2) quality of extra-curricular
</p>
<p>activities, (3) the amount of tuition students pay themselves, (4) whether or not
</p>
<p>students can have fun without alcohol when they go out, and (5) their study time
</p>
<p>per week.
</p>
<p>Step 1: Write in the command editor
</p>
<p>pwcorr Money_Spent_Partying Study_Time Fun_Without_Alcohol
</p>
<p>Quality_Extra_Curricular_Activ Amount_Tuition_Student_Pays, sig (see Fig. 8.18)
</p>
<p>The correlation output in Table 8.2 displays the bivariate correlations between the
</p>
<p>five continuous variables in our dataset. For each bivariate correlation, Stata
</p>
<p>provides the Pearson correlation coefficient and the significance level ( p). For
</p>
<p>example, 0.1711 is the correlation coefficient between study time and money spent
</p>
<p>partying. The second number (0.29) is the corresponding significance level. To
</p>
<p>determine whether two variables are correlated, we first look at the significance or
</p>
<p>alpha level for each correlation. If we find that sig &gt;0.05, we can conclude that the
</p>
<p>two variables are not correlated. In this case, we do not interpret the correlation
</p>
<p>coefficient, which should be small anyways. In cases where we find a significant p-
</p>
<p>value (sig&lt;0.05), we can go on and interpret the strength of the correlation using the
</p>
<p>benchmarks provided in Sect. 8.6. To highlight, let us look at the correlation between
</p>
<p>Table 8.2 Stata correlation output
</p>
<p>Fig. 8.18 Doing a correlation in Stata
</p>
<p>8.6 Correlation Analysis 147</p>
<p/>
</div>
<div class="page"><p/>
<p>the amount of tuition students pay and the amount of time students generally
</p>
<p>dedicate to their studies per week; we find that there is no correlation between
</p>
<p>these two variables. The significance or alpha level (denoted p in statistical lan-
</p>
<p>guage) is 0.228, which is much higher than the benchmark of 0.05. Hence, we would
</p>
<p>conclude from there that there is no correlation between these two variables. In other
</p>
<p>words, we would stop our interpretation here, and we would not interpret the
</p>
<p>correlation coefficient, because it is not statistically different from zero. In contrast,
</p>
<p>if we look at the relationship between the variable money spent partying and the
</p>
<p>variable quality of extra-curricular activities, we find that the significance level is
</p>
<p>0.000. This means that we can be nearly 100% sure that there is a correlation
</p>
<p>between the two variables. Having established that a correlation exists, we can
</p>
<p>now look at the sign and the magnitude of the coefficient. We find that the sign is
</p>
<p>negative, indicating that the more students spend money while going out, the less
</p>
<p>they participate in extra-curricular activities in their university. Knowing that there is
</p>
<p>a negative correlation, we can now interpret the magnitude of the correlation
</p>
<p>coefficient, which is &ndash;0.601, indicating that we have a medium strong to strong
</p>
<p>negative correlation. In addition to the correlation between the quality of extra-
</p>
<p>curricular activities and money spent partying, there is one more statistically signifi-
</p>
<p>cant and substantively strong correlation, namely, between students&rsquo; study time per
</p>
<p>week and whether or not they can have fun partying without alcohol. This correlation
</p>
<p>is significant at the 0.000 level and substantively strong (i.e., r &frac14; &ndash;0.762). The
</p>
<p>negative sign further highlights that it is a negative relationship, indicating that high
</p>
<p>values for one variable trigger low values for the other variables. In this case, this
</p>
<p>implies that students that study a lot also think that they can have a lot of fun without
</p>
<p>alcohol when they party.
</p>
<p>8.7 Bivariate Regression Analysis
</p>
<p>In correlation analyses, we look at the direction of the line (positive or negative) and
</p>
<p>at how closely the points of the scatterplot follow that line. This allows us to detect
</p>
<p>the degree to which two variables covary, but it does not allow us to determine how
</p>
<p>strongly an independent variable influences a dependent variable. In regression
</p>
<p>analysis, we are interested in the magnitude of the influence of independent on
</p>
<p>dependent variable, as measured by the steepness of the slope. To determine the
</p>
<p>influence of an independent variable on a dependent variable, two things are
</p>
<p>important: (1) the steeper the slope, the more strongly the independent variable
</p>
<p>impacts the dependent variable. (2) The closer the points are to the line, the more
</p>
<p>certain we can be that this relationship actually exists.
</p>
<p>8.7.1 Gauging the Steepness of a Regression Line
</p>
<p>To explain the notion that a steeper slope indicates a stronger relationship, let us
</p>
<p>compare the two graphs in Fig. 8.19. Both graphs depict a perfect relationship,
</p>
<p>meaning that all the points are on a straight line. The correlation for both would be
</p>
<p>1. However, we can see that the first line is much steeper than the second line.
</p>
<p>148 8 Bivariate Relationships Featuring Two Continuous Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>In other words, the y value grows stronger with higher x values. In contrast, the
</p>
<p>second line only moves slightly upward. Consequently, the regression coefficient is
</p>
<p>higher in the first compared to the second graph.
</p>
<p>To determine the relationship between x and y, we use a point slope:
</p>
<p>y &frac14; a&thorn; bx
</p>
<p>y is the dependent variable.
</p>
<p>x is the independent variable.
</p>
<p>b is the slope of the line.
</p>
<p>a is the intercept (y when x &frac14; 0).
</p>
<p>The formula for the regression line:
</p>
<p>b &frac14; r
Sy
</p>
<p>Sx
a &frac14; �y� b�x
</p>
<p>When we draw the regression line, we could in theory draw an infinite number of
</p>
<p>lines. The line that explains the data best is the line that has the smallest sum of
</p>
<p>squared errors. In statistical terms, this line is called the least square line (OLS line).
</p>
<p>Figure 8.20 displays the least square line between the independent variable
</p>
<p>average GDP per capita per country and the dependent variable energy usage in
</p>
<p>kilograms of oil per person. The equation denoting this relationship is as follows:
</p>
<p>energy usage &frac14; 318 + 0.25 average country GDP per capita.
</p>
<p>This means 318 kg is the amount of energy that an average citizen uses when
</p>
<p>GDP is at 0. The equation further predicts that for every 1 unit (dollar) increase on
</p>
<p>the y-axis, y values increase by 0.25 kg. So in this example, this means that for each
</p>
<p>extra dollar the average citizen in a country becomes richer, she uses 0.25 kg more of
</p>
<p>energy (oil) per year. To render the interpretation more tangible, the equation would
</p>
<p>Fig. 8.19 Two regression lines featuring a strong and weak relationship, respectively
</p>
<p>8.7 Bivariate Regression Analysis 149</p>
<p/>
</div>
<div class="page"><p/>
<p>predict that a resident in a country, where the average citizens earn 10,000 dollars, is
</p>
<p>predicted to consume 2818 kg of energy (318 + 0.25 � 10000 &frac14; 2818).
</p>
<p>8.7.2 Gauging the Error Term
</p>
<p>The metric we use to determine the magnitude of a relationship between an indepen-
</p>
<p>dent and a dependent variable is the steepness of the slope. As a rule, we can say that
</p>
<p>the steeper the slope, the more certain we can be that a relationship exists. However,
</p>
<p>the steepness of the slope is not the only criterion we use to determine whether or not
</p>
<p>an independent variable relates to a dependent variable. Rather, we also have to look
</p>
<p>how close the data points are to the line. The closer the points are to the line, the less
</p>
<p>error there is in the data. Figure 8.21 displays two identical lines measuring the
</p>
<p>relationship between age in months and height in centimeters for babies and toddlers.
</p>
<p>What we can see is that the relationship is equally strong for the two lines. However,
</p>
<p>the data fits the first line much better than the second line. There is more &ldquo;noise&rdquo; in
</p>
<p>the data in the second line, thus rendering the estimation of each of the points or
</p>
<p>observations less exact in the second line compared to the first line.
</p>
<p>Figure 8.22 graphically explains what we mean by error term or residual. The
</p>
<p>error term or residual in a regression analysis measures the distance from each data
</p>
<p>point to the regression line. The farther any single observation or data point is away
</p>
<p>from the line, the less this observation fits the general relationship. The larger the
</p>
<p>average distance is from the line, the less well does the average data point fits the
</p>
<p>linear prediction. In other words, the greater the distance between the average data
</p>
<p>E
n
</p>
<p>e
rg
</p>
<p>y
 U
</p>
<p>s
a
</p>
<p>g
e
</p>
<p> i
n
</p>
<p> K
ilo
</p>
<p>g
ra
</p>
<p>m
s
</p>
<p>1
5
</p>
<p>0
0
</p>
<p>0
1
</p>
<p>0
0
</p>
<p>0
0
</p>
<p>5
0
</p>
<p>0
0
</p>
<p>0
</p>
<p>0 10000 20000 30000
</p>
<p>GDP per Capita or Country&rsquo;s  Average Income
</p>
<p>Energy Usage = 318 + .25 . GDP per Capita
</p>
<p>Fig. 8.20 The equation between per capita GDP and energy usage
</p>
<p>150 8 Bivariate Relationships Featuring Two Continuous Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>Fig. 8.21 Better and worse fitting data
</p>
<p>Fig. 8.22 The error term in a regression analysis
</p>
<p>8.7 Bivariate Regression Analysis 151</p>
<p/>
</div>
<div class="page"><p/>
<p>point and the line, the less we can be assured that the relationship portrayed by the
</p>
<p>regression line actually exists.
</p>
<p>8.8 Doing a Bivariate Regression Analysis in SPSS
</p>
<p>To conduct the bivariate regression analysis, we take the same variables we used for
</p>
<p>the scatterplots, that is, our dependent variable money spent partying and the
</p>
<p>independent variable quality of extra-curricular activities
</p>
<p>Step 1: Go to&mdash;Analyze&mdash;Regression&mdash;Linear (see Fig. 8.23).
</p>
<p>Step 2: Choose the dependent variable&mdash;choose the independent variable&mdash;click
</p>
<p>okay (Fig. 8.24).
</p>
<p>Fig. 8.23 Doing a regression analysis in SPSS (first step)
</p>
<p>152 8 Bivariate Relationships Featuring Two Continuous Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>8.9 Interpreting an SPSS (Bivariate) Regression Output
</p>
<p>The SPSS regression output consists of three tables: (1) a model summary table,
</p>
<p>(2) an ANOVAoutput, and (3) a coefficients&rsquo; table.We interpret each table separately
</p>
<p>8.9.1 The Model Summary Table
</p>
<p>The model summary table (see Table 8.3) indicates how well the model fits the data.
</p>
<p>It consists of four parameters: (1) the Pearson correlation coefficient (r), (2) the R-
</p>
<p>squared value, (3) the adjusted R-squared value, and (4) the standard error of the
</p>
<p>estimate.
</p>
<p>Fig. 8.24 Doing a regression analysis in SPSS (second step)
</p>
<p>Table 8.3 SPSS model summary table
</p>
<p>8.9 Interpreting an SPSS (Bivariate) Regression Output 153</p>
<p/>
</div>
<div class="page"><p/>
<p>R is the correlation coefficient between the real data points and the values
</p>
<p>predicted by the model. For the example at hand, the correlation coefficient is high
</p>
<p>indicating that real values and predicated values correlate at the level of 0.600.
</p>
<p>R-squared is the most important parameter in the model summary statistic&rsquo;s table
</p>
<p>and is a measure of model fit (i.e., it is the squared correlation between the model&rsquo;s
</p>
<p>predicted values and the real values). It explains how much of the variance in the
</p>
<p>dependent variable the independent variable(s) in the model explain. In theory, the
</p>
<p>R-squared values can range from 0 to 1. An R-squared value of 0 means that the
</p>
<p>independent variable(s) do not explain any of the variance of the dependent variable,
</p>
<p>and a value of 1 signifies that the independent variable(s) explain all the variance in
</p>
<p>the dependent variable. In our example, the R-squared value of 0.361 implies that the
</p>
<p>independent variable&mdash;the quality of extra-curricular activities&mdash;explains 36.1% of
</p>
<p>the variance in the dependent variable, the money students spent partying per week.
</p>
<p>The adjusted R-squared is a second statistic of model fit. It helps us compare
</p>
<p>different models. In real research, it might be helpful to compare models with a
</p>
<p>different number of independent variables to determine which of the alternative
</p>
<p>models is superior in a statistical sense. To highlight, the R-squared will always
</p>
<p>increase or remain constant if I add variables. Yet, a new variable might not add
</p>
<p>anything substantial to the model. Rather, some of the increase in R-squared could be
</p>
<p>simply due to coincidental variation in a specific sample. Therefore, the adjusted R-
</p>
<p>squared will be smaller than the R-squared since it controls for some of the idiosyn-
</p>
<p>cratic variance in the original estimate. As such, the adjusted R-squared is a measure
</p>
<p>of model fit adjusted for the number of independent variables in the model. It helps
</p>
<p>us compare different models; the best fitting model is always the model with the
</p>
<p>highest adjusted R-squared (not the model with the highest R-squared).2 In our
</p>
<p>sample, the adjusted R-squared is 0.344 (We do not interpret this estimator in
</p>
<p>bivariate regression analysis).
</p>
<p>The standard error of the estimate is the standard deviation of the error term
</p>
<p>and the square root of the mean square residual (or error). (Normally, we do not
</p>
<p>interpret this estimator when we conduct regression models.) In our sample, the
</p>
<p>standard error of the estimate is 24.43.
</p>
<p>8.9.2 The Regression ANOVA Table
</p>
<p>The f-test in a regression model works like an f-test or ANOVA analysis (see
</p>
<p>Table 8.4). It is an indication of the significance of the model (does the regression
</p>
<p>equation fit the observed data adequately?). If the f-ratio is significant, the regression
</p>
<p>equation has predictive power, which means that we have at least one statistically
</p>
<p>significant variable in the model. In contrast, if the f-test is not significant, then none
</p>
<p>of the variables in the model is statistically significant, and the model has no
</p>
<p>predictive power. In our sample, the f-value is 21.43, and the corresponding signifi-
</p>
<p>cance level is 0.000. Hence, we can already conclude that our independent
</p>
<p>2Please note that we can only compare adjusted R-squared values of different models, if these
</p>
<p>models have the same number of observations.
</p>
<p>154 8 Bivariate Relationships Featuring Two Continuous Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>variable&mdash;the quality of extra-curricular activities&mdash;influences our dependent vari-
</p>
<p>able, the money students spend per week partying.
</p>
<p>8.9.3 The Regression Coefficient Table
</p>
<p>The coefficients&rsquo; table (see Table 8.5) is the most important part of a regression
</p>
<p>output. It tells us how the independent variable relates to the dependent variable. A
</p>
<p>coefficients&rsquo; table has the following statistics:
</p>
<p>Unstandardized RegressionWeights The first column portrays the unstandardized
</p>
<p>regression weights, which give us an indication of how the independent variable
</p>
<p>(s) relates to the dependent variable. In our example, the unstandardized regression
</p>
<p>weight or coefficient depicting the influence of extra-curricular activities on students&rsquo;
</p>
<p>party spending is &ndash;0.839. The constant is 114.87. In other words, the &ndash;0.839 is the
</p>
<p>slope coefficient; it indicates the change in the DV associated with a 1-unit change in
</p>
<p>the IV. In our example, this implies that for each point on the 0&ndash;100 scale, students
</p>
<p>like the extra-curricular activities more, their party spending decreases by 0.839
</p>
<p>dollars per week. The 114.87 is the predicted spending pattern if the independent
</p>
<p>Table 8.4 SPSS ANOVA table of the regression output
</p>
<p>Table 8.5 The SPSS regression coefficients&rsquo;.
</p>
<p>8.9 Interpreting an SPSS (Bivariate) Regression Output 155</p>
<p/>
</div>
<div class="page"><p/>
<p>variable has the value 0 (i.e., if students think that the extra-curricular activities at
</p>
<p>their university are very bad).
</p>
<p>We can also express this relationship in a regression equation: y&frac14; 114.87 &ndash; 0.839x.
</p>
<p>The Standard Error This statistic gives us an indication of how much variation
</p>
<p>there is around the predicted coefficient. As a rule, we can say that the smaller the
</p>
<p>standard error in relation to the regression weight is, the more certainty we can have
</p>
<p>in the interpretation of our relationship. In our case, the standard error behind the
</p>
<p>relationship between extra-curricular activities and money spent partying is 0.181.
</p>
<p>Standardized Regression Coefficients (Beta) In multiple regression models, it is
</p>
<p>impossible to compare the magnitude of the coefficients of the independent
</p>
<p>variables. To highlight, the variable gender is a dummy variable coded 0 for guys
</p>
<p>and 1 for girls. In contrast, the variable fun without alcohol is a variable coded on a
</p>
<p>100-point scale (i.e., 0&ndash;100). Unstandardized weights are standardized coefficients
</p>
<p>that allow us to compare the effect size of several independent variables. To do so,
</p>
<p>SPSS converts the unstandardized coefficients to z-scores (i.e., weights with mean of
</p>
<p>zero and standard deviation of 1.0). The size of the standardized regression weights
</p>
<p>gives us some indication of the importance of the variable in the regression equation.
</p>
<p>In a multiple regression analysis, it allows us to determine the relative strength of
</p>
<p>each independent variable in comparison to other variables on the dependent vari-
</p>
<p>able. The standardized beta is &ndash;0.600 in our bivariate model.
</p>
<p>T-value The t-test compares the unstandardized regression against a predicted value
</p>
<p>of zero (i.e., no contribution to regression equation). It does so by dividing the
</p>
<p>unstandardized regression coefficient (i.e., our measure of effect size) by the stan-
</p>
<p>dard error (i.e., our measure of variability in the data). As a rule, we can say that the
</p>
<p>higher the T-value, the higher the chance that we have a statistically significant
</p>
<p>relationship (see significance value). In our example, the T-value is &ndash;4.629 (&ndash;0.839/
</p>
<p>0.181).
</p>
<p>Significance Value (Alpha Level) The significance level (sig) indicates the proba-
</p>
<p>bility that a specific independent variable impacts the dependent variable. In our
</p>
<p>example, the significance level is 0.000, which implies that we can be nearly 100%
</p>
<p>sure that the quality of extra-curricular activities influences students&rsquo; spending
</p>
<p>patterns while partying.
</p>
<p>8.10 Doing a (Bivariate) Regression Analysis in Stata
</p>
<p>To conduct the regression analysis, we will use the same variables that we used for
</p>
<p>the scatterplots, that is, our dependent variable is money spent partying and our
</p>
<p>independent variable is the quality of extra-curricular activities (see Table 7.11).
</p>
<p>156 8 Bivariate Relationships Featuring Two Continuous Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>Step 1: Write into the command editor: reg Money_Spent_Partying
</p>
<p>Quality_Extra_Curricular_Activ (see Fig. 8.25).
</p>
<p>8.10.1 Interpreting a Stata (Bivariate) Regression Output
</p>
<p>On the following pages, we explain how to interpret a Stata bivariate regression
</p>
<p>output (see Table 8.6):
</p>
<p>Number of obs indicates how many observations the model is based upon
</p>
<p>The f-test provides the f-test value for the regression analysis. It works like an f-test
</p>
<p>or ANOVA analysis and gives an indication of the significance of the model (i.e., it
</p>
<p>measures whether the regression equation fits the observed data adequately). If the f-
</p>
<p>ratio is significant, the regression equation has predictive power, whichmeans that we
</p>
<p>have at least one statistically significant variable in the model. In contrast, if the f-test
</p>
<p>is not significant, then none of the variables in the model is statistically significant,
</p>
<p>and the model has no predictive power. In our sample, the f-value is 21.43 and the
</p>
<p>corresponding significance level is 0.000 (Prob &gt; F). Hence, we can already con-
</p>
<p>clude that our independent variable&mdash;the quality of extra-curricular activities&mdash;
</p>
<p>influences our dependent variable, the money students spend per week partying.
</p>
<p>(The Table you see to the left of the summary statistics (i.e., Number of obs, F,
</p>
<p>Prob&gt;F,R-squared, Adj R-squared, RootMSE) is the summary statistics of the f-test
</p>
<p>(see section on t-test or ANOVA for more details).)
</p>
<p>Table 8.6 The Stata bivariate regression
</p>
<p>Fig. 8.25 Doing a bivariate regression analysis in Stata
</p>
<p>8.10 Doing a (Bivariate) Regression Analysis in Stata 157</p>
<p/>
</div>
<div class="page"><p/>
<p>R-squared is an important parameter when we interpret a regression output. It is a
</p>
<p>measure of model fit (i.e., it is the squared correlation between the model&rsquo;s predicted
</p>
<p>values and the real values). It explains how much of the variation in the dependent
</p>
<p>variable is explained by the independent variables in the model. In theory, the R-
</p>
<p>squared values can range from 0 to 1. An R-squared value of 0 means that the
</p>
<p>independent variable(s) do not explain anything in the variance of the dependent
</p>
<p>variable. An R-squared value of 1 signifies that the independent variable(s) explain all
</p>
<p>the variance in the dependent variable. In our example, the R-squared value of 0.361
</p>
<p>implies that the independent variable&mdash;the quality of extra-curricular activities&mdash;
</p>
<p>explains 36.1% of the variance in the dependent variable, the money students spent
</p>
<p>partying per week.
</p>
<p>The adjusted R-squared is a second statistic of model fit that helps us compare
</p>
<p>different models. In real research, it might be helpful to compare models with a
</p>
<p>different number of independent variables to determine which of the alternative
</p>
<p>models is superior in a statistical sense. To highlight, the R-squared will always
</p>
<p>increase or remain constant if I add variables even though a new variable might not
</p>
<p>add anything substantial to the model. Rather, some of the increase in the R-squared
</p>
<p>could be simply due to coincidental variation in a specific sample. Therefore, the
</p>
<p>adjusted R-squared will be smaller than the R-squared since it controls for some of
</p>
<p>the idiosyncratic variance in the original estimate. Therefore, the adjusted R is a
</p>
<p>measure of model fit adjusted for the number of independent variables in the model.
</p>
<p>It helps us to compare different models; the best fitting model is always the model
</p>
<p>with the highest adjusted R-squared (not the model with the highest R-squared).3 In
</p>
<p>our sample, the adjusted R-squared is 0.344. (We do not interpret this estimator in
</p>
<p>bivariate regression analysis.)
</p>
<p>The root MSE (root mean squared error) is the standard deviation of the error term
</p>
<p>and the square root of the mean square residual (or error). (Normally, we do not
</p>
<p>interpret this estimator when we conduct regression models.) In our sample, the
</p>
<p>standard error of the estimate is 24.43.
</p>
<p>Coef. (coefficient) The first column portrays the unstandardized regression
</p>
<p>weights, which give us an indication of how the independent variable(s) relate to
</p>
<p>the dependent variable. In our example, the unstandardized regression weight or
</p>
<p>coefficient depicting the influence of extra-curricular activities on students&rsquo; party
</p>
<p>spending is&mdash;0.839. The constant is 114.87. In other words, the &ndash;0.839 is the slope
</p>
<p>coefficient; it indicates the change in the dependent variable associated with a 1-unit
</p>
<p>change in the independent variable. In our example, this implies that for each
</p>
<p>additional point on the 0&ndash;100 scale that students like the extra-curricular activities,
</p>
<p>their party spending decreases by 0.839 dollars per week. The constant (cons)
</p>
<p>coefficient of 114.87 is the predicted spending pattern if the independent variable
</p>
<p>3Ibid.
</p>
<p>158 8 Bivariate Relationships Featuring Two Continuous Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>has the value 0 (i.e., this implies that if students do not like the extra-curricular
</p>
<p>activities at their school at all, they are predicted to spend 115 dollars per week
</p>
<p>partying).
</p>
<p>We can also express this relationship in a regression equation: y&frac14; 114.87 &ndash; 0.839x
</p>
<p>The standard error gives us an indication of how much variation there is around
</p>
<p>the predicted coefficient. As a rule, we can say that the smaller the standard error
</p>
<p>relative to the regression weight, the more certainty we can have in the interpretation
</p>
<p>of our relationship between independent and dependent variable. In our case, the
</p>
<p>standard error behind the relationship between extra-curricular activities and money
</p>
<p>spent partying is 0.181.
</p>
<p>Standardized regression coefficients (beta) In multiple regression models, it is
</p>
<p>impossible to compare the magnitude of the coefficients of the independent
</p>
<p>variables. To highlight, the variable gender is a dummy variable coded 0 for guys
</p>
<p>and 1 for girls. In contrast, the variable fun without alcohol is a variable coded on a
</p>
<p>100-point scale (i.e., 0&ndash;100). Standardized weights are standardized coefficients that
</p>
<p>allow us to compare the effect size of several independent variables. To do so, Stata
</p>
<p>converts the unstandardized coefficients to z-scores (i.e., weights with mean of zero
</p>
<p>and standard deviation of 1). The size of the standardized regression weights gives us
</p>
<p>some indication of the importance of the variable in the regression equation. In a
</p>
<p>multiple regression analysis, it allows us to determine the relative strength of each
</p>
<p>independent variable in comparison to other variables on the dependent variable.
</p>
<p>The standardized beta is not one of the default options in the Stata package.
</p>
<p>However, it can be easily calculated. To do so, add the option beta at the end of
</p>
<p>the regression analysis. Put in the command field:
</p>
<p>reg Money_Spent_Partying Quality_Extra_Curricular_Activ, beta (see Fig. 8.26)
</p>
<p>In our bivariate example, the standardized beta coefficient is &ndash;0.600 (see
</p>
<p>Table 8.7).
</p>
<p>T-value The t-test compares the unstandardized regression weight against a
</p>
<p>predicted value of zero (i.e., no contribution to regression equation). It does so by
</p>
<p>dividing the unstandardized regression coefficient (i.e., our measure of effect size)
</p>
<p>by the standard error (i.e., our measure of variability in the data). As a rule, we can
</p>
<p>say that the higher the t-value, the higher the chance that we have a statistically
</p>
<p>significant relationship (see significance value). In our example, the t-value is &ndash;4.629
</p>
<p>(&ndash;0.839/0.181).
</p>
<p>Fig. 8.26 Doing a bivariate regression analysis with standardized beta coefficients
</p>
<p>8.10 Doing a (Bivariate) Regression Analysis in Stata 159</p>
<p/>
</div>
<div class="page"><p/>
<p>P&gt; t is the significance value or alpha level The significance level determines the
</p>
<p>probability with which we can determine that a specific independent variable
</p>
<p>impacts the dependent variable. In our example, the significance level is 0.000,
</p>
<p>which implies that we can be nearly 100% sure that the quality of extra-curricular
</p>
<p>activities influences students&rsquo; spending patterns while partying.
</p>
<p>(95% conf. interval) Assuming that our sample was randomly picked from a
</p>
<p>population of university students, the confidence interval depicts the interval in
</p>
<p>which the real relationship between the perceived quality of extra-curricular activities
</p>
<p>and students spending patterns lies. Our coefficient for the quality of extra-curricular
</p>
<p>activities has a confidence interval that ranges from &ndash;1.21 to &ndash;0.472. This means
</p>
<p>that the relationship in the population could be anywhere in this range. Similarly, the
</p>
<p>confidence interval around the constant implies that somebody who rates the quality
</p>
<p>of extra-curricular activities at 0 is expected to spend between 96.36 dollars and
</p>
<p>133.38 for partying in a week.
</p>
<p>8.10.2 Reporting and Interpreting the Results of a Bivariate
Regression Model
</p>
<p>When we report the results of bivariate regression model, we report the coefficient,
</p>
<p>standard error, and significance level, as well as the R-squared and the number of
</p>
<p>observations in the model. In an article or report, we would report the results as
</p>
<p>follows: Table 8.8 reports the results of a bivariate regression model measuring the
</p>
<p>influence of the quality of extra-curricular activities on students&rsquo; weekly spending
</p>
<p>patterns when they party based on a survey conducted with 40 undergraduate
</p>
<p>students at a Canadian university. The model portrays a negative and statistically
</p>
<p>significant relationship between the two variables. In substantive terms, the model
</p>
<p>predicts that for every point students&rsquo; evaluation of the extra-curricular activities at
</p>
<p>their university increases, they spent 84 cents less per week partying. This influence
</p>
<p>is substantial. For example, somebody, who thinks that the extra-curricular activities
</p>
<p>at her university are poor (and rates them at 20), is predicted to spend approximately
</p>
<p>98 dollars for party activities. In contrast, somebody, who likes the extra-curricular
</p>
<p>Table 8.7 The Stata bivariate regression table with standardized coefficients
</p>
<p>160 8 Bivariate Relationships Featuring Two Continuous Variables</p>
<p/>
</div>
<div class="page"><p/>
<p>activities (and rates them at 80), is only expected to 48 dollars for her weekly
</p>
<p>partying. The R-squared of the model further highlights that the independent vari-
</p>
<p>able, the quality of extra-curricular activities, explains 34% of the variance in the
</p>
<p>dependent variable partying spending per week.
</p>
<p>Further Reading
</p>
<p>Gravetter, F. J., &amp; Forzano, L. A. B. (2018). Research methods for the behavioral sciences. Boston:
</p>
<p>Cengage Learning (chapter 12). Nice introduction into correlational research; covers the data
</p>
<p>and methods for correlational analysis, applications of the correlational strategy, and strength
</p>
<p>and weakness of the correlational research strategy.
</p>
<p>Montgomery, D. C., Peck, E. A., &amp; Vining, G. G. (2012). Introduction to linear regression analysis
</p>
<p>(Vol. 821). San Francisco: John Wiley &amp; Sons (chapters 1 and 2). Chapters 1 and 2 provide a
</p>
<p>hands on and practical introduction into linear regression modelling, first in the bivariate realm
</p>
<p>and then in the multivariate realm.
</p>
<p>Ott, R. L., &amp; Longnecker, M. T. (2015). An introduction to statistical methods and data analysis.
</p>
<p>Toronto, ON: Nelson Education (chapter 11). Provides a good introduction into correlation and
</p>
<p>regression analysis clearly highlighting the differences between the two techniques.
</p>
<p>Roberts, L. W., Wilkinson, L., Peter, T., &amp; Edgerton, J. (2015). Understanding social statistics.
</p>
<p>Don Mills: Oxford University Press (chapters 10&ndash;14). These chapters offer students the basic
</p>
<p>tools to examine the form and strength of bivariate relationships.
</p>
<p>Table 8.8 Reporting a bivariate regression outcome
</p>
<p>Coefficient Std. error Sig
</p>
<p>Quality of extra-curricular activities &ndash;0.839 0.181 0.000
</p>
<p>Constant 114.87 9.14 0.000
</p>
<p>R-squared 0.34
</p>
<p>N 40
</p>
<p>Further Reading 161</p>
<p/>
</div>
<div class="page"><p/>
<p>Multivariate Regression Analysis 9
</p>
<p>Abstract
</p>
<p>This final chapter provides an introduction into multivariate regression modeling.
</p>
<p>We will cover the logic behind multiple regression modeling and explain the
</p>
<p>interpretation of a multivariate regression model. We will further cover the
</p>
<p>assumptions this type of model is based upon. Finally, and using our data, we
</p>
<p>will provide concrete examples on how to interpret a multiple regression model.
</p>
<p>9.1 The Logic Behind Multivariate Regression Analysis
</p>
<p>Bivariate regression analysis is very rarely used in real applied research, because an
</p>
<p>outcome is hardly ever just dependent on one predictor. Rather, multiple factors
</p>
<p>normally explain the dependent variable (see Fig. 9.1). To highlight, if we want to
</p>
<p>explain a student&rsquo;s grade in an exam, several factors might come into play. A
</p>
<p>student&rsquo;s grade might depend on how much the respective student studied for the
</p>
<p>exam; it might depend on her health and even on her general mood. Multiple regres-
</p>
<p>sion modeling allows us to absolutely and comparatively gauge the influence of all
</p>
<p>of these factors on the dependent variable.
</p>
<p>Multiple regression analysis is an extension of bivariate regression analysis. It
</p>
<p>allows us to test the influence of multiple independent (predictor) variables on a
</p>
<p>dependent variable. Just like in the case of two variables, the goal of this method is to
</p>
<p>create an equation or a &ldquo;model&rdquo; that explains the impact of/relationship between
</p>
<p>these variables.
</p>
<p>Let us assume that we want to explain the dependent variable &ldquo;Y&rdquo; and we have
</p>
<p>several independent variables X1. . .Xp. Then, the multiple regression equation we
</p>
<p>need to calculate is:
</p>
<p># Springer International Publishing AG 2019
</p>
<p>D. Stockemer, Quantitative Methods for the Social Sciences,
</p>
<p>https://doi.org/10.1007/978-3-319-99118-4_9
</p>
<p>163</p>
<p/>
<div class="annotation"><a href="http://crossmark.crossref.org/dialog/?doi=10.1007/978-3-319-99118-4_9&amp;domain=pdf">http://crossmark.crossref.org/dialog/?doi=10.1007/978-3-319-99118-4_9&amp;domain=pdf</a></div>
</div>
<div class="page"><p/>
<p>Y 0 &frac14; A&thorn; B1X1 &thorn; B2X2 &thorn; . . . &thorn; BpXp
</p>
<p>Y' is the predicted score of the dependent (criterion) variable (dependent variable).
</p>
<p>A is a constant which gives the value of Y0 when all Xs are zero (Y-intercept or
</p>
<p>constant).
</p>
<p>Xs are all the independent variable values (values of the independent variables).
</p>
<p>B1&ndash;Bp are regression weights. They are the contribution of each independent
</p>
<p>variable to the predicted value of the dependent variable (i.e., each represents
</p>
<p>the change in Y0 resulting from a unit change in a specific predictor variable when
</p>
<p>all other predictors are held at constant values).
</p>
<p>Example Suppose we want to study the predictors of a student&rsquo;s grade in a math
</p>
<p>exam (see Figure 8.21). We ask a random sample of students at a German high
</p>
<p>school about their grade in their last math exam, the time they spent studying for this
</p>
<p>exam, their general mood, and whether they were in good perceived health when
</p>
<p>taking the exam. Let us further assume that we run a multiple regression model and
</p>
<p>receive the following equation (for now we ignore the question of whether the
</p>
<p>variables are statistically significant or not). We receive the following equation:
</p>
<p>Y 0 &frac14; 10:5&thorn; 3:1X1 &thorn; 1:5X2 &thorn; 0:5X3 &thorn; e
</p>
<p>We would interpret the model as follows:
</p>
<p>10.5 (on a scale from 0 to 100) is the hypothetical grade a student is expected to get,
</p>
<p>if she does not study at all, her general health is at its worst (she would rank her
</p>
<p>health by the value 0), and her general mood is also at the lowest value (she would
</p>
<p>also rank this at 0).
</p>
<p>Fig. 9.1 Predictors of a
</p>
<p>student&rsquo;s grade
</p>
<p>164 9 Multivariate Regression Analysis</p>
<p/>
</div>
<div class="page"><p/>
<p>3.1 is the slope coefficient for the variable study time. This implies that for every
</p>
<p>hour a student studies, her grade is expected to increase by 3.1 points.
</p>
<p>1.5. is the slope coefficient for somebody&rsquo;s general health, indicating that per each
</p>
<p>point somebody&rsquo;s perceived health increases, her math grade is predicted to
</p>
<p>improve by 1.5 points.
</p>
<p>0.5 is the slope coefficient for somebody&rsquo;s general mood. In other words, for each
</p>
<p>point somebody&rsquo;s general mood increases, her test performance is expected to
</p>
<p>increase by 0.5 points.
</p>
<p>As we can see from the example, the multivariate regression model is an extension
</p>
<p>of the bivariate model. It has the same parameters and the interpretation is analogous.
</p>
<p>To do a multiple regression analysis in SPSS (or Stata), follow the same steps as you
</p>
<p>would follow for a bivariate regression. Just add more variables as independent
</p>
<p>variables.
</p>
<p>9.2 The Functional Forms of Independent Variables to Include
in a Multivariate Regression Model
</p>
<p>In this introduction to survey research and quantitative methods, we only cover
</p>
<p>continuous dependent variables (noncontinuous dependent variables will be the
</p>
<p>subject of more advanced statistical courses). Yet, we still have to determine in
</p>
<p>what type of functional form we would include our independent variables. Provided
</p>
<p>that the relationship between a continuous independent and a continuous dependent
</p>
<p>variable is linear (the relationship follows a line), we will include the independent
</p>
<p>variables in its linear form. If a scatterplot would highlight that the relationship
</p>
<p>between independent and dependent variable is not linear (e.g., it follows a curve),
</p>
<p>we would need to transform the variable. However, this is also material for a more
</p>
<p>advanced class. We would also not change binary or dummy variables. The only
</p>
<p>variables we must be careful with, for the purpose of this introductory textbook, are
</p>
<p>categorical variables. If we have a categorical nominal variable (i.e., different
</p>
<p>religious affiliations), we create N &ndash; 1 dummy variables, with one of the categories
</p>
<p>serving as a reference category (see Table 4.14). If we have ordinal variables, we
</p>
<p>could also test whether the relationship is in fact ordered. For example, we could test
</p>
<p>via a multiple comparison test whether the relationship between times partying per
</p>
<p>week and money spent partying per week is in principle ordinal. By including the
</p>
<p>variable&mdash;times partying per week&mdash;in its linear ordinal form, we also assume that
</p>
<p>the relationship between partying less than one time per week and one time per week
</p>
<p>is the same as between four and five times per week. However, in the ANOVA or
</p>
<p>f-test, we find that this is not true (see Table 6.2). Rather, we find that students that
</p>
<p>party three times or less regardless of whether they party, on average, less than once,
</p>
<p>once, twice, or three times per week, spend approximately the same amount of
</p>
<p>money when they party; only students that party four or more times spend signifi-
</p>
<p>cantly more. Because of this dichotomy in the relationship, it would make sense to
</p>
<p>9.2 The Functional Forms of Independent Variables to Include in a Multivariate. . . 165</p>
<p/>
<div class="annotation"><a href="https://doi.org/10.1007/978-3-319-99118-4_14">https://doi.org/10.1007/978-3-319-99118-4_14</a></div>
</div>
<div class="page"><p/>
<p>create a dummy variable between the two categories. (In the dataset, we label this
</p>
<p>variable money spent partying 3.)
</p>
<p>9.3 Interpretation Help for a Multivariate Regression Model
</p>
<p>When you want to interpret a multivariate regression model, we can follow the
</p>
<p>same logic as for a bivariate regression model. The four guiding steps can help:
</p>
<p>1. Look at what variables are significant.
</p>
<p>2. Interpret the substantive value of significant variable.
</p>
<p>3. Compare the relative strength of the significant variables.
</p>
<p>4. Interpret the model fit.
</p>
<p>9.4 Doing a Multiple Regression Model in SPSS
</p>
<p>In our sample survey, we have included seven possible predictor variables, and we
</p>
<p>want to determine the relative and absolute influence of these seven predictor
</p>
<p>variables on the dependent variable, money spent partying per week. Because we
</p>
<p>know from the ANOVA analysis (see Sect. 7.2.) that the relationship between the
</p>
<p>ordinal variable times partying and money spent partying is not linear, but rather
</p>
<p>only matters for individuals who party four times per week or more, we create a
</p>
<p>binary variable, coded 0 for partying three times or less per week and 1 for partying
</p>
<p>four times or more. We add this recoded independent variable together with the
</p>
<p>remaining six independent variables into the model (see Sect. 9.7) and label it
</p>
<p>Times_Partying_3. The dependent variable is money spent partying.
</p>
<p>9.5 Interpreting a Multiple Regression Model in SPSS
</p>
<p>Following the four steps outlined under Sect. 9.3., we can proceed as follows (see
</p>
<p>Table 9.1):
</p>
<p>1. If we look at the significance level, we find that two variables are statistically
</p>
<p>significant (i.e., quality of extra-curricular activities and times partying 3). For all
</p>
<p>other variables, the significance level is higher than 0.05. Hence, we would
</p>
<p>conclude that these indicators do not influence the amount of money students
</p>
<p>spent per week partying.
</p>
<p>2. The first significant variable, the quality of extra-curricular activities, has the
</p>
<p>expected negative sign indicating that the more the students enjoy their extra-
</p>
<p>curricular activities at their institution, the less money they spent weekly partying.
</p>
<p>This observation also confirms our initial hypothesis. Holding everything else
</p>
<p>constant, the model predicts that per every point a student enjoys her extra-
</p>
<p>curricular activities more, she spends 62 cents less per week partying.
</p>
<p>166 9 Multivariate Regression Analysis</p>
<p/>
</div>
<div class="page"><p/>
<p>For example, this implies that somebody who thinks that the extra-curricular acti-
</p>
<p>vities are very bad at her university (i.e., she rates the quality of extra-curricular
</p>
<p>activities at 0) spends 62 dollars more per week studying than somebody who
</p>
<p>thinks that the extra-curricular activities are excellent (i.e., she rates the quality of
</p>
<p>extra-curricular activities at 100).
</p>
<p>The second significant variable, times partying 3, also has the expected positive
</p>
<p>sign. The regression coefficient of 24.81 indicates that people that party four or
</p>
<p>more times are expected to spend nearly 25 dollars more on their partying habits
</p>
<p>than students that party three times or less.
</p>
<p>Table 9.1 Multiple regression output in SPSS
</p>
<p>9.5 Interpreting a Multiple Regression Model in SPSS 167</p>
<p/>
</div>
<div class="page"><p/>
<p>3. If we compare the two statistically significant variables, we find that the standard-
</p>
<p>ized beta coefficient is higher for the variable quality of extra-curricular activities
</p>
<p>(i.e., the standardized beta coefficient is &ndash;0.421) than for the variable times
</p>
<p>partying 3 (0.387). This higher standard beta coefficient illustrates that the vari-
</p>
<p>able quality of extra-curricular activities has more explanatory power in the
</p>
<p>model than the variable times partying 3.
</p>
<p>4. The model fits the data quite well; the seven independent variables explain 57%
</p>
<p>of the variance in the dependent variable, the amount of money students spent
</p>
<p>partying. (The R-squared is 0.568.)
</p>
<p>9.6 Doing a Multiple Regression Model in Stata
</p>
<p>In our survey, we have included seven possible predictor variables, and we want to
</p>
<p>determine the relative and absolute influence of these seven predictor variables on
</p>
<p>the dependent variable. Because we know from the ANOVA analysis (see Table 6.2)
</p>
<p>that the relationship between the ordinal variable times partying and money spent
</p>
<p>partying is not linear but rather only becomes different for individuals who party four
</p>
<p>times or more, we create a binary variable, coded 0 for partying three times or less
</p>
<p>per week and 1 for partying four times or more. We add this recoded independent
</p>
<p>variable together with the remaining six independent variables into the model (see
</p>
<p>Sect. 9.8). The dependent variable is money spent partying.
</p>
<p>9.7 Interpreting a Multiple Regression Model in Stata
</p>
<p>Following the four steps outlined under 10.3., we can proceed as follows (see
</p>
<p>Tables 9.2 and 9.3):
</p>
<p>Table 9.2 Multiple regression output in Stata
</p>
<p>168 9 Multivariate Regression Analysis</p>
<p/>
</div>
<div class="page"><p/>
<p>1. If we look at the significance level, we find that two variables are statistically
</p>
<p>significant (i.e., quality of extra-curricular activities and times partying 3). For all
</p>
<p>other variables, the significance level is higher than 0.05. Hence, we would
</p>
<p>conclude that these indicators do not influence the amount of money students
</p>
<p>spent per week partying.
</p>
<p>2. The first significant variable, the quality of extra-curricular activities, has the
</p>
<p>expected negative sign indicating that the more students enjoy their extra-
</p>
<p>curricular activities at their institution, the less money they spent weekly partying.
</p>
<p>This observation also confirms our initial hypothesis. Holding everything else
</p>
<p>constant, the model predicts that per every point a student enjoys her extra-
</p>
<p>curricular activities more, she spends 62 cents less per week partying. For
</p>
<p>example, this implies that somebody who thinks that the extra-curricular activities
</p>
<p>are very bad at her university (i.e., she rates the quality of extra-curricular
</p>
<p>activities at 0) spends 62 dollars more per week studying than somebody who
</p>
<p>thinks that the extra-curricular activities are excellent (i.e., she rates the quality of
</p>
<p>extra-curricular activities at 100).
</p>
<p>The second significant variable, times partying 2, also has the expected positive
</p>
<p>sign. The regression coefficient of 24.81 indicates that people that party four or
</p>
<p>more times are expected to spend nearly 25 dollars more on their weekly partying
</p>
<p>habits than students that party three times or less.
</p>
<p>3. If we compare the two statistically significant variables, we find that the
</p>
<p>standardized beta coefficient is higher for the variable quality of extra-curricular
</p>
<p>activities (i.e., the standardized beta coefficient is &ndash;0.421) than for the variable
</p>
<p>times partying 3 (0.387). This higher standard beta coefficient illustrates that the
</p>
<p>variable quality of extra-curricular activities has more explanatory power in the
</p>
<p>model than the variable times partying 3.
</p>
<p>Table 9.3 Multiple regression output in Stata with standardized coefficients
</p>
<p>9.7 Interpreting a Multiple Regression Model in Stata 169</p>
<p/>
</div>
<div class="page"><p/>
<p>4. The model fits the data quite well; the seven independent variables explain nearly
</p>
<p>57% of the variance in the dependent variable, the amount of money students
</p>
<p>spent partying. (The R-squared is 0.573.)
</p>
<p>9.8 Reporting the Results of a Multiple Regression Analysis
</p>
<p>In the multiple regression analysis (see Table 9.2), we evaluated the influence of
</p>
<p>seven independent variables (the quality of extra-curricular activities, students&rsquo; study
</p>
<p>time per week, the year students are in, gender, whether they party two times or less
</p>
<p>or three times or more per week, the degree to which they think that they can have
</p>
<p>fun without alcohol, and the amount of tuition the students pay) on the dependent
</p>
<p>variable, the weekly amount of money students spent partying. We find that two of
</p>
<p>the seven variables are statistically significant and show the expected effect; that is,
</p>
<p>the more students think that the extra-curriculars at their university are good, the less
</p>
<p>money they spent partying per week. The same applies to students that party few
</p>
<p>times; they too spend less money going out. In substantive terms, the model predicts
</p>
<p>that per every point students increase their ranking of the extra-curricular activities at
</p>
<p>their school, they will spend 59 cents less partying per week. The coefficient for the
</p>
<p>dummy variable, partying two times or less or three times or more per week,
</p>
<p>indicates that students that party three or more times are predicted to spend 26 dollars
</p>
<p>more on their partying habits than students that party less. Using the 95% bench-
</p>
<p>mark, none of the other variables is statistically significant. Consequently, we cannot
</p>
<p>interpret the other coefficients because they are not different from zero. In terms of
</p>
<p>model fit, the data fits the model fairly well: the seven independent variables explain
</p>
<p>57% of the variance in the dependent variable.
</p>
<p>9.9 Finding the Best Model
</p>
<p>In real research the inclusion of variables into a regression model should be theoreti-
</p>
<p>cally driven; that is, theory should tell us which independent variables we should
</p>
<p>include in a model to explain and predict a dependent variable. However, we might
</p>
<p>also be interested in finding the best model. There are two ways to proceed, and there
</p>
<p>is some disagreement among statisticians: One way is to only include statistically
</p>
<p>significant variables into the model. Another way is to use the adjusted R-squared as a
</p>
<p>benchmark. To recall, the adjusted R-squared is a measure of model fit that allows us
</p>
<p>to compare different models. For every additional predictor I include in the model, the
</p>
<p>adjusted R-squared increases only if the new term improves the model beyond pure
</p>
<p>chance. (Please note that a poor predictor can decrease the adjusted R-squared, but it
</p>
<p>can never decrease the R-squared.) Using the adjusted R-squared as a benchmark to
</p>
<p>find the best model, we should proceed as follows: (1) start with the complete model,
</p>
<p>which includes all the predictors, (2) remove the non-statistically significant predictor
</p>
<p>with the lowest standardized coefficient, and (3) continue this procedure until the
</p>
<p>170 9 Multivariate Regression Analysis</p>
<p/>
</div>
<div class="page"><p/>
<p>adjusted R-squared does no longer increases. Table 9.4 highlights this procedure. We
</p>
<p>start with the full model. The full model has an adjusted R-squared of 0.4797.We take
</p>
<p>out the variable with the lowed standardized beta coefficient (fun without alcohol).
</p>
<p>After taking out this variable, we see that the adjusted R-squared increases to 0.4948
</p>
<p>(see Model 2). This indicates that the variable fun without alcohol does not add
</p>
<p>anything substantial to the model and should be removed. In a next step, we remove
</p>
<p>the variable, year of study. Removing this variable leads to another increase in the
</p>
<p>adjusted R-squared (i.e., the new adjusted R-squared is 0.5075), indicating again that
</p>
<p>this variable does not add anything substantively to the model and should be removed
</p>
<p>(see Model 3). Next, we remove the variable gender and see another increase in the
</p>
<p>adjusted R-squared to 0.5194. If we now remove the variable with the lowest adjusted
</p>
<p>R-squared, the study time per week, we find that the adjusted R-squared decreases to
</p>
<p>0.5127 (see Model 5), which is lower than the adjusted R-squared from Model
</p>
<p>4, which is 0.5114. Based on these calculations, we can conclude that Model 4 has
</p>
<p>the best model fit.
</p>
<p>9.10 Assumptions of the Classical Linear Regression Model
or Ordinary Least Square Regression Model (OLS)
</p>
<p>The classical linear regression model (OLS) is the simplest type of regression model.
</p>
<p>OLS only works with a continuous dependent variable. It has ten underlying
</p>
<p>assumptions:
</p>
<p>1. Linearity in the parameters: Linearity in the parameters implies that the
</p>
<p>relationship between a continuous independent variable and a dependent vari-
</p>
<p>able must roughly follow a line. Relationships that do not follow a line (e.g.,
</p>
<p>they might follow a quadratic function or a logarithmic function) must be
</p>
<p>included into the model using the correct functional forms (more advanced
</p>
<p>textbooks in regression analysis will capture these cases).
</p>
<p>Table 9.4 Finding the best model
</p>
<p>Model 1 Model 2 Model 3 Model 4 Model 5
</p>
<p>Quality of extra-curricular activities &ndash;0.421 &ndash;0.415 &ndash;0.416 0.421 &ndash;0.442
</p>
<p>Gender 0.056 0.062 0.051
</p>
<p>Study time per week 0.141 0.200 0.159 0.140
</p>
<p>Year of study 0.065 0.051
</p>
<p>Times partying (two times or less/
</p>
<p>three times or more
</p>
<p>0.387 0.401 0.421 0.418 0.418
</p>
<p>Fun without alcohol &ndash;0.047
</p>
<p>Amount of tuition student pays 0.179 0.218 0.201 0.180 0.150
</p>
<p>Constant 75.47 70.22 76.36 77.53 92.66
</p>
<p>R-squared 0.5731 0.5725 0.5707 56.87 0.5502
</p>
<p>Adjusted R-squared 0.4797 0.4948 0.5075 51.94 0.5127
</p>
<p>9.10 Assumptions of the Classical Linear Regression Model or Ordinary Least. . . 171</p>
<p/>
</div>
<div class="page"><p/>
<p>2. X is fixed: This rule implies that one observation can only have one x and
</p>
<p>one y value.
</p>
<p>3. Mean of disturbance is zero: This follows the rule to draw the ordinary least
</p>
<p>square line. We draw the best fitting line, which implies that the summed up
</p>
<p>distance of the points below the line is the same as the summed up distance
</p>
<p>above the line.
</p>
<p>4. Homoscedasticity: The homoscedasticity assumption implies that the variance
</p>
<p>around the regression line is similar for all the predictor variables around the
</p>
<p>regression line (X) (see Fig. 9.2). To highlight, in the first graph, the points are
</p>
<p>distributed rather equally around a hypothetical line. In the second graph, the
</p>
<p>points are closer to the hypothetical line at the bottom of the graph in com-
</p>
<p>parison to the top of the graph. In our example, the first graph would be an
</p>
<p>example of homoscedasticity and the second graph an example of data suffering
</p>
<p>from heteroscedasticity. At this stage in your learning, it is important that you
</p>
<p>have heard about heteroscedasticity, but details of the problem will be covered
</p>
<p>in more advanced textbooks and classes.
</p>
<p>5. No autocorrelation: There are basically two forms of autocorrelation: (1) con-
</p>
<p>temporaneous correlation, where the dependent variable from one observations
</p>
<p>affects the dependent variable of another observation in the same dataset (e.g.,
</p>
<p>Mexican growth rates might not be independent because growth rates in the
</p>
<p>United States might affect growth rates in Mexico), and (2) autocorrelation in
</p>
<p>pooled time series datasets. That is, past values of the dependent variable
</p>
<p>influence future values of the dependent (e.g., the US growth rate in 2017
</p>
<p>might affect the US growth rate in 2018). This second type of autocorrelation
</p>
<p>is not really pertinent for cross-sectional analysis but becomes relevant for panel
</p>
<p>analysis.
</p>
<p>6. No endogeneity: Endogeneity is one of the fundamental problems in regression
</p>
<p>analysis. Regression analysis is based on the assumption that the independent
</p>
<p>variable impacts the dependent variable but not vice versa. In many real-world
</p>
<p>political science scenarios, this assumption is problematic. For example, there is
</p>
<p>debate in the literature whether high women&rsquo;s representation in instances of
</p>
<p>power influences/decreases corruption or whether low levels of corruption foster
</p>
<p>the election of women (see Esarey and Schwindt-Bayer 2017). There are stati-
</p>
<p>stical remedies such as instrumental regression techniques, which can model a
</p>
<p>feedback loop, that is, more advanced techniques can measure whether two
</p>
<p>variables influence themselves mutually. These techniques will also be covered
</p>
<p>in more advanced books and classes.
</p>
<p>7. No omitted variables: We have an omitted variable problem if we do not
</p>
<p>include a variable in our regression model that theory tells us that we should
</p>
<p>include. Omitting a relevant or important variable from a model can have four
</p>
<p>negative consequences: (1) If the omitted variable is correlated with the included
</p>
<p>variables, then the parameters estimated in the model are biased, meaning that
</p>
<p>their expected values do not match their true values. (2) The error variance of the
</p>
<p>estimated parameters is biased. (3) The confidence intervals of included vari-
</p>
<p>ables and more general the hypothesis testing procedures are unreliable, and
</p>
<p>(4) the R-squared of the estimated model is unreliable.
</p>
<p>172 9 Multivariate Regression Analysis</p>
<p/>
</div>
<div class="page"><p/>
<p>8. More cases than parameters (N &gt; k): Technically, a regression analysis only
</p>
<p>runs if we have more cases than parameters. In more general terms, the regres-
</p>
<p>sion estimates become more reliable the more cases we have.
</p>
<p>9. No constant &ldquo;variables&rdquo;: For an independent variable to explain variation in a
</p>
<p>dependent variable, there must be variation in the independent variable. If there is
</p>
<p>no variation, then there is no reason to include the independent variable in a
</p>
<p>100
</p>
<p>80
</p>
<p>60
</p>
<p>40
</p>
<p>20
</p>
<p>0
</p>
<p>100
</p>
<p>80
</p>
<p>60
</p>
<p>40
</p>
<p>20
</p>
<p>0
</p>
<p>0
</p>
<p>0 20 40 60
</p>
<p>Homoscedasticity
</p>
<p>Heteroscedasticity
</p>
<p>80 100
</p>
<p>20 40 60 80 100
</p>
<p>(Graph image published under the CC-BY-SA-3.0 license
</p>
<p>(http://creativecommons.org/licenses/by-sa/3.0/), via Wikimedia Commons)
</p>
<p>(Graph image published under the CC-BY-SA-3.0 license
</p>
<p>(http://creativecommons.org/licenses/by-sa/3.0/), via Wikimedia Commons)
</p>
<p>Fig. 9.2 Homoscedasticity and heteroscedasticity
</p>
<p>9.10 Assumptions of the Classical Linear Regression Model or Ordinary Least. . . 173</p>
<p/>
</div>
<div class="page"><p/>
<p>regression model. The same applies to the dependent variable. If the dependent
</p>
<p>variable is constant or near constant, and does not vary with independent
</p>
<p>variables, then there is no reason to conduct any analysis in the first place.
</p>
<p>10. No perfect collinearity among regressors: This rule means that the independent
</p>
<p>variables included in a regression should represent different concepts. To high-
</p>
<p>light, the more two variables are correlated, the more they will take explanatory
</p>
<p>power from each other (if they are perfectly collinear, a regression program such
</p>
<p>as Stata or SPSS cannot distinguish these variables from one another). This
</p>
<p>becomes problematic because relevant variables might become nonsignificant
</p>
<p>in a regression model, if they are too highly correlated with other relevant
</p>
<p>variables. More advanced books and classes will also tackle the problem of
</p>
<p>perfect collinearity and multicollinearity. For the purposes of an introductory
</p>
<p>course, it is enough if you have heard about multicollinearity.
</p>
<p>Reference
</p>
<p>Esarey, J., &amp; Schwindt-Bayer, L. A. (2017). Women&rsquo;s representation, accountability and corruption
</p>
<p>in democracies. British Journal of Political Science, 1&ndash;32.
</p>
<p>Further Reading
</p>
<p>Since basically all books listed under bivariate correlation and regression analysis also cover
</p>
<p>multiple regression analysis, the books I present here go beyond the scope of this textbook
</p>
<p>here. These books could be interesting further reads, in particular to students, who want to learn
</p>
<p>more what is covered here.
</p>
<p>Heeringa, S. G., West, B. T., &amp; Berglund, P. A. (2017). Applied survey data analysis. Boca Raton:
</p>
<p>Chapman and Hall/CRC. An overview of different approaches to analyze complex sample
</p>
<p>survey data. In addition to multiple linear regression analysis the topics covered include
</p>
<p>different types of maximum likelihood estimations such as logit, probit, and ordinal regression
</p>
<p>analysis, as well as survival or event history analysis.
</p>
<p>Lewis-Beck, C., &amp; Lewis-Beck, M. (2015). Applied regression: An introduction (Vol. 22).
</p>
<p>Thousand Oaks: Sage A comprehensive introduction into different types of regression techniques.
</p>
<p>Pesaran, M. H. (2015). Time series and panel data econometrics. Oxford: Oxford University Press.
</p>
<p>Comprehensive introduction into different forms of time seriesmodels and panel data estimations.
</p>
<p>Wooldridge, J. M. (2015). Introductory econometrics: A modern approach. Mason, OH: Nelson Edu-
</p>
<p>cation. Comprehensive book about various regression techniques; it is, however, mathematically
</p>
<p>relatively advanced.
</p>
<p>174 9 Multivariate Regression Analysis</p>
<p/>
</div>
<div class="page"><p/>
<p>Appendix 1: The Data of the Sample
Questionnaire
</p>
<p>MSP ST Gender Year TP FWA QECA ATSP
</p>
<p>Student 1 50 7 0 2 2 60 90 30
</p>
<p>Student 2 35 8 1 3 1 70 40 50
</p>
<p>Student 3 120 12 1 3 4 30 20 60
</p>
<p>Student 4 80 3 0 4 4 50 50 100
</p>
<p>Student 5 100 11 0 1 1 30 10 0
</p>
<p>Student 6 120 14 1 5 4 20 20 0
</p>
<p>Student 7 90 11 0 4 2 50 50 0
</p>
<p>Student 8 80 10 1 4 3 40 50 10
</p>
<p>Student 9 70 9 0 3 3 30 50 60
</p>
<p>Student 10 80 8 1 2 3 40 40 100
</p>
<p>Student 11 60 12 1 4 2 60 40 0
</p>
<p>Student 12 50 14 1 2 1 30 70 10
</p>
<p>Student 13 100 13 0 3 4 0 30 0
</p>
<p>Student 14 90 15 0 3 0 0 20 0
</p>
<p>Student 15 60 7 0 3 3 60 50 0
</p>
<p>Student 16 40 6 1 4 0 70 90 0
</p>
<p>Student 17 60 5 1 4 2 80 50 60
</p>
<p>Student 18 90 8 0 5 2 90 30 70
</p>
<p>Student 19 130 12 1 4 5 10 20 50
</p>
<p>Student 20 70 11 0 1 1 20 60 30
</p>
<p>Student 21 80 13 1 3 4 10 70 50
</p>
<p>Student 22 50 6 0 4 4 60 40 10
</p>
<p>Student 23 110 5 1 4 4 70 30 100
</p>
<p>Student 24 60 8 1 2 3 50 60 100
</p>
<p>Student 25 70 10 1 4 2 60 40 80
</p>
<p>Student 26 60 10 1 4 2 40 70 10
</p>
<p>Student 27 50 11 0 3 2 30 50 0
</p>
<p>Student 28 75 4 0 4 3 80 70 0
</p>
<p>Student 29 80 7 0 6 4 90 30 0
</p>
<p>Student 30 30 12 1 3 0 20 80 40
</p>
<p>Student 31 70 7 0 4 3 70 30 10
</p>
<p>Student 32 70 14 1 2 1 0 50 100
</p>
<p>(continued)
</p>
<p># Springer International Publishing AG 2019
</p>
<p>D. Stockemer, Quantitative Methods for the Social Sciences,
</p>
<p>https://doi.org/10.1007/978-3-319-99118-4
</p>
<p>175</p>
<p/>
<div class="annotation"><a href="https://doi.org/10.1007/978-3-319-99118-4">https://doi.org/10.1007/978-3-319-99118-4</a></div>
</div>
<div class="page"><p/>
<p>MSP ST Gender Year TP FWA QECA ATSP
</p>
<p>Student 33 70 3 0 4 3 60 40 50
</p>
<p>Student 34 60 11 1 4 2 50 50 70
</p>
<p>Student 35 70 9 0 2 1 60 20 40
</p>
<p>Student 36 60 11 0 3 1 20 60 60
</p>
<p>Student 37 60 11 1 4 1 30 40 20
</p>
<p>Student 38 90 8 1 1 2 50 10 50
</p>
<p>Student 39 70 9 0 3 3 50 90 30
</p>
<p>Student 40 200 10 1 4 5 40 20 100
</p>
<p>MSPMoney spent partying, ST Study time, Gender Gender, Year Year, TS Times spent parting per
</p>
<p>week, FWA Fun without alcohol, QECA Quality of extra curricula activities, ATSP Amount of
</p>
<p>tuition the student pays
</p>
<p>176 Appendix 1: The Data of the Sample Questionnaire</p>
<p/>
</div>
<div class="page"><p/>
<p>Appendix 2: Possible Group Assignments That
Go with This Course
</p>
<p>As an optional component, this book is built around a practical assignment. The
</p>
<p>assignment consists of a semester-long group project, which gives students the
</p>
<p>opportunity to practically apply their quantitative research skills. In more detail, at
</p>
<p>the beginning of the term, students are assigned to a study/ working group that
</p>
<p>consists of four individuals. Over the course of the semester, each group is expected
</p>
<p>to draft an original questionnaire, solicit 40 respondents of their survey (i.e. 10 per
</p>
<p>student) and perform a set of exercises with their data (i.e. some exercises on
</p>
<p>descriptive statistics, means testing/ correlation and regression analysis).
</p>
<p>Assignment 1:
</p>
<p>Go together in groups of four to five people and design your own questionnaire. It
</p>
<p>should include continuous, dummy and categorical variables (after Chap. 4).
</p>
<p>Assignment 2:
</p>
<p>Each group member should collect ten surveys based on a convenience sample.
</p>
<p>Because of time constraints there is no need to conduct a pre-test of the survey.
</p>
<p>Assignment 3:
</p>
<p>Conduct some descriptive statistics with some of your variables. Also construct a Pie
</p>
<p>Chart, Boxplot and Histogram.
</p>
<p>Assignment 4:
</p>
<p>Your assignment will consist of a number of data exercises
</p>
<p>1. Graph your dependent variable as a histogram
</p>
<p>2. Graph your dependent variable and one continuous independent variable as a
</p>
<p>boxplot
</p>
<p>3. Display some descriptive statistics
</p>
<p>4. Conduct an independent samples t-test. Use the dependent variable of your study;
</p>
<p>as grouping variable use your dichotomous variable (or one of your dichotomous
</p>
<p>variables).
</p>
<p>5. Conduct a one way anova test. Use the dependent variable of your study; As
</p>
<p>factor use one of your ordinal variables
</p>
<p># Springer International Publishing AG 2019
</p>
<p>D. Stockemer, Quantitative Methods for the Social Sciences,
</p>
<p>https://doi.org/10.1007/978-3-319-99118-4
</p>
<p>177</p>
<p/>
<div class="annotation"><a href="https://doi.org/10.1007/978-3-319-99118-4">https://doi.org/10.1007/978-3-319-99118-4</a></div>
</div>
<div class="page"><p/>
<p>6. Run a correlation matrix with your dependent variable and two other continuous
</p>
<p>variables.
</p>
<p>7. Run a multivariate regression analysis with all your independent variables and
</p>
<p>your dependent variable.
</p>
<p>178 Appendix 2: Possible Group Assignments That Go with This Course</p>
<p/>
</div>
<div class="page"><p/>
<p>Index
</p>
<p>A
</p>
<p>Adjusted R-squared, 153, 154, 158, 170, 171
</p>
<p>ANOVA, 111&ndash;113, 115&ndash;118, 120&ndash;122, 124,
</p>
<p>125, 153&ndash;155, 157, 165, 166, 168,
</p>
<p>177
</p>
<p>Autocorrelation, 172
</p>
<p>B
</p>
<p>Boxplot, 80, 84&ndash;86, 88, 177
</p>
<p>C
</p>
<p>Causation
</p>
<p>reversed causation, 18, 32
</p>
<p>Chi-square test, 125&ndash;128, 130, 131
</p>
<p>Collinearity, 174
</p>
<p>Comparative Study of Electoral Systems
</p>
<p>(CSES), 28, 29
</p>
<p>Concepts, 9, 10, 12&ndash;14, 16&ndash;19, 23, 68, 174
</p>
<p>Confidence interval, 91&ndash;97, 108, 110, 122, 141,
</p>
<p>142, 160, 172
</p>
<p>Correlation, 2, 15, 133, 142&ndash;148, 153, 154,
</p>
<p>158, 172, 177, 178
</p>
<p>Cumulative, 7, 10, 53, 76&ndash;78
</p>
<p>D
</p>
<p>Deviation, 91&ndash;97, 107, 109, 115, 120, 143, 154,
</p>
<p>156, 158, 159
</p>
<p>E
</p>
<p>Empirical, 1, 2, 5&ndash;20, 25, 31, 32
</p>
<p>Endogeneity, 32, 172
</p>
<p>Error term, 150, 151, 154, 158
</p>
<p>European Social Survey (ESS), 20, 27, 28, 30,
</p>
<p>33, 59, 60
</p>
<p>F
</p>
<p>Falsifiability, 6
</p>
<p>F-test, 111&ndash;122, 124, 125, 127, 154, 157, 165
</p>
<p>H
</p>
<p>Heteroscedasticity, 172, 173
</p>
<p>Histogram, 80, 82, 83, 87&ndash;91, 104, 105, 108,
</p>
<p>177
</p>
<p>Homoscedasticity, 172, 173
</p>
<p>Hypothesis
</p>
<p>alternative/research hypothesis, 18, 121,
</p>
<p>122
</p>
<p>null hypothesis, 18, 107, 108, 111, 128
</p>
<p>I
</p>
<p>Independent samples t-test, 101&ndash;113, 125, 177
</p>
<p>M
</p>
<p>Means, 1, 2, 6, 26, 29, 40, 46, 64, 67, 79, 80, 87,
</p>
<p>91&ndash;94, 96&ndash;98, 101&ndash;104, 107, 109,
</p>
<p>110, 112, 114, 116, 118, 120&ndash;124,
</p>
<p>133, 143, 146, 148&ndash;150, 154,
</p>
<p>156&ndash;160, 172, 174, 177
</p>
<p>Measure of central tendency, 79, 80, 84
</p>
<p>Measurements, 6, 8, 14, 15, 19, 20, 30, 38, 39,
</p>
<p>54, 68
</p>
<p>Median, 79, 80, 84, 86, 88
</p>
<p>Model fit, 153, 154, 158, 166, 168, 170, 171
</p>
<p>N
</p>
<p>Normal distribution, 87, 88, 90, 92
</p>
<p>Normative, 5, 8, 12, 39, 40
</p>
<p># Springer International Publishing AG 2019
</p>
<p>D. Stockemer, Quantitative Methods for the Social Sciences,
</p>
<p>https://doi.org/10.1007/978-3-319-99118-4
</p>
<p>179</p>
<p/>
<div class="annotation"><a href="https://doi.org/10.1007/978-3-319-99118-4">https://doi.org/10.1007/978-3-319-99118-4</a></div>
</div>
<div class="page"><p/>
<p>O
</p>
<p>Operationalization, 1, 13, 14, 19, 43, 46
</p>
<p>Ordinary least squares (OLS), 171&ndash;173
</p>
<p>P
</p>
<p>Parsimony, 12, 38, 48
</p>
<p>Pie charts, 80&ndash;84, 177
</p>
<p>Population, 12, 23, 25&ndash;27, 29, 30, 32&ndash;34,
</p>
<p>57&ndash;59, 61&ndash;64, 66, 67, 87, 90, 92&ndash;94,
</p>
<p>104, 141, 160
</p>
<p>Pre-test, 30, 68, 69, 104, 108, 177
</p>
<p>Q
</p>
<p>Question
</p>
<p>closed-ended question, 42, 43
</p>
<p>open-ended question, 42, 43, 53, 68
</p>
<p>R
</p>
<p>Range, 13, 26, 33, 45, 79, 80, 84, 86, 93, 94,
</p>
<p>113, 122, 141, 154, 158, 160
</p>
<p>Rational choice, 11
</p>
<p>Regression
</p>
<p>bivariate regression, 138, 140, 148&ndash;150,
</p>
<p>152&ndash;161, 163, 165, 166
</p>
<p>multiple regression, 1, 156, 159, 163&ndash;170
</p>
<p>regression coefficient, 149, 154&ndash;156, 159,
</p>
<p>167, 169
</p>
<p>standardized regression coefficient, 156, 159
</p>
<p>Research
</p>
<p>qualitative research, 8&ndash;10, 27
</p>
<p>quantitative research, 2, 8&ndash;10, 18&ndash;20, 42,
</p>
<p>43, 165, 177
</p>
<p>Residual, 150, 154, 158
</p>
<p>R-squared, 153, 154, 158, 160, 161, 168, 170&ndash;172
</p>
<p>S
</p>
<p>Sample
</p>
<p>biased sample, 58&ndash;61, 66
</p>
<p>non-random sampling
</p>
<p>convenience sampling, 62, 67
</p>
<p>purposive sampling, 62, 63
</p>
<p>quota sampling, 63
</p>
<p>snowball sampling, 62, 63
</p>
<p>volunteer sampling, 62, 63
</p>
<p>random sample, 23, 28, 58&ndash;62, 93, 96, 98,
</p>
<p>164
</p>
<p>representative sample, 20, 23, 27, 58&ndash;61,
</p>
<p>64, 67
</p>
<p>Sampling, 19, 26, 30, 57, 59, 62&ndash;65, 67, 91&ndash;97
</p>
<p>Sampling error, 62, 91&ndash;97
</p>
<p>Scales
</p>
<p>Guttman scale, 44, 46
</p>
<p>Likert scale, 44, 45, 49, 68
</p>
<p>Scatterplot, 134&ndash;144, 148, 152, 156, 165
</p>
<p>Social desirability
</p>
<p>social desirability bias, 41, 42, 60, 65
</p>
<p>Standard deviation, 91&ndash;97, 107, 109, 120, 143,
</p>
<p>154, 156, 158, 159
</p>
<p>Standard error
</p>
<p>standard error of the estimate, 153, 154, 158
</p>
<p>Statistical significance, 107
</p>
<p>Statistics
</p>
<p>bivariate statistics, 101&ndash;131
</p>
<p>descriptive statitistics, 1, 77, 95, 98, 120,
</p>
<p>128, 177
</p>
<p>univariate statistics, 2
</p>
<p>Survey
</p>
<p>cohort survey, 33
</p>
<p>cross sectional survey, 29&ndash;32
</p>
<p>face-to-face survey, 64, 65, 67
</p>
<p>longitudinal survey, 30, 32, 33
</p>
<p>mail in survey, 65, 66
</p>
<p>online survey, 60, 61, 63&ndash;67
</p>
<p>panel survey, 33, 34
</p>
<p>telephone survey, 64, 65, 67
</p>
<p>trend survey, 32
</p>
<p>T
</p>
<p>Theory, 9&ndash;12, 16&ndash;19, 31, 40, 50, 52, 136, 149,
</p>
<p>154, 158, 170, 172
</p>
<p>Transmissibility, 7
</p>
<p>V
</p>
<p>Validity
</p>
<p>construct validity, 41
</p>
<p>content validity, 14, 15, 19
</p>
<p>Variable
</p>
<p>continuous variable, 50&ndash;53, 87, 104, 111,
</p>
<p>114, 125, 133&ndash;161, 177
</p>
<p>control variable, 16, 19, 20, 53
</p>
<p>dependent variable, 16&ndash;20, 31, 32, 53, 74,
</p>
<p>75, 80, 101, 104, 108, 113, 114, 119,
</p>
<p>125, 127, 130, 133&ndash;137, 139, 141,
</p>
<p>142, 144, 148&ndash;150, 152, 154&ndash;161,
</p>
<p>163&ndash;166, 168, 170&ndash;173, 177, 178
</p>
<p>dichotomous variable, 50&ndash;53, 104, 177
</p>
<p>dummy variable, 50, 51, 111, 156, 159, 165,
</p>
<p>170, 177
</p>
<p>180 Index</p>
<p/>
</div>
<div class="page"><p/>
<p>independent variable, 16&ndash;18, 20, 24, 31, 33,
</p>
<p>34, 38, 53, 74&ndash;76, 102, 119, 125,
</p>
<p>133, 134, 136, 137, 139, 142,
</p>
<p>148&ndash;150, 152, 154&ndash;161, 163, 165,
</p>
<p>166, 168, 170&ndash;174, 177, 178
</p>
<p>interval variable, 50
</p>
<p>nominal variable, 50&ndash;53, 111, 165
</p>
<p>omitted variable, 172
</p>
<p>ordinal variable, 44, 46, 50&ndash;53, 76, 111,
</p>
<p>114, 165, 166, 168, 177
</p>
<p>string variable, 50&ndash;52, 74, 75
</p>
<p>W
</p>
<p>World Value Survey (WVS), 15, 27&ndash;29, 33
</p>
<p>Index 181</p>
<p/>
</div>
<ul>	<li>Contents</li>
	<li>1: Introduction</li>
	<li>2: The Nuts and Bolts of Empirical Social Science</li>
<ul>	<li>2.1 What Is Empirical Research in the Social Sciences?</li>
	<li>2.2 Qualitative and Quantitative Research</li>
	<li>2.3 Theories, Concepts, Variables, and Hypothesis</li>
<ul>	<li>2.3.1 Theories</li>
	<li>2.3.2 Concepts</li>
	<li>2.3.3 Variables</li>
<ul>	<li>2.3.3.1 Types of Variables</li>
</ul>
	<li>2.3.4 Hypotheses</li>
</ul>
	<li>2.4 The Quantitative Research Process</li>
	<li>References</li>
<ul>	<li>Further Reading</li>
	<li>Research Design</li>
	<li>Theories and Hypotheses</li>
	<li>Qualitative Research</li>
</ul>
</ul>
	<li>3: A Short Introduction to Survey Research</li>
<ul>	<li>3.1 What Is Survey Research?</li>
	<li>3.2 A Short History of Survey Research</li>
	<li>3.3 The Importance of Survey Research in the Social Sciences and Beyond</li>
	<li>3.4 Overview of Some of the Most Widely Used Surveys in the Social Sciences</li>
<ul>	<li>3.4.1 The Comparative Study of Electoral Systems (CSES)</li>
	<li>3.4.2 The World Values Survey (WVS)</li>
	<li>3.4.3 The European Social Survey (ESS)</li>
</ul>
	<li>3.5 Different Types of Surveys</li>
<ul>	<li>3.5.1 Cross-sectional Survey</li>
	<li>3.5.2 Longitudinal Survey</li>
<ul>	<li>3.5.2.1 Trend Surveys</li>
	<li>3.5.2.2 Cohort Surveys</li>
	<li>3.5.2.3 Panel Surveys</li>
</ul>
</ul>
	<li>References</li>
<ul>	<li>Further Reading</li>
	<li>Why Do We Need Survey Research?</li>
	<li>Applied Survey Research</li>
</ul>
</ul>
	<li>4: Constructing a Survey</li>
<ul>	<li>4.1 Question Design</li>
	<li>4.2 Ordering of Questions</li>
	<li>4.3 Number of Questions</li>
	<li>4.4 Getting the Questions Right</li>
<ul>	<li>4.4.1 Vague Questions</li>
	<li>4.4.2 Biased or Value-Laden Questions</li>
	<li>4.4.3 Threatening Questions</li>
	<li>4.4.4 Complex Questions</li>
	<li>4.4.5 Negative Questions</li>
	<li>4.4.6 Pointless Questions</li>
</ul>
	<li>4.5 Social Desirability</li>
	<li>4.6 Open-Ended and Closed-Ended Questions</li>
	<li>4.7 Types of Closed-Ended Survey Questions</li>
<ul>	<li>4.7.1 Scales</li>
	<li>4.7.2 Dichotomous Survey Questions</li>
	<li>4.7.3 Multiple-Choice Questions</li>
	<li>4.7.4 Numerical Continuous Questions</li>
	<li>4.7.5 Categorical Survey Questions</li>
	<li>4.7.6 Rank-Order Questions</li>
	<li>4.7.7 Matrix Table Questions</li>
</ul>
	<li>4.8 Different Variables</li>
	<li>4.9 Coding of Different Variables in a Dataset</li>
<ul>	<li>4.9.1 Coding of Nominal Variables</li>
</ul>
	<li>4.10 Drafting a Questionnaire: General Information</li>
<ul>	<li>4.10.1 Drafting a Questionnaire: A Step-by-Step Approach</li>
<ul>	<li>Sample Questionnaire</li>
</ul>
</ul>
	<li>4.11 Background Information About the Questionnaire</li>
	<li>References</li>
<ul>	<li>Further Reading</li>
	<li>Nuts and Bolts of Survey Research</li>
	<li>Constructing a Survey</li>
	<li>Applied Texts: Question Wording</li>
</ul>
</ul>
	<li>5: Conducting a Survey</li>
<ul>	<li>5.1 Population and Sample</li>
	<li>5.2 Representative, Random, and Biased Samples</li>
	<li>5.3 Sampling Error</li>
	<li>5.4 Non-random Sampling Techniques</li>
	<li>5.5 Different Types of Surveys</li>
	<li>5.6 Which Type of Survey Should Researchers Use?</li>
	<li>5.7 Pre-tests</li>
<ul>	<li>5.7.1 What Is a Pre-test?</li>
	<li>5.7.2 How to Conduct a Pre-test?</li>
</ul>
	<li>References</li>
<ul>	<li>Further Reading</li>
	<li>Constructing and Conducting a Survey</li>
	<li>Internet Survey</li>
</ul>
</ul>
	<li>6: Univariate Statistics</li>
<ul>	<li>6.1 SPSS and Stata</li>
	<li>6.2 Putting Data into an SPSS Spreadsheet</li>
	<li>6.3 Putting Data into a Stata Spreadsheet</li>
	<li>6.4 Frequency Tables</li>
<ul>	<li>6.4.1 Constructing a Frequency Table in SPSS</li>
	<li>6.4.2 Constructing a Frequency Table in Stata</li>
</ul>
	<li>6.5 The Measures of Central Tendency: Mean, Median, Mode, and Range</li>
	<li>6.6 Displaying Data Graphically: Pie Charts, Boxplots, and Histograms</li>
<ul>	<li>6.6.1 Pie Charts</li>
	<li>6.6.2 Doing a Pie Chart in SPSS</li>
	<li>6.6.3 Doing a Pie Chart in Stata</li>
</ul>
	<li>6.7 Boxplots</li>
<ul>	<li>6.7.1 Doing a Boxplot in SPSS</li>
	<li>6.7.2 Doing a Boxplot in Stata</li>
</ul>
	<li>6.8 Histograms</li>
<ul>	<li>6.8.1 Doing a Histogram in SPSS</li>
	<li>6.8.2 Doing a Histogram in Stata</li>
</ul>
	<li>6.9 Deviation, Variance, Standard Deviation, Standard Error, Sampling Error, and Confidence Interval</li>
<ul>	<li>6.9.1 Calculating the Confidence Interval in SPSS</li>
	<li>6.9.2 Calculating the Confidence Interval in Stata</li>
</ul>
	<li>Further Reading</li>
<ul>	<li>SPSS Introductory Books</li>
	<li>Stata Introductory Books</li>
	<li>Univariate and Descriptive Statistics</li>
</ul>
</ul>
	<li>7: Bivariate Statistics with Categorical Variables</li>
<ul>	<li>7.1 Independent Sample t-Test</li>
<ul>	<li>7.1.1 Doing an Independent Samples t-Test in SPSS</li>
	<li>7.1.2 Interpreting an Independent Samples t-Test SPSS Output</li>
	<li>7.1.3 Reading an SPSS Independent Samples t-Test Output Column by Column</li>
	<li>7.1.4 Doing an Independent Samples t-Test in Stata</li>
	<li>7.1.5 Interpreting an Independent Samples t-Test Stata Output</li>
	<li>7.1.6 Reporting the Results of an Independent Samples t-Test</li>
</ul>
	<li>7.2 F-Test or One-Way ANOVA</li>
<ul>	<li>7.2.1 Doing an f-Test in SPSS</li>
	<li>7.2.2 Interpreting an SPSS ANOVA Output</li>
	<li>7.2.3 Doing a Post hoc or Multiple Comparison Test in SPSS</li>
	<li>7.2.4 Doing an f-Test in Stata</li>
	<li>7.2.5 Interpreting an f-Test in Stata</li>
	<li>7.2.6 Doing a Post hoc or Multiple Comparison Test with Unequal Variance in Stata</li>
	<li>7.2.7 Reporting the Results of an f-Test</li>
</ul>
	<li>7.3 Cross-tabulation Table and Chi-Square Test</li>
<ul>	<li>7.3.1 Cross-tabulation Table</li>
	<li>7.3.2 Chi-Square Test</li>
	<li>7.3.3 Doing a Chi-Square Test in SPSS</li>
	<li>7.3.4 Interpreting an SPSS Chi-Square Test</li>
	<li>7.3.5 Doing a Chi-Square Test in Stata</li>
	<li>7.3.6 Reporting a Chi-Square Test Result</li>
</ul>
	<li>Reference</li>
<ul>	<li>Further Reading</li>
	<li>Statistics Textbooks</li>
	<li>Presenting Results in Publications</li>
</ul>
</ul>
	<li>8: Bivariate Relationships Featuring Two Continuous Variables</li>
<ul>	<li>8.1 What Is a Bivariate Relationship Between Two Continuous Variables?</li>
<ul>	<li>8.1.1 Positive and Negative Relationships</li>
</ul>
	<li>8.2 Scatterplots</li>
<ul>	<li>8.2.1 Positive Relationships Displayed in a Scatterplot</li>
	<li>8.2.2 Negative Relationships Displayed in a Scatterplot</li>
	<li>8.2.3 No Relationship Displayed in a Scatterplot</li>
</ul>
	<li>8.3 Drawing the Line in a Scatterplot</li>
	<li>8.4 Doing Scatterplots in SPSS</li>
	<li>8.5 Doing Scatterplots in Stata</li>
	<li>8.6 Correlation Analysis</li>
<ul>	<li>8.6.1 Doing a Correlation Analysis in SPSS</li>
	<li>8.6.2 Interpreting an SPSS Correlation Output</li>
	<li>8.6.3 Doing a Correlation Analysis in Stata</li>
</ul>
	<li>8.7 Bivariate Regression Analysis</li>
<ul>	<li>8.7.1 Gauging the Steepness of a Regression Line</li>
	<li>8.7.2 Gauging the Error Term</li>
</ul>
	<li>8.8 Doing a Bivariate Regression Analysis in SPSS</li>
	<li>8.9 Interpreting an SPSS (Bivariate) Regression Output</li>
<ul>	<li>8.9.1 The Model Summary Table</li>
	<li>8.9.2 The Regression ANOVA Table</li>
	<li>8.9.3 The Regression Coefficient Table</li>
</ul>
	<li>8.10 Doing a (Bivariate) Regression Analysis in Stata</li>
<ul>	<li>8.10.1 Interpreting a Stata (Bivariate) Regression Output</li>
	<li>8.10.2 Reporting and Interpreting the Results of a Bivariate Regression Model</li>
</ul>
	<li>Further Reading</li>
</ul>
	<li>9: Multivariate Regression Analysis</li>
<ul>	<li>9.1 The Logic Behind Multivariate Regression Analysis</li>
	<li>9.2 The Functional Forms of Independent Variables to Include in a Multivariate Regression Model</li>
	<li>9.3 Interpretation Help for a Multivariate Regression Model</li>
	<li>9.4 Doing a Multiple Regression Model in SPSS</li>
	<li>9.5 Interpreting a Multiple Regression Model in SPSS</li>
	<li>9.6 Doing a Multiple Regression Model in Stata</li>
	<li>9.7 Interpreting a Multiple Regression Model in Stata</li>
	<li>9.8 Reporting the Results of a Multiple Regression Analysis</li>
	<li>9.9 Finding the Best Model</li>
	<li>9.10 Assumptions of the Classical Linear Regression Model or Ordinary Least Square Regression Model (OLS)</li>
	<li>Reference</li>
<ul>	<li>Further Reading</li>
</ul>
</ul>
	<li>Appendix 1: The Data of the Sample Questionnaire</li>
	<li>Appendix 2: Possible Group Assignments That Go with This Course</li>
	<li>Index</li>
</ul>
</body></html>